Using cuda:0
Model Setting
    hidden dim:8
    layers: 1
    alpha: 0.200000
    beta: 1.000000
    eigs dim: 64
    sample hop: 1
model: eig+path
Train Setting
    epochs: 1000
    learning rate: 0.010000
Data Setting
    train: /kaggle/input/sigformer-datasets/1kSberData/train.txt
    valid: /kaggle/input/sigformer-datasets/1kSberData/valid.txt
    test: /kaggle/input/sigformer-datasets/1kSberData/test.txt
    offset: 0.5
Test Setting
    valid interval: 20
    test batch size: 256
    stopping step: 10
    topks:  [5, 10, 15, 20]
---------------------------
users: 999, items: 7403.
train: 1831515 pos + 2867825 neg.
valid: 337195 pos + 492637 neg.
test: 580187 pos + 802613 neg.
[0/1000] Valid Result: ndcg@5 = 0.002924, recall@5 = 0.000055, pre@5 = 0.002683.
[0/1000] Valid Result: ndcg@10 = 0.003077, recall@10 = 0.000096, pre@10 = 0.002993.
[0/1000] Valid Result: ndcg@15 = 0.003082, recall@15 = 0.000136, pre@15 = 0.003027.
[0/1000] Valid Result: ndcg@20 = 0.003294, recall@20 = 0.000208, pre@20 = 0.003354.
Test Result(at 0 epoch):
ndcg@5 = 0.011087, recall@5 = 0.000190, pre@5 = 0.011359.
ndcg@10 = 0.011357, recall@10 = 0.000309, pre@10 = 0.011562.
ndcg@15 = 0.011729, recall@15 = 0.000437, pre@15 = 0.012035.
ndcg@20 = 0.011507, recall@20 = 0.000531, pre@20 = 0.011613.
epoch 1, train_loss = 0.674890
epoch 2, train_loss = 0.659189
epoch 3, train_loss = 0.645236
epoch 4, train_loss = 0.632467
epoch 5, train_loss = 0.620102
epoch 6, train_loss = 0.607691
epoch 7, train_loss = 0.595230
epoch 8, train_loss = 0.582678
epoch 9, train_loss = 0.570166
epoch 10, train_loss = 0.557887
epoch 11, train_loss = 0.546066
epoch 12, train_loss = 0.534787
epoch 13, train_loss = 0.524132
epoch 14, train_loss = 0.514050
epoch 15, train_loss = 0.504701
epoch 16, train_loss = 0.496019
epoch 17, train_loss = 0.487917
epoch 18, train_loss = 0.480849
epoch 19, train_loss = 0.473998
epoch 20, train_loss = 0.467808
[20/1000] Valid Result: ndcg@5 = 0.005487, recall@5 = 0.000213, pre@5 = 0.005779.
[20/1000] Valid Result: ndcg@10 = 0.005966, recall@10 = 0.000479, pre@10 = 0.006295.
[20/1000] Valid Result: ndcg@15 = 0.006769, recall@15 = 0.000651, pre@15 = 0.007362.
[20/1000] Valid Result: ndcg@20 = 0.006832, recall@20 = 0.000853, pre@20 = 0.007276.
Test Result(at 20 epoch):
ndcg@5 = 0.013751, recall@5 = 0.000234, pre@5 = 0.013793.
ndcg@10 = 0.013359, recall@10 = 0.000398, pre@10 = 0.013185.
ndcg@15 = 0.013930, recall@15 = 0.000596, pre@15 = 0.014131.
ndcg@20 = 0.013828, recall@20 = 0.000790, pre@20 = 0.013945.
epoch 21, train_loss = 0.462139
epoch 22, train_loss = 0.456999
epoch 23, train_loss = 0.452268
epoch 24, train_loss = 0.447782
epoch 25, train_loss = 0.443620
epoch 26, train_loss = 0.439711
epoch 27, train_loss = 0.436247
epoch 28, train_loss = 0.433015
epoch 29, train_loss = 0.429932
epoch 30, train_loss = 0.427105
epoch 31, train_loss = 0.424279
epoch 32, train_loss = 0.421679
epoch 33, train_loss = 0.419237
epoch 34, train_loss = 0.416978
epoch 35, train_loss = 0.414849
epoch 36, train_loss = 0.412711
epoch 37, train_loss = 0.410869
epoch 38, train_loss = 0.408845
epoch 39, train_loss = 0.407341
epoch 40, train_loss = 0.405388
[40/1000] Valid Result: ndcg@5 = 0.006939, recall@5 = 0.000394, pre@5 = 0.007637.
[40/1000] Valid Result: ndcg@10 = 0.008355, recall@10 = 0.000636, pre@10 = 0.009288.
[40/1000] Valid Result: ndcg@15 = 0.009164, recall@15 = 0.001080, pre@15 = 0.010045.
[40/1000] Valid Result: ndcg@20 = 0.009438, recall@20 = 0.001305, pre@20 = 0.010165.
Test Result(at 40 epoch):
ndcg@5 = 0.018936, recall@5 = 0.000438, pre@5 = 0.018458.
ndcg@10 = 0.018886, recall@10 = 0.000711, pre@10 = 0.018661.
ndcg@15 = 0.019135, recall@15 = 0.000941, pre@15 = 0.019067.
ndcg@20 = 0.019198, recall@20 = 0.001283, pre@20 = 0.019168.
epoch 41, train_loss = 0.403886
epoch 42, train_loss = 0.402307
epoch 43, train_loss = 0.400786
epoch 44, train_loss = 0.399435
epoch 45, train_loss = 0.397960
epoch 46, train_loss = 0.396554
epoch 47, train_loss = 0.395274
epoch 48, train_loss = 0.393963
epoch 49, train_loss = 0.393105
epoch 50, train_loss = 0.391918
epoch 51, train_loss = 0.390699
epoch 52, train_loss = 0.389838
epoch 53, train_loss = 0.388864
epoch 54, train_loss = 0.388114
epoch 55, train_loss = 0.387461
epoch 56, train_loss = 0.386493
epoch 57, train_loss = 0.385890
epoch 58, train_loss = 0.385154
epoch 59, train_loss = 0.384727
epoch 60, train_loss = 0.384464
[60/1000] Valid Result: ndcg@5 = 0.009900, recall@5 = 0.000480, pre@5 = 0.010733.
[60/1000] Valid Result: ndcg@10 = 0.009446, recall@10 = 0.000697, pre@10 = 0.009701.
[60/1000] Valid Result: ndcg@15 = 0.009791, recall@15 = 0.000970, pre@15 = 0.010045.
[60/1000] Valid Result: ndcg@20 = 0.010214, recall@20 = 0.001224, pre@20 = 0.010526.
Test Result(at 60 epoch):
ndcg@5 = 0.020115, recall@5 = 0.000388, pre@5 = 0.020284.
ndcg@10 = 0.020193, recall@10 = 0.000700, pre@10 = 0.020385.
ndcg@15 = 0.020448, recall@15 = 0.000992, pre@15 = 0.020690.
ndcg@20 = 0.020778, recall@20 = 0.001307, pre@20 = 0.021095.
epoch 61, train_loss = 0.383721
epoch 62, train_loss = 0.383337
epoch 63, train_loss = 0.383088
epoch 64, train_loss = 0.382646
epoch 65, train_loss = 0.382277
epoch 66, train_loss = 0.381828
epoch 67, train_loss = 0.381544
epoch 68, train_loss = 0.381227
epoch 69, train_loss = 0.381161
epoch 70, train_loss = 0.380827
epoch 71, train_loss = 0.380571
epoch 72, train_loss = 0.380608
epoch 73, train_loss = 0.380302
epoch 74, train_loss = 0.380206
epoch 75, train_loss = 0.380090
epoch 76, train_loss = 0.380201
epoch 77, train_loss = 0.380204
epoch 78, train_loss = 0.380127
epoch 79, train_loss = 0.380103
epoch 80, train_loss = 0.380227
[80/1000] Valid Result: ndcg@5 = 0.010022, recall@5 = 0.000507, pre@5 = 0.010114.
[80/1000] Valid Result: ndcg@10 = 0.010377, recall@10 = 0.000748, pre@10 = 0.010526.
[80/1000] Valid Result: ndcg@15 = 0.010841, recall@15 = 0.001066, pre@15 = 0.011077.
[80/1000] Valid Result: ndcg@20 = 0.010671, recall@20 = 0.001276, pre@20 = 0.010681.
Test Result(at 80 epoch):
ndcg@5 = 0.019539, recall@5 = 0.000387, pre@5 = 0.019878.
ndcg@10 = 0.020710, recall@10 = 0.000709, pre@10 = 0.021400.
ndcg@15 = 0.021892, recall@15 = 0.001043, pre@15 = 0.022921.
ndcg@20 = 0.022109, recall@20 = 0.001409, pre@20 = 0.022972.
epoch 81, train_loss = 0.380356
epoch 82, train_loss = 0.380545
epoch 83, train_loss = 0.380637
epoch 84, train_loss = 0.380952
epoch 85, train_loss = 0.381010
epoch 86, train_loss = 0.381310
epoch 87, train_loss = 0.381536
epoch 88, train_loss = 0.382096
epoch 89, train_loss = 0.382248
epoch 90, train_loss = 0.382718
epoch 91, train_loss = 0.383196
epoch 92, train_loss = 0.383728
epoch 93, train_loss = 0.384195
epoch 94, train_loss = 0.384646
epoch 95, train_loss = 0.385259
epoch 96, train_loss = 0.385610
epoch 97, train_loss = 0.386527
epoch 98, train_loss = 0.387006
epoch 99, train_loss = 0.387960
epoch 100, train_loss = 0.388572
[100/1000] Valid Result: ndcg@5 = 0.010273, recall@5 = 0.000566, pre@5 = 0.010526.
[100/1000] Valid Result: ndcg@10 = 0.010691, recall@10 = 0.000790, pre@10 = 0.010939.
[100/1000] Valid Result: ndcg@15 = 0.010839, recall@15 = 0.001032, pre@15 = 0.011008.
[100/1000] Valid Result: ndcg@20 = 0.010866, recall@20 = 0.001321, pre@20 = 0.010939.
Test Result(at 100 epoch):
ndcg@5 = 0.019472, recall@5 = 0.000314, pre@5 = 0.019878.
ndcg@10 = 0.021259, recall@10 = 0.000654, pre@10 = 0.022211.
ndcg@15 = 0.022657, recall@15 = 0.001148, pre@15 = 0.023935.
ndcg@20 = 0.022555, recall@20 = 0.001405, pre@20 = 0.023479.
epoch 101, train_loss = 0.389589
epoch 102, train_loss = 0.390383
epoch 103, train_loss = 0.391378
epoch 104, train_loss = 0.392314
epoch 105, train_loss = 0.393801
epoch 106, train_loss = 0.395021
epoch 107, train_loss = 0.396097
epoch 108, train_loss = 0.397514
epoch 109, train_loss = 0.398873
epoch 110, train_loss = 0.400330
epoch 111, train_loss = 0.401684
epoch 112, train_loss = 0.403081
epoch 113, train_loss = 0.404604
epoch 114, train_loss = 0.405906
epoch 115, train_loss = 0.407485
epoch 116, train_loss = 0.408998
epoch 117, train_loss = 0.410296
epoch 118, train_loss = 0.411923
epoch 119, train_loss = 0.413529
epoch 120, train_loss = 0.415091
[120/1000] Valid Result: ndcg@5 = 0.009140, recall@5 = 0.000189, pre@5 = 0.008462.
[120/1000] Valid Result: ndcg@10 = 0.009853, recall@10 = 0.000590, pre@10 = 0.009804.
[120/1000] Valid Result: ndcg@15 = 0.010574, recall@15 = 0.000978, pre@15 = 0.010802.
[120/1000] Valid Result: ndcg@20 = 0.010400, recall@20 = 0.001157, pre@20 = 0.010423.
epoch 121, train_loss = 0.416662
epoch 122, train_loss = 0.418403
epoch 123, train_loss = 0.419980
epoch 124, train_loss = 0.421854
epoch 125, train_loss = 0.423489
epoch 126, train_loss = 0.425305
epoch 127, train_loss = 0.426982
epoch 128, train_loss = 0.428853
epoch 129, train_loss = 0.430653
epoch 130, train_loss = 0.432624
epoch 131, train_loss = 0.434340
epoch 132, train_loss = 0.436297
epoch 133, train_loss = 0.438044
epoch 134, train_loss = 0.439985
epoch 135, train_loss = 0.441993
epoch 136, train_loss = 0.443758
epoch 137, train_loss = 0.445830
epoch 138, train_loss = 0.447822
epoch 139, train_loss = 0.449622
epoch 140, train_loss = 0.451521
[140/1000] Valid Result: ndcg@5 = 0.006561, recall@5 = 0.000124, pre@5 = 0.006398.
[140/1000] Valid Result: ndcg@10 = 0.008001, recall@10 = 0.000460, pre@10 = 0.008566.
[140/1000] Valid Result: ndcg@15 = 0.008413, recall@15 = 0.000681, pre@15 = 0.009013.
[140/1000] Valid Result: ndcg@20 = 0.008765, recall@20 = 0.000865, pre@20 = 0.009391.
epoch 141, train_loss = 0.453418
epoch 142, train_loss = 0.455424
epoch 143, train_loss = 0.457570
epoch 144, train_loss = 0.459429
epoch 145, train_loss = 0.461641
epoch 146, train_loss = 0.463528
epoch 147, train_loss = 0.465588
epoch 148, train_loss = 0.467561
epoch 149, train_loss = 0.469633
epoch 150, train_loss = 0.471442
epoch 151, train_loss = 0.473329
epoch 152, train_loss = 0.475256
epoch 153, train_loss = 0.476926
epoch 154, train_loss = 0.478471
epoch 155, train_loss = 0.480042
epoch 156, train_loss = 0.481449
epoch 157, train_loss = 0.482971
epoch 158, train_loss = 0.484029
epoch 159, train_loss = 0.485110
epoch 160, train_loss = 0.486113
[160/1000] Valid Result: ndcg@5 = 0.004574, recall@5 = 0.000099, pre@5 = 0.004954.
[160/1000] Valid Result: ndcg@10 = 0.006183, recall@10 = 0.000300, pre@10 = 0.007018.
[160/1000] Valid Result: ndcg@15 = 0.006521, recall@15 = 0.000421, pre@15 = 0.007224.
[160/1000] Valid Result: ndcg@20 = 0.007090, recall@20 = 0.000617, pre@20 = 0.007895.
epoch 161, train_loss = 0.486894
epoch 162, train_loss = 0.487616
epoch 163, train_loss = 0.488447
epoch 164, train_loss = 0.489026
epoch 165, train_loss = 0.489485
epoch 166, train_loss = 0.489987
epoch 167, train_loss = 0.490259
epoch 168, train_loss = 0.490633
epoch 169, train_loss = 0.490813
epoch 170, train_loss = 0.490960
epoch 171, train_loss = 0.490926
epoch 172, train_loss = 0.490805
epoch 173, train_loss = 0.490506
epoch 174, train_loss = 0.490386
epoch 175, train_loss = 0.489999
epoch 176, train_loss = 0.489580
epoch 177, train_loss = 0.489280
epoch 178, train_loss = 0.488980
epoch 179, train_loss = 0.488560
epoch 180, train_loss = 0.488207
[180/1000] Valid Result: ndcg@5 = 0.005264, recall@5 = 0.000110, pre@5 = 0.005573.
[180/1000] Valid Result: ndcg@10 = 0.005942, recall@10 = 0.000299, pre@10 = 0.006398.
[180/1000] Valid Result: ndcg@15 = 0.006827, recall@15 = 0.000691, pre@15 = 0.007499.
[180/1000] Valid Result: ndcg@20 = 0.007326, recall@20 = 0.000936, pre@20 = 0.008050.
epoch 181, train_loss = 0.487675
epoch 182, train_loss = 0.486982
epoch 183, train_loss = 0.486123
epoch 184, train_loss = 0.485366
epoch 185, train_loss = 0.484622
epoch 186, train_loss = 0.483875
epoch 187, train_loss = 0.483246
epoch 188, train_loss = 0.482451
epoch 189, train_loss = 0.481694
epoch 190, train_loss = 0.481128
epoch 191, train_loss = 0.480476
epoch 192, train_loss = 0.479904
epoch 193, train_loss = 0.479537
epoch 194, train_loss = 0.479267
epoch 195, train_loss = 0.479056
epoch 196, train_loss = 0.478615
epoch 197, train_loss = 0.478530
epoch 198, train_loss = 0.478409
epoch 199, train_loss = 0.478306
epoch 200, train_loss = 0.478107
[200/1000] Valid Result: ndcg@5 = 0.008001, recall@5 = 0.000177, pre@5 = 0.007843.
[200/1000] Valid Result: ndcg@10 = 0.007757, recall@10 = 0.000384, pre@10 = 0.007637.
[200/1000] Valid Result: ndcg@15 = 0.008115, recall@15 = 0.000712, pre@15 = 0.008187.
[200/1000] Valid Result: ndcg@20 = 0.008493, recall@20 = 0.001020, pre@20 = 0.008720.
epoch 201, train_loss = 0.478021
epoch 202, train_loss = 0.477915
epoch 203, train_loss = 0.477819
epoch 204, train_loss = 0.477889
epoch 205, train_loss = 0.477819
epoch 206, train_loss = 0.477733
epoch 207, train_loss = 0.477915
epoch 208, train_loss = 0.477901
epoch 209, train_loss = 0.477881
epoch 210, train_loss = 0.478042
epoch 211, train_loss = 0.478003
epoch 212, train_loss = 0.478103
epoch 213, train_loss = 0.478292
epoch 214, train_loss = 0.478201
epoch 215, train_loss = 0.478504
epoch 216, train_loss = 0.478462
epoch 217, train_loss = 0.478530
epoch 218, train_loss = 0.478401
epoch 219, train_loss = 0.478268
epoch 220, train_loss = 0.478213
[220/1000] Valid Result: ndcg@5 = 0.009823, recall@5 = 0.000360, pre@5 = 0.010114.
[220/1000] Valid Result: ndcg@10 = 0.008858, recall@10 = 0.000563, pre@10 = 0.008566.
[220/1000] Valid Result: ndcg@15 = 0.008573, recall@15 = 0.000715, pre@15 = 0.008187.
[220/1000] Valid Result: ndcg@20 = 0.008474, recall@20 = 0.000897, pre@20 = 0.008101.
epoch 221, train_loss = 0.478032
epoch 222, train_loss = 0.477958
epoch 223, train_loss = 0.477820
epoch 224, train_loss = 0.477746
epoch 225, train_loss = 0.477566
epoch 226, train_loss = 0.477489
epoch 227, train_loss = 0.477314
epoch 228, train_loss = 0.477295
epoch 229, train_loss = 0.477191
epoch 230, train_loss = 0.477212
epoch 231, train_loss = 0.477084
epoch 232, train_loss = 0.477118
epoch 233, train_loss = 0.476979
epoch 234, train_loss = 0.476940
epoch 235, train_loss = 0.477025
epoch 236, train_loss = 0.477014
epoch 237, train_loss = 0.477176
epoch 238, train_loss = 0.477149
epoch 239, train_loss = 0.477234
epoch 240, train_loss = 0.477521
[240/1000] Valid Result: ndcg@5 = 0.008223, recall@5 = 0.000292, pre@5 = 0.008669.
[240/1000] Valid Result: ndcg@10 = 0.008159, recall@10 = 0.000470, pre@10 = 0.008256.
[240/1000] Valid Result: ndcg@15 = 0.008028, recall@15 = 0.000701, pre@15 = 0.007912.
[240/1000] Valid Result: ndcg@20 = 0.008183, recall@20 = 0.000888, pre@20 = 0.008101.
epoch 241, train_loss = 0.477386
epoch 242, train_loss = 0.477604
epoch 243, train_loss = 0.477893
epoch 244, train_loss = 0.477819
epoch 245, train_loss = 0.478148
epoch 246, train_loss = 0.478222
epoch 247, train_loss = 0.478464
epoch 248, train_loss = 0.478554
epoch 249, train_loss = 0.478572
epoch 250, train_loss = 0.478752
epoch 251, train_loss = 0.478968
epoch 252, train_loss = 0.478790
epoch 253, train_loss = 0.479070
epoch 254, train_loss = 0.479130
epoch 255, train_loss = 0.479086
epoch 256, train_loss = 0.479356
epoch 257, train_loss = 0.479181
epoch 258, train_loss = 0.479383
epoch 259, train_loss = 0.479309
epoch 260, train_loss = 0.479137
[260/1000] Valid Result: ndcg@5 = 0.007810, recall@5 = 0.000270, pre@5 = 0.007637.
[260/1000] Valid Result: ndcg@10 = 0.008356, recall@10 = 0.000472, pre@10 = 0.008462.
[260/1000] Valid Result: ndcg@15 = 0.008069, recall@15 = 0.000697, pre@15 = 0.007912.
[260/1000] Valid Result: ndcg@20 = 0.008651, recall@20 = 0.000957, pre@20 = 0.008772.
epoch 261, train_loss = 0.479356
epoch 262, train_loss = 0.479562
epoch 263, train_loss = 0.479371
epoch 264, train_loss = 0.479409
epoch 265, train_loss = 0.479481
epoch 266, train_loss = 0.479420
epoch 267, train_loss = 0.479454
epoch 268, train_loss = 0.479628
epoch 269, train_loss = 0.479834
epoch 270, train_loss = 0.479745
epoch 271, train_loss = 0.479993
epoch 272, train_loss = 0.480059
epoch 273, train_loss = 0.480174
epoch 274, train_loss = 0.480401
epoch 275, train_loss = 0.480369
epoch 276, train_loss = 0.480444
epoch 277, train_loss = 0.480532
epoch 278, train_loss = 0.480631
epoch 279, train_loss = 0.480590
epoch 280, train_loss = 0.480636
[280/1000] Valid Result: ndcg@5 = 0.007915, recall@5 = 0.000291, pre@5 = 0.008256.
[280/1000] Valid Result: ndcg@10 = 0.008396, recall@10 = 0.000542, pre@10 = 0.008772.
[280/1000] Valid Result: ndcg@15 = 0.008185, recall@15 = 0.000659, pre@15 = 0.008256.
[280/1000] Valid Result: ndcg@20 = 0.008277, recall@20 = 0.000851, pre@20 = 0.008308.
epoch 281, train_loss = 0.480894
epoch 282, train_loss = 0.480832
epoch 283, train_loss = 0.480932
epoch 284, train_loss = 0.481189
epoch 285, train_loss = 0.481349
epoch 286, train_loss = 0.481198
epoch 287, train_loss = 0.481410
epoch 288, train_loss = 0.481508
epoch 289, train_loss = 0.481594
epoch 290, train_loss = 0.481802
epoch 291, train_loss = 0.481890
epoch 292, train_loss = 0.481994
epoch 293, train_loss = 0.482141
epoch 294, train_loss = 0.482161
epoch 295, train_loss = 0.482361
epoch 296, train_loss = 0.482527
epoch 297, train_loss = 0.482640
epoch 298, train_loss = 0.482703
epoch 299, train_loss = 0.482813
epoch 300, train_loss = 0.482981
[300/1000] Valid Result: ndcg@5 = 0.007101, recall@5 = 0.000312, pre@5 = 0.007637.
[300/1000] Valid Result: ndcg@10 = 0.008073, recall@10 = 0.000509, pre@10 = 0.008669.
[300/1000] Valid Result: ndcg@15 = 0.008127, recall@15 = 0.000714, pre@15 = 0.008531.
[300/1000] Valid Result: ndcg@20 = 0.008344, recall@20 = 0.000880, pre@20 = 0.008720.
---------------------------
Test Result(at 100 epoch):
ndcg@5 = 0.019472, recall@5 = 0.000314, pre@5 = 0.019878.
ndcg@10 = 0.021259, recall@10 = 0.000654, pre@10 = 0.022211.
ndcg@15 = 0.022657, recall@15 = 0.001148, pre@15 = 0.023935.
ndcg@20 = 0.022555, recall@20 = 0.001405, pre@20 = 0.023479.
