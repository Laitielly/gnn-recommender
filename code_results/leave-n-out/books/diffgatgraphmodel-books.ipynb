{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-24T20:50:43.497590Z",
     "iopub.status.busy": "2025-06-24T20:50:43.497370Z",
     "iopub.status.idle": "2025-06-24T20:50:58.130116Z",
     "shell.execute_reply": "2025-06-24T20:50:58.129090Z",
     "shell.execute_reply.started": "2025-06-24T20:50:43.497566Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.1/727.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install torch_geometric rectools\n",
    "!pip -q install comet_ml\n",
    "!pip -q install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:50:58.132430Z",
     "iopub.status.busy": "2025-06-24T20:50:58.132193Z",
     "iopub.status.idle": "2025-06-24T20:51:03.399861Z",
     "shell.execute_reply": "2025-06-24T20:51:03.399257Z",
     "shell.execute_reply.started": "2025-06-24T20:50:58.132408Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:51:03.400944Z",
     "iopub.status.busy": "2025-06-24T20:51:03.400519Z",
     "iopub.status.idle": "2025-06-24T20:51:03.407339Z",
     "shell.execute_reply": "2025-06-24T20:51:03.406778Z",
     "shell.execute_reply.started": "2025-06-24T20:51:03.400919Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:51:03.408256Z",
     "iopub.status.busy": "2025-06-24T20:51:03.407995Z",
     "iopub.status.idle": "2025-06-24T20:51:07.381770Z",
     "shell.execute_reply": "2025-06-24T20:51:07.381250Z",
     "shell.execute_reply.started": "2025-06-24T20:51:03.408239Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/annanet/gnn-recommender/cf72e82fe89b46d282db2a35def476b3\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "  api_key=os.getenv('API_KEY'),\n",
    "  project_name=\"gnn-recommender\",\n",
    "  workspace=\"annanet\",\n",
    "  log_code=True\n",
    ")\n",
    "\n",
    "experiment.set_name('diffGATGraphModel-books')\n",
    "experiment.add_tags(['books', 'leave-n-out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.comet.com/annanet/gnn-recommender/cf72e82fe89b46d282db2a35def476b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:51:18.115899Z",
     "iopub.status.busy": "2025-06-24T20:51:18.115576Z",
     "iopub.status.idle": "2025-06-24T20:51:18.120232Z",
     "shell.execute_reply": "2025-06-24T20:51:18.119412Z",
     "shell.execute_reply.started": "2025-06-24T20:51:18.115875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'seed': 42,\n",
    "    'types_of_feedback': [\"explicit_positive\", \"expliсit_negative\",\n",
    "                          \"implicit_positive\", \"implicit_negative\"],\n",
    "    'train_edge_type': ('item','to_feedback_explicit_positive','explicit_positive'),\n",
    "    'train_num_epochs': 100,\n",
    "    'train_lr': 8e-5,\n",
    "    'train_batch_size': 32768,\n",
    "    'train_print_every': 10,  \n",
    "    'train_test_every': 10,\n",
    "    'test_topk': 10,\n",
    "    'test_batch_size': 32768\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:51:22.844759Z",
     "iopub.status.busy": "2025-06-24T20:51:22.844288Z",
     "iopub.status.idle": "2025-06-24T20:51:22.866653Z",
     "shell.execute_reply": "2025-06-24T20:51:22.865981Z",
     "shell.execute_reply.started": "2025-06-24T20:51:22.844736Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv', 'test.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('/kaggle/input/data/leave-n-out/books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:51:25.330880Z",
     "iopub.status.busy": "2025-06-24T20:51:25.330072Z",
     "iopub.status.idle": "2025-06-24T20:51:35.032988Z",
     "shell.execute_reply": "2025-06-24T20:51:35.032421Z",
     "shell.execute_reply.started": "2025-06-24T20:51:25.330830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv, GATConv\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from rectools import Columns\n",
    "from rectools.metrics import MAP, Precision, Recall, NDCG, calc_metrics\n",
    "\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:51:35.034576Z",
     "iopub.status.busy": "2025-06-24T20:51:35.034059Z",
     "iopub.status.idle": "2025-06-24T20:51:35.042817Z",
     "shell.execute_reply": "2025-06-24T20:51:35.042078Z",
     "shell.execute_reply.started": "2025-06-24T20:51:35.034551Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = hyperparameters['seed']\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:51:40.623651Z",
     "iopub.status.busy": "2025-06-24T20:51:40.623135Z",
     "iopub.status.idle": "2025-06-24T20:52:12.835319Z",
     "shell.execute_reply": "2025-06-24T20:52:12.834535Z",
     "shell.execute_reply.started": "2025-06-24T20:51:40.623626Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            user_id  book_id  rating  \\\n",
      "0  000883382802f2d95a3dd545bb953882  8525590       3   \n",
      "1  000883382802f2d95a3dd545bb953882  2767052       5   \n",
      "2  000883382802f2d95a3dd545bb953882  3236307       5   \n",
      "3  000883382802f2d95a3dd545bb953882   256683       4   \n",
      "4  000883382802f2d95a3dd545bb953882  6001758       5   \n",
      "\n",
      "                  date_added                       date  \n",
      "0  2011-10-31 18:37:56-07:00  2011-10-31 18:37:56-07:00  \n",
      "1  2011-10-31 18:40:33-07:00  2011-10-31 18:40:33-07:00  \n",
      "2  2011-11-02 08:30:30-07:00  2011-11-02 08:30:30-07:00  \n",
      "3  2011-11-02 08:55:16-07:00  2011-11-02 08:55:16-07:00  \n",
      "4  2011-11-02 08:57:21-07:00  2011-11-02 08:57:21-07:00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/4238775169.py:5: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  train['date'] = pd.to_datetime(train['date_added'])\n"
     ]
    }
   ],
   "source": [
    "rootpath = '/kaggle/input/data/leave-n-out/books/'\n",
    "train = pd.read_csv(\n",
    "    rootpath+'train.csv'\n",
    ")\n",
    "train['date'] = pd.to_datetime(train['date_added'])\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:52:12.836718Z",
     "iopub.status.busy": "2025-06-24T20:52:12.836496Z",
     "iopub.status.idle": "2025-06-24T20:52:12.921518Z",
     "shell.execute_reply": "2025-06-24T20:52:12.920712Z",
     "shell.execute_reply.started": "2025-06-24T20:52:12.836702Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество explicit позитивного фидбека 359463\n",
      "Количество explicit негативного фидбека 178217\n"
     ]
    }
   ],
   "source": [
    "explicit_positive = train[(train[\"rating\"] == 5)].index\n",
    "explisit_negative = train[(train[\"rating\"] <= 2)].index\n",
    "\n",
    "explicit_combined_feedback = explicit_positive.union(explisit_negative)\n",
    "print('Количество explicit позитивного фидбека', explicit_positive.shape[0])\n",
    "print('Количество explicit негативного фидбека', explisit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:52:12.923308Z",
     "iopub.status.busy": "2025-06-24T20:52:12.922584Z",
     "iopub.status.idle": "2025-06-24T20:52:13.013109Z",
     "shell.execute_reply": "2025-06-24T20:52:13.012339Z",
     "shell.execute_reply.started": "2025-06-24T20:52:12.923284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество implicit позитивного фидбека 430342\n",
      "Количество implicit негативного фидбека 258651\n"
     ]
    }
   ],
   "source": [
    "implicit_positive = train[(train[\"rating\"] == 4)].index\n",
    "implicit_negative = train[(train[\"rating\"] == 3)].index\n",
    "\n",
    "implicit_combined_feedback = implicit_positive.union(implicit_negative)\n",
    "print('Количество implicit позитивного фидбека', implicit_positive.shape[0])\n",
    "print('Количество implicit негативного фидбека', implicit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:52:13.015232Z",
     "iopub.status.busy": "2025-06-24T20:52:13.014589Z",
     "iopub.status.idle": "2025-06-24T20:52:13.217135Z",
     "shell.execute_reply": "2025-06-24T20:52:13.216408Z",
     "shell.execute_reply.started": "2025-06-24T20:52:13.015206Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>8525590</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2011-10-31 18:37:56-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>2767052</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2011-10-31 18:40:33-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>3236307</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2011-11-02 08:30:30-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>256683</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2011-11-02 08:55:16-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>6001758</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2011-11-02 08:57:21-07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id  book_id             target  \\\n",
       "0  000883382802f2d95a3dd545bb953882  8525590  implicit_negative   \n",
       "1  000883382802f2d95a3dd545bb953882  2767052  explicit_positive   \n",
       "2  000883382802f2d95a3dd545bb953882  3236307  explicit_positive   \n",
       "3  000883382802f2d95a3dd545bb953882   256683  implicit_positive   \n",
       "4  000883382802f2d95a3dd545bb953882  6001758  explicit_positive   \n",
       "\n",
       "                        date  \n",
       "0  2011-10-31 18:37:56-07:00  \n",
       "1  2011-10-31 18:40:33-07:00  \n",
       "2  2011-11-02 08:30:30-07:00  \n",
       "3  2011-11-02 08:55:16-07:00  \n",
       "4  2011-11-02 08:57:21-07:00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:, \"target\"] = \"\"\n",
    "train.loc[explicit_positive, \"target\"] = \"explicit_positive\"\n",
    "train.loc[explisit_negative, \"target\"] = \"expliсit_negative\"\n",
    "train.loc[implicit_positive, \"target\"] = \"implicit_positive\"\n",
    "train.loc[implicit_negative, \"target\"] = \"implicit_negative\"\n",
    "\n",
    "train = train[['user_id','book_id','target','date']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:52:13.218108Z",
     "iopub.status.busy": "2025-06-24T20:52:13.217825Z",
     "iopub.status.idle": "2025-06-24T20:52:18.389780Z",
     "shell.execute_reply": "2025-06-24T20:52:18.388898Z",
     "shell.execute_reply.started": "2025-06-24T20:52:13.218090Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = train.sort_values(by=[\"user_id\", \"date\"]).reset_index(drop=True)\n",
    "train.columns = ['user_id', 'item_id', 'target', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:52:23.622195Z",
     "iopub.status.busy": "2025-06-24T20:52:23.621367Z",
     "iopub.status.idle": "2025-06-24T20:52:27.419854Z",
     "shell.execute_reply": "2025-06-24T20:52:27.418970Z",
     "shell.execute_reply.started": "2025-06-24T20:52:23.622169Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            user_id   book_id  rating  \\\n",
      "0  000883382802f2d95a3dd545bb953882   8135807       4   \n",
      "1  000883382802f2d95a3dd545bb953882  18301124       5   \n",
      "2  000883382802f2d95a3dd545bb953882  18220354       4   \n",
      "3  000883382802f2d95a3dd545bb953882  17383918       5   \n",
      "4  000883382802f2d95a3dd545bb953882  13188676       5   \n",
      "\n",
      "                  date_added                       date  \n",
      "0  2013-08-13 09:37:39-07:00  2013-08-13 09:37:39-07:00  \n",
      "1  2013-10-27 22:18:01-07:00  2013-10-27 22:18:01-07:00  \n",
      "2  2013-12-09 22:20:59-08:00  2013-12-09 22:20:59-08:00  \n",
      "3  2013-12-22 20:57:14-08:00  2013-12-22 20:57:14-08:00  \n",
      "4  2013-12-22 20:58:15-08:00  2013-12-22 20:58:15-08:00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/2717431719.py:4: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  test['date'] = pd.to_datetime(test['date_added'])\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\n",
    "    rootpath+'test.csv'\n",
    ")\n",
    "test['date'] = pd.to_datetime(test['date_added'])\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:52:30.861438Z",
     "iopub.status.busy": "2025-06-24T20:52:30.860828Z",
     "iopub.status.idle": "2025-06-24T20:52:30.877885Z",
     "shell.execute_reply": "2025-06-24T20:52:30.877210Z",
     "shell.execute_reply.started": "2025-06-24T20:52:30.861416Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>8135807</td>\n",
       "      <td>2013-08-13 09:37:39-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>18301124</td>\n",
       "      <td>2013-10-27 22:18:01-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>18220354</td>\n",
       "      <td>2013-12-09 22:20:59-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>17383918</td>\n",
       "      <td>2013-12-22 20:57:14-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>13188676</td>\n",
       "      <td>2013-12-22 20:58:15-08:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id   item_id                       date\n",
       "0  000883382802f2d95a3dd545bb953882   8135807  2013-08-13 09:37:39-07:00\n",
       "1  000883382802f2d95a3dd545bb953882  18301124  2013-10-27 22:18:01-07:00\n",
       "2  000883382802f2d95a3dd545bb953882  18220354  2013-12-09 22:20:59-08:00\n",
       "3  000883382802f2d95a3dd545bb953882  17383918  2013-12-22 20:57:14-08:00\n",
       "4  000883382802f2d95a3dd545bb953882  13188676  2013-12-22 20:58:15-08:00"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[['user_id','book_id', 'date']]\n",
    "test.columns = ['user_id', 'item_id', 'date']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP model v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:52:34.160180Z",
     "iopub.status.busy": "2025-06-24T20:52:34.159634Z",
     "iopub.status.idle": "2025-06-24T20:52:34.224128Z",
     "shell.execute_reply": "2025-06-24T20:52:34.223392Z",
     "shell.execute_reply.started": "2025-06-24T20:52:34.160161Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151126, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[(test.user_id.isin(train.user_id)) & (test.item_id.isin(train.item_id))].copy()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:52:34.494583Z",
     "iopub.status.busy": "2025-06-24T20:52:34.494021Z",
     "iopub.status.idle": "2025-06-24T20:52:34.938613Z",
     "shell.execute_reply": "2025-06-24T20:52:34.938064Z",
     "shell.execute_reply.started": "2025-06-24T20:52:34.494563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. Преобразование данных - для куарека не особо нужно, но для других - напоминалка\n",
    "# делаем всегда! чтобы не сломать ничего дальше и чтобы все индексы были от 0 до N без пропусков\n",
    "user_encoder = LabelEncoder()\n",
    "video_encoder = LabelEncoder()\n",
    "\n",
    "train.loc[:, 'user_id'] = user_encoder.fit_transform(train['user_id'])\n",
    "train.loc[:, 'item_id'] = video_encoder.fit_transform(train['item_id'])\n",
    "\n",
    "test.loc[:, 'user_id'] = user_encoder.transform(test['user_id'])\n",
    "test.loc[:, 'item_id'] = video_encoder.transform(test['item_id'])\n",
    "\n",
    "train['user_id'] = train['user_id'].astype(int)\n",
    "train['item_id'] = train['item_id'].astype(int)\n",
    "test['user_id'] = test['user_id'].astype(int)\n",
    "test['item_id'] = test['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:52:36.147435Z",
     "iopub.status.busy": "2025-06-24T20:52:36.146734Z",
     "iopub.status.idle": "2025-06-24T20:52:36.170609Z",
     "shell.execute_reply": "2025-06-24T20:52:36.170059Z",
     "shell.execute_reply.started": "2025-06-24T20:52:36.147409Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных item_id 25456\n",
      "Количество уникальных user_id 18892\n"
     ]
    }
   ],
   "source": [
    "# т.е. сразу знаем количество и в каких пределах изменяется user_id и video_id\n",
    "num_videos = train['item_id'].nunique()\n",
    "num_users = train['user_id'].nunique()\n",
    "\n",
    "print('Количество уникальных item_id', num_videos)\n",
    "print('Количество уникальных user_id', num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:54:07.481111Z",
     "iopub.status.busy": "2025-06-24T20:54:07.480348Z",
     "iopub.status.idle": "2025-06-24T20:54:07.487157Z",
     "shell.execute_reply": "2025-06-24T20:54:07.486353Z",
     "shell.execute_reply.started": "2025-06-24T20:54:07.481086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_hetero_data(df) -> HeteroData:\n",
    "    data = HeteroData()\n",
    "    users = df['user_id'].unique()\n",
    "    num_users = len(users)\n",
    "    num_items = df['item_id'].max() + 1\n",
    "    feedback_types = df['target'].unique().tolist()\n",
    "\n",
    "    # узлы\n",
    "    data['user'].node_id = torch.arange(num_users)\n",
    "    data['item'].node_id = torch.arange(num_items)\n",
    "    for ft in feedback_types:\n",
    "        data[ft].node_id = torch.arange(num_users)\n",
    "\n",
    "    # ребра item<->feedback->user\n",
    "    for ft in feedback_types:\n",
    "        mask = df['target'] == ft\n",
    "        items = torch.LongTensor(df.loc[mask, 'item_id'].values)\n",
    "        users_idx = torch.LongTensor(df.loc[mask, 'user_id'].values)\n",
    "        # item -> fb\n",
    "        data['item', f'to_feedback_{ft}', ft].edge_index = torch.stack([items, users_idx], dim=0)\n",
    "        # fb -> item\n",
    "        data[ft, f'feedback_to_item_{ft}', 'item'].edge_index = torch.stack([users_idx, items], dim=0)\n",
    "        # fb -> user (1:1)\n",
    "        idx = torch.arange(num_users)\n",
    "        data[ft, f'to_user_{ft}', 'user'].edge_index = torch.stack([idx, idx], dim=0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:54:12.741519Z",
     "iopub.status.busy": "2025-06-24T20:54:12.741236Z",
     "iopub.status.idle": "2025-06-24T20:54:12.753098Z",
     "shell.execute_reply": "2025-06-24T20:54:12.752431Z",
     "shell.execute_reply.started": "2025-06-24T20:54:12.741500Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SignedHeteroGNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 feedback_types: list,\n",
    "                 emb_dim: int = 32,\n",
    "                 hidden_dim: int = 16,\n",
    "                 heads: int = 2,\n",
    "                 dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.feedback_types = feedback_types\n",
    "        self.pos_types = ['implicit_positive', 'explicit_positive']\n",
    "        self.neg_types = ['implicit_negative', 'expliсit_negative']\n",
    "\n",
    "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_dim)\n",
    "        self.fb_emb   = nn.ModuleDict({\n",
    "            ft: nn.Embedding(num_users, emb_dim) for ft in feedback_types\n",
    "        })\n",
    "\n",
    "        conv1, conv2 = {}, {}\n",
    "        for ft in feedback_types:\n",
    "            # ft -> user\n",
    "            conv1[(ft, f'to_user_{ft}', 'user')] = GATConv(emb_dim, hidden_dim,\n",
    "                                                      heads=heads,\n",
    "                                                      add_self_loops=False)\n",
    "            conv2[(ft, f'to_user_{ft}', 'user')] = GATConv(hidden_dim*heads, emb_dim,\n",
    "                                                      heads=1,\n",
    "                                                      add_self_loops=False)\n",
    "            # ft -> item\n",
    "            conv1[(ft, f'feedback_to_item_{ft}', 'item')] = GATConv(emb_dim, hidden_dim,\n",
    "                                                       heads=heads,\n",
    "                                                       add_self_loops=False)\n",
    "            conv2[(ft, f'feedback_to_item_{ft}', 'item')] = GATConv(hidden_dim*heads, emb_dim,\n",
    "                                                       heads=1,\n",
    "                                                       add_self_loops=False)\n",
    "\n",
    "            # item -> ft\n",
    "            conv1[('item', f'to_feedback_{ft}', ft)] = GATConv(emb_dim, hidden_dim,\n",
    "                                                       heads=heads,\n",
    "                                                       add_self_loops=False)\n",
    "            conv2[('item', f'to_feedback_{ft}', ft)] = GATConv(hidden_dim*heads, emb_dim,\n",
    "                                                       heads=1,\n",
    "                                                       add_self_loops=False)\n",
    "\n",
    "        self.conv1 = HeteroConv(conv1, aggr='mean')\n",
    "        self.conv2 = HeteroConv(conv2, aggr='mean')\n",
    "\n",
    "        # LayerNorm и Dropout\n",
    "        types = ['user', 'item'] + feedback_types\n",
    "        self.norm1 = nn.ModuleDict({t: nn.LayerNorm(hidden_dim*heads) for t in types})\n",
    "        self.norm2 = nn.ModuleDict({t: nn.LayerNorm(emb_dim) for t in types})\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = {\n",
    "            'user': self.user_emb(data['user'].node_id),\n",
    "            'item': self.item_emb(data['item'].node_id)\n",
    "        }\n",
    "        for ft in self.feedback_types:\n",
    "            x[ft] = self.fb_emb[ft](data[ft].node_id)\n",
    "\n",
    "        h1 = self.conv1(x, data.edge_index_dict)\n",
    "        # print(h1.keys())\n",
    "        # Собираем позитивный и негативный вклад для user\n",
    "        pos_msgs = torch.zeros_like(h1['user'])\n",
    "        neg_msgs = torch.zeros_like(h1['user'])\n",
    "        for ft in self.pos_types:\n",
    "            pos_msgs += h1[ft]  \n",
    "        for ft in self.neg_types:\n",
    "            neg_msgs += h1[ft]\n",
    "\n",
    "        # signed-aggregation: attraction от pos, repulsion от neg\n",
    "        user_h1 = pos_msgs - neg_msgs\n",
    "        user_h1 = F.leaky_relu(self.norm1['user'](user_h1))\n",
    "        user_h1 = self.dropout(user_h1)\n",
    "\n",
    "        h1['user'] = user_h1\n",
    "\n",
    "        h2 = self.conv2(h1, data.edge_index_dict)\n",
    "        # print(h2.keys())\n",
    "        pos_msgs2, neg_msgs2 = 0, 0\n",
    "        for ft in self.pos_types:\n",
    "            pos_msgs2 += h2[ft]\n",
    "        for ft in self.neg_types:\n",
    "            neg_msgs2 += h2[ft]\n",
    "\n",
    "        user_h2 = pos_msgs2 - neg_msgs2\n",
    "        user_h2 = F.leaky_relu(self.norm2['user'](user_h2))\n",
    "\n",
    "        return user_h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:54:14.186664Z",
     "iopub.status.busy": "2025-06-24T20:54:14.186106Z",
     "iopub.status.idle": "2025-06-24T20:54:14.625374Z",
     "shell.execute_reply": "2025-06-24T20:54:14.624716Z",
     "shell.execute_reply.started": "2025-06-24T20:54:14.186638Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ node_id=[18892] },\n",
       "  item={ node_id=[25456] },\n",
       "  implicit_negative={ node_id=[18892] },\n",
       "  explicit_positive={ node_id=[18892] },\n",
       "  implicit_positive={ node_id=[18892] },\n",
       "  expliсit_negative={ node_id=[18892] },\n",
       "  (item, to_feedback_implicit_negative, implicit_negative)={ edge_index=[2, 258651] },\n",
       "  (implicit_negative, feedback_to_item_implicit_negative, item)={ edge_index=[2, 258651] },\n",
       "  (implicit_negative, to_user_implicit_negative, user)={ edge_index=[2, 18892] },\n",
       "  (item, to_feedback_explicit_positive, explicit_positive)={ edge_index=[2, 359463] },\n",
       "  (explicit_positive, feedback_to_item_explicit_positive, item)={ edge_index=[2, 359463] },\n",
       "  (explicit_positive, to_user_explicit_positive, user)={ edge_index=[2, 18892] },\n",
       "  (item, to_feedback_implicit_positive, implicit_positive)={ edge_index=[2, 430342] },\n",
       "  (implicit_positive, feedback_to_item_implicit_positive, item)={ edge_index=[2, 430342] },\n",
       "  (implicit_positive, to_user_implicit_positive, user)={ edge_index=[2, 18892] },\n",
       "  (item, to_feedback_expliсit_negative, expliсit_negative)={ edge_index=[2, 178217] },\n",
       "  (expliсit_negative, feedback_to_item_expliсit_negative, item)={ edge_index=[2, 178217] },\n",
       "  (expliсit_negative, to_user_expliсit_negative, user)={ edge_index=[2, 18892] }\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = prepare_hetero_data(train)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:54:16.172075Z",
     "iopub.status.busy": "2025-06-24T20:54:16.171423Z",
     "iopub.status.idle": "2025-06-24T20:54:16.195133Z",
     "shell.execute_reply": "2025-06-24T20:54:16.194538Z",
     "shell.execute_reply.started": "2025-06-24T20:54:16.172055Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25456, 0, 25455)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.item_id.nunique(), train.item_id.min(), train.item_id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:54:18.618555Z",
     "iopub.status.busy": "2025-06-24T20:54:18.617896Z",
     "iopub.status.idle": "2025-06-24T20:54:18.807980Z",
     "shell.execute_reply": "2025-06-24T20:54:18.807195Z",
     "shell.execute_reply.started": "2025-06-24T20:54:18.618533Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_users = len(train['user_id'].unique())\n",
    "num_items = train['item_id'].max() + 1\n",
    "feedback_types = train['target'].unique().tolist()\n",
    "model = SignedHeteroGNN(num_users, num_items, feedback_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:54:19.984758Z",
     "iopub.status.busy": "2025-06-24T20:54:19.984255Z",
     "iopub.status.idle": "2025-06-24T20:54:19.989707Z",
     "shell.execute_reply": "2025-06-24T20:54:19.989042Z",
     "shell.execute_reply.started": "2025-06-24T20:54:19.984738Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignedHeteroGNN(\n",
       "  (user_emb): Embedding(18892, 32)\n",
       "  (item_emb): Embedding(25456, 32)\n",
       "  (fb_emb): ModuleDict(\n",
       "    (implicit_negative): Embedding(18892, 32)\n",
       "    (explicit_positive): Embedding(18892, 32)\n",
       "    (implicit_positive): Embedding(18892, 32)\n",
       "    (expliсit_negative): Embedding(18892, 32)\n",
       "  )\n",
       "  (conv1): HeteroConv(num_relations=12)\n",
       "  (conv2): HeteroConv(num_relations=12)\n",
       "  (norm1): ModuleDict(\n",
       "    (user): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (item): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (implicit_negative): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (explicit_positive): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (implicit_positive): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (expliсit_negative): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (norm2): ModuleDict(\n",
       "    (user): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (item): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (implicit_negative): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (explicit_positive): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (implicit_positive): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (expliсit_negative): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:54:20.379031Z",
     "iopub.status.busy": "2025-06-24T20:54:20.378666Z",
     "iopub.status.idle": "2025-06-24T20:54:21.525568Z",
     "shell.execute_reply": "2025-06-24T20:54:21.524909Z",
     "shell.execute_reply.started": "2025-06-24T20:54:20.379002Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5162e-01, -7.1993e-03, -1.1890e-02,  ..., -9.2425e-05,\n",
       "         -4.1174e-03,  2.5627e-01],\n",
       "        [ 3.5853e-01, -9.4277e-03, -2.6036e-03,  ..., -3.6192e-03,\n",
       "         -1.2521e-02,  3.6283e-01],\n",
       "        [-7.5855e-03, -7.2857e-03, -4.0534e-03,  ...,  1.1243e+00,\n",
       "         -7.8982e-03,  6.9816e-01],\n",
       "        ...,\n",
       "        [ 4.1303e-01, -1.0085e-02, -1.1072e-02,  ..., -6.9892e-03,\n",
       "          2.3222e-01, -1.1042e-03],\n",
       "        [ 5.2519e-01, -1.3659e-02, -1.9419e-02,  ...,  8.0117e-01,\n",
       "         -7.5687e-03,  1.7108e+00],\n",
       "        [-2.6951e-03, -1.8021e-03, -6.7737e-03,  ..., -5.3802e-03,\n",
       "          2.1237e-01, -5.6841e-04]], grad_fn=<LeakyReluBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:54:23.800164Z",
     "iopub.status.busy": "2025-06-24T20:54:23.799890Z",
     "iopub.status.idle": "2025-06-24T20:54:24.277486Z",
     "shell.execute_reply": "2025-06-24T20:54:24.276828Z",
     "shell.execute_reply.started": "2025-06-24T20:54:23.800144Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = test[['user_id', 'item_id']]\n",
    "interactions = test_df.rename(columns={\n",
    "    'user_id': Columns.User,\n",
    "    'item_id': Columns.Item,\n",
    "})\n",
    "\n",
    "viewed_items = train.groupby(\"user_id\")[\"item_id\"].agg(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:54:36.366343Z",
     "iopub.status.busy": "2025-06-24T20:54:36.365434Z",
     "iopub.status.idle": "2025-06-24T20:54:36.376909Z",
     "shell.execute_reply": "2025-06-24T20:54:36.376138Z",
     "shell.execute_reply.started": "2025-06-24T20:54:36.366313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, train_data,\n",
    "             test_batch_size, top_k,\n",
    "             viewed_items, interactions,\n",
    "             device, test_step):\n",
    "    \"\"\"\n",
    "    Оцениваем модель по всем пользователям:\n",
    "    - строим топ-K рекомендации\n",
    "    - фильтруем уже просмотренные\n",
    "    - считаем recall@K, precision@K, map@K\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    num_users = train_data['user'].node_id.shape[0]\n",
    "    test_top_k = top_k * 150\n",
    "\n",
    "    item_emb = model.item_emb.weight\n",
    "    item_emb_t = item_emb.t().detach()\n",
    "    del item_emb\n",
    "    gc.collect()\n",
    "\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_users, test_batch_size):\n",
    "            end = min(i + test_batch_size, num_users)\n",
    "            batch_users = torch.arange(i, end).to(device)\n",
    "            user_e = model(\n",
    "                data=train_data.to(device)\n",
    "            )\n",
    "            rating = torch.mm(user_e[batch_users].detach(), item_emb_t)\n",
    "            _, topk = torch.topk(rating, k=test_top_k, dim=1)\n",
    "            all_scores.append(topk)\n",
    "\n",
    "            del user_e, rating\n",
    "            gc.collect()\n",
    "    all_scores = torch.cat(all_scores, dim=0).cpu().numpy()\n",
    "\n",
    "    users_list, items, ranks = [], [], []\n",
    "    for u in range(num_users):\n",
    "        seen = viewed_items.get(u, set())\n",
    "        recs = all_scores[u]\n",
    "        mask = ~np.isin(recs, list(seen))\n",
    "        filtered = recs[mask][:top_k]\n",
    "        for rank, it in enumerate(filtered, 1):\n",
    "            users_list.append(u)\n",
    "            items.append(int(it))\n",
    "            ranks.append(rank)\n",
    "    reco_df = pd.DataFrame({\n",
    "        'user_id': users_list,\n",
    "        'item_id': items,\n",
    "        'rank': ranks\n",
    "    })\n",
    "\n",
    "    metrics = {\n",
    "        f'map@{top_k}': MAP(k=top_k),\n",
    "        f'precision@{top_k}': Precision(k=top_k),\n",
    "        f'recall@{top_k}': Recall(k=top_k),\n",
    "        f'ndcg@{top_k}': NDCG(k=top_k)\n",
    "    }\n",
    "    results = calc_metrics(metrics=metrics,\n",
    "                           reco=reco_df,\n",
    "                           interactions=interactions)\n",
    "    print(f\"Step {test_step} — Test metrics:\")\n",
    "    for name, val in results.items():\n",
    "        print(f\"  {name}: {val:.9f}\")\n",
    "        experiment.log_metric(f\"Test {name} vs step\", val, step=test_step)\n",
    "    del all_scores\n",
    "    gc.collect()\n",
    "\n",
    "    model.to(device)\n",
    "    train_data.to(device)\n",
    "    model.train()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T23:13:55.354444Z",
     "iopub.status.busy": "2025-06-24T23:13:55.353711Z",
     "iopub.status.idle": "2025-06-24T23:13:55.365411Z",
     "shell.execute_reply": "2025-06-24T23:13:55.364682Z",
     "shell.execute_reply.started": "2025-06-24T23:13:55.354421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                train_data: HeteroData,\n",
    "                edge_type: tuple,\n",
    "                num_epochs: int = 10,\n",
    "                lr: float = 1e-3,\n",
    "                batch_size: int = 1024,\n",
    "                device: str = None,\n",
    "                print_every: int = 100,\n",
    "                test_every: int = 500,\n",
    "                top_k: int = 10,\n",
    "                test_batch_size=2048):\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    train_data = train_data.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    src, dst = train_data[edge_type].edge_index\n",
    "    num_train = src.size(0)\n",
    "    test_top_k = top_k * 300\n",
    "    total_steps = 5497\n",
    "    print(f\"Num of training examples: {num_train}\")\n",
    "    for epoch in range(501,1001):\n",
    "        model.train()\n",
    "        perm = torch.randperm(num_train, device=device)\n",
    "        total_loss = 0.0\n",
    "        step = 0\n",
    "        for i in range(0, num_train, batch_size):\n",
    "            idx = perm[i:i + batch_size]\n",
    "            users = dst[idx]\n",
    "            pos_items = src[idx]\n",
    "            neg_items = torch.randint(0, model.item_emb.num_embeddings,\n",
    "                                      size=pos_items.size(), device=device)\n",
    "            optimizer.zero_grad()\n",
    "            user_embs = model(train_data)[users]\n",
    "            pos_emb = model.item_emb(pos_items)\n",
    "            neg_emb = model.item_emb(neg_items)\n",
    "            pos_score = (user_embs * pos_emb).sum(dim=1)\n",
    "            neg_score = (user_embs * neg_emb).sum(dim=1)\n",
    "            loss = -torch.log(torch.sigmoid(pos_score - neg_score) + 1e-15).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * users.size(0)\n",
    "            step += 1\n",
    "\n",
    "            experiment.log_metric('Train BPR Loss vs step', loss.item(), step=total_steps)\n",
    "            if step % print_every == 0 or step == 1:\n",
    "                avg_loss = total_loss /  (step * batch_size)\n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                d = (pos_score - neg_score).detach().cpu()\n",
    "                print(f\"Epoch {epoch}, Step {step}, LR: {current_lr:.6f}, Current Loss: {loss.item():.4f}, Avg Loss: {avg_loss:.4f}\")\n",
    "                print(f\"Diff stats — min: {d.min():.4f}, max: {d.max():.4f}, mean: {d.mean():.4f}, std: {d.std():.4f}\")\n",
    "                print()\n",
    "\n",
    "                experiment.log_metric('Diff stats (mean) vs step', d.mean(), step=total_steps)\n",
    "                experiment.log_metric('Diff stats (std) vs step', d.std(), step=total_steps)\n",
    "\n",
    "            del user_embs, pos_emb, neg_emb, pos_score, neg_score\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            if step % test_every == 0 or step == 1:\n",
    "                evaluate(model, train_data,\n",
    "                         test_batch_size, top_k,\n",
    "                         viewed_items, interactions,\n",
    "                         device, test_step=total_steps)\n",
    "            total_steps += 1\n",
    "        epoch_loss = total_loss / num_train\n",
    "        experiment.log_metric(f'Train Loss vs epoch', epoch_loss, epoch=epoch - 1)\n",
    "        print(f\"Epoch {epoch} completed, Train Loss: {epoch_loss:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:54:40.828068Z",
     "iopub.status.busy": "2025-06-24T20:54:40.827760Z",
     "iopub.status.idle": "2025-06-24T20:54:40.856235Z",
     "shell.execute_reply": "2025-06-24T20:54:40.855707Z",
     "shell.execute_reply.started": "2025-06-24T20:54:40.828050Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "experiment.log_parameters(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:54:42.140054Z",
     "iopub.status.busy": "2025-06-24T20:54:42.139363Z",
     "iopub.status.idle": "2025-06-24T20:54:42.143380Z",
     "shell.execute_reply": "2025-06-24T20:54:42.142631Z",
     "shell.execute_reply.started": "2025-06-24T20:54:42.140032Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-24T20:54:43.404716Z",
     "iopub.status.busy": "2025-06-24T20:54:43.404151Z",
     "iopub.status.idle": "2025-06-24T21:18:06.482445Z",
     "shell.execute_reply": "2025-06-24T21:18:06.481659Z",
     "shell.execute_reply.started": "2025-06-24T20:54:43.404695Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training examples: 359463\n",
      "Epoch 1, Step 1, LR: 0.000080, Current Loss: 2.3516, Avg Loss: 2.3516\n",
      "Diff stats — min: -23.6654, max: 24.3270, mean: 0.0091, std: 5.6245\n",
      "\n",
      "Step 0 — Test metrics:\n",
      "  precision@10: 0.000396406\n",
      "  recall@10: 0.000397874\n",
      "  ndcg@10: 0.000407474\n",
      "  map@10: 0.000124084\n",
      "Epoch 1, Step 10, LR: 0.000080, Current Loss: 2.2534, Avg Loss: 2.3044\n",
      "Diff stats — min: -20.5828, max: 21.5892, mean: 0.0318, std: 5.3981\n",
      "\n",
      "Step 9 — Test metrics:\n",
      "  precision@10: 0.000383192\n",
      "  recall@10: 0.000384661\n",
      "  ndcg@10: 0.000375116\n",
      "  map@10: 0.000108172\n",
      "Epoch 1 completed, Train Loss: 2.2995\n",
      "Epoch 2, Step 1, LR: 0.000080, Current Loss: 2.2087, Avg Loss: 2.2087\n",
      "Diff stats — min: -26.2154, max: 21.1165, mean: 0.0978, std: 5.3705\n",
      "\n",
      "Step 11 — Test metrics:\n",
      "  precision@10: 0.000383192\n",
      "  recall@10: 0.000384661\n",
      "  ndcg@10: 0.000375140\n",
      "  map@10: 0.000108199\n",
      "Epoch 2, Step 10, LR: 0.000080, Current Loss: 2.1678, Avg Loss: 2.2084\n",
      "Diff stats — min: -22.4431, max: 22.2424, mean: 0.0200, std: 5.1674\n",
      "\n",
      "Step 20 — Test metrics:\n",
      "  precision@10: 0.000343552\n",
      "  recall@10: 0.000344286\n",
      "  ndcg@10: 0.000338367\n",
      "  map@10: 0.000097628\n",
      "Epoch 2 completed, Train Loss: 2.2037\n",
      "Epoch 3, Step 1, LR: 0.000080, Current Loss: 2.1683, Avg Loss: 2.1683\n",
      "Diff stats — min: -20.1033, max: 20.9203, mean: 0.0341, std: 5.1896\n",
      "\n",
      "Step 22 — Test metrics:\n",
      "  precision@10: 0.000343552\n",
      "  recall@10: 0.000344286\n",
      "  ndcg@10: 0.000339893\n",
      "  map@10: 0.000098556\n",
      "Epoch 3, Step 10, LR: 0.000080, Current Loss: 2.0536, Avg Loss: 2.1055\n",
      "Diff stats — min: -20.2047, max: 23.5354, mean: 0.0515, std: 4.9142\n",
      "\n",
      "Step 31 — Test metrics:\n",
      "  precision@10: 0.000396406\n",
      "  recall@10: 0.000397874\n",
      "  ndcg@10: 0.000376002\n",
      "  map@10: 0.000105339\n",
      "Epoch 3 completed, Train Loss: 2.1030\n",
      "Epoch 4, Step 1, LR: 0.000080, Current Loss: 2.0508, Avg Loss: 2.0508\n",
      "Diff stats — min: -19.0187, max: 21.0016, mean: 0.0409, std: 4.8831\n",
      "\n",
      "Step 33 — Test metrics:\n",
      "  precision@10: 0.000403013\n",
      "  recall@10: 0.000404481\n",
      "  ndcg@10: 0.000381198\n",
      "  map@10: 0.000106552\n",
      "Epoch 4, Step 10, LR: 0.000080, Current Loss: 1.9487, Avg Loss: 2.0029\n",
      "Diff stats — min: -20.0186, max: 24.5159, mean: 0.0732, std: 4.6578\n",
      "\n",
      "Step 42 — Test metrics:\n",
      "  precision@10: 0.000396406\n",
      "  recall@10: 0.000397874\n",
      "  ndcg@10: 0.000372684\n",
      "  map@10: 0.000103311\n",
      "Epoch 4 completed, Train Loss: 1.9985\n",
      "Epoch 5, Step 1, LR: 0.000080, Current Loss: 1.9490, Avg Loss: 1.9490\n",
      "Diff stats — min: -21.3605, max: 18.9751, mean: 0.0305, std: 4.6073\n",
      "\n",
      "Step 44 — Test metrics:\n",
      "  precision@10: 0.000389799\n",
      "  recall@10: 0.000390533\n",
      "  ndcg@10: 0.000372256\n",
      "  map@10: 0.000103720\n",
      "Epoch 5, Step 10, LR: 0.000080, Current Loss: 1.8787, Avg Loss: 1.9112\n",
      "Diff stats — min: -18.1863, max: 19.9204, mean: 0.0565, std: 4.4602\n",
      "\n",
      "Step 53 — Test metrics:\n",
      "  precision@10: 0.000396406\n",
      "  recall@10: 0.000397140\n",
      "  ndcg@10: 0.000389336\n",
      "  map@10: 0.000112055\n",
      "Epoch 5 completed, Train Loss: 1.9080\n",
      "Epoch 6, Step 1, LR: 0.000080, Current Loss: 1.8526, Avg Loss: 1.8526\n",
      "Diff stats — min: -19.9184, max: 21.8938, mean: 0.0627, std: 4.3982\n",
      "\n",
      "Step 55 — Test metrics:\n",
      "  precision@10: 0.000389799\n",
      "  recall@10: 0.000390533\n",
      "  ndcg@10: 0.000384406\n",
      "  map@10: 0.000111058\n",
      "Epoch 6, Step 10, LR: 0.000080, Current Loss: 1.8017, Avg Loss: 1.8330\n",
      "Diff stats — min: -21.2705, max: 20.1644, mean: 0.0630, std: 4.2551\n",
      "\n",
      "Step 64 — Test metrics:\n",
      "  precision@10: 0.000389799\n",
      "  recall@10: 0.000390533\n",
      "  ndcg@10: 0.000370920\n",
      "  map@10: 0.000103023\n",
      "Epoch 6 completed, Train Loss: 1.8289\n",
      "Epoch 7, Step 1, LR: 0.000080, Current Loss: 1.7638, Avg Loss: 1.7638\n",
      "Diff stats — min: -19.4487, max: 18.2125, mean: 0.0658, std: 4.1693\n",
      "\n",
      "Step 66 — Test metrics:\n",
      "  precision@10: 0.000369979\n",
      "  recall@10: 0.000370713\n",
      "  ndcg@10: 0.000357584\n",
      "  map@10: 0.000100558\n",
      "Epoch 7, Step 10, LR: 0.000080, Current Loss: 1.7317, Avg Loss: 1.7656\n",
      "Diff stats — min: -18.5207, max: 16.8038, mean: 0.0635, std: 4.0678\n",
      "\n",
      "Step 75 — Test metrics:\n",
      "  precision@10: 0.000356765\n",
      "  recall@10: 0.000357499\n",
      "  ndcg@10: 0.000355290\n",
      "  map@10: 0.000103322\n",
      "Epoch 7 completed, Train Loss: 1.7637\n",
      "Epoch 8, Step 1, LR: 0.000080, Current Loss: 1.7408, Avg Loss: 1.7408\n",
      "Diff stats — min: -21.8867, max: 18.1665, mean: 0.0319, std: 4.0601\n",
      "\n",
      "Step 77 — Test metrics:\n",
      "  precision@10: 0.000356765\n",
      "  recall@10: 0.000357499\n",
      "  ndcg@10: 0.000355172\n",
      "  map@10: 0.000103288\n",
      "Epoch 8, Step 10, LR: 0.000080, Current Loss: 1.6809, Avg Loss: 1.7163\n",
      "Diff stats — min: -17.6838, max: 17.8993, mean: 0.0803, std: 3.9637\n",
      "\n",
      "Step 86 — Test metrics:\n",
      "  precision@10: 0.000363372\n",
      "  recall@10: 0.000364840\n",
      "  ndcg@10: 0.000350993\n",
      "  map@10: 0.000099443\n",
      "Epoch 8 completed, Train Loss: 1.7150\n",
      "Epoch 9, Step 1, LR: 0.000080, Current Loss: 1.7054, Avg Loss: 1.7054\n",
      "Diff stats — min: -23.4688, max: 18.3418, mean: 0.0412, std: 3.9852\n",
      "\n",
      "Step 88 — Test metrics:\n",
      "  precision@10: 0.000363372\n",
      "  recall@10: 0.000364840\n",
      "  ndcg@10: 0.000361203\n",
      "  map@10: 0.000105848\n",
      "Epoch 9, Step 10, LR: 0.000080, Current Loss: 1.6583, Avg Loss: 1.6734\n",
      "Diff stats — min: -18.9763, max: 19.9782, mean: 0.0556, std: 3.8701\n",
      "\n",
      "Step 97 — Test metrics:\n",
      "  precision@10: 0.000330338\n",
      "  recall@10: 0.000331806\n",
      "  ndcg@10: 0.000334033\n",
      "  map@10: 0.000099513\n",
      "Epoch 9 completed, Train Loss: 1.6744\n",
      "Epoch 10, Step 1, LR: 0.000080, Current Loss: 1.6689, Avg Loss: 1.6689\n",
      "Diff stats — min: -18.5520, max: 18.2058, mean: 0.0377, std: 3.8703\n",
      "\n",
      "Step 99 — Test metrics:\n",
      "  precision@10: 0.000343552\n",
      "  recall@10: 0.000345020\n",
      "  ndcg@10: 0.000341958\n",
      "  map@10: 0.000100596\n",
      "Epoch 10, Step 10, LR: 0.000080, Current Loss: 1.6378, Avg Loss: 1.6426\n",
      "Diff stats — min: -17.2500, max: 17.9642, mean: 0.0423, std: 3.7970\n",
      "\n",
      "Step 108 — Test metrics:\n",
      "  precision@10: 0.000330338\n",
      "  recall@10: 0.000331072\n",
      "  ndcg@10: 0.000343473\n",
      "  map@10: 0.000104893\n",
      "Epoch 10 completed, Train Loss: 1.6408\n",
      "Epoch 11, Step 1, LR: 0.000080, Current Loss: 1.6092, Avg Loss: 1.6092\n",
      "Diff stats — min: -23.6921, max: 25.8622, mean: 0.0651, std: 3.7535\n",
      "\n",
      "Step 110 — Test metrics:\n",
      "  precision@10: 0.000330338\n",
      "  recall@10: 0.000331072\n",
      "  ndcg@10: 0.000338767\n",
      "  map@10: 0.000101873\n",
      "Epoch 11, Step 10, LR: 0.000080, Current Loss: 1.5853, Avg Loss: 1.6077\n",
      "Diff stats — min: -17.8353, max: 17.9066, mean: 0.0924, std: 3.7141\n",
      "\n",
      "Step 119 — Test metrics:\n",
      "  precision@10: 0.000323732\n",
      "  recall@10: 0.000324466\n",
      "  ndcg@10: 0.000333597\n",
      "  map@10: 0.000100564\n",
      "Epoch 11 completed, Train Loss: 1.6058\n",
      "Epoch 12, Step 1, LR: 0.000080, Current Loss: 1.5889, Avg Loss: 1.5889\n",
      "Diff stats — min: -18.9959, max: 18.1730, mean: 0.0740, std: 3.7077\n",
      "\n",
      "Step 121 — Test metrics:\n",
      "  precision@10: 0.000317125\n",
      "  recall@10: 0.000317859\n",
      "  ndcg@10: 0.000329698\n",
      "  map@10: 0.000100077\n",
      "Epoch 12, Step 10, LR: 0.000080, Current Loss: 1.5869, Avg Loss: 1.5772\n",
      "Diff stats — min: -18.2835, max: 18.2596, mean: 0.0352, std: 3.6397\n",
      "\n",
      "Step 130 — Test metrics:\n",
      "  precision@10: 0.000330338\n",
      "  recall@10: 0.000331072\n",
      "  ndcg@10: 0.000332104\n",
      "  map@10: 0.000097846\n",
      "Epoch 12 completed, Train Loss: 1.5749\n",
      "Epoch 13, Step 1, LR: 0.000080, Current Loss: 1.5846, Avg Loss: 1.5846\n",
      "Diff stats — min: -19.4125, max: 19.9372, mean: 0.0359, std: 3.6334\n",
      "\n",
      "Step 132 — Test metrics:\n",
      "  precision@10: 0.000330338\n",
      "  recall@10: 0.000331072\n",
      "  ndcg@10: 0.000331930\n",
      "  map@10: 0.000097772\n",
      "Epoch 13, Step 10, LR: 0.000080, Current Loss: 1.5399, Avg Loss: 1.5542\n",
      "Diff stats — min: -18.6055, max: 19.5573, mean: 0.0773, std: 3.5666\n",
      "\n",
      "Step 141 — Test metrics:\n",
      "  precision@10: 0.000330338\n",
      "  recall@10: 0.000330338\n",
      "  ndcg@10: 0.000330129\n",
      "  map@10: 0.000096849\n",
      "Epoch 13 completed, Train Loss: 1.5525\n",
      "Epoch 14, Step 1, LR: 0.000080, Current Loss: 1.5417, Avg Loss: 1.5417\n",
      "Diff stats — min: -17.1003, max: 15.4890, mean: 0.0544, std: 3.5403\n",
      "\n",
      "Step 143 — Test metrics:\n",
      "  precision@10: 0.000343552\n",
      "  recall@10: 0.000343552\n",
      "  ndcg@10: 0.000340428\n",
      "  map@10: 0.000099041\n",
      "Epoch 14, Step 10, LR: 0.000080, Current Loss: 1.5021, Avg Loss: 1.5296\n",
      "Diff stats — min: -16.7409, max: 17.8232, mean: 0.0961, std: 3.4928\n",
      "\n",
      "Step 152 — Test metrics:\n",
      "  precision@10: 0.000350159\n",
      "  recall@10: 0.000350159\n",
      "  ndcg@10: 0.000349557\n",
      "  map@10: 0.000102292\n",
      "Epoch 14 completed, Train Loss: 1.5288\n",
      "Epoch 15, Step 1, LR: 0.000080, Current Loss: 1.5110, Avg Loss: 1.5110\n",
      "Diff stats — min: -18.3183, max: 18.1897, mean: 0.0761, std: 3.4875\n",
      "\n",
      "Step 154 — Test metrics:\n",
      "  precision@10: 0.000350159\n",
      "  recall@10: 0.000350159\n",
      "  ndcg@10: 0.000348600\n",
      "  map@10: 0.000101749\n",
      "Epoch 15, Step 10, LR: 0.000080, Current Loss: 1.4918, Avg Loss: 1.5036\n",
      "Diff stats — min: -15.9014, max: 16.4878, mean: 0.0846, std: 3.4544\n",
      "\n",
      "Step 163 — Test metrics:\n",
      "  precision@10: 0.000350159\n",
      "  recall@10: 0.000350159\n",
      "  ndcg@10: 0.000351796\n",
      "  map@10: 0.000103409\n",
      "Epoch 15 completed, Train Loss: 1.5037\n",
      "Epoch 16, Step 1, LR: 0.000080, Current Loss: 1.4789, Avg Loss: 1.4789\n",
      "Diff stats — min: -17.7432, max: 17.0116, mean: 0.0934, std: 3.4269\n",
      "\n",
      "Step 165 — Test metrics:\n",
      "  precision@10: 0.000350159\n",
      "  recall@10: 0.000350159\n",
      "  ndcg@10: 0.000353859\n",
      "  map@10: 0.000104594\n",
      "Epoch 16, Step 10, LR: 0.000080, Current Loss: 1.4768, Avg Loss: 1.4826\n",
      "Diff stats — min: -16.2559, max: 18.3541, mean: 0.0822, std: 3.3972\n",
      "\n",
      "Step 174 — Test metrics:\n",
      "  precision@10: 0.000350159\n",
      "  recall@10: 0.000350159\n",
      "  ndcg@10: 0.000367268\n",
      "  map@10: 0.000112522\n",
      "Epoch 16 completed, Train Loss: 1.4823\n",
      "Epoch 17, Step 1, LR: 0.000080, Current Loss: 1.4797, Avg Loss: 1.4797\n",
      "Diff stats — min: -15.8436, max: 16.3364, mean: 0.0695, std: 3.3887\n",
      "\n",
      "Step 176 — Test metrics:\n",
      "  precision@10: 0.000350159\n",
      "  recall@10: 0.000350159\n",
      "  ndcg@10: 0.000368716\n",
      "  map@10: 0.000113256\n",
      "Epoch 17, Step 10, LR: 0.000080, Current Loss: 1.4550, Avg Loss: 1.4641\n",
      "Diff stats — min: -16.0493, max: 19.6840, mean: 0.0957, std: 3.3594\n",
      "\n",
      "Step 185 — Test metrics:\n",
      "  precision@10: 0.000336945\n",
      "  recall@10: 0.000336945\n",
      "  ndcg@10: 0.000359279\n",
      "  map@10: 0.000111293\n",
      "Epoch 17 completed, Train Loss: 1.4650\n",
      "Epoch 18, Step 1, LR: 0.000080, Current Loss: 1.4702, Avg Loss: 1.4702\n",
      "Diff stats — min: -17.1094, max: 15.1865, mean: 0.0505, std: 3.3389\n",
      "\n",
      "Step 187 — Test metrics:\n",
      "  precision@10: 0.000330338\n",
      "  recall@10: 0.000330338\n",
      "  ndcg@10: 0.000354902\n",
      "  map@10: 0.000110558\n",
      "Epoch 18, Step 10, LR: 0.000080, Current Loss: 1.4282, Avg Loss: 1.4431\n",
      "Diff stats — min: -16.5554, max: 15.7650, mean: 0.0985, std: 3.2869\n",
      "\n",
      "Step 196 — Test metrics:\n",
      "  precision@10: 0.000350159\n",
      "  recall@10: 0.000350159\n",
      "  ndcg@10: 0.000375469\n",
      "  map@10: 0.000117202\n",
      "Epoch 18 completed, Train Loss: 1.4434\n",
      "Epoch 19, Step 1, LR: 0.000080, Current Loss: 1.4361, Avg Loss: 1.4361\n",
      "Diff stats — min: -17.2442, max: 15.7616, mean: 0.0837, std: 3.2911\n",
      "\n",
      "Step 198 — Test metrics:\n",
      "  precision@10: 0.000350159\n",
      "  recall@10: 0.000350159\n",
      "  ndcg@10: 0.000375643\n",
      "  map@10: 0.000117275\n",
      "Epoch 19, Step 10, LR: 0.000080, Current Loss: 1.4151, Avg Loss: 1.4277\n",
      "Diff stats — min: -16.6525, max: 15.6412, mean: 0.0865, std: 3.2310\n",
      "\n",
      "Step 207 — Test metrics:\n",
      "  precision@10: 0.000343552\n",
      "  recall@10: 0.000343552\n",
      "  ndcg@10: 0.000370443\n",
      "  map@10: 0.000116109\n",
      "Epoch 19 completed, Train Loss: 1.4257\n",
      "Epoch 20, Step 1, LR: 0.000080, Current Loss: 1.3959, Avg Loss: 1.3959\n",
      "Diff stats — min: -15.2042, max: 18.1606, mean: 0.1350, std: 3.2446\n",
      "\n",
      "Step 209 — Test metrics:\n",
      "  precision@10: 0.000343552\n",
      "  recall@10: 0.000343552\n",
      "  ndcg@10: 0.000370672\n",
      "  map@10: 0.000116282\n",
      "Epoch 20, Step 10, LR: 0.000080, Current Loss: 1.4011, Avg Loss: 1.4058\n",
      "Diff stats — min: -18.3414, max: 18.6156, mean: 0.0901, std: 3.1983\n",
      "\n",
      "Step 218 — Test metrics:\n",
      "  precision@10: 0.000356765\n",
      "  recall@10: 0.000356765\n",
      "  ndcg@10: 0.000379713\n",
      "  map@10: 0.000117902\n",
      "Epoch 20 completed, Train Loss: 1.4040\n",
      "Epoch 21, Step 1, LR: 0.000080, Current Loss: 1.3892, Avg Loss: 1.3892\n",
      "Diff stats — min: -15.2559, max: 15.4629, mean: 0.0969, std: 3.1671\n",
      "\n",
      "Step 220 — Test metrics:\n",
      "  precision@10: 0.000363372\n",
      "  recall@10: 0.000363372\n",
      "  ndcg@10: 0.000383374\n",
      "  map@10: 0.000118314\n",
      "Epoch 21, Step 10, LR: 0.000080, Current Loss: 1.3790, Avg Loss: 1.3846\n",
      "Diff stats — min: -15.3934, max: 16.7191, mean: 0.0993, std: 3.1448\n",
      "\n",
      "Step 229 — Test metrics:\n",
      "  precision@10: 0.000363372\n",
      "  recall@10: 0.000363372\n",
      "  ndcg@10: 0.000385502\n",
      "  map@10: 0.000119375\n",
      "Epoch 21 completed, Train Loss: 1.3832\n",
      "Epoch 22, Step 1, LR: 0.000080, Current Loss: 1.3885, Avg Loss: 1.3885\n",
      "Diff stats — min: -15.8982, max: 18.5286, mean: 0.0864, std: 3.1502\n",
      "\n",
      "Step 231 — Test metrics:\n",
      "  precision@10: 0.000363372\n",
      "  recall@10: 0.000363372\n",
      "  ndcg@10: 0.000385811\n",
      "  map@10: 0.000119520\n",
      "Epoch 22, Step 10, LR: 0.000080, Current Loss: 1.3601, Avg Loss: 1.3739\n",
      "Diff stats — min: -14.9806, max: 16.6555, mean: 0.1153, std: 3.1138\n",
      "\n",
      "Step 240 — Test metrics:\n",
      "  precision@10: 0.000356765\n",
      "  recall@10: 0.000356765\n",
      "  ndcg@10: 0.000380973\n",
      "  map@10: 0.000118576\n",
      "Epoch 22 completed, Train Loss: 1.3731\n",
      "Epoch 23, Step 1, LR: 0.000080, Current Loss: 1.3554, Avg Loss: 1.3554\n",
      "Diff stats — min: -15.3234, max: 15.0666, mean: 0.1066, std: 3.0834\n",
      "\n",
      "Step 242 — Test metrics:\n",
      "  precision@10: 0.000363372\n",
      "  recall@10: 0.000363372\n",
      "  ndcg@10: 0.000386476\n",
      "  map@10: 0.000119832\n",
      "Epoch 23, Step 10, LR: 0.000080, Current Loss: 1.3469, Avg Loss: 1.3477\n",
      "Diff stats — min: -17.9640, max: 16.2439, mean: 0.1033, std: 3.0597\n",
      "\n",
      "Step 251 — Test metrics:\n",
      "  precision@10: 0.000363372\n",
      "  recall@10: 0.000363372\n",
      "  ndcg@10: 0.000388348\n",
      "  map@10: 0.000120773\n",
      "Epoch 23 completed, Train Loss: 1.3473\n",
      "Epoch 24, Step 1, LR: 0.000080, Current Loss: 1.3358, Avg Loss: 1.3358\n",
      "Diff stats — min: -18.9464, max: 18.2628, mean: 0.1134, std: 3.0496\n",
      "\n",
      "Step 253 — Test metrics:\n",
      "  precision@10: 0.000369979\n",
      "  recall@10: 0.000370713\n",
      "  ndcg@10: 0.000392551\n",
      "  map@10: 0.000121507\n",
      "Epoch 24, Step 10, LR: 0.000080, Current Loss: 1.3437, Avg Loss: 1.3353\n",
      "Diff stats — min: -20.5694, max: 18.6206, mean: 0.0965, std: 3.0485\n",
      "\n",
      "Step 262 — Test metrics:\n",
      "  precision@10: 0.000356765\n",
      "  recall@10: 0.000357499\n",
      "  ndcg@10: 0.000383940\n",
      "  map@10: 0.000120089\n",
      "Epoch 24 completed, Train Loss: 1.3337\n",
      "Epoch 25, Step 1, LR: 0.000080, Current Loss: 1.3300, Avg Loss: 1.3300\n",
      "Diff stats — min: -16.3488, max: 16.5996, mean: 0.1058, std: 3.0128\n",
      "\n",
      "Step 264 — Test metrics:\n",
      "  precision@10: 0.000356765\n",
      "  recall@10: 0.000357499\n",
      "  ndcg@10: 0.000383653\n",
      "  map@10: 0.000119952\n",
      "Epoch 25, Step 10, LR: 0.000080, Current Loss: 1.3326, Avg Loss: 1.3197\n",
      "Diff stats — min: -16.6198, max: 18.3506, mean: 0.0691, std: 2.9671\n",
      "\n",
      "Step 273 — Test metrics:\n",
      "  precision@10: 0.000369979\n",
      "  recall@10: 0.000370713\n",
      "  ndcg@10: 0.000392211\n",
      "  map@10: 0.000121449\n",
      "Epoch 25 completed, Train Loss: 1.3183\n",
      "Epoch 26, Step 1, LR: 0.000080, Current Loss: 1.3062, Avg Loss: 1.3062\n",
      "Diff stats — min: -13.5300, max: 19.0565, mean: 0.1174, std: 2.9571\n",
      "\n",
      "Step 275 — Test metrics:\n",
      "  precision@10: 0.000363372\n",
      "  recall@10: 0.000364106\n",
      "  ndcg@10: 0.000387260\n",
      "  map@10: 0.000120369\n",
      "Epoch 26, Step 10, LR: 0.000080, Current Loss: 1.2730, Avg Loss: 1.2979\n",
      "Diff stats — min: -14.9376, max: 14.9872, mean: 0.1525, std: 2.9174\n",
      "\n",
      "Step 284 — Test metrics:\n",
      "  precision@10: 0.000369979\n",
      "  recall@10: 0.000370713\n",
      "  ndcg@10: 0.000395801\n",
      "  map@10: 0.000123734\n",
      "Epoch 26 completed, Train Loss: 1.2972\n",
      "Epoch 27, Step 1, LR: 0.000080, Current Loss: 1.2787, Avg Loss: 1.2787\n",
      "Diff stats — min: -16.5712, max: 17.6065, mean: 0.1361, std: 2.9084\n",
      "\n",
      "Step 286 — Test metrics:\n",
      "  precision@10: 0.000376586\n",
      "  recall@10: 0.000377320\n",
      "  ndcg@10: 0.000400956\n",
      "  map@10: 0.000124846\n",
      "Epoch 27, Step 10, LR: 0.000080, Current Loss: 1.2827, Avg Loss: 1.2827\n",
      "Diff stats — min: -16.8274, max: 16.2909, mean: 0.1129, std: 2.8938\n",
      "\n",
      "Step 295 — Test metrics:\n",
      "  precision@10: 0.000369979\n",
      "  recall@10: 0.000370713\n",
      "  ndcg@10: 0.000399411\n",
      "  map@10: 0.000125494\n",
      "Epoch 27 completed, Train Loss: 1.2817\n",
      "Epoch 28, Step 1, LR: 0.000080, Current Loss: 1.2757, Avg Loss: 1.2757\n",
      "Diff stats — min: -20.6511, max: 21.4217, mean: 0.1340, std: 2.8971\n",
      "\n",
      "Step 297 — Test metrics:\n",
      "  precision@10: 0.000376586\n",
      "  recall@10: 0.000377320\n",
      "  ndcg@10: 0.000403800\n",
      "  map@10: 0.000126257\n",
      "Epoch 28, Step 10, LR: 0.000080, Current Loss: 1.2690, Avg Loss: 1.2690\n",
      "Diff stats — min: -16.1552, max: 14.4721, mean: 0.1109, std: 2.8450\n",
      "\n",
      "Step 306 — Test metrics:\n",
      "  precision@10: 0.000383192\n",
      "  recall@10: 0.000383926\n",
      "  ndcg@10: 0.000401680\n",
      "  map@10: 0.000123035\n",
      "Epoch 28 completed, Train Loss: 1.2687\n",
      "Epoch 29, Step 1, LR: 0.000080, Current Loss: 1.2503, Avg Loss: 1.2503\n",
      "Diff stats — min: -15.8966, max: 14.6079, mean: 0.1374, std: 2.8226\n",
      "\n",
      "Step 308 — Test metrics:\n",
      "  precision@10: 0.000383192\n",
      "  recall@10: 0.000383926\n",
      "  ndcg@10: 0.000401680\n",
      "  map@10: 0.000123035\n",
      "Epoch 29, Step 10, LR: 0.000080, Current Loss: 1.2636, Avg Loss: 1.2509\n",
      "Diff stats — min: -14.5926, max: 18.0708, mean: 0.0886, std: 2.7958\n",
      "\n",
      "Step 317 — Test metrics:\n",
      "  precision@10: 0.000389799\n",
      "  recall@10: 0.000390533\n",
      "  ndcg@10: 0.000406971\n",
      "  map@10: 0.000124330\n",
      "Epoch 29 completed, Train Loss: 1.2509\n",
      "Epoch 30, Step 1, LR: 0.000080, Current Loss: 1.2341, Avg Loss: 1.2341\n",
      "Diff stats — min: -15.8274, max: 18.4721, mean: 0.1347, std: 2.7702\n",
      "\n",
      "Step 319 — Test metrics:\n",
      "  precision@10: 0.000389799\n",
      "  recall@10: 0.000390533\n",
      "  ndcg@10: 0.000414897\n",
      "  map@10: 0.000129047\n",
      "Epoch 30, Step 10, LR: 0.000080, Current Loss: 1.2350, Avg Loss: 1.2400\n",
      "Diff stats — min: -17.1310, max: 16.0298, mean: 0.1227, std: 2.7616\n",
      "\n",
      "Step 328 — Test metrics:\n",
      "  precision@10: 0.000409619\n",
      "  recall@10: 0.000410354\n",
      "  ndcg@10: 0.000431051\n",
      "  map@10: 0.000132874\n",
      "Epoch 30 completed, Train Loss: 1.2393\n",
      "Epoch 31, Step 1, LR: 0.000080, Current Loss: 1.2336, Avg Loss: 1.2336\n",
      "Diff stats — min: -16.4302, max: 19.0284, mean: 0.1334, std: 2.7728\n",
      "\n",
      "Step 330 — Test metrics:\n",
      "  precision@10: 0.000409619\n",
      "  recall@10: 0.000410354\n",
      "  ndcg@10: 0.000430907\n",
      "  map@10: 0.000132762\n",
      "Epoch 31, Step 10, LR: 0.000080, Current Loss: 1.2261, Avg Loss: 1.2267\n",
      "Diff stats — min: -16.2770, max: 16.6197, mean: 0.1114, std: 2.7218\n",
      "\n",
      "Step 339 — Test metrics:\n",
      "  precision@10: 0.000416226\n",
      "  recall@10: 0.000416960\n",
      "  ndcg@10: 0.000430908\n",
      "  map@10: 0.000130709\n",
      "Epoch 31 completed, Train Loss: 1.2260\n",
      "Epoch 32, Step 1, LR: 0.000080, Current Loss: 1.2244, Avg Loss: 1.2244\n",
      "Diff stats — min: -14.6642, max: 14.8202, mean: 0.1264, std: 2.7304\n",
      "\n",
      "Step 341 — Test metrics:\n",
      "  precision@10: 0.000416226\n",
      "  recall@10: 0.000416960\n",
      "  ndcg@10: 0.000430786\n",
      "  map@10: 0.000130644\n",
      "Epoch 32, Step 10, LR: 0.000080, Current Loss: 1.1920, Avg Loss: 1.2151\n",
      "Diff stats — min: -16.0867, max: 17.4043, mean: 0.1483, std: 2.6749\n",
      "\n",
      "Step 350 — Test metrics:\n",
      "  precision@10: 0.000416226\n",
      "  recall@10: 0.000416960\n",
      "  ndcg@10: 0.000436340\n",
      "  map@10: 0.000133761\n",
      "Epoch 32 completed, Train Loss: 1.2146\n",
      "Epoch 33, Step 1, LR: 0.000080, Current Loss: 1.2092, Avg Loss: 1.2092\n",
      "Diff stats — min: -15.0080, max: 13.1155, mean: 0.1292, std: 2.6899\n",
      "\n",
      "Step 352 — Test metrics:\n",
      "  precision@10: 0.000422833\n",
      "  recall@10: 0.000423567\n",
      "  ndcg@10: 0.000440096\n",
      "  map@10: 0.000134242\n",
      "Epoch 33, Step 10, LR: 0.000080, Current Loss: 1.1972, Avg Loss: 1.2049\n",
      "Diff stats — min: -14.4962, max: 15.8643, mean: 0.1439, std: 2.6695\n",
      "\n",
      "Step 361 — Test metrics:\n",
      "  precision@10: 0.000416226\n",
      "  recall@10: 0.000416960\n",
      "  ndcg@10: 0.000432219\n",
      "  map@10: 0.000131225\n",
      "Epoch 33 completed, Train Loss: 1.2032\n",
      "Epoch 34, Step 1, LR: 0.000080, Current Loss: 1.1892, Avg Loss: 1.1892\n",
      "Diff stats — min: -13.1472, max: 17.3873, mean: 0.1450, std: 2.6540\n",
      "\n",
      "Step 363 — Test metrics:\n",
      "  precision@10: 0.000422833\n",
      "  recall@10: 0.000423567\n",
      "  ndcg@10: 0.000433146\n",
      "  map@10: 0.000129948\n",
      "Epoch 34, Step 10, LR: 0.000080, Current Loss: 1.1982, Avg Loss: 1.1949\n",
      "Diff stats — min: -15.1446, max: 17.9173, mean: 0.1221, std: 2.6460\n",
      "\n",
      "Step 372 — Test metrics:\n",
      "  precision@10: 0.000429440\n",
      "  recall@10: 0.000430174\n",
      "  ndcg@10: 0.000437856\n",
      "  map@10: 0.000130939\n",
      "Epoch 34 completed, Train Loss: 1.1940\n",
      "Epoch 35, Step 1, LR: 0.000080, Current Loss: 1.1840, Avg Loss: 1.1840\n",
      "Diff stats — min: -16.7411, max: 19.1043, mean: 0.1380, std: 2.6313\n",
      "\n",
      "Step 374 — Test metrics:\n",
      "  precision@10: 0.000429440\n",
      "  recall@10: 0.000430174\n",
      "  ndcg@10: 0.000436848\n",
      "  map@10: 0.000130388\n",
      "Epoch 35, Step 10, LR: 0.000080, Current Loss: 1.1768, Avg Loss: 1.1811\n",
      "Diff stats — min: -13.6728, max: 13.4172, mean: 0.1375, std: 2.6024\n",
      "\n",
      "Step 383 — Test metrics:\n",
      "  precision@10: 0.000429440\n",
      "  recall@10: 0.000430174\n",
      "  ndcg@10: 0.000428945\n",
      "  map@10: 0.000125562\n",
      "Epoch 35 completed, Train Loss: 1.1818\n",
      "Epoch 36, Step 1, LR: 0.000080, Current Loss: 1.1783, Avg Loss: 1.1783\n",
      "Diff stats — min: -14.2922, max: 15.7472, mean: 0.1362, std: 2.6100\n",
      "\n",
      "Step 385 — Test metrics:\n",
      "  precision@10: 0.000436047\n",
      "  recall@10: 0.000436781\n",
      "  ndcg@10: 0.000433655\n",
      "  map@10: 0.000126453\n",
      "Epoch 36, Step 10, LR: 0.000080, Current Loss: 1.1537, Avg Loss: 1.1729\n",
      "Diff stats — min: -14.5465, max: 15.2791, mean: 0.1605, std: 2.5623\n",
      "\n",
      "Step 394 — Test metrics:\n",
      "  precision@10: 0.000436047\n",
      "  recall@10: 0.000436781\n",
      "  ndcg@10: 0.000437779\n",
      "  map@10: 0.000128587\n",
      "Epoch 36 completed, Train Loss: 1.1729\n",
      "Epoch 37, Step 1, LR: 0.000080, Current Loss: 1.1760, Avg Loss: 1.1760\n",
      "Diff stats — min: -14.4081, max: 14.3100, mean: 0.1162, std: 2.5746\n",
      "\n",
      "Step 396 — Test metrics:\n",
      "  precision@10: 0.000436047\n",
      "  recall@10: 0.000436781\n",
      "  ndcg@10: 0.000438015\n",
      "  map@10: 0.000128716\n",
      "Epoch 37, Step 10, LR: 0.000080, Current Loss: 1.1533, Avg Loss: 1.1632\n",
      "Diff stats — min: -14.9132, max: 15.2804, mean: 0.1471, std: 2.5456\n",
      "\n",
      "Step 405 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000464151\n",
      "  map@10: 0.000136708\n",
      "Epoch 37 completed, Train Loss: 1.1623\n",
      "Epoch 38, Step 1, LR: 0.000080, Current Loss: 1.1655, Avg Loss: 1.1655\n",
      "Diff stats — min: -15.5983, max: 14.8269, mean: 0.1356, std: 2.5727\n",
      "\n",
      "Step 407 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000464702\n",
      "  map@10: 0.000136993\n",
      "Epoch 38, Step 10, LR: 0.000080, Current Loss: 1.1510, Avg Loss: 1.1560\n",
      "Diff stats — min: -14.1097, max: 16.7956, mean: 0.1351, std: 2.5180\n",
      "\n",
      "Step 416 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000463954\n",
      "  map@10: 0.000136561\n",
      "Epoch 38 completed, Train Loss: 1.1554\n",
      "Epoch 39, Step 1, LR: 0.000080, Current Loss: 1.1520, Avg Loss: 1.1520\n",
      "Diff stats — min: -18.5748, max: 16.2277, mean: 0.1499, std: 2.5537\n",
      "\n",
      "Step 418 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000464128\n",
      "  map@10: 0.000136634\n",
      "Epoch 39, Step 10, LR: 0.000080, Current Loss: 1.1449, Avg Loss: 1.1428\n",
      "Diff stats — min: -14.6715, max: 15.6076, mean: 0.1435, std: 2.5210\n",
      "\n",
      "Step 427 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000455020\n",
      "  map@10: 0.000131294\n",
      "Epoch 39 completed, Train Loss: 1.1424\n",
      "Epoch 40, Step 1, LR: 0.000080, Current Loss: 1.1387, Avg Loss: 1.1387\n",
      "Diff stats — min: -14.8098, max: 14.5630, mean: 0.1498, std: 2.5086\n",
      "\n",
      "Step 429 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000455020\n",
      "  map@10: 0.000131294\n",
      "Epoch 40, Step 10, LR: 0.000080, Current Loss: 1.1267, Avg Loss: 1.1346\n",
      "Diff stats — min: -13.6072, max: 13.3227, mean: 0.1572, std: 2.4770\n",
      "\n",
      "Step 438 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000452716\n",
      "  map@10: 0.000129907\n",
      "Epoch 40 completed, Train Loss: 1.1335\n",
      "Epoch 41, Step 1, LR: 0.000080, Current Loss: 1.1290, Avg Loss: 1.1290\n",
      "Diff stats — min: -15.5175, max: 15.5606, mean: 0.1419, std: 2.4618\n",
      "\n",
      "Step 440 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000452630\n",
      "  map@10: 0.000129862\n",
      "Epoch 41, Step 10, LR: 0.000080, Current Loss: 1.1192, Avg Loss: 1.1302\n",
      "Diff stats — min: -16.0601, max: 15.9733, mean: 0.1578, std: 2.4607\n",
      "\n",
      "Step 449 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000453761\n",
      "  map@10: 0.000130478\n",
      "Epoch 41 completed, Train Loss: 1.1295\n",
      "Epoch 42, Step 1, LR: 0.000080, Current Loss: 1.1107, Avg Loss: 1.1107\n",
      "Diff stats — min: -15.6401, max: 15.4735, mean: 0.1730, std: 2.4512\n",
      "\n",
      "Step 451 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000458410\n",
      "  map@10: 0.000131359\n",
      "Epoch 42, Step 10, LR: 0.000080, Current Loss: 1.1306, Avg Loss: 1.1189\n",
      "Diff stats — min: -13.0989, max: 14.7886, mean: 0.1243, std: 2.4410\n",
      "\n",
      "Step 460 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000458939\n",
      "  map@10: 0.000131517\n",
      "Epoch 42 completed, Train Loss: 1.1179\n",
      "Epoch 43, Step 1, LR: 0.000080, Current Loss: 1.1078, Avg Loss: 1.1078\n",
      "Diff stats — min: -13.2711, max: 14.6488, mean: 0.1566, std: 2.4167\n",
      "\n",
      "Step 462 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000460022\n",
      "  map@10: 0.000132067\n",
      "Epoch 43, Step 10, LR: 0.000080, Current Loss: 1.1030, Avg Loss: 1.1115\n",
      "Diff stats — min: -16.9970, max: 15.5016, mean: 0.1618, std: 2.4113\n",
      "\n",
      "Step 471 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000459131\n",
      "  map@10: 0.000131548\n",
      "Epoch 43 completed, Train Loss: 1.1108\n",
      "Epoch 44, Step 1, LR: 0.000080, Current Loss: 1.0967, Avg Loss: 1.0967\n",
      "Diff stats — min: -12.9050, max: 14.4475, mean: 0.1657, std: 2.3983\n",
      "\n",
      "Step 473 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000459033\n",
      "  map@10: 0.000131475\n",
      "Epoch 44, Step 10, LR: 0.000080, Current Loss: 1.1121, Avg Loss: 1.1041\n",
      "Diff stats — min: -15.5933, max: 13.0899, mean: 0.1303, std: 2.3934\n",
      "\n",
      "Step 482 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000454060\n",
      "  map@10: 0.000130363\n",
      "Epoch 44 completed, Train Loss: 1.1030\n",
      "Epoch 45, Step 1, LR: 0.000080, Current Loss: 1.1035, Avg Loss: 1.1035\n",
      "Diff stats — min: -13.1240, max: 14.7194, mean: 0.1536, std: 2.3979\n",
      "\n",
      "Step 484 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000453526\n",
      "  map@10: 0.000130114\n",
      "Epoch 45, Step 10, LR: 0.000080, Current Loss: 1.1056, Avg Loss: 1.0939\n",
      "Diff stats — min: -16.7817, max: 15.7500, mean: 0.1398, std: 2.3866\n",
      "\n",
      "Step 493 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000453764\n",
      "  map@10: 0.000130190\n",
      "Epoch 45 completed, Train Loss: 1.0940\n",
      "Epoch 46, Step 1, LR: 0.000080, Current Loss: 1.0802, Avg Loss: 1.0802\n",
      "Diff stats — min: -16.2513, max: 16.8929, mean: 0.1769, std: 2.3690\n",
      "\n",
      "Step 495 — Test metrics:\n",
      "  precision@10: 0.000455867\n",
      "  recall@10: 0.000456601\n",
      "  ndcg@10: 0.000449622\n",
      "  map@10: 0.000129584\n",
      "Epoch 46, Step 10, LR: 0.000080, Current Loss: 1.0847, Avg Loss: 1.0834\n",
      "Diff stats — min: -14.4957, max: 13.6867, mean: 0.1744, std: 2.3730\n",
      "\n",
      "Step 504 — Test metrics:\n",
      "  precision@10: 0.000455867\n",
      "  recall@10: 0.000456601\n",
      "  ndcg@10: 0.000450994\n",
      "  map@10: 0.000130219\n",
      "Epoch 46 completed, Train Loss: 1.0831\n",
      "Epoch 47, Step 1, LR: 0.000080, Current Loss: 1.0994, Avg Loss: 1.0994\n",
      "Diff stats — min: -14.0964, max: 13.9373, mean: 0.1312, std: 2.3490\n",
      "\n",
      "Step 506 — Test metrics:\n",
      "  precision@10: 0.000455867\n",
      "  recall@10: 0.000456601\n",
      "  ndcg@10: 0.000451428\n",
      "  map@10: 0.000130410\n",
      "Epoch 47, Step 10, LR: 0.000080, Current Loss: 1.0646, Avg Loss: 1.0819\n",
      "Diff stats — min: -13.6853, max: 15.7143, mean: 0.1759, std: 2.3055\n",
      "\n",
      "Step 515 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000466863\n",
      "  map@10: 0.000135466\n",
      "Epoch 47 completed, Train Loss: 1.0806\n",
      "Epoch 48, Step 1, LR: 0.000080, Current Loss: 1.0762, Avg Loss: 1.0762\n",
      "Diff stats — min: -12.9011, max: 19.1560, mean: 0.1572, std: 2.3140\n",
      "\n",
      "Step 517 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000466908\n",
      "  map@10: 0.000135521\n",
      "Epoch 48, Step 10, LR: 0.000080, Current Loss: 1.0605, Avg Loss: 1.0692\n",
      "Diff stats — min: -12.6420, max: 15.0459, mean: 0.1702, std: 2.2913\n",
      "\n",
      "Step 526 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000462712\n",
      "  map@10: 0.000134894\n",
      "Epoch 48 completed, Train Loss: 1.0680\n",
      "Epoch 49, Step 1, LR: 0.000080, Current Loss: 1.0555, Avg Loss: 1.0555\n",
      "Diff stats — min: -13.5190, max: 13.8887, mean: 0.1848, std: 2.2888\n",
      "\n",
      "Step 528 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000467074\n",
      "  map@10: 0.000135639\n",
      "Epoch 49, Step 10, LR: 0.000080, Current Loss: 1.0695, Avg Loss: 1.0639\n",
      "Diff stats — min: -12.7851, max: 15.0975, mean: 0.1511, std: 2.2816\n",
      "\n",
      "Step 537 — Test metrics:\n",
      "  precision@10: 0.000488901\n",
      "  recall@10: 0.000489635\n",
      "  ndcg@10: 0.000483498\n",
      "  map@10: 0.000139632\n",
      "Epoch 49 completed, Train Loss: 1.0629\n",
      "Epoch 50, Step 1, LR: 0.000080, Current Loss: 1.0631, Avg Loss: 1.0631\n",
      "Diff stats — min: -17.7556, max: 14.9387, mean: 0.1638, std: 2.2850\n",
      "\n",
      "Step 539 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000479469\n",
      "  map@10: 0.000139044\n",
      "Epoch 50, Step 10, LR: 0.000080, Current Loss: 1.0502, Avg Loss: 1.0544\n",
      "Diff stats — min: -12.3979, max: 15.5412, mean: 0.1705, std: 2.2542\n",
      "\n",
      "Step 548 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000477916\n",
      "  map@10: 0.000138082\n",
      "Epoch 50 completed, Train Loss: 1.0541\n",
      "Epoch 51, Step 1, LR: 0.000080, Current Loss: 1.0551, Avg Loss: 1.0551\n",
      "Diff stats — min: -14.0275, max: 13.3789, mean: 0.1584, std: 2.2515\n",
      "\n",
      "Step 550 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000477916\n",
      "  map@10: 0.000138082\n",
      "Epoch 51, Step 10, LR: 0.000080, Current Loss: 1.0462, Avg Loss: 1.0498\n",
      "Diff stats — min: -11.8617, max: 12.5078, mean: 0.1643, std: 2.2329\n",
      "\n",
      "Step 559 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000481306\n",
      "  map@10: 0.000139980\n",
      "Epoch 51 completed, Train Loss: 1.0492\n",
      "Epoch 52, Step 1, LR: 0.000080, Current Loss: 1.0413, Avg Loss: 1.0413\n",
      "Diff stats — min: -17.0732, max: 13.8053, mean: 0.1785, std: 2.2460\n",
      "\n",
      "Step 561 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000477372\n",
      "  map@10: 0.000137770\n",
      "Epoch 52, Step 10, LR: 0.000080, Current Loss: 1.0338, Avg Loss: 1.0397\n",
      "Diff stats — min: -12.4670, max: 12.3620, mean: 0.1706, std: 2.2023\n",
      "\n",
      "Step 570 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000480065\n",
      "  map@10: 0.000139189\n",
      "Epoch 52 completed, Train Loss: 1.0391\n",
      "Epoch 53, Step 1, LR: 0.000080, Current Loss: 1.0297, Avg Loss: 1.0297\n",
      "Diff stats — min: -11.6092, max: 12.9181, mean: 0.1850, std: 2.2111\n",
      "\n",
      "Step 572 — Test metrics:\n",
      "  precision@10: 0.000475687\n",
      "  recall@10: 0.000476421\n",
      "  ndcg@10: 0.000475862\n",
      "  map@10: 0.000138528\n",
      "Epoch 53, Step 10, LR: 0.000080, Current Loss: 1.0221, Avg Loss: 1.0294\n",
      "Diff stats — min: -12.8311, max: 14.5049, mean: 0.1917, std: 2.1941\n",
      "\n",
      "Step 581 — Test metrics:\n",
      "  precision@10: 0.000475687\n",
      "  recall@10: 0.000476421\n",
      "  ndcg@10: 0.000475625\n",
      "  map@10: 0.000138418\n",
      "Epoch 53 completed, Train Loss: 1.0292\n",
      "Epoch 54, Step 1, LR: 0.000080, Current Loss: 1.0277, Avg Loss: 1.0277\n",
      "Diff stats — min: -14.6434, max: 15.0345, mean: 0.1780, std: 2.1945\n",
      "\n",
      "Step 583 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000479322\n",
      "  map@10: 0.000138848\n",
      "Epoch 54, Step 10, LR: 0.000080, Current Loss: 1.0187, Avg Loss: 1.0226\n",
      "Diff stats — min: -14.0539, max: 12.1433, mean: 0.1781, std: 2.1621\n",
      "\n",
      "Step 592 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000467910\n",
      "  map@10: 0.000135893\n",
      "Epoch 54 completed, Train Loss: 1.0222\n",
      "Epoch 55, Step 1, LR: 0.000080, Current Loss: 1.0325, Avg Loss: 1.0325\n",
      "Diff stats — min: -18.2332, max: 12.6735, mean: 0.1545, std: 2.1747\n",
      "\n",
      "Step 594 — Test metrics:\n",
      "  precision@10: 0.000475687\n",
      "  recall@10: 0.000476421\n",
      "  ndcg@10: 0.000467755\n",
      "  map@10: 0.000133801\n",
      "Epoch 55, Step 10, LR: 0.000080, Current Loss: 1.0151, Avg Loss: 1.0171\n",
      "Diff stats — min: -13.2605, max: 14.0629, mean: 0.1812, std: 2.1587\n",
      "\n",
      "Step 603 — Test metrics:\n",
      "  precision@10: 0.000475687\n",
      "  recall@10: 0.000476421\n",
      "  ndcg@10: 0.000465538\n",
      "  map@10: 0.000132527\n",
      "Epoch 55 completed, Train Loss: 1.0173\n",
      "Epoch 56, Step 1, LR: 0.000080, Current Loss: 1.0079, Avg Loss: 1.0079\n",
      "Diff stats — min: -14.5761, max: 13.5984, mean: 0.1835, std: 2.1396\n",
      "\n",
      "Step 605 — Test metrics:\n",
      "  precision@10: 0.000475687\n",
      "  recall@10: 0.000476421\n",
      "  ndcg@10: 0.000467442\n",
      "  map@10: 0.000133628\n",
      "Epoch 56, Step 10, LR: 0.000080, Current Loss: 0.9979, Avg Loss: 1.0099\n",
      "Diff stats — min: -13.9024, max: 13.5909, mean: 0.1967, std: 2.1227\n",
      "\n",
      "Step 614 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000462154\n",
      "  map@10: 0.000132469\n",
      "Epoch 56 completed, Train Loss: 1.0094\n",
      "Epoch 57, Step 1, LR: 0.000080, Current Loss: 0.9942, Avg Loss: 0.9942\n",
      "Diff stats — min: -14.9527, max: 13.7686, mean: 0.1931, std: 2.1094\n",
      "\n",
      "Step 616 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000461980\n",
      "  map@10: 0.000132396\n",
      "Epoch 57, Step 10, LR: 0.000080, Current Loss: 0.9995, Avg Loss: 1.0010\n",
      "Diff stats — min: -13.3362, max: 14.5314, mean: 0.1779, std: 2.1017\n",
      "\n",
      "Step 625 — Test metrics:\n",
      "  precision@10: 0.000475687\n",
      "  recall@10: 0.000476421\n",
      "  ndcg@10: 0.000467533\n",
      "  map@10: 0.000133659\n",
      "Epoch 57 completed, Train Loss: 1.0013\n",
      "Epoch 58, Step 1, LR: 0.000080, Current Loss: 0.9946, Avg Loss: 0.9946\n",
      "Diff stats — min: -13.8190, max: 13.5331, mean: 0.1783, std: 2.0890\n",
      "\n",
      "Step 627 — Test metrics:\n",
      "  precision@10: 0.000475687\n",
      "  recall@10: 0.000476421\n",
      "  ndcg@10: 0.000467533\n",
      "  map@10: 0.000133659\n",
      "Epoch 58, Step 10, LR: 0.000080, Current Loss: 0.9947, Avg Loss: 0.9954\n",
      "Diff stats — min: -12.2617, max: 12.8651, mean: 0.1781, std: 2.0832\n",
      "\n",
      "Step 636 — Test metrics:\n",
      "  precision@10: 0.000475687\n",
      "  recall@10: 0.000476421\n",
      "  ndcg@10: 0.000475529\n",
      "  map@10: 0.000138423\n",
      "Epoch 58 completed, Train Loss: 0.9954\n",
      "Epoch 59, Step 1, LR: 0.000080, Current Loss: 0.9897, Avg Loss: 0.9897\n",
      "Diff stats — min: -18.7171, max: 13.9486, mean: 0.1800, std: 2.0765\n",
      "\n",
      "Step 638 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000477655\n",
      "  map@10: 0.000137909\n",
      "Epoch 59, Step 10, LR: 0.000080, Current Loss: 0.9888, Avg Loss: 0.9899\n",
      "Diff stats — min: -16.7911, max: 14.1965, mean: 0.1757, std: 2.0607\n",
      "\n",
      "Step 647 — Test metrics:\n",
      "  precision@10: 0.000475687\n",
      "  recall@10: 0.000476421\n",
      "  ndcg@10: 0.000473708\n",
      "  map@10: 0.000137429\n",
      "Epoch 59 completed, Train Loss: 0.9889\n",
      "Epoch 60, Step 1, LR: 0.000080, Current Loss: 0.9777, Avg Loss: 0.9777\n",
      "Diff stats — min: -13.3989, max: 16.4775, mean: 0.1826, std: 2.0398\n",
      "\n",
      "Step 649 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000478126\n",
      "  map@10: 0.000138292\n",
      "Epoch 60, Step 10, LR: 0.000080, Current Loss: 0.9824, Avg Loss: 0.9833\n",
      "Diff stats — min: -13.0709, max: 14.0619, mean: 0.1637, std: 2.0205\n",
      "\n",
      "Step 658 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000460599\n",
      "  map@10: 0.000133319\n",
      "Epoch 60 completed, Train Loss: 0.9824\n",
      "Epoch 61, Step 1, LR: 0.000080, Current Loss: 0.9690, Avg Loss: 0.9690\n",
      "Diff stats — min: -13.4057, max: 11.9267, mean: 0.1970, std: 2.0265\n",
      "\n",
      "Step 660 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000465924\n",
      "  map@10: 0.000134593\n",
      "Epoch 61, Step 10, LR: 0.000080, Current Loss: 0.9669, Avg Loss: 0.9710\n",
      "Diff stats — min: -12.8054, max: 11.1201, mean: 0.1876, std: 2.0087\n",
      "\n",
      "Step 669 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000463037\n",
      "  map@10: 0.000132933\n",
      "Epoch 61 completed, Train Loss: 0.9714\n",
      "Epoch 62, Step 1, LR: 0.000080, Current Loss: 0.9708, Avg Loss: 0.9708\n",
      "Diff stats — min: -11.4190, max: 12.6085, mean: 0.1737, std: 1.9994\n",
      "\n",
      "Step 671 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000462574\n",
      "  map@10: 0.000132676\n",
      "Epoch 62, Step 10, LR: 0.000080, Current Loss: 0.9748, Avg Loss: 0.9659\n",
      "Diff stats — min: -15.3687, max: 12.9937, mean: 0.1678, std: 2.0076\n",
      "\n",
      "Step 680 — Test metrics:\n",
      "  precision@10: 0.000475687\n",
      "  recall@10: 0.000476421\n",
      "  ndcg@10: 0.000472171\n",
      "  map@10: 0.000136824\n",
      "Epoch 62 completed, Train Loss: 0.9659\n",
      "Epoch 63, Step 1, LR: 0.000080, Current Loss: 0.9623, Avg Loss: 0.9623\n",
      "Diff stats — min: -12.1522, max: 14.8535, mean: 0.1891, std: 1.9937\n",
      "\n",
      "Step 682 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000477080\n",
      "  map@10: 0.000137823\n",
      "Epoch 63, Step 10, LR: 0.000080, Current Loss: 0.9615, Avg Loss: 0.9611\n",
      "Diff stats — min: -12.6203, max: 12.7426, mean: 0.1793, std: 1.9816\n",
      "\n",
      "Step 691 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000476918\n",
      "  map@10: 0.000137778\n",
      "Epoch 63 completed, Train Loss: 0.9619\n",
      "Epoch 64, Step 1, LR: 0.000080, Current Loss: 0.9556, Avg Loss: 0.9556\n",
      "Diff stats — min: -14.6550, max: 12.4608, mean: 0.1826, std: 1.9644\n",
      "\n",
      "Step 693 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000477076\n",
      "  map@10: 0.000137862\n",
      "Epoch 64, Step 10, LR: 0.000080, Current Loss: 0.9514, Avg Loss: 0.9522\n",
      "Diff stats — min: -15.3914, max: 13.9228, mean: 0.1757, std: 1.9403\n",
      "\n",
      "Step 702 — Test metrics:\n",
      "  precision@10: 0.000455867\n",
      "  recall@10: 0.000456601\n",
      "  ndcg@10: 0.000459293\n",
      "  map@10: 0.000134732\n",
      "Epoch 64 completed, Train Loss: 0.9521\n",
      "Epoch 65, Step 1, LR: 0.000080, Current Loss: 0.9489, Avg Loss: 0.9489\n",
      "Diff stats — min: -11.2919, max: 14.4522, mean: 0.1887, std: 1.9494\n",
      "\n",
      "Step 704 — Test metrics:\n",
      "  precision@10: 0.000455867\n",
      "  recall@10: 0.000456601\n",
      "  ndcg@10: 0.000460561\n",
      "  map@10: 0.000135400\n",
      "Epoch 65, Step 10, LR: 0.000080, Current Loss: 0.9507, Avg Loss: 0.9471\n",
      "Diff stats — min: -15.3503, max: 15.9330, mean: 0.1733, std: 1.9335\n",
      "\n",
      "Step 713 — Test metrics:\n",
      "  precision@10: 0.000455867\n",
      "  recall@10: 0.000456601\n",
      "  ndcg@10: 0.000461037\n",
      "  map@10: 0.000135602\n",
      "Epoch 65 completed, Train Loss: 0.9468\n",
      "Epoch 66, Step 1, LR: 0.000080, Current Loss: 0.9511, Avg Loss: 0.9511\n",
      "Diff stats — min: -13.6921, max: 13.4950, mean: 0.1737, std: 1.9343\n",
      "\n",
      "Step 715 — Test metrics:\n",
      "  precision@10: 0.000455867\n",
      "  recall@10: 0.000456601\n",
      "  ndcg@10: 0.000462027\n",
      "  map@10: 0.000136171\n",
      "Epoch 66, Step 10, LR: 0.000080, Current Loss: 0.9397, Avg Loss: 0.9404\n",
      "Diff stats — min: -11.3121, max: 13.1849, mean: 0.1843, std: 1.9133\n",
      "\n",
      "Step 724 — Test metrics:\n",
      "  precision@10: 0.000455867\n",
      "  recall@10: 0.000456601\n",
      "  ndcg@10: 0.000461534\n",
      "  map@10: 0.000135885\n",
      "Epoch 66 completed, Train Loss: 0.9403\n",
      "Epoch 67, Step 1, LR: 0.000080, Current Loss: 0.9366, Avg Loss: 0.9366\n",
      "Diff stats — min: -13.0094, max: 16.1510, mean: 0.1821, std: 1.8984\n",
      "\n",
      "Step 726 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000466183\n",
      "  map@10: 0.000136766\n",
      "Epoch 67, Step 10, LR: 0.000080, Current Loss: 0.9383, Avg Loss: 0.9346\n",
      "Diff stats — min: -12.6095, max: 13.1009, mean: 0.1759, std: 1.8927\n",
      "\n",
      "Step 735 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000470281\n",
      "  map@10: 0.000137364\n",
      "Epoch 67 completed, Train Loss: 0.9336\n",
      "Epoch 68, Step 1, LR: 0.000080, Current Loss: 0.9319, Avg Loss: 0.9319\n",
      "Diff stats — min: -13.6769, max: 11.6991, mean: 0.1857, std: 1.8849\n",
      "\n",
      "Step 737 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000467086\n",
      "  map@10: 0.000137254\n",
      "Epoch 68, Step 10, LR: 0.000080, Current Loss: 0.9236, Avg Loss: 0.9285\n",
      "Diff stats — min: -12.5869, max: 18.8880, mean: 0.1973, std: 1.8827\n",
      "\n",
      "Step 746 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000472969\n",
      "  map@10: 0.000138777\n",
      "Epoch 68 completed, Train Loss: 0.9286\n",
      "Epoch 69, Step 1, LR: 0.000080, Current Loss: 0.9242, Avg Loss: 0.9242\n",
      "Diff stats — min: -11.5539, max: 12.7061, mean: 0.1851, std: 1.8604\n",
      "\n",
      "Step 748 — Test metrics:\n",
      "  precision@10: 0.000475687\n",
      "  recall@10: 0.000476421\n",
      "  ndcg@10: 0.000476840\n",
      "  map@10: 0.000139280\n",
      "Epoch 69, Step 10, LR: 0.000080, Current Loss: 0.9128, Avg Loss: 0.9201\n",
      "Diff stats — min: -14.9177, max: 14.9001, mean: 0.1956, std: 1.8414\n",
      "\n",
      "Step 757 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000473547\n",
      "  map@10: 0.000139013\n",
      "Epoch 69 completed, Train Loss: 0.9199\n",
      "Epoch 70, Step 1, LR: 0.000080, Current Loss: 0.9226, Avg Loss: 0.9226\n",
      "Diff stats — min: -11.8591, max: 16.6837, mean: 0.1817, std: 1.8538\n",
      "\n",
      "Step 759 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000469591\n",
      "  map@10: 0.000138465\n",
      "Epoch 70, Step 10, LR: 0.000080, Current Loss: 0.9174, Avg Loss: 0.9167\n",
      "Diff stats — min: -13.4851, max: 12.8927, mean: 0.1827, std: 1.8324\n",
      "\n",
      "Step 768 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000475554\n",
      "  map@10: 0.000139952\n",
      "Epoch 70 completed, Train Loss: 0.9166\n",
      "Epoch 71, Step 1, LR: 0.000080, Current Loss: 0.9193, Avg Loss: 0.9193\n",
      "Diff stats — min: -13.9401, max: 12.0336, mean: 0.1743, std: 1.8251\n",
      "\n",
      "Step 770 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000477255\n",
      "  map@10: 0.000140835\n",
      "Epoch 71, Step 10, LR: 0.000080, Current Loss: 0.9122, Avg Loss: 0.9108\n",
      "Diff stats — min: -16.8676, max: 14.1896, mean: 0.1822, std: 1.8121\n",
      "\n",
      "Step 779 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000485835\n",
      "  map@10: 0.000142230\n",
      "Epoch 71 completed, Train Loss: 0.9100\n",
      "Epoch 72, Step 1, LR: 0.000080, Current Loss: 0.8972, Avg Loss: 0.8972\n",
      "Diff stats — min: -11.8904, max: 12.4753, mean: 0.2010, std: 1.7950\n",
      "\n",
      "Step 781 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000485903\n",
      "  map@10: 0.000142238\n",
      "Epoch 72, Step 10, LR: 0.000080, Current Loss: 0.9027, Avg Loss: 0.9081\n",
      "Diff stats — min: -12.5654, max: 18.5395, mean: 0.1951, std: 1.8019\n",
      "\n",
      "Step 790 — Test metrics:\n",
      "  precision@10: 0.000488901\n",
      "  recall@10: 0.000489635\n",
      "  ndcg@10: 0.000488669\n",
      "  map@10: 0.000142132\n",
      "Epoch 72 completed, Train Loss: 0.9077\n",
      "Epoch 73, Step 1, LR: 0.000080, Current Loss: 0.9149, Avg Loss: 0.9149\n",
      "Diff stats — min: -12.2324, max: 12.6777, mean: 0.1705, std: 1.8052\n",
      "\n",
      "Step 792 — Test metrics:\n",
      "  precision@10: 0.000495507\n",
      "  recall@10: 0.000496241\n",
      "  ndcg@10: 0.000493436\n",
      "  map@10: 0.000143084\n",
      "Epoch 73, Step 10, LR: 0.000080, Current Loss: 0.8936, Avg Loss: 0.9007\n",
      "Diff stats — min: -10.8737, max: 12.0578, mean: 0.2022, std: 1.7828\n",
      "\n",
      "Step 801 — Test metrics:\n",
      "  precision@10: 0.000495507\n",
      "  recall@10: 0.000496241\n",
      "  ndcg@10: 0.000494639\n",
      "  map@10: 0.000143773\n",
      "Epoch 73 completed, Train Loss: 0.9000\n",
      "Epoch 74, Step 1, LR: 0.000080, Current Loss: 0.8936, Avg Loss: 0.8936\n",
      "Diff stats — min: -14.3602, max: 13.5258, mean: 0.1971, std: 1.7723\n",
      "\n",
      "Step 803 — Test metrics:\n",
      "  precision@10: 0.000495507\n",
      "  recall@10: 0.000496241\n",
      "  ndcg@10: 0.000493532\n",
      "  map@10: 0.000143233\n",
      "Epoch 74, Step 10, LR: 0.000080, Current Loss: 0.8985, Avg Loss: 0.8965\n",
      "Diff stats — min: -13.9238, max: 13.0540, mean: 0.1930, std: 1.7826\n",
      "\n",
      "Step 812 — Test metrics:\n",
      "  precision@10: 0.000502114\n",
      "  recall@10: 0.000502848\n",
      "  ndcg@10: 0.000498762\n",
      "  map@10: 0.000144438\n",
      "Epoch 74 completed, Train Loss: 0.8969\n",
      "Epoch 75, Step 1, LR: 0.000080, Current Loss: 0.9054, Avg Loss: 0.9054\n",
      "Diff stats — min: -14.8992, max: 13.0737, mean: 0.1716, std: 1.7699\n",
      "\n",
      "Step 814 — Test metrics:\n",
      "  precision@10: 0.000502114\n",
      "  recall@10: 0.000502848\n",
      "  ndcg@10: 0.000498718\n",
      "  map@10: 0.000144365\n",
      "Epoch 75, Step 10, LR: 0.000080, Current Loss: 0.9051, Avg Loss: 0.8953\n",
      "Diff stats — min: -10.9566, max: 12.9991, mean: 0.1630, std: 1.7538\n",
      "\n",
      "Step 823 — Test metrics:\n",
      "  precision@10: 0.000488901\n",
      "  recall@10: 0.000489635\n",
      "  ndcg@10: 0.000493393\n",
      "  map@10: 0.000144722\n",
      "Epoch 75 completed, Train Loss: 0.8948\n",
      "Epoch 76, Step 1, LR: 0.000080, Current Loss: 0.8882, Avg Loss: 0.8882\n",
      "Diff stats — min: -13.7163, max: 12.1125, mean: 0.1967, std: 1.7486\n",
      "\n",
      "Step 825 — Test metrics:\n",
      "  precision@10: 0.000488901\n",
      "  recall@10: 0.000489635\n",
      "  ndcg@10: 0.000493357\n",
      "  map@10: 0.000144691\n",
      "Epoch 76, Step 10, LR: 0.000080, Current Loss: 0.8869, Avg Loss: 0.8892\n",
      "Diff stats — min: -13.1441, max: 17.6739, mean: 0.1928, std: 1.7416\n",
      "\n",
      "Step 834 — Test metrics:\n",
      "  precision@10: 0.000495507\n",
      "  recall@10: 0.000496241\n",
      "  ndcg@10: 0.000498564\n",
      "  map@10: 0.000145884\n",
      "Epoch 76 completed, Train Loss: 0.8891\n",
      "Epoch 77, Step 1, LR: 0.000080, Current Loss: 0.8885, Avg Loss: 0.8885\n",
      "Diff stats — min: -12.2114, max: 13.8224, mean: 0.1925, std: 1.7437\n",
      "\n",
      "Step 836 — Test metrics:\n",
      "  precision@10: 0.000495507\n",
      "  recall@10: 0.000496241\n",
      "  ndcg@10: 0.000499106\n",
      "  map@10: 0.000146133\n",
      "Epoch 77, Step 10, LR: 0.000080, Current Loss: 0.8862, Avg Loss: 0.8877\n",
      "Diff stats — min: -12.9550, max: 13.7260, mean: 0.1928, std: 1.7414\n",
      "\n",
      "Step 845 — Test metrics:\n",
      "  precision@10: 0.000508721\n",
      "  recall@10: 0.000509455\n",
      "  ndcg@10: 0.000505345\n",
      "  map@10: 0.000145610\n",
      "Epoch 77 completed, Train Loss: 0.8869\n",
      "Epoch 78, Step 1, LR: 0.000080, Current Loss: 0.8829, Avg Loss: 0.8829\n",
      "Diff stats — min: -11.7130, max: 12.8240, mean: 0.1986, std: 1.7341\n",
      "\n",
      "Step 847 — Test metrics:\n",
      "  precision@10: 0.000508721\n",
      "  recall@10: 0.000509455\n",
      "  ndcg@10: 0.000508523\n",
      "  map@10: 0.000147372\n",
      "Epoch 78, Step 10, LR: 0.000080, Current Loss: 0.8796, Avg Loss: 0.8838\n",
      "Diff stats — min: -11.3343, max: 14.2183, mean: 0.1965, std: 1.7208\n",
      "\n",
      "Step 856 — Test metrics:\n",
      "  precision@10: 0.000515328\n",
      "  recall@10: 0.000516062\n",
      "  ndcg@10: 0.000509776\n",
      "  map@10: 0.000146453\n",
      "Epoch 78 completed, Train Loss: 0.8824\n",
      "Epoch 79, Step 1, LR: 0.000080, Current Loss: 0.8725, Avg Loss: 0.8725\n",
      "Diff stats — min: -12.5850, max: 12.7595, mean: 0.2067, std: 1.7157\n",
      "\n",
      "Step 858 — Test metrics:\n",
      "  precision@10: 0.000515328\n",
      "  recall@10: 0.000516062\n",
      "  ndcg@10: 0.000509070\n",
      "  map@10: 0.000146114\n",
      "Epoch 79, Step 10, LR: 0.000080, Current Loss: 0.8807, Avg Loss: 0.8780\n",
      "Diff stats — min: -11.1645, max: 12.8390, mean: 0.1856, std: 1.7080\n",
      "\n",
      "Step 867 — Test metrics:\n",
      "  precision@10: 0.000528541\n",
      "  recall@10: 0.000529275\n",
      "  ndcg@10: 0.000517824\n",
      "  map@10: 0.000147572\n",
      "Epoch 79 completed, Train Loss: 0.8776\n",
      "Epoch 80, Step 1, LR: 0.000080, Current Loss: 0.8800, Avg Loss: 0.8800\n",
      "Diff stats — min: -10.4797, max: 11.1883, mean: 0.1974, std: 1.7216\n",
      "\n",
      "Step 869 — Test metrics:\n",
      "  precision@10: 0.000528541\n",
      "  recall@10: 0.000529275\n",
      "  ndcg@10: 0.000518617\n",
      "  map@10: 0.000147939\n",
      "Epoch 80, Step 10, LR: 0.000080, Current Loss: 0.8777, Avg Loss: 0.8752\n",
      "Diff stats — min: -14.3120, max: 12.0511, mean: 0.1838, std: 1.6910\n",
      "\n",
      "Step 878 — Test metrics:\n",
      "  precision@10: 0.000535148\n",
      "  recall@10: 0.000535882\n",
      "  ndcg@10: 0.000526939\n",
      "  map@10: 0.000151258\n",
      "Epoch 80 completed, Train Loss: 0.8749\n",
      "Epoch 81, Step 1, LR: 0.000080, Current Loss: 0.8645, Avg Loss: 0.8645\n",
      "Diff stats — min: -12.6398, max: 12.6069, mean: 0.2140, std: 1.6929\n",
      "\n",
      "Step 880 — Test metrics:\n",
      "  precision@10: 0.000535148\n",
      "  recall@10: 0.000535882\n",
      "  ndcg@10: 0.000526867\n",
      "  map@10: 0.000151219\n",
      "Epoch 81, Step 10, LR: 0.000080, Current Loss: 0.8662, Avg Loss: 0.8694\n",
      "Diff stats — min: -11.2000, max: 12.4468, mean: 0.2109, std: 1.6939\n",
      "\n",
      "Step 889 — Test metrics:\n",
      "  precision@10: 0.000535148\n",
      "  recall@10: 0.000535882\n",
      "  ndcg@10: 0.000525789\n",
      "  map@10: 0.000150731\n",
      "Epoch 81 completed, Train Loss: 0.8700\n",
      "Epoch 82, Step 1, LR: 0.000080, Current Loss: 0.8614, Avg Loss: 0.8614\n",
      "Diff stats — min: -11.3752, max: 11.8124, mean: 0.2111, std: 1.6734\n",
      "\n",
      "Step 891 — Test metrics:\n",
      "  precision@10: 0.000535148\n",
      "  recall@10: 0.000535882\n",
      "  ndcg@10: 0.000519624\n",
      "  map@10: 0.000146969\n",
      "Epoch 82, Step 10, LR: 0.000080, Current Loss: 0.8680, Avg Loss: 0.8667\n",
      "Diff stats — min: -12.2533, max: 13.3281, mean: 0.1914, std: 1.6699\n",
      "\n",
      "Step 900 — Test metrics:\n",
      "  precision@10: 0.000548362\n",
      "  recall@10: 0.000549096\n",
      "  ndcg@10: 0.000528819\n",
      "  map@10: 0.000148681\n",
      "Epoch 82 completed, Train Loss: 0.8664\n",
      "Epoch 83, Step 1, LR: 0.000080, Current Loss: 0.8683, Avg Loss: 0.8683\n",
      "Diff stats — min: -10.6092, max: 10.6526, mean: 0.1938, std: 1.6705\n",
      "\n",
      "Step 902 — Test metrics:\n",
      "  precision@10: 0.000548362\n",
      "  recall@10: 0.000549096\n",
      "  ndcg@10: 0.000528350\n",
      "  map@10: 0.000148471\n",
      "Epoch 83, Step 10, LR: 0.000080, Current Loss: 0.8638, Avg Loss: 0.8631\n",
      "Diff stats — min: -10.7736, max: 11.9213, mean: 0.2047, std: 1.6783\n",
      "\n",
      "Step 911 — Test metrics:\n",
      "  precision@10: 0.000554968\n",
      "  recall@10: 0.000555702\n",
      "  ndcg@10: 0.000534016\n",
      "  map@10: 0.000149819\n",
      "Epoch 83 completed, Train Loss: 0.8624\n",
      "Epoch 84, Step 1, LR: 0.000080, Current Loss: 0.8627, Avg Loss: 0.8627\n",
      "Diff stats — min: -12.3137, max: 11.0009, mean: 0.1955, std: 1.6549\n",
      "\n",
      "Step 913 — Test metrics:\n",
      "  precision@10: 0.000554968\n",
      "  recall@10: 0.000555702\n",
      "  ndcg@10: 0.000536033\n",
      "  map@10: 0.000150983\n",
      "Epoch 84, Step 10, LR: 0.000080, Current Loss: 0.8686, Avg Loss: 0.8640\n",
      "Diff stats — min: -13.5060, max: 10.9400, mean: 0.1780, std: 1.6455\n",
      "\n",
      "Step 922 — Test metrics:\n",
      "  precision@10: 0.000554968\n",
      "  recall@10: 0.000555702\n",
      "  ndcg@10: 0.000538069\n",
      "  map@10: 0.000151728\n",
      "Epoch 84 completed, Train Loss: 0.8633\n",
      "Epoch 85, Step 1, LR: 0.000080, Current Loss: 0.8596, Avg Loss: 0.8596\n",
      "Diff stats — min: -14.1378, max: 14.4613, mean: 0.1981, std: 1.6495\n",
      "\n",
      "Step 924 — Test metrics:\n",
      "  precision@10: 0.000554968\n",
      "  recall@10: 0.000555702\n",
      "  ndcg@10: 0.000539669\n",
      "  map@10: 0.000152553\n",
      "Epoch 85, Step 10, LR: 0.000080, Current Loss: 0.8610, Avg Loss: 0.8562\n",
      "Diff stats — min: -9.3747, max: 14.3561, mean: 0.1977, std: 1.6524\n",
      "\n",
      "Step 933 — Test metrics:\n",
      "  precision@10: 0.000548362\n",
      "  recall@10: 0.000549096\n",
      "  ndcg@10: 0.000537753\n",
      "  map@10: 0.000153075\n",
      "Epoch 85 completed, Train Loss: 0.8570\n",
      "Epoch 86, Step 1, LR: 0.000080, Current Loss: 0.8572, Avg Loss: 0.8572\n",
      "Diff stats — min: -10.9628, max: 11.6707, mean: 0.1954, std: 1.6322\n",
      "\n",
      "Step 935 — Test metrics:\n",
      "  precision@10: 0.000548362\n",
      "  recall@10: 0.000549096\n",
      "  ndcg@10: 0.000537753\n",
      "  map@10: 0.000153075\n",
      "Epoch 86, Step 10, LR: 0.000080, Current Loss: 0.8576, Avg Loss: 0.8546\n",
      "Diff stats — min: -11.9242, max: 13.2890, mean: 0.1949, std: 1.6369\n",
      "\n",
      "Step 944 — Test metrics:\n",
      "  precision@10: 0.000548362\n",
      "  recall@10: 0.000549096\n",
      "  ndcg@10: 0.000536813\n",
      "  map@10: 0.000152653\n",
      "Epoch 86 completed, Train Loss: 0.8546\n",
      "Epoch 87, Step 1, LR: 0.000080, Current Loss: 0.8501, Avg Loss: 0.8501\n",
      "Diff stats — min: -12.3635, max: 13.9952, mean: 0.2120, std: 1.6365\n",
      "\n",
      "Step 946 — Test metrics:\n",
      "  precision@10: 0.000548362\n",
      "  recall@10: 0.000549096\n",
      "  ndcg@10: 0.000536813\n",
      "  map@10: 0.000152653\n",
      "Epoch 87, Step 10, LR: 0.000080, Current Loss: 0.8581, Avg Loss: 0.8508\n",
      "Diff stats — min: -14.7053, max: 11.5046, mean: 0.1905, std: 1.6283\n",
      "\n",
      "Step 955 — Test metrics:\n",
      "  precision@10: 0.000548362\n",
      "  recall@10: 0.000549096\n",
      "  ndcg@10: 0.000536018\n",
      "  map@10: 0.000152296\n",
      "Epoch 87 completed, Train Loss: 0.8511\n",
      "Epoch 88, Step 1, LR: 0.000080, Current Loss: 0.8465, Avg Loss: 0.8465\n",
      "Diff stats — min: -9.1552, max: 12.0834, mean: 0.2119, std: 1.6184\n",
      "\n",
      "Step 957 — Test metrics:\n",
      "  precision@10: 0.000548362\n",
      "  recall@10: 0.000549096\n",
      "  ndcg@10: 0.000537538\n",
      "  map@10: 0.000153232\n",
      "Epoch 88, Step 10, LR: 0.000080, Current Loss: 0.8478, Avg Loss: 0.8474\n",
      "Diff stats — min: -12.8750, max: 11.8776, mean: 0.2048, std: 1.6143\n",
      "\n",
      "Step 966 — Test metrics:\n",
      "  precision@10: 0.000561575\n",
      "  recall@10: 0.000562309\n",
      "  ndcg@10: 0.000543219\n",
      "  map@10: 0.000153004\n",
      "Epoch 88 completed, Train Loss: 0.8473\n",
      "Epoch 89, Step 1, LR: 0.000080, Current Loss: 0.8476, Avg Loss: 0.8476\n",
      "Diff stats — min: -14.2139, max: 11.6003, mean: 0.2163, std: 1.6341\n",
      "\n",
      "Step 968 — Test metrics:\n",
      "  precision@10: 0.000561575\n",
      "  recall@10: 0.000562309\n",
      "  ndcg@10: 0.000544436\n",
      "  map@10: 0.000153647\n",
      "Epoch 89, Step 10, LR: 0.000080, Current Loss: 0.8446, Avg Loss: 0.8440\n",
      "Diff stats — min: -11.3171, max: 13.0089, mean: 0.1977, std: 1.5887\n",
      "\n",
      "Step 977 — Test metrics:\n",
      "  precision@10: 0.000568182\n",
      "  recall@10: 0.000568916\n",
      "  ndcg@10: 0.000549839\n",
      "  map@10: 0.000154950\n",
      "Epoch 89 completed, Train Loss: 0.8433\n",
      "Epoch 90, Step 1, LR: 0.000080, Current Loss: 0.8378, Avg Loss: 0.8378\n",
      "Diff stats — min: -11.6668, max: 11.6597, mean: 0.2173, std: 1.5992\n",
      "\n",
      "Step 979 — Test metrics:\n",
      "  precision@10: 0.000561575\n",
      "  recall@10: 0.000562309\n",
      "  ndcg@10: 0.000545809\n",
      "  map@10: 0.000154362\n",
      "Epoch 90, Step 10, LR: 0.000080, Current Loss: 0.8454, Avg Loss: 0.8426\n",
      "Diff stats — min: -13.0294, max: 16.0090, mean: 0.2023, std: 1.6035\n",
      "\n",
      "Step 988 — Test metrics:\n",
      "  precision@10: 0.000568182\n",
      "  recall@10: 0.000568916\n",
      "  ndcg@10: 0.000550496\n",
      "  map@10: 0.000155162\n",
      "Epoch 90 completed, Train Loss: 0.8426\n",
      "Epoch 91, Step 1, LR: 0.000080, Current Loss: 0.8361, Avg Loss: 0.8361\n",
      "Diff stats — min: -13.1120, max: 10.9763, mean: 0.2139, std: 1.5860\n",
      "\n",
      "Step 990 — Test metrics:\n",
      "  precision@10: 0.000568182\n",
      "  recall@10: 0.000568916\n",
      "  ndcg@10: 0.000551725\n",
      "  map@10: 0.000155870\n",
      "Epoch 91, Step 10, LR: 0.000080, Current Loss: 0.8369, Avg Loss: 0.8386\n",
      "Diff stats — min: -8.8530, max: 11.3524, mean: 0.2112, std: 1.5823\n",
      "\n",
      "Step 999 — Test metrics:\n",
      "  precision@10: 0.000581395\n",
      "  recall@10: 0.000582129\n",
      "  ndcg@10: 0.000561555\n",
      "  map@10: 0.000157894\n",
      "Epoch 91 completed, Train Loss: 0.8387\n",
      "Epoch 92, Step 1, LR: 0.000080, Current Loss: 0.8374, Avg Loss: 0.8374\n",
      "Diff stats — min: -10.6190, max: 12.7161, mean: 0.2114, std: 1.5869\n",
      "\n",
      "Step 1001 — Test metrics:\n",
      "  precision@10: 0.000581395\n",
      "  recall@10: 0.000582129\n",
      "  ndcg@10: 0.000564102\n",
      "  map@10: 0.000159278\n",
      "Epoch 92, Step 10, LR: 0.000080, Current Loss: 0.8315, Avg Loss: 0.8345\n",
      "Diff stats — min: -11.7126, max: 14.4716, mean: 0.2118, std: 1.5646\n",
      "\n",
      "Step 1010 — Test metrics:\n",
      "  precision@10: 0.000574789\n",
      "  recall@10: 0.000575523\n",
      "  ndcg@10: 0.000558709\n",
      "  map@10: 0.000157881\n",
      "Epoch 92 completed, Train Loss: 0.8354\n",
      "Epoch 93, Step 1, LR: 0.000080, Current Loss: 0.8318, Avg Loss: 0.8318\n",
      "Diff stats — min: -13.9116, max: 12.0553, mean: 0.2154, std: 1.5680\n",
      "\n",
      "Step 1012 — Test metrics:\n",
      "  precision@10: 0.000574789\n",
      "  recall@10: 0.000575523\n",
      "  ndcg@10: 0.000558883\n",
      "  map@10: 0.000157954\n",
      "Epoch 93, Step 10, LR: 0.000080, Current Loss: 0.8319, Avg Loss: 0.8325\n",
      "Diff stats — min: -9.7349, max: 11.4555, mean: 0.2105, std: 1.5617\n",
      "\n",
      "Step 1021 — Test metrics:\n",
      "  precision@10: 0.000581395\n",
      "  recall@10: 0.000582129\n",
      "  ndcg@10: 0.000561650\n",
      "  map@10: 0.000157968\n",
      "Epoch 93 completed, Train Loss: 0.8329\n",
      "Epoch 94, Step 1, LR: 0.000080, Current Loss: 0.8339, Avg Loss: 0.8339\n",
      "Diff stats — min: -10.7668, max: 13.1822, mean: 0.1990, std: 1.5499\n",
      "\n",
      "Step 1023 — Test metrics:\n",
      "  precision@10: 0.000574789\n",
      "  recall@10: 0.000575523\n",
      "  ndcg@10: 0.000556471\n",
      "  map@10: 0.000156866\n",
      "Epoch 94, Step 10, LR: 0.000080, Current Loss: 0.8195, Avg Loss: 0.8299\n",
      "Diff stats — min: -9.1057, max: 12.4361, mean: 0.2300, std: 1.5498\n",
      "\n",
      "Step 1032 — Test metrics:\n",
      "  precision@10: 0.000581395\n",
      "  recall@10: 0.000582129\n",
      "  ndcg@10: 0.000556502\n",
      "  map@10: 0.000155259\n",
      "Epoch 94 completed, Train Loss: 0.8293\n",
      "Epoch 95, Step 1, LR: 0.000080, Current Loss: 0.8226, Avg Loss: 0.8226\n",
      "Diff stats — min: -11.2898, max: 14.2553, mean: 0.2179, std: 1.5394\n",
      "\n",
      "Step 1034 — Test metrics:\n",
      "  precision@10: 0.000581395\n",
      "  recall@10: 0.000582129\n",
      "  ndcg@10: 0.000558232\n",
      "  map@10: 0.000156287\n",
      "Epoch 95, Step 10, LR: 0.000080, Current Loss: 0.8285, Avg Loss: 0.8264\n",
      "Diff stats — min: -10.6948, max: 11.5795, mean: 0.1999, std: 1.5294\n",
      "\n",
      "Step 1043 — Test metrics:\n",
      "  precision@10: 0.000588002\n",
      "  recall@10: 0.000588736\n",
      "  ndcg@10: 0.000565610\n",
      "  map@10: 0.000158457\n",
      "Epoch 95 completed, Train Loss: 0.8263\n",
      "Epoch 96, Step 1, LR: 0.000080, Current Loss: 0.8135, Avg Loss: 0.8135\n",
      "Diff stats — min: -10.9347, max: 14.2630, mean: 0.2411, std: 1.5498\n",
      "\n",
      "Step 1045 — Test metrics:\n",
      "  precision@10: 0.000588002\n",
      "  recall@10: 0.000588736\n",
      "  ndcg@10: 0.000567346\n",
      "  map@10: 0.000159438\n",
      "Epoch 96, Step 10, LR: 0.000080, Current Loss: 0.8212, Avg Loss: 0.8248\n",
      "Diff stats — min: -12.5638, max: 11.3369, mean: 0.2190, std: 1.5404\n",
      "\n",
      "Step 1054 — Test metrics:\n",
      "  precision@10: 0.000574789\n",
      "  recall@10: 0.000575523\n",
      "  ndcg@10: 0.000560239\n",
      "  map@10: 0.000158712\n",
      "Epoch 96 completed, Train Loss: 0.8245\n",
      "Epoch 97, Step 1, LR: 0.000080, Current Loss: 0.8240, Avg Loss: 0.8240\n",
      "Diff stats — min: -10.6361, max: 11.5141, mean: 0.2102, std: 1.5318\n",
      "\n",
      "Step 1056 — Test metrics:\n",
      "  precision@10: 0.000574789\n",
      "  recall@10: 0.000575523\n",
      "  ndcg@10: 0.000561303\n",
      "  map@10: 0.000159281\n",
      "Epoch 97, Step 10, LR: 0.000080, Current Loss: 0.8216, Avg Loss: 0.8211\n",
      "Diff stats — min: -9.8187, max: 13.2427, mean: 0.2136, std: 1.5253\n",
      "\n",
      "Step 1065 — Test metrics:\n",
      "  precision@10: 0.000594609\n",
      "  recall@10: 0.000595343\n",
      "  ndcg@10: 0.000573772\n",
      "  map@10: 0.000160953\n",
      "Epoch 97 completed, Train Loss: 0.8209\n",
      "Epoch 98, Step 1, LR: 0.000080, Current Loss: 0.8216, Avg Loss: 0.8216\n",
      "Diff stats — min: -8.9789, max: 10.8728, mean: 0.2105, std: 1.5218\n",
      "\n",
      "Step 1067 — Test metrics:\n",
      "  precision@10: 0.000601216\n",
      "  recall@10: 0.000601950\n",
      "  ndcg@10: 0.000579409\n",
      "  map@10: 0.000162505\n",
      "Epoch 98, Step 10, LR: 0.000080, Current Loss: 0.8189, Avg Loss: 0.8198\n",
      "Diff stats — min: -10.7832, max: 13.5248, mean: 0.2133, std: 1.5197\n",
      "\n",
      "Step 1076 — Test metrics:\n",
      "  precision@10: 0.000607822\n",
      "  recall@10: 0.000608556\n",
      "  ndcg@10: 0.000586267\n",
      "  map@10: 0.000164661\n",
      "Epoch 98 completed, Train Loss: 0.8189\n",
      "Epoch 99, Step 1, LR: 0.000080, Current Loss: 0.8165, Avg Loss: 0.8165\n",
      "Diff stats — min: -11.5295, max: 11.2804, mean: 0.2259, std: 1.5342\n",
      "\n",
      "Step 1078 — Test metrics:\n",
      "  precision@10: 0.000607822\n",
      "  recall@10: 0.000608556\n",
      "  ndcg@10: 0.000585438\n",
      "  map@10: 0.000164055\n",
      "Epoch 99, Step 10, LR: 0.000080, Current Loss: 0.8223, Avg Loss: 0.8161\n",
      "Diff stats — min: -10.3302, max: 12.6598, mean: 0.2003, std: 1.5063\n",
      "\n",
      "Step 1087 — Test metrics:\n",
      "  precision@10: 0.000607822\n",
      "  recall@10: 0.000608556\n",
      "  ndcg@10: 0.000584666\n",
      "  map@10: 0.000163630\n",
      "Epoch 99 completed, Train Loss: 0.8162\n",
      "Epoch 100, Step 1, LR: 0.000080, Current Loss: 0.8159, Avg Loss: 0.8159\n",
      "Diff stats — min: -8.5205, max: 11.1796, mean: 0.2084, std: 1.4940\n",
      "\n",
      "Step 1089 — Test metrics:\n",
      "  precision@10: 0.000607822\n",
      "  recall@10: 0.000608556\n",
      "  ndcg@10: 0.000582335\n",
      "  map@10: 0.000162304\n",
      "Epoch 100, Step 10, LR: 0.000080, Current Loss: 0.8062, Avg Loss: 0.8110\n",
      "Diff stats — min: -10.1389, max: 15.7796, mean: 0.2308, std: 1.4995\n",
      "\n",
      "Step 1098 — Test metrics:\n",
      "  precision@10: 0.000601216\n",
      "  recall@10: 0.000601950\n",
      "  ndcg@10: 0.000575247\n",
      "  map@10: 0.000160164\n",
      "Epoch 100 completed, Train Loss: 0.8113\n"
     ]
    }
   ],
   "source": [
    "edge_type = hyperparameters['train_edge_type']\n",
    "num_epochs = hyperparameters['train_num_epochs']\n",
    "lr = hyperparameters['train_lr']\n",
    "batch_size = hyperparameters['train_batch_size']\n",
    "print_every = hyperparameters['train_print_every']\n",
    "test_every = hyperparameters['train_test_every']\n",
    "top_k = hyperparameters['test_topk']\n",
    "test_batch_size = hyperparameters['test_batch_size']\n",
    "model = train_model(model,\n",
    "                    data,\n",
    "                    edge_type=edge_type,\n",
    "                    num_epochs=num_epochs,\n",
    "                    lr=lr,\n",
    "                    batch_size=batch_size,\n",
    "                    print_every=print_every,\n",
    "                    test_every=test_every,\n",
    "                    top_k=top_k,\n",
    "                    test_batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-24T21:22:10.079811Z",
     "iopub.status.busy": "2025-06-24T21:22:10.079535Z",
     "iopub.status.idle": "2025-06-24T21:45:28.869311Z",
     "shell.execute_reply": "2025-06-24T21:45:28.868715Z",
     "shell.execute_reply.started": "2025-06-24T21:22:10.079791Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training examples: 359463\n",
      "Epoch 101, Step 1, LR: 0.000080, Current Loss: 0.8119, Avg Loss: 0.8119\n",
      "Diff stats — min: -11.2890, max: 12.3440, mean: 0.2172, std: 1.4980\n",
      "\n",
      "Step 1099 — Test metrics:\n",
      "  precision@10: 0.000601216\n",
      "  recall@10: 0.000601950\n",
      "  ndcg@10: 0.000571621\n",
      "  map@10: 0.000158384\n",
      "Epoch 101, Step 10, LR: 0.000080, Current Loss: 0.8067, Avg Loss: 0.8087\n",
      "Diff stats — min: -9.3998, max: 12.5838, mean: 0.2213, std: 1.4834\n",
      "\n",
      "Step 1108 — Test metrics:\n",
      "  precision@10: 0.000588002\n",
      "  recall@10: 0.000588736\n",
      "  ndcg@10: 0.000563141\n",
      "  map@10: 0.000156840\n",
      "Epoch 101 completed, Train Loss: 0.8085\n",
      "Epoch 102, Step 1, LR: 0.000080, Current Loss: 0.8116, Avg Loss: 0.8116\n",
      "Diff stats — min: -11.5500, max: 12.2888, mean: 0.2156, std: 1.4992\n",
      "\n",
      "Step 1110 — Test metrics:\n",
      "  precision@10: 0.000601216\n",
      "  recall@10: 0.000601950\n",
      "  ndcg@10: 0.000572786\n",
      "  map@10: 0.000158704\n",
      "Epoch 102, Step 10, LR: 0.000080, Current Loss: 0.8044, Avg Loss: 0.8047\n",
      "Diff stats — min: -7.9543, max: 11.3144, mean: 0.2130, std: 1.4556\n",
      "\n",
      "Step 1119 — Test metrics:\n",
      "  precision@10: 0.000614429\n",
      "  recall@10: 0.000615163\n",
      "  ndcg@10: 0.000592508\n",
      "  map@10: 0.000166063\n",
      "Epoch 102 completed, Train Loss: 0.8047\n",
      "Epoch 103, Step 1, LR: 0.000080, Current Loss: 0.8054, Avg Loss: 0.8054\n",
      "Diff stats — min: -9.3923, max: 13.0548, mean: 0.2088, std: 1.4545\n",
      "\n",
      "Step 1121 — Test metrics:\n",
      "  precision@10: 0.000607822\n",
      "  recall@10: 0.000608556\n",
      "  ndcg@10: 0.000588825\n",
      "  map@10: 0.000165652\n",
      "Epoch 103, Step 10, LR: 0.000080, Current Loss: 0.7977, Avg Loss: 0.8005\n",
      "Diff stats — min: -9.8849, max: 11.0052, mean: 0.2184, std: 1.4420\n",
      "\n",
      "Step 1130 — Test metrics:\n",
      "  precision@10: 0.000627643\n",
      "  recall@10: 0.000629111\n",
      "  ndcg@10: 0.000592894\n",
      "  map@10: 0.000163051\n",
      "Epoch 103 completed, Train Loss: 0.8005\n",
      "Epoch 104, Step 1, LR: 0.000080, Current Loss: 0.8026, Avg Loss: 0.8026\n",
      "Diff stats — min: -8.6964, max: 10.0031, mean: 0.2088, std: 1.4395\n",
      "\n",
      "Step 1132 — Test metrics:\n",
      "  precision@10: 0.000621036\n",
      "  recall@10: 0.000622504\n",
      "  ndcg@10: 0.000581897\n",
      "  map@10: 0.000158361\n",
      "Epoch 104, Step 10, LR: 0.000080, Current Loss: 0.7936, Avg Loss: 0.7954\n",
      "Diff stats — min: -10.3969, max: 11.8046, mean: 0.2186, std: 1.4269\n",
      "\n",
      "Step 1141 — Test metrics:\n",
      "  precision@10: 0.000614429\n",
      "  recall@10: 0.000615897\n",
      "  ndcg@10: 0.000580894\n",
      "  map@10: 0.000158973\n",
      "Epoch 104 completed, Train Loss: 0.7947\n",
      "Epoch 105, Step 1, LR: 0.000080, Current Loss: 0.7858, Avg Loss: 0.7858\n",
      "Diff stats — min: -7.7661, max: 10.8213, mean: 0.2342, std: 1.4201\n",
      "\n",
      "Step 1143 — Test metrics:\n",
      "  precision@10: 0.000614429\n",
      "  recall@10: 0.000615897\n",
      "  ndcg@10: 0.000581135\n",
      "  map@10: 0.000159110\n",
      "Epoch 105, Step 10, LR: 0.000080, Current Loss: 0.7847, Avg Loss: 0.7887\n",
      "Diff stats — min: -10.0997, max: 10.2348, mean: 0.2276, std: 1.4062\n",
      "\n",
      "Step 1152 — Test metrics:\n",
      "  precision@10: 0.000621036\n",
      "  recall@10: 0.000622504\n",
      "  ndcg@10: 0.000595883\n",
      "  map@10: 0.000165979\n",
      "Epoch 105 completed, Train Loss: 0.7899\n",
      "Epoch 106, Step 1, LR: 0.000080, Current Loss: 0.7872, Avg Loss: 0.7872\n",
      "Diff stats — min: -11.4947, max: 10.2606, mean: 0.2257, std: 1.4095\n",
      "\n",
      "Step 1154 — Test metrics:\n",
      "  precision@10: 0.000621036\n",
      "  recall@10: 0.000622504\n",
      "  ndcg@10: 0.000597079\n",
      "  map@10: 0.000166548\n",
      "Epoch 106, Step 10, LR: 0.000080, Current Loss: 0.7918, Avg Loss: 0.7871\n",
      "Diff stats — min: -12.1248, max: 12.7905, mean: 0.2126, std: 1.4081\n",
      "\n",
      "Step 1163 — Test metrics:\n",
      "  precision@10: 0.000627643\n",
      "  recall@10: 0.000629111\n",
      "  ndcg@10: 0.000599284\n",
      "  map@10: 0.000166069\n",
      "Epoch 106 completed, Train Loss: 0.7866\n",
      "Epoch 107, Step 1, LR: 0.000080, Current Loss: 0.7835, Avg Loss: 0.7835\n",
      "Diff stats — min: -10.0318, max: 11.6051, mean: 0.2240, std: 1.3949\n",
      "\n",
      "Step 1165 — Test metrics:\n",
      "  precision@10: 0.000614429\n",
      "  recall@10: 0.000615897\n",
      "  ndcg@10: 0.000584715\n",
      "  map@10: 0.000161040\n",
      "Epoch 107, Step 10, LR: 0.000080, Current Loss: 0.7740, Avg Loss: 0.7817\n",
      "Diff stats — min: -9.7313, max: 11.3824, mean: 0.2412, std: 1.3860\n",
      "\n",
      "Step 1174 — Test metrics:\n",
      "  precision@10: 0.000601216\n",
      "  recall@10: 0.000602684\n",
      "  ndcg@10: 0.000575906\n",
      "  map@10: 0.000159296\n",
      "Epoch 107 completed, Train Loss: 0.7811\n",
      "Epoch 108, Step 1, LR: 0.000080, Current Loss: 0.7841, Avg Loss: 0.7841\n",
      "Diff stats — min: -8.5486, max: 9.5955, mean: 0.2137, std: 1.3755\n",
      "\n",
      "Step 1176 — Test metrics:\n",
      "  precision@10: 0.000594609\n",
      "  recall@10: 0.000596077\n",
      "  ndcg@10: 0.000570612\n",
      "  map@10: 0.000158057\n",
      "Epoch 108, Step 10, LR: 0.000080, Current Loss: 0.7728, Avg Loss: 0.7788\n",
      "Diff stats — min: -9.6316, max: 9.5553, mean: 0.2345, std: 1.3644\n",
      "\n",
      "Step 1185 — Test metrics:\n",
      "  precision@10: 0.000601216\n",
      "  recall@10: 0.000602684\n",
      "  ndcg@10: 0.000572181\n",
      "  map@10: 0.000157560\n",
      "Epoch 108 completed, Train Loss: 0.7783\n",
      "Epoch 109, Step 1, LR: 0.000080, Current Loss: 0.7683, Avg Loss: 0.7683\n",
      "Diff stats — min: -12.5166, max: 14.1896, mean: 0.2340, std: 1.3496\n",
      "\n",
      "Step 1187 — Test metrics:\n",
      "  precision@10: 0.000614429\n",
      "  recall@10: 0.000615897\n",
      "  ndcg@10: 0.000581291\n",
      "  map@10: 0.000159259\n",
      "Epoch 109, Step 10, LR: 0.000080, Current Loss: 0.7715, Avg Loss: 0.7730\n",
      "Diff stats — min: -7.9524, max: 11.1795, mean: 0.2299, std: 1.3516\n",
      "\n",
      "Step 1196 — Test metrics:\n",
      "  precision@10: 0.000607822\n",
      "  recall@10: 0.000609291\n",
      "  ndcg@10: 0.000581071\n",
      "  map@10: 0.000160667\n",
      "Epoch 109 completed, Train Loss: 0.7735\n",
      "Epoch 110, Step 1, LR: 0.000080, Current Loss: 0.7721, Avg Loss: 0.7721\n",
      "Diff stats — min: -8.7787, max: 8.9967, mean: 0.2311, std: 1.3580\n",
      "\n",
      "Step 1198 — Test metrics:\n",
      "  precision@10: 0.000614429\n",
      "  recall@10: 0.000615897\n",
      "  ndcg@10: 0.000594141\n",
      "  map@10: 0.000166479\n",
      "Epoch 110, Step 10, LR: 0.000080, Current Loss: 0.7725, Avg Loss: 0.7696\n",
      "Diff stats — min: -7.3882, max: 9.9544, mean: 0.2179, std: 1.3317\n",
      "\n",
      "Step 1207 — Test metrics:\n",
      "  precision@10: 0.000614429\n",
      "  recall@10: 0.000615897\n",
      "  ndcg@10: 0.000596708\n",
      "  map@10: 0.000167714\n",
      "Epoch 110 completed, Train Loss: 0.7693\n",
      "Epoch 111, Step 1, LR: 0.000080, Current Loss: 0.7641, Avg Loss: 0.7641\n",
      "Diff stats — min: -10.9950, max: 10.7163, mean: 0.2398, std: 1.3438\n",
      "\n",
      "Step 1209 — Test metrics:\n",
      "  precision@10: 0.000627643\n",
      "  recall@10: 0.000629111\n",
      "  ndcg@10: 0.000606717\n",
      "  map@10: 0.000169843\n",
      "Epoch 111, Step 10, LR: 0.000080, Current Loss: 0.7652, Avg Loss: 0.7681\n",
      "Diff stats — min: -6.6999, max: 8.5855, mean: 0.2276, std: 1.3196\n",
      "\n",
      "Step 1218 — Test metrics:\n",
      "  precision@10: 0.000640856\n",
      "  recall@10: 0.000642324\n",
      "  ndcg@10: 0.000607671\n",
      "  map@10: 0.000166631\n",
      "Epoch 111 completed, Train Loss: 0.7679\n",
      "Epoch 112, Step 1, LR: 0.000080, Current Loss: 0.7650, Avg Loss: 0.7650\n",
      "Diff stats — min: -12.1317, max: 9.2479, mean: 0.2218, std: 1.3108\n",
      "\n",
      "Step 1220 — Test metrics:\n",
      "  precision@10: 0.000640856\n",
      "  recall@10: 0.000642324\n",
      "  ndcg@10: 0.000613563\n",
      "  map@10: 0.000169882\n",
      "Epoch 112, Step 10, LR: 0.000080, Current Loss: 0.7621, Avg Loss: 0.7619\n",
      "Diff stats — min: -11.1260, max: 10.3901, mean: 0.2258, std: 1.3047\n",
      "\n",
      "Step 1229 — Test metrics:\n",
      "  precision@10: 0.000647463\n",
      "  recall@10: 0.000648931\n",
      "  ndcg@10: 0.000608848\n",
      "  map@10: 0.000165779\n",
      "Epoch 112 completed, Train Loss: 0.7624\n",
      "Epoch 113, Step 1, LR: 0.000080, Current Loss: 0.7625, Avg Loss: 0.7625\n",
      "Diff stats — min: -7.8059, max: 8.8171, mean: 0.2264, std: 1.3055\n",
      "\n",
      "Step 1231 — Test metrics:\n",
      "  precision@10: 0.000640856\n",
      "  recall@10: 0.000642324\n",
      "  ndcg@10: 0.000605505\n",
      "  map@10: 0.000165651\n",
      "Epoch 113, Step 10, LR: 0.000080, Current Loss: 0.7647, Avg Loss: 0.7607\n",
      "Diff stats — min: -8.6350, max: 11.7426, mean: 0.2218, std: 1.3093\n",
      "\n",
      "Step 1240 — Test metrics:\n",
      "  precision@10: 0.000621036\n",
      "  recall@10: 0.000622504\n",
      "  ndcg@10: 0.000605618\n",
      "  map@10: 0.000171095\n",
      "Epoch 113 completed, Train Loss: 0.7602\n",
      "Epoch 114, Step 1, LR: 0.000080, Current Loss: 0.7559, Avg Loss: 0.7559\n",
      "Diff stats — min: -10.6113, max: 8.2833, mean: 0.2346, std: 1.2950\n",
      "\n",
      "Step 1242 — Test metrics:\n",
      "  precision@10: 0.000621036\n",
      "  recall@10: 0.000622504\n",
      "  ndcg@10: 0.000603540\n",
      "  map@10: 0.000169921\n",
      "Epoch 114, Step 10, LR: 0.000080, Current Loss: 0.7533, Avg Loss: 0.7572\n",
      "Diff stats — min: -8.4192, max: 9.6822, mean: 0.2375, std: 1.2900\n",
      "\n",
      "Step 1251 — Test metrics:\n",
      "  precision@10: 0.000647463\n",
      "  recall@10: 0.000648931\n",
      "  ndcg@10: 0.000635687\n",
      "  map@10: 0.000181334\n",
      "Epoch 114 completed, Train Loss: 0.7568\n",
      "Epoch 115, Step 1, LR: 0.000080, Current Loss: 0.7536, Avg Loss: 0.7536\n",
      "Diff stats — min: -11.1862, max: 11.3251, mean: 0.2331, std: 1.2836\n",
      "\n",
      "Step 1253 — Test metrics:\n",
      "  precision@10: 0.000660677\n",
      "  recall@10: 0.000662145\n",
      "  ndcg@10: 0.000645875\n",
      "  map@10: 0.000183691\n",
      "Epoch 115, Step 10, LR: 0.000080, Current Loss: 0.7537, Avg Loss: 0.7543\n",
      "Diff stats — min: -8.7943, max: 10.7790, mean: 0.2244, std: 1.2635\n",
      "\n",
      "Step 1262 — Test metrics:\n",
      "  precision@10: 0.000660677\n",
      "  recall@10: 0.000662145\n",
      "  ndcg@10: 0.000639064\n",
      "  map@10: 0.000179960\n",
      "Epoch 115 completed, Train Loss: 0.7540\n",
      "Epoch 116, Step 1, LR: 0.000080, Current Loss: 0.7473, Avg Loss: 0.7473\n",
      "Diff stats — min: -11.5478, max: 10.9034, mean: 0.2407, std: 1.2700\n",
      "\n",
      "Step 1264 — Test metrics:\n",
      "  precision@10: 0.000647463\n",
      "  recall@10: 0.000648931\n",
      "  ndcg@10: 0.000626249\n",
      "  map@10: 0.000176106\n",
      "Epoch 116, Step 10, LR: 0.000080, Current Loss: 0.7501, Avg Loss: 0.7504\n",
      "Diff stats — min: -8.8616, max: 13.2513, mean: 0.2349, std: 1.2718\n",
      "\n",
      "Step 1273 — Test metrics:\n",
      "  precision@10: 0.000640856\n",
      "  recall@10: 0.000642324\n",
      "  ndcg@10: 0.000618048\n",
      "  map@10: 0.000173276\n",
      "Epoch 116 completed, Train Loss: 0.7505\n",
      "Epoch 117, Step 1, LR: 0.000080, Current Loss: 0.7479, Avg Loss: 0.7479\n",
      "Diff stats — min: -7.7643, max: 11.6533, mean: 0.2354, std: 1.2661\n",
      "\n",
      "Step 1275 — Test metrics:\n",
      "  precision@10: 0.000627643\n",
      "  recall@10: 0.000629111\n",
      "  ndcg@10: 0.000609072\n",
      "  map@10: 0.000171670\n",
      "Epoch 117, Step 10, LR: 0.000080, Current Loss: 0.7473, Avg Loss: 0.7473\n",
      "Diff stats — min: -9.2412, max: 9.9941, mean: 0.2305, std: 1.2505\n",
      "\n",
      "Step 1284 — Test metrics:\n",
      "  precision@10: 0.000647463\n",
      "  recall@10: 0.000648931\n",
      "  ndcg@10: 0.000630763\n",
      "  map@10: 0.000179381\n",
      "Epoch 117 completed, Train Loss: 0.7469\n",
      "Epoch 118, Step 1, LR: 0.000080, Current Loss: 0.7442, Avg Loss: 0.7442\n",
      "Diff stats — min: -8.2336, max: 9.8037, mean: 0.2374, std: 1.2485\n",
      "\n",
      "Step 1286 — Test metrics:\n",
      "  precision@10: 0.000647463\n",
      "  recall@10: 0.000648931\n",
      "  ndcg@10: 0.000630931\n",
      "  map@10: 0.000179446\n",
      "Epoch 118, Step 10, LR: 0.000080, Current Loss: 0.7453, Avg Loss: 0.7443\n",
      "Diff stats — min: -13.1029, max: 9.4927, mean: 0.2323, std: 1.2446\n",
      "\n",
      "Step 1295 — Test metrics:\n",
      "  precision@10: 0.000627643\n",
      "  recall@10: 0.000629111\n",
      "  ndcg@10: 0.000623488\n",
      "  map@10: 0.000179847\n",
      "Epoch 118 completed, Train Loss: 0.7446\n",
      "Epoch 119, Step 1, LR: 0.000080, Current Loss: 0.7428, Avg Loss: 0.7428\n",
      "Diff stats — min: -6.6665, max: 9.0717, mean: 0.2360, std: 1.2376\n",
      "\n",
      "Step 1297 — Test metrics:\n",
      "  precision@10: 0.000627643\n",
      "  recall@10: 0.000629111\n",
      "  ndcg@10: 0.000622641\n",
      "  map@10: 0.000179425\n",
      "Epoch 119, Step 10, LR: 0.000080, Current Loss: 0.7422, Avg Loss: 0.7415\n",
      "Diff stats — min: -8.9237, max: 10.0128, mean: 0.2269, std: 1.2174\n",
      "\n",
      "Step 1306 — Test metrics:\n",
      "  precision@10: 0.000634249\n",
      "  recall@10: 0.000635718\n",
      "  ndcg@10: 0.000626829\n",
      "  map@10: 0.000180435\n",
      "Epoch 119 completed, Train Loss: 0.7411\n",
      "Epoch 120, Step 1, LR: 0.000080, Current Loss: 0.7407, Avg Loss: 0.7407\n",
      "Diff stats — min: -7.9196, max: 10.3802, mean: 0.2350, std: 1.2297\n",
      "\n",
      "Step 1308 — Test metrics:\n",
      "  precision@10: 0.000654070\n",
      "  recall@10: 0.000655538\n",
      "  ndcg@10: 0.000645869\n",
      "  map@10: 0.000186346\n",
      "Epoch 120, Step 10, LR: 0.000080, Current Loss: 0.7401, Avg Loss: 0.7381\n",
      "Diff stats — min: -9.7378, max: 9.7499, mean: 0.2325, std: 1.2218\n",
      "\n",
      "Step 1317 — Test metrics:\n",
      "  precision@10: 0.000654070\n",
      "  recall@10: 0.000655538\n",
      "  ndcg@10: 0.000656199\n",
      "  map@10: 0.000192735\n",
      "Epoch 120 completed, Train Loss: 0.7373\n",
      "Epoch 121, Step 1, LR: 0.000080, Current Loss: 0.7386, Avg Loss: 0.7386\n",
      "Diff stats — min: -6.5365, max: 8.7472, mean: 0.2306, std: 1.2079\n",
      "\n",
      "Step 1319 — Test metrics:\n",
      "  precision@10: 0.000660677\n",
      "  recall@10: 0.000662145\n",
      "  ndcg@10: 0.000660402\n",
      "  map@10: 0.000193396\n",
      "Epoch 121, Step 10, LR: 0.000080, Current Loss: 0.7384, Avg Loss: 0.7349\n",
      "Diff stats — min: -8.9824, max: 11.1717, mean: 0.2327, std: 1.2149\n",
      "\n",
      "Step 1328 — Test metrics:\n",
      "  precision@10: 0.000647463\n",
      "  recall@10: 0.000648931\n",
      "  ndcg@10: 0.000640392\n",
      "  map@10: 0.000185224\n",
      "Epoch 121 completed, Train Loss: 0.7352\n",
      "Epoch 122, Step 1, LR: 0.000080, Current Loss: 0.7336, Avg Loss: 0.7336\n",
      "Diff stats — min: -11.2323, max: 9.6635, mean: 0.2352, std: 1.1980\n",
      "\n",
      "Step 1330 — Test metrics:\n",
      "  precision@10: 0.000647463\n",
      "  recall@10: 0.000648931\n",
      "  ndcg@10: 0.000633162\n",
      "  map@10: 0.000180948\n",
      "Epoch 122, Step 10, LR: 0.000080, Current Loss: 0.7263, Avg Loss: 0.7319\n",
      "Diff stats — min: -9.7140, max: 9.7594, mean: 0.2536, std: 1.2038\n",
      "\n",
      "Step 1339 — Test metrics:\n",
      "  precision@10: 0.000640856\n",
      "  recall@10: 0.000642324\n",
      "  ndcg@10: 0.000643105\n",
      "  map@10: 0.000188498\n",
      "Epoch 122 completed, Train Loss: 0.7327\n",
      "Epoch 123, Step 1, LR: 0.000080, Current Loss: 0.7284, Avg Loss: 0.7284\n",
      "Diff stats — min: -8.0904, max: 8.1524, mean: 0.2466, std: 1.1974\n",
      "\n",
      "Step 1341 — Test metrics:\n",
      "  precision@10: 0.000654070\n",
      "  recall@10: 0.000655538\n",
      "  ndcg@10: 0.000656144\n",
      "  map@10: 0.000192352\n",
      "Epoch 123, Step 10, LR: 0.000080, Current Loss: 0.7276, Avg Loss: 0.7306\n",
      "Diff stats — min: -10.1406, max: 8.9405, mean: 0.2440, std: 1.1870\n",
      "\n",
      "Step 1350 — Test metrics:\n",
      "  precision@10: 0.000634249\n",
      "  recall@10: 0.000635718\n",
      "  ndcg@10: 0.000642668\n",
      "  map@10: 0.000189914\n",
      "Epoch 123 completed, Train Loss: 0.7310\n",
      "Epoch 124, Step 1, LR: 0.000080, Current Loss: 0.7263, Avg Loss: 0.7263\n",
      "Diff stats — min: -8.2212, max: 7.8749, mean: 0.2447, std: 1.1842\n",
      "\n",
      "Step 1352 — Test metrics:\n",
      "  precision@10: 0.000627643\n",
      "  recall@10: 0.000629111\n",
      "  ndcg@10: 0.000638844\n",
      "  map@10: 0.000189382\n",
      "Epoch 124, Step 10, LR: 0.000080, Current Loss: 0.7245, Avg Loss: 0.7267\n",
      "Diff stats — min: -7.1381, max: 11.0841, mean: 0.2451, std: 1.1781\n",
      "\n",
      "Step 1361 — Test metrics:\n",
      "  precision@10: 0.000667283\n",
      "  recall@10: 0.000668751\n",
      "  ndcg@10: 0.000659225\n",
      "  map@10: 0.000190580\n",
      "Epoch 124 completed, Train Loss: 0.7266\n",
      "Epoch 125, Step 1, LR: 0.000080, Current Loss: 0.7245, Avg Loss: 0.7245\n",
      "Diff stats — min: -8.0569, max: 10.6811, mean: 0.2431, std: 1.1730\n",
      "\n",
      "Step 1363 — Test metrics:\n",
      "  precision@10: 0.000660677\n",
      "  recall@10: 0.000662145\n",
      "  ndcg@10: 0.000641951\n",
      "  map@10: 0.000182020\n",
      "Epoch 125, Step 10, LR: 0.000080, Current Loss: 0.7248, Avg Loss: 0.7267\n",
      "Diff stats — min: -7.1603, max: 8.0188, mean: 0.2436, std: 1.1775\n",
      "\n",
      "Step 1372 — Test metrics:\n",
      "  precision@10: 0.000660677\n",
      "  recall@10: 0.000662145\n",
      "  ndcg@10: 0.000651104\n",
      "  map@10: 0.000187587\n",
      "Epoch 125 completed, Train Loss: 0.7264\n",
      "Epoch 126, Step 1, LR: 0.000080, Current Loss: 0.7187, Avg Loss: 0.7187\n",
      "Diff stats — min: -9.3663, max: 9.9859, mean: 0.2573, std: 1.1781\n",
      "\n",
      "Step 1374 — Test metrics:\n",
      "  precision@10: 0.000654070\n",
      "  recall@10: 0.000655538\n",
      "  ndcg@10: 0.000643533\n",
      "  map@10: 0.000185156\n",
      "Epoch 126, Step 10, LR: 0.000080, Current Loss: 0.7179, Avg Loss: 0.7216\n",
      "Diff stats — min: -7.9350, max: 10.2981, mean: 0.2463, std: 1.1489\n",
      "\n",
      "Step 1383 — Test metrics:\n",
      "  precision@10: 0.000640856\n",
      "  recall@10: 0.000642324\n",
      "  ndcg@10: 0.000632977\n",
      "  map@10: 0.000182459\n",
      "Epoch 126 completed, Train Loss: 0.7218\n",
      "Epoch 127, Step 1, LR: 0.000080, Current Loss: 0.7169, Avg Loss: 0.7169\n",
      "Diff stats — min: -7.2011, max: 10.4294, mean: 0.2504, std: 1.1528\n",
      "\n",
      "Step 1385 — Test metrics:\n",
      "  precision@10: 0.000634249\n",
      "  recall@10: 0.000635718\n",
      "  ndcg@10: 0.000628829\n",
      "  map@10: 0.000181837\n",
      "Epoch 127, Step 10, LR: 0.000080, Current Loss: 0.7175, Avg Loss: 0.7198\n",
      "Diff stats — min: -9.9487, max: 10.4137, mean: 0.2464, std: 1.1483\n",
      "\n",
      "Step 1394 — Test metrics:\n",
      "  precision@10: 0.000654070\n",
      "  recall@10: 0.000655538\n",
      "  ndcg@10: 0.000642693\n",
      "  map@10: 0.000184480\n",
      "Epoch 127 completed, Train Loss: 0.7197\n",
      "Epoch 128, Step 1, LR: 0.000080, Current Loss: 0.7199, Avg Loss: 0.7199\n",
      "Diff stats — min: -7.7405, max: 9.0320, mean: 0.2442, std: 1.1544\n",
      "\n",
      "Step 1396 — Test metrics:\n",
      "  precision@10: 0.000667283\n",
      "  recall@10: 0.000668751\n",
      "  ndcg@10: 0.000655975\n",
      "  map@10: 0.000188863\n",
      "Epoch 128, Step 10, LR: 0.000080, Current Loss: 0.7186, Avg Loss: 0.7175\n",
      "Diff stats — min: -9.2460, max: 8.9043, mean: 0.2408, std: 1.1408\n",
      "\n",
      "Step 1405 — Test metrics:\n",
      "  precision@10: 0.000680497\n",
      "  recall@10: 0.000681965\n",
      "  ndcg@10: 0.000671779\n",
      "  map@10: 0.000194079\n",
      "Epoch 128 completed, Train Loss: 0.7178\n",
      "Epoch 129, Step 1, LR: 0.000080, Current Loss: 0.7158, Avg Loss: 0.7158\n",
      "Diff stats — min: -8.5160, max: 10.1759, mean: 0.2450, std: 1.1371\n",
      "\n",
      "Step 1407 — Test metrics:\n",
      "  precision@10: 0.000693710\n",
      "  recall@10: 0.000695179\n",
      "  ndcg@10: 0.000679051\n",
      "  map@10: 0.000194876\n",
      "Epoch 129, Step 10, LR: 0.000080, Current Loss: 0.7115, Avg Loss: 0.7153\n",
      "Diff stats — min: -6.6802, max: 7.7772, mean: 0.2522, std: 1.1287\n",
      "\n",
      "Step 1416 — Test metrics:\n",
      "  precision@10: 0.000693710\n",
      "  recall@10: 0.000695179\n",
      "  ndcg@10: 0.000682834\n",
      "  map@10: 0.000197249\n",
      "Epoch 129 completed, Train Loss: 0.7151\n",
      "Epoch 130, Step 1, LR: 0.000080, Current Loss: 0.7178, Avg Loss: 0.7178\n",
      "Diff stats — min: -9.0498, max: 8.2416, mean: 0.2380, std: 1.1291\n",
      "\n",
      "Step 1418 — Test metrics:\n",
      "  precision@10: 0.000687104\n",
      "  recall@10: 0.000688572\n",
      "  ndcg@10: 0.000685754\n",
      "  map@10: 0.000200875\n",
      "Epoch 130, Step 10, LR: 0.000080, Current Loss: 0.7159, Avg Loss: 0.7148\n",
      "Diff stats — min: -9.7867, max: 11.6522, mean: 0.2405, std: 1.1310\n",
      "\n",
      "Step 1427 — Test metrics:\n",
      "  precision@10: 0.000667283\n",
      "  recall@10: 0.000668751\n",
      "  ndcg@10: 0.000682636\n",
      "  map@10: 0.000204542\n",
      "Epoch 130 completed, Train Loss: 0.7147\n",
      "Epoch 131, Step 1, LR: 0.000080, Current Loss: 0.7094, Avg Loss: 0.7094\n",
      "Diff stats — min: -9.0847, max: 8.7770, mean: 0.2491, std: 1.1148\n",
      "\n",
      "Step 1429 — Test metrics:\n",
      "  precision@10: 0.000673890\n",
      "  recall@10: 0.000675358\n",
      "  ndcg@10: 0.000680633\n",
      "  map@10: 0.000201404\n",
      "Epoch 131, Step 10, LR: 0.000080, Current Loss: 0.7081, Avg Loss: 0.7105\n",
      "Diff stats — min: -6.7901, max: 9.9332, mean: 0.2528, std: 1.1149\n",
      "\n",
      "Step 1438 — Test metrics:\n",
      "  precision@10: 0.000673890\n",
      "  recall@10: 0.000675358\n",
      "  ndcg@10: 0.000675553\n",
      "  map@10: 0.000198633\n",
      "Epoch 131 completed, Train Loss: 0.7108\n",
      "Epoch 132, Step 1, LR: 0.000080, Current Loss: 0.7082, Avg Loss: 0.7082\n",
      "Diff stats — min: -6.5915, max: 13.0399, mean: 0.2496, std: 1.1136\n",
      "\n",
      "Step 1440 — Test metrics:\n",
      "  precision@10: 0.000667283\n",
      "  recall@10: 0.000668751\n",
      "  ndcg@10: 0.000665132\n",
      "  map@10: 0.000194158\n",
      "Epoch 132, Step 10, LR: 0.000080, Current Loss: 0.7125, Avg Loss: 0.7097\n",
      "Diff stats — min: -10.8317, max: 9.2444, mean: 0.2400, std: 1.1125\n",
      "\n",
      "Step 1449 — Test metrics:\n",
      "  precision@10: 0.000680497\n",
      "  recall@10: 0.000681965\n",
      "  ndcg@10: 0.000668111\n",
      "  map@10: 0.000192190\n",
      "Epoch 132 completed, Train Loss: 0.7097\n",
      "Epoch 133, Step 1, LR: 0.000080, Current Loss: 0.7046, Avg Loss: 0.7046\n",
      "Diff stats — min: -8.1259, max: 8.3898, mean: 0.2579, std: 1.1130\n",
      "\n",
      "Step 1451 — Test metrics:\n",
      "  precision@10: 0.000673890\n",
      "  recall@10: 0.000675358\n",
      "  ndcg@10: 0.000663344\n",
      "  map@10: 0.000191239\n",
      "Epoch 133, Step 10, LR: 0.000080, Current Loss: 0.7113, Avg Loss: 0.7078\n",
      "Diff stats — min: -8.8541, max: 8.1805, mean: 0.2361, std: 1.0961\n",
      "\n",
      "Step 1460 — Test metrics:\n",
      "  precision@10: 0.000733351\n",
      "  recall@10: 0.000734819\n",
      "  ndcg@10: 0.000715345\n",
      "  map@10: 0.000205569\n",
      "Epoch 133 completed, Train Loss: 0.7078\n",
      "Epoch 134, Step 1, LR: 0.000080, Current Loss: 0.7105, Avg Loss: 0.7105\n",
      "Diff stats — min: -9.4382, max: 10.9655, mean: 0.2402, std: 1.1033\n",
      "\n",
      "Step 1462 — Test metrics:\n",
      "  precision@10: 0.000733351\n",
      "  recall@10: 0.000734819\n",
      "  ndcg@10: 0.000721898\n",
      "  map@10: 0.000209470\n",
      "Epoch 134, Step 10, LR: 0.000080, Current Loss: 0.7022, Avg Loss: 0.7057\n",
      "Diff stats — min: -6.4295, max: 9.2216, mean: 0.2558, std: 1.0955\n",
      "\n",
      "Step 1471 — Test metrics:\n",
      "  precision@10: 0.000726744\n",
      "  recall@10: 0.000728212\n",
      "  ndcg@10: 0.000728862\n",
      "  map@10: 0.000215352\n",
      "Epoch 134 completed, Train Loss: 0.7056\n",
      "Epoch 135, Step 1, LR: 0.000080, Current Loss: 0.6991, Avg Loss: 0.6991\n",
      "Diff stats — min: -8.7240, max: 8.9173, mean: 0.2557, std: 1.0813\n",
      "\n",
      "Step 1473 — Test metrics:\n",
      "  precision@10: 0.000720137\n",
      "  recall@10: 0.000721606\n",
      "  ndcg@10: 0.000717989\n",
      "  map@10: 0.000210677\n",
      "Epoch 135, Step 10, LR: 0.000080, Current Loss: 0.7013, Avg Loss: 0.7028\n",
      "Diff stats — min: -10.5935, max: 8.3528, mean: 0.2553, std: 1.0915\n",
      "\n",
      "Step 1482 — Test metrics:\n",
      "  precision@10: 0.000700317\n",
      "  recall@10: 0.000701785\n",
      "  ndcg@10: 0.000706464\n",
      "  map@10: 0.000209315\n",
      "Epoch 135 completed, Train Loss: 0.7031\n",
      "Epoch 136, Step 1, LR: 0.000080, Current Loss: 0.7022, Avg Loss: 0.7022\n",
      "Diff stats — min: -7.8084, max: 9.1460, mean: 0.2502, std: 1.0827\n",
      "\n",
      "Step 1484 — Test metrics:\n",
      "  precision@10: 0.000700317\n",
      "  recall@10: 0.000701785\n",
      "  ndcg@10: 0.000705653\n",
      "  map@10: 0.000208911\n",
      "Epoch 136, Step 10, LR: 0.000080, Current Loss: 0.6990, Avg Loss: 0.7015\n",
      "Diff stats — min: -7.7689, max: 7.0962, mean: 0.2515, std: 1.0705\n",
      "\n",
      "Step 1493 — Test metrics:\n",
      "  precision@10: 0.000706924\n",
      "  recall@10: 0.000708392\n",
      "  ndcg@10: 0.000721574\n",
      "  map@10: 0.000216892\n",
      "Epoch 136 completed, Train Loss: 0.7017\n",
      "Epoch 137, Step 1, LR: 0.000080, Current Loss: 0.7001, Avg Loss: 0.7001\n",
      "Diff stats — min: -6.1491, max: 7.3309, mean: 0.2467, std: 1.0653\n",
      "\n",
      "Step 1495 — Test metrics:\n",
      "  precision@10: 0.000706924\n",
      "  recall@10: 0.000708392\n",
      "  ndcg@10: 0.000717103\n",
      "  map@10: 0.000214325\n",
      "Epoch 137, Step 10, LR: 0.000080, Current Loss: 0.6967, Avg Loss: 0.6983\n",
      "Diff stats — min: -8.9642, max: 6.9933, mean: 0.2550, std: 1.0671\n",
      "\n",
      "Step 1504 — Test metrics:\n",
      "  precision@10: 0.000693710\n",
      "  recall@10: 0.000695179\n",
      "  ndcg@10: 0.000700670\n",
      "  map@10: 0.000207784\n",
      "Epoch 137 completed, Train Loss: 0.6985\n",
      "Epoch 138, Step 1, LR: 0.000080, Current Loss: 0.6991, Avg Loss: 0.6991\n",
      "Diff stats — min: -8.6948, max: 7.9608, mean: 0.2498, std: 1.0678\n",
      "\n",
      "Step 1506 — Test metrics:\n",
      "  precision@10: 0.000700317\n",
      "  recall@10: 0.000701785\n",
      "  ndcg@10: 0.000704288\n",
      "  map@10: 0.000208124\n",
      "Epoch 138, Step 10, LR: 0.000080, Current Loss: 0.6980, Avg Loss: 0.6980\n",
      "Diff stats — min: -6.5667, max: 7.6007, mean: 0.2482, std: 1.0573\n",
      "\n",
      "Step 1515 — Test metrics:\n",
      "  precision@10: 0.000739958\n",
      "  recall@10: 0.000741426\n",
      "  ndcg@10: 0.000741355\n",
      "  map@10: 0.000218923\n",
      "Epoch 138 completed, Train Loss: 0.6979\n",
      "Epoch 139, Step 1, LR: 0.000080, Current Loss: 0.6988, Avg Loss: 0.6988\n",
      "Diff stats — min: -7.0729, max: 7.9351, mean: 0.2472, std: 1.0598\n",
      "\n",
      "Step 1517 — Test metrics:\n",
      "  precision@10: 0.000739958\n",
      "  recall@10: 0.000741426\n",
      "  ndcg@10: 0.000743326\n",
      "  map@10: 0.000220019\n",
      "Epoch 139, Step 10, LR: 0.000080, Current Loss: 0.6985, Avg Loss: 0.6962\n",
      "Diff stats — min: -7.0852, max: 7.7462, mean: 0.2437, std: 1.0505\n",
      "\n",
      "Step 1526 — Test metrics:\n",
      "  precision@10: 0.000726744\n",
      "  recall@10: 0.000728212\n",
      "  ndcg@10: 0.000741910\n",
      "  map@10: 0.000222478\n",
      "Epoch 139 completed, Train Loss: 0.6960\n",
      "Epoch 140, Step 1, LR: 0.000080, Current Loss: 0.6948, Avg Loss: 0.6948\n",
      "Diff stats — min: -7.4270, max: 8.2928, mean: 0.2513, std: 1.0507\n",
      "\n",
      "Step 1528 — Test metrics:\n",
      "  precision@10: 0.000733351\n",
      "  recall@10: 0.000734819\n",
      "  ndcg@10: 0.000742089\n",
      "  map@10: 0.000220503\n",
      "Epoch 140, Step 10, LR: 0.000080, Current Loss: 0.6903, Avg Loss: 0.6933\n",
      "Diff stats — min: -9.4999, max: 9.5245, mean: 0.2583, std: 1.0425\n",
      "\n",
      "Step 1537 — Test metrics:\n",
      "  precision@10: 0.000720137\n",
      "  recall@10: 0.000721606\n",
      "  ndcg@10: 0.000743823\n",
      "  map@10: 0.000225642\n",
      "Epoch 140 completed, Train Loss: 0.6933\n",
      "Epoch 141, Step 1, LR: 0.000080, Current Loss: 0.6932, Avg Loss: 0.6932\n",
      "Diff stats — min: -5.8094, max: 7.6025, mean: 0.2511, std: 1.0398\n",
      "\n",
      "Step 1539 — Test metrics:\n",
      "  precision@10: 0.000726744\n",
      "  recall@10: 0.000728212\n",
      "  ndcg@10: 0.000745697\n",
      "  map@10: 0.000224820\n",
      "Epoch 141, Step 10, LR: 0.000080, Current Loss: 0.6902, Avg Loss: 0.6917\n",
      "Diff stats — min: -7.0755, max: 7.7559, mean: 0.2566, std: 1.0391\n",
      "\n",
      "Step 1548 — Test metrics:\n",
      "  precision@10: 0.000733351\n",
      "  recall@10: 0.000734819\n",
      "  ndcg@10: 0.000750851\n",
      "  map@10: 0.000225740\n",
      "Epoch 141 completed, Train Loss: 0.6918\n",
      "Epoch 142, Step 1, LR: 0.000080, Current Loss: 0.6878, Avg Loss: 0.6878\n",
      "Diff stats — min: -9.3132, max: 9.0641, mean: 0.2594, std: 1.0336\n",
      "\n",
      "Step 1550 — Test metrics:\n",
      "  precision@10: 0.000726744\n",
      "  recall@10: 0.000728212\n",
      "  ndcg@10: 0.000745707\n",
      "  map@10: 0.000224657\n",
      "Epoch 142, Step 10, LR: 0.000080, Current Loss: 0.6867, Avg Loss: 0.6902\n",
      "Diff stats — min: -5.7601, max: 7.3451, mean: 0.2586, std: 1.0255\n",
      "\n",
      "Step 1559 — Test metrics:\n",
      "  precision@10: 0.000726744\n",
      "  recall@10: 0.000728212\n",
      "  ndcg@10: 0.000737053\n",
      "  map@10: 0.000219469\n",
      "Epoch 142 completed, Train Loss: 0.6900\n",
      "Epoch 143, Step 1, LR: 0.000080, Current Loss: 0.6872, Avg Loss: 0.6872\n",
      "Diff stats — min: -6.3109, max: 12.6797, mean: 0.2588, std: 1.0298\n",
      "\n",
      "Step 1561 — Test metrics:\n",
      "  precision@10: 0.000726744\n",
      "  recall@10: 0.000728212\n",
      "  ndcg@10: 0.000739318\n",
      "  map@10: 0.000220722\n",
      "Epoch 143, Step 10, LR: 0.000080, Current Loss: 0.6863, Avg Loss: 0.6890\n",
      "Diff stats — min: -6.3713, max: 7.5604, mean: 0.2577, std: 1.0204\n",
      "\n",
      "Step 1570 — Test metrics:\n",
      "  precision@10: 0.000720137\n",
      "  recall@10: 0.000721606\n",
      "  ndcg@10: 0.000731961\n",
      "  map@10: 0.000217822\n",
      "Epoch 143 completed, Train Loss: 0.6889\n",
      "Epoch 144, Step 1, LR: 0.000080, Current Loss: 0.6889, Avg Loss: 0.6889\n",
      "Diff stats — min: -7.3017, max: 6.9017, mean: 0.2515, std: 1.0202\n",
      "\n",
      "Step 1572 — Test metrics:\n",
      "  precision@10: 0.000726744\n",
      "  recall@10: 0.000728212\n",
      "  ndcg@10: 0.000736579\n",
      "  map@10: 0.000218963\n",
      "Epoch 144, Step 10, LR: 0.000080, Current Loss: 0.6848, Avg Loss: 0.6869\n",
      "Diff stats — min: -6.0867, max: 7.5206, mean: 0.2542, std: 1.0060\n",
      "\n",
      "Step 1581 — Test metrics:\n",
      "  precision@10: 0.000753171\n",
      "  recall@10: 0.000754639\n",
      "  ndcg@10: 0.000757124\n",
      "  map@10: 0.000223595\n",
      "Epoch 144 completed, Train Loss: 0.6871\n",
      "Epoch 145, Step 1, LR: 0.000080, Current Loss: 0.6883, Avg Loss: 0.6883\n",
      "Diff stats — min: -7.8381, max: 8.5079, mean: 0.2503, std: 1.0149\n",
      "\n",
      "Step 1583 — Test metrics:\n",
      "  precision@10: 0.000739958\n",
      "  recall@10: 0.000741426\n",
      "  ndcg@10: 0.000747563\n",
      "  map@10: 0.000221668\n",
      "Epoch 145, Step 10, LR: 0.000080, Current Loss: 0.6858, Avg Loss: 0.6856\n",
      "Diff stats — min: -6.4575, max: 7.4554, mean: 0.2525, std: 1.0073\n",
      "\n",
      "Step 1592 — Test metrics:\n",
      "  precision@10: 0.000726744\n",
      "  recall@10: 0.000728212\n",
      "  ndcg@10: 0.000744444\n",
      "  map@10: 0.000223301\n",
      "Epoch 145 completed, Train Loss: 0.6855\n",
      "Epoch 146, Step 1, LR: 0.000080, Current Loss: 0.6843, Avg Loss: 0.6843\n",
      "Diff stats — min: -7.0275, max: 10.2443, mean: 0.2537, std: 1.0028\n",
      "\n",
      "Step 1594 — Test metrics:\n",
      "  precision@10: 0.000726744\n",
      "  recall@10: 0.000728212\n",
      "  ndcg@10: 0.000748897\n",
      "  map@10: 0.000225729\n",
      "Epoch 146, Step 10, LR: 0.000080, Current Loss: 0.6804, Avg Loss: 0.6837\n",
      "Diff stats — min: -5.9979, max: 7.5404, mean: 0.2623, std: 1.0031\n",
      "\n",
      "Step 1603 — Test metrics:\n",
      "  precision@10: 0.000799419\n",
      "  recall@10: 0.000800887\n",
      "  ndcg@10: 0.000813785\n",
      "  map@10: 0.000243607\n",
      "Epoch 146 completed, Train Loss: 0.6838\n",
      "Epoch 147, Step 1, LR: 0.000080, Current Loss: 0.6809, Avg Loss: 0.6809\n",
      "Diff stats — min: -6.5311, max: 9.4122, mean: 0.2593, std: 0.9991\n",
      "\n",
      "Step 1605 — Test metrics:\n",
      "  precision@10: 0.000806025\n",
      "  recall@10: 0.000807494\n",
      "  ndcg@10: 0.000816880\n",
      "  map@10: 0.000243581\n",
      "Epoch 147, Step 10, LR: 0.000080, Current Loss: 0.6807, Avg Loss: 0.6816\n",
      "Diff stats — min: -6.5407, max: 7.7331, mean: 0.2587, std: 0.9953\n",
      "\n",
      "Step 1614 — Test metrics:\n",
      "  precision@10: 0.000779598\n",
      "  recall@10: 0.000781066\n",
      "  ndcg@10: 0.000794584\n",
      "  map@10: 0.000237726\n",
      "Epoch 147 completed, Train Loss: 0.6818\n",
      "Epoch 148, Step 1, LR: 0.000080, Current Loss: 0.6808, Avg Loss: 0.6808\n",
      "Diff stats — min: -5.4927, max: 9.8105, mean: 0.2603, std: 1.0005\n",
      "\n",
      "Step 1616 — Test metrics:\n",
      "  precision@10: 0.000766385\n",
      "  recall@10: 0.000767853\n",
      "  ndcg@10: 0.000785099\n",
      "  map@10: 0.000235862\n",
      "Epoch 148, Step 10, LR: 0.000080, Current Loss: 0.6757, Avg Loss: 0.6805\n",
      "Diff stats — min: -7.1051, max: 7.5474, mean: 0.2655, std: 0.9867\n",
      "\n",
      "Step 1625 — Test metrics:\n",
      "  precision@10: 0.000772992\n",
      "  recall@10: 0.000774460\n",
      "  ndcg@10: 0.000775658\n",
      "  map@10: 0.000228272\n",
      "Epoch 148 completed, Train Loss: 0.6803\n",
      "Epoch 149, Step 1, LR: 0.000080, Current Loss: 0.6811, Avg Loss: 0.6811\n",
      "Diff stats — min: -8.6305, max: 8.1813, mean: 0.2548, std: 0.9901\n",
      "\n",
      "Step 1627 — Test metrics:\n",
      "  precision@10: 0.000759778\n",
      "  recall@10: 0.000761246\n",
      "  ndcg@10: 0.000764916\n",
      "  map@10: 0.000225638\n",
      "Epoch 149, Step 10, LR: 0.000080, Current Loss: 0.6757, Avg Loss: 0.6786\n",
      "Diff stats — min: -7.9852, max: 8.3600, mean: 0.2657, std: 0.9881\n",
      "\n",
      "Step 1636 — Test metrics:\n",
      "  precision@10: 0.000759778\n",
      "  recall@10: 0.000761246\n",
      "  ndcg@10: 0.000783565\n",
      "  map@10: 0.000236368\n",
      "Epoch 149 completed, Train Loss: 0.6787\n",
      "Epoch 150, Step 1, LR: 0.000080, Current Loss: 0.6746, Avg Loss: 0.6746\n",
      "Diff stats — min: -13.6111, max: 7.5672, mean: 0.2641, std: 0.9773\n",
      "\n",
      "Step 1638 — Test metrics:\n",
      "  precision@10: 0.000799419\n",
      "  recall@10: 0.000800887\n",
      "  ndcg@10: 0.000809518\n",
      "  map@10: 0.000240532\n",
      "Epoch 150, Step 10, LR: 0.000080, Current Loss: 0.6720, Avg Loss: 0.6774\n",
      "Diff stats — min: -6.9584, max: 7.7851, mean: 0.2673, std: 0.9726\n",
      "\n",
      "Step 1647 — Test metrics:\n",
      "  precision@10: 0.000832452\n",
      "  recall@10: 0.000833921\n",
      "  ndcg@10: 0.000831771\n",
      "  map@10: 0.000244548\n",
      "Epoch 150 completed, Train Loss: 0.6772\n",
      "Epoch 151, Step 1, LR: 0.000080, Current Loss: 0.6770, Avg Loss: 0.6770\n",
      "Diff stats — min: -10.2846, max: 6.9103, mean: 0.2573, std: 0.9755\n",
      "\n",
      "Step 1649 — Test metrics:\n",
      "  precision@10: 0.000839059\n",
      "  recall@10: 0.000840527\n",
      "  ndcg@10: 0.000829152\n",
      "  map@10: 0.000241153\n",
      "Epoch 151, Step 10, LR: 0.000080, Current Loss: 0.6807, Avg Loss: 0.6763\n",
      "Diff stats — min: -7.6267, max: 9.6143, mean: 0.2483, std: 0.9724\n",
      "\n",
      "Step 1658 — Test metrics:\n",
      "  precision@10: 0.000845666\n",
      "  recall@10: 0.000847134\n",
      "  ndcg@10: 0.000835006\n",
      "  map@10: 0.000243172\n",
      "Epoch 151 completed, Train Loss: 0.6762\n",
      "Epoch 152, Step 1, LR: 0.000080, Current Loss: 0.6716, Avg Loss: 0.6716\n",
      "Diff stats — min: -10.7383, max: 11.6830, mean: 0.2664, std: 0.9675\n",
      "\n",
      "Step 1660 — Test metrics:\n",
      "  precision@10: 0.000825846\n",
      "  recall@10: 0.000827314\n",
      "  ndcg@10: 0.000821727\n",
      "  map@10: 0.000240665\n",
      "Epoch 152, Step 10, LR: 0.000080, Current Loss: 0.6717, Avg Loss: 0.6741\n",
      "Diff stats — min: -5.8099, max: 10.3763, mean: 0.2638, std: 0.9613\n",
      "\n",
      "Step 1669 — Test metrics:\n",
      "  precision@10: 0.000806025\n",
      "  recall@10: 0.000807494\n",
      "  ndcg@10: 0.000809980\n",
      "  map@10: 0.000239087\n",
      "Epoch 152 completed, Train Loss: 0.6740\n",
      "Epoch 153, Step 1, LR: 0.000080, Current Loss: 0.6740, Avg Loss: 0.6740\n",
      "Diff stats — min: -4.9000, max: 6.8072, mean: 0.2581, std: 0.9604\n",
      "\n",
      "Step 1671 — Test metrics:\n",
      "  precision@10: 0.000799419\n",
      "  recall@10: 0.000800887\n",
      "  ndcg@10: 0.000805963\n",
      "  map@10: 0.000238529\n",
      "Epoch 153, Step 10, LR: 0.000080, Current Loss: 0.6705, Avg Loss: 0.6730\n",
      "Diff stats — min: -5.4783, max: 9.3494, mean: 0.2620, std: 0.9513\n",
      "\n",
      "Step 1680 — Test metrics:\n",
      "  precision@10: 0.000832452\n",
      "  recall@10: 0.000833921\n",
      "  ndcg@10: 0.000836707\n",
      "  map@10: 0.000247175\n",
      "Epoch 153 completed, Train Loss: 0.6731\n",
      "Epoch 154, Step 1, LR: 0.000080, Current Loss: 0.6716, Avg Loss: 0.6716\n",
      "Diff stats — min: -7.9794, max: 8.3769, mean: 0.2623, std: 0.9586\n",
      "\n",
      "Step 1682 — Test metrics:\n",
      "  precision@10: 0.000832452\n",
      "  recall@10: 0.000833921\n",
      "  ndcg@10: 0.000835876\n",
      "  map@10: 0.000246638\n",
      "Epoch 154, Step 10, LR: 0.000080, Current Loss: 0.6688, Avg Loss: 0.6733\n",
      "Diff stats — min: -6.2291, max: 8.8119, mean: 0.2637, std: 0.9468\n",
      "\n",
      "Step 1691 — Test metrics:\n",
      "  precision@10: 0.000832452\n",
      "  recall@10: 0.000833921\n",
      "  ndcg@10: 0.000838756\n",
      "  map@10: 0.000248161\n",
      "Epoch 154 completed, Train Loss: 0.6730\n",
      "Epoch 155, Step 1, LR: 0.000080, Current Loss: 0.6720, Avg Loss: 0.6720\n",
      "Diff stats — min: -6.4249, max: 7.1237, mean: 0.2611, std: 0.9554\n",
      "\n",
      "Step 1693 — Test metrics:\n",
      "  precision@10: 0.000852273\n",
      "  recall@10: 0.000853741\n",
      "  ndcg@10: 0.000852725\n",
      "  map@10: 0.000251428\n",
      "Epoch 155, Step 10, LR: 0.000080, Current Loss: 0.6708, Avg Loss: 0.6703\n",
      "Diff stats — min: -6.3153, max: 11.7198, mean: 0.2593, std: 0.9476\n",
      "\n",
      "Step 1702 — Test metrics:\n",
      "  precision@10: 0.000852273\n",
      "  recall@10: 0.000853741\n",
      "  ndcg@10: 0.000861230\n",
      "  map@10: 0.000255376\n",
      "Epoch 155 completed, Train Loss: 0.6702\n",
      "Epoch 156, Step 1, LR: 0.000080, Current Loss: 0.6702, Avg Loss: 0.6702\n",
      "Diff stats — min: -6.0244, max: 10.9856, mean: 0.2605, std: 0.9483\n",
      "\n",
      "Step 1704 — Test metrics:\n",
      "  precision@10: 0.000852273\n",
      "  recall@10: 0.000853741\n",
      "  ndcg@10: 0.000863226\n",
      "  map@10: 0.000256474\n",
      "Epoch 156, Step 10, LR: 0.000080, Current Loss: 0.6709, Avg Loss: 0.6699\n",
      "Diff stats — min: -5.1417, max: 7.7053, mean: 0.2578, std: 0.9434\n",
      "\n",
      "Step 1713 — Test metrics:\n",
      "  precision@10: 0.000845666\n",
      "  recall@10: 0.000847134\n",
      "  ndcg@10: 0.000851002\n",
      "  map@10: 0.000250832\n",
      "Epoch 156 completed, Train Loss: 0.6699\n",
      "Epoch 157, Step 1, LR: 0.000080, Current Loss: 0.6716, Avg Loss: 0.6716\n",
      "Diff stats — min: -7.2177, max: 7.3731, mean: 0.2564, std: 0.9436\n",
      "\n",
      "Step 1715 — Test metrics:\n",
      "  precision@10: 0.000852273\n",
      "  recall@10: 0.000853741\n",
      "  ndcg@10: 0.000856805\n",
      "  map@10: 0.000252318\n",
      "Epoch 157, Step 10, LR: 0.000080, Current Loss: 0.6686, Avg Loss: 0.6688\n",
      "Diff stats — min: -5.4926, max: 6.8432, mean: 0.2588, std: 0.9321\n",
      "\n",
      "Step 1724 — Test metrics:\n",
      "  precision@10: 0.000839059\n",
      "  recall@10: 0.000840527\n",
      "  ndcg@10: 0.000847846\n",
      "  map@10: 0.000250911\n",
      "Epoch 157 completed, Train Loss: 0.6684\n",
      "Epoch 158, Step 1, LR: 0.000080, Current Loss: 0.6667, Avg Loss: 0.6667\n",
      "Diff stats — min: -6.2154, max: 6.1318, mean: 0.2624, std: 0.9316\n",
      "\n",
      "Step 1726 — Test metrics:\n",
      "  precision@10: 0.000858879\n",
      "  recall@10: 0.000860348\n",
      "  ndcg@10: 0.000865149\n",
      "  map@10: 0.000255848\n",
      "Epoch 158, Step 10, LR: 0.000080, Current Loss: 0.6690, Avg Loss: 0.6674\n",
      "Diff stats — min: -6.7681, max: 6.8369, mean: 0.2592, std: 0.9361\n",
      "\n",
      "Step 1735 — Test metrics:\n",
      "  precision@10: 0.000878700\n",
      "  recall@10: 0.000880168\n",
      "  ndcg@10: 0.000888536\n",
      "  map@10: 0.000264251\n",
      "Epoch 158 completed, Train Loss: 0.6674\n",
      "Epoch 159, Step 1, LR: 0.000080, Current Loss: 0.6687, Avg Loss: 0.6687\n",
      "Diff stats — min: -6.7744, max: 6.8354, mean: 0.2579, std: 0.9321\n",
      "\n",
      "Step 1737 — Test metrics:\n",
      "  precision@10: 0.000878700\n",
      "  recall@10: 0.000880168\n",
      "  ndcg@10: 0.000889452\n",
      "  map@10: 0.000264680\n",
      "Epoch 159, Step 10, LR: 0.000080, Current Loss: 0.6644, Avg Loss: 0.6664\n",
      "Diff stats — min: -5.7864, max: 7.9099, mean: 0.2637, std: 0.9220\n",
      "\n",
      "Step 1746 — Test metrics:\n",
      "  precision@10: 0.000924947\n",
      "  recall@10: 0.000926415\n",
      "  ndcg@10: 0.000934988\n",
      "  map@10: 0.000277846\n",
      "Epoch 159 completed, Train Loss: 0.6663\n",
      "Epoch 160, Step 1, LR: 0.000080, Current Loss: 0.6656, Avg Loss: 0.6656\n",
      "Diff stats — min: -5.9690, max: 8.3043, mean: 0.2601, std: 0.9198\n",
      "\n",
      "Step 1748 — Test metrics:\n",
      "  precision@10: 0.000931554\n",
      "  recall@10: 0.000933022\n",
      "  ndcg@10: 0.000944887\n",
      "  map@10: 0.000281453\n",
      "Epoch 160, Step 10, LR: 0.000080, Current Loss: 0.6623, Avg Loss: 0.6650\n",
      "Diff stats — min: -7.0350, max: 7.0892, mean: 0.2688, std: 0.9242\n",
      "\n",
      "Step 1757 — Test metrics:\n",
      "  precision@10: 0.000957981\n",
      "  recall@10: 0.000959449\n",
      "  ndcg@10: 0.000969902\n",
      "  map@10: 0.000289035\n",
      "Epoch 160 completed, Train Loss: 0.6650\n",
      "Epoch 161, Step 1, LR: 0.000080, Current Loss: 0.6634, Avg Loss: 0.6634\n",
      "Diff stats — min: -6.4574, max: 6.8845, mean: 0.2609, std: 0.9093\n",
      "\n",
      "Step 1759 — Test metrics:\n",
      "  precision@10: 0.000951374\n",
      "  recall@10: 0.000952842\n",
      "  ndcg@10: 0.000969042\n",
      "  map@10: 0.000290173\n",
      "Epoch 161, Step 10, LR: 0.000080, Current Loss: 0.6617, Avg Loss: 0.6637\n",
      "Diff stats — min: -5.8335, max: 6.7391, mean: 0.2678, std: 0.9188\n",
      "\n",
      "Step 1768 — Test metrics:\n",
      "  precision@10: 0.000898520\n",
      "  recall@10: 0.000899988\n",
      "  ndcg@10: 0.000919453\n",
      "  map@10: 0.000276359\n",
      "Epoch 161 completed, Train Loss: 0.6638\n",
      "Epoch 162, Step 1, LR: 0.000080, Current Loss: 0.6649, Avg Loss: 0.6649\n",
      "Diff stats — min: -5.8732, max: 7.3409, mean: 0.2604, std: 0.9174\n",
      "\n",
      "Step 1770 — Test metrics:\n",
      "  precision@10: 0.000885307\n",
      "  recall@10: 0.000886775\n",
      "  ndcg@10: 0.000907606\n",
      "  map@10: 0.000273316\n",
      "Epoch 162, Step 10, LR: 0.000080, Current Loss: 0.6595, Avg Loss: 0.6625\n",
      "Diff stats — min: -5.3127, max: 10.0989, mean: 0.2700, std: 0.9107\n",
      "\n",
      "Step 1779 — Test metrics:\n",
      "  precision@10: 0.000891913\n",
      "  recall@10: 0.000893381\n",
      "  ndcg@10: 0.000914985\n",
      "  map@10: 0.000274784\n",
      "Epoch 162 completed, Train Loss: 0.6625\n",
      "Epoch 163, Step 1, LR: 0.000080, Current Loss: 0.6614, Avg Loss: 0.6614\n",
      "Diff stats — min: -6.0675, max: 7.7805, mean: 0.2641, std: 0.9078\n",
      "\n",
      "Step 1781 — Test metrics:\n",
      "  precision@10: 0.000898520\n",
      "  recall@10: 0.000899988\n",
      "  ndcg@10: 0.000923355\n",
      "  map@10: 0.000277639\n",
      "Epoch 163, Step 10, LR: 0.000080, Current Loss: 0.6636, Avg Loss: 0.6615\n",
      "Diff stats — min: -7.5751, max: 7.8899, mean: 0.2597, std: 0.9087\n",
      "\n",
      "Step 1790 — Test metrics:\n",
      "  precision@10: 0.000938161\n",
      "  recall@10: 0.000939629\n",
      "  ndcg@10: 0.000952733\n",
      "  map@10: 0.000284529\n",
      "Epoch 163 completed, Train Loss: 0.6612\n",
      "Epoch 164, Step 1, LR: 0.000080, Current Loss: 0.6613, Avg Loss: 0.6613\n",
      "Diff stats — min: -7.1846, max: 6.8725, mean: 0.2623, std: 0.9029\n",
      "\n",
      "Step 1792 — Test metrics:\n",
      "  precision@10: 0.000931554\n",
      "  recall@10: 0.000933022\n",
      "  ndcg@10: 0.000949069\n",
      "  map@10: 0.000284088\n",
      "Epoch 164, Step 10, LR: 0.000080, Current Loss: 0.6597, Avg Loss: 0.6598\n",
      "Diff stats — min: -5.5188, max: 8.4801, mean: 0.2656, std: 0.9013\n",
      "\n",
      "Step 1801 — Test metrics:\n",
      "  precision@10: 0.000957981\n",
      "  recall@10: 0.000959449\n",
      "  ndcg@10: 0.000970946\n",
      "  map@10: 0.000288262\n",
      "Epoch 164 completed, Train Loss: 0.6602\n",
      "Epoch 165, Step 1, LR: 0.000080, Current Loss: 0.6615, Avg Loss: 0.6615\n",
      "Diff stats — min: -8.3291, max: 13.6424, mean: 0.2633, std: 0.9063\n",
      "\n",
      "Step 1803 — Test metrics:\n",
      "  precision@10: 0.000951374\n",
      "  recall@10: 0.000952842\n",
      "  ndcg@10: 0.000965745\n",
      "  map@10: 0.000287030\n",
      "Epoch 165, Step 10, LR: 0.000080, Current Loss: 0.6620, Avg Loss: 0.6589\n",
      "Diff stats — min: -5.7952, max: 7.8234, mean: 0.2584, std: 0.8961\n",
      "\n",
      "Step 1812 — Test metrics:\n",
      "  precision@10: 0.000984408\n",
      "  recall@10: 0.000985876\n",
      "  ndcg@10: 0.000999270\n",
      "  map@10: 0.000296974\n",
      "Epoch 165 completed, Train Loss: 0.6592\n",
      "Epoch 166, Step 1, LR: 0.000080, Current Loss: 0.6573, Avg Loss: 0.6573\n",
      "Diff stats — min: -9.6693, max: 6.9476, mean: 0.2711, std: 0.9036\n",
      "\n",
      "Step 1814 — Test metrics:\n",
      "  precision@10: 0.000977801\n",
      "  recall@10: 0.000979269\n",
      "  ndcg@10: 0.000998833\n",
      "  map@10: 0.000298387\n",
      "Epoch 166, Step 10, LR: 0.000080, Current Loss: 0.6562, Avg Loss: 0.6582\n",
      "Diff stats — min: -5.2793, max: 6.8824, mean: 0.2690, std: 0.8898\n",
      "\n",
      "Step 1823 — Test metrics:\n",
      "  precision@10: 0.001017442\n",
      "  recall@10: 0.001018910\n",
      "  ndcg@10: 0.001042529\n",
      "  map@10: 0.000313218\n",
      "Epoch 166 completed, Train Loss: 0.6581\n",
      "Epoch 167, Step 1, LR: 0.000080, Current Loss: 0.6599, Avg Loss: 0.6599\n",
      "Diff stats — min: -11.1098, max: 6.6268, mean: 0.2622, std: 0.8963\n",
      "\n",
      "Step 1825 — Test metrics:\n",
      "  precision@10: 0.000997622\n",
      "  recall@10: 0.000999090\n",
      "  ndcg@10: 0.001021383\n",
      "  map@10: 0.000306006\n",
      "Epoch 167, Step 10, LR: 0.000080, Current Loss: 0.6625, Avg Loss: 0.6564\n",
      "Diff stats — min: -9.1512, max: 9.1338, mean: 0.2555, std: 0.8959\n",
      "\n",
      "Step 1834 — Test metrics:\n",
      "  precision@10: 0.000957981\n",
      "  recall@10: 0.000959449\n",
      "  ndcg@10: 0.000974267\n",
      "  map@10: 0.000290708\n",
      "Epoch 167 completed, Train Loss: 0.6564\n",
      "Epoch 168, Step 1, LR: 0.000080, Current Loss: 0.6579, Avg Loss: 0.6579\n",
      "Diff stats — min: -6.7689, max: 7.2334, mean: 0.2646, std: 0.8895\n",
      "\n",
      "Step 1836 — Test metrics:\n",
      "  precision@10: 0.000951374\n",
      "  recall@10: 0.000952842\n",
      "  ndcg@10: 0.000962995\n",
      "  map@10: 0.000285504\n",
      "Epoch 168, Step 10, LR: 0.000080, Current Loss: 0.6554, Avg Loss: 0.6557\n",
      "Diff stats — min: -4.9143, max: 8.6063, mean: 0.2703, std: 0.8909\n",
      "\n",
      "Step 1845 — Test metrics:\n",
      "  precision@10: 0.000971195\n",
      "  recall@10: 0.000972663\n",
      "  ndcg@10: 0.000983722\n",
      "  map@10: 0.000291542\n",
      "Epoch 168 completed, Train Loss: 0.6558\n",
      "Epoch 169, Step 1, LR: 0.000080, Current Loss: 0.6539, Avg Loss: 0.6539\n",
      "Diff stats — min: -5.2067, max: 7.1191, mean: 0.2749, std: 0.8946\n",
      "\n",
      "Step 1847 — Test metrics:\n",
      "  precision@10: 0.000997622\n",
      "  recall@10: 0.000999090\n",
      "  ndcg@10: 0.001010561\n",
      "  map@10: 0.000299433\n",
      "Epoch 169, Step 10, LR: 0.000080, Current Loss: 0.6522, Avg Loss: 0.6545\n",
      "Diff stats — min: -8.5323, max: 7.7857, mean: 0.2720, std: 0.8784\n",
      "\n",
      "Step 1856 — Test metrics:\n",
      "  precision@10: 0.001010835\n",
      "  recall@10: 0.001012303\n",
      "  ndcg@10: 0.001025578\n",
      "  map@10: 0.000305065\n",
      "Epoch 169 completed, Train Loss: 0.6546\n",
      "Epoch 170, Step 1, LR: 0.000080, Current Loss: 0.6548, Avg Loss: 0.6548\n",
      "Diff stats — min: -6.4718, max: 5.7550, mean: 0.2683, std: 0.8805\n",
      "\n",
      "Step 1858 — Test metrics:\n",
      "  precision@10: 0.001004228\n",
      "  recall@10: 0.001005696\n",
      "  ndcg@10: 0.001025365\n",
      "  map@10: 0.000306981\n",
      "Epoch 170, Step 10, LR: 0.000080, Current Loss: 0.6554, Avg Loss: 0.6545\n",
      "Diff stats — min: -4.5730, max: 7.6669, mean: 0.2689, std: 0.8861\n",
      "\n",
      "Step 1867 — Test metrics:\n",
      "  precision@10: 0.000971195\n",
      "  recall@10: 0.000972663\n",
      "  ndcg@10: 0.000980325\n",
      "  map@10: 0.000290166\n",
      "Epoch 170 completed, Train Loss: 0.6542\n",
      "Epoch 171, Step 1, LR: 0.000080, Current Loss: 0.6520, Avg Loss: 0.6520\n",
      "Diff stats — min: -5.5870, max: 8.7547, mean: 0.2725, std: 0.8754\n",
      "\n",
      "Step 1869 — Test metrics:\n",
      "  precision@10: 0.000977801\n",
      "  recall@10: 0.000979269\n",
      "  ndcg@10: 0.000984885\n",
      "  map@10: 0.000291037\n",
      "Epoch 171, Step 10, LR: 0.000080, Current Loss: 0.6529, Avg Loss: 0.6525\n",
      "Diff stats — min: -6.3872, max: 7.1564, mean: 0.2689, std: 0.8732\n",
      "\n",
      "Step 1878 — Test metrics:\n",
      "  precision@10: 0.001017442\n",
      "  recall@10: 0.001018910\n",
      "  ndcg@10: 0.001022397\n",
      "  map@10: 0.000301588\n",
      "Epoch 171 completed, Train Loss: 0.6523\n",
      "Epoch 172, Step 1, LR: 0.000080, Current Loss: 0.6502, Avg Loss: 0.6502\n",
      "Diff stats — min: -6.1321, max: 6.9042, mean: 0.2755, std: 0.8745\n",
      "\n",
      "Step 1880 — Test metrics:\n",
      "  precision@10: 0.001024049\n",
      "  recall@10: 0.001025517\n",
      "  ndcg@10: 0.001031344\n",
      "  map@10: 0.000304598\n",
      "Epoch 172, Step 10, LR: 0.000080, Current Loss: 0.6530, Avg Loss: 0.6524\n",
      "Diff stats — min: -4.8771, max: 7.2995, mean: 0.2699, std: 0.8764\n",
      "\n",
      "Step 1889 — Test metrics:\n",
      "  precision@10: 0.001017442\n",
      "  recall@10: 0.001018910\n",
      "  ndcg@10: 0.001041052\n",
      "  map@10: 0.000312912\n",
      "Epoch 172 completed, Train Loss: 0.6524\n",
      "Epoch 173, Step 1, LR: 0.000080, Current Loss: 0.6506, Avg Loss: 0.6506\n",
      "Diff stats — min: -5.8751, max: 5.6386, mean: 0.2741, std: 0.8717\n",
      "\n",
      "Step 1891 — Test metrics:\n",
      "  precision@10: 0.001010835\n",
      "  recall@10: 0.001012303\n",
      "  ndcg@10: 0.001035426\n",
      "  map@10: 0.000311443\n",
      "Epoch 173, Step 10, LR: 0.000080, Current Loss: 0.6512, Avg Loss: 0.6513\n",
      "Diff stats — min: -4.6442, max: 7.3410, mean: 0.2689, std: 0.8626\n",
      "\n",
      "Step 1900 — Test metrics:\n",
      "  precision@10: 0.001004228\n",
      "  recall@10: 0.001005696\n",
      "  ndcg@10: 0.001018048\n",
      "  map@10: 0.000302060\n",
      "Epoch 173 completed, Train Loss: 0.6516\n",
      "Epoch 174, Step 1, LR: 0.000080, Current Loss: 0.6490, Avg Loss: 0.6490\n",
      "Diff stats — min: -9.1805, max: 7.9602, mean: 0.2742, std: 0.8653\n",
      "\n",
      "Step 1902 — Test metrics:\n",
      "  precision@10: 0.001017442\n",
      "  recall@10: 0.001018910\n",
      "  ndcg@10: 0.001041380\n",
      "  map@10: 0.000312623\n",
      "Epoch 174, Step 10, LR: 0.000080, Current Loss: 0.6507, Avg Loss: 0.6501\n",
      "Diff stats — min: -5.5236, max: 5.9087, mean: 0.2709, std: 0.8638\n",
      "\n",
      "Step 1911 — Test metrics:\n",
      "  precision@10: 0.001050476\n",
      "  recall@10: 0.001051944\n",
      "  ndcg@10: 0.001074948\n",
      "  map@10: 0.000321832\n",
      "Epoch 174 completed, Train Loss: 0.6499\n",
      "Epoch 175, Step 1, LR: 0.000080, Current Loss: 0.6505, Avg Loss: 0.6505\n",
      "Diff stats — min: -7.3222, max: 7.5162, mean: 0.2698, std: 0.8611\n",
      "\n",
      "Step 1913 — Test metrics:\n",
      "  precision@10: 0.001043869\n",
      "  recall@10: 0.001045337\n",
      "  ndcg@10: 0.001070624\n",
      "  map@10: 0.000321417\n",
      "Epoch 175, Step 10, LR: 0.000080, Current Loss: 0.6487, Avg Loss: 0.6501\n",
      "Diff stats — min: -10.4432, max: 9.2737, mean: 0.2738, std: 0.8646\n",
      "\n",
      "Step 1922 — Test metrics:\n",
      "  precision@10: 0.001050476\n",
      "  recall@10: 0.001051944\n",
      "  ndcg@10: 0.001086654\n",
      "  map@10: 0.000329186\n",
      "Epoch 175 completed, Train Loss: 0.6500\n",
      "Epoch 176, Step 1, LR: 0.000080, Current Loss: 0.6512, Avg Loss: 0.6512\n",
      "Diff stats — min: -7.7733, max: 10.8371, mean: 0.2692, std: 0.8654\n",
      "\n",
      "Step 1924 — Test metrics:\n",
      "  precision@10: 0.001037262\n",
      "  recall@10: 0.001038730\n",
      "  ndcg@10: 0.001077880\n",
      "  map@10: 0.000327454\n",
      "Epoch 176, Step 10, LR: 0.000080, Current Loss: 0.6485, Avg Loss: 0.6490\n",
      "Diff stats — min: -5.2669, max: 6.0206, mean: 0.2722, std: 0.8555\n",
      "\n",
      "Step 1933 — Test metrics:\n",
      "  precision@10: 0.001057082\n",
      "  recall@10: 0.001058551\n",
      "  ndcg@10: 0.001088953\n",
      "  map@10: 0.000328503\n",
      "Epoch 176 completed, Train Loss: 0.6491\n",
      "Epoch 177, Step 1, LR: 0.000080, Current Loss: 0.6475, Avg Loss: 0.6475\n",
      "Diff stats — min: -5.1404, max: 5.7520, mean: 0.2754, std: 0.8585\n",
      "\n",
      "Step 1935 — Test metrics:\n",
      "  precision@10: 0.001063689\n",
      "  recall@10: 0.001065157\n",
      "  ndcg@10: 0.001104782\n",
      "  map@10: 0.000336127\n",
      "Epoch 177, Step 10, LR: 0.000080, Current Loss: 0.6444, Avg Loss: 0.6464\n",
      "Diff stats — min: -6.4591, max: 9.4490, mean: 0.2832, std: 0.8609\n",
      "\n",
      "Step 1944 — Test metrics:\n",
      "  precision@10: 0.001063689\n",
      "  recall@10: 0.001065157\n",
      "  ndcg@10: 0.001096673\n",
      "  map@10: 0.000330970\n",
      "Epoch 177 completed, Train Loss: 0.6462\n",
      "Epoch 178, Step 1, LR: 0.000080, Current Loss: 0.6471, Avg Loss: 0.6471\n",
      "Diff stats — min: -5.3515, max: 6.0467, mean: 0.2738, std: 0.8514\n",
      "\n",
      "Step 1946 — Test metrics:\n",
      "  precision@10: 0.001070296\n",
      "  recall@10: 0.001071764\n",
      "  ndcg@10: 0.001116117\n",
      "  map@10: 0.000341052\n",
      "Epoch 178, Step 10, LR: 0.000080, Current Loss: 0.6495, Avg Loss: 0.6462\n",
      "Diff stats — min: -5.3917, max: 5.2767, mean: 0.2711, std: 0.8573\n",
      "\n",
      "Step 1955 — Test metrics:\n",
      "  precision@10: 0.001103330\n",
      "  recall@10: 0.001104798\n",
      "  ndcg@10: 0.001162009\n",
      "  map@10: 0.000358156\n",
      "Epoch 178 completed, Train Loss: 0.6465\n",
      "Epoch 179, Step 1, LR: 0.000080, Current Loss: 0.6480, Avg Loss: 0.6480\n",
      "Diff stats — min: -4.5812, max: 6.0017, mean: 0.2711, std: 0.8501\n",
      "\n",
      "Step 1957 — Test metrics:\n",
      "  precision@10: 0.001149577\n",
      "  recall@10: 0.001151045\n",
      "  ndcg@10: 0.001191329\n",
      "  map@10: 0.000362130\n",
      "Epoch 179, Step 10, LR: 0.000080, Current Loss: 0.6442, Avg Loss: 0.6453\n",
      "Diff stats — min: -7.5489, max: 7.2279, mean: 0.2800, std: 0.8517\n",
      "\n",
      "Step 1966 — Test metrics:\n",
      "  precision@10: 0.001189218\n",
      "  recall@10: 0.001190686\n",
      "  ndcg@10: 0.001216185\n",
      "  map@10: 0.000364119\n",
      "Epoch 179 completed, Train Loss: 0.6450\n",
      "Epoch 180, Step 1, LR: 0.000080, Current Loss: 0.6481, Avg Loss: 0.6481\n",
      "Diff stats — min: -4.8283, max: 6.6046, mean: 0.2687, std: 0.8443\n",
      "\n",
      "Step 1968 — Test metrics:\n",
      "  precision@10: 0.001169397\n",
      "  recall@10: 0.001170866\n",
      "  ndcg@10: 0.001196710\n",
      "  map@10: 0.000358291\n",
      "Epoch 180, Step 10, LR: 0.000080, Current Loss: 0.6474, Avg Loss: 0.6451\n",
      "Diff stats — min: -4.8404, max: 8.3454, mean: 0.2712, std: 0.8476\n",
      "\n",
      "Step 1977 — Test metrics:\n",
      "  precision@10: 0.001142970\n",
      "  recall@10: 0.001144439\n",
      "  ndcg@10: 0.001175222\n",
      "  map@10: 0.000354513\n",
      "Epoch 180 completed, Train Loss: 0.6448\n",
      "Epoch 181, Step 1, LR: 0.000080, Current Loss: 0.6452, Avg Loss: 0.6452\n",
      "Diff stats — min: -4.4960, max: 9.2776, mean: 0.2772, std: 0.8500\n",
      "\n",
      "Step 1979 — Test metrics:\n",
      "  precision@10: 0.001136364\n",
      "  recall@10: 0.001137832\n",
      "  ndcg@10: 0.001167246\n",
      "  map@10: 0.000351359\n",
      "Epoch 181, Step 10, LR: 0.000080, Current Loss: 0.6444, Avg Loss: 0.6444\n",
      "Diff stats — min: -6.3755, max: 8.1316, mean: 0.2765, std: 0.8441\n",
      "\n",
      "Step 1988 — Test metrics:\n",
      "  precision@10: 0.001142970\n",
      "  recall@10: 0.001144439\n",
      "  ndcg@10: 0.001163183\n",
      "  map@10: 0.000346957\n",
      "Epoch 181 completed, Train Loss: 0.6444\n",
      "Epoch 182, Step 1, LR: 0.000080, Current Loss: 0.6458, Avg Loss: 0.6458\n",
      "Diff stats — min: -4.4473, max: 6.8089, mean: 0.2758, std: 0.8489\n",
      "\n",
      "Step 1990 — Test metrics:\n",
      "  precision@10: 0.001149577\n",
      "  recall@10: 0.001151045\n",
      "  ndcg@10: 0.001171566\n",
      "  map@10: 0.000349757\n",
      "Epoch 182, Step 10, LR: 0.000080, Current Loss: 0.6411, Avg Loss: 0.6431\n",
      "Diff stats — min: -6.6084, max: 6.4785, mean: 0.2834, std: 0.8423\n",
      "\n",
      "Step 1999 — Test metrics:\n",
      "  precision@10: 0.001162791\n",
      "  recall@10: 0.001164259\n",
      "  ndcg@10: 0.001211917\n",
      "  map@10: 0.000369369\n",
      "Epoch 182 completed, Train Loss: 0.6431\n",
      "Epoch 183, Step 1, LR: 0.000080, Current Loss: 0.6387, Avg Loss: 0.6387\n",
      "Diff stats — min: -5.1797, max: 5.7247, mean: 0.2878, std: 0.8383\n",
      "\n",
      "Step 2001 — Test metrics:\n",
      "  precision@10: 0.001176004\n",
      "  recall@10: 0.001177472\n",
      "  ndcg@10: 0.001224723\n",
      "  map@10: 0.000373878\n",
      "Epoch 183, Step 10, LR: 0.000080, Current Loss: 0.6391, Avg Loss: 0.6414\n",
      "Diff stats — min: -6.8814, max: 8.1425, mean: 0.2880, std: 0.8421\n",
      "\n",
      "Step 2010 — Test metrics:\n",
      "  precision@10: 0.001162791\n",
      "  recall@10: 0.001164259\n",
      "  ndcg@10: 0.001218018\n",
      "  map@10: 0.000373176\n",
      "Epoch 183 completed, Train Loss: 0.6414\n",
      "Epoch 184, Step 1, LR: 0.000080, Current Loss: 0.6399, Avg Loss: 0.6399\n",
      "Diff stats — min: -5.0574, max: 6.9631, mean: 0.2831, std: 0.8333\n",
      "\n",
      "Step 2012 — Test metrics:\n",
      "  precision@10: 0.001189218\n",
      "  recall@10: 0.001190686\n",
      "  ndcg@10: 0.001232961\n",
      "  map@10: 0.000374709\n",
      "Epoch 184, Step 10, LR: 0.000080, Current Loss: 0.6417, Avg Loss: 0.6416\n",
      "Diff stats — min: -7.0166, max: 8.5057, mean: 0.2811, std: 0.8380\n",
      "\n",
      "Step 2021 — Test metrics:\n",
      "  precision@10: 0.001162791\n",
      "  recall@10: 0.001164259\n",
      "  ndcg@10: 0.001213619\n",
      "  map@10: 0.000370748\n",
      "Epoch 184 completed, Train Loss: 0.6417\n",
      "Epoch 185, Step 1, LR: 0.000080, Current Loss: 0.6429, Avg Loss: 0.6429\n",
      "Diff stats — min: -5.4791, max: 7.2370, mean: 0.2776, std: 0.8381\n",
      "\n",
      "Step 2023 — Test metrics:\n",
      "  precision@10: 0.001156184\n",
      "  recall@10: 0.001157652\n",
      "  ndcg@10: 0.001194068\n",
      "  map@10: 0.000360880\n",
      "Epoch 185, Step 10, LR: 0.000080, Current Loss: 0.6405, Avg Loss: 0.6407\n",
      "Diff stats — min: -4.5330, max: 6.3816, mean: 0.2841, std: 0.8399\n",
      "\n",
      "Step 2032 — Test metrics:\n",
      "  precision@10: 0.001136364\n",
      "  recall@10: 0.001137832\n",
      "  ndcg@10: 0.001164586\n",
      "  map@10: 0.000348846\n",
      "Epoch 185 completed, Train Loss: 0.6406\n",
      "Epoch 186, Step 1, LR: 0.000080, Current Loss: 0.6393, Avg Loss: 0.6393\n",
      "Diff stats — min: -5.2611, max: 6.9741, mean: 0.2827, std: 0.8294\n",
      "\n",
      "Step 2034 — Test metrics:\n",
      "  precision@10: 0.001162791\n",
      "  recall@10: 0.001164259\n",
      "  ndcg@10: 0.001183628\n",
      "  map@10: 0.000352692\n",
      "Epoch 186, Step 10, LR: 0.000080, Current Loss: 0.6408, Avg Loss: 0.6400\n",
      "Diff stats — min: -4.9165, max: 7.4677, mean: 0.2805, std: 0.8335\n",
      "\n",
      "Step 2043 — Test metrics:\n",
      "  precision@10: 0.001182611\n",
      "  recall@10: 0.001184079\n",
      "  ndcg@10: 0.001223081\n",
      "  map@10: 0.000369993\n",
      "Epoch 186 completed, Train Loss: 0.6397\n",
      "Epoch 187, Step 1, LR: 0.000080, Current Loss: 0.6402, Avg Loss: 0.6402\n",
      "Diff stats — min: -4.6641, max: 7.6483, mean: 0.2818, std: 0.8329\n",
      "\n",
      "Step 2045 — Test metrics:\n",
      "  precision@10: 0.001189218\n",
      "  recall@10: 0.001190686\n",
      "  ndcg@10: 0.001231655\n",
      "  map@10: 0.000373267\n",
      "Epoch 187, Step 10, LR: 0.000080, Current Loss: 0.6383, Avg Loss: 0.6392\n",
      "Diff stats — min: -7.7304, max: 8.6075, mean: 0.2872, std: 0.8381\n",
      "\n",
      "Step 2054 — Test metrics:\n",
      "  precision@10: 0.001281712\n",
      "  recall@10: 0.001283181\n",
      "  ndcg@10: 0.001347203\n",
      "  map@10: 0.000413236\n",
      "Epoch 187 completed, Train Loss: 0.6393\n",
      "Epoch 188, Step 1, LR: 0.000080, Current Loss: 0.6397, Avg Loss: 0.6397\n",
      "Diff stats — min: -6.1739, max: 5.9955, mean: 0.2822, std: 0.8301\n",
      "\n",
      "Step 2056 — Test metrics:\n",
      "  precision@10: 0.001288319\n",
      "  recall@10: 0.001289787\n",
      "  ndcg@10: 0.001369802\n",
      "  map@10: 0.000424767\n",
      "Epoch 188, Step 10, LR: 0.000080, Current Loss: 0.6362, Avg Loss: 0.6387\n",
      "Diff stats — min: -4.3592, max: 7.7505, mean: 0.2875, std: 0.8233\n",
      "\n",
      "Step 2065 — Test metrics:\n",
      "  precision@10: 0.001255285\n",
      "  recall@10: 0.001256754\n",
      "  ndcg@10: 0.001315793\n",
      "  map@10: 0.000403172\n",
      "Epoch 188 completed, Train Loss: 0.6386\n",
      "Epoch 189, Step 1, LR: 0.000080, Current Loss: 0.6377, Avg Loss: 0.6377\n",
      "Diff stats — min: -5.2860, max: 6.4195, mean: 0.2869, std: 0.8313\n",
      "\n",
      "Step 2067 — Test metrics:\n",
      "  precision@10: 0.001248679\n",
      "  recall@10: 0.001250147\n",
      "  ndcg@10: 0.001302933\n",
      "  map@10: 0.000397809\n",
      "Epoch 189, Step 10, LR: 0.000080, Current Loss: 0.6386, Avg Loss: 0.6378\n",
      "Diff stats — min: -10.5323, max: 5.6801, mean: 0.2816, std: 0.8236\n",
      "\n",
      "Step 2076 — Test metrics:\n",
      "  precision@10: 0.001202431\n",
      "  recall@10: 0.001203899\n",
      "  ndcg@10: 0.001267300\n",
      "  map@10: 0.000389310\n",
      "Epoch 189 completed, Train Loss: 0.6377\n",
      "Epoch 190, Step 1, LR: 0.000080, Current Loss: 0.6414, Avg Loss: 0.6414\n",
      "Diff stats — min: -5.0668, max: 5.0040, mean: 0.2756, std: 0.8230\n",
      "\n",
      "Step 2078 — Test metrics:\n",
      "  precision@10: 0.001202431\n",
      "  recall@10: 0.001203899\n",
      "  ndcg@10: 0.001264924\n",
      "  map@10: 0.000388099\n",
      "Epoch 190, Step 10, LR: 0.000080, Current Loss: 0.6340, Avg Loss: 0.6366\n",
      "Diff stats — min: -6.1936, max: 6.1062, mean: 0.2921, std: 0.8224\n",
      "\n",
      "Step 2087 — Test metrics:\n",
      "  precision@10: 0.001228858\n",
      "  recall@10: 0.001230327\n",
      "  ndcg@10: 0.001285371\n",
      "  map@10: 0.000393033\n",
      "Epoch 190 completed, Train Loss: 0.6364\n",
      "Epoch 191, Step 1, LR: 0.000080, Current Loss: 0.6395, Avg Loss: 0.6395\n",
      "Diff stats — min: -5.0368, max: 6.7188, mean: 0.2840, std: 0.8354\n",
      "\n",
      "Step 2089 — Test metrics:\n",
      "  precision@10: 0.001248679\n",
      "  recall@10: 0.001250147\n",
      "  ndcg@10: 0.001299395\n",
      "  map@10: 0.000396027\n",
      "Epoch 191, Step 10, LR: 0.000080, Current Loss: 0.6335, Avg Loss: 0.6353\n",
      "Diff stats — min: -4.6883, max: 6.4281, mean: 0.2942, std: 0.8249\n",
      "\n",
      "Step 2098 — Test metrics:\n",
      "  precision@10: 0.001281712\n",
      "  recall@10: 0.001283181\n",
      "  ndcg@10: 0.001323200\n",
      "  map@10: 0.000400296\n",
      "Epoch 191 completed, Train Loss: 0.6351\n",
      "Epoch 192, Step 1, LR: 0.000080, Current Loss: 0.6327, Avg Loss: 0.6327\n",
      "Diff stats — min: -5.8618, max: 7.8411, mean: 0.2944, std: 0.8216\n",
      "\n",
      "Step 2100 — Test metrics:\n",
      "  precision@10: 0.001288319\n",
      "  recall@10: 0.001289787\n",
      "  ndcg@10: 0.001331090\n",
      "  map@10: 0.000403281\n",
      "Epoch 192, Step 10, LR: 0.000080, Current Loss: 0.6384, Avg Loss: 0.6348\n",
      "Diff stats — min: -6.9803, max: 7.2652, mean: 0.2820, std: 0.8230\n",
      "\n",
      "Step 2109 — Test metrics:\n",
      "  precision@10: 0.001255285\n",
      "  recall@10: 0.001256754\n",
      "  ndcg@10: 0.001315982\n",
      "  map@10: 0.000403601\n",
      "Epoch 192 completed, Train Loss: 0.6351\n",
      "Epoch 193, Step 1, LR: 0.000080, Current Loss: 0.6327, Avg Loss: 0.6327\n",
      "Diff stats — min: -3.7854, max: 6.6433, mean: 0.2947, std: 0.8210\n",
      "\n",
      "Step 2111 — Test metrics:\n",
      "  precision@10: 0.001228858\n",
      "  recall@10: 0.001230327\n",
      "  ndcg@10: 0.001297942\n",
      "  map@10: 0.000399808\n",
      "Epoch 193, Step 10, LR: 0.000080, Current Loss: 0.6343, Avg Loss: 0.6339\n",
      "Diff stats — min: -4.9637, max: 6.2352, mean: 0.2913, std: 0.8233\n",
      "\n",
      "Step 2120 — Test metrics:\n",
      "  precision@10: 0.001248679\n",
      "  recall@10: 0.001250147\n",
      "  ndcg@10: 0.001303708\n",
      "  map@10: 0.000397545\n",
      "Epoch 193 completed, Train Loss: 0.6338\n",
      "Epoch 194, Step 1, LR: 0.000080, Current Loss: 0.6369, Avg Loss: 0.6369\n",
      "Diff stats — min: -5.3573, max: 10.4972, mean: 0.2845, std: 0.8204\n",
      "\n",
      "Step 2122 — Test metrics:\n",
      "  precision@10: 0.001255285\n",
      "  recall@10: 0.001256754\n",
      "  ndcg@10: 0.001316647\n",
      "  map@10: 0.000403042\n",
      "Epoch 194, Step 10, LR: 0.000080, Current Loss: 0.6352, Avg Loss: 0.6338\n",
      "Diff stats — min: -4.1229, max: 6.0402, mean: 0.2868, std: 0.8162\n",
      "\n",
      "Step 2131 — Test metrics:\n",
      "  precision@10: 0.001327960\n",
      "  recall@10: 0.001329428\n",
      "  ndcg@10: 0.001416970\n",
      "  map@10: 0.000440926\n",
      "Epoch 194 completed, Train Loss: 0.6339\n",
      "Epoch 195, Step 1, LR: 0.000080, Current Loss: 0.6332, Avg Loss: 0.6332\n",
      "Diff stats — min: -5.9948, max: 9.7996, mean: 0.2923, std: 0.8207\n",
      "\n",
      "Step 2133 — Test metrics:\n",
      "  precision@10: 0.001347780\n",
      "  recall@10: 0.001349248\n",
      "  ndcg@10: 0.001440607\n",
      "  map@10: 0.000448779\n",
      "Epoch 195, Step 10, LR: 0.000080, Current Loss: 0.6319, Avg Loss: 0.6326\n",
      "Diff stats — min: -7.0014, max: 5.6936, mean: 0.2916, std: 0.8076\n",
      "\n",
      "Step 2142 — Test metrics:\n",
      "  precision@10: 0.001360994\n",
      "  recall@10: 0.001362462\n",
      "  ndcg@10: 0.001452927\n",
      "  map@10: 0.000451248\n",
      "Epoch 195 completed, Train Loss: 0.6328\n",
      "Epoch 196, Step 1, LR: 0.000080, Current Loss: 0.6319, Avg Loss: 0.6319\n",
      "Diff stats — min: -6.1056, max: 7.1030, mean: 0.2946, std: 0.8156\n",
      "\n",
      "Step 2144 — Test metrics:\n",
      "  precision@10: 0.001367600\n",
      "  recall@10: 0.001369069\n",
      "  ndcg@10: 0.001459429\n",
      "  map@10: 0.000453817\n",
      "Epoch 196, Step 10, LR: 0.000080, Current Loss: 0.6328, Avg Loss: 0.6322\n",
      "Diff stats — min: -4.5553, max: 6.5394, mean: 0.2913, std: 0.8137\n",
      "\n",
      "Step 2153 — Test metrics:\n",
      "  precision@10: 0.001367600\n",
      "  recall@10: 0.001369069\n",
      "  ndcg@10: 0.001441377\n",
      "  map@10: 0.000444154\n",
      "Epoch 196 completed, Train Loss: 0.6320\n",
      "Epoch 197, Step 1, LR: 0.000080, Current Loss: 0.6318, Avg Loss: 0.6318\n",
      "Diff stats — min: -7.2691, max: 6.7388, mean: 0.2968, std: 0.8227\n",
      "\n",
      "Step 2155 — Test metrics:\n",
      "  precision@10: 0.001367600\n",
      "  recall@10: 0.001369069\n",
      "  ndcg@10: 0.001439230\n",
      "  map@10: 0.000443055\n",
      "Epoch 197, Step 10, LR: 0.000080, Current Loss: 0.6336, Avg Loss: 0.6311\n",
      "Diff stats — min: -5.5953, max: 8.5250, mean: 0.2915, std: 0.8193\n",
      "\n",
      "Step 2164 — Test metrics:\n",
      "  precision@10: 0.001327960\n",
      "  recall@10: 0.001329428\n",
      "  ndcg@10: 0.001400879\n",
      "  map@10: 0.000431237\n",
      "Epoch 197 completed, Train Loss: 0.6308\n",
      "Epoch 198, Step 1, LR: 0.000080, Current Loss: 0.6308, Avg Loss: 0.6308\n",
      "Diff stats — min: -8.0223, max: 6.7355, mean: 0.2952, std: 0.8133\n",
      "\n",
      "Step 2166 — Test metrics:\n",
      "  precision@10: 0.001327960\n",
      "  recall@10: 0.001329428\n",
      "  ndcg@10: 0.001400532\n",
      "  map@10: 0.000431171\n",
      "Epoch 198, Step 10, LR: 0.000080, Current Loss: 0.6269, Avg Loss: 0.6297\n",
      "Diff stats — min: -5.0486, max: 6.7590, mean: 0.3068, std: 0.8179\n",
      "\n",
      "Step 2175 — Test metrics:\n",
      "  precision@10: 0.001341173\n",
      "  recall@10: 0.001342642\n",
      "  ndcg@10: 0.001411281\n",
      "  map@10: 0.000433591\n",
      "Epoch 198 completed, Train Loss: 0.6296\n",
      "Epoch 199, Step 1, LR: 0.000080, Current Loss: 0.6294, Avg Loss: 0.6294\n",
      "Diff stats — min: -6.2804, max: 6.1930, mean: 0.2983, std: 0.8117\n",
      "\n",
      "Step 2177 — Test metrics:\n",
      "  precision@10: 0.001367600\n",
      "  recall@10: 0.001369069\n",
      "  ndcg@10: 0.001428583\n",
      "  map@10: 0.000436186\n",
      "Epoch 199, Step 10, LR: 0.000080, Current Loss: 0.6268, Avg Loss: 0.6295\n",
      "Diff stats — min: -6.0875, max: 5.7758, mean: 0.3041, std: 0.8108\n",
      "\n",
      "Step 2186 — Test metrics:\n",
      "  precision@10: 0.001413848\n",
      "  recall@10: 0.001415316\n",
      "  ndcg@10: 0.001483215\n",
      "  map@10: 0.000454675\n",
      "Epoch 199 completed, Train Loss: 0.6296\n",
      "Epoch 200, Step 1, LR: 0.000080, Current Loss: 0.6306, Avg Loss: 0.6306\n",
      "Diff stats — min: -4.9254, max: 7.5549, mean: 0.2957, std: 0.8121\n",
      "\n",
      "Step 2188 — Test metrics:\n",
      "  precision@10: 0.001420455\n",
      "  recall@10: 0.001421923\n",
      "  ndcg@10: 0.001495208\n",
      "  map@10: 0.000459428\n",
      "Epoch 200, Step 10, LR: 0.000080, Current Loss: 0.6286, Avg Loss: 0.6293\n",
      "Diff stats — min: -6.5056, max: 6.7330, mean: 0.3028, std: 0.8200\n",
      "\n",
      "Step 2197 — Test metrics:\n",
      "  precision@10: 0.001440275\n",
      "  recall@10: 0.001441743\n",
      "  ndcg@10: 0.001511095\n",
      "  map@10: 0.000463057\n",
      "Epoch 200 completed, Train Loss: 0.6290\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model,\n",
    "                    data,\n",
    "                    edge_type=edge_type,\n",
    "                    num_epochs=num_epochs,\n",
    "                    lr=lr,\n",
    "                    batch_size=batch_size,\n",
    "                    print_every=print_every,\n",
    "                    test_every=test_every,\n",
    "                    top_k=top_k,\n",
    "                    test_batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-24T21:49:06.100010Z",
     "iopub.status.busy": "2025-06-24T21:49:06.099747Z",
     "iopub.status.idle": "2025-06-24T23:01:33.615914Z",
     "shell.execute_reply": "2025-06-24T23:01:33.615233Z",
     "shell.execute_reply.started": "2025-06-24T21:49:06.099995Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training examples: 359463\n",
      "Epoch 201, Step 1, LR: 0.000080, Current Loss: 0.6295, Avg Loss: 0.6295\n",
      "Diff stats — min: -5.0975, max: 6.5454, mean: 0.2994, std: 0.8144\n",
      "\n",
      "Step 2198 — Test metrics:\n",
      "  precision@10: 0.001427061\n",
      "  recall@10: 0.001428529\n",
      "  ndcg@10: 0.001521570\n",
      "  map@10: 0.000472687\n",
      "Epoch 201, Step 10, LR: 0.000080, Current Loss: 0.6268, Avg Loss: 0.6289\n",
      "Diff stats — min: -7.8867, max: 7.3657, mean: 0.3024, std: 0.8066\n",
      "\n",
      "Step 2207 — Test metrics:\n",
      "  precision@10: 0.001479915\n",
      "  recall@10: 0.001481384\n",
      "  ndcg@10: 0.001591277\n",
      "  map@10: 0.000497965\n",
      "Epoch 201 completed, Train Loss: 0.6288\n",
      "Epoch 202, Step 1, LR: 0.000080, Current Loss: 0.6287, Avg Loss: 0.6287\n",
      "Diff stats — min: -4.2175, max: 7.3493, mean: 0.2994, std: 0.8119\n",
      "\n",
      "Step 2209 — Test metrics:\n",
      "  precision@10: 0.001460095\n",
      "  recall@10: 0.001461563\n",
      "  ndcg@10: 0.001577656\n",
      "  map@10: 0.000495773\n",
      "Epoch 202, Step 10, LR: 0.000080, Current Loss: 0.6285, Avg Loss: 0.6274\n",
      "Diff stats — min: -4.5263, max: 14.7675, mean: 0.2990, std: 0.8105\n",
      "\n",
      "Step 2218 — Test metrics:\n",
      "  precision@10: 0.001473309\n",
      "  recall@10: 0.001474777\n",
      "  ndcg@10: 0.001565460\n",
      "  map@10: 0.000485588\n",
      "Epoch 202 completed, Train Loss: 0.6275\n",
      "Epoch 203, Step 1, LR: 0.000080, Current Loss: 0.6271, Avg Loss: 0.6271\n",
      "Diff stats — min: -5.1543, max: 5.7110, mean: 0.3013, std: 0.8055\n",
      "\n",
      "Step 2220 — Test metrics:\n",
      "  precision@10: 0.001479915\n",
      "  recall@10: 0.001481384\n",
      "  ndcg@10: 0.001573576\n",
      "  map@10: 0.000488519\n",
      "Epoch 203, Step 10, LR: 0.000080, Current Loss: 0.6252, Avg Loss: 0.6264\n",
      "Diff stats — min: -4.8030, max: 7.5282, mean: 0.3080, std: 0.8109\n",
      "\n",
      "Step 2229 — Test metrics:\n",
      "  precision@10: 0.001486522\n",
      "  recall@10: 0.001487990\n",
      "  ndcg@10: 0.001593044\n",
      "  map@10: 0.000496982\n",
      "Epoch 203 completed, Train Loss: 0.6263\n",
      "Epoch 204, Step 1, LR: 0.000080, Current Loss: 0.6258, Avg Loss: 0.6258\n",
      "Diff stats — min: -6.4244, max: 10.6445, mean: 0.3056, std: 0.8096\n",
      "\n",
      "Step 2231 — Test metrics:\n",
      "  precision@10: 0.001486522\n",
      "  recall@10: 0.001487990\n",
      "  ndcg@10: 0.001591893\n",
      "  map@10: 0.000496434\n",
      "Epoch 204, Step 10, LR: 0.000080, Current Loss: 0.6284, Avg Loss: 0.6250\n",
      "Diff stats — min: -6.1041, max: 4.8111, mean: 0.2984, std: 0.8047\n",
      "\n",
      "Step 2240 — Test metrics:\n",
      "  precision@10: 0.001506342\n",
      "  recall@10: 0.001507811\n",
      "  ndcg@10: 0.001639090\n",
      "  map@10: 0.000518802\n",
      "Epoch 204 completed, Train Loss: 0.6251\n",
      "Epoch 205, Step 1, LR: 0.000080, Current Loss: 0.6209, Avg Loss: 0.6209\n",
      "Diff stats — min: -4.3017, max: 5.8983, mean: 0.3157, std: 0.8053\n",
      "\n",
      "Step 2242 — Test metrics:\n",
      "  precision@10: 0.001526163\n",
      "  recall@10: 0.001527631\n",
      "  ndcg@10: 0.001661986\n",
      "  map@10: 0.000526657\n",
      "Epoch 205, Step 10, LR: 0.000080, Current Loss: 0.6225, Avg Loss: 0.6240\n",
      "Diff stats — min: -4.4160, max: 7.3696, mean: 0.3132, std: 0.8078\n",
      "\n",
      "Step 2251 — Test metrics:\n",
      "  precision@10: 0.001499736\n",
      "  recall@10: 0.001501204\n",
      "  ndcg@10: 0.001621803\n",
      "  map@10: 0.000510722\n",
      "Epoch 205 completed, Train Loss: 0.6242\n",
      "Epoch 206, Step 1, LR: 0.000080, Current Loss: 0.6215, Avg Loss: 0.6215\n",
      "Diff stats — min: -4.3417, max: 4.9160, mean: 0.3137, std: 0.8032\n",
      "\n",
      "Step 2253 — Test metrics:\n",
      "  precision@10: 0.001486522\n",
      "  recall@10: 0.001487990\n",
      "  ndcg@10: 0.001617502\n",
      "  map@10: 0.000511427\n",
      "Epoch 206, Step 10, LR: 0.000080, Current Loss: 0.6261, Avg Loss: 0.6233\n",
      "Diff stats — min: -4.9159, max: 8.8045, mean: 0.3043, std: 0.8077\n",
      "\n",
      "Step 2262 — Test metrics:\n",
      "  precision@10: 0.001499736\n",
      "  recall@10: 0.001501204\n",
      "  ndcg@10: 0.001652447\n",
      "  map@10: 0.000527160\n",
      "Epoch 206 completed, Train Loss: 0.6234\n",
      "Epoch 207, Step 1, LR: 0.000080, Current Loss: 0.6247, Avg Loss: 0.6247\n",
      "Diff stats — min: -4.8232, max: 6.3666, mean: 0.3068, std: 0.8038\n",
      "\n",
      "Step 2264 — Test metrics:\n",
      "  precision@10: 0.001512949\n",
      "  recall@10: 0.001514417\n",
      "  ndcg@10: 0.001659847\n",
      "  map@10: 0.000528167\n",
      "Epoch 207, Step 10, LR: 0.000080, Current Loss: 0.6228, Avg Loss: 0.6222\n",
      "Diff stats — min: -5.9397, max: 7.4906, mean: 0.3099, std: 0.8028\n",
      "\n",
      "Step 2273 — Test metrics:\n",
      "  precision@10: 0.001592230\n",
      "  recall@10: 0.001593699\n",
      "  ndcg@10: 0.001723277\n",
      "  map@10: 0.000543289\n",
      "Epoch 207 completed, Train Loss: 0.6224\n",
      "Epoch 208, Step 1, LR: 0.000080, Current Loss: 0.6226, Avg Loss: 0.6226\n",
      "Diff stats — min: -5.6749, max: 6.2617, mean: 0.3110, std: 0.8024\n",
      "\n",
      "Step 2275 — Test metrics:\n",
      "  precision@10: 0.001572410\n",
      "  recall@10: 0.001573878\n",
      "  ndcg@10: 0.001717510\n",
      "  map@10: 0.000545817\n",
      "Epoch 208, Step 10, LR: 0.000080, Current Loss: 0.6237, Avg Loss: 0.6224\n",
      "Diff stats — min: -5.4649, max: 7.3246, mean: 0.3101, std: 0.8078\n",
      "\n",
      "Step 2284 — Test metrics:\n",
      "  precision@10: 0.001605444\n",
      "  recall@10: 0.001606912\n",
      "  ndcg@10: 0.001728766\n",
      "  map@10: 0.000542461\n",
      "Epoch 208 completed, Train Loss: 0.6225\n",
      "Epoch 209, Step 1, LR: 0.000080, Current Loss: 0.6179, Avg Loss: 0.6179\n",
      "Diff stats — min: -3.9539, max: 5.8374, mean: 0.3225, std: 0.8043\n",
      "\n",
      "Step 2286 — Test metrics:\n",
      "  precision@10: 0.001618658\n",
      "  recall@10: 0.001620126\n",
      "  ndcg@10: 0.001735799\n",
      "  map@10: 0.000543051\n",
      "Epoch 209, Step 10, LR: 0.000080, Current Loss: 0.6223, Avg Loss: 0.6210\n",
      "Diff stats — min: -4.4417, max: 5.9957, mean: 0.3127, std: 0.8048\n",
      "\n",
      "Step 2295 — Test metrics:\n",
      "  precision@10: 0.001572410\n",
      "  recall@10: 0.001573878\n",
      "  ndcg@10: 0.001736183\n",
      "  map@10: 0.000554956\n",
      "Epoch 209 completed, Train Loss: 0.6207\n",
      "Epoch 210, Step 1, LR: 0.000080, Current Loss: 0.6211, Avg Loss: 0.6211\n",
      "Diff stats — min: -4.8817, max: 6.0554, mean: 0.3175, std: 0.8114\n",
      "\n",
      "Step 2297 — Test metrics:\n",
      "  precision@10: 0.001579017\n",
      "  recall@10: 0.001580485\n",
      "  ndcg@10: 0.001752966\n",
      "  map@10: 0.000563367\n",
      "Epoch 210, Step 10, LR: 0.000080, Current Loss: 0.6188, Avg Loss: 0.6196\n",
      "Diff stats — min: -8.2939, max: 5.5034, mean: 0.3198, std: 0.8038\n",
      "\n",
      "Step 2306 — Test metrics:\n",
      "  precision@10: 0.001579017\n",
      "  recall@10: 0.001580485\n",
      "  ndcg@10: 0.001747235\n",
      "  map@10: 0.000558931\n",
      "Epoch 210 completed, Train Loss: 0.6195\n",
      "Epoch 211, Step 1, LR: 0.000080, Current Loss: 0.6186, Avg Loss: 0.6186\n",
      "Diff stats — min: -6.2565, max: 5.4677, mean: 0.3254, std: 0.8155\n",
      "\n",
      "Step 2308 — Test metrics:\n",
      "  precision@10: 0.001598837\n",
      "  recall@10: 0.001600305\n",
      "  ndcg@10: 0.001766619\n",
      "  map@10: 0.000564966\n",
      "Epoch 211, Step 10, LR: 0.000080, Current Loss: 0.6203, Avg Loss: 0.6192\n",
      "Diff stats — min: -4.8055, max: 6.7826, mean: 0.3222, std: 0.8184\n",
      "\n",
      "Step 2317 — Test metrics:\n",
      "  precision@10: 0.001618658\n",
      "  recall@10: 0.001620126\n",
      "  ndcg@10: 0.001760056\n",
      "  map@10: 0.000556091\n",
      "Epoch 211 completed, Train Loss: 0.6191\n",
      "Epoch 212, Step 1, LR: 0.000080, Current Loss: 0.6183, Avg Loss: 0.6183\n",
      "Diff stats — min: -5.3322, max: 7.0203, mean: 0.3250, std: 0.8146\n",
      "\n",
      "Step 2319 — Test metrics:\n",
      "  precision@10: 0.001625264\n",
      "  recall@10: 0.001626732\n",
      "  ndcg@10: 0.001774361\n",
      "  map@10: 0.000562478\n",
      "Epoch 212, Step 10, LR: 0.000080, Current Loss: 0.6188, Avg Loss: 0.6175\n",
      "Diff stats — min: -5.2755, max: 4.8581, mean: 0.3232, std: 0.8103\n",
      "\n",
      "Step 2328 — Test metrics:\n",
      "  precision@10: 0.001664905\n",
      "  recall@10: 0.001666373\n",
      "  ndcg@10: 0.001858252\n",
      "  map@10: 0.000600186\n",
      "Epoch 212 completed, Train Loss: 0.6177\n",
      "Epoch 213, Step 1, LR: 0.000080, Current Loss: 0.6206, Avg Loss: 0.6206\n",
      "Diff stats — min: -4.3432, max: 4.9645, mean: 0.3183, std: 0.8079\n",
      "\n",
      "Step 2330 — Test metrics:\n",
      "  precision@10: 0.001678118\n",
      "  recall@10: 0.001679587\n",
      "  ndcg@10: 0.001877814\n",
      "  map@10: 0.000607459\n",
      "Epoch 213, Step 10, LR: 0.000080, Current Loss: 0.6156, Avg Loss: 0.6178\n",
      "Diff stats — min: -6.2882, max: 10.2846, mean: 0.3316, std: 0.8145\n",
      "\n",
      "Step 2339 — Test metrics:\n",
      "  precision@10: 0.001704545\n",
      "  recall@10: 0.001706014\n",
      "  ndcg@10: 0.001880541\n",
      "  map@10: 0.000600537\n",
      "Epoch 213 completed, Train Loss: 0.6177\n",
      "Epoch 214, Step 1, LR: 0.000080, Current Loss: 0.6162, Avg Loss: 0.6162\n",
      "Diff stats — min: -7.1577, max: 6.3617, mean: 0.3306, std: 0.8148\n",
      "\n",
      "Step 2341 — Test metrics:\n",
      "  precision@10: 0.001684725\n",
      "  recall@10: 0.001686193\n",
      "  ndcg@10: 0.001876163\n",
      "  map@10: 0.000603778\n",
      "Epoch 214, Step 10, LR: 0.000080, Current Loss: 0.6162, Avg Loss: 0.6162\n",
      "Diff stats — min: -7.5661, max: 5.2350, mean: 0.3326, std: 0.8190\n",
      "\n",
      "Step 2350 — Test metrics:\n",
      "  precision@10: 0.001638478\n",
      "  recall@10: 0.001639946\n",
      "  ndcg@10: 0.001823235\n",
      "  map@10: 0.000585916\n",
      "Epoch 214 completed, Train Loss: 0.6163\n",
      "Epoch 215, Step 1, LR: 0.000080, Current Loss: 0.6147, Avg Loss: 0.6147\n",
      "Diff stats — min: -4.0228, max: 7.3442, mean: 0.3343, std: 0.8161\n",
      "\n",
      "Step 2352 — Test metrics:\n",
      "  precision@10: 0.001651691\n",
      "  recall@10: 0.001653160\n",
      "  ndcg@10: 0.001838113\n",
      "  map@10: 0.000591930\n",
      "Epoch 215, Step 10, LR: 0.000080, Current Loss: 0.6174, Avg Loss: 0.6147\n",
      "Diff stats — min: -3.6292, max: 6.2269, mean: 0.3322, std: 0.8248\n",
      "\n",
      "Step 2361 — Test metrics:\n",
      "  precision@10: 0.001764006\n",
      "  recall@10: 0.001765475\n",
      "  ndcg@10: 0.001952785\n",
      "  map@10: 0.000627219\n",
      "Epoch 215 completed, Train Loss: 0.6146\n",
      "Epoch 216, Step 1, LR: 0.000080, Current Loss: 0.6140, Avg Loss: 0.6140\n",
      "Diff stats — min: -3.7714, max: 6.2977, mean: 0.3347, std: 0.8115\n",
      "\n",
      "Step 2363 — Test metrics:\n",
      "  precision@10: 0.001783827\n",
      "  recall@10: 0.001785295\n",
      "  ndcg@10: 0.001986743\n",
      "  map@10: 0.000641324\n",
      "Epoch 216, Step 10, LR: 0.000080, Current Loss: 0.6160, Avg Loss: 0.6144\n",
      "Diff stats — min: -5.6717, max: 6.4666, mean: 0.3372, std: 0.8303\n",
      "\n",
      "Step 2372 — Test metrics:\n",
      "  precision@10: 0.001764006\n",
      "  recall@10: 0.001765475\n",
      "  ndcg@10: 0.001979779\n",
      "  map@10: 0.000642855\n",
      "Epoch 216 completed, Train Loss: 0.6141\n",
      "Epoch 217, Step 1, LR: 0.000080, Current Loss: 0.6148, Avg Loss: 0.6148\n",
      "Diff stats — min: -7.4381, max: 5.4500, mean: 0.3375, std: 0.8234\n",
      "\n",
      "Step 2374 — Test metrics:\n",
      "  precision@10: 0.001730973\n",
      "  recall@10: 0.001732441\n",
      "  ndcg@10: 0.001959115\n",
      "  map@10: 0.000639706\n",
      "Epoch 217, Step 10, LR: 0.000080, Current Loss: 0.6159, Avg Loss: 0.6134\n",
      "Diff stats — min: -4.5902, max: 8.7138, mean: 0.3372, std: 0.8293\n",
      "\n",
      "Step 2383 — Test metrics:\n",
      "  precision@10: 0.001830074\n",
      "  recall@10: 0.001831542\n",
      "  ndcg@10: 0.002022010\n",
      "  map@10: 0.000649629\n",
      "Epoch 217 completed, Train Loss: 0.6134\n",
      "Epoch 218, Step 1, LR: 0.000080, Current Loss: 0.6141, Avg Loss: 0.6141\n",
      "Diff stats — min: -4.1178, max: 6.0680, mean: 0.3409, std: 0.8278\n",
      "\n",
      "Step 2385 — Test metrics:\n",
      "  precision@10: 0.001843288\n",
      "  recall@10: 0.001844756\n",
      "  ndcg@10: 0.002025161\n",
      "  map@10: 0.000647828\n",
      "Epoch 218, Step 10, LR: 0.000080, Current Loss: 0.6114, Avg Loss: 0.6123\n",
      "Diff stats — min: -11.3189, max: 6.8466, mean: 0.3462, std: 0.8274\n",
      "\n",
      "Step 2394 — Test metrics:\n",
      "  precision@10: 0.001823467\n",
      "  recall@10: 0.001824935\n",
      "  ndcg@10: 0.002057152\n",
      "  map@10: 0.000670361\n",
      "Epoch 218 completed, Train Loss: 0.6121\n",
      "Epoch 219, Step 1, LR: 0.000080, Current Loss: 0.6120, Avg Loss: 0.6120\n",
      "Diff stats — min: -3.6742, max: 6.4703, mean: 0.3452, std: 0.8253\n",
      "\n",
      "Step 2396 — Test metrics:\n",
      "  precision@10: 0.001843288\n",
      "  recall@10: 0.001844756\n",
      "  ndcg@10: 0.002069807\n",
      "  map@10: 0.000672270\n",
      "Epoch 219, Step 10, LR: 0.000080, Current Loss: 0.6132, Avg Loss: 0.6119\n",
      "Diff stats — min: -5.1467, max: 6.4674, mean: 0.3461, std: 0.8353\n",
      "\n",
      "Step 2405 — Test metrics:\n",
      "  precision@10: 0.001830074\n",
      "  recall@10: 0.001831542\n",
      "  ndcg@10: 0.002048123\n",
      "  map@10: 0.000663466\n",
      "Epoch 219 completed, Train Loss: 0.6119\n",
      "Epoch 220, Step 1, LR: 0.000080, Current Loss: 0.6095, Avg Loss: 0.6095\n",
      "Diff stats — min: -4.9656, max: 5.5379, mean: 0.3525, std: 0.8292\n",
      "\n",
      "Step 2407 — Test metrics:\n",
      "  precision@10: 0.001843288\n",
      "  recall@10: 0.001844756\n",
      "  ndcg@10: 0.002041294\n",
      "  map@10: 0.000656073\n",
      "Epoch 220, Step 10, LR: 0.000080, Current Loss: 0.6122, Avg Loss: 0.6110\n",
      "Diff stats — min: -3.7444, max: 5.0605, mean: 0.3487, std: 0.8345\n",
      "\n",
      "Step 2416 — Test metrics:\n",
      "  precision@10: 0.001849894\n",
      "  recall@10: 0.001851362\n",
      "  ndcg@10: 0.002035350\n",
      "  map@10: 0.000650848\n",
      "Epoch 220 completed, Train Loss: 0.6109\n",
      "Epoch 221, Step 1, LR: 0.000080, Current Loss: 0.6115, Avg Loss: 0.6115\n",
      "Diff stats — min: -4.8093, max: 9.4203, mean: 0.3489, std: 0.8325\n",
      "\n",
      "Step 2418 — Test metrics:\n",
      "  precision@10: 0.001882928\n",
      "  recall@10: 0.001884396\n",
      "  ndcg@10: 0.002068026\n",
      "  map@10: 0.000660569\n",
      "Epoch 221, Step 10, LR: 0.000080, Current Loss: 0.6094, Avg Loss: 0.6101\n",
      "Diff stats — min: -6.3119, max: 5.7253, mean: 0.3563, std: 0.8378\n",
      "\n",
      "Step 2427 — Test metrics:\n",
      "  precision@10: 0.001942389\n",
      "  recall@10: 0.001943857\n",
      "  ndcg@10: 0.002158522\n",
      "  map@10: 0.000696807\n",
      "Epoch 221 completed, Train Loss: 0.6098\n",
      "Epoch 222, Step 1, LR: 0.000080, Current Loss: 0.6118, Avg Loss: 0.6118\n",
      "Diff stats — min: -4.7241, max: 6.3965, mean: 0.3520, std: 0.8411\n",
      "\n",
      "Step 2429 — Test metrics:\n",
      "  precision@10: 0.001922569\n",
      "  recall@10: 0.001924037\n",
      "  ndcg@10: 0.002156441\n",
      "  map@10: 0.000700213\n",
      "Epoch 222, Step 10, LR: 0.000080, Current Loss: 0.6092, Avg Loss: 0.6087\n",
      "Diff stats — min: -4.3526, max: 7.9125, mean: 0.3545, std: 0.8323\n",
      "\n",
      "Step 2438 — Test metrics:\n",
      "  precision@10: 0.001909355\n",
      "  recall@10: 0.001910823\n",
      "  ndcg@10: 0.002150308\n",
      "  map@10: 0.000700574\n",
      "Epoch 222 completed, Train Loss: 0.6091\n",
      "Epoch 223, Step 1, LR: 0.000080, Current Loss: 0.6113, Avg Loss: 0.6113\n",
      "Diff stats — min: -5.2756, max: 5.7404, mean: 0.3531, std: 0.8400\n",
      "\n",
      "Step 2440 — Test metrics:\n",
      "  precision@10: 0.001896142\n",
      "  recall@10: 0.001897610\n",
      "  ndcg@10: 0.002131774\n",
      "  map@10: 0.000693252\n",
      "Epoch 223, Step 10, LR: 0.000080, Current Loss: 0.6080, Avg Loss: 0.6088\n",
      "Diff stats — min: -3.7585, max: 6.2747, mean: 0.3626, std: 0.8450\n",
      "\n",
      "Step 2449 — Test metrics:\n",
      "  precision@10: 0.001922569\n",
      "  recall@10: 0.001924037\n",
      "  ndcg@10: 0.002120822\n",
      "  map@10: 0.000680220\n",
      "Epoch 223 completed, Train Loss: 0.6083\n",
      "Epoch 224, Step 1, LR: 0.000080, Current Loss: 0.6085, Avg Loss: 0.6085\n",
      "Diff stats — min: -4.6601, max: 5.6414, mean: 0.3616, std: 0.8435\n",
      "\n",
      "Step 2451 — Test metrics:\n",
      "  precision@10: 0.001922569\n",
      "  recall@10: 0.001924037\n",
      "  ndcg@10: 0.002124729\n",
      "  map@10: 0.000682317\n",
      "Epoch 224, Step 10, LR: 0.000080, Current Loss: 0.6080, Avg Loss: 0.6073\n",
      "Diff stats — min: -4.9977, max: 7.5972, mean: 0.3636, std: 0.8472\n",
      "\n",
      "Step 2460 — Test metrics:\n",
      "  precision@10: 0.001942389\n",
      "  recall@10: 0.001943857\n",
      "  ndcg@10: 0.002154220\n",
      "  map@10: 0.000693086\n",
      "Epoch 224 completed, Train Loss: 0.6077\n",
      "Epoch 225, Step 1, LR: 0.000080, Current Loss: 0.6053, Avg Loss: 0.6053\n",
      "Diff stats — min: -6.0225, max: 6.0999, mean: 0.3700, std: 0.8477\n",
      "\n",
      "Step 2462 — Test metrics:\n",
      "  precision@10: 0.001935782\n",
      "  recall@10: 0.001937250\n",
      "  ndcg@10: 0.002158913\n",
      "  map@10: 0.000697459\n",
      "Epoch 225, Step 10, LR: 0.000080, Current Loss: 0.6078, Avg Loss: 0.6065\n",
      "Diff stats — min: -4.0040, max: 5.6040, mean: 0.3642, std: 0.8475\n",
      "\n",
      "Step 2471 — Test metrics:\n",
      "  precision@10: 0.001968816\n",
      "  recall@10: 0.001970284\n",
      "  ndcg@10: 0.002259738\n",
      "  map@10: 0.000746782\n",
      "Epoch 225 completed, Train Loss: 0.6062\n",
      "Epoch 226, Step 1, LR: 0.000080, Current Loss: 0.6065, Avg Loss: 0.6065\n",
      "Diff stats — min: -5.1759, max: 5.6888, mean: 0.3712, std: 0.8567\n",
      "\n",
      "Step 2473 — Test metrics:\n",
      "  precision@10: 0.002008457\n",
      "  recall@10: 0.002009925\n",
      "  ndcg@10: 0.002287342\n",
      "  map@10: 0.000752395\n",
      "Epoch 226, Step 10, LR: 0.000080, Current Loss: 0.6031, Avg Loss: 0.6057\n",
      "Diff stats — min: -5.1661, max: 6.4747, mean: 0.3782, std: 0.8547\n",
      "\n",
      "Step 2482 — Test metrics:\n",
      "  precision@10: 0.001988636\n",
      "  recall@10: 0.001990105\n",
      "  ndcg@10: 0.002252890\n",
      "  map@10: 0.000736552\n",
      "Epoch 226 completed, Train Loss: 0.6056\n",
      "Epoch 227, Step 1, LR: 0.000080, Current Loss: 0.6056, Avg Loss: 0.6056\n",
      "Diff stats — min: -4.3708, max: 5.1094, mean: 0.3704, std: 0.8489\n",
      "\n",
      "Step 2484 — Test metrics:\n",
      "  precision@10: 0.001982030\n",
      "  recall@10: 0.001983498\n",
      "  ndcg@10: 0.002249962\n",
      "  map@10: 0.000736662\n",
      "Epoch 227, Step 10, LR: 0.000080, Current Loss: 0.6031, Avg Loss: 0.6042\n",
      "Diff stats — min: -3.9194, max: 10.0130, mean: 0.3788, std: 0.8563\n",
      "\n",
      "Step 2493 — Test metrics:\n",
      "  precision@10: 0.002067918\n",
      "  recall@10: 0.002069386\n",
      "  ndcg@10: 0.002345072\n",
      "  map@10: 0.000767846\n",
      "Epoch 227 completed, Train Loss: 0.6039\n",
      "Epoch 228, Step 1, LR: 0.000080, Current Loss: 0.6059, Avg Loss: 0.6059\n",
      "Diff stats — min: -3.5752, max: 5.9322, mean: 0.3741, std: 0.8584\n",
      "\n",
      "Step 2495 — Test metrics:\n",
      "  precision@10: 0.002114165\n",
      "  recall@10: 0.002115633\n",
      "  ndcg@10: 0.002382614\n",
      "  map@10: 0.000777417\n",
      "Epoch 228, Step 10, LR: 0.000080, Current Loss: 0.6019, Avg Loss: 0.6029\n",
      "Diff stats — min: -5.0797, max: 8.3719, mean: 0.3856, std: 0.8650\n",
      "\n",
      "Step 2504 — Test metrics:\n",
      "  precision@10: 0.002100951\n",
      "  recall@10: 0.002102420\n",
      "  ndcg@10: 0.002383564\n",
      "  map@10: 0.000780836\n",
      "Epoch 228 completed, Train Loss: 0.6033\n",
      "Epoch 229, Step 1, LR: 0.000080, Current Loss: 0.6022, Avg Loss: 0.6022\n",
      "Diff stats — min: -4.4622, max: 6.0547, mean: 0.3830, std: 0.8601\n",
      "\n",
      "Step 2506 — Test metrics:\n",
      "  precision@10: 0.002100951\n",
      "  recall@10: 0.002102420\n",
      "  ndcg@10: 0.002380941\n",
      "  map@10: 0.000779438\n",
      "Epoch 229, Step 10, LR: 0.000080, Current Loss: 0.6026, Avg Loss: 0.6026\n",
      "Diff stats — min: -4.2178, max: 5.9283, mean: 0.3827, std: 0.8615\n",
      "\n",
      "Step 2515 — Test metrics:\n",
      "  precision@10: 0.002107558\n",
      "  recall@10: 0.002109026\n",
      "  ndcg@10: 0.002375521\n",
      "  map@10: 0.000776060\n",
      "Epoch 229 completed, Train Loss: 0.6026\n",
      "Epoch 230, Step 1, LR: 0.000080, Current Loss: 0.5994, Avg Loss: 0.5994\n",
      "Diff stats — min: -6.2207, max: 6.2125, mean: 0.3909, std: 0.8630\n",
      "\n",
      "Step 2517 — Test metrics:\n",
      "  precision@10: 0.002081131\n",
      "  recall@10: 0.002082599\n",
      "  ndcg@10: 0.002352688\n",
      "  map@10: 0.000769862\n",
      "Epoch 230, Step 10, LR: 0.000080, Current Loss: 0.6035, Avg Loss: 0.6008\n",
      "Diff stats — min: -4.3239, max: 8.2815, mean: 0.3823, std: 0.8658\n",
      "\n",
      "Step 2526 — Test metrics:\n",
      "  precision@10: 0.002100951\n",
      "  recall@10: 0.002102420\n",
      "  ndcg@10: 0.002385683\n",
      "  map@10: 0.000782334\n",
      "Epoch 230 completed, Train Loss: 0.6006\n",
      "Epoch 231, Step 1, LR: 0.000080, Current Loss: 0.6024, Avg Loss: 0.6024\n",
      "Diff stats — min: -5.9697, max: 5.7751, mean: 0.3889, std: 0.8749\n",
      "\n",
      "Step 2528 — Test metrics:\n",
      "  precision@10: 0.002100951\n",
      "  recall@10: 0.002102420\n",
      "  ndcg@10: 0.002400244\n",
      "  map@10: 0.000791394\n",
      "Epoch 231, Step 10, LR: 0.000080, Current Loss: 0.6027, Avg Loss: 0.6008\n",
      "Diff stats — min: -4.2590, max: 7.5252, mean: 0.3885, std: 0.8752\n",
      "\n",
      "Step 2537 — Test metrics:\n",
      "  precision@10: 0.002173626\n",
      "  recall@10: 0.002175094\n",
      "  ndcg@10: 0.002474174\n",
      "  map@10: 0.000813763\n",
      "Epoch 231 completed, Train Loss: 0.6007\n",
      "Epoch 232, Step 1, LR: 0.000080, Current Loss: 0.5948, Avg Loss: 0.5948\n",
      "Diff stats — min: -4.9461, max: 6.4980, mean: 0.4042, std: 0.8665\n",
      "\n",
      "Step 2539 — Test metrics:\n",
      "  precision@10: 0.002200053\n",
      "  recall@10: 0.002201521\n",
      "  ndcg@10: 0.002512351\n",
      "  map@10: 0.000828699\n",
      "Epoch 232, Step 10, LR: 0.000080, Current Loss: 0.6038, Avg Loss: 0.5994\n",
      "Diff stats — min: -7.3989, max: 8.5362, mean: 0.3863, std: 0.8775\n",
      "\n",
      "Step 2548 — Test metrics:\n",
      "  precision@10: 0.002219873\n",
      "  recall@10: 0.002221341\n",
      "  ndcg@10: 0.002536670\n",
      "  map@10: 0.000835888\n",
      "Epoch 232 completed, Train Loss: 0.5993\n",
      "Epoch 233, Step 1, LR: 0.000080, Current Loss: 0.6029, Avg Loss: 0.6029\n",
      "Diff stats — min: -3.2091, max: 6.1382, mean: 0.3868, std: 0.8721\n",
      "\n",
      "Step 2550 — Test metrics:\n",
      "  precision@10: 0.002233087\n",
      "  recall@10: 0.002234555\n",
      "  ndcg@10: 0.002536234\n",
      "  map@10: 0.000831842\n",
      "Epoch 233, Step 10, LR: 0.000080, Current Loss: 0.6008, Avg Loss: 0.5991\n",
      "Diff stats — min: -5.9620, max: 6.8622, mean: 0.3967, std: 0.8837\n",
      "\n",
      "Step 2559 — Test metrics:\n",
      "  precision@10: 0.002200053\n",
      "  recall@10: 0.002201521\n",
      "  ndcg@10: 0.002484121\n",
      "  map@10: 0.000811107\n",
      "Epoch 233 completed, Train Loss: 0.5994\n",
      "Epoch 234, Step 1, LR: 0.000080, Current Loss: 0.5980, Avg Loss: 0.5980\n",
      "Diff stats — min: -4.7670, max: 5.2551, mean: 0.4005, std: 0.8763\n",
      "\n",
      "Step 2561 — Test metrics:\n",
      "  precision@10: 0.002206660\n",
      "  recall@10: 0.002208128\n",
      "  ndcg@10: 0.002486883\n",
      "  map@10: 0.000810997\n",
      "Epoch 234, Step 10, LR: 0.000080, Current Loss: 0.5976, Avg Loss: 0.5982\n",
      "Diff stats — min: -3.7099, max: 4.9918, mean: 0.4032, std: 0.8806\n",
      "\n",
      "Step 2570 — Test metrics:\n",
      "  precision@10: 0.002239693\n",
      "  recall@10: 0.002241162\n",
      "  ndcg@10: 0.002563790\n",
      "  map@10: 0.000846883\n",
      "Epoch 234 completed, Train Loss: 0.5982\n",
      "Epoch 235, Step 1, LR: 0.000080, Current Loss: 0.5976, Avg Loss: 0.5976\n",
      "Diff stats — min: -4.2949, max: 8.6527, mean: 0.4055, std: 0.8873\n",
      "\n",
      "Step 2572 — Test metrics:\n",
      "  precision@10: 0.002246300\n",
      "  recall@10: 0.002247768\n",
      "  ndcg@10: 0.002578088\n",
      "  map@10: 0.000853259\n",
      "Epoch 235, Step 10, LR: 0.000080, Current Loss: 0.5987, Avg Loss: 0.5969\n",
      "Diff stats — min: -5.2501, max: 5.3277, mean: 0.4014, std: 0.8820\n",
      "\n",
      "Step 2581 — Test metrics:\n",
      "  precision@10: 0.002252907\n",
      "  recall@10: 0.002254375\n",
      "  ndcg@10: 0.002597297\n",
      "  map@10: 0.000862236\n",
      "Epoch 235 completed, Train Loss: 0.5971\n",
      "Epoch 236, Step 1, LR: 0.000080, Current Loss: 0.5967, Avg Loss: 0.5967\n",
      "Diff stats — min: -3.5555, max: 6.4100, mean: 0.4098, std: 0.8910\n",
      "\n",
      "Step 2583 — Test metrics:\n",
      "  precision@10: 0.002259514\n",
      "  recall@10: 0.002260982\n",
      "  ndcg@10: 0.002614431\n",
      "  map@10: 0.000870822\n",
      "Epoch 236, Step 10, LR: 0.000080, Current Loss: 0.5978, Avg Loss: 0.5966\n",
      "Diff stats — min: -5.1742, max: 5.7766, mean: 0.4083, std: 0.8935\n",
      "\n",
      "Step 2592 — Test metrics:\n",
      "  precision@10: 0.002299154\n",
      "  recall@10: 0.002300623\n",
      "  ndcg@10: 0.002636258\n",
      "  map@10: 0.000870697\n",
      "Epoch 236 completed, Train Loss: 0.5963\n",
      "Epoch 237, Step 1, LR: 0.000080, Current Loss: 0.5959, Avg Loss: 0.5959\n",
      "Diff stats — min: -5.3062, max: 5.2309, mean: 0.4139, std: 0.8957\n",
      "\n",
      "Step 2594 — Test metrics:\n",
      "  precision@10: 0.002292548\n",
      "  recall@10: 0.002294016\n",
      "  ndcg@10: 0.002617356\n",
      "  map@10: 0.000861218\n",
      "Epoch 237, Step 10, LR: 0.000080, Current Loss: 0.5943, Avg Loss: 0.5943\n",
      "Diff stats — min: -3.8006, max: 5.0356, mean: 0.4173, std: 0.8939\n",
      "\n",
      "Step 2603 — Test metrics:\n",
      "  precision@10: 0.002318975\n",
      "  recall@10: 0.002320443\n",
      "  ndcg@10: 0.002654595\n",
      "  map@10: 0.000874856\n",
      "Epoch 237 completed, Train Loss: 0.5943\n",
      "Epoch 238, Step 1, LR: 0.000080, Current Loss: 0.5915, Avg Loss: 0.5915\n",
      "Diff stats — min: -4.0163, max: 5.2976, mean: 0.4239, std: 0.8935\n",
      "\n",
      "Step 2605 — Test metrics:\n",
      "  precision@10: 0.002312368\n",
      "  recall@10: 0.002313836\n",
      "  ndcg@10: 0.002670299\n",
      "  map@10: 0.000885792\n",
      "Epoch 238, Step 10, LR: 0.000080, Current Loss: 0.5936, Avg Loss: 0.5932\n",
      "Diff stats — min: -4.0613, max: 5.5825, mean: 0.4235, std: 0.9035\n",
      "\n",
      "Step 2614 — Test metrics:\n",
      "  precision@10: 0.002305761\n",
      "  recall@10: 0.002307229\n",
      "  ndcg@10: 0.002688841\n",
      "  map@10: 0.000898306\n",
      "Epoch 238 completed, Train Loss: 0.5931\n",
      "Epoch 239, Step 1, LR: 0.000080, Current Loss: 0.5945, Avg Loss: 0.5945\n",
      "Diff stats — min: -3.9641, max: 9.4536, mean: 0.4191, std: 0.8995\n",
      "\n",
      "Step 2616 — Test metrics:\n",
      "  precision@10: 0.002345402\n",
      "  recall@10: 0.002346870\n",
      "  ndcg@10: 0.002729350\n",
      "  map@10: 0.000911260\n",
      "Epoch 239, Step 10, LR: 0.000080, Current Loss: 0.5939, Avg Loss: 0.5936\n",
      "Diff stats — min: -3.9246, max: 7.8998, mean: 0.4212, std: 0.9005\n",
      "\n",
      "Step 2625 — Test metrics:\n",
      "  precision@10: 0.002398256\n",
      "  recall@10: 0.002399724\n",
      "  ndcg@10: 0.002812105\n",
      "  map@10: 0.000945025\n",
      "Epoch 239 completed, Train Loss: 0.5936\n",
      "Epoch 240, Step 1, LR: 0.000080, Current Loss: 0.5936, Avg Loss: 0.5936\n",
      "Diff stats — min: -5.4022, max: 8.5183, mean: 0.4221, std: 0.9018\n",
      "\n",
      "Step 2627 — Test metrics:\n",
      "  precision@10: 0.002411469\n",
      "  recall@10: 0.002412938\n",
      "  ndcg@10: 0.002815306\n",
      "  map@10: 0.000943187\n",
      "Epoch 240, Step 10, LR: 0.000080, Current Loss: 0.5935, Avg Loss: 0.5926\n",
      "Diff stats — min: -4.3330, max: 5.3155, mean: 0.4260, std: 0.9086\n",
      "\n",
      "Step 2636 — Test metrics:\n",
      "  precision@10: 0.002365222\n",
      "  recall@10: 0.002365956\n",
      "  ndcg@10: 0.002753741\n",
      "  map@10: 0.000919266\n",
      "Epoch 240 completed, Train Loss: 0.5927\n",
      "Epoch 241, Step 1, LR: 0.000080, Current Loss: 0.5923, Avg Loss: 0.5923\n",
      "Diff stats — min: -4.4139, max: 5.6094, mean: 0.4254, std: 0.9019\n",
      "\n",
      "Step 2638 — Test metrics:\n",
      "  precision@10: 0.002365222\n",
      "  recall@10: 0.002365956\n",
      "  ndcg@10: 0.002755807\n",
      "  map@10: 0.000920653\n",
      "Epoch 241, Step 10, LR: 0.000080, Current Loss: 0.5923, Avg Loss: 0.5918\n",
      "Diff stats — min: -4.9593, max: 5.7230, mean: 0.4289, std: 0.9087\n",
      "\n",
      "Step 2647 — Test metrics:\n",
      "  precision@10: 0.002404863\n",
      "  recall@10: 0.002405597\n",
      "  ndcg@10: 0.002798231\n",
      "  map@10: 0.000933846\n",
      "Epoch 241 completed, Train Loss: 0.5916\n",
      "Epoch 242, Step 1, LR: 0.000080, Current Loss: 0.5886, Avg Loss: 0.5886\n",
      "Diff stats — min: -5.0691, max: 5.1409, mean: 0.4400, std: 0.9132\n",
      "\n",
      "Step 2649 — Test metrics:\n",
      "  precision@10: 0.002411469\n",
      "  recall@10: 0.002412203\n",
      "  ndcg@10: 0.002814745\n",
      "  map@10: 0.000941544\n",
      "Epoch 242, Step 10, LR: 0.000080, Current Loss: 0.5885, Avg Loss: 0.5901\n",
      "Diff stats — min: -7.3768, max: 5.8586, mean: 0.4403, std: 0.9143\n",
      "\n",
      "Step 2658 — Test metrics:\n",
      "  precision@10: 0.002470930\n",
      "  recall@10: 0.002472398\n",
      "  ndcg@10: 0.002885886\n",
      "  map@10: 0.000965901\n",
      "Epoch 242 completed, Train Loss: 0.5901\n",
      "Epoch 243, Step 1, LR: 0.000080, Current Loss: 0.5872, Avg Loss: 0.5872\n",
      "Diff stats — min: -7.9145, max: 5.4154, mean: 0.4434, std: 0.9132\n",
      "\n",
      "Step 2660 — Test metrics:\n",
      "  precision@10: 0.002484144\n",
      "  recall@10: 0.002485612\n",
      "  ndcg@10: 0.002892763\n",
      "  map@10: 0.000965975\n",
      "Epoch 243, Step 10, LR: 0.000080, Current Loss: 0.5866, Avg Loss: 0.5895\n",
      "Diff stats — min: -4.3182, max: 5.9433, mean: 0.4465, std: 0.9172\n",
      "\n",
      "Step 2669 — Test metrics:\n",
      "  precision@10: 0.002451110\n",
      "  recall@10: 0.002452578\n",
      "  ndcg@10: 0.002855333\n",
      "  map@10: 0.000953241\n",
      "Epoch 243 completed, Train Loss: 0.5894\n",
      "Epoch 244, Step 1, LR: 0.000080, Current Loss: 0.5879, Avg Loss: 0.5879\n",
      "Diff stats — min: -3.8776, max: 6.6813, mean: 0.4450, std: 0.9202\n",
      "\n",
      "Step 2671 — Test metrics:\n",
      "  precision@10: 0.002451110\n",
      "  recall@10: 0.002452578\n",
      "  ndcg@10: 0.002858708\n",
      "  map@10: 0.000955546\n",
      "Epoch 244, Step 10, LR: 0.000080, Current Loss: 0.5870, Avg Loss: 0.5889\n",
      "Diff stats — min: -5.3837, max: 7.6803, mean: 0.4484, std: 0.9235\n",
      "\n",
      "Step 2680 — Test metrics:\n",
      "  precision@10: 0.002424683\n",
      "  recall@10: 0.002426151\n",
      "  ndcg@10: 0.002799145\n",
      "  map@10: 0.000928518\n",
      "Epoch 244 completed, Train Loss: 0.5888\n",
      "Epoch 245, Step 1, LR: 0.000080, Current Loss: 0.5858, Avg Loss: 0.5858\n",
      "Diff stats — min: -5.7163, max: 6.2763, mean: 0.4499, std: 0.9217\n",
      "\n",
      "Step 2682 — Test metrics:\n",
      "  precision@10: 0.002404863\n",
      "  recall@10: 0.002405597\n",
      "  ndcg@10: 0.002794991\n",
      "  map@10: 0.000930629\n",
      "Epoch 245, Step 10, LR: 0.000080, Current Loss: 0.5857, Avg Loss: 0.5869\n",
      "Diff stats — min: -6.0513, max: 5.5135, mean: 0.4525, std: 0.9253\n",
      "\n",
      "Step 2691 — Test metrics:\n",
      "  precision@10: 0.002470930\n",
      "  recall@10: 0.002471664\n",
      "  ndcg@10: 0.002891409\n",
      "  map@10: 0.000968007\n",
      "Epoch 245 completed, Train Loss: 0.5870\n",
      "Epoch 246, Step 1, LR: 0.000080, Current Loss: 0.5864, Avg Loss: 0.5864\n",
      "Diff stats — min: -3.8868, max: 6.7784, mean: 0.4524, std: 0.9291\n",
      "\n",
      "Step 2693 — Test metrics:\n",
      "  precision@10: 0.002490751\n",
      "  recall@10: 0.002491485\n",
      "  ndcg@10: 0.002920932\n",
      "  map@10: 0.000980232\n",
      "Epoch 246, Step 10, LR: 0.000080, Current Loss: 0.5831, Avg Loss: 0.5857\n",
      "Diff stats — min: -5.0572, max: 5.0990, mean: 0.4593, std: 0.9251\n",
      "\n",
      "Step 2702 — Test metrics:\n",
      "  precision@10: 0.002536998\n",
      "  recall@10: 0.002537732\n",
      "  ndcg@10: 0.002961474\n",
      "  map@10: 0.000990105\n",
      "Epoch 246 completed, Train Loss: 0.5857\n",
      "Epoch 247, Step 1, LR: 0.000080, Current Loss: 0.5820, Avg Loss: 0.5820\n",
      "Diff stats — min: -7.8224, max: 6.0844, mean: 0.4624, std: 0.9279\n",
      "\n",
      "Step 2704 — Test metrics:\n",
      "  precision@10: 0.002543605\n",
      "  recall@10: 0.002544339\n",
      "  ndcg@10: 0.002963118\n",
      "  map@10: 0.000990024\n",
      "Epoch 247, Step 10, LR: 0.000080, Current Loss: 0.5843, Avg Loss: 0.5850\n",
      "Diff stats — min: -8.2852, max: 6.7674, mean: 0.4594, std: 0.9325\n",
      "\n",
      "Step 2713 — Test metrics:\n",
      "  precision@10: 0.002583245\n",
      "  recall@10: 0.002584713\n",
      "  ndcg@10: 0.003031093\n",
      "  map@10: 0.001017182\n",
      "Epoch 247 completed, Train Loss: 0.5849\n",
      "Epoch 248, Step 1, LR: 0.000080, Current Loss: 0.5804, Avg Loss: 0.5804\n",
      "Diff stats — min: -4.1747, max: 5.8749, mean: 0.4684, std: 0.9301\n",
      "\n",
      "Step 2715 — Test metrics:\n",
      "  precision@10: 0.002596459\n",
      "  recall@10: 0.002597927\n",
      "  ndcg@10: 0.003040024\n",
      "  map@10: 0.001018981\n",
      "Epoch 248, Step 10, LR: 0.000080, Current Loss: 0.5850, Avg Loss: 0.5843\n",
      "Diff stats — min: -4.6607, max: 8.8906, mean: 0.4595, std: 0.9373\n",
      "\n",
      "Step 2724 — Test metrics:\n",
      "  precision@10: 0.002517178\n",
      "  recall@10: 0.002517912\n",
      "  ndcg@10: 0.002960407\n",
      "  map@10: 0.000994219\n",
      "Epoch 248 completed, Train Loss: 0.5846\n",
      "Epoch 249, Step 1, LR: 0.000080, Current Loss: 0.5823, Avg Loss: 0.5823\n",
      "Diff stats — min: -5.1620, max: 6.2686, mean: 0.4690, std: 0.9430\n",
      "\n",
      "Step 2726 — Test metrics:\n",
      "  precision@10: 0.002517178\n",
      "  recall@10: 0.002517912\n",
      "  ndcg@10: 0.002971554\n",
      "  map@10: 0.001000823\n",
      "Epoch 249, Step 10, LR: 0.000080, Current Loss: 0.5862, Avg Loss: 0.5838\n",
      "Diff stats — min: -5.0958, max: 5.1155, mean: 0.4597, std: 0.9423\n",
      "\n",
      "Step 2735 — Test metrics:\n",
      "  precision@10: 0.002596459\n",
      "  recall@10: 0.002597193\n",
      "  ndcg@10: 0.003052779\n",
      "  map@10: 0.001028201\n",
      "Epoch 249 completed, Train Loss: 0.5836\n",
      "Epoch 250, Step 1, LR: 0.000080, Current Loss: 0.5824, Avg Loss: 0.5824\n",
      "Diff stats — min: -3.5508, max: 9.7161, mean: 0.4686, std: 0.9426\n",
      "\n",
      "Step 2737 — Test metrics:\n",
      "  precision@10: 0.002616279\n",
      "  recall@10: 0.002617747\n",
      "  ndcg@10: 0.003079595\n",
      "  map@10: 0.001038654\n",
      "Epoch 250, Step 10, LR: 0.000080, Current Loss: 0.5777, Avg Loss: 0.5820\n",
      "Diff stats — min: -3.5712, max: 6.6470, mean: 0.4860, std: 0.9542\n",
      "\n",
      "Step 2746 — Test metrics:\n",
      "  precision@10: 0.002596459\n",
      "  recall@10: 0.002597193\n",
      "  ndcg@10: 0.003097690\n",
      "  map@10: 0.001053615\n",
      "Epoch 250 completed, Train Loss: 0.5819\n",
      "Epoch 251, Step 1, LR: 0.000080, Current Loss: 0.5793, Avg Loss: 0.5793\n",
      "Diff stats — min: -3.3593, max: 5.2871, mean: 0.4760, std: 0.9402\n",
      "\n",
      "Step 2748 — Test metrics:\n",
      "  precision@10: 0.002603066\n",
      "  recall@10: 0.002603800\n",
      "  ndcg@10: 0.003075183\n",
      "  map@10: 0.001037886\n",
      "Epoch 251, Step 10, LR: 0.000080, Current Loss: 0.5764, Avg Loss: 0.5808\n",
      "Diff stats — min: -4.0374, max: 5.6299, mean: 0.4872, std: 0.9496\n",
      "\n",
      "Step 2757 — Test metrics:\n",
      "  precision@10: 0.002616279\n",
      "  recall@10: 0.002617013\n",
      "  ndcg@10: 0.003093579\n",
      "  map@10: 0.001045376\n",
      "Epoch 251 completed, Train Loss: 0.5811\n",
      "Epoch 252, Step 1, LR: 0.000080, Current Loss: 0.5773, Avg Loss: 0.5773\n",
      "Diff stats — min: -4.6905, max: 5.9554, mean: 0.4868, std: 0.9531\n",
      "\n",
      "Step 2759 — Test metrics:\n",
      "  precision@10: 0.002642706\n",
      "  recall@10: 0.002643440\n",
      "  ndcg@10: 0.003115784\n",
      "  map@10: 0.001051399\n",
      "Epoch 252, Step 10, LR: 0.000080, Current Loss: 0.5773, Avg Loss: 0.5796\n",
      "Diff stats — min: -5.7479, max: 6.0986, mean: 0.4868, std: 0.9532\n",
      "\n",
      "Step 2768 — Test metrics:\n",
      "  precision@10: 0.002649313\n",
      "  recall@10: 0.002650047\n",
      "  ndcg@10: 0.003156065\n",
      "  map@10: 0.001071699\n",
      "Epoch 252 completed, Train Loss: 0.5797\n",
      "Epoch 253, Step 1, LR: 0.000080, Current Loss: 0.5783, Avg Loss: 0.5783\n",
      "Diff stats — min: -4.3898, max: 5.6649, mean: 0.4821, std: 0.9491\n",
      "\n",
      "Step 2770 — Test metrics:\n",
      "  precision@10: 0.002669133\n",
      "  recall@10: 0.002669867\n",
      "  ndcg@10: 0.003174111\n",
      "  map@10: 0.001076756\n",
      "Epoch 253, Step 10, LR: 0.000080, Current Loss: 0.5766, Avg Loss: 0.5796\n",
      "Diff stats — min: -4.4370, max: 5.9365, mean: 0.4908, std: 0.9585\n",
      "\n",
      "Step 2779 — Test metrics:\n",
      "  precision@10: 0.002702167\n",
      "  recall@10: 0.002702901\n",
      "  ndcg@10: 0.003182563\n",
      "  map@10: 0.001072174\n",
      "Epoch 253 completed, Train Loss: 0.5793\n",
      "Epoch 254, Step 1, LR: 0.000080, Current Loss: 0.5804, Avg Loss: 0.5804\n",
      "Diff stats — min: -3.6476, max: 7.3385, mean: 0.4847, std: 0.9660\n",
      "\n",
      "Step 2781 — Test metrics:\n",
      "  precision@10: 0.002702167\n",
      "  recall@10: 0.002702901\n",
      "  ndcg@10: 0.003190148\n",
      "  map@10: 0.001076743\n",
      "Epoch 254, Step 10, LR: 0.000080, Current Loss: 0.5733, Avg Loss: 0.5781\n",
      "Diff stats — min: -4.5234, max: 6.1471, mean: 0.4969, std: 0.9529\n",
      "\n",
      "Step 2790 — Test metrics:\n",
      "  precision@10: 0.002695560\n",
      "  recall@10: 0.002696294\n",
      "  ndcg@10: 0.003198947\n",
      "  map@10: 0.001084776\n",
      "Epoch 254 completed, Train Loss: 0.5782\n",
      "Epoch 255, Step 1, LR: 0.000080, Current Loss: 0.5807, Avg Loss: 0.5807\n",
      "Diff stats — min: -7.2970, max: 6.0049, mean: 0.4857, std: 0.9689\n",
      "\n",
      "Step 2792 — Test metrics:\n",
      "  precision@10: 0.002695560\n",
      "  recall@10: 0.002696294\n",
      "  ndcg@10: 0.003192284\n",
      "  map@10: 0.001080689\n",
      "Epoch 255, Step 10, LR: 0.000080, Current Loss: 0.5746, Avg Loss: 0.5775\n",
      "Diff stats — min: -4.4847, max: 5.6675, mean: 0.5003, std: 0.9674\n",
      "\n",
      "Step 2801 — Test metrics:\n",
      "  precision@10: 0.002695560\n",
      "  recall@10: 0.002696294\n",
      "  ndcg@10: 0.003209245\n",
      "  map@10: 0.001090502\n",
      "Epoch 255 completed, Train Loss: 0.5774\n",
      "Epoch 256, Step 1, LR: 0.000080, Current Loss: 0.5761, Avg Loss: 0.5761\n",
      "Diff stats — min: -4.0696, max: 7.7297, mean: 0.4981, std: 0.9714\n",
      "\n",
      "Step 2803 — Test metrics:\n",
      "  precision@10: 0.002695560\n",
      "  recall@10: 0.002696294\n",
      "  ndcg@10: 0.003201784\n",
      "  map@10: 0.001086244\n",
      "Epoch 256, Step 10, LR: 0.000080, Current Loss: 0.5736, Avg Loss: 0.5762\n",
      "Diff stats — min: -4.7164, max: 6.7688, mean: 0.5040, std: 0.9700\n",
      "\n",
      "Step 2812 — Test metrics:\n",
      "  precision@10: 0.002768235\n",
      "  recall@10: 0.002768969\n",
      "  ndcg@10: 0.003233123\n",
      "  map@10: 0.001084540\n",
      "Epoch 256 completed, Train Loss: 0.5761\n",
      "Epoch 257, Step 1, LR: 0.000080, Current Loss: 0.5734, Avg Loss: 0.5734\n",
      "Diff stats — min: -3.7347, max: 9.9068, mean: 0.5063, std: 0.9739\n",
      "\n",
      "Step 2814 — Test metrics:\n",
      "  precision@10: 0.002774841\n",
      "  recall@10: 0.002775576\n",
      "  ndcg@10: 0.003224481\n",
      "  map@10: 0.001076832\n",
      "Epoch 257, Step 10, LR: 0.000080, Current Loss: 0.5760, Avg Loss: 0.5752\n",
      "Diff stats — min: -4.4332, max: 6.4667, mean: 0.5012, std: 0.9760\n",
      "\n",
      "Step 2823 — Test metrics:\n",
      "  precision@10: 0.002827696\n",
      "  recall@10: 0.002828430\n",
      "  ndcg@10: 0.003255179\n",
      "  map@10: 0.001079145\n",
      "Epoch 257 completed, Train Loss: 0.5757\n",
      "Epoch 258, Step 1, LR: 0.000080, Current Loss: 0.5785, Avg Loss: 0.5785\n",
      "Diff stats — min: -5.9408, max: 6.5257, mean: 0.4958, std: 0.9783\n",
      "\n",
      "Step 2825 — Test metrics:\n",
      "  precision@10: 0.002827696\n",
      "  recall@10: 0.002828430\n",
      "  ndcg@10: 0.003273594\n",
      "  map@10: 0.001089732\n",
      "Epoch 258, Step 10, LR: 0.000080, Current Loss: 0.5721, Avg Loss: 0.5750\n",
      "Diff stats — min: -4.2436, max: 5.8500, mean: 0.5128, std: 0.9782\n",
      "\n",
      "Step 2834 — Test metrics:\n",
      "  precision@10: 0.002814482\n",
      "  recall@10: 0.002815216\n",
      "  ndcg@10: 0.003291212\n",
      "  map@10: 0.001103967\n",
      "Epoch 258 completed, Train Loss: 0.5750\n",
      "Epoch 259, Step 1, LR: 0.000080, Current Loss: 0.5776, Avg Loss: 0.5776\n",
      "Diff stats — min: -4.5094, max: 6.6208, mean: 0.4991, std: 0.9795\n",
      "\n",
      "Step 2836 — Test metrics:\n",
      "  precision@10: 0.002794662\n",
      "  recall@10: 0.002795396\n",
      "  ndcg@10: 0.003282990\n",
      "  map@10: 0.001105014\n",
      "Epoch 259, Step 10, LR: 0.000080, Current Loss: 0.5698, Avg Loss: 0.5737\n",
      "Diff stats — min: -3.8582, max: 6.4051, mean: 0.5228, std: 0.9886\n",
      "\n",
      "Step 2845 — Test metrics:\n",
      "  precision@10: 0.002840909\n",
      "  recall@10: 0.002841643\n",
      "  ndcg@10: 0.003406385\n",
      "  map@10: 0.001165188\n",
      "Epoch 259 completed, Train Loss: 0.5735\n",
      "Epoch 260, Step 1, LR: 0.000080, Current Loss: 0.5724, Avg Loss: 0.5724\n",
      "Diff stats — min: -4.2414, max: 6.2480, mean: 0.5169, std: 0.9888\n",
      "\n",
      "Step 2847 — Test metrics:\n",
      "  precision@10: 0.002834302\n",
      "  recall@10: 0.002835036\n",
      "  ndcg@10: 0.003403758\n",
      "  map@10: 0.001165783\n",
      "Epoch 260, Step 10, LR: 0.000080, Current Loss: 0.5737, Avg Loss: 0.5726\n",
      "Diff stats — min: -4.1369, max: 5.7421, mean: 0.5141, std: 0.9894\n",
      "\n",
      "Step 2856 — Test metrics:\n",
      "  precision@10: 0.002840909\n",
      "  recall@10: 0.002841643\n",
      "  ndcg@10: 0.003391485\n",
      "  map@10: 0.001156020\n",
      "Epoch 260 completed, Train Loss: 0.5724\n",
      "Epoch 261, Step 1, LR: 0.000080, Current Loss: 0.5696, Avg Loss: 0.5696\n",
      "Diff stats — min: -4.9339, max: 7.6673, mean: 0.5232, std: 0.9884\n",
      "\n",
      "Step 2858 — Test metrics:\n",
      "  precision@10: 0.002847516\n",
      "  recall@10: 0.002848250\n",
      "  ndcg@10: 0.003395403\n",
      "  map@10: 0.001156455\n",
      "Epoch 261, Step 10, LR: 0.000080, Current Loss: 0.5713, Avg Loss: 0.5716\n",
      "Diff stats — min: -6.7593, max: 5.3585, mean: 0.5209, std: 0.9910\n",
      "\n",
      "Step 2867 — Test metrics:\n",
      "  precision@10: 0.002860729\n",
      "  recall@10: 0.002861463\n",
      "  ndcg@10: 0.003399546\n",
      "  map@10: 0.001154525\n",
      "Epoch 261 completed, Train Loss: 0.5714\n",
      "Epoch 262, Step 1, LR: 0.000080, Current Loss: 0.5679, Avg Loss: 0.5679\n",
      "Diff stats — min: -3.6546, max: 6.1371, mean: 0.5308, std: 0.9939\n",
      "\n",
      "Step 2869 — Test metrics:\n",
      "  precision@10: 0.002880550\n",
      "  recall@10: 0.002881284\n",
      "  ndcg@10: 0.003405484\n",
      "  map@10: 0.001153516\n",
      "Epoch 262, Step 10, LR: 0.000080, Current Loss: 0.5725, Avg Loss: 0.5699\n",
      "Diff stats — min: -6.8727, max: 11.6975, mean: 0.5237, std: 1.0044\n",
      "\n",
      "Step 2878 — Test metrics:\n",
      "  precision@10: 0.002860729\n",
      "  recall@10: 0.002861463\n",
      "  ndcg@10: 0.003351182\n",
      "  map@10: 0.001126675\n",
      "Epoch 262 completed, Train Loss: 0.5702\n",
      "Epoch 263, Step 1, LR: 0.000080, Current Loss: 0.5729, Avg Loss: 0.5729\n",
      "Diff stats — min: -4.2044, max: 5.7027, mean: 0.5222, std: 1.0028\n",
      "\n",
      "Step 2880 — Test metrics:\n",
      "  precision@10: 0.002873943\n",
      "  recall@10: 0.002874677\n",
      "  ndcg@10: 0.003358206\n",
      "  map@10: 0.001127173\n",
      "Epoch 263, Step 10, LR: 0.000080, Current Loss: 0.5678, Avg Loss: 0.5698\n",
      "Diff stats — min: -4.5070, max: 5.6188, mean: 0.5374, std: 1.0075\n",
      "\n",
      "Step 2889 — Test metrics:\n",
      "  precision@10: 0.002906977\n",
      "  recall@10: 0.002907711\n",
      "  ndcg@10: 0.003464130\n",
      "  map@10: 0.001179717\n",
      "Epoch 263 completed, Train Loss: 0.5697\n",
      "Epoch 264, Step 1, LR: 0.000080, Current Loss: 0.5683, Avg Loss: 0.5683\n",
      "Diff stats — min: -4.6738, max: 6.6319, mean: 0.5371, std: 1.0085\n",
      "\n",
      "Step 2891 — Test metrics:\n",
      "  precision@10: 0.002900370\n",
      "  recall@10: 0.002901104\n",
      "  ndcg@10: 0.003470443\n",
      "  map@10: 0.001185167\n",
      "Epoch 264, Step 10, LR: 0.000080, Current Loss: 0.5690, Avg Loss: 0.5690\n",
      "Diff stats — min: -4.7031, max: 6.4632, mean: 0.5337, std: 1.0049\n",
      "\n",
      "Step 2900 — Test metrics:\n",
      "  precision@10: 0.002906977\n",
      "  recall@10: 0.002907711\n",
      "  ndcg@10: 0.003421862\n",
      "  map@10: 0.001154905\n",
      "Epoch 264 completed, Train Loss: 0.5687\n",
      "Epoch 265, Step 1, LR: 0.000080, Current Loss: 0.5732, Avg Loss: 0.5732\n",
      "Diff stats — min: -5.5522, max: 5.6577, mean: 0.5213, std: 1.0016\n",
      "\n",
      "Step 2902 — Test metrics:\n",
      "  precision@10: 0.002893763\n",
      "  recall@10: 0.002894497\n",
      "  ndcg@10: 0.003414491\n",
      "  map@10: 0.001154302\n",
      "Epoch 265, Step 10, LR: 0.000080, Current Loss: 0.5655, Avg Loss: 0.5679\n",
      "Diff stats — min: -4.6033, max: 9.1100, mean: 0.5450, std: 1.0101\n",
      "\n",
      "Step 2911 — Test metrics:\n",
      "  precision@10: 0.002920190\n",
      "  recall@10: 0.002920924\n",
      "  ndcg@10: 0.003426750\n",
      "  map@10: 0.001153114\n",
      "Epoch 265 completed, Train Loss: 0.5678\n",
      "Epoch 266, Step 1, LR: 0.000080, Current Loss: 0.5677, Avg Loss: 0.5677\n",
      "Diff stats — min: -4.3863, max: 7.5770, mean: 0.5379, std: 1.0069\n",
      "\n",
      "Step 2913 — Test metrics:\n",
      "  precision@10: 0.002906977\n",
      "  recall@10: 0.002907711\n",
      "  ndcg@10: 0.003431705\n",
      "  map@10: 0.001159167\n",
      "Epoch 266, Step 10, LR: 0.000080, Current Loss: 0.5668, Avg Loss: 0.5665\n",
      "Diff stats — min: -4.8846, max: 5.6011, mean: 0.5445, std: 1.0149\n",
      "\n",
      "Step 2922 — Test metrics:\n",
      "  precision@10: 0.002933404\n",
      "  recall@10: 0.002934138\n",
      "  ndcg@10: 0.003516010\n",
      "  map@10: 0.001200673\n",
      "Epoch 266 completed, Train Loss: 0.5666\n",
      "Epoch 267, Step 1, LR: 0.000080, Current Loss: 0.5626, Avg Loss: 0.5626\n",
      "Diff stats — min: -4.3214, max: 7.2106, mean: 0.5550, std: 1.0148\n",
      "\n",
      "Step 2924 — Test metrics:\n",
      "  precision@10: 0.002933404\n",
      "  recall@10: 0.002934138\n",
      "  ndcg@10: 0.003516351\n",
      "  map@10: 0.001201103\n",
      "Epoch 267, Step 10, LR: 0.000080, Current Loss: 0.5650, Avg Loss: 0.5657\n",
      "Diff stats — min: -4.3066, max: 6.2928, mean: 0.5501, std: 1.0175\n",
      "\n",
      "Step 2933 — Test metrics:\n",
      "  precision@10: 0.002986258\n",
      "  recall@10: 0.002986992\n",
      "  ndcg@10: 0.003572351\n",
      "  map@10: 0.001219387\n",
      "Epoch 267 completed, Train Loss: 0.5656\n",
      "Epoch 268, Step 1, LR: 0.000080, Current Loss: 0.5673, Avg Loss: 0.5673\n",
      "Diff stats — min: -4.0478, max: 5.6666, mean: 0.5458, std: 1.0208\n",
      "\n",
      "Step 2935 — Test metrics:\n",
      "  precision@10: 0.002992865\n",
      "  recall@10: 0.002993599\n",
      "  ndcg@10: 0.003573505\n",
      "  map@10: 0.001219156\n",
      "Epoch 268, Step 10, LR: 0.000080, Current Loss: 0.5613, Avg Loss: 0.5655\n",
      "Diff stats — min: -3.8224, max: 6.0648, mean: 0.5624, std: 1.0215\n",
      "\n",
      "Step 2944 — Test metrics:\n",
      "  precision@10: 0.002992865\n",
      "  recall@10: 0.002993599\n",
      "  ndcg@10: 0.003565896\n",
      "  map@10: 0.001214167\n",
      "Epoch 268 completed, Train Loss: 0.5654\n",
      "Epoch 269, Step 1, LR: 0.000080, Current Loss: 0.5626, Avg Loss: 0.5626\n",
      "Diff stats — min: -5.2453, max: 7.5025, mean: 0.5590, std: 1.0227\n",
      "\n",
      "Step 2946 — Test metrics:\n",
      "  precision@10: 0.002979651\n",
      "  recall@10: 0.002980385\n",
      "  ndcg@10: 0.003547406\n",
      "  map@10: 0.001206863\n",
      "Epoch 269, Step 10, LR: 0.000080, Current Loss: 0.5647, Avg Loss: 0.5636\n",
      "Diff stats — min: -4.2434, max: 9.8866, mean: 0.5591, std: 1.0330\n",
      "\n",
      "Step 2955 — Test metrics:\n",
      "  precision@10: 0.003025899\n",
      "  recall@10: 0.003026633\n",
      "  ndcg@10: 0.003593901\n",
      "  map@10: 0.001220226\n",
      "Epoch 269 completed, Train Loss: 0.5636\n",
      "Epoch 270, Step 1, LR: 0.000080, Current Loss: 0.5603, Avg Loss: 0.5603\n",
      "Diff stats — min: -3.9593, max: 5.5698, mean: 0.5656, std: 1.0247\n",
      "\n",
      "Step 2957 — Test metrics:\n",
      "  precision@10: 0.003012685\n",
      "  recall@10: 0.003013419\n",
      "  ndcg@10: 0.003589071\n",
      "  map@10: 0.001220582\n",
      "Epoch 270, Step 10, LR: 0.000080, Current Loss: 0.5621, Avg Loss: 0.5629\n",
      "Diff stats — min: -4.1514, max: 5.0236, mean: 0.5684, std: 1.0390\n",
      "\n",
      "Step 2966 — Test metrics:\n",
      "  precision@10: 0.003058932\n",
      "  recall@10: 0.003059666\n",
      "  ndcg@10: 0.003659283\n",
      "  map@10: 0.001249657\n",
      "Epoch 270 completed, Train Loss: 0.5628\n",
      "Epoch 271, Step 1, LR: 0.000080, Current Loss: 0.5619, Avg Loss: 0.5619\n",
      "Diff stats — min: -5.2794, max: 5.6908, mean: 0.5672, std: 1.0333\n",
      "\n",
      "Step 2968 — Test metrics:\n",
      "  precision@10: 0.003052326\n",
      "  recall@10: 0.003053060\n",
      "  ndcg@10: 0.003656553\n",
      "  map@10: 0.001249642\n",
      "Epoch 271, Step 10, LR: 0.000080, Current Loss: 0.5628, Avg Loss: 0.5623\n",
      "Diff stats — min: -5.4278, max: 7.1274, mean: 0.5651, std: 1.0355\n",
      "\n",
      "Step 2977 — Test metrics:\n",
      "  precision@10: 0.003045719\n",
      "  recall@10: 0.003046453\n",
      "  ndcg@10: 0.003635636\n",
      "  map@10: 0.001240049\n",
      "Epoch 271 completed, Train Loss: 0.5623\n",
      "Epoch 272, Step 1, LR: 0.000080, Current Loss: 0.5622, Avg Loss: 0.5622\n",
      "Diff stats — min: -4.7209, max: 5.3893, mean: 0.5692, std: 1.0412\n",
      "\n",
      "Step 2979 — Test metrics:\n",
      "  precision@10: 0.003019292\n",
      "  recall@10: 0.003020026\n",
      "  ndcg@10: 0.003614119\n",
      "  map@10: 0.001233987\n",
      "Epoch 272, Step 10, LR: 0.000080, Current Loss: 0.5576, Avg Loss: 0.5613\n",
      "Diff stats — min: -4.4365, max: 7.9304, mean: 0.5823, std: 1.0422\n",
      "\n",
      "Step 2988 — Test metrics:\n",
      "  precision@10: 0.003039112\n",
      "  recall@10: 0.003039846\n",
      "  ndcg@10: 0.003605933\n",
      "  map@10: 0.001223241\n",
      "Epoch 272 completed, Train Loss: 0.5614\n",
      "Epoch 273, Step 1, LR: 0.000080, Current Loss: 0.5629, Avg Loss: 0.5629\n",
      "Diff stats — min: -4.0838, max: 6.2904, mean: 0.5650, std: 1.0345\n",
      "\n",
      "Step 2990 — Test metrics:\n",
      "  precision@10: 0.003052326\n",
      "  recall@10: 0.003053060\n",
      "  ndcg@10: 0.003612856\n",
      "  map@10: 0.001223708\n",
      "Epoch 273, Step 10, LR: 0.000080, Current Loss: 0.5575, Avg Loss: 0.5603\n",
      "Diff stats — min: -3.8939, max: 6.1272, mean: 0.5831, std: 1.0433\n",
      "\n",
      "Step 2999 — Test metrics:\n",
      "  precision@10: 0.003118393\n",
      "  recall@10: 0.003119127\n",
      "  ndcg@10: 0.003677229\n",
      "  map@10: 0.001243821\n",
      "Epoch 273 completed, Train Loss: 0.5601\n",
      "Epoch 274, Step 1, LR: 0.000080, Current Loss: 0.5578, Avg Loss: 0.5578\n",
      "Diff stats — min: -4.3684, max: 7.2940, mean: 0.5830, std: 1.0458\n",
      "\n",
      "Step 3001 — Test metrics:\n",
      "  precision@10: 0.003118393\n",
      "  recall@10: 0.003119127\n",
      "  ndcg@10: 0.003686670\n",
      "  map@10: 0.001249498\n",
      "Epoch 274, Step 10, LR: 0.000080, Current Loss: 0.5581, Avg Loss: 0.5590\n",
      "Diff stats — min: -4.6483, max: 6.3007, mean: 0.5846, std: 1.0496\n",
      "\n",
      "Step 3010 — Test metrics:\n",
      "  precision@10: 0.003138214\n",
      "  recall@10: 0.003138948\n",
      "  ndcg@10: 0.003721602\n",
      "  map@10: 0.001262229\n",
      "Epoch 274 completed, Train Loss: 0.5587\n",
      "Epoch 275, Step 1, LR: 0.000080, Current Loss: 0.5584, Avg Loss: 0.5584\n",
      "Diff stats — min: -7.2426, max: 5.7464, mean: 0.5861, std: 1.0529\n",
      "\n",
      "Step 3012 — Test metrics:\n",
      "  precision@10: 0.003131607\n",
      "  recall@10: 0.003132341\n",
      "  ndcg@10: 0.003724919\n",
      "  map@10: 0.001265993\n",
      "Epoch 275, Step 10, LR: 0.000080, Current Loss: 0.5558, Avg Loss: 0.5577\n",
      "Diff stats — min: -3.6584, max: 6.7872, mean: 0.5936, std: 1.0547\n",
      "\n",
      "Step 3021 — Test metrics:\n",
      "  precision@10: 0.003151427\n",
      "  recall@10: 0.003152161\n",
      "  ndcg@10: 0.003736847\n",
      "  map@10: 0.001267724\n",
      "Epoch 275 completed, Train Loss: 0.5573\n",
      "Epoch 276, Step 1, LR: 0.000080, Current Loss: 0.5575, Avg Loss: 0.5575\n",
      "Diff stats — min: -4.5603, max: 7.6308, mean: 0.5874, std: 1.0518\n",
      "\n",
      "Step 3023 — Test metrics:\n",
      "  precision@10: 0.003158034\n",
      "  recall@10: 0.003158768\n",
      "  ndcg@10: 0.003752997\n",
      "  map@10: 0.001275563\n",
      "Epoch 276, Step 10, LR: 0.000080, Current Loss: 0.5595, Avg Loss: 0.5578\n",
      "Diff stats — min: -4.0422, max: 7.1658, mean: 0.5872, std: 1.0609\n",
      "\n",
      "Step 3032 — Test metrics:\n",
      "  precision@10: 0.003144820\n",
      "  recall@10: 0.003145554\n",
      "  ndcg@10: 0.003747962\n",
      "  map@10: 0.001277380\n",
      "Epoch 276 completed, Train Loss: 0.5578\n",
      "Epoch 277, Step 1, LR: 0.000080, Current Loss: 0.5575, Avg Loss: 0.5575\n",
      "Diff stats — min: -5.3651, max: 6.8427, mean: 0.5953, std: 1.0671\n",
      "\n",
      "Step 3034 — Test metrics:\n",
      "  precision@10: 0.003164641\n",
      "  recall@10: 0.003165375\n",
      "  ndcg@10: 0.003779840\n",
      "  map@10: 0.001291047\n",
      "Epoch 277, Step 10, LR: 0.000080, Current Loss: 0.5542, Avg Loss: 0.5565\n",
      "Diff stats — min: -3.9325, max: 7.9793, mean: 0.6041, std: 1.0684\n",
      "\n",
      "Step 3043 — Test metrics:\n",
      "  precision@10: 0.003197674\n",
      "  recall@10: 0.003198409\n",
      "  ndcg@10: 0.003794344\n",
      "  map@10: 0.001289251\n",
      "Epoch 277 completed, Train Loss: 0.5565\n",
      "Epoch 278, Step 1, LR: 0.000080, Current Loss: 0.5545, Avg Loss: 0.5545\n",
      "Diff stats — min: -4.5927, max: 7.0300, mean: 0.6023, std: 1.0663\n",
      "\n",
      "Step 3045 — Test metrics:\n",
      "  precision@10: 0.003184461\n",
      "  recall@10: 0.003185195\n",
      "  ndcg@10: 0.003790681\n",
      "  map@10: 0.001290533\n",
      "Epoch 278, Step 10, LR: 0.000080, Current Loss: 0.5510, Avg Loss: 0.5555\n",
      "Diff stats — min: -5.4646, max: 6.4525, mean: 0.6123, std: 1.0671\n",
      "\n",
      "Step 3054 — Test metrics:\n",
      "  precision@10: 0.003151427\n",
      "  recall@10: 0.003152161\n",
      "  ndcg@10: 0.003757598\n",
      "  map@10: 0.001280049\n",
      "Epoch 278 completed, Train Loss: 0.5553\n",
      "Epoch 279, Step 1, LR: 0.000080, Current Loss: 0.5546, Avg Loss: 0.5546\n",
      "Diff stats — min: -4.8564, max: 5.8009, mean: 0.6071, std: 1.0736\n",
      "\n",
      "Step 3056 — Test metrics:\n",
      "  precision@10: 0.003184461\n",
      "  recall@10: 0.003185195\n",
      "  ndcg@10: 0.003784144\n",
      "  map@10: 0.001286278\n",
      "Epoch 279, Step 10, LR: 0.000080, Current Loss: 0.5527, Avg Loss: 0.5534\n",
      "Diff stats — min: -5.0940, max: 7.0234, mean: 0.6115, std: 1.0737\n",
      "\n",
      "Step 3065 — Test metrics:\n",
      "  precision@10: 0.003230708\n",
      "  recall@10: 0.003231442\n",
      "  ndcg@10: 0.003871639\n",
      "  map@10: 0.001324497\n",
      "Epoch 279 completed, Train Loss: 0.5534\n",
      "Epoch 280, Step 1, LR: 0.000080, Current Loss: 0.5493, Avg Loss: 0.5493\n",
      "Diff stats — min: -5.8228, max: 5.5566, mean: 0.6153, std: 1.0639\n",
      "\n",
      "Step 3067 — Test metrics:\n",
      "  precision@10: 0.003230708\n",
      "  recall@10: 0.003231442\n",
      "  ndcg@10: 0.003862587\n",
      "  map@10: 0.001319084\n",
      "Epoch 280, Step 10, LR: 0.000080, Current Loss: 0.5541, Avg Loss: 0.5530\n",
      "Diff stats — min: -6.4282, max: 5.7585, mean: 0.6057, std: 1.0685\n",
      "\n",
      "Step 3076 — Test metrics:\n",
      "  precision@10: 0.003263742\n",
      "  recall@10: 0.003264476\n",
      "  ndcg@10: 0.003899766\n",
      "  map@10: 0.001331476\n",
      "Epoch 280 completed, Train Loss: 0.5528\n",
      "Epoch 281, Step 1, LR: 0.000080, Current Loss: 0.5499, Avg Loss: 0.5499\n",
      "Diff stats — min: -3.7708, max: 6.4656, mean: 0.6197, std: 1.0751\n",
      "\n",
      "Step 3078 — Test metrics:\n",
      "  precision@10: 0.003250529\n",
      "  recall@10: 0.003251263\n",
      "  ndcg@10: 0.003883570\n",
      "  map@10: 0.001325981\n",
      "Epoch 281, Step 10, LR: 0.000080, Current Loss: 0.5542, Avg Loss: 0.5518\n",
      "Diff stats — min: -4.4794, max: 5.5883, mean: 0.6137, std: 1.0837\n",
      "\n",
      "Step 3087 — Test metrics:\n",
      "  precision@10: 0.003171247\n",
      "  recall@10: 0.003171981\n",
      "  ndcg@10: 0.003797023\n",
      "  map@10: 0.001296691\n",
      "Epoch 281 completed, Train Loss: 0.5514\n",
      "Epoch 282, Step 1, LR: 0.000080, Current Loss: 0.5479, Avg Loss: 0.5479\n",
      "Diff stats — min: -5.2461, max: 6.5377, mean: 0.6274, std: 1.0791\n",
      "\n",
      "Step 3089 — Test metrics:\n",
      "  precision@10: 0.003171247\n",
      "  recall@10: 0.003171981\n",
      "  ndcg@10: 0.003797999\n",
      "  map@10: 0.001298007\n",
      "Epoch 282, Step 10, LR: 0.000080, Current Loss: 0.5516, Avg Loss: 0.5509\n",
      "Diff stats — min: -4.8570, max: 5.9477, mean: 0.6209, std: 1.0848\n",
      "\n",
      "Step 3098 — Test metrics:\n",
      "  precision@10: 0.003230708\n",
      "  recall@10: 0.003231442\n",
      "  ndcg@10: 0.003830868\n",
      "  map@10: 0.001300619\n",
      "Epoch 282 completed, Train Loss: 0.5513\n",
      "Epoch 283, Step 1, LR: 0.000080, Current Loss: 0.5488, Avg Loss: 0.5488\n",
      "Diff stats — min: -5.7262, max: 5.8923, mean: 0.6247, std: 1.0789\n",
      "\n",
      "Step 3100 — Test metrics:\n",
      "  precision@10: 0.003257135\n",
      "  recall@10: 0.003257869\n",
      "  ndcg@10: 0.003851620\n",
      "  map@10: 0.001305742\n",
      "Epoch 283, Step 10, LR: 0.000080, Current Loss: 0.5464, Avg Loss: 0.5502\n",
      "Diff stats — min: -3.7751, max: 6.4836, mean: 0.6323, std: 1.0809\n",
      "\n",
      "Step 3109 — Test metrics:\n",
      "  precision@10: 0.003283562\n",
      "  recall@10: 0.003284296\n",
      "  ndcg@10: 0.003884163\n",
      "  map@10: 0.001317209\n",
      "Epoch 283 completed, Train Loss: 0.5499\n",
      "Epoch 284, Step 1, LR: 0.000080, Current Loss: 0.5505, Avg Loss: 0.5505\n",
      "Diff stats — min: -4.4037, max: 6.9350, mean: 0.6271, std: 1.0914\n",
      "\n",
      "Step 3111 — Test metrics:\n",
      "  precision@10: 0.003276956\n",
      "  recall@10: 0.003277690\n",
      "  ndcg@10: 0.003879986\n",
      "  map@10: 0.001316506\n",
      "Epoch 284, Step 10, LR: 0.000080, Current Loss: 0.5479, Avg Loss: 0.5498\n",
      "Diff stats — min: -4.1203, max: 5.4255, mean: 0.6346, std: 1.0905\n",
      "\n",
      "Step 3120 — Test metrics:\n",
      "  precision@10: 0.003303383\n",
      "  recall@10: 0.003304117\n",
      "  ndcg@10: 0.003919057\n",
      "  map@10: 0.001330745\n",
      "Epoch 284 completed, Train Loss: 0.5496\n",
      "Epoch 285, Step 1, LR: 0.000080, Current Loss: 0.5467, Avg Loss: 0.5467\n",
      "Diff stats — min: -4.8257, max: 5.6889, mean: 0.6343, std: 1.0852\n",
      "\n",
      "Step 3122 — Test metrics:\n",
      "  precision@10: 0.003323203\n",
      "  recall@10: 0.003323937\n",
      "  ndcg@10: 0.003931700\n",
      "  map@10: 0.001332874\n",
      "Epoch 285, Step 10, LR: 0.000080, Current Loss: 0.5487, Avg Loss: 0.5491\n",
      "Diff stats — min: -4.0578, max: 6.0229, mean: 0.6389, std: 1.1030\n",
      "\n",
      "Step 3131 — Test metrics:\n",
      "  precision@10: 0.003362844\n",
      "  recall@10: 0.003363578\n",
      "  ndcg@10: 0.003930687\n",
      "  map@10: 0.001320423\n",
      "Epoch 285 completed, Train Loss: 0.5490\n",
      "Epoch 286, Step 1, LR: 0.000080, Current Loss: 0.5495, Avg Loss: 0.5495\n",
      "Diff stats — min: -3.9321, max: 5.8605, mean: 0.6362, std: 1.1026\n",
      "\n",
      "Step 3133 — Test metrics:\n",
      "  precision@10: 0.003349630\n",
      "  recall@10: 0.003350364\n",
      "  ndcg@10: 0.003929917\n",
      "  map@10: 0.001322922\n",
      "Epoch 286, Step 10, LR: 0.000080, Current Loss: 0.5487, Avg Loss: 0.5476\n",
      "Diff stats — min: -3.8014, max: 5.7089, mean: 0.6372, std: 1.1002\n",
      "\n",
      "Step 3142 — Test metrics:\n",
      "  precision@10: 0.003382664\n",
      "  recall@10: 0.003383398\n",
      "  ndcg@10: 0.003990684\n",
      "  map@10: 0.001349829\n",
      "Epoch 286 completed, Train Loss: 0.5476\n",
      "Epoch 287, Step 1, LR: 0.000080, Current Loss: 0.5500, Avg Loss: 0.5500\n",
      "Diff stats — min: -4.6086, max: 6.7062, mean: 0.6369, std: 1.1057\n",
      "\n",
      "Step 3144 — Test metrics:\n",
      "  precision@10: 0.003382664\n",
      "  recall@10: 0.003383398\n",
      "  ndcg@10: 0.003986719\n",
      "  map@10: 0.001347710\n",
      "Epoch 287, Step 10, LR: 0.000080, Current Loss: 0.5450, Avg Loss: 0.5462\n",
      "Diff stats — min: -5.7890, max: 7.2442, mean: 0.6485, std: 1.1038\n",
      "\n",
      "Step 3153 — Test metrics:\n",
      "  precision@10: 0.003376057\n",
      "  recall@10: 0.003376791\n",
      "  ndcg@10: 0.003946958\n",
      "  map@10: 0.001326549\n",
      "Epoch 287 completed, Train Loss: 0.5461\n",
      "Epoch 288, Step 1, LR: 0.000080, Current Loss: 0.5437, Avg Loss: 0.5437\n",
      "Diff stats — min: -4.2875, max: 8.7578, mean: 0.6541, std: 1.1077\n",
      "\n",
      "Step 3155 — Test metrics:\n",
      "  precision@10: 0.003376057\n",
      "  recall@10: 0.003376791\n",
      "  ndcg@10: 0.003943484\n",
      "  map@10: 0.001324604\n",
      "Epoch 288, Step 10, LR: 0.000080, Current Loss: 0.5452, Avg Loss: 0.5446\n",
      "Diff stats — min: -7.6675, max: 6.9506, mean: 0.6521, std: 1.1111\n",
      "\n",
      "Step 3164 — Test metrics:\n",
      "  precision@10: 0.003349630\n",
      "  recall@10: 0.003350364\n",
      "  ndcg@10: 0.003955257\n",
      "  map@10: 0.001338954\n",
      "Epoch 288 completed, Train Loss: 0.5447\n",
      "Epoch 289, Step 1, LR: 0.000080, Current Loss: 0.5442, Avg Loss: 0.5442\n",
      "Diff stats — min: -5.0724, max: 7.0880, mean: 0.6553, std: 1.1120\n",
      "\n",
      "Step 3166 — Test metrics:\n",
      "  precision@10: 0.003356237\n",
      "  recall@10: 0.003356971\n",
      "  ndcg@10: 0.003950595\n",
      "  map@10: 0.001333624\n",
      "Epoch 289, Step 10, LR: 0.000080, Current Loss: 0.5451, Avg Loss: 0.5431\n",
      "Diff stats — min: -5.8344, max: 7.0974, mean: 0.6544, std: 1.1148\n",
      "\n",
      "Step 3175 — Test metrics:\n",
      "  precision@10: 0.003395877\n",
      "  recall@10: 0.003396611\n",
      "  ndcg@10: 0.003974930\n",
      "  map@10: 0.001335726\n",
      "Epoch 289 completed, Train Loss: 0.5436\n",
      "Epoch 290, Step 1, LR: 0.000080, Current Loss: 0.5423, Avg Loss: 0.5423\n",
      "Diff stats — min: -5.2912, max: 7.4844, mean: 0.6566, std: 1.1053\n",
      "\n",
      "Step 3177 — Test metrics:\n",
      "  precision@10: 0.003389271\n",
      "  recall@10: 0.003390005\n",
      "  ndcg@10: 0.003969247\n",
      "  map@10: 0.001334839\n",
      "Epoch 290, Step 10, LR: 0.000080, Current Loss: 0.5409, Avg Loss: 0.5431\n",
      "Diff stats — min: -4.3878, max: 5.9936, mean: 0.6610, std: 1.1055\n",
      "\n",
      "Step 3186 — Test metrics:\n",
      "  precision@10: 0.003428911\n",
      "  recall@10: 0.003429645\n",
      "  ndcg@10: 0.004042726\n",
      "  map@10: 0.001366801\n",
      "Epoch 290 completed, Train Loss: 0.5431\n",
      "Epoch 291, Step 1, LR: 0.000080, Current Loss: 0.5408, Avg Loss: 0.5408\n",
      "Diff stats — min: -4.8639, max: 5.7668, mean: 0.6655, std: 1.1127\n",
      "\n",
      "Step 3188 — Test metrics:\n",
      "  precision@10: 0.003448732\n",
      "  recall@10: 0.003449466\n",
      "  ndcg@10: 0.004050948\n",
      "  map@10: 0.001366082\n",
      "Epoch 291, Step 10, LR: 0.000080, Current Loss: 0.5410, Avg Loss: 0.5424\n",
      "Diff stats — min: -4.0532, max: 9.1435, mean: 0.6704, std: 1.1230\n",
      "\n",
      "Step 3197 — Test metrics:\n",
      "  precision@10: 0.003448732\n",
      "  recall@10: 0.003449466\n",
      "  ndcg@10: 0.004047587\n",
      "  map@10: 0.001364158\n",
      "Epoch 291 completed, Train Loss: 0.5425\n",
      "Epoch 292, Step 1, LR: 0.000080, Current Loss: 0.5422, Avg Loss: 0.5422\n",
      "Diff stats — min: -6.4796, max: 7.1451, mean: 0.6702, std: 1.1280\n",
      "\n",
      "Step 3199 — Test metrics:\n",
      "  precision@10: 0.003442125\n",
      "  recall@10: 0.003442859\n",
      "  ndcg@10: 0.004055240\n",
      "  map@10: 0.001370516\n",
      "Epoch 292, Step 10, LR: 0.000080, Current Loss: 0.5384, Avg Loss: 0.5408\n",
      "Diff stats — min: -4.7934, max: 7.0388, mean: 0.6796, std: 1.1260\n",
      "\n",
      "Step 3208 — Test metrics:\n",
      "  precision@10: 0.003468552\n",
      "  recall@10: 0.003469286\n",
      "  ndcg@10: 0.004094980\n",
      "  map@10: 0.001387131\n",
      "Epoch 292 completed, Train Loss: 0.5406\n",
      "Epoch 293, Step 1, LR: 0.000080, Current Loss: 0.5425, Avg Loss: 0.5425\n",
      "Diff stats — min: -4.5346, max: 5.3056, mean: 0.6708, std: 1.1298\n",
      "\n",
      "Step 3210 — Test metrics:\n",
      "  precision@10: 0.003488372\n",
      "  recall@10: 0.003489106\n",
      "  ndcg@10: 0.004109778\n",
      "  map@10: 0.001390287\n",
      "Epoch 293, Step 10, LR: 0.000080, Current Loss: 0.5413, Avg Loss: 0.5405\n",
      "Diff stats — min: -4.1077, max: 7.3029, mean: 0.6721, std: 1.1280\n",
      "\n",
      "Step 3219 — Test metrics:\n",
      "  precision@10: 0.003528013\n",
      "  recall@10: 0.003528747\n",
      "  ndcg@10: 0.004160389\n",
      "  map@10: 0.001409767\n",
      "Epoch 293 completed, Train Loss: 0.5404\n",
      "Epoch 294, Step 1, LR: 0.000080, Current Loss: 0.5409, Avg Loss: 0.5409\n",
      "Diff stats — min: -4.1432, max: 8.6314, mean: 0.6733, std: 1.1284\n",
      "\n",
      "Step 3221 — Test metrics:\n",
      "  precision@10: 0.003528013\n",
      "  recall@10: 0.003528747\n",
      "  ndcg@10: 0.004174619\n",
      "  map@10: 0.001418389\n",
      "Epoch 294, Step 10, LR: 0.000080, Current Loss: 0.5445, Avg Loss: 0.5407\n",
      "Diff stats — min: -6.0941, max: 6.0257, mean: 0.6730, std: 1.1433\n",
      "\n",
      "Step 3230 — Test metrics:\n",
      "  precision@10: 0.003475159\n",
      "  recall@10: 0.003475893\n",
      "  ndcg@10: 0.004088075\n",
      "  map@10: 0.001381488\n",
      "Epoch 294 completed, Train Loss: 0.5403\n",
      "Epoch 295, Step 1, LR: 0.000080, Current Loss: 0.5440, Avg Loss: 0.5440\n",
      "Diff stats — min: -3.8239, max: 7.2036, mean: 0.6709, std: 1.1370\n",
      "\n",
      "Step 3232 — Test metrics:\n",
      "  precision@10: 0.003481765\n",
      "  recall@10: 0.003482499\n",
      "  ndcg@10: 0.004075993\n",
      "  map@10: 0.001372120\n",
      "Epoch 295, Step 10, LR: 0.000080, Current Loss: 0.5428, Avg Loss: 0.5400\n",
      "Diff stats — min: -5.8513, max: 6.6689, mean: 0.6805, std: 1.1472\n",
      "\n",
      "Step 3241 — Test metrics:\n",
      "  precision@10: 0.003468552\n",
      "  recall@10: 0.003469286\n",
      "  ndcg@10: 0.004056536\n",
      "  map@10: 0.001363408\n",
      "Epoch 295 completed, Train Loss: 0.5397\n",
      "Epoch 296, Step 1, LR: 0.000080, Current Loss: 0.5398, Avg Loss: 0.5398\n",
      "Diff stats — min: -5.1577, max: 6.7584, mean: 0.6848, std: 1.1419\n",
      "\n",
      "Step 3243 — Test metrics:\n",
      "  precision@10: 0.003475159\n",
      "  recall@10: 0.003475893\n",
      "  ndcg@10: 0.004064945\n",
      "  map@10: 0.001366366\n",
      "Epoch 296, Step 10, LR: 0.000080, Current Loss: 0.5360, Avg Loss: 0.5377\n",
      "Diff stats — min: -4.1948, max: 11.1419, mean: 0.6955, std: 1.1452\n",
      "\n",
      "Step 3252 — Test metrics:\n",
      "  precision@10: 0.003501586\n",
      "  recall@10: 0.003502320\n",
      "  ndcg@10: 0.004145039\n",
      "  map@10: 0.001405440\n",
      "Epoch 296 completed, Train Loss: 0.5378\n",
      "Epoch 297, Step 1, LR: 0.000080, Current Loss: 0.5355, Avg Loss: 0.5355\n",
      "Diff stats — min: -4.1703, max: 7.7123, mean: 0.6926, std: 1.1356\n",
      "\n",
      "Step 3254 — Test metrics:\n",
      "  precision@10: 0.003521406\n",
      "  recall@10: 0.003522140\n",
      "  ndcg@10: 0.004168143\n",
      "  map@10: 0.001413240\n",
      "Epoch 297, Step 10, LR: 0.000080, Current Loss: 0.5350, Avg Loss: 0.5377\n",
      "Diff stats — min: -5.7725, max: 8.0850, mean: 0.7001, std: 1.1466\n",
      "\n",
      "Step 3263 — Test metrics:\n",
      "  precision@10: 0.003547833\n",
      "  recall@10: 0.003548567\n",
      "  ndcg@10: 0.004169110\n",
      "  map@10: 0.001407272\n",
      "Epoch 297 completed, Train Loss: 0.5374\n",
      "Epoch 298, Step 1, LR: 0.000080, Current Loss: 0.5337, Avg Loss: 0.5337\n",
      "Diff stats — min: -4.5431, max: 5.8866, mean: 0.7006, std: 1.1404\n",
      "\n",
      "Step 3265 — Test metrics:\n",
      "  precision@10: 0.003541226\n",
      "  recall@10: 0.003541960\n",
      "  ndcg@10: 0.004177808\n",
      "  map@10: 0.001414094\n",
      "Epoch 298, Step 10, LR: 0.000080, Current Loss: 0.5358, Avg Loss: 0.5362\n",
      "Diff stats — min: -4.0195, max: 7.7728, mean: 0.7026, std: 1.1550\n",
      "\n",
      "Step 3274 — Test metrics:\n",
      "  precision@10: 0.003554440\n",
      "  recall@10: 0.003555174\n",
      "  ndcg@10: 0.004178864\n",
      "  map@10: 0.001410885\n",
      "Epoch 298 completed, Train Loss: 0.5361\n",
      "Epoch 299, Step 1, LR: 0.000080, Current Loss: 0.5356, Avg Loss: 0.5356\n",
      "Diff stats — min: -3.9837, max: 5.6600, mean: 0.7015, std: 1.1524\n",
      "\n",
      "Step 3276 — Test metrics:\n",
      "  precision@10: 0.003528013\n",
      "  recall@10: 0.003528747\n",
      "  ndcg@10: 0.004168489\n",
      "  map@10: 0.001412165\n",
      "Epoch 299, Step 10, LR: 0.000080, Current Loss: 0.5295, Avg Loss: 0.5337\n",
      "Diff stats — min: -4.5854, max: 5.2679, mean: 0.7235, std: 1.1579\n",
      "\n",
      "Step 3285 — Test metrics:\n",
      "  precision@10: 0.003528013\n",
      "  recall@10: 0.003528747\n",
      "  ndcg@10: 0.004189119\n",
      "  map@10: 0.001424274\n",
      "Epoch 299 completed, Train Loss: 0.5338\n",
      "Epoch 300, Step 1, LR: 0.000080, Current Loss: 0.5331, Avg Loss: 0.5331\n",
      "Diff stats — min: -4.4809, max: 7.5736, mean: 0.7124, std: 1.1597\n",
      "\n",
      "Step 3287 — Test metrics:\n",
      "  precision@10: 0.003528013\n",
      "  recall@10: 0.003528747\n",
      "  ndcg@10: 0.004218857\n",
      "  map@10: 0.001441976\n",
      "Epoch 300, Step 10, LR: 0.000080, Current Loss: 0.5333, Avg Loss: 0.5332\n",
      "Diff stats — min: -4.0205, max: 8.1992, mean: 0.7096, std: 1.1534\n",
      "\n",
      "Step 3296 — Test metrics:\n",
      "  precision@10: 0.003580867\n",
      "  recall@10: 0.003581601\n",
      "  ndcg@10: 0.004285642\n",
      "  map@10: 0.001466448\n",
      "Epoch 300 completed, Train Loss: 0.5334\n",
      "Epoch 301, Step 1, LR: 0.000080, Current Loss: 0.5316, Avg Loss: 0.5316\n",
      "Diff stats — min: -5.1444, max: 6.2840, mean: 0.7147, std: 1.1541\n",
      "\n",
      "Step 3298 — Test metrics:\n",
      "  precision@10: 0.003600687\n",
      "  recall@10: 0.003601421\n",
      "  ndcg@10: 0.004290299\n",
      "  map@10: 0.001464699\n",
      "Epoch 301, Step 10, LR: 0.000080, Current Loss: 0.5357, Avg Loss: 0.5333\n",
      "Diff stats — min: -4.4392, max: 6.5614, mean: 0.7154, std: 1.1743\n",
      "\n",
      "Step 3307 — Test metrics:\n",
      "  precision@10: 0.003607294\n",
      "  recall@10: 0.003608028\n",
      "  ndcg@10: 0.004261614\n",
      "  map@10: 0.001443041\n",
      "Epoch 301 completed, Train Loss: 0.5334\n",
      "Epoch 302, Step 1, LR: 0.000080, Current Loss: 0.5319, Avg Loss: 0.5319\n",
      "Diff stats — min: -4.6046, max: 6.2388, mean: 0.7185, std: 1.1623\n",
      "\n",
      "Step 3309 — Test metrics:\n",
      "  precision@10: 0.003633721\n",
      "  recall@10: 0.003634455\n",
      "  ndcg@10: 0.004251091\n",
      "  map@10: 0.001430171\n",
      "Epoch 302, Step 10, LR: 0.000080, Current Loss: 0.5296, Avg Loss: 0.5327\n",
      "Diff stats — min: -5.2976, max: 6.4982, mean: 0.7276, std: 1.1673\n",
      "\n",
      "Step 3318 — Test metrics:\n",
      "  precision@10: 0.003607294\n",
      "  recall@10: 0.003608028\n",
      "  ndcg@10: 0.004216887\n",
      "  map@10: 0.001417348\n",
      "Epoch 302 completed, Train Loss: 0.5329\n",
      "Epoch 303, Step 1, LR: 0.000080, Current Loss: 0.5344, Avg Loss: 0.5344\n",
      "Diff stats — min: -5.5541, max: 6.1037, mean: 0.7153, std: 1.1700\n",
      "\n",
      "Step 3320 — Test metrics:\n",
      "  precision@10: 0.003607294\n",
      "  recall@10: 0.003608028\n",
      "  ndcg@10: 0.004220666\n",
      "  map@10: 0.001419773\n",
      "Epoch 303, Step 10, LR: 0.000080, Current Loss: 0.5309, Avg Loss: 0.5317\n",
      "Diff stats — min: -5.1736, max: 7.1088, mean: 0.7292, std: 1.1769\n",
      "\n",
      "Step 3329 — Test metrics:\n",
      "  precision@10: 0.003627114\n",
      "  recall@10: 0.003627848\n",
      "  ndcg@10: 0.004284933\n",
      "  map@10: 0.001451462\n",
      "Epoch 303 completed, Train Loss: 0.5314\n",
      "Epoch 304, Step 1, LR: 0.000080, Current Loss: 0.5297, Avg Loss: 0.5297\n",
      "Diff stats — min: -4.3891, max: 7.2275, mean: 0.7318, std: 1.1734\n",
      "\n",
      "Step 3331 — Test metrics:\n",
      "  precision@10: 0.003633721\n",
      "  recall@10: 0.003634455\n",
      "  ndcg@10: 0.004302945\n",
      "  map@10: 0.001461207\n",
      "Epoch 304, Step 10, LR: 0.000080, Current Loss: 0.5301, Avg Loss: 0.5306\n",
      "Diff stats — min: -4.6620, max: 6.9306, mean: 0.7311, std: 1.1754\n",
      "\n",
      "Step 3340 — Test metrics:\n",
      "  precision@10: 0.003640328\n",
      "  recall@10: 0.003641062\n",
      "  ndcg@10: 0.004323741\n",
      "  map@10: 0.001471115\n",
      "Epoch 304 completed, Train Loss: 0.5306\n",
      "Epoch 305, Step 1, LR: 0.000080, Current Loss: 0.5322, Avg Loss: 0.5322\n",
      "Diff stats — min: -4.1746, max: 7.3252, mean: 0.7246, std: 1.1749\n",
      "\n",
      "Step 3342 — Test metrics:\n",
      "  precision@10: 0.003640328\n",
      "  recall@10: 0.003641062\n",
      "  ndcg@10: 0.004306866\n",
      "  map@10: 0.001461121\n",
      "Epoch 305, Step 10, LR: 0.000080, Current Loss: 0.5294, Avg Loss: 0.5302\n",
      "Diff stats — min: -4.9274, max: 6.6165, mean: 0.7343, std: 1.1782\n",
      "\n",
      "Step 3351 — Test metrics:\n",
      "  precision@10: 0.003666755\n",
      "  recall@10: 0.003667489\n",
      "  ndcg@10: 0.004317445\n",
      "  map@10: 0.001461278\n",
      "Epoch 305 completed, Train Loss: 0.5300\n",
      "Epoch 306, Step 1, LR: 0.000080, Current Loss: 0.5266, Avg Loss: 0.5266\n",
      "Diff stats — min: -5.0743, max: 6.7160, mean: 0.7469, std: 1.1843\n",
      "\n",
      "Step 3353 — Test metrics:\n",
      "  precision@10: 0.003686575\n",
      "  recall@10: 0.003687309\n",
      "  ndcg@10: 0.004324770\n",
      "  map@10: 0.001459927\n",
      "Epoch 306, Step 10, LR: 0.000080, Current Loss: 0.5299, Avg Loss: 0.5292\n",
      "Diff stats — min: -6.5618, max: 7.1144, mean: 0.7383, std: 1.1870\n",
      "\n",
      "Step 3362 — Test metrics:\n",
      "  precision@10: 0.003693182\n",
      "  recall@10: 0.003693916\n",
      "  ndcg@10: 0.004310893\n",
      "  map@10: 0.001447660\n",
      "Epoch 306 completed, Train Loss: 0.5287\n",
      "Epoch 307, Step 1, LR: 0.000080, Current Loss: 0.5269, Avg Loss: 0.5269\n",
      "Diff stats — min: -6.1849, max: 6.0304, mean: 0.7435, std: 1.1811\n",
      "\n",
      "Step 3364 — Test metrics:\n",
      "  precision@10: 0.003686575\n",
      "  recall@10: 0.003687309\n",
      "  ndcg@10: 0.004306029\n",
      "  map@10: 0.001447280\n",
      "Epoch 307, Step 10, LR: 0.000080, Current Loss: 0.5295, Avg Loss: 0.5274\n",
      "Diff stats — min: -4.9302, max: 6.8746, mean: 0.7377, std: 1.1833\n",
      "\n",
      "Step 3373 — Test metrics:\n",
      "  precision@10: 0.003699789\n",
      "  recall@10: 0.003700523\n",
      "  ndcg@10: 0.004348177\n",
      "  map@10: 0.001468417\n",
      "Epoch 307 completed, Train Loss: 0.5273\n",
      "Epoch 308, Step 1, LR: 0.000080, Current Loss: 0.5332, Avg Loss: 0.5332\n",
      "Diff stats — min: -4.1678, max: 6.3493, mean: 0.7340, std: 1.1954\n",
      "\n",
      "Step 3375 — Test metrics:\n",
      "  precision@10: 0.003693182\n",
      "  recall@10: 0.003693916\n",
      "  ndcg@10: 0.004369549\n",
      "  map@10: 0.001483208\n",
      "Epoch 308, Step 10, LR: 0.000080, Current Loss: 0.5270, Avg Loss: 0.5268\n",
      "Diff stats — min: -4.6247, max: 8.5156, mean: 0.7502, std: 1.1934\n",
      "\n",
      "Step 3384 — Test metrics:\n",
      "  precision@10: 0.003726216\n",
      "  recall@10: 0.003726950\n",
      "  ndcg@10: 0.004380073\n",
      "  map@10: 0.001479926\n",
      "Epoch 308 completed, Train Loss: 0.5264\n",
      "Epoch 309, Step 1, LR: 0.000080, Current Loss: 0.5275, Avg Loss: 0.5275\n",
      "Diff stats — min: -4.5914, max: 6.4182, mean: 0.7442, std: 1.1846\n",
      "\n",
      "Step 3386 — Test metrics:\n",
      "  precision@10: 0.003719609\n",
      "  recall@10: 0.003720343\n",
      "  ndcg@10: 0.004376794\n",
      "  map@10: 0.001480770\n",
      "Epoch 309, Step 10, LR: 0.000080, Current Loss: 0.5260, Avg Loss: 0.5258\n",
      "Diff stats — min: -4.3720, max: 6.0789, mean: 0.7520, std: 1.1891\n",
      "\n",
      "Step 3395 — Test metrics:\n",
      "  precision@10: 0.003693182\n",
      "  recall@10: 0.003693916\n",
      "  ndcg@10: 0.004319003\n",
      "  map@10: 0.001455101\n",
      "Epoch 309 completed, Train Loss: 0.5257\n",
      "Epoch 310, Step 1, LR: 0.000080, Current Loss: 0.5236, Avg Loss: 0.5236\n",
      "Diff stats — min: -4.4453, max: 7.1306, mean: 0.7590, std: 1.1931\n",
      "\n",
      "Step 3397 — Test metrics:\n",
      "  precision@10: 0.003686575\n",
      "  recall@10: 0.003687309\n",
      "  ndcg@10: 0.004321083\n",
      "  map@10: 0.001457715\n",
      "Epoch 310, Step 10, LR: 0.000080, Current Loss: 0.5235, Avg Loss: 0.5243\n",
      "Diff stats — min: -4.6837, max: 7.1515, mean: 0.7627, std: 1.1981\n",
      "\n",
      "Step 3406 — Test metrics:\n",
      "  precision@10: 0.003739429\n",
      "  recall@10: 0.003740163\n",
      "  ndcg@10: 0.004380208\n",
      "  map@10: 0.001478728\n",
      "Epoch 310 completed, Train Loss: 0.5239\n",
      "Epoch 311, Step 1, LR: 0.000080, Current Loss: 0.5261, Avg Loss: 0.5261\n",
      "Diff stats — min: -4.7102, max: 7.8306, mean: 0.7525, std: 1.1927\n",
      "\n",
      "Step 3408 — Test metrics:\n",
      "  precision@10: 0.003752643\n",
      "  recall@10: 0.003753377\n",
      "  ndcg@10: 0.004395876\n",
      "  map@10: 0.001484123\n",
      "Epoch 311, Step 10, LR: 0.000080, Current Loss: 0.5247, Avg Loss: 0.5240\n",
      "Diff stats — min: -4.1477, max: 6.8663, mean: 0.7617, std: 1.2006\n",
      "\n",
      "Step 3417 — Test metrics:\n",
      "  precision@10: 0.003752643\n",
      "  recall@10: 0.003753377\n",
      "  ndcg@10: 0.004358199\n",
      "  map@10: 0.001460045\n",
      "Epoch 311 completed, Train Loss: 0.5241\n",
      "Epoch 312, Step 1, LR: 0.000080, Current Loss: 0.5190, Avg Loss: 0.5190\n",
      "Diff stats — min: -4.4567, max: 9.8688, mean: 0.7755, std: 1.1975\n",
      "\n",
      "Step 3419 — Test metrics:\n",
      "  precision@10: 0.003772463\n",
      "  recall@10: 0.003773197\n",
      "  ndcg@10: 0.004370476\n",
      "  map@10: 0.001461810\n",
      "Epoch 312, Step 10, LR: 0.000080, Current Loss: 0.5222, Avg Loss: 0.5226\n",
      "Diff stats — min: -4.3002, max: 6.7699, mean: 0.7693, std: 1.2034\n",
      "\n",
      "Step 3428 — Test metrics:\n",
      "  precision@10: 0.003818710\n",
      "  recall@10: 0.003819444\n",
      "  ndcg@10: 0.004479694\n",
      "  map@10: 0.001514992\n",
      "Epoch 312 completed, Train Loss: 0.5228\n",
      "Epoch 313, Step 1, LR: 0.000080, Current Loss: 0.5260, Avg Loss: 0.5260\n",
      "Diff stats — min: -5.3771, max: 8.1000, mean: 0.7641, std: 1.2113\n",
      "\n",
      "Step 3430 — Test metrics:\n",
      "  precision@10: 0.003812104\n",
      "  recall@10: 0.003812838\n",
      "  ndcg@10: 0.004474837\n",
      "  map@10: 0.001513474\n",
      "Epoch 313, Step 10, LR: 0.000080, Current Loss: 0.5205, Avg Loss: 0.5225\n",
      "Diff stats — min: -5.4309, max: 6.0597, mean: 0.7806, std: 1.2117\n",
      "\n",
      "Step 3439 — Test metrics:\n",
      "  precision@10: 0.003858351\n",
      "  recall@10: 0.003859085\n",
      "  ndcg@10: 0.004508476\n",
      "  map@10: 0.001520846\n",
      "Epoch 313 completed, Train Loss: 0.5220\n",
      "Epoch 314, Step 1, LR: 0.000080, Current Loss: 0.5196, Avg Loss: 0.5196\n",
      "Diff stats — min: -5.0040, max: 6.4232, mean: 0.7847, std: 1.2137\n",
      "\n",
      "Step 3441 — Test metrics:\n",
      "  precision@10: 0.003864958\n",
      "  recall@10: 0.003865692\n",
      "  ndcg@10: 0.004519196\n",
      "  map@10: 0.001525382\n",
      "Epoch 314, Step 10, LR: 0.000080, Current Loss: 0.5208, Avg Loss: 0.5214\n",
      "Diff stats — min: -4.6702, max: 7.4658, mean: 0.7797, std: 1.2113\n",
      "\n",
      "Step 3450 — Test metrics:\n",
      "  precision@10: 0.003792283\n",
      "  recall@10: 0.003793017\n",
      "  ndcg@10: 0.004397331\n",
      "  map@10: 0.001472383\n",
      "Epoch 314 completed, Train Loss: 0.5211\n",
      "Epoch 315, Step 1, LR: 0.000080, Current Loss: 0.5222, Avg Loss: 0.5222\n",
      "Diff stats — min: -4.5306, max: 6.5098, mean: 0.7783, std: 1.2168\n",
      "\n",
      "Step 3452 — Test metrics:\n",
      "  precision@10: 0.003792283\n",
      "  recall@10: 0.003793017\n",
      "  ndcg@10: 0.004395482\n",
      "  map@10: 0.001471083\n",
      "Epoch 315, Step 10, LR: 0.000080, Current Loss: 0.5214, Avg Loss: 0.5202\n",
      "Diff stats — min: -4.4102, max: 6.5541, mean: 0.7764, std: 1.2086\n",
      "\n",
      "Step 3461 — Test metrics:\n",
      "  precision@10: 0.003812104\n",
      "  recall@10: 0.003812838\n",
      "  ndcg@10: 0.004466769\n",
      "  map@10: 0.001508663\n",
      "Epoch 315 completed, Train Loss: 0.5196\n",
      "Epoch 316, Step 1, LR: 0.000080, Current Loss: 0.5236, Avg Loss: 0.5236\n",
      "Diff stats — min: -4.4979, max: 5.7070, mean: 0.7784, std: 1.2233\n",
      "\n",
      "Step 3463 — Test metrics:\n",
      "  precision@10: 0.003851744\n",
      "  recall@10: 0.003852478\n",
      "  ndcg@10: 0.004508924\n",
      "  map@10: 0.001522251\n",
      "Epoch 316, Step 10, LR: 0.000080, Current Loss: 0.5224, Avg Loss: 0.5202\n",
      "Diff stats — min: -4.0494, max: 7.1642, mean: 0.7802, std: 1.2210\n",
      "\n",
      "Step 3472 — Test metrics:\n",
      "  precision@10: 0.003911205\n",
      "  recall@10: 0.003911939\n",
      "  ndcg@10: 0.004589061\n",
      "  map@10: 0.001553151\n",
      "Epoch 316 completed, Train Loss: 0.5200\n",
      "Epoch 317, Step 1, LR: 0.000080, Current Loss: 0.5216, Avg Loss: 0.5216\n",
      "Diff stats — min: -4.7624, max: 7.4032, mean: 0.7844, std: 1.2245\n",
      "\n",
      "Step 3474 — Test metrics:\n",
      "  precision@10: 0.003924419\n",
      "  recall@10: 0.003925153\n",
      "  ndcg@10: 0.004600668\n",
      "  map@10: 0.001556276\n",
      "Epoch 317, Step 10, LR: 0.000080, Current Loss: 0.5183, Avg Loss: 0.5189\n",
      "Diff stats — min: -9.1007, max: 6.3614, mean: 0.7940, std: 1.2235\n",
      "\n",
      "Step 3483 — Test metrics:\n",
      "  precision@10: 0.003891385\n",
      "  recall@10: 0.003892119\n",
      "  ndcg@10: 0.004547994\n",
      "  map@10: 0.001533989\n",
      "Epoch 317 completed, Train Loss: 0.5191\n",
      "Epoch 318, Step 1, LR: 0.000080, Current Loss: 0.5205, Avg Loss: 0.5205\n",
      "Diff stats — min: -4.3074, max: 6.3050, mean: 0.7883, std: 1.2255\n",
      "\n",
      "Step 3485 — Test metrics:\n",
      "  precision@10: 0.003897992\n",
      "  recall@10: 0.003898726\n",
      "  ndcg@10: 0.004551638\n",
      "  map@10: 0.001534592\n",
      "Epoch 318, Step 10, LR: 0.000080, Current Loss: 0.5153, Avg Loss: 0.5179\n",
      "Diff stats — min: -5.6341, max: 6.8230, mean: 0.8057, std: 1.2286\n",
      "\n",
      "Step 3494 — Test metrics:\n",
      "  precision@10: 0.003878171\n",
      "  recall@10: 0.003878905\n",
      "  ndcg@10: 0.004538139\n",
      "  map@10: 0.001532290\n",
      "Epoch 318 completed, Train Loss: 0.5179\n",
      "Epoch 319, Step 1, LR: 0.000080, Current Loss: 0.5139, Avg Loss: 0.5139\n",
      "Diff stats — min: -4.2480, max: 5.9977, mean: 0.8063, std: 1.2236\n",
      "\n",
      "Step 3496 — Test metrics:\n",
      "  precision@10: 0.003904598\n",
      "  recall@10: 0.003905332\n",
      "  ndcg@10: 0.004554558\n",
      "  map@10: 0.001534647\n",
      "Epoch 319, Step 10, LR: 0.000080, Current Loss: 0.5135, Avg Loss: 0.5167\n",
      "Diff stats — min: -5.1116, max: 6.2272, mean: 0.8108, std: 1.2286\n",
      "\n",
      "Step 3505 — Test metrics:\n",
      "  precision@10: 0.003931025\n",
      "  recall@10: 0.003931759\n",
      "  ndcg@10: 0.004539609\n",
      "  map@10: 0.001517797\n",
      "Epoch 319 completed, Train Loss: 0.5165\n",
      "Epoch 320, Step 1, LR: 0.000080, Current Loss: 0.5133, Avg Loss: 0.5133\n",
      "Diff stats — min: -4.5211, max: 6.3718, mean: 0.8107, std: 1.2288\n",
      "\n",
      "Step 3507 — Test metrics:\n",
      "  precision@10: 0.003924419\n",
      "  recall@10: 0.003925153\n",
      "  ndcg@10: 0.004540609\n",
      "  map@10: 0.001520167\n",
      "Epoch 320, Step 10, LR: 0.000080, Current Loss: 0.5146, Avg Loss: 0.5150\n",
      "Diff stats — min: -4.6116, max: 8.1228, mean: 0.8103, std: 1.2339\n",
      "\n",
      "Step 3516 — Test metrics:\n",
      "  precision@10: 0.003950846\n",
      "  recall@10: 0.003951580\n",
      "  ndcg@10: 0.004587011\n",
      "  map@10: 0.001539568\n",
      "Epoch 320 completed, Train Loss: 0.5152\n",
      "Epoch 321, Step 1, LR: 0.000080, Current Loss: 0.5169, Avg Loss: 0.5169\n",
      "Diff stats — min: -4.3115, max: 6.8616, mean: 0.8065, std: 1.2376\n",
      "\n",
      "Step 3518 — Test metrics:\n",
      "  precision@10: 0.003970666\n",
      "  recall@10: 0.003971400\n",
      "  ndcg@10: 0.004614405\n",
      "  map@10: 0.001551036\n",
      "Epoch 321, Step 10, LR: 0.000080, Current Loss: 0.5126, Avg Loss: 0.5151\n",
      "Diff stats — min: -4.8317, max: 6.3265, mean: 0.8189, std: 1.2351\n",
      "\n",
      "Step 3527 — Test metrics:\n",
      "  precision@10: 0.004030127\n",
      "  recall@10: 0.004030861\n",
      "  ndcg@10: 0.004650660\n",
      "  map@10: 0.001556855\n",
      "Epoch 321 completed, Train Loss: 0.5148\n",
      "Epoch 322, Step 1, LR: 0.000080, Current Loss: 0.5101, Avg Loss: 0.5101\n",
      "Diff stats — min: -5.0360, max: 8.7491, mean: 0.8293, std: 1.2449\n",
      "\n",
      "Step 3529 — Test metrics:\n",
      "  precision@10: 0.003944239\n",
      "  recall@10: 0.003944973\n",
      "  ndcg@10: 0.004593934\n",
      "  map@10: 0.001547226\n",
      "Epoch 322, Step 10, LR: 0.000080, Current Loss: 0.5124, Avg Loss: 0.5131\n",
      "Diff stats — min: -4.0645, max: 6.6265, mean: 0.8146, std: 1.2295\n",
      "\n",
      "Step 3538 — Test metrics:\n",
      "  precision@10: 0.003964059\n",
      "  recall@10: 0.003964793\n",
      "  ndcg@10: 0.004563857\n",
      "  map@10: 0.001522351\n",
      "Epoch 322 completed, Train Loss: 0.5129\n",
      "Epoch 323, Step 1, LR: 0.000080, Current Loss: 0.5184, Avg Loss: 0.5184\n",
      "Diff stats — min: -5.8478, max: 6.1519, mean: 0.8098, std: 1.2487\n",
      "\n",
      "Step 3540 — Test metrics:\n",
      "  precision@10: 0.003957452\n",
      "  recall@10: 0.003958187\n",
      "  ndcg@10: 0.004556550\n",
      "  map@10: 0.001519913\n",
      "Epoch 323, Step 10, LR: 0.000080, Current Loss: 0.5109, Avg Loss: 0.5131\n",
      "Diff stats — min: -4.2260, max: 6.5626, mean: 0.8351, std: 1.2561\n",
      "\n",
      "Step 3549 — Test metrics:\n",
      "  precision@10: 0.003950846\n",
      "  recall@10: 0.003951580\n",
      "  ndcg@10: 0.004558967\n",
      "  map@10: 0.001522941\n",
      "Epoch 323 completed, Train Loss: 0.5129\n",
      "Epoch 324, Step 1, LR: 0.000080, Current Loss: 0.5129, Avg Loss: 0.5129\n",
      "Diff stats — min: -4.3800, max: 6.9331, mean: 0.8262, std: 1.2512\n",
      "\n",
      "Step 3551 — Test metrics:\n",
      "  precision@10: 0.003970666\n",
      "  recall@10: 0.003971400\n",
      "  ndcg@10: 0.004570589\n",
      "  map@10: 0.001524868\n",
      "Epoch 324, Step 10, LR: 0.000080, Current Loss: 0.5123, Avg Loss: 0.5119\n",
      "Diff stats — min: -4.2854, max: 7.7383, mean: 0.8279, std: 1.2500\n",
      "\n",
      "Step 3560 — Test metrics:\n",
      "  precision@10: 0.003977273\n",
      "  recall@10: 0.003978007\n",
      "  ndcg@10: 0.004588988\n",
      "  map@10: 0.001535410\n",
      "Epoch 324 completed, Train Loss: 0.5117\n",
      "Epoch 325, Step 1, LR: 0.000080, Current Loss: 0.5102, Avg Loss: 0.5102\n",
      "Diff stats — min: -5.1749, max: 7.0785, mean: 0.8358, std: 1.2530\n",
      "\n",
      "Step 3562 — Test metrics:\n",
      "  precision@10: 0.004010307\n",
      "  recall@10: 0.004011041\n",
      "  ndcg@10: 0.004607423\n",
      "  map@10: 0.001536873\n",
      "Epoch 325, Step 10, LR: 0.000080, Current Loss: 0.5147, Avg Loss: 0.5110\n",
      "Diff stats — min: -5.6594, max: 7.8992, mean: 0.8274, std: 1.2619\n",
      "\n",
      "Step 3571 — Test metrics:\n",
      "  precision@10: 0.004049947\n",
      "  recall@10: 0.004050681\n",
      "  ndcg@10: 0.004623706\n",
      "  map@10: 0.001534600\n",
      "Epoch 325 completed, Train Loss: 0.5105\n",
      "Epoch 326, Step 1, LR: 0.000080, Current Loss: 0.5095, Avg Loss: 0.5095\n",
      "Diff stats — min: -4.0899, max: 7.6944, mean: 0.8385, std: 1.2552\n",
      "\n",
      "Step 3573 — Test metrics:\n",
      "  precision@10: 0.004056554\n",
      "  recall@10: 0.004057288\n",
      "  ndcg@10: 0.004630182\n",
      "  map@10: 0.001536157\n",
      "Epoch 326, Step 10, LR: 0.000080, Current Loss: 0.5090, Avg Loss: 0.5103\n",
      "Diff stats — min: -4.0248, max: 6.3611, mean: 0.8479, std: 1.2665\n",
      "\n",
      "Step 3582 — Test metrics:\n",
      "  precision@10: 0.004096195\n",
      "  recall@10: 0.004096929\n",
      "  ndcg@10: 0.004711209\n",
      "  map@10: 0.001573574\n",
      "Epoch 326 completed, Train Loss: 0.5106\n",
      "Epoch 327, Step 1, LR: 0.000080, Current Loss: 0.5146, Avg Loss: 0.5146\n",
      "Diff stats — min: -4.4970, max: 6.6616, mean: 0.8317, std: 1.2666\n",
      "\n",
      "Step 3584 — Test metrics:\n",
      "  precision@10: 0.004109408\n",
      "  recall@10: 0.004110142\n",
      "  ndcg@10: 0.004730024\n",
      "  map@10: 0.001581670\n",
      "Epoch 327, Step 10, LR: 0.000080, Current Loss: 0.5106, Avg Loss: 0.5092\n",
      "Diff stats — min: -6.3147, max: 9.9554, mean: 0.8387, std: 1.2613\n",
      "\n",
      "Step 3593 — Test metrics:\n",
      "  precision@10: 0.004188689\n",
      "  recall@10: 0.004189423\n",
      "  ndcg@10: 0.004794487\n",
      "  map@10: 0.001598898\n",
      "Epoch 327 completed, Train Loss: 0.5090\n",
      "Epoch 328, Step 1, LR: 0.000080, Current Loss: 0.5090, Avg Loss: 0.5090\n",
      "Diff stats — min: -4.5076, max: 7.0543, mean: 0.8441, std: 1.2617\n",
      "\n",
      "Step 3595 — Test metrics:\n",
      "  precision@10: 0.004182082\n",
      "  recall@10: 0.004182817\n",
      "  ndcg@10: 0.004791025\n",
      "  map@10: 0.001598499\n",
      "Epoch 328, Step 10, LR: 0.000080, Current Loss: 0.5078, Avg Loss: 0.5074\n",
      "Diff stats — min: -6.2300, max: 6.9875, mean: 0.8490, std: 1.2645\n",
      "\n",
      "Step 3604 — Test metrics:\n",
      "  precision@10: 0.004135835\n",
      "  recall@10: 0.004136569\n",
      "  ndcg@10: 0.004763296\n",
      "  map@10: 0.001592734\n",
      "Epoch 328 completed, Train Loss: 0.5073\n",
      "Epoch 329, Step 1, LR: 0.000080, Current Loss: 0.5063, Avg Loss: 0.5063\n",
      "Diff stats — min: -4.6707, max: 7.6939, mean: 0.8545, std: 1.2656\n",
      "\n",
      "Step 3606 — Test metrics:\n",
      "  precision@10: 0.004129228\n",
      "  recall@10: 0.004129962\n",
      "  ndcg@10: 0.004762431\n",
      "  map@10: 0.001594207\n",
      "Epoch 329, Step 10, LR: 0.000080, Current Loss: 0.5049, Avg Loss: 0.5078\n",
      "Diff stats — min: -4.6456, max: 10.6704, mean: 0.8625, std: 1.2729\n",
      "\n",
      "Step 3615 — Test metrics:\n",
      "  precision@10: 0.004162262\n",
      "  recall@10: 0.004162996\n",
      "  ndcg@10: 0.004764092\n",
      "  map@10: 0.001584310\n",
      "Epoch 329 completed, Train Loss: 0.5075\n",
      "Epoch 330, Step 1, LR: 0.000080, Current Loss: 0.5063, Avg Loss: 0.5063\n",
      "Diff stats — min: -4.4414, max: 5.6448, mean: 0.8600, std: 1.2721\n",
      "\n",
      "Step 3617 — Test metrics:\n",
      "  precision@10: 0.004175476\n",
      "  recall@10: 0.004176210\n",
      "  ndcg@10: 0.004773542\n",
      "  map@10: 0.001585254\n",
      "Epoch 330, Step 10, LR: 0.000080, Current Loss: 0.5061, Avg Loss: 0.5064\n",
      "Diff stats — min: -5.2429, max: 8.2500, mean: 0.8633, std: 1.2785\n",
      "\n",
      "Step 3626 — Test metrics:\n",
      "  precision@10: 0.004215116\n",
      "  recall@10: 0.004215850\n",
      "  ndcg@10: 0.004792048\n",
      "  map@10: 0.001586127\n",
      "Epoch 330 completed, Train Loss: 0.5063\n",
      "Epoch 331, Step 1, LR: 0.000080, Current Loss: 0.5102, Avg Loss: 0.5102\n",
      "Diff stats — min: -6.1251, max: 6.3403, mean: 0.8493, std: 1.2747\n",
      "\n",
      "Step 3628 — Test metrics:\n",
      "  precision@10: 0.004215116\n",
      "  recall@10: 0.004215850\n",
      "  ndcg@10: 0.004795561\n",
      "  map@10: 0.001588311\n",
      "Epoch 331, Step 10, LR: 0.000080, Current Loss: 0.5036, Avg Loss: 0.5066\n",
      "Diff stats — min: -5.2296, max: 6.1688, mean: 0.8705, std: 1.2775\n",
      "\n",
      "Step 3637 — Test metrics:\n",
      "  precision@10: 0.004188689\n",
      "  recall@10: 0.004189423\n",
      "  ndcg@10: 0.004779762\n",
      "  map@10: 0.001588277\n",
      "Epoch 331 completed, Train Loss: 0.5067\n",
      "Epoch 332, Step 1, LR: 0.000080, Current Loss: 0.5069, Avg Loss: 0.5069\n",
      "Diff stats — min: -4.6622, max: 6.2141, mean: 0.8622, std: 1.2791\n",
      "\n",
      "Step 3639 — Test metrics:\n",
      "  precision@10: 0.004182082\n",
      "  recall@10: 0.004182817\n",
      "  ndcg@10: 0.004770170\n",
      "  map@10: 0.001583740\n",
      "Epoch 332, Step 10, LR: 0.000080, Current Loss: 0.5053, Avg Loss: 0.5052\n",
      "Diff stats — min: -4.2320, max: 6.8769, mean: 0.8702, std: 1.2875\n",
      "\n",
      "Step 3648 — Test metrics:\n",
      "  precision@10: 0.004201903\n",
      "  recall@10: 0.004202637\n",
      "  ndcg@10: 0.004754264\n",
      "  map@10: 0.001567671\n",
      "Epoch 332 completed, Train Loss: 0.5049\n",
      "Epoch 333, Step 1, LR: 0.000080, Current Loss: 0.5044, Avg Loss: 0.5044\n",
      "Diff stats — min: -5.0825, max: 6.8830, mean: 0.8709, std: 1.2805\n",
      "\n",
      "Step 3650 — Test metrics:\n",
      "  precision@10: 0.004234937\n",
      "  recall@10: 0.004235671\n",
      "  ndcg@10: 0.004784872\n",
      "  map@10: 0.001576429\n",
      "Epoch 333, Step 10, LR: 0.000080, Current Loss: 0.5029, Avg Loss: 0.5044\n",
      "Diff stats — min: -4.8922, max: 8.5248, mean: 0.8785, std: 1.2857\n",
      "\n",
      "Step 3659 — Test metrics:\n",
      "  precision@10: 0.004215116\n",
      "  recall@10: 0.004215850\n",
      "  ndcg@10: 0.004799316\n",
      "  map@10: 0.001588285\n",
      "Epoch 333 completed, Train Loss: 0.5041\n",
      "Epoch 334, Step 1, LR: 0.000080, Current Loss: 0.5020, Avg Loss: 0.5020\n",
      "Diff stats — min: -4.1874, max: 10.9115, mean: 0.8859, std: 1.2920\n",
      "\n",
      "Step 3661 — Test metrics:\n",
      "  precision@10: 0.004221723\n",
      "  recall@10: 0.004222457\n",
      "  ndcg@10: 0.004804531\n",
      "  map@10: 0.001590408\n",
      "Epoch 334, Step 10, LR: 0.000080, Current Loss: 0.5019, Avg Loss: 0.5043\n",
      "Diff stats — min: -4.8821, max: 8.2142, mean: 0.8818, std: 1.2869\n",
      "\n",
      "Step 3670 — Test metrics:\n",
      "  precision@10: 0.004215116\n",
      "  recall@10: 0.004215850\n",
      "  ndcg@10: 0.004827460\n",
      "  map@10: 0.001608889\n",
      "Epoch 334 completed, Train Loss: 0.5041\n",
      "Epoch 335, Step 1, LR: 0.000080, Current Loss: 0.5054, Avg Loss: 0.5054\n",
      "Diff stats — min: -5.2318, max: 6.4654, mean: 0.8773, std: 1.2946\n",
      "\n",
      "Step 3672 — Test metrics:\n",
      "  precision@10: 0.004241543\n",
      "  recall@10: 0.004242277\n",
      "  ndcg@10: 0.004848591\n",
      "  map@10: 0.001613802\n",
      "Epoch 335, Step 10, LR: 0.000080, Current Loss: 0.4979, Avg Loss: 0.5032\n",
      "Diff stats — min: -4.1459, max: 6.9148, mean: 0.9003, std: 1.2984\n",
      "\n",
      "Step 3681 — Test metrics:\n",
      "  precision@10: 0.004301004\n",
      "  recall@10: 0.004301738\n",
      "  ndcg@10: 0.004873140\n",
      "  map@10: 0.001609817\n",
      "Epoch 335 completed, Train Loss: 0.5030\n",
      "Epoch 336, Step 1, LR: 0.000080, Current Loss: 0.5039, Avg Loss: 0.5039\n",
      "Diff stats — min: -4.5532, max: 7.0483, mean: 0.8807, std: 1.2935\n",
      "\n",
      "Step 3683 — Test metrics:\n",
      "  precision@10: 0.004320825\n",
      "  recall@10: 0.004321559\n",
      "  ndcg@10: 0.004879744\n",
      "  map@10: 0.001606721\n",
      "Epoch 336, Step 10, LR: 0.000080, Current Loss: 0.4952, Avg Loss: 0.5025\n",
      "Diff stats — min: -7.7336, max: 6.6066, mean: 0.9000, std: 1.2860\n",
      "\n",
      "Step 3692 — Test metrics:\n",
      "  precision@10: 0.004353858\n",
      "  recall@10: 0.004354592\n",
      "  ndcg@10: 0.004886112\n",
      "  map@10: 0.001603446\n",
      "Epoch 336 completed, Train Loss: 0.5023\n",
      "Epoch 337, Step 1, LR: 0.000080, Current Loss: 0.5023, Avg Loss: 0.5023\n",
      "Diff stats — min: -4.8735, max: 7.7042, mean: 0.8846, std: 1.2923\n",
      "\n",
      "Step 3694 — Test metrics:\n",
      "  precision@10: 0.004340645\n",
      "  recall@10: 0.004341379\n",
      "  ndcg@10: 0.004876347\n",
      "  map@10: 0.001600882\n",
      "Epoch 337, Step 10, LR: 0.000080, Current Loss: 0.5023, Avg Loss: 0.5005\n",
      "Diff stats — min: -5.2776, max: 8.4986, mean: 0.8918, std: 1.3047\n",
      "\n",
      "Step 3703 — Test metrics:\n",
      "  precision@10: 0.004301004\n",
      "  recall@10: 0.004301738\n",
      "  ndcg@10: 0.004871742\n",
      "  map@10: 0.001611593\n",
      "Epoch 337 completed, Train Loss: 0.5004\n",
      "Epoch 338, Step 1, LR: 0.000080, Current Loss: 0.5027, Avg Loss: 0.5027\n",
      "Diff stats — min: -4.8779, max: 7.7454, mean: 0.8886, std: 1.3005\n",
      "\n",
      "Step 3705 — Test metrics:\n",
      "  precision@10: 0.004314218\n",
      "  recall@10: 0.004314952\n",
      "  ndcg@10: 0.004876960\n",
      "  map@10: 0.001610245\n",
      "Epoch 338, Step 10, LR: 0.000080, Current Loss: 0.5034, Avg Loss: 0.5000\n",
      "Diff stats — min: -5.3091, max: 7.9650, mean: 0.8937, std: 1.3113\n",
      "\n",
      "Step 3714 — Test metrics:\n",
      "  precision@10: 0.004320825\n",
      "  recall@10: 0.004321559\n",
      "  ndcg@10: 0.004877326\n",
      "  map@10: 0.001608740\n",
      "Epoch 338 completed, Train Loss: 0.4999\n",
      "Epoch 339, Step 1, LR: 0.000080, Current Loss: 0.5011, Avg Loss: 0.5011\n",
      "Diff stats — min: -5.4081, max: 8.4620, mean: 0.9012, std: 1.3139\n",
      "\n",
      "Step 3716 — Test metrics:\n",
      "  precision@10: 0.004320825\n",
      "  recall@10: 0.004321559\n",
      "  ndcg@10: 0.004883357\n",
      "  map@10: 0.001611320\n",
      "Epoch 339, Step 10, LR: 0.000080, Current Loss: 0.4968, Avg Loss: 0.4987\n",
      "Diff stats — min: -4.9424, max: 7.9943, mean: 0.9049, std: 1.2985\n",
      "\n",
      "Step 3725 — Test metrics:\n",
      "  precision@10: 0.004301004\n",
      "  recall@10: 0.004301738\n",
      "  ndcg@10: 0.004893361\n",
      "  map@10: 0.001622247\n",
      "Epoch 339 completed, Train Loss: 0.4991\n",
      "Epoch 340, Step 1, LR: 0.000080, Current Loss: 0.4998, Avg Loss: 0.4998\n",
      "Diff stats — min: -4.9500, max: 6.7460, mean: 0.9082, std: 1.3173\n",
      "\n",
      "Step 3727 — Test metrics:\n",
      "  precision@10: 0.004281184\n",
      "  recall@10: 0.004281918\n",
      "  ndcg@10: 0.004871728\n",
      "  map@10: 0.001614119\n",
      "Epoch 340, Step 10, LR: 0.000080, Current Loss: 0.4968, Avg Loss: 0.4981\n",
      "Diff stats — min: -5.3712, max: 7.3952, mean: 0.9095, std: 1.3045\n",
      "\n",
      "Step 3736 — Test metrics:\n",
      "  precision@10: 0.004360465\n",
      "  recall@10: 0.004361199\n",
      "  ndcg@10: 0.004899588\n",
      "  map@10: 0.001607214\n",
      "Epoch 340 completed, Train Loss: 0.4982\n",
      "Epoch 341, Step 1, LR: 0.000080, Current Loss: 0.4991, Avg Loss: 0.4991\n",
      "Diff stats — min: -5.4503, max: 6.4646, mean: 0.9125, std: 1.3193\n",
      "\n",
      "Step 3738 — Test metrics:\n",
      "  precision@10: 0.004380285\n",
      "  recall@10: 0.004381019\n",
      "  ndcg@10: 0.004913588\n",
      "  map@10: 0.001609162\n",
      "Epoch 341, Step 10, LR: 0.000080, Current Loss: 0.5028, Avg Loss: 0.4985\n",
      "Diff stats — min: -4.9792, max: 7.6832, mean: 0.9050, std: 1.3244\n",
      "\n",
      "Step 3747 — Test metrics:\n",
      "  precision@10: 0.004373679\n",
      "  recall@10: 0.004374413\n",
      "  ndcg@10: 0.004889664\n",
      "  map@10: 0.001598864\n",
      "Epoch 341 completed, Train Loss: 0.4983\n",
      "Epoch 342, Step 1, LR: 0.000080, Current Loss: 0.4994, Avg Loss: 0.4994\n",
      "Diff stats — min: -4.1175, max: 6.5573, mean: 0.9118, std: 1.3185\n",
      "\n",
      "Step 3749 — Test metrics:\n",
      "  precision@10: 0.004386892\n",
      "  recall@10: 0.004387626\n",
      "  ndcg@10: 0.004901721\n",
      "  map@10: 0.001602181\n",
      "Epoch 342, Step 10, LR: 0.000080, Current Loss: 0.4950, Avg Loss: 0.4972\n",
      "Diff stats — min: -4.3080, max: 6.9168, mean: 0.9194, std: 1.3153\n",
      "\n",
      "Step 3758 — Test metrics:\n",
      "  precision@10: 0.004413319\n",
      "  recall@10: 0.004414053\n",
      "  ndcg@10: 0.004902271\n",
      "  map@10: 0.001597283\n",
      "Epoch 342 completed, Train Loss: 0.4969\n",
      "Epoch 343, Step 1, LR: 0.000080, Current Loss: 0.4911, Avg Loss: 0.4911\n",
      "Diff stats — min: -4.9266, max: 6.3820, mean: 0.9293, std: 1.3079\n",
      "\n",
      "Step 3760 — Test metrics:\n",
      "  precision@10: 0.004386892\n",
      "  recall@10: 0.004387626\n",
      "  ndcg@10: 0.004921552\n",
      "  map@10: 0.001614937\n",
      "Epoch 343, Step 10, LR: 0.000080, Current Loss: 0.4985, Avg Loss: 0.4967\n",
      "Diff stats — min: -4.8442, max: 7.0027, mean: 0.9150, std: 1.3208\n",
      "\n",
      "Step 3769 — Test metrics:\n",
      "  precision@10: 0.004479387\n",
      "  recall@10: 0.004480121\n",
      "  ndcg@10: 0.005027737\n",
      "  map@10: 0.001653744\n",
      "Epoch 343 completed, Train Loss: 0.4966\n",
      "Epoch 344, Step 1, LR: 0.000080, Current Loss: 0.4928, Avg Loss: 0.4928\n",
      "Diff stats — min: -4.4284, max: 7.8643, mean: 0.9322, std: 1.3229\n",
      "\n",
      "Step 3771 — Test metrics:\n",
      "  precision@10: 0.004485994\n",
      "  recall@10: 0.004486728\n",
      "  ndcg@10: 0.005042708\n",
      "  map@10: 0.001660495\n",
      "Epoch 344, Step 10, LR: 0.000080, Current Loss: 0.4962, Avg Loss: 0.4954\n",
      "Diff stats — min: -4.0551, max: 7.2809, mean: 0.9222, std: 1.3213\n",
      "\n",
      "Step 3780 — Test metrics:\n",
      "  precision@10: 0.004452960\n",
      "  recall@10: 0.004453694\n",
      "  ndcg@10: 0.005028504\n",
      "  map@10: 0.001662220\n",
      "Epoch 344 completed, Train Loss: 0.4948\n",
      "Epoch 345, Step 1, LR: 0.000080, Current Loss: 0.4979, Avg Loss: 0.4979\n",
      "Diff stats — min: -5.1086, max: 7.3892, mean: 0.9235, std: 1.3323\n",
      "\n",
      "Step 3782 — Test metrics:\n",
      "  precision@10: 0.004466173\n",
      "  recall@10: 0.004466907\n",
      "  ndcg@10: 0.005031370\n",
      "  map@10: 0.001660267\n",
      "Epoch 345, Step 10, LR: 0.000080, Current Loss: 0.4953, Avg Loss: 0.4954\n",
      "Diff stats — min: -4.0947, max: 6.6558, mean: 0.9363, std: 1.3393\n",
      "\n",
      "Step 3791 — Test metrics:\n",
      "  precision@10: 0.004426533\n",
      "  recall@10: 0.004427267\n",
      "  ndcg@10: 0.004936753\n",
      "  map@10: 0.001612605\n",
      "Epoch 345 completed, Train Loss: 0.4949\n",
      "Epoch 346, Step 1, LR: 0.000080, Current Loss: 0.4932, Avg Loss: 0.4932\n",
      "Diff stats — min: -7.3199, max: 7.9283, mean: 0.9386, std: 1.3340\n",
      "\n",
      "Step 3793 — Test metrics:\n",
      "  precision@10: 0.004452960\n",
      "  recall@10: 0.004453694\n",
      "  ndcg@10: 0.004950489\n",
      "  map@10: 0.001613926\n",
      "Epoch 346, Step 10, LR: 0.000080, Current Loss: 0.4923, Avg Loss: 0.4940\n",
      "Diff stats — min: -4.4158, max: 7.6191, mean: 0.9406, std: 1.3317\n",
      "\n",
      "Step 3802 — Test metrics:\n",
      "  precision@10: 0.004512421\n",
      "  recall@10: 0.004513155\n",
      "  ndcg@10: 0.004998325\n",
      "  map@10: 0.001626400\n",
      "Epoch 346 completed, Train Loss: 0.4935\n",
      "Epoch 347, Step 1, LR: 0.000080, Current Loss: 0.4917, Avg Loss: 0.4917\n",
      "Diff stats — min: -5.2644, max: 6.7563, mean: 0.9388, std: 1.3258\n",
      "\n",
      "Step 3804 — Test metrics:\n",
      "  precision@10: 0.004472780\n",
      "  recall@10: 0.004473514\n",
      "  ndcg@10: 0.004967497\n",
      "  map@10: 0.001619073\n",
      "Epoch 347, Step 10, LR: 0.000080, Current Loss: 0.4918, Avg Loss: 0.4923\n",
      "Diff stats — min: -4.8560, max: 7.4079, mean: 0.9420, std: 1.3310\n",
      "\n",
      "Step 3813 — Test metrics:\n",
      "  precision@10: 0.004591702\n",
      "  recall@10: 0.004592436\n",
      "  ndcg@10: 0.005065181\n",
      "  map@10: 0.001645517\n",
      "Epoch 347 completed, Train Loss: 0.4923\n",
      "Epoch 348, Step 1, LR: 0.000080, Current Loss: 0.4972, Avg Loss: 0.4972\n",
      "Diff stats — min: -5.4986, max: 7.6617, mean: 0.9357, std: 1.3463\n",
      "\n",
      "Step 3815 — Test metrics:\n",
      "  precision@10: 0.004591702\n",
      "  recall@10: 0.004592436\n",
      "  ndcg@10: 0.005087740\n",
      "  map@10: 0.001657818\n",
      "Epoch 348, Step 10, LR: 0.000080, Current Loss: 0.4987, Avg Loss: 0.4922\n",
      "Diff stats — min: -4.9405, max: 8.6732, mean: 0.9265, std: 1.3388\n",
      "\n",
      "Step 3824 — Test metrics:\n",
      "  precision@10: 0.004598309\n",
      "  recall@10: 0.004599043\n",
      "  ndcg@10: 0.005090374\n",
      "  map@10: 0.001656673\n",
      "Epoch 348 completed, Train Loss: 0.4920\n",
      "Epoch 349, Step 1, LR: 0.000080, Current Loss: 0.4925, Avg Loss: 0.4925\n",
      "Diff stats — min: -4.2162, max: 8.9321, mean: 0.9436, std: 1.3376\n",
      "\n",
      "Step 3826 — Test metrics:\n",
      "  precision@10: 0.004591702\n",
      "  recall@10: 0.004592436\n",
      "  ndcg@10: 0.005082797\n",
      "  map@10: 0.001654445\n",
      "Epoch 349, Step 10, LR: 0.000080, Current Loss: 0.4958, Avg Loss: 0.4910\n",
      "Diff stats — min: -9.6024, max: 13.7380, mean: 0.9407, std: 1.3489\n",
      "\n",
      "Step 3835 — Test metrics:\n",
      "  precision@10: 0.004591702\n",
      "  recall@10: 0.004592436\n",
      "  ndcg@10: 0.005094614\n",
      "  map@10: 0.001662596\n",
      "Epoch 349 completed, Train Loss: 0.4911\n",
      "Epoch 350, Step 1, LR: 0.000080, Current Loss: 0.4939, Avg Loss: 0.4939\n",
      "Diff stats — min: -4.8437, max: 7.4969, mean: 0.9454, std: 1.3447\n",
      "\n",
      "Step 3837 — Test metrics:\n",
      "  precision@10: 0.004578488\n",
      "  recall@10: 0.004579222\n",
      "  ndcg@10: 0.005079491\n",
      "  map@10: 0.001656445\n",
      "Epoch 350, Step 10, LR: 0.000080, Current Loss: 0.4838, Avg Loss: 0.4905\n",
      "Diff stats — min: -4.4168, max: 6.2679, mean: 0.9708, std: 1.3388\n",
      "\n",
      "Step 3846 — Test metrics:\n",
      "  precision@10: 0.004618129\n",
      "  recall@10: 0.004618863\n",
      "  ndcg@10: 0.005070991\n",
      "  map@10: 0.001638213\n",
      "Epoch 350 completed, Train Loss: 0.4906\n",
      "Epoch 351, Step 1, LR: 0.000080, Current Loss: 0.4855, Avg Loss: 0.4855\n",
      "Diff stats — min: -4.7862, max: 7.1663, mean: 0.9680, std: 1.3437\n",
      "\n",
      "Step 3848 — Test metrics:\n",
      "  precision@10: 0.004631342\n",
      "  recall@10: 0.004632077\n",
      "  ndcg@10: 0.005088968\n",
      "  map@10: 0.001645955\n",
      "Epoch 351, Step 10, LR: 0.000080, Current Loss: 0.4848, Avg Loss: 0.4893\n",
      "Diff stats — min: -4.3267, max: 6.2760, mean: 0.9737, std: 1.3473\n",
      "\n",
      "Step 3857 — Test metrics:\n",
      "  precision@10: 0.004677590\n",
      "  recall@10: 0.004678324\n",
      "  ndcg@10: 0.005167029\n",
      "  map@10: 0.001682298\n",
      "Epoch 351 completed, Train Loss: 0.4889\n",
      "Epoch 352, Step 1, LR: 0.000080, Current Loss: 0.4883, Avg Loss: 0.4883\n",
      "Diff stats — min: -4.8333, max: 6.2012, mean: 0.9654, std: 1.3487\n",
      "\n",
      "Step 3859 — Test metrics:\n",
      "  precision@10: 0.004631342\n",
      "  recall@10: 0.004632077\n",
      "  ndcg@10: 0.005130242\n",
      "  map@10: 0.001671751\n",
      "Epoch 352, Step 10, LR: 0.000080, Current Loss: 0.4925, Avg Loss: 0.4889\n",
      "Diff stats — min: -5.4488, max: 6.9922, mean: 0.9548, std: 1.3548\n",
      "\n",
      "Step 3868 — Test metrics:\n",
      "  precision@10: 0.004618129\n",
      "  recall@10: 0.004618863\n",
      "  ndcg@10: 0.005148352\n",
      "  map@10: 0.001686934\n",
      "Epoch 352 completed, Train Loss: 0.4887\n",
      "Epoch 353, Step 1, LR: 0.000080, Current Loss: 0.4826, Avg Loss: 0.4826\n",
      "Diff stats — min: -5.3601, max: 7.1529, mean: 0.9859, std: 1.3546\n",
      "\n",
      "Step 3870 — Test metrics:\n",
      "  precision@10: 0.004624736\n",
      "  recall@10: 0.004625470\n",
      "  ndcg@10: 0.005146939\n",
      "  map@10: 0.001684274\n",
      "Epoch 353, Step 10, LR: 0.000080, Current Loss: 0.4877, Avg Loss: 0.4875\n",
      "Diff stats — min: -4.7863, max: 7.3831, mean: 0.9736, std: 1.3595\n",
      "\n",
      "Step 3879 — Test metrics:\n",
      "  precision@10: 0.004657770\n",
      "  recall@10: 0.004658504\n",
      "  ndcg@10: 0.005141706\n",
      "  map@10: 0.001672254\n",
      "Epoch 353 completed, Train Loss: 0.4875\n",
      "Epoch 354, Step 1, LR: 0.000080, Current Loss: 0.4882, Avg Loss: 0.4882\n",
      "Diff stats — min: -4.7975, max: 7.8526, mean: 0.9766, std: 1.3654\n",
      "\n",
      "Step 3881 — Test metrics:\n",
      "  precision@10: 0.004631342\n",
      "  recall@10: 0.004632077\n",
      "  ndcg@10: 0.005114305\n",
      "  map@10: 0.001663177\n",
      "Epoch 354, Step 10, LR: 0.000080, Current Loss: 0.4812, Avg Loss: 0.4862\n",
      "Diff stats — min: -6.3311, max: 7.2026, mean: 0.9914, std: 1.3564\n",
      "\n",
      "Step 3890 — Test metrics:\n",
      "  precision@10: 0.004624736\n",
      "  recall@10: 0.004625470\n",
      "  ndcg@10: 0.005087098\n",
      "  map@10: 0.001648281\n",
      "Epoch 354 completed, Train Loss: 0.4862\n",
      "Epoch 355, Step 1, LR: 0.000080, Current Loss: 0.4859, Avg Loss: 0.4859\n",
      "Diff stats — min: -4.1824, max: 7.2760, mean: 0.9783, std: 1.3593\n",
      "\n",
      "Step 3892 — Test metrics:\n",
      "  precision@10: 0.004631342\n",
      "  recall@10: 0.004632077\n",
      "  ndcg@10: 0.005097456\n",
      "  map@10: 0.001652481\n",
      "Epoch 355, Step 10, LR: 0.000080, Current Loss: 0.4858, Avg Loss: 0.4855\n",
      "Diff stats — min: -4.1880, max: 6.8109, mean: 0.9840, std: 1.3662\n",
      "\n",
      "Step 3901 — Test metrics:\n",
      "  precision@10: 0.004690803\n",
      "  recall@10: 0.004691537\n",
      "  ndcg@10: 0.005146261\n",
      "  map@10: 0.001664630\n",
      "Epoch 355 completed, Train Loss: 0.4855\n",
      "Epoch 356, Step 1, LR: 0.000080, Current Loss: 0.4898, Avg Loss: 0.4898\n",
      "Diff stats — min: -13.0600, max: 7.1710, mean: 0.9787, std: 1.3773\n",
      "\n",
      "Step 3903 — Test metrics:\n",
      "  precision@10: 0.004750264\n",
      "  recall@10: 0.004750998\n",
      "  ndcg@10: 0.005196676\n",
      "  map@10: 0.001680185\n",
      "Epoch 356, Step 10, LR: 0.000080, Current Loss: 0.4792, Avg Loss: 0.4855\n",
      "Diff stats — min: -4.7084, max: 7.5481, mean: 0.9910, std: 1.3480\n",
      "\n",
      "Step 3912 — Test metrics:\n",
      "  precision@10: 0.004756871\n",
      "  recall@10: 0.004757605\n",
      "  ndcg@10: 0.005180375\n",
      "  map@10: 0.001667121\n",
      "Epoch 356 completed, Train Loss: 0.4853\n",
      "Epoch 357, Step 1, LR: 0.000080, Current Loss: 0.4840, Avg Loss: 0.4840\n",
      "Diff stats — min: -5.2146, max: 7.8909, mean: 0.9879, std: 1.3658\n",
      "\n",
      "Step 3914 — Test metrics:\n",
      "  precision@10: 0.004697410\n",
      "  recall@10: 0.004698144\n",
      "  ndcg@10: 0.005142349\n",
      "  map@10: 0.001660779\n",
      "Epoch 357, Step 10, LR: 0.000080, Current Loss: 0.4848, Avg Loss: 0.4847\n",
      "Diff stats — min: -6.8274, max: 7.7832, mean: 0.9857, std: 1.3639\n",
      "\n",
      "Step 3923 — Test metrics:\n",
      "  precision@10: 0.004763478\n",
      "  recall@10: 0.004764212\n",
      "  ndcg@10: 0.005191336\n",
      "  map@10: 0.001672538\n",
      "Epoch 357 completed, Train Loss: 0.4851\n",
      "Epoch 358, Step 1, LR: 0.000080, Current Loss: 0.4890, Avg Loss: 0.4890\n",
      "Diff stats — min: -5.2853, max: 8.6540, mean: 0.9838, std: 1.3804\n",
      "\n",
      "Step 3925 — Test metrics:\n",
      "  precision@10: 0.004723837\n",
      "  recall@10: 0.004724571\n",
      "  ndcg@10: 0.005165690\n",
      "  map@10: 0.001668246\n",
      "Epoch 358, Step 10, LR: 0.000080, Current Loss: 0.4842, Avg Loss: 0.4842\n",
      "Diff stats — min: -4.5613, max: 7.3366, mean: 0.9913, std: 1.3696\n",
      "\n",
      "Step 3934 — Test metrics:\n",
      "  precision@10: 0.004704017\n",
      "  recall@10: 0.004704751\n",
      "  ndcg@10: 0.005166326\n",
      "  map@10: 0.001676607\n",
      "Epoch 358 completed, Train Loss: 0.4838\n",
      "Epoch 359, Step 1, LR: 0.000080, Current Loss: 0.4846, Avg Loss: 0.4846\n",
      "Diff stats — min: -5.7648, max: 6.8020, mean: 0.9941, std: 1.3745\n",
      "\n",
      "Step 3936 — Test metrics:\n",
      "  precision@10: 0.004743658\n",
      "  recall@10: 0.004744392\n",
      "  ndcg@10: 0.005189682\n",
      "  map@10: 0.001679661\n",
      "Epoch 359, Step 10, LR: 0.000080, Current Loss: 0.4792, Avg Loss: 0.4828\n",
      "Diff stats — min: -6.7444, max: 7.1171, mean: 1.0119, std: 1.3765\n",
      "\n",
      "Step 3945 — Test metrics:\n",
      "  precision@10: 0.004750264\n",
      "  recall@10: 0.004750998\n",
      "  ndcg@10: 0.005207312\n",
      "  map@10: 0.001686881\n",
      "Epoch 359 completed, Train Loss: 0.4825\n",
      "Epoch 360, Step 1, LR: 0.000080, Current Loss: 0.4784, Avg Loss: 0.4784\n",
      "Diff stats — min: -4.6429, max: 7.7091, mean: 1.0121, std: 1.3728\n",
      "\n",
      "Step 3947 — Test metrics:\n",
      "  precision@10: 0.004756871\n",
      "  recall@10: 0.004757605\n",
      "  ndcg@10: 0.005191197\n",
      "  map@10: 0.001675104\n",
      "Epoch 360, Step 10, LR: 0.000080, Current Loss: 0.4832, Avg Loss: 0.4824\n",
      "Diff stats — min: -5.3377, max: 8.4523, mean: 1.0004, std: 1.3764\n",
      "\n",
      "Step 3956 — Test metrics:\n",
      "  precision@10: 0.004750264\n",
      "  recall@10: 0.004750998\n",
      "  ndcg@10: 0.005200588\n",
      "  map@10: 0.001682859\n",
      "Epoch 360 completed, Train Loss: 0.4821\n",
      "Epoch 361, Step 1, LR: 0.000080, Current Loss: 0.4787, Avg Loss: 0.4787\n",
      "Diff stats — min: -4.5287, max: 7.0972, mean: 1.0088, std: 1.3686\n",
      "\n",
      "Step 3958 — Test metrics:\n",
      "  precision@10: 0.004750264\n",
      "  recall@10: 0.004750998\n",
      "  ndcg@10: 0.005203457\n",
      "  map@10: 0.001683735\n",
      "Epoch 361, Step 10, LR: 0.000080, Current Loss: 0.4805, Avg Loss: 0.4818\n",
      "Diff stats — min: -7.5696, max: 7.2207, mean: 1.0130, std: 1.3841\n",
      "\n",
      "Step 3967 — Test metrics:\n",
      "  precision@10: 0.004822939\n",
      "  recall@10: 0.004823673\n",
      "  ndcg@10: 0.005249398\n",
      "  map@10: 0.001688957\n",
      "Epoch 361 completed, Train Loss: 0.4821\n",
      "Epoch 362, Step 1, LR: 0.000080, Current Loss: 0.4835, Avg Loss: 0.4835\n",
      "Diff stats — min: -4.7872, max: 6.9217, mean: 1.0071, std: 1.3893\n",
      "\n",
      "Step 3969 — Test metrics:\n",
      "  precision@10: 0.004822939\n",
      "  recall@10: 0.004823673\n",
      "  ndcg@10: 0.005231891\n",
      "  map@10: 0.001677935\n",
      "Epoch 362, Step 10, LR: 0.000080, Current Loss: 0.4785, Avg Loss: 0.4801\n",
      "Diff stats — min: -5.3257, max: 6.9820, mean: 1.0219, std: 1.3887\n",
      "\n",
      "Step 3978 — Test metrics:\n",
      "  precision@10: 0.004743658\n",
      "  recall@10: 0.004744392\n",
      "  ndcg@10: 0.005187109\n",
      "  map@10: 0.001673327\n",
      "Epoch 362 completed, Train Loss: 0.4804\n",
      "Epoch 363, Step 1, LR: 0.000080, Current Loss: 0.4766, Avg Loss: 0.4766\n",
      "Diff stats — min: -4.7224, max: 8.5643, mean: 1.0289, std: 1.3886\n",
      "\n",
      "Step 3980 — Test metrics:\n",
      "  precision@10: 0.004756871\n",
      "  recall@10: 0.004757605\n",
      "  ndcg@10: 0.005196720\n",
      "  map@10: 0.001675322\n",
      "Epoch 363, Step 10, LR: 0.000080, Current Loss: 0.4815, Avg Loss: 0.4798\n",
      "Diff stats — min: -5.2123, max: 6.8801, mean: 1.0178, std: 1.3944\n",
      "\n",
      "Step 3989 — Test metrics:\n",
      "  precision@10: 0.004796512\n",
      "  recall@10: 0.004797246\n",
      "  ndcg@10: 0.005225237\n",
      "  map@10: 0.001681457\n",
      "Epoch 363 completed, Train Loss: 0.4798\n",
      "Epoch 364, Step 1, LR: 0.000080, Current Loss: 0.4768, Avg Loss: 0.4768\n",
      "Diff stats — min: -4.9250, max: 7.4242, mean: 1.0302, std: 1.3929\n",
      "\n",
      "Step 3991 — Test metrics:\n",
      "  precision@10: 0.004816332\n",
      "  recall@10: 0.004817066\n",
      "  ndcg@10: 0.005230622\n",
      "  map@10: 0.001680691\n",
      "Epoch 364, Step 10, LR: 0.000080, Current Loss: 0.4795, Avg Loss: 0.4786\n",
      "Diff stats — min: -4.7787, max: 8.5870, mean: 1.0275, std: 1.3996\n",
      "\n",
      "Step 4000 — Test metrics:\n",
      "  precision@10: 0.004829545\n",
      "  recall@10: 0.004830280\n",
      "  ndcg@10: 0.005251063\n",
      "  map@10: 0.001688769\n",
      "Epoch 364 completed, Train Loss: 0.4787\n",
      "Epoch 365, Step 1, LR: 0.000080, Current Loss: 0.4828, Avg Loss: 0.4828\n",
      "Diff stats — min: -4.0476, max: 8.5606, mean: 1.0177, std: 1.4009\n",
      "\n",
      "Step 4002 — Test metrics:\n",
      "  precision@10: 0.004869186\n",
      "  recall@10: 0.004869920\n",
      "  ndcg@10: 0.005277930\n",
      "  map@10: 0.001693338\n",
      "Epoch 365, Step 10, LR: 0.000080, Current Loss: 0.4768, Avg Loss: 0.4780\n",
      "Diff stats — min: -5.2776, max: 7.4277, mean: 1.0344, std: 1.3982\n",
      "\n",
      "Step 4011 — Test metrics:\n",
      "  precision@10: 0.004855973\n",
      "  recall@10: 0.004857441\n",
      "  ndcg@10: 0.005308096\n",
      "  map@10: 0.001714457\n",
      "Epoch 365 completed, Train Loss: 0.4773\n",
      "Epoch 366, Step 1, LR: 0.000080, Current Loss: 0.4781, Avg Loss: 0.4781\n",
      "Diff stats — min: -5.4038, max: 6.6360, mean: 1.0368, std: 1.4041\n",
      "\n",
      "Step 4013 — Test metrics:\n",
      "  precision@10: 0.004842759\n",
      "  recall@10: 0.004844227\n",
      "  ndcg@10: 0.005290591\n",
      "  map@10: 0.001708379\n",
      "Epoch 366, Step 10, LR: 0.000080, Current Loss: 0.4753, Avg Loss: 0.4775\n",
      "Diff stats — min: -5.2738, max: 10.2534, mean: 1.0345, std: 1.3921\n",
      "\n",
      "Step 4022 — Test metrics:\n",
      "  precision@10: 0.004908827\n",
      "  recall@10: 0.004909561\n",
      "  ndcg@10: 0.005325986\n",
      "  map@10: 0.001711616\n",
      "Epoch 366 completed, Train Loss: 0.4771\n",
      "Epoch 367, Step 1, LR: 0.000080, Current Loss: 0.4755, Avg Loss: 0.4755\n",
      "Diff stats — min: -5.0767, max: 7.4438, mean: 1.0408, std: 1.4009\n",
      "\n",
      "Step 4024 — Test metrics:\n",
      "  precision@10: 0.004882400\n",
      "  recall@10: 0.004883134\n",
      "  ndcg@10: 0.005315500\n",
      "  map@10: 0.001712786\n",
      "Epoch 367, Step 10, LR: 0.000080, Current Loss: 0.4702, Avg Loss: 0.4756\n",
      "Diff stats — min: -4.9934, max: 6.8709, mean: 1.0615, std: 1.4060\n",
      "\n",
      "Step 4033 — Test metrics:\n",
      "  precision@10: 0.004889006\n",
      "  recall@10: 0.004889740\n",
      "  ndcg@10: 0.005296765\n",
      "  map@10: 0.001699134\n",
      "Epoch 367 completed, Train Loss: 0.4754\n",
      "Epoch 368, Step 1, LR: 0.000080, Current Loss: 0.4733, Avg Loss: 0.4733\n",
      "Diff stats — min: -4.7226, max: 8.1780, mean: 1.0496, std: 1.4064\n",
      "\n",
      "Step 4035 — Test metrics:\n",
      "  precision@10: 0.004915433\n",
      "  recall@10: 0.004916902\n",
      "  ndcg@10: 0.005307026\n",
      "  map@10: 0.001697178\n",
      "Epoch 368, Step 10, LR: 0.000080, Current Loss: 0.4747, Avg Loss: 0.4761\n",
      "Diff stats — min: -5.6034, max: 7.9830, mean: 1.0475, std: 1.4068\n",
      "\n",
      "Step 4044 — Test metrics:\n",
      "  precision@10: 0.004961681\n",
      "  recall@10: 0.004963149\n",
      "  ndcg@10: 0.005355612\n",
      "  map@10: 0.001712615\n",
      "Epoch 368 completed, Train Loss: 0.4766\n",
      "Epoch 369, Step 1, LR: 0.000080, Current Loss: 0.4744, Avg Loss: 0.4744\n",
      "Diff stats — min: -4.8397, max: 6.7698, mean: 1.0474, std: 1.4054\n",
      "\n",
      "Step 4046 — Test metrics:\n",
      "  precision@10: 0.004955074\n",
      "  recall@10: 0.004956542\n",
      "  ndcg@10: 0.005362617\n",
      "  map@10: 0.001718476\n",
      "Epoch 369, Step 10, LR: 0.000080, Current Loss: 0.4757, Avg Loss: 0.4754\n",
      "Diff stats — min: -5.1478, max: 7.6370, mean: 1.0438, std: 1.4043\n",
      "\n",
      "Step 4055 — Test metrics:\n",
      "  precision@10: 0.004908827\n",
      "  recall@10: 0.004910295\n",
      "  ndcg@10: 0.005325185\n",
      "  map@10: 0.001711084\n",
      "Epoch 369 completed, Train Loss: 0.4750\n",
      "Epoch 370, Step 1, LR: 0.000080, Current Loss: 0.4737, Avg Loss: 0.4737\n",
      "Diff stats — min: -5.0835, max: 6.8573, mean: 1.0525, std: 1.4084\n",
      "\n",
      "Step 4057 — Test metrics:\n",
      "  precision@10: 0.004875793\n",
      "  recall@10: 0.004877261\n",
      "  ndcg@10: 0.005304000\n",
      "  map@10: 0.001708051\n",
      "Epoch 370, Step 10, LR: 0.000080, Current Loss: 0.4726, Avg Loss: 0.4740\n",
      "Diff stats — min: -4.8294, max: 7.6763, mean: 1.0557, std: 1.4096\n",
      "\n",
      "Step 4066 — Test metrics:\n",
      "  precision@10: 0.004935254\n",
      "  recall@10: 0.004936722\n",
      "  ndcg@10: 0.005326956\n",
      "  map@10: 0.001703372\n",
      "Epoch 370 completed, Train Loss: 0.4744\n",
      "Epoch 371, Step 1, LR: 0.000080, Current Loss: 0.4720, Avg Loss: 0.4720\n",
      "Diff stats — min: -5.5115, max: 7.1192, mean: 1.0583, std: 1.4113\n",
      "\n",
      "Step 4068 — Test metrics:\n",
      "  precision@10: 0.004902220\n",
      "  recall@10: 0.004903688\n",
      "  ndcg@10: 0.005290574\n",
      "  map@10: 0.001691010\n",
      "Epoch 371, Step 10, LR: 0.000080, Current Loss: 0.4697, Avg Loss: 0.4742\n",
      "Diff stats — min: -4.5751, max: 6.9295, mean: 1.0652, std: 1.4093\n",
      "\n",
      "Step 4077 — Test metrics:\n",
      "  precision@10: 0.004961681\n",
      "  recall@10: 0.004963149\n",
      "  ndcg@10: 0.005342208\n",
      "  map@10: 0.001705551\n",
      "Epoch 371 completed, Train Loss: 0.4738\n",
      "Epoch 372, Step 1, LR: 0.000080, Current Loss: 0.4774, Avg Loss: 0.4774\n",
      "Diff stats — min: -4.8568, max: 7.1098, mean: 1.0439, std: 1.4141\n",
      "\n",
      "Step 4079 — Test metrics:\n",
      "  precision@10: 0.004955074\n",
      "  recall@10: 0.004956542\n",
      "  ndcg@10: 0.005341065\n",
      "  map@10: 0.001706371\n",
      "Epoch 372, Step 10, LR: 0.000080, Current Loss: 0.4722, Avg Loss: 0.4738\n",
      "Diff stats — min: -6.7070, max: 7.5490, mean: 1.0638, std: 1.4187\n",
      "\n",
      "Step 4088 — Test metrics:\n",
      "  precision@10: 0.004955074\n",
      "  recall@10: 0.004956542\n",
      "  ndcg@10: 0.005337260\n",
      "  map@10: 0.001704469\n",
      "Epoch 372 completed, Train Loss: 0.4733\n",
      "Epoch 373, Step 1, LR: 0.000080, Current Loss: 0.4724, Avg Loss: 0.4724\n",
      "Diff stats — min: -4.7434, max: 6.9209, mean: 1.0595, std: 1.4127\n",
      "\n",
      "Step 4090 — Test metrics:\n",
      "  precision@10: 0.004974894\n",
      "  recall@10: 0.004976362\n",
      "  ndcg@10: 0.005342465\n",
      "  map@10: 0.001702679\n",
      "Epoch 373, Step 10, LR: 0.000080, Current Loss: 0.4730, Avg Loss: 0.4729\n",
      "Diff stats — min: -5.4907, max: 7.3460, mean: 1.0635, std: 1.4210\n",
      "\n",
      "Step 4099 — Test metrics:\n",
      "  precision@10: 0.004889006\n",
      "  recall@10: 0.004889740\n",
      "  ndcg@10: 0.005300818\n",
      "  map@10: 0.001700853\n",
      "Epoch 373 completed, Train Loss: 0.4728\n",
      "Epoch 374, Step 1, LR: 0.000080, Current Loss: 0.4715, Avg Loss: 0.4715\n",
      "Diff stats — min: -5.0234, max: 7.5330, mean: 1.0691, std: 1.4229\n",
      "\n",
      "Step 4101 — Test metrics:\n",
      "  precision@10: 0.004908827\n",
      "  recall@10: 0.004909561\n",
      "  ndcg@10: 0.005315853\n",
      "  map@10: 0.001703936\n",
      "Epoch 374, Step 10, LR: 0.000080, Current Loss: 0.4718, Avg Loss: 0.4713\n",
      "Diff stats — min: -5.4458, max: 7.0979, mean: 1.0696, std: 1.4211\n",
      "\n",
      "Step 4110 — Test metrics:\n",
      "  precision@10: 0.005021142\n",
      "  recall@10: 0.005022610\n",
      "  ndcg@10: 0.005420415\n",
      "  map@10: 0.001733967\n",
      "Epoch 374 completed, Train Loss: 0.4712\n",
      "Epoch 375, Step 1, LR: 0.000080, Current Loss: 0.4745, Avg Loss: 0.4745\n",
      "Diff stats — min: -7.7094, max: 7.3081, mean: 1.0638, std: 1.4301\n",
      "\n",
      "Step 4112 — Test metrics:\n",
      "  precision@10: 0.005021142\n",
      "  recall@10: 0.005022610\n",
      "  ndcg@10: 0.005418256\n",
      "  map@10: 0.001733360\n",
      "Epoch 375, Step 10, LR: 0.000080, Current Loss: 0.4679, Avg Loss: 0.4698\n",
      "Diff stats — min: -5.3414, max: 7.3838, mean: 1.0863, std: 1.4293\n",
      "\n",
      "Step 4121 — Test metrics:\n",
      "  precision@10: 0.004988108\n",
      "  recall@10: 0.004989576\n",
      "  ndcg@10: 0.005392263\n",
      "  map@10: 0.001726767\n",
      "Epoch 375 completed, Train Loss: 0.4696\n",
      "Epoch 376, Step 1, LR: 0.000080, Current Loss: 0.4659, Avg Loss: 0.4659\n",
      "Diff stats — min: -4.6255, max: 7.0764, mean: 1.0942, std: 1.4335\n",
      "\n",
      "Step 4123 — Test metrics:\n",
      "  precision@10: 0.004994715\n",
      "  recall@10: 0.004996183\n",
      "  ndcg@10: 0.005397401\n",
      "  map@10: 0.001728192\n",
      "Epoch 376, Step 10, LR: 0.000080, Current Loss: 0.4717, Avg Loss: 0.4698\n",
      "Diff stats — min: -4.8448, max: 8.8842, mean: 1.0784, std: 1.4368\n",
      "\n",
      "Step 4132 — Test metrics:\n",
      "  precision@10: 0.004974894\n",
      "  recall@10: 0.004976362\n",
      "  ndcg@10: 0.005354782\n",
      "  map@10: 0.001706898\n",
      "Epoch 376 completed, Train Loss: 0.4698\n",
      "Epoch 377, Step 1, LR: 0.000080, Current Loss: 0.4657, Avg Loss: 0.4657\n",
      "Diff stats — min: -5.1711, max: 7.1302, mean: 1.0870, std: 1.4196\n",
      "\n",
      "Step 4134 — Test metrics:\n",
      "  precision@10: 0.004974894\n",
      "  recall@10: 0.004976362\n",
      "  ndcg@10: 0.005351751\n",
      "  map@10: 0.001705577\n",
      "Epoch 377, Step 10, LR: 0.000080, Current Loss: 0.4686, Avg Loss: 0.4684\n",
      "Diff stats — min: -5.3262, max: 9.0644, mean: 1.0843, std: 1.4301\n",
      "\n",
      "Step 4143 — Test metrics:\n",
      "  precision@10: 0.004974894\n",
      "  recall@10: 0.004976362\n",
      "  ndcg@10: 0.005352081\n",
      "  map@10: 0.001704462\n",
      "Epoch 377 completed, Train Loss: 0.4684\n",
      "Epoch 378, Step 1, LR: 0.000080, Current Loss: 0.4721, Avg Loss: 0.4721\n",
      "Diff stats — min: -4.4975, max: 6.9260, mean: 1.0788, std: 1.4383\n",
      "\n",
      "Step 4145 — Test metrics:\n",
      "  precision@10: 0.004988108\n",
      "  recall@10: 0.004989576\n",
      "  ndcg@10: 0.005362181\n",
      "  map@10: 0.001706522\n",
      "Epoch 378, Step 10, LR: 0.000080, Current Loss: 0.4707, Avg Loss: 0.4697\n",
      "Diff stats — min: -5.7685, max: 8.5552, mean: 1.0907, std: 1.4488\n",
      "\n",
      "Step 4154 — Test metrics:\n",
      "  precision@10: 0.005014535\n",
      "  recall@10: 0.005016003\n",
      "  ndcg@10: 0.005430163\n",
      "  map@10: 0.001739986\n",
      "Epoch 378 completed, Train Loss: 0.4694\n",
      "Epoch 379, Step 1, LR: 0.000080, Current Loss: 0.4670, Avg Loss: 0.4670\n",
      "Diff stats — min: -5.6073, max: 7.1098, mean: 1.0931, std: 1.4320\n",
      "\n",
      "Step 4156 — Test metrics:\n",
      "  precision@10: 0.005021142\n",
      "  recall@10: 0.005022610\n",
      "  ndcg@10: 0.005439006\n",
      "  map@10: 0.001743198\n",
      "Epoch 379, Step 10, LR: 0.000080, Current Loss: 0.4700, Avg Loss: 0.4678\n",
      "Diff stats — min: -5.0128, max: 7.9651, mean: 1.0968, std: 1.4530\n",
      "\n",
      "Step 4165 — Test metrics:\n",
      "  precision@10: 0.005021142\n",
      "  recall@10: 0.005022610\n",
      "  ndcg@10: 0.005415072\n",
      "  map@10: 0.001729464\n",
      "Epoch 379 completed, Train Loss: 0.4681\n",
      "Epoch 380, Step 1, LR: 0.000080, Current Loss: 0.4712, Avg Loss: 0.4712\n",
      "Diff stats — min: -5.1104, max: 7.6889, mean: 1.0872, std: 1.4455\n",
      "\n",
      "Step 4167 — Test metrics:\n",
      "  precision@10: 0.005014535\n",
      "  recall@10: 0.005016003\n",
      "  ndcg@10: 0.005412401\n",
      "  map@10: 0.001729832\n",
      "Epoch 380, Step 10, LR: 0.000080, Current Loss: 0.4710, Avg Loss: 0.4686\n",
      "Diff stats — min: -6.2275, max: 7.6741, mean: 1.0877, std: 1.4467\n",
      "\n",
      "Step 4176 — Test metrics:\n",
      "  precision@10: 0.005021142\n",
      "  recall@10: 0.005022610\n",
      "  ndcg@10: 0.005416000\n",
      "  map@10: 0.001728330\n",
      "Epoch 380 completed, Train Loss: 0.4683\n",
      "Epoch 381, Step 1, LR: 0.000080, Current Loss: 0.4663, Avg Loss: 0.4663\n",
      "Diff stats — min: -5.2996, max: 8.7323, mean: 1.1022, std: 1.4477\n",
      "\n",
      "Step 4178 — Test metrics:\n",
      "  precision@10: 0.005021142\n",
      "  recall@10: 0.005022610\n",
      "  ndcg@10: 0.005436091\n",
      "  map@10: 0.001739867\n",
      "Epoch 381, Step 10, LR: 0.000080, Current Loss: 0.4691, Avg Loss: 0.4669\n",
      "Diff stats — min: -5.1740, max: 7.9264, mean: 1.0940, std: 1.4457\n",
      "\n",
      "Step 4187 — Test metrics:\n",
      "  precision@10: 0.005040962\n",
      "  recall@10: 0.005042430\n",
      "  ndcg@10: 0.005427383\n",
      "  map@10: 0.001729573\n",
      "Epoch 381 completed, Train Loss: 0.4668\n",
      "Epoch 382, Step 1, LR: 0.000080, Current Loss: 0.4646, Avg Loss: 0.4646\n",
      "Diff stats — min: -5.1624, max: 7.9259, mean: 1.1072, std: 1.4438\n",
      "\n",
      "Step 4189 — Test metrics:\n",
      "  precision@10: 0.005014535\n",
      "  recall@10: 0.005016003\n",
      "  ndcg@10: 0.005402725\n",
      "  map@10: 0.001722992\n",
      "Epoch 382, Step 10, LR: 0.000080, Current Loss: 0.4692, Avg Loss: 0.4650\n",
      "Diff stats — min: -6.2139, max: 9.3079, mean: 1.0969, std: 1.4513\n",
      "\n",
      "Step 4198 — Test metrics:\n",
      "  precision@10: 0.005060782\n",
      "  recall@10: 0.005062250\n",
      "  ndcg@10: 0.005451019\n",
      "  map@10: 0.001738901\n",
      "Epoch 382 completed, Train Loss: 0.4654\n",
      "Epoch 383, Step 1, LR: 0.000080, Current Loss: 0.4573, Avg Loss: 0.4573\n",
      "Diff stats — min: -4.7427, max: 8.0802, mean: 1.1275, std: 1.4406\n",
      "\n",
      "Step 4200 — Test metrics:\n",
      "  precision@10: 0.005067389\n",
      "  recall@10: 0.005068857\n",
      "  ndcg@10: 0.005464073\n",
      "  map@10: 0.001744354\n",
      "Epoch 383, Step 10, LR: 0.000080, Current Loss: 0.4654, Avg Loss: 0.4649\n",
      "Diff stats — min: -5.0390, max: 8.8987, mean: 1.1081, std: 1.4501\n",
      "\n",
      "Step 4209 — Test metrics:\n",
      "  precision@10: 0.005087209\n",
      "  recall@10: 0.005088677\n",
      "  ndcg@10: 0.005506411\n",
      "  map@10: 0.001762509\n",
      "Epoch 383 completed, Train Loss: 0.4654\n",
      "Epoch 384, Step 1, LR: 0.000080, Current Loss: 0.4645, Avg Loss: 0.4645\n",
      "Diff stats — min: -5.1663, max: 9.0420, mean: 1.1112, std: 1.4496\n",
      "\n",
      "Step 4211 — Test metrics:\n",
      "  precision@10: 0.005100423\n",
      "  recall@10: 0.005101891\n",
      "  ndcg@10: 0.005510155\n",
      "  map@10: 0.001760923\n",
      "Epoch 384, Step 10, LR: 0.000080, Current Loss: 0.4681, Avg Loss: 0.4637\n",
      "Diff stats — min: -6.1045, max: 7.3589, mean: 1.1015, std: 1.4524\n",
      "\n",
      "Step 4220 — Test metrics:\n",
      "  precision@10: 0.005080603\n",
      "  recall@10: 0.005082071\n",
      "  ndcg@10: 0.005455234\n",
      "  map@10: 0.001733261\n",
      "Epoch 384 completed, Train Loss: 0.4638\n",
      "Epoch 385, Step 1, LR: 0.000080, Current Loss: 0.4633, Avg Loss: 0.4633\n",
      "Diff stats — min: -5.8008, max: 6.8602, mean: 1.1241, std: 1.4607\n",
      "\n",
      "Step 4222 — Test metrics:\n",
      "  precision@10: 0.005060782\n",
      "  recall@10: 0.005062250\n",
      "  ndcg@10: 0.005433223\n",
      "  map@10: 0.001726567\n",
      "Epoch 385, Step 10, LR: 0.000080, Current Loss: 0.4631, Avg Loss: 0.4633\n",
      "Diff stats — min: -5.1887, max: 8.1807, mean: 1.1295, std: 1.4654\n",
      "\n",
      "Step 4231 — Test metrics:\n",
      "  precision@10: 0.005001321\n",
      "  recall@10: 0.005002790\n",
      "  ndcg@10: 0.005383025\n",
      "  map@10: 0.001714133\n",
      "Epoch 385 completed, Train Loss: 0.4636\n",
      "Epoch 386, Step 1, LR: 0.000080, Current Loss: 0.4643, Avg Loss: 0.4643\n",
      "Diff stats — min: -5.2084, max: 8.8292, mean: 1.1212, std: 1.4614\n",
      "\n",
      "Step 4233 — Test metrics:\n",
      "  precision@10: 0.004994715\n",
      "  recall@10: 0.004996183\n",
      "  ndcg@10: 0.005392523\n",
      "  map@10: 0.001722496\n",
      "Epoch 386, Step 10, LR: 0.000080, Current Loss: 0.4571, Avg Loss: 0.4629\n",
      "Diff stats — min: -5.0431, max: 8.5133, mean: 1.1392, std: 1.4539\n",
      "\n",
      "Step 4242 — Test metrics:\n",
      "  precision@10: 0.005021142\n",
      "  recall@10: 0.005021876\n",
      "  ndcg@10: 0.005441943\n",
      "  map@10: 0.001741860\n",
      "Epoch 386 completed, Train Loss: 0.4622\n",
      "Epoch 387, Step 1, LR: 0.000080, Current Loss: 0.4580, Avg Loss: 0.4580\n",
      "Diff stats — min: -5.6354, max: 7.7065, mean: 1.1431, std: 1.4628\n",
      "\n",
      "Step 4244 — Test metrics:\n",
      "  precision@10: 0.005054175\n",
      "  recall@10: 0.005054910\n",
      "  ndcg@10: 0.005467122\n",
      "  map@10: 0.001747524\n",
      "Epoch 387, Step 10, LR: 0.000080, Current Loss: 0.4638, Avg Loss: 0.4616\n",
      "Diff stats — min: -5.1639, max: 7.9428, mean: 1.1296, std: 1.4695\n",
      "\n",
      "Step 4253 — Test metrics:\n",
      "  precision@10: 0.005133457\n",
      "  recall@10: 0.005134191\n",
      "  ndcg@10: 0.005503217\n",
      "  map@10: 0.001746537\n",
      "Epoch 387 completed, Train Loss: 0.4614\n",
      "Epoch 388, Step 1, LR: 0.000080, Current Loss: 0.4622, Avg Loss: 0.4622\n",
      "Diff stats — min: -5.1439, max: 10.7048, mean: 1.1382, std: 1.4759\n",
      "\n",
      "Step 4255 — Test metrics:\n",
      "  precision@10: 0.005126850\n",
      "  recall@10: 0.005127584\n",
      "  ndcg@10: 0.005481808\n",
      "  map@10: 0.001736381\n",
      "Epoch 388, Step 10, LR: 0.000080, Current Loss: 0.4611, Avg Loss: 0.4600\n",
      "Diff stats — min: -5.0781, max: 7.3822, mean: 1.1290, std: 1.4587\n",
      "\n",
      "Step 4264 — Test metrics:\n",
      "  precision@10: 0.005100423\n",
      "  recall@10: 0.005101157\n",
      "  ndcg@10: 0.005482528\n",
      "  map@10: 0.001743712\n",
      "Epoch 388 completed, Train Loss: 0.4596\n",
      "Epoch 389, Step 1, LR: 0.000080, Current Loss: 0.4624, Avg Loss: 0.4624\n",
      "Diff stats — min: -4.8368, max: 8.0167, mean: 1.1443, std: 1.4820\n",
      "\n",
      "Step 4266 — Test metrics:\n",
      "  precision@10: 0.005067389\n",
      "  recall@10: 0.005068123\n",
      "  ndcg@10: 0.005469861\n",
      "  map@10: 0.001744988\n",
      "Epoch 389, Step 10, LR: 0.000080, Current Loss: 0.4624, Avg Loss: 0.4604\n",
      "Diff stats — min: -5.3893, max: 7.5322, mean: 1.1339, std: 1.4694\n",
      "\n",
      "Step 4275 — Test metrics:\n",
      "  precision@10: 0.005126850\n",
      "  recall@10: 0.005128318\n",
      "  ndcg@10: 0.005516441\n",
      "  map@10: 0.001755769\n",
      "Epoch 389 completed, Train Loss: 0.4604\n",
      "Epoch 390, Step 1, LR: 0.000080, Current Loss: 0.4571, Avg Loss: 0.4571\n",
      "Diff stats — min: -5.2584, max: 7.8317, mean: 1.1476, std: 1.4669\n",
      "\n",
      "Step 4277 — Test metrics:\n",
      "  precision@10: 0.005107030\n",
      "  recall@10: 0.005107764\n",
      "  ndcg@10: 0.005509138\n",
      "  map@10: 0.001757187\n",
      "Epoch 390, Step 10, LR: 0.000080, Current Loss: 0.4578, Avg Loss: 0.4599\n",
      "Diff stats — min: -4.8434, max: 8.2692, mean: 1.1552, std: 1.4779\n",
      "\n",
      "Step 4286 — Test metrics:\n",
      "  precision@10: 0.005146670\n",
      "  recall@10: 0.005147404\n",
      "  ndcg@10: 0.005538245\n",
      "  map@10: 0.001763180\n",
      "Epoch 390 completed, Train Loss: 0.4599\n",
      "Epoch 391, Step 1, LR: 0.000080, Current Loss: 0.4627, Avg Loss: 0.4627\n",
      "Diff stats — min: -5.4967, max: 8.6575, mean: 1.1401, std: 1.4804\n",
      "\n",
      "Step 4288 — Test metrics:\n",
      "  precision@10: 0.005146670\n",
      "  recall@10: 0.005147404\n",
      "  ndcg@10: 0.005547298\n",
      "  map@10: 0.001769161\n",
      "Epoch 391, Step 10, LR: 0.000080, Current Loss: 0.4582, Avg Loss: 0.4593\n",
      "Diff stats — min: -4.7140, max: 7.7731, mean: 1.1559, std: 1.4790\n",
      "\n",
      "Step 4297 — Test metrics:\n",
      "  precision@10: 0.005113636\n",
      "  recall@10: 0.005114370\n",
      "  ndcg@10: 0.005524256\n",
      "  map@10: 0.001765358\n",
      "Epoch 391 completed, Train Loss: 0.4592\n",
      "Epoch 392, Step 1, LR: 0.000080, Current Loss: 0.4536, Avg Loss: 0.4536\n",
      "Diff stats — min: -4.8392, max: 7.8732, mean: 1.1642, std: 1.4718\n",
      "\n",
      "Step 4299 — Test metrics:\n",
      "  precision@10: 0.005133457\n",
      "  recall@10: 0.005134191\n",
      "  ndcg@10: 0.005530315\n",
      "  map@10: 0.001763148\n",
      "Epoch 392, Step 10, LR: 0.000080, Current Loss: 0.4646, Avg Loss: 0.4586\n",
      "Diff stats — min: -5.2982, max: 7.2567, mean: 1.1395, std: 1.4844\n",
      "\n",
      "Step 4308 — Test metrics:\n",
      "  precision@10: 0.005153277\n",
      "  recall@10: 0.005154011\n",
      "  ndcg@10: 0.005526799\n",
      "  map@10: 0.001753876\n",
      "Epoch 392 completed, Train Loss: 0.4583\n",
      "Epoch 393, Step 1, LR: 0.000080, Current Loss: 0.4594, Avg Loss: 0.4594\n",
      "Diff stats — min: -5.8680, max: 9.1344, mean: 1.1598, std: 1.4913\n",
      "\n",
      "Step 4310 — Test metrics:\n",
      "  precision@10: 0.005153277\n",
      "  recall@10: 0.005154011\n",
      "  ndcg@10: 0.005528367\n",
      "  map@10: 0.001754159\n",
      "Epoch 393, Step 10, LR: 0.000080, Current Loss: 0.4541, Avg Loss: 0.4577\n",
      "Diff stats — min: -6.4651, max: 6.9814, mean: 1.1666, std: 1.4772\n",
      "\n",
      "Step 4319 — Test metrics:\n",
      "  precision@10: 0.005173097\n",
      "  recall@10: 0.005173831\n",
      "  ndcg@10: 0.005532720\n",
      "  map@10: 0.001754256\n",
      "Epoch 393 completed, Train Loss: 0.4576\n",
      "Epoch 394, Step 1, LR: 0.000080, Current Loss: 0.4573, Avg Loss: 0.4573\n",
      "Diff stats — min: -5.8699, max: 10.4104, mean: 1.1683, std: 1.4941\n",
      "\n",
      "Step 4321 — Test metrics:\n",
      "  precision@10: 0.005159884\n",
      "  recall@10: 0.005160618\n",
      "  ndcg@10: 0.005526096\n",
      "  map@10: 0.001752087\n",
      "Epoch 394, Step 10, LR: 0.000080, Current Loss: 0.4602, Avg Loss: 0.4580\n",
      "Diff stats — min: -4.6260, max: 10.0949, mean: 1.1591, std: 1.4949\n",
      "\n",
      "Step 4330 — Test metrics:\n",
      "  precision@10: 0.005173097\n",
      "  recall@10: 0.005173831\n",
      "  ndcg@10: 0.005537637\n",
      "  map@10: 0.001755181\n",
      "Epoch 394 completed, Train Loss: 0.4577\n",
      "Epoch 395, Step 1, LR: 0.000080, Current Loss: 0.4569, Avg Loss: 0.4569\n",
      "Diff stats — min: -4.8145, max: 9.1516, mean: 1.1711, std: 1.4932\n",
      "\n",
      "Step 4332 — Test metrics:\n",
      "  precision@10: 0.005166490\n",
      "  recall@10: 0.005167225\n",
      "  ndcg@10: 0.005536773\n",
      "  map@10: 0.001756345\n",
      "Epoch 395, Step 10, LR: 0.000080, Current Loss: 0.4586, Avg Loss: 0.4566\n",
      "Diff stats — min: -6.2133, max: 7.8337, mean: 1.1652, std: 1.4966\n",
      "\n",
      "Step 4341 — Test metrics:\n",
      "  precision@10: 0.005159884\n",
      "  recall@10: 0.005160618\n",
      "  ndcg@10: 0.005525256\n",
      "  map@10: 0.001751616\n",
      "Epoch 395 completed, Train Loss: 0.4563\n",
      "Epoch 396, Step 1, LR: 0.000080, Current Loss: 0.4598, Avg Loss: 0.4598\n",
      "Diff stats — min: -6.0952, max: 7.4075, mean: 1.1599, std: 1.4928\n",
      "\n",
      "Step 4343 — Test metrics:\n",
      "  precision@10: 0.005146670\n",
      "  recall@10: 0.005147404\n",
      "  ndcg@10: 0.005514854\n",
      "  map@10: 0.001749224\n",
      "Epoch 396, Step 10, LR: 0.000080, Current Loss: 0.4520, Avg Loss: 0.4561\n",
      "Diff stats — min: -4.4772, max: 7.2909, mean: 1.1844, std: 1.4928\n",
      "\n",
      "Step 4352 — Test metrics:\n",
      "  precision@10: 0.005192918\n",
      "  recall@10: 0.005193652\n",
      "  ndcg@10: 0.005571681\n",
      "  map@10: 0.001768452\n",
      "Epoch 396 completed, Train Loss: 0.4562\n",
      "Epoch 397, Step 1, LR: 0.000080, Current Loss: 0.4532, Avg Loss: 0.4532\n",
      "Diff stats — min: -5.4860, max: 6.9074, mean: 1.1861, std: 1.4985\n",
      "\n",
      "Step 4354 — Test metrics:\n",
      "  precision@10: 0.005225951\n",
      "  recall@10: 0.005226685\n",
      "  ndcg@10: 0.005594414\n",
      "  map@10: 0.001772463\n",
      "Epoch 397, Step 10, LR: 0.000080, Current Loss: 0.4566, Avg Loss: 0.4553\n",
      "Diff stats — min: -5.3320, max: 9.2502, mean: 1.1803, std: 1.5060\n",
      "\n",
      "Step 4363 — Test metrics:\n",
      "  precision@10: 0.005298626\n",
      "  recall@10: 0.005299360\n",
      "  ndcg@10: 0.005665757\n",
      "  map@10: 0.001796374\n",
      "Epoch 397 completed, Train Loss: 0.4553\n",
      "Epoch 398, Step 1, LR: 0.000080, Current Loss: 0.4548, Avg Loss: 0.4548\n",
      "Diff stats — min: -5.0895, max: 10.3490, mean: 1.1842, std: 1.5025\n",
      "\n",
      "Step 4365 — Test metrics:\n",
      "  precision@10: 0.005311839\n",
      "  recall@10: 0.005312573\n",
      "  ndcg@10: 0.005673708\n",
      "  map@10: 0.001797229\n",
      "Epoch 398, Step 10, LR: 0.000080, Current Loss: 0.4535, Avg Loss: 0.4550\n",
      "Diff stats — min: -5.3886, max: 7.2520, mean: 1.1805, std: 1.4922\n",
      "\n",
      "Step 4374 — Test metrics:\n",
      "  precision@10: 0.005245772\n",
      "  recall@10: 0.005247240\n",
      "  ndcg@10: 0.005601122\n",
      "  map@10: 0.001769697\n",
      "Epoch 398 completed, Train Loss: 0.4552\n",
      "Epoch 399, Step 1, LR: 0.000080, Current Loss: 0.4560, Avg Loss: 0.4560\n",
      "Diff stats — min: -5.0335, max: 7.8964, mean: 1.1797, std: 1.5029\n",
      "\n",
      "Step 4376 — Test metrics:\n",
      "  precision@10: 0.005225951\n",
      "  recall@10: 0.005227420\n",
      "  ndcg@10: 0.005569597\n",
      "  map@10: 0.001756846\n",
      "Epoch 399, Step 10, LR: 0.000080, Current Loss: 0.4535, Avg Loss: 0.4541\n",
      "Diff stats — min: -4.5847, max: 6.7607, mean: 1.1852, std: 1.4980\n",
      "\n",
      "Step 4385 — Test metrics:\n",
      "  precision@10: 0.005159884\n",
      "  recall@10: 0.005160618\n",
      "  ndcg@10: 0.005528540\n",
      "  map@10: 0.001751100\n",
      "Epoch 399 completed, Train Loss: 0.4542\n",
      "Epoch 400, Step 1, LR: 0.000080, Current Loss: 0.4481, Avg Loss: 0.4481\n",
      "Diff stats — min: -4.7895, max: 9.2670, mean: 1.2056, std: 1.5021\n",
      "\n",
      "Step 4387 — Test metrics:\n",
      "  precision@10: 0.005146670\n",
      "  recall@10: 0.005147404\n",
      "  ndcg@10: 0.005528488\n",
      "  map@10: 0.001755153\n",
      "Epoch 400, Step 10, LR: 0.000080, Current Loss: 0.4500, Avg Loss: 0.4527\n",
      "Diff stats — min: -5.5725, max: 10.8006, mean: 1.1983, std: 1.5005\n",
      "\n",
      "Step 4396 — Test metrics:\n",
      "  precision@10: 0.005232558\n",
      "  recall@10: 0.005233292\n",
      "  ndcg@10: 0.005590550\n",
      "  map@10: 0.001769667\n",
      "Epoch 400 completed, Train Loss: 0.4527\n",
      "Epoch 401, Step 1, LR: 0.000080, Current Loss: 0.4525, Avg Loss: 0.4525\n",
      "Diff stats — min: -5.6408, max: 8.1266, mean: 1.1916, std: 1.5028\n",
      "\n",
      "Step 4398 — Test metrics:\n",
      "  precision@10: 0.005245772\n",
      "  recall@10: 0.005246506\n",
      "  ndcg@10: 0.005602038\n",
      "  map@10: 0.001773618\n",
      "Epoch 401, Step 10, LR: 0.000080, Current Loss: 0.4525, Avg Loss: 0.4529\n",
      "Diff stats — min: -5.8634, max: 11.6130, mean: 1.1971, std: 1.5120\n",
      "\n",
      "Step 4407 — Test metrics:\n",
      "  precision@10: 0.005278805\n",
      "  recall@10: 0.005279540\n",
      "  ndcg@10: 0.005630646\n",
      "  map@10: 0.001778942\n",
      "Epoch 401 completed, Train Loss: 0.4531\n",
      "Epoch 402, Step 1, LR: 0.000080, Current Loss: 0.4523, Avg Loss: 0.4523\n",
      "Diff stats — min: -5.9335, max: 7.0558, mean: 1.2012, std: 1.5132\n",
      "\n",
      "Step 4409 — Test metrics:\n",
      "  precision@10: 0.005305233\n",
      "  recall@10: 0.005305967\n",
      "  ndcg@10: 0.005652648\n",
      "  map@10: 0.001783997\n",
      "Epoch 402, Step 10, LR: 0.000080, Current Loss: 0.4520, Avg Loss: 0.4518\n",
      "Diff stats — min: -4.7118, max: 7.9286, mean: 1.1947, std: 1.5010\n",
      "\n",
      "Step 4418 — Test metrics:\n",
      "  precision@10: 0.005364693\n",
      "  recall@10: 0.005364693\n",
      "  ndcg@10: 0.005695724\n",
      "  map@10: 0.001792788\n",
      "Epoch 402 completed, Train Loss: 0.4515\n",
      "Epoch 403, Step 1, LR: 0.000080, Current Loss: 0.4492, Avg Loss: 0.4492\n",
      "Diff stats — min: -5.0703, max: 7.6130, mean: 1.2092, std: 1.5108\n",
      "\n",
      "Step 4420 — Test metrics:\n",
      "  precision@10: 0.005338266\n",
      "  recall@10: 0.005338266\n",
      "  ndcg@10: 0.005682280\n",
      "  map@10: 0.001792303\n",
      "Epoch 403, Step 10, LR: 0.000080, Current Loss: 0.4500, Avg Loss: 0.4518\n",
      "Diff stats — min: -5.5434, max: 8.1027, mean: 1.2023, std: 1.5077\n",
      "\n",
      "Step 4429 — Test metrics:\n",
      "  precision@10: 0.005325053\n",
      "  recall@10: 0.005325053\n",
      "  ndcg@10: 0.005671931\n",
      "  map@10: 0.001790205\n",
      "Epoch 403 completed, Train Loss: 0.4512\n",
      "Epoch 404, Step 1, LR: 0.000080, Current Loss: 0.4545, Avg Loss: 0.4545\n",
      "Diff stats — min: -5.0929, max: 8.4054, mean: 1.1990, std: 1.5211\n",
      "\n",
      "Step 4431 — Test metrics:\n",
      "  precision@10: 0.005298626\n",
      "  recall@10: 0.005298626\n",
      "  ndcg@10: 0.005658798\n",
      "  map@10: 0.001789702\n",
      "Epoch 404, Step 10, LR: 0.000080, Current Loss: 0.4513, Avg Loss: 0.4521\n",
      "Diff stats — min: -6.2416, max: 8.8202, mean: 1.2017, std: 1.5086\n",
      "\n",
      "Step 4440 — Test metrics:\n",
      "  precision@10: 0.005285412\n",
      "  recall@10: 0.005286146\n",
      "  ndcg@10: 0.005644580\n",
      "  map@10: 0.001783777\n",
      "Epoch 404 completed, Train Loss: 0.4516\n",
      "Epoch 405, Step 1, LR: 0.000080, Current Loss: 0.4520, Avg Loss: 0.4520\n",
      "Diff stats — min: -5.1600, max: 8.0965, mean: 1.2063, std: 1.5174\n",
      "\n",
      "Step 4442 — Test metrics:\n",
      "  precision@10: 0.005305233\n",
      "  recall@10: 0.005305967\n",
      "  ndcg@10: 0.005656093\n",
      "  map@10: 0.001787363\n",
      "Epoch 405, Step 10, LR: 0.000080, Current Loss: 0.4560, Avg Loss: 0.4504\n",
      "Diff stats — min: -5.1455, max: 8.5350, mean: 1.1980, std: 1.5260\n",
      "\n",
      "Step 4451 — Test metrics:\n",
      "  precision@10: 0.005272199\n",
      "  recall@10: 0.005273667\n",
      "  ndcg@10: 0.005617001\n",
      "  map@10: 0.001773405\n",
      "Epoch 405 completed, Train Loss: 0.4499\n",
      "Epoch 406, Step 1, LR: 0.000080, Current Loss: 0.4471, Avg Loss: 0.4471\n",
      "Diff stats — min: -5.2587, max: 7.4338, mean: 1.2249, std: 1.5200\n",
      "\n",
      "Step 4453 — Test metrics:\n",
      "  precision@10: 0.005338266\n",
      "  recall@10: 0.005339735\n",
      "  ndcg@10: 0.005663163\n",
      "  map@10: 0.001783376\n",
      "Epoch 406, Step 10, LR: 0.000080, Current Loss: 0.4473, Avg Loss: 0.4489\n",
      "Diff stats — min: -7.1031, max: 10.2904, mean: 1.2190, std: 1.5187\n",
      "\n",
      "Step 4462 — Test metrics:\n",
      "  precision@10: 0.005285412\n",
      "  recall@10: 0.005286146\n",
      "  ndcg@10: 0.005634941\n",
      "  map@10: 0.001779554\n",
      "Epoch 406 completed, Train Loss: 0.4493\n",
      "Epoch 407, Step 1, LR: 0.000080, Current Loss: 0.4526, Avg Loss: 0.4526\n",
      "Diff stats — min: -5.7660, max: 8.8321, mean: 1.2097, std: 1.5282\n",
      "\n",
      "Step 4464 — Test metrics:\n",
      "  precision@10: 0.005292019\n",
      "  recall@10: 0.005292753\n",
      "  ndcg@10: 0.005639752\n",
      "  map@10: 0.001779732\n",
      "Epoch 407, Step 10, LR: 0.000080, Current Loss: 0.4449, Avg Loss: 0.4486\n",
      "Diff stats — min: -4.8064, max: 8.0177, mean: 1.2317, std: 1.5203\n",
      "\n",
      "Step 4473 — Test metrics:\n",
      "  precision@10: 0.005272199\n",
      "  recall@10: 0.005272933\n",
      "  ndcg@10: 0.005641700\n",
      "  map@10: 0.001787610\n",
      "Epoch 407 completed, Train Loss: 0.4488\n",
      "Epoch 408, Step 1, LR: 0.000080, Current Loss: 0.4443, Avg Loss: 0.4443\n",
      "Diff stats — min: -4.7168, max: 10.5169, mean: 1.2358, std: 1.5247\n",
      "\n",
      "Step 4475 — Test metrics:\n",
      "  precision@10: 0.005278805\n",
      "  recall@10: 0.005279540\n",
      "  ndcg@10: 0.005642747\n",
      "  map@10: 0.001785272\n",
      "Epoch 408, Step 10, LR: 0.000080, Current Loss: 0.4474, Avg Loss: 0.4470\n",
      "Diff stats — min: -4.9476, max: 11.3057, mean: 1.2305, std: 1.5310\n",
      "\n",
      "Step 4484 — Test metrics:\n",
      "  precision@10: 0.005397727\n",
      "  recall@10: 0.005399195\n",
      "  ndcg@10: 0.005718182\n",
      "  map@10: 0.001798317\n",
      "Epoch 408 completed, Train Loss: 0.4471\n",
      "Epoch 409, Step 1, LR: 0.000080, Current Loss: 0.4446, Avg Loss: 0.4446\n",
      "Diff stats — min: -5.1106, max: 8.3028, mean: 1.2362, std: 1.5249\n",
      "\n",
      "Step 4486 — Test metrics:\n",
      "  precision@10: 0.005391121\n",
      "  recall@10: 0.005392589\n",
      "  ndcg@10: 0.005713209\n",
      "  map@10: 0.001797494\n",
      "Epoch 409, Step 10, LR: 0.000080, Current Loss: 0.4482, Avg Loss: 0.4477\n",
      "Diff stats — min: -5.2195, max: 8.1299, mean: 1.2361, std: 1.5449\n",
      "\n",
      "Step 4495 — Test metrics:\n",
      "  precision@10: 0.005391121\n",
      "  recall@10: 0.005391855\n",
      "  ndcg@10: 0.005725773\n",
      "  map@10: 0.001803542\n",
      "Epoch 409 completed, Train Loss: 0.4478\n",
      "Epoch 410, Step 1, LR: 0.000080, Current Loss: 0.4455, Avg Loss: 0.4455\n",
      "Diff stats — min: -5.6370, max: 8.9340, mean: 1.2363, std: 1.5300\n",
      "\n",
      "Step 4497 — Test metrics:\n",
      "  precision@10: 0.005377907\n",
      "  recall@10: 0.005379375\n",
      "  ndcg@10: 0.005729783\n",
      "  map@10: 0.001809163\n",
      "Epoch 410, Step 10, LR: 0.000080, Current Loss: 0.4473, Avg Loss: 0.4472\n",
      "Diff stats — min: -5.7403, max: 7.7428, mean: 1.2295, std: 1.5262\n",
      "\n",
      "Step 4506 — Test metrics:\n",
      "  precision@10: 0.005305233\n",
      "  recall@10: 0.005305967\n",
      "  ndcg@10: 0.005664359\n",
      "  map@10: 0.001791563\n",
      "Epoch 410 completed, Train Loss: 0.4470\n",
      "Epoch 411, Step 1, LR: 0.000080, Current Loss: 0.4481, Avg Loss: 0.4481\n",
      "Diff stats — min: -4.7297, max: 8.1026, mean: 1.2293, std: 1.5320\n",
      "\n",
      "Step 4508 — Test metrics:\n",
      "  precision@10: 0.005338266\n",
      "  recall@10: 0.005339735\n",
      "  ndcg@10: 0.005678072\n",
      "  map@10: 0.001790218\n",
      "Epoch 411, Step 10, LR: 0.000080, Current Loss: 0.4407, Avg Loss: 0.4455\n",
      "Diff stats — min: -5.8217, max: 8.1409, mean: 1.2493, std: 1.5261\n",
      "\n",
      "Step 4517 — Test metrics:\n",
      "  precision@10: 0.005318446\n",
      "  recall@10: 0.005320648\n",
      "  ndcg@10: 0.005669451\n",
      "  map@10: 0.001791233\n",
      "Epoch 411 completed, Train Loss: 0.4458\n",
      "Epoch 412, Step 1, LR: 0.000080, Current Loss: 0.4457, Avg Loss: 0.4457\n",
      "Diff stats — min: -6.1264, max: 7.9296, mean: 1.2439, std: 1.5380\n",
      "\n",
      "Step 4519 — Test metrics:\n",
      "  precision@10: 0.005364693\n",
      "  recall@10: 0.005366896\n",
      "  ndcg@10: 0.005706790\n",
      "  map@10: 0.001800540\n",
      "Epoch 412, Step 10, LR: 0.000080, Current Loss: 0.4454, Avg Loss: 0.4451\n",
      "Diff stats — min: -4.5316, max: 8.4941, mean: 1.2388, std: 1.5334\n",
      "\n",
      "Step 4528 — Test metrics:\n",
      "  precision@10: 0.005344873\n",
      "  recall@10: 0.005346341\n",
      "  ndcg@10: 0.005707991\n",
      "  map@10: 0.001805394\n",
      "Epoch 412 completed, Train Loss: 0.4449\n",
      "Epoch 413, Step 1, LR: 0.000080, Current Loss: 0.4408, Avg Loss: 0.4408\n",
      "Diff stats — min: -5.4431, max: 8.7479, mean: 1.2585, std: 1.5364\n",
      "\n",
      "Step 4530 — Test metrics:\n",
      "  precision@10: 0.005358087\n",
      "  recall@10: 0.005359555\n",
      "  ndcg@10: 0.005708711\n",
      "  map@10: 0.001802992\n",
      "Epoch 413, Step 10, LR: 0.000080, Current Loss: 0.4468, Avg Loss: 0.4428\n",
      "Diff stats — min: -5.7101, max: 8.0135, mean: 1.2346, std: 1.5337\n",
      "\n",
      "Step 4539 — Test metrics:\n",
      "  precision@10: 0.005391121\n",
      "  recall@10: 0.005392589\n",
      "  ndcg@10: 0.005730054\n",
      "  map@10: 0.001804552\n",
      "Epoch 413 completed, Train Loss: 0.4433\n",
      "Epoch 414, Step 1, LR: 0.000080, Current Loss: 0.4423, Avg Loss: 0.4423\n",
      "Diff stats — min: -5.0144, max: 7.4137, mean: 1.2584, std: 1.5397\n",
      "\n",
      "Step 4541 — Test metrics:\n",
      "  precision@10: 0.005457188\n",
      "  recall@10: 0.005458656\n",
      "  ndcg@10: 0.005763618\n",
      "  map@10: 0.001807155\n",
      "Epoch 414, Step 10, LR: 0.000080, Current Loss: 0.4433, Avg Loss: 0.4441\n",
      "Diff stats — min: -6.3249, max: 7.4631, mean: 1.2589, std: 1.5465\n",
      "\n",
      "Step 4550 — Test metrics:\n",
      "  precision@10: 0.005391121\n",
      "  recall@10: 0.005392589\n",
      "  ndcg@10: 0.005696838\n",
      "  map@10: 0.001787765\n",
      "Epoch 414 completed, Train Loss: 0.4434\n",
      "Epoch 415, Step 1, LR: 0.000080, Current Loss: 0.4437, Avg Loss: 0.4437\n",
      "Diff stats — min: -5.3746, max: 7.2288, mean: 1.2507, std: 1.5385\n",
      "\n",
      "Step 4552 — Test metrics:\n",
      "  precision@10: 0.005351480\n",
      "  recall@10: 0.005352948\n",
      "  ndcg@10: 0.005673261\n",
      "  map@10: 0.001786789\n",
      "Epoch 415, Step 10, LR: 0.000080, Current Loss: 0.4417, Avg Loss: 0.4429\n",
      "Diff stats — min: -5.6161, max: 8.0005, mean: 1.2661, std: 1.5490\n",
      "\n",
      "Step 4561 — Test metrics:\n",
      "  precision@10: 0.005351480\n",
      "  recall@10: 0.005353682\n",
      "  ndcg@10: 0.005720076\n",
      "  map@10: 0.001813072\n",
      "Epoch 415 completed, Train Loss: 0.4425\n",
      "Epoch 416, Step 1, LR: 0.000080, Current Loss: 0.4414, Avg Loss: 0.4414\n",
      "Diff stats — min: -5.5299, max: 8.7615, mean: 1.2591, std: 1.5387\n",
      "\n",
      "Step 4563 — Test metrics:\n",
      "  precision@10: 0.005298626\n",
      "  recall@10: 0.005300828\n",
      "  ndcg@10: 0.005682360\n",
      "  map@10: 0.001803830\n",
      "Epoch 416, Step 10, LR: 0.000080, Current Loss: 0.4395, Avg Loss: 0.4421\n",
      "Diff stats — min: -4.8843, max: 8.8616, mean: 1.2677, std: 1.5436\n",
      "\n",
      "Step 4572 — Test metrics:\n",
      "  precision@10: 0.005344873\n",
      "  recall@10: 0.005346341\n",
      "  ndcg@10: 0.005727314\n",
      "  map@10: 0.001817044\n",
      "Epoch 416 completed, Train Loss: 0.4422\n",
      "Epoch 417, Step 1, LR: 0.000080, Current Loss: 0.4420, Avg Loss: 0.4420\n",
      "Diff stats — min: -12.6304, max: 8.7850, mean: 1.2711, std: 1.5578\n",
      "\n",
      "Step 4574 — Test metrics:\n",
      "  precision@10: 0.005351480\n",
      "  recall@10: 0.005353682\n",
      "  ndcg@10: 0.005719297\n",
      "  map@10: 0.001810086\n",
      "Epoch 417, Step 10, LR: 0.000080, Current Loss: 0.4401, Avg Loss: 0.4404\n",
      "Diff stats — min: -5.2004, max: 8.2502, mean: 1.2674, std: 1.5437\n",
      "\n",
      "Step 4583 — Test metrics:\n",
      "  precision@10: 0.005410941\n",
      "  recall@10: 0.005413143\n",
      "  ndcg@10: 0.005755355\n",
      "  map@10: 0.001814810\n",
      "Epoch 417 completed, Train Loss: 0.4406\n",
      "Epoch 418, Step 1, LR: 0.000080, Current Loss: 0.4389, Avg Loss: 0.4389\n",
      "Diff stats — min: -5.0067, max: 8.3046, mean: 1.2746, std: 1.5509\n",
      "\n",
      "Step 4585 — Test metrics:\n",
      "  precision@10: 0.005377907\n",
      "  recall@10: 0.005380109\n",
      "  ndcg@10: 0.005716038\n",
      "  map@10: 0.001800082\n",
      "Epoch 418, Step 10, LR: 0.000080, Current Loss: 0.4456, Avg Loss: 0.4410\n",
      "Diff stats — min: -6.9921, max: 8.2064, mean: 1.2619, std: 1.5629\n",
      "\n",
      "Step 4594 — Test metrics:\n",
      "  precision@10: 0.005377907\n",
      "  recall@10: 0.005380109\n",
      "  ndcg@10: 0.005698646\n",
      "  map@10: 0.001790562\n",
      "Epoch 418 completed, Train Loss: 0.4409\n",
      "Epoch 419, Step 1, LR: 0.000080, Current Loss: 0.4397, Avg Loss: 0.4397\n",
      "Diff stats — min: -4.8447, max: 9.1635, mean: 1.2723, std: 1.5468\n",
      "\n",
      "Step 4596 — Test metrics:\n",
      "  precision@10: 0.005351480\n",
      "  recall@10: 0.005353682\n",
      "  ndcg@10: 0.005701803\n",
      "  map@10: 0.001799489\n",
      "Epoch 419, Step 10, LR: 0.000080, Current Loss: 0.4414, Avg Loss: 0.4403\n",
      "Diff stats — min: -5.4190, max: 8.6297, mean: 1.2781, std: 1.5648\n",
      "\n",
      "Step 4605 — Test metrics:\n",
      "  precision@10: 0.005371300\n",
      "  recall@10: 0.005374237\n",
      "  ndcg@10: 0.005727473\n",
      "  map@10: 0.001808760\n",
      "Epoch 419 completed, Train Loss: 0.4408\n",
      "Epoch 420, Step 1, LR: 0.000080, Current Loss: 0.4402, Avg Loss: 0.4402\n",
      "Diff stats — min: -5.7245, max: 8.3280, mean: 1.2803, std: 1.5607\n",
      "\n",
      "Step 4607 — Test metrics:\n",
      "  precision@10: 0.005371300\n",
      "  recall@10: 0.005374237\n",
      "  ndcg@10: 0.005737782\n",
      "  map@10: 0.001815649\n",
      "Epoch 420, Step 10, LR: 0.000080, Current Loss: 0.4444, Avg Loss: 0.4410\n",
      "Diff stats — min: -6.1880, max: 8.5589, mean: 1.2691, std: 1.5688\n",
      "\n",
      "Step 4616 — Test metrics:\n",
      "  precision@10: 0.005377907\n",
      "  recall@10: 0.005379375\n",
      "  ndcg@10: 0.005750426\n",
      "  map@10: 0.001820869\n",
      "Epoch 420 completed, Train Loss: 0.4411\n",
      "Epoch 421, Step 1, LR: 0.000080, Current Loss: 0.4401, Avg Loss: 0.4401\n",
      "Diff stats — min: -4.9992, max: 7.4496, mean: 1.2775, std: 1.5576\n",
      "\n",
      "Step 4618 — Test metrics:\n",
      "  precision@10: 0.005391121\n",
      "  recall@10: 0.005393323\n",
      "  ndcg@10: 0.005741874\n",
      "  map@10: 0.001811788\n",
      "Epoch 421, Step 10, LR: 0.000080, Current Loss: 0.4381, Avg Loss: 0.4412\n",
      "Diff stats — min: -5.3751, max: 7.6779, mean: 1.2954, std: 1.5695\n",
      "\n",
      "Step 4627 — Test metrics:\n",
      "  precision@10: 0.005443975\n",
      "  recall@10: 0.005446177\n",
      "  ndcg@10: 0.005779916\n",
      "  map@10: 0.001818688\n",
      "Epoch 421 completed, Train Loss: 0.4408\n",
      "Epoch 422, Step 1, LR: 0.000080, Current Loss: 0.4373, Avg Loss: 0.4373\n",
      "Diff stats — min: -5.2929, max: 8.4484, mean: 1.2820, std: 1.5530\n",
      "\n",
      "Step 4629 — Test metrics:\n",
      "  precision@10: 0.005450581\n",
      "  recall@10: 0.005452784\n",
      "  ndcg@10: 0.005780446\n",
      "  map@10: 0.001817613\n",
      "Epoch 422, Step 10, LR: 0.000080, Current Loss: 0.4410, Avg Loss: 0.4391\n",
      "Diff stats — min: -6.8950, max: 7.5083, mean: 1.2915, std: 1.5766\n",
      "\n",
      "Step 4638 — Test metrics:\n",
      "  precision@10: 0.005424154\n",
      "  recall@10: 0.005426357\n",
      "  ndcg@10: 0.005767938\n",
      "  map@10: 0.001815807\n",
      "Epoch 422 completed, Train Loss: 0.4390\n",
      "Epoch 423, Step 1, LR: 0.000080, Current Loss: 0.4372, Avg Loss: 0.4372\n",
      "Diff stats — min: -5.3336, max: 8.5711, mean: 1.2968, std: 1.5684\n",
      "\n",
      "Step 4640 — Test metrics:\n",
      "  precision@10: 0.005430761\n",
      "  recall@10: 0.005432963\n",
      "  ndcg@10: 0.005781553\n",
      "  map@10: 0.001821965\n",
      "Epoch 423, Step 10, LR: 0.000080, Current Loss: 0.4363, Avg Loss: 0.4398\n",
      "Diff stats — min: -4.6142, max: 10.1696, mean: 1.3032, std: 1.5726\n",
      "\n",
      "Step 4649 — Test metrics:\n",
      "  precision@10: 0.005410941\n",
      "  recall@10: 0.005413143\n",
      "  ndcg@10: 0.005752212\n",
      "  map@10: 0.001813416\n",
      "Epoch 423 completed, Train Loss: 0.4395\n",
      "Epoch 424, Step 1, LR: 0.000080, Current Loss: 0.4369, Avg Loss: 0.4369\n",
      "Diff stats — min: -5.1496, max: 7.7674, mean: 1.3044, std: 1.5741\n",
      "\n",
      "Step 4651 — Test metrics:\n",
      "  precision@10: 0.005397727\n",
      "  recall@10: 0.005399930\n",
      "  ndcg@10: 0.005747305\n",
      "  map@10: 0.001813869\n",
      "Epoch 424, Step 10, LR: 0.000080, Current Loss: 0.4399, Avg Loss: 0.4381\n",
      "Diff stats — min: -6.0585, max: 9.9931, mean: 1.2876, std: 1.5674\n",
      "\n",
      "Step 4660 — Test metrics:\n",
      "  precision@10: 0.005556290\n",
      "  recall@10: 0.005558492\n",
      "  ndcg@10: 0.005865298\n",
      "  map@10: 0.001840467\n",
      "Epoch 424 completed, Train Loss: 0.4379\n",
      "Epoch 425, Step 1, LR: 0.000080, Current Loss: 0.4377, Avg Loss: 0.4377\n",
      "Diff stats — min: -5.8484, max: 8.7455, mean: 1.2968, std: 1.5698\n",
      "\n",
      "Step 4662 — Test metrics:\n",
      "  precision@10: 0.005536469\n",
      "  recall@10: 0.005538672\n",
      "  ndcg@10: 0.005856850\n",
      "  map@10: 0.001839263\n",
      "Epoch 425, Step 10, LR: 0.000080, Current Loss: 0.4426, Avg Loss: 0.4382\n",
      "Diff stats — min: -5.3157, max: 7.3769, mean: 1.2822, std: 1.5739\n",
      "\n",
      "Step 4671 — Test metrics:\n",
      "  precision@10: 0.005496829\n",
      "  recall@10: 0.005499031\n",
      "  ndcg@10: 0.005763492\n",
      "  map@10: 0.001796527\n",
      "Epoch 425 completed, Train Loss: 0.4380\n",
      "Epoch 426, Step 1, LR: 0.000080, Current Loss: 0.4363, Avg Loss: 0.4363\n",
      "Diff stats — min: -4.7166, max: 8.1352, mean: 1.3032, std: 1.5725\n",
      "\n",
      "Step 4673 — Test metrics:\n",
      "  precision@10: 0.005503436\n",
      "  recall@10: 0.005505638\n",
      "  ndcg@10: 0.005769554\n",
      "  map@10: 0.001797610\n",
      "Epoch 426, Step 10, LR: 0.000080, Current Loss: 0.4389, Avg Loss: 0.4366\n",
      "Diff stats — min: -4.7902, max: 10.5178, mean: 1.3020, std: 1.5810\n",
      "\n",
      "Step 4682 — Test metrics:\n",
      "  precision@10: 0.005470402\n",
      "  recall@10: 0.005472604\n",
      "  ndcg@10: 0.005786296\n",
      "  map@10: 0.001816153\n",
      "Epoch 426 completed, Train Loss: 0.4367\n",
      "Epoch 427, Step 1, LR: 0.000080, Current Loss: 0.4364, Avg Loss: 0.4364\n",
      "Diff stats — min: -5.0736, max: 8.6996, mean: 1.3044, std: 1.5736\n",
      "\n",
      "Step 4684 — Test metrics:\n",
      "  precision@10: 0.005457188\n",
      "  recall@10: 0.005459390\n",
      "  ndcg@10: 0.005777900\n",
      "  map@10: 0.001814355\n",
      "Epoch 427, Step 10, LR: 0.000080, Current Loss: 0.4385, Avg Loss: 0.4361\n",
      "Diff stats — min: -8.2057, max: 13.4441, mean: 1.3019, std: 1.5831\n",
      "\n",
      "Step 4693 — Test metrics:\n",
      "  precision@10: 0.005450581\n",
      "  recall@10: 0.005452784\n",
      "  ndcg@10: 0.005790325\n",
      "  map@10: 0.001822888\n",
      "Epoch 427 completed, Train Loss: 0.4360\n",
      "Epoch 428, Step 1, LR: 0.000080, Current Loss: 0.4374, Avg Loss: 0.4374\n",
      "Diff stats — min: -4.9995, max: 9.8273, mean: 1.3007, std: 1.5749\n",
      "\n",
      "Step 4695 — Test metrics:\n",
      "  precision@10: 0.005424154\n",
      "  recall@10: 0.005426357\n",
      "  ndcg@10: 0.005788453\n",
      "  map@10: 0.001829657\n",
      "Epoch 428, Step 10, LR: 0.000080, Current Loss: 0.4357, Avg Loss: 0.4353\n",
      "Diff stats — min: -9.4404, max: 9.2632, mean: 1.3084, std: 1.5774\n",
      "\n",
      "Step 4704 — Test metrics:\n",
      "  precision@10: 0.005463795\n",
      "  recall@10: 0.005466731\n",
      "  ndcg@10: 0.005811808\n",
      "  map@10: 0.001834183\n",
      "Epoch 428 completed, Train Loss: 0.4350\n",
      "Epoch 429, Step 1, LR: 0.000080, Current Loss: 0.4368, Avg Loss: 0.4368\n",
      "Diff stats — min: -6.3970, max: 9.0767, mean: 1.3141, std: 1.5890\n",
      "\n",
      "Step 4706 — Test metrics:\n",
      "  precision@10: 0.005437368\n",
      "  recall@10: 0.005440304\n",
      "  ndcg@10: 0.005784993\n",
      "  map@10: 0.001826742\n",
      "Epoch 429, Step 10, LR: 0.000080, Current Loss: 0.4283, Avg Loss: 0.4352\n",
      "Diff stats — min: -4.8178, max: 8.1190, mean: 1.3268, std: 1.5707\n",
      "\n",
      "Step 4715 — Test metrics:\n",
      "  precision@10: 0.005457188\n",
      "  recall@10: 0.005459390\n",
      "  ndcg@10: 0.005775919\n",
      "  map@10: 0.001817715\n",
      "Epoch 429 completed, Train Loss: 0.4358\n",
      "Epoch 430, Step 1, LR: 0.000080, Current Loss: 0.4372, Avg Loss: 0.4372\n",
      "Diff stats — min: -5.0130, max: 8.0325, mean: 1.3103, std: 1.5872\n",
      "\n",
      "Step 4717 — Test metrics:\n",
      "  precision@10: 0.005457188\n",
      "  recall@10: 0.005459390\n",
      "  ndcg@10: 0.005772470\n",
      "  map@10: 0.001814501\n",
      "Epoch 430, Step 10, LR: 0.000080, Current Loss: 0.4348, Avg Loss: 0.4341\n",
      "Diff stats — min: -5.6773, max: 12.8337, mean: 1.3173, std: 1.5832\n",
      "\n",
      "Step 4726 — Test metrics:\n",
      "  precision@10: 0.005562896\n",
      "  recall@10: 0.005565099\n",
      "  ndcg@10: 0.005876845\n",
      "  map@10: 0.001844153\n",
      "Epoch 430 completed, Train Loss: 0.4339\n",
      "Epoch 431, Step 1, LR: 0.000080, Current Loss: 0.4379, Avg Loss: 0.4379\n",
      "Diff stats — min: -8.6111, max: 8.7104, mean: 1.3179, std: 1.5979\n",
      "\n",
      "Step 4728 — Test metrics:\n",
      "  precision@10: 0.005529863\n",
      "  recall@10: 0.005532065\n",
      "  ndcg@10: 0.005850366\n",
      "  map@10: 0.001837496\n",
      "Epoch 431, Step 10, LR: 0.000080, Current Loss: 0.4308, Avg Loss: 0.4351\n",
      "Diff stats — min: -6.2347, max: 10.0300, mean: 1.3412, std: 1.5922\n",
      "\n",
      "Step 4737 — Test metrics:\n",
      "  precision@10: 0.005595930\n",
      "  recall@10: 0.005598132\n",
      "  ndcg@10: 0.005921329\n",
      "  map@10: 0.001862179\n",
      "Epoch 431 completed, Train Loss: 0.4344\n",
      "Epoch 432, Step 1, LR: 0.000080, Current Loss: 0.4385, Avg Loss: 0.4385\n",
      "Diff stats — min: -5.2226, max: 8.0870, mean: 1.3092, std: 1.5887\n",
      "\n",
      "Step 4739 — Test metrics:\n",
      "  precision@10: 0.005576110\n",
      "  recall@10: 0.005578312\n",
      "  ndcg@10: 0.005907358\n",
      "  map@10: 0.001858939\n",
      "Epoch 432, Step 10, LR: 0.000080, Current Loss: 0.4263, Avg Loss: 0.4329\n",
      "Diff stats — min: -5.0722, max: 7.7462, mean: 1.3422, std: 1.5780\n",
      "\n",
      "Step 4748 — Test metrics:\n",
      "  precision@10: 0.005576110\n",
      "  recall@10: 0.005578312\n",
      "  ndcg@10: 0.005855287\n",
      "  map@10: 0.001828939\n",
      "Epoch 432 completed, Train Loss: 0.4329\n",
      "Epoch 433, Step 1, LR: 0.000080, Current Loss: 0.4279, Avg Loss: 0.4279\n",
      "Diff stats — min: -5.1002, max: 9.7607, mean: 1.3365, std: 1.5772\n",
      "\n",
      "Step 4750 — Test metrics:\n",
      "  precision@10: 0.005576110\n",
      "  recall@10: 0.005578312\n",
      "  ndcg@10: 0.005855671\n",
      "  map@10: 0.001829857\n",
      "Epoch 433, Step 10, LR: 0.000080, Current Loss: 0.4307, Avg Loss: 0.4314\n",
      "Diff stats — min: -4.9887, max: 8.1764, mean: 1.3383, std: 1.5949\n",
      "\n",
      "Step 4759 — Test metrics:\n",
      "  precision@10: 0.005556290\n",
      "  recall@10: 0.005558492\n",
      "  ndcg@10: 0.005833209\n",
      "  map@10: 0.001822194\n",
      "Epoch 433 completed, Train Loss: 0.4321\n",
      "Epoch 434, Step 1, LR: 0.000080, Current Loss: 0.4294, Avg Loss: 0.4294\n",
      "Diff stats — min: -5.4279, max: 8.6809, mean: 1.3494, std: 1.6021\n",
      "\n",
      "Step 4761 — Test metrics:\n",
      "  precision@10: 0.005562896\n",
      "  recall@10: 0.005565099\n",
      "  ndcg@10: 0.005842299\n",
      "  map@10: 0.001824545\n",
      "Epoch 434, Step 10, LR: 0.000080, Current Loss: 0.4301, Avg Loss: 0.4313\n",
      "Diff stats — min: -5.5486, max: 8.4637, mean: 1.3425, std: 1.5979\n",
      "\n",
      "Step 4770 — Test metrics:\n",
      "  precision@10: 0.005595930\n",
      "  recall@10: 0.005598132\n",
      "  ndcg@10: 0.005877726\n",
      "  map@10: 0.001837241\n",
      "Epoch 434 completed, Train Loss: 0.4319\n",
      "Epoch 435, Step 1, LR: 0.000080, Current Loss: 0.4314, Avg Loss: 0.4314\n",
      "Diff stats — min: -5.1482, max: 8.5135, mean: 1.3325, std: 1.5889\n",
      "\n",
      "Step 4772 — Test metrics:\n",
      "  precision@10: 0.005556290\n",
      "  recall@10: 0.005558492\n",
      "  ndcg@10: 0.005855998\n",
      "  map@10: 0.001835487\n",
      "Epoch 435, Step 10, LR: 0.000080, Current Loss: 0.4288, Avg Loss: 0.4322\n",
      "Diff stats — min: -4.9580, max: 8.5830, mean: 1.3476, std: 1.5942\n",
      "\n",
      "Step 4781 — Test metrics:\n",
      "  precision@10: 0.005510042\n",
      "  recall@10: 0.005512245\n",
      "  ndcg@10: 0.005848684\n",
      "  map@10: 0.001844129\n",
      "Epoch 435 completed, Train Loss: 0.4322\n",
      "Epoch 436, Step 1, LR: 0.000080, Current Loss: 0.4293, Avg Loss: 0.4293\n",
      "Diff stats — min: -6.8431, max: 8.0610, mean: 1.3442, std: 1.5909\n",
      "\n",
      "Step 4783 — Test metrics:\n",
      "  precision@10: 0.005543076\n",
      "  recall@10: 0.005545278\n",
      "  ndcg@10: 0.005857877\n",
      "  map@10: 0.001839995\n",
      "Epoch 436, Step 10, LR: 0.000080, Current Loss: 0.4295, Avg Loss: 0.4318\n",
      "Diff stats — min: -5.7545, max: 8.3153, mean: 1.3456, std: 1.5937\n",
      "\n",
      "Step 4792 — Test metrics:\n",
      "  precision@10: 0.005562896\n",
      "  recall@10: 0.005565099\n",
      "  ndcg@10: 0.005845052\n",
      "  map@10: 0.001827762\n",
      "Epoch 436 completed, Train Loss: 0.4319\n",
      "Epoch 437, Step 1, LR: 0.000080, Current Loss: 0.4271, Avg Loss: 0.4271\n",
      "Diff stats — min: -6.1837, max: 8.2155, mean: 1.3561, std: 1.5996\n",
      "\n",
      "Step 4794 — Test metrics:\n",
      "  precision@10: 0.005595930\n",
      "  recall@10: 0.005598132\n",
      "  ndcg@10: 0.005869525\n",
      "  map@10: 0.001832263\n",
      "Epoch 437, Step 10, LR: 0.000080, Current Loss: 0.4308, Avg Loss: 0.4308\n",
      "Diff stats — min: -5.4683, max: 10.3855, mean: 1.3534, std: 1.6113\n",
      "\n",
      "Step 4803 — Test metrics:\n",
      "  precision@10: 0.005609144\n",
      "  recall@10: 0.005611346\n",
      "  ndcg@10: 0.005884133\n",
      "  map@10: 0.001837441\n",
      "Epoch 437 completed, Train Loss: 0.4305\n",
      "Epoch 438, Step 1, LR: 0.000080, Current Loss: 0.4277, Avg Loss: 0.4277\n",
      "Diff stats — min: -5.0428, max: 8.7274, mean: 1.3529, std: 1.5943\n",
      "\n",
      "Step 4805 — Test metrics:\n",
      "  precision@10: 0.005622357\n",
      "  recall@10: 0.005624560\n",
      "  ndcg@10: 0.005885656\n",
      "  map@10: 0.001835050\n",
      "Epoch 438, Step 10, LR: 0.000080, Current Loss: 0.4307, Avg Loss: 0.4291\n",
      "Diff stats — min: -5.8883, max: 9.9303, mean: 1.3502, std: 1.6066\n",
      "\n",
      "Step 4814 — Test metrics:\n",
      "  precision@10: 0.005628964\n",
      "  recall@10: 0.005631166\n",
      "  ndcg@10: 0.005905734\n",
      "  map@10: 0.001845687\n",
      "Epoch 438 completed, Train Loss: 0.4293\n",
      "Epoch 439, Step 1, LR: 0.000080, Current Loss: 0.4307, Avg Loss: 0.4307\n",
      "Diff stats — min: -5.3057, max: 9.6746, mean: 1.3385, std: 1.5916\n",
      "\n",
      "Step 4816 — Test metrics:\n",
      "  precision@10: 0.005635571\n",
      "  recall@10: 0.005637773\n",
      "  ndcg@10: 0.005924028\n",
      "  map@10: 0.001854850\n",
      "Epoch 439, Step 10, LR: 0.000080, Current Loss: 0.4271, Avg Loss: 0.4291\n",
      "Diff stats — min: -5.0739, max: 8.5462, mean: 1.3607, std: 1.6022\n",
      "\n",
      "Step 4825 — Test metrics:\n",
      "  precision@10: 0.005628964\n",
      "  recall@10: 0.005631166\n",
      "  ndcg@10: 0.005910802\n",
      "  map@10: 0.001849433\n",
      "Epoch 439 completed, Train Loss: 0.4289\n",
      "Epoch 440, Step 1, LR: 0.000080, Current Loss: 0.4295, Avg Loss: 0.4295\n",
      "Diff stats — min: -5.4741, max: 8.3334, mean: 1.3614, std: 1.6170\n",
      "\n",
      "Step 4827 — Test metrics:\n",
      "  precision@10: 0.005622357\n",
      "  recall@10: 0.005624560\n",
      "  ndcg@10: 0.005910011\n",
      "  map@10: 0.001849469\n",
      "Epoch 440, Step 10, LR: 0.000080, Current Loss: 0.4335, Avg Loss: 0.4287\n",
      "Diff stats — min: -5.2501, max: 8.0667, mean: 1.3472, std: 1.6134\n",
      "\n",
      "Step 4836 — Test metrics:\n",
      "  precision@10: 0.005648784\n",
      "  recall@10: 0.005650987\n",
      "  ndcg@10: 0.005898798\n",
      "  map@10: 0.001835871\n",
      "Epoch 440 completed, Train Loss: 0.4284\n",
      "Epoch 441, Step 1, LR: 0.000080, Current Loss: 0.4266, Avg Loss: 0.4266\n",
      "Diff stats — min: -5.6454, max: 9.8958, mean: 1.3686, std: 1.6098\n",
      "\n",
      "Step 4838 — Test metrics:\n",
      "  precision@10: 0.005642178\n",
      "  recall@10: 0.005644380\n",
      "  ndcg@10: 0.005896419\n",
      "  map@10: 0.001836073\n",
      "Epoch 441, Step 10, LR: 0.000080, Current Loss: 0.4245, Avg Loss: 0.4273\n",
      "Diff stats — min: -5.1865, max: 10.1289, mean: 1.3742, std: 1.6075\n",
      "\n",
      "Step 4847 — Test metrics:\n",
      "  precision@10: 0.005576110\n",
      "  recall@10: 0.005578312\n",
      "  ndcg@10: 0.005867090\n",
      "  map@10: 0.001839633\n",
      "Epoch 441 completed, Train Loss: 0.4275\n",
      "Epoch 442, Step 1, LR: 0.000080, Current Loss: 0.4319, Avg Loss: 0.4319\n",
      "Diff stats — min: -6.0187, max: 8.6423, mean: 1.3538, std: 1.6190\n",
      "\n",
      "Step 4849 — Test metrics:\n",
      "  precision@10: 0.005615751\n",
      "  recall@10: 0.005617953\n",
      "  ndcg@10: 0.005894150\n",
      "  map@10: 0.001845323\n",
      "Epoch 442, Step 10, LR: 0.000080, Current Loss: 0.4232, Avg Loss: 0.4270\n",
      "Diff stats — min: -5.8353, max: 9.5259, mean: 1.3818, std: 1.6139\n",
      "\n",
      "Step 4858 — Test metrics:\n",
      "  precision@10: 0.005714852\n",
      "  recall@10: 0.005717054\n",
      "  ndcg@10: 0.005997549\n",
      "  map@10: 0.001878526\n",
      "Epoch 442 completed, Train Loss: 0.4265\n",
      "Epoch 443, Step 1, LR: 0.000080, Current Loss: 0.4321, Avg Loss: 0.4321\n",
      "Diff stats — min: -5.2049, max: 7.8941, mean: 1.3622, std: 1.6267\n",
      "\n",
      "Step 4860 — Test metrics:\n",
      "  precision@10: 0.005721459\n",
      "  recall@10: 0.005723661\n",
      "  ndcg@10: 0.005990920\n",
      "  map@10: 0.001871967\n",
      "Epoch 443, Step 10, LR: 0.000080, Current Loss: 0.4258, Avg Loss: 0.4272\n",
      "Diff stats — min: -5.6452, max: 10.4458, mean: 1.3733, std: 1.6138\n",
      "\n",
      "Step 4869 — Test metrics:\n",
      "  precision@10: 0.005728066\n",
      "  recall@10: 0.005730268\n",
      "  ndcg@10: 0.005966175\n",
      "  map@10: 0.001855455\n",
      "Epoch 443 completed, Train Loss: 0.4268\n",
      "Epoch 444, Step 1, LR: 0.000080, Current Loss: 0.4293, Avg Loss: 0.4293\n",
      "Diff stats — min: -5.6462, max: 9.3580, mean: 1.3735, std: 1.6302\n",
      "\n",
      "Step 4871 — Test metrics:\n",
      "  precision@10: 0.005695032\n",
      "  recall@10: 0.005697234\n",
      "  ndcg@10: 0.005957858\n",
      "  map@10: 0.001859726\n",
      "Epoch 444, Step 10, LR: 0.000080, Current Loss: 0.4268, Avg Loss: 0.4263\n",
      "Diff stats — min: -5.2774, max: 10.9364, mean: 1.3696, std: 1.6128\n",
      "\n",
      "Step 4880 — Test metrics:\n",
      "  precision@10: 0.005661998\n",
      "  recall@10: 0.005664200\n",
      "  ndcg@10: 0.005847182\n",
      "  map@10: 0.001802502\n",
      "Epoch 444 completed, Train Loss: 0.4262\n",
      "Epoch 445, Step 1, LR: 0.000080, Current Loss: 0.4361, Avg Loss: 0.4361\n",
      "Diff stats — min: -5.2053, max: 10.4841, mean: 1.3504, std: 1.6275\n",
      "\n",
      "Step 4882 — Test metrics:\n",
      "  precision@10: 0.005675211\n",
      "  recall@10: 0.005677414\n",
      "  ndcg@10: 0.005867651\n",
      "  map@10: 0.001810005\n",
      "Epoch 445, Step 10, LR: 0.000080, Current Loss: 0.4224, Avg Loss: 0.4254\n",
      "Diff stats — min: -4.9876, max: 9.5419, mean: 1.3991, std: 1.6326\n",
      "\n",
      "Step 4891 — Test metrics:\n",
      "  precision@10: 0.005655391\n",
      "  recall@10: 0.005657593\n",
      "  ndcg@10: 0.005853833\n",
      "  map@10: 0.001808778\n",
      "Epoch 445 completed, Train Loss: 0.4258\n",
      "Epoch 446, Step 1, LR: 0.000080, Current Loss: 0.4218, Avg Loss: 0.4218\n",
      "Diff stats — min: -5.5087, max: 8.4318, mean: 1.3886, std: 1.6158\n",
      "\n",
      "Step 4893 — Test metrics:\n",
      "  precision@10: 0.005708245\n",
      "  recall@10: 0.005710447\n",
      "  ndcg@10: 0.005905953\n",
      "  map@10: 0.001827182\n",
      "Epoch 446, Step 10, LR: 0.000080, Current Loss: 0.4281, Avg Loss: 0.4251\n",
      "Diff stats — min: -6.6749, max: 9.2287, mean: 1.3792, std: 1.6325\n",
      "\n",
      "Step 4902 — Test metrics:\n",
      "  precision@10: 0.005695032\n",
      "  recall@10: 0.005697234\n",
      "  ndcg@10: 0.005961998\n",
      "  map@10: 0.001863155\n",
      "Epoch 446 completed, Train Loss: 0.4248\n",
      "Epoch 447, Step 1, LR: 0.000080, Current Loss: 0.4232, Avg Loss: 0.4232\n",
      "Diff stats — min: -5.8756, max: 7.6340, mean: 1.3872, std: 1.6185\n",
      "\n",
      "Step 4904 — Test metrics:\n",
      "  precision@10: 0.005668605\n",
      "  recall@10: 0.005670807\n",
      "  ndcg@10: 0.005917995\n",
      "  map@10: 0.001842289\n",
      "Epoch 447, Step 10, LR: 0.000080, Current Loss: 0.4193, Avg Loss: 0.4243\n",
      "Diff stats — min: -5.8400, max: 8.6346, mean: 1.3974, std: 1.6123\n",
      "\n",
      "Step 4913 — Test metrics:\n",
      "  precision@10: 0.005648784\n",
      "  recall@10: 0.005650987\n",
      "  ndcg@10: 0.005897518\n",
      "  map@10: 0.001836323\n",
      "Epoch 447 completed, Train Loss: 0.4239\n",
      "Epoch 448, Step 1, LR: 0.000080, Current Loss: 0.4290, Avg Loss: 0.4290\n",
      "Diff stats — min: -5.1335, max: 8.0063, mean: 1.3785, std: 1.6285\n",
      "\n",
      "Step 4915 — Test metrics:\n",
      "  precision@10: 0.005655391\n",
      "  recall@10: 0.005657593\n",
      "  ndcg@10: 0.005912752\n",
      "  map@10: 0.001845368\n",
      "Epoch 448, Step 10, LR: 0.000080, Current Loss: 0.4229, Avg Loss: 0.4255\n",
      "Diff stats — min: -5.6902, max: 9.0930, mean: 1.3933, std: 1.6236\n",
      "\n",
      "Step 4924 — Test metrics:\n",
      "  precision@10: 0.005688425\n",
      "  recall@10: 0.005690627\n",
      "  ndcg@10: 0.005944755\n",
      "  map@10: 0.001852977\n",
      "Epoch 448 completed, Train Loss: 0.4250\n",
      "Epoch 449, Step 1, LR: 0.000080, Current Loss: 0.4247, Avg Loss: 0.4247\n",
      "Diff stats — min: -5.7324, max: 8.6660, mean: 1.3971, std: 1.6327\n",
      "\n",
      "Step 4926 — Test metrics:\n",
      "  precision@10: 0.005741279\n",
      "  recall@10: 0.005743481\n",
      "  ndcg@10: 0.005991263\n",
      "  map@10: 0.001866046\n",
      "Epoch 449, Step 10, LR: 0.000080, Current Loss: 0.4273, Avg Loss: 0.4237\n",
      "Diff stats — min: -5.5091, max: 10.5955, mean: 1.3846, std: 1.6345\n",
      "\n",
      "Step 4935 — Test metrics:\n",
      "  precision@10: 0.005761099\n",
      "  recall@10: 0.005763302\n",
      "  ndcg@10: 0.006007651\n",
      "  map@10: 0.001871504\n",
      "Epoch 449 completed, Train Loss: 0.4237\n",
      "Epoch 450, Step 1, LR: 0.000080, Current Loss: 0.4197, Avg Loss: 0.4197\n",
      "Diff stats — min: -6.2867, max: 8.2565, mean: 1.4111, std: 1.6306\n",
      "\n",
      "Step 4937 — Test metrics:\n",
      "  precision@10: 0.005754493\n",
      "  recall@10: 0.005756695\n",
      "  ndcg@10: 0.006027206\n",
      "  map@10: 0.001885109\n",
      "Epoch 450, Step 10, LR: 0.000080, Current Loss: 0.4238, Avg Loss: 0.4227\n",
      "Diff stats — min: -8.7614, max: 8.7406, mean: 1.4001, std: 1.6360\n",
      "\n",
      "Step 4946 — Test metrics:\n",
      "  precision@10: 0.005708245\n",
      "  recall@10: 0.005710447\n",
      "  ndcg@10: 0.006007299\n",
      "  map@10: 0.001888236\n",
      "Epoch 450 completed, Train Loss: 0.4220\n",
      "Epoch 451, Step 1, LR: 0.000080, Current Loss: 0.4214, Avg Loss: 0.4214\n",
      "Diff stats — min: -5.4258, max: 8.9655, mean: 1.4004, std: 1.6254\n",
      "\n",
      "Step 4948 — Test metrics:\n",
      "  precision@10: 0.005675211\n",
      "  recall@10: 0.005677414\n",
      "  ndcg@10: 0.005978734\n",
      "  map@10: 0.001881087\n",
      "Epoch 451, Step 10, LR: 0.000080, Current Loss: 0.4201, Avg Loss: 0.4229\n",
      "Diff stats — min: -5.1043, max: 9.3548, mean: 1.4155, std: 1.6380\n",
      "\n",
      "Step 4957 — Test metrics:\n",
      "  precision@10: 0.005609144\n",
      "  recall@10: 0.005611346\n",
      "  ndcg@10: 0.005835802\n",
      "  map@10: 0.001813352\n",
      "Epoch 451 completed, Train Loss: 0.4231\n",
      "Epoch 452, Step 1, LR: 0.000080, Current Loss: 0.4233, Avg Loss: 0.4233\n",
      "Diff stats — min: -5.4947, max: 9.8115, mean: 1.3934, std: 1.6261\n",
      "\n",
      "Step 4959 — Test metrics:\n",
      "  precision@10: 0.005615751\n",
      "  recall@10: 0.005617953\n",
      "  ndcg@10: 0.005837911\n",
      "  map@10: 0.001813095\n",
      "Epoch 452, Step 10, LR: 0.000080, Current Loss: 0.4212, Avg Loss: 0.4237\n",
      "Diff stats — min: -6.0429, max: 8.1185, mean: 1.4079, std: 1.6364\n",
      "\n",
      "Step 4968 — Test metrics:\n",
      "  precision@10: 0.005701638\n",
      "  recall@10: 0.005703841\n",
      "  ndcg@10: 0.005895238\n",
      "  map@10: 0.001824052\n",
      "Epoch 452 completed, Train Loss: 0.4230\n",
      "Epoch 453, Step 1, LR: 0.000080, Current Loss: 0.4186, Avg Loss: 0.4186\n",
      "Diff stats — min: -5.8074, max: 10.5743, mean: 1.4227, std: 1.6408\n",
      "\n",
      "Step 4970 — Test metrics:\n",
      "  precision@10: 0.005714852\n",
      "  recall@10: 0.005717054\n",
      "  ndcg@10: 0.005890946\n",
      "  map@10: 0.001818559\n",
      "Epoch 453, Step 10, LR: 0.000080, Current Loss: 0.4219, Avg Loss: 0.4215\n",
      "Diff stats — min: -5.5991, max: 10.1378, mean: 1.4157, std: 1.6463\n",
      "\n",
      "Step 4979 — Test metrics:\n",
      "  precision@10: 0.005668605\n",
      "  recall@10: 0.005670807\n",
      "  ndcg@10: 0.005946448\n",
      "  map@10: 0.001862407\n",
      "Epoch 453 completed, Train Loss: 0.4213\n",
      "Epoch 454, Step 1, LR: 0.000080, Current Loss: 0.4212, Avg Loss: 0.4212\n",
      "Diff stats — min: -6.6262, max: 8.7121, mean: 1.4105, std: 1.6395\n",
      "\n",
      "Step 4981 — Test metrics:\n",
      "  precision@10: 0.005688425\n",
      "  recall@10: 0.005690627\n",
      "  ndcg@10: 0.005961013\n",
      "  map@10: 0.001865959\n",
      "Epoch 454, Step 10, LR: 0.000080, Current Loss: 0.4238, Avg Loss: 0.4219\n",
      "Diff stats — min: -5.5787, max: 8.2512, mean: 1.4148, std: 1.6501\n",
      "\n",
      "Step 4990 — Test metrics:\n",
      "  precision@10: 0.005661998\n",
      "  recall@10: 0.005664200\n",
      "  ndcg@10: 0.005916661\n",
      "  map@10: 0.001848197\n",
      "Epoch 454 completed, Train Loss: 0.4216\n",
      "Epoch 455, Step 1, LR: 0.000080, Current Loss: 0.4146, Avg Loss: 0.4146\n",
      "Diff stats — min: -5.2285, max: 8.5801, mean: 1.4363, std: 1.6384\n",
      "\n",
      "Step 4992 — Test metrics:\n",
      "  precision@10: 0.005675211\n",
      "  recall@10: 0.005677414\n",
      "  ndcg@10: 0.005921830\n",
      "  map@10: 0.001849781\n",
      "Epoch 455, Step 10, LR: 0.000080, Current Loss: 0.4179, Avg Loss: 0.4190\n",
      "Diff stats — min: -5.6648, max: 8.6894, mean: 1.4314, std: 1.6454\n",
      "\n",
      "Step 5001 — Test metrics:\n",
      "  precision@10: 0.005622357\n",
      "  recall@10: 0.005624560\n",
      "  ndcg@10: 0.005868521\n",
      "  map@10: 0.001831308\n",
      "Epoch 455 completed, Train Loss: 0.4196\n",
      "Epoch 456, Step 1, LR: 0.000080, Current Loss: 0.4193, Avg Loss: 0.4193\n",
      "Diff stats — min: -5.1044, max: 8.7318, mean: 1.4265, std: 1.6500\n",
      "\n",
      "Step 5003 — Test metrics:\n",
      "  precision@10: 0.005655391\n",
      "  recall@10: 0.005657593\n",
      "  ndcg@10: 0.005897223\n",
      "  map@10: 0.001838866\n",
      "Epoch 456, Step 10, LR: 0.000080, Current Loss: 0.4206, Avg Loss: 0.4196\n",
      "Diff stats — min: -6.4363, max: 8.4665, mean: 1.4233, std: 1.6469\n",
      "\n",
      "Step 5012 — Test metrics:\n",
      "  precision@10: 0.005728066\n",
      "  recall@10: 0.005731002\n",
      "  ndcg@10: 0.005977183\n",
      "  map@10: 0.001864560\n",
      "Epoch 456 completed, Train Loss: 0.4197\n",
      "Epoch 457, Step 1, LR: 0.000080, Current Loss: 0.4172, Avg Loss: 0.4172\n",
      "Diff stats — min: -5.2166, max: 10.2397, mean: 1.4264, std: 1.6368\n",
      "\n",
      "Step 5014 — Test metrics:\n",
      "  precision@10: 0.005728066\n",
      "  recall@10: 0.005731002\n",
      "  ndcg@10: 0.005978351\n",
      "  map@10: 0.001864746\n",
      "Epoch 457, Step 10, LR: 0.000080, Current Loss: 0.4198, Avg Loss: 0.4195\n",
      "Diff stats — min: -5.7822, max: 10.9424, mean: 1.4297, std: 1.6550\n",
      "\n",
      "Step 5023 — Test metrics:\n",
      "  precision@10: 0.005734672\n",
      "  recall@10: 0.005736875\n",
      "  ndcg@10: 0.005972625\n",
      "  map@10: 0.001859863\n",
      "Epoch 457 completed, Train Loss: 0.4196\n",
      "Epoch 458, Step 1, LR: 0.000080, Current Loss: 0.4213, Avg Loss: 0.4213\n",
      "Diff stats — min: -5.4571, max: 10.1675, mean: 1.4244, std: 1.6557\n",
      "\n",
      "Step 5025 — Test metrics:\n",
      "  precision@10: 0.005728066\n",
      "  recall@10: 0.005730268\n",
      "  ndcg@10: 0.005965951\n",
      "  map@10: 0.001857847\n",
      "Epoch 458, Step 10, LR: 0.000080, Current Loss: 0.4165, Avg Loss: 0.4194\n",
      "Diff stats — min: -6.7980, max: 9.9896, mean: 1.4419, std: 1.6579\n",
      "\n",
      "Step 5034 — Test metrics:\n",
      "  precision@10: 0.005648784\n",
      "  recall@10: 0.005650987\n",
      "  ndcg@10: 0.005901885\n",
      "  map@10: 0.001843373\n",
      "Epoch 458 completed, Train Loss: 0.4192\n",
      "Epoch 459, Step 1, LR: 0.000080, Current Loss: 0.4206, Avg Loss: 0.4206\n",
      "Diff stats — min: -7.4352, max: 8.7285, mean: 1.4267, std: 1.6536\n",
      "\n",
      "Step 5036 — Test metrics:\n",
      "  precision@10: 0.005655391\n",
      "  recall@10: 0.005657593\n",
      "  ndcg@10: 0.005915562\n",
      "  map@10: 0.001848278\n",
      "Epoch 459, Step 10, LR: 0.000080, Current Loss: 0.4158, Avg Loss: 0.4184\n",
      "Diff stats — min: -5.8291, max: 11.1786, mean: 1.4395, std: 1.6464\n",
      "\n",
      "Step 5045 — Test metrics:\n",
      "  precision@10: 0.005754493\n",
      "  recall@10: 0.005757429\n",
      "  ndcg@10: 0.006015242\n",
      "  map@10: 0.001880940\n",
      "Epoch 459 completed, Train Loss: 0.4187\n",
      "Epoch 460, Step 1, LR: 0.000080, Current Loss: 0.4233, Avg Loss: 0.4233\n",
      "Diff stats — min: -5.5758, max: 8.7456, mean: 1.4237, std: 1.6610\n",
      "\n",
      "Step 5047 — Test metrics:\n",
      "  precision@10: 0.005741279\n",
      "  recall@10: 0.005743481\n",
      "  ndcg@10: 0.006033786\n",
      "  map@10: 0.001896025\n",
      "Epoch 460, Step 10, LR: 0.000080, Current Loss: 0.4183, Avg Loss: 0.4177\n",
      "Diff stats — min: -5.8186, max: 13.7449, mean: 1.4416, std: 1.6639\n",
      "\n",
      "Step 5056 — Test metrics:\n",
      "  precision@10: 0.005681818\n",
      "  recall@10: 0.005684755\n",
      "  ndcg@10: 0.005956055\n",
      "  map@10: 0.001866279\n",
      "Epoch 460 completed, Train Loss: 0.4176\n",
      "Epoch 461, Step 1, LR: 0.000080, Current Loss: 0.4128, Avg Loss: 0.4128\n",
      "Diff stats — min: -4.5037, max: 8.3979, mean: 1.4516, std: 1.6516\n",
      "\n",
      "Step 5058 — Test metrics:\n",
      "  precision@10: 0.005668605\n",
      "  recall@10: 0.005671541\n",
      "  ndcg@10: 0.005937675\n",
      "  map@10: 0.001859106\n",
      "Epoch 461, Step 10, LR: 0.000080, Current Loss: 0.4137, Avg Loss: 0.4161\n",
      "Diff stats — min: -6.1155, max: 9.0542, mean: 1.4441, std: 1.6456\n",
      "\n",
      "Step 5067 — Test metrics:\n",
      "  precision@10: 0.005728066\n",
      "  recall@10: 0.005731002\n",
      "  ndcg@10: 0.005979993\n",
      "  map@10: 0.001867845\n",
      "Epoch 461 completed, Train Loss: 0.4161\n",
      "Epoch 462, Step 1, LR: 0.000080, Current Loss: 0.4163, Avg Loss: 0.4163\n",
      "Diff stats — min: -6.5117, max: 12.5042, mean: 1.4498, std: 1.6621\n",
      "\n",
      "Step 5069 — Test metrics:\n",
      "  precision@10: 0.005734672\n",
      "  recall@10: 0.005737609\n",
      "  ndcg@10: 0.005988317\n",
      "  map@10: 0.001871627\n",
      "Epoch 462, Step 10, LR: 0.000080, Current Loss: 0.4182, Avg Loss: 0.4174\n",
      "Diff stats — min: -5.6917, max: 8.6729, mean: 1.4338, std: 1.6546\n",
      "\n",
      "Step 5078 — Test metrics:\n",
      "  precision@10: 0.005714852\n",
      "  recall@10: 0.005717788\n",
      "  ndcg@10: 0.005989158\n",
      "  map@10: 0.001877957\n",
      "Epoch 462 completed, Train Loss: 0.4170\n",
      "Epoch 463, Step 1, LR: 0.000080, Current Loss: 0.4204, Avg Loss: 0.4204\n",
      "Diff stats — min: -6.4653, max: 9.5762, mean: 1.4373, std: 1.6640\n",
      "\n",
      "Step 5080 — Test metrics:\n",
      "  precision@10: 0.005714852\n",
      "  recall@10: 0.005717788\n",
      "  ndcg@10: 0.005983406\n",
      "  map@10: 0.001874753\n",
      "Epoch 463, Step 10, LR: 0.000080, Current Loss: 0.4126, Avg Loss: 0.4167\n",
      "Diff stats — min: -6.1315, max: 13.1162, mean: 1.4536, std: 1.6511\n",
      "\n",
      "Step 5089 — Test metrics:\n",
      "  precision@10: 0.005728066\n",
      "  recall@10: 0.005731002\n",
      "  ndcg@10: 0.005962278\n",
      "  map@10: 0.001857809\n",
      "Epoch 463 completed, Train Loss: 0.4164\n",
      "Epoch 464, Step 1, LR: 0.000080, Current Loss: 0.4187, Avg Loss: 0.4187\n",
      "Diff stats — min: -12.7671, max: 8.8405, mean: 1.4419, std: 1.6649\n",
      "\n",
      "Step 5091 — Test metrics:\n",
      "  precision@10: 0.005754493\n",
      "  recall@10: 0.005757429\n",
      "  ndcg@10: 0.005964121\n",
      "  map@10: 0.001853365\n",
      "Epoch 464, Step 10, LR: 0.000080, Current Loss: 0.4136, Avg Loss: 0.4162\n",
      "Diff stats — min: -5.6170, max: 9.1242, mean: 1.4618, std: 1.6623\n",
      "\n",
      "Step 5100 — Test metrics:\n",
      "  precision@10: 0.005820560\n",
      "  recall@10: 0.005822763\n",
      "  ndcg@10: 0.005984723\n",
      "  map@10: 0.001844213\n",
      "Epoch 464 completed, Train Loss: 0.4162\n",
      "Epoch 465, Step 1, LR: 0.000080, Current Loss: 0.4103, Avg Loss: 0.4103\n",
      "Diff stats — min: -5.4916, max: 7.7590, mean: 1.4676, std: 1.6548\n",
      "\n",
      "Step 5102 — Test metrics:\n",
      "  precision@10: 0.005807347\n",
      "  recall@10: 0.005809549\n",
      "  ndcg@10: 0.005980364\n",
      "  map@10: 0.001845430\n",
      "Epoch 465, Step 10, LR: 0.000080, Current Loss: 0.4199, Avg Loss: 0.4157\n",
      "Diff stats — min: -6.3615, max: 8.7695, mean: 1.4465, std: 1.6760\n",
      "\n",
      "Step 5111 — Test metrics:\n",
      "  precision@10: 0.005846987\n",
      "  recall@10: 0.005849924\n",
      "  ndcg@10: 0.006066919\n",
      "  map@10: 0.001886849\n",
      "Epoch 465 completed, Train Loss: 0.4158\n",
      "Epoch 466, Step 1, LR: 0.000080, Current Loss: 0.4151, Avg Loss: 0.4151\n",
      "Diff stats — min: -5.4113, max: 8.6560, mean: 1.4680, std: 1.6765\n",
      "\n",
      "Step 5113 — Test metrics:\n",
      "  precision@10: 0.005833774\n",
      "  recall@10: 0.005836710\n",
      "  ndcg@10: 0.006064009\n",
      "  map@10: 0.001889159\n",
      "Epoch 466, Step 10, LR: 0.000080, Current Loss: 0.4179, Avg Loss: 0.4144\n",
      "Diff stats — min: -5.8485, max: 8.5495, mean: 1.4430, std: 1.6652\n",
      "\n",
      "Step 5122 — Test metrics:\n",
      "  precision@10: 0.005846987\n",
      "  recall@10: 0.005849924\n",
      "  ndcg@10: 0.006088318\n",
      "  map@10: 0.001898686\n",
      "Epoch 466 completed, Train Loss: 0.4143\n",
      "Epoch 467, Step 1, LR: 0.000080, Current Loss: 0.4164, Avg Loss: 0.4164\n",
      "Diff stats — min: -6.3641, max: 8.9621, mean: 1.4600, std: 1.6694\n",
      "\n",
      "Step 5124 — Test metrics:\n",
      "  precision@10: 0.005853594\n",
      "  recall@10: 0.005856530\n",
      "  ndcg@10: 0.006086885\n",
      "  map@10: 0.001895687\n",
      "Epoch 467, Step 10, LR: 0.000080, Current Loss: 0.4147, Avg Loss: 0.4154\n",
      "Diff stats — min: -5.6012, max: 13.7465, mean: 1.4644, std: 1.6746\n",
      "\n",
      "Step 5133 — Test metrics:\n",
      "  precision@10: 0.005833774\n",
      "  recall@10: 0.005836710\n",
      "  ndcg@10: 0.006070609\n",
      "  map@10: 0.001891545\n",
      "Epoch 467 completed, Train Loss: 0.4154\n",
      "Epoch 468, Step 1, LR: 0.000080, Current Loss: 0.4097, Avg Loss: 0.4097\n",
      "Diff stats — min: -5.2159, max: 8.9907, mean: 1.4723, std: 1.6595\n",
      "\n",
      "Step 5135 — Test metrics:\n",
      "  precision@10: 0.005807347\n",
      "  recall@10: 0.005810283\n",
      "  ndcg@10: 0.006047060\n",
      "  map@10: 0.001884896\n",
      "Epoch 468, Step 10, LR: 0.000080, Current Loss: 0.4176, Avg Loss: 0.4144\n",
      "Diff stats — min: -5.7641, max: 8.8334, mean: 1.4639, std: 1.6858\n",
      "\n",
      "Step 5144 — Test metrics:\n",
      "  precision@10: 0.005747886\n",
      "  recall@10: 0.005750822\n",
      "  ndcg@10: 0.005987346\n",
      "  map@10: 0.001865808\n",
      "Epoch 468 completed, Train Loss: 0.4147\n",
      "Epoch 469, Step 1, LR: 0.000080, Current Loss: 0.4104, Avg Loss: 0.4104\n",
      "Diff stats — min: -5.1840, max: 10.0658, mean: 1.4866, std: 1.6785\n",
      "\n",
      "Step 5146 — Test metrics:\n",
      "  precision@10: 0.005754493\n",
      "  recall@10: 0.005757429\n",
      "  ndcg@10: 0.005992598\n",
      "  map@10: 0.001868993\n",
      "Epoch 469, Step 10, LR: 0.000080, Current Loss: 0.4121, Avg Loss: 0.4134\n",
      "Diff stats — min: -5.6348, max: 8.6365, mean: 1.4700, std: 1.6712\n",
      "\n",
      "Step 5155 — Test metrics:\n",
      "  precision@10: 0.005695032\n",
      "  recall@10: 0.005697968\n",
      "  ndcg@10: 0.005941259\n",
      "  map@10: 0.001856169\n",
      "Epoch 469 completed, Train Loss: 0.4133\n",
      "Epoch 470, Step 1, LR: 0.000080, Current Loss: 0.4100, Avg Loss: 0.4100\n",
      "Diff stats — min: -5.7634, max: 8.6464, mean: 1.4773, std: 1.6689\n",
      "\n",
      "Step 5157 — Test metrics:\n",
      "  precision@10: 0.005721459\n",
      "  recall@10: 0.005724395\n",
      "  ndcg@10: 0.005986624\n",
      "  map@10: 0.001873890\n",
      "Epoch 470, Step 10, LR: 0.000080, Current Loss: 0.4145, Avg Loss: 0.4123\n",
      "Diff stats — min: -5.5882, max: 8.2336, mean: 1.4740, std: 1.6808\n",
      "\n",
      "Step 5166 — Test metrics:\n",
      "  precision@10: 0.005886628\n",
      "  recall@10: 0.005889564\n",
      "  ndcg@10: 0.006098008\n",
      "  map@10: 0.001893172\n",
      "Epoch 470 completed, Train Loss: 0.4124\n",
      "Epoch 471, Step 1, LR: 0.000080, Current Loss: 0.4118, Avg Loss: 0.4118\n",
      "Diff stats — min: -5.6904, max: 9.6115, mean: 1.4787, std: 1.6745\n",
      "\n",
      "Step 5168 — Test metrics:\n",
      "  precision@10: 0.005866808\n",
      "  recall@10: 0.005869744\n",
      "  ndcg@10: 0.006083619\n",
      "  map@10: 0.001889209\n",
      "Epoch 471, Step 10, LR: 0.000080, Current Loss: 0.4160, Avg Loss: 0.4125\n",
      "Diff stats — min: -6.0378, max: 8.0697, mean: 1.4663, std: 1.6787\n",
      "\n",
      "Step 5177 — Test metrics:\n",
      "  precision@10: 0.005880021\n",
      "  recall@10: 0.005882957\n",
      "  ndcg@10: 0.006110344\n",
      "  map@10: 0.001900828\n",
      "Epoch 471 completed, Train Loss: 0.4127\n",
      "Epoch 472, Step 1, LR: 0.000080, Current Loss: 0.4115, Avg Loss: 0.4115\n",
      "Diff stats — min: -5.6344, max: 8.2726, mean: 1.4829, std: 1.6802\n",
      "\n",
      "Step 5179 — Test metrics:\n",
      "  precision@10: 0.005846987\n",
      "  recall@10: 0.005849924\n",
      "  ndcg@10: 0.006099243\n",
      "  map@10: 0.001903437\n",
      "Epoch 472, Step 10, LR: 0.000080, Current Loss: 0.4119, Avg Loss: 0.4132\n",
      "Diff stats — min: -5.7873, max: 9.4359, mean: 1.4831, std: 1.6816\n",
      "\n",
      "Step 5188 — Test metrics:\n",
      "  precision@10: 0.005728066\n",
      "  recall@10: 0.005731002\n",
      "  ndcg@10: 0.006043955\n",
      "  map@10: 0.001904760\n",
      "Epoch 472 completed, Train Loss: 0.4131\n",
      "Epoch 473, Step 1, LR: 0.000080, Current Loss: 0.4105, Avg Loss: 0.4105\n",
      "Diff stats — min: -5.8381, max: 9.8635, mean: 1.4893, std: 1.6843\n",
      "\n",
      "Step 5190 — Test metrics:\n",
      "  precision@10: 0.005734672\n",
      "  recall@10: 0.005737609\n",
      "  ndcg@10: 0.006058827\n",
      "  map@10: 0.001912765\n",
      "Epoch 473, Step 10, LR: 0.000080, Current Loss: 0.4100, Avg Loss: 0.4116\n",
      "Diff stats — min: -6.1221, max: 8.5775, mean: 1.4958, std: 1.6883\n",
      "\n",
      "Step 5199 — Test metrics:\n",
      "  precision@10: 0.005846987\n",
      "  recall@10: 0.005849924\n",
      "  ndcg@10: 0.006130119\n",
      "  map@10: 0.001923342\n",
      "Epoch 473 completed, Train Loss: 0.4115\n",
      "Epoch 474, Step 1, LR: 0.000080, Current Loss: 0.4064, Avg Loss: 0.4064\n",
      "Diff stats — min: -5.1938, max: 8.2466, mean: 1.5020, std: 1.6800\n",
      "\n",
      "Step 5201 — Test metrics:\n",
      "  precision@10: 0.005827167\n",
      "  recall@10: 0.005830103\n",
      "  ndcg@10: 0.006115005\n",
      "  map@10: 0.001919569\n",
      "Epoch 474, Step 10, LR: 0.000080, Current Loss: 0.4087, Avg Loss: 0.4099\n",
      "Diff stats — min: -5.5908, max: 9.1312, mean: 1.5028, std: 1.6873\n",
      "\n",
      "Step 5210 — Test metrics:\n",
      "  precision@10: 0.005833774\n",
      "  recall@10: 0.005836710\n",
      "  ndcg@10: 0.006080462\n",
      "  map@10: 0.001899344\n",
      "Epoch 474 completed, Train Loss: 0.4098\n",
      "Epoch 475, Step 1, LR: 0.000080, Current Loss: 0.4120, Avg Loss: 0.4120\n",
      "Diff stats — min: -7.4389, max: 9.6237, mean: 1.4952, std: 1.6937\n",
      "\n",
      "Step 5212 — Test metrics:\n",
      "  precision@10: 0.005827167\n",
      "  recall@10: 0.005830103\n",
      "  ndcg@10: 0.006073973\n",
      "  map@10: 0.001896468\n",
      "Epoch 475, Step 10, LR: 0.000080, Current Loss: 0.4052, Avg Loss: 0.4109\n",
      "Diff stats — min: -9.9914, max: 8.5534, mean: 1.5150, std: 1.6887\n",
      "\n",
      "Step 5221 — Test metrics:\n",
      "  precision@10: 0.005787526\n",
      "  recall@10: 0.005790463\n",
      "  ndcg@10: 0.006123109\n",
      "  map@10: 0.001934079\n",
      "Epoch 475 completed, Train Loss: 0.4109\n",
      "Epoch 476, Step 1, LR: 0.000080, Current Loss: 0.4071, Avg Loss: 0.4071\n",
      "Diff stats — min: -6.7909, max: 8.3076, mean: 1.5043, std: 1.6860\n",
      "\n",
      "Step 5223 — Test metrics:\n",
      "  precision@10: 0.005761099\n",
      "  recall@10: 0.005764036\n",
      "  ndcg@10: 0.006101804\n",
      "  map@10: 0.001928713\n",
      "Epoch 476, Step 10, LR: 0.000080, Current Loss: 0.4144, Avg Loss: 0.4099\n",
      "Diff stats — min: -5.3793, max: 8.4777, mean: 1.4911, std: 1.7014\n",
      "\n",
      "Step 5232 — Test metrics:\n",
      "  precision@10: 0.005886628\n",
      "  recall@10: 0.005889564\n",
      "  ndcg@10: 0.006105205\n",
      "  map@10: 0.001897281\n",
      "Epoch 476 completed, Train Loss: 0.4101\n",
      "Epoch 477, Step 1, LR: 0.000080, Current Loss: 0.4123, Avg Loss: 0.4123\n",
      "Diff stats — min: -5.3464, max: 9.9654, mean: 1.4873, std: 1.6883\n",
      "\n",
      "Step 5234 — Test metrics:\n",
      "  precision@10: 0.005873414\n",
      "  recall@10: 0.005876351\n",
      "  ndcg@10: 0.006094384\n",
      "  map@10: 0.001894389\n",
      "Epoch 477, Step 10, LR: 0.000080, Current Loss: 0.4086, Avg Loss: 0.4099\n",
      "Diff stats — min: -6.6685, max: 10.9043, mean: 1.5118, std: 1.6982\n",
      "\n",
      "Step 5243 — Test metrics:\n",
      "  precision@10: 0.005794133\n",
      "  recall@10: 0.005796335\n",
      "  ndcg@10: 0.006032127\n",
      "  map@10: 0.001880869\n",
      "Epoch 477 completed, Train Loss: 0.4093\n",
      "Epoch 478, Step 1, LR: 0.000080, Current Loss: 0.4061, Avg Loss: 0.4061\n",
      "Diff stats — min: -5.5886, max: 12.3909, mean: 1.5110, std: 1.6884\n",
      "\n",
      "Step 5245 — Test metrics:\n",
      "  precision@10: 0.005747886\n",
      "  recall@10: 0.005750088\n",
      "  ndcg@10: 0.005993300\n",
      "  map@10: 0.001869480\n",
      "Epoch 478, Step 10, LR: 0.000080, Current Loss: 0.4082, Avg Loss: 0.4081\n",
      "Diff stats — min: -5.5804, max: 8.8642, mean: 1.5023, std: 1.6874\n",
      "\n",
      "Step 5254 — Test metrics:\n",
      "  precision@10: 0.005807347\n",
      "  recall@10: 0.005809549\n",
      "  ndcg@10: 0.006072462\n",
      "  map@10: 0.001901580\n",
      "Epoch 478 completed, Train Loss: 0.4083\n",
      "Epoch 479, Step 1, LR: 0.000080, Current Loss: 0.4086, Avg Loss: 0.4086\n",
      "Diff stats — min: -5.7899, max: 9.0699, mean: 1.5097, std: 1.6950\n",
      "\n",
      "Step 5256 — Test metrics:\n",
      "  precision@10: 0.005807347\n",
      "  recall@10: 0.005809549\n",
      "  ndcg@10: 0.006100438\n",
      "  map@10: 0.001918666\n",
      "Epoch 479, Step 10, LR: 0.000080, Current Loss: 0.4109, Avg Loss: 0.4074\n",
      "Diff stats — min: -5.4326, max: 9.1810, mean: 1.4946, std: 1.6932\n",
      "\n",
      "Step 5265 — Test metrics:\n",
      "  precision@10: 0.005794133\n",
      "  recall@10: 0.005797070\n",
      "  ndcg@10: 0.006112161\n",
      "  map@10: 0.001928214\n",
      "Epoch 479 completed, Train Loss: 0.4081\n",
      "Epoch 480, Step 1, LR: 0.000080, Current Loss: 0.4017, Avg Loss: 0.4017\n",
      "Diff stats — min: -6.1077, max: 9.8605, mean: 1.5297, std: 1.6909\n",
      "\n",
      "Step 5267 — Test metrics:\n",
      "  precision@10: 0.005833774\n",
      "  recall@10: 0.005836710\n",
      "  ndcg@10: 0.006150909\n",
      "  map@10: 0.001939011\n",
      "Epoch 480, Step 10, LR: 0.000080, Current Loss: 0.4100, Avg Loss: 0.4077\n",
      "Diff stats — min: -6.2986, max: 9.0160, mean: 1.5070, std: 1.7025\n",
      "\n",
      "Step 5276 — Test metrics:\n",
      "  precision@10: 0.005946089\n",
      "  recall@10: 0.005949025\n",
      "  ndcg@10: 0.006229573\n",
      "  map@10: 0.001953182\n",
      "Epoch 480 completed, Train Loss: 0.4077\n",
      "Epoch 481, Step 1, LR: 0.000080, Current Loss: 0.4099, Avg Loss: 0.4099\n",
      "Diff stats — min: -6.8095, max: 11.2513, mean: 1.5149, std: 1.7113\n",
      "\n",
      "Step 5278 — Test metrics:\n",
      "  precision@10: 0.005985729\n",
      "  recall@10: 0.005988666\n",
      "  ndcg@10: 0.006249543\n",
      "  map@10: 0.001954939\n",
      "Epoch 481, Step 10, LR: 0.000080, Current Loss: 0.4095, Avg Loss: 0.4080\n",
      "Diff stats — min: -5.4644, max: 8.8135, mean: 1.5051, std: 1.6960\n",
      "\n",
      "Step 5287 — Test metrics:\n",
      "  precision@10: 0.005899841\n",
      "  recall@10: 0.005902778\n",
      "  ndcg@10: 0.006137490\n",
      "  map@10: 0.001912128\n",
      "Epoch 481 completed, Train Loss: 0.4082\n",
      "Epoch 482, Step 1, LR: 0.000080, Current Loss: 0.4086, Avg Loss: 0.4086\n",
      "Diff stats — min: -6.0464, max: 8.4365, mean: 1.5192, std: 1.7072\n",
      "\n",
      "Step 5289 — Test metrics:\n",
      "  precision@10: 0.005913055\n",
      "  recall@10: 0.005915991\n",
      "  ndcg@10: 0.006153434\n",
      "  map@10: 0.001918192\n",
      "Epoch 482, Step 10, LR: 0.000080, Current Loss: 0.4050, Avg Loss: 0.4072\n",
      "Diff stats — min: -5.9408, max: 9.7519, mean: 1.5262, std: 1.6989\n",
      "\n",
      "Step 5298 — Test metrics:\n",
      "  precision@10: 0.005899841\n",
      "  recall@10: 0.005902778\n",
      "  ndcg@10: 0.006146315\n",
      "  map@10: 0.001917961\n",
      "Epoch 482 completed, Train Loss: 0.4072\n",
      "Epoch 483, Step 1, LR: 0.000080, Current Loss: 0.4090, Avg Loss: 0.4090\n",
      "Diff stats — min: -5.6963, max: 9.6159, mean: 1.5134, std: 1.7053\n",
      "\n",
      "Step 5300 — Test metrics:\n",
      "  precision@10: 0.005899841\n",
      "  recall@10: 0.005902778\n",
      "  ndcg@10: 0.006153767\n",
      "  map@10: 0.001923244\n",
      "Epoch 483, Step 10, LR: 0.000080, Current Loss: 0.4066, Avg Loss: 0.4077\n",
      "Diff stats — min: -5.3165, max: 9.3453, mean: 1.5215, std: 1.7029\n",
      "\n",
      "Step 5309 — Test metrics:\n",
      "  precision@10: 0.005952696\n",
      "  recall@10: 0.005955632\n",
      "  ndcg@10: 0.006180785\n",
      "  map@10: 0.001927756\n",
      "Epoch 483 completed, Train Loss: 0.4074\n",
      "Epoch 484, Step 1, LR: 0.000080, Current Loss: 0.4100, Avg Loss: 0.4100\n",
      "Diff stats — min: -6.0513, max: 9.1638, mean: 1.5101, std: 1.7024\n",
      "\n",
      "Step 5311 — Test metrics:\n",
      "  precision@10: 0.005946089\n",
      "  recall@10: 0.005948291\n",
      "  ndcg@10: 0.006180901\n",
      "  map@10: 0.001929122\n",
      "Epoch 484, Step 10, LR: 0.000080, Current Loss: 0.4082, Avg Loss: 0.4068\n",
      "Diff stats — min: -6.2506, max: 9.0475, mean: 1.5085, std: 1.6942\n",
      "\n",
      "Step 5320 — Test metrics:\n",
      "  precision@10: 0.005840381\n",
      "  recall@10: 0.005842583\n",
      "  ndcg@10: 0.006095300\n",
      "  map@10: 0.001906737\n",
      "Epoch 484 completed, Train Loss: 0.4064\n",
      "Epoch 485, Step 1, LR: 0.000080, Current Loss: 0.4076, Avg Loss: 0.4076\n",
      "Diff stats — min: -5.2243, max: 9.8408, mean: 1.5170, std: 1.7026\n",
      "\n",
      "Step 5322 — Test metrics:\n",
      "  precision@10: 0.005866808\n",
      "  recall@10: 0.005869010\n",
      "  ndcg@10: 0.006134961\n",
      "  map@10: 0.001923944\n",
      "Epoch 485, Step 10, LR: 0.000080, Current Loss: 0.4036, Avg Loss: 0.4059\n",
      "Diff stats — min: -6.1170, max: 8.4939, mean: 1.5342, std: 1.7050\n",
      "\n",
      "Step 5331 — Test metrics:\n",
      "  precision@10: 0.005932875\n",
      "  recall@10: 0.005935812\n",
      "  ndcg@10: 0.006238206\n",
      "  map@10: 0.001963221\n",
      "Epoch 485 completed, Train Loss: 0.4062\n",
      "Epoch 486, Step 1, LR: 0.000080, Current Loss: 0.4065, Avg Loss: 0.4065\n",
      "Diff stats — min: -6.2853, max: 8.4566, mean: 1.5270, std: 1.7077\n",
      "\n",
      "Step 5333 — Test metrics:\n",
      "  precision@10: 0.005913055\n",
      "  recall@10: 0.005915991\n",
      "  ndcg@10: 0.006237394\n",
      "  map@10: 0.001968212\n",
      "Epoch 486, Step 10, LR: 0.000080, Current Loss: 0.4040, Avg Loss: 0.4057\n",
      "Diff stats — min: -5.7188, max: 8.4912, mean: 1.5399, std: 1.7092\n",
      "\n",
      "Step 5342 — Test metrics:\n",
      "  precision@10: 0.005827167\n",
      "  recall@10: 0.005829369\n",
      "  ndcg@10: 0.006161461\n",
      "  map@10: 0.001946724\n",
      "Epoch 486 completed, Train Loss: 0.4057\n",
      "Epoch 487, Step 1, LR: 0.000080, Current Loss: 0.4066, Avg Loss: 0.4066\n",
      "Diff stats — min: -6.3108, max: 8.6632, mean: 1.5264, std: 1.7062\n",
      "\n",
      "Step 5344 — Test metrics:\n",
      "  precision@10: 0.005807347\n",
      "  recall@10: 0.005809549\n",
      "  ndcg@10: 0.006147552\n",
      "  map@10: 0.001946039\n",
      "Epoch 487, Step 10, LR: 0.000080, Current Loss: 0.3989, Avg Loss: 0.4052\n",
      "Diff stats — min: -5.6924, max: 8.6448, mean: 1.5517, std: 1.7036\n",
      "\n",
      "Step 5353 — Test metrics:\n",
      "  precision@10: 0.005866808\n",
      "  recall@10: 0.005869010\n",
      "  ndcg@10: 0.006154553\n",
      "  map@10: 0.001935049\n",
      "Epoch 487 completed, Train Loss: 0.4050\n",
      "Epoch 488, Step 1, LR: 0.000080, Current Loss: 0.4075, Avg Loss: 0.4075\n",
      "Diff stats — min: -5.2037, max: 9.1246, mean: 1.5248, std: 1.7089\n",
      "\n",
      "Step 5355 — Test metrics:\n",
      "  precision@10: 0.005886628\n",
      "  recall@10: 0.005888830\n",
      "  ndcg@10: 0.006163572\n",
      "  map@10: 0.001934624\n",
      "Epoch 488, Step 10, LR: 0.000080, Current Loss: 0.4023, Avg Loss: 0.4042\n",
      "Diff stats — min: -6.0947, max: 9.1510, mean: 1.5459, std: 1.7126\n",
      "\n",
      "Step 5364 — Test metrics:\n",
      "  precision@10: 0.005979123\n",
      "  recall@10: 0.005982059\n",
      "  ndcg@10: 0.006263714\n",
      "  map@10: 0.001968133\n",
      "Epoch 488 completed, Train Loss: 0.4043\n",
      "Epoch 489, Step 1, LR: 0.000080, Current Loss: 0.4072, Avg Loss: 0.4072\n",
      "Diff stats — min: -5.8723, max: 9.2656, mean: 1.5314, std: 1.7141\n",
      "\n",
      "Step 5366 — Test metrics:\n",
      "  precision@10: 0.005952696\n",
      "  recall@10: 0.005955632\n",
      "  ndcg@10: 0.006255378\n",
      "  map@10: 0.001970560\n",
      "Epoch 489, Step 10, LR: 0.000080, Current Loss: 0.4051, Avg Loss: 0.4040\n",
      "Diff stats — min: -6.1633, max: 9.3080, mean: 1.5400, std: 1.7148\n",
      "\n",
      "Step 5375 — Test metrics:\n",
      "  precision@10: 0.005846987\n",
      "  recall@10: 0.005849190\n",
      "  ndcg@10: 0.006180195\n",
      "  map@10: 0.001952840\n",
      "Epoch 489 completed, Train Loss: 0.4042\n",
      "Epoch 490, Step 1, LR: 0.000080, Current Loss: 0.4097, Avg Loss: 0.4097\n",
      "Diff stats — min: -5.6039, max: 10.7437, mean: 1.5259, std: 1.7157\n",
      "\n",
      "Step 5377 — Test metrics:\n",
      "  precision@10: 0.005853594\n",
      "  recall@10: 0.005855796\n",
      "  ndcg@10: 0.006178793\n",
      "  map@10: 0.001950447\n",
      "Epoch 490, Step 10, LR: 0.000080, Current Loss: 0.4018, Avg Loss: 0.4052\n",
      "Diff stats — min: -5.5886, max: 9.8517, mean: 1.5444, std: 1.7080\n",
      "\n",
      "Step 5386 — Test metrics:\n",
      "  precision@10: 0.005853594\n",
      "  recall@10: 0.005855796\n",
      "  ndcg@10: 0.006153001\n",
      "  map@10: 0.001936876\n",
      "Epoch 490 completed, Train Loss: 0.4048\n",
      "Epoch 491, Step 1, LR: 0.000080, Current Loss: 0.3999, Avg Loss: 0.3999\n",
      "Diff stats — min: -5.3782, max: 9.4184, mean: 1.5577, std: 1.7158\n",
      "\n",
      "Step 5388 — Test metrics:\n",
      "  precision@10: 0.005880021\n",
      "  recall@10: 0.005882223\n",
      "  ndcg@10: 0.006165201\n",
      "  map@10: 0.001938355\n",
      "Epoch 491, Step 10, LR: 0.000080, Current Loss: 0.4053, Avg Loss: 0.4029\n",
      "Diff stats — min: -5.1645, max: 9.4452, mean: 1.5451, std: 1.7234\n",
      "\n",
      "Step 5397 — Test metrics:\n",
      "  precision@10: 0.005899841\n",
      "  recall@10: 0.005902044\n",
      "  ndcg@10: 0.006180815\n",
      "  map@10: 0.001940911\n",
      "Epoch 491 completed, Train Loss: 0.4028\n",
      "Epoch 492, Step 1, LR: 0.000080, Current Loss: 0.3963, Avg Loss: 0.3963\n",
      "Diff stats — min: -5.6499, max: 8.5881, mean: 1.5733, std: 1.7178\n",
      "\n",
      "Step 5399 — Test metrics:\n",
      "  precision@10: 0.005913055\n",
      "  recall@10: 0.005915257\n",
      "  ndcg@10: 0.006188304\n",
      "  map@10: 0.001940885\n",
      "Epoch 492, Step 10, LR: 0.000080, Current Loss: 0.4026, Avg Loss: 0.4026\n",
      "Diff stats — min: -5.5820, max: 10.3097, mean: 1.5555, std: 1.7227\n",
      "\n",
      "Step 5408 — Test metrics:\n",
      "  precision@10: 0.005866808\n",
      "  recall@10: 0.005869744\n",
      "  ndcg@10: 0.006227729\n",
      "  map@10: 0.001975312\n",
      "Epoch 492 completed, Train Loss: 0.4033\n",
      "Epoch 493, Step 1, LR: 0.000080, Current Loss: 0.4001, Avg Loss: 0.4001\n",
      "Diff stats — min: -5.6624, max: 8.5164, mean: 1.5601, std: 1.7214\n",
      "\n",
      "Step 5410 — Test metrics:\n",
      "  precision@10: 0.005886628\n",
      "  recall@10: 0.005889564\n",
      "  ndcg@10: 0.006234204\n",
      "  map@10: 0.001973474\n",
      "Epoch 493, Step 10, LR: 0.000080, Current Loss: 0.4042, Avg Loss: 0.4022\n",
      "Diff stats — min: -5.8554, max: 8.3691, mean: 1.5607, std: 1.7357\n",
      "\n",
      "Step 5419 — Test metrics:\n",
      "  precision@10: 0.005866808\n",
      "  recall@10: 0.005869744\n",
      "  ndcg@10: 0.006206670\n",
      "  map@10: 0.001962793\n",
      "Epoch 493 completed, Train Loss: 0.4021\n",
      "Epoch 494, Step 1, LR: 0.000080, Current Loss: 0.3996, Avg Loss: 0.3996\n",
      "Diff stats — min: -5.7043, max: 8.7921, mean: 1.5639, std: 1.7195\n",
      "\n",
      "Step 5421 — Test metrics:\n",
      "  precision@10: 0.005846987\n",
      "  recall@10: 0.005849190\n",
      "  ndcg@10: 0.006193360\n",
      "  map@10: 0.001961139\n",
      "Epoch 494, Step 10, LR: 0.000080, Current Loss: 0.4011, Avg Loss: 0.4017\n",
      "Diff stats — min: -5.9857, max: 10.9098, mean: 1.5686, std: 1.7289\n",
      "\n",
      "Step 5430 — Test metrics:\n",
      "  precision@10: 0.005959302\n",
      "  recall@10: 0.005961505\n",
      "  ndcg@10: 0.006248622\n",
      "  map@10: 0.001965317\n",
      "Epoch 494 completed, Train Loss: 0.4010\n",
      "Epoch 495, Step 1, LR: 0.000080, Current Loss: 0.3999, Avg Loss: 0.3999\n",
      "Diff stats — min: -5.7598, max: 9.5914, mean: 1.5724, std: 1.7290\n",
      "\n",
      "Step 5432 — Test metrics:\n",
      "  precision@10: 0.005979123\n",
      "  recall@10: 0.005981325\n",
      "  ndcg@10: 0.006253512\n",
      "  map@10: 0.001962989\n",
      "Epoch 495, Step 10, LR: 0.000080, Current Loss: 0.4060, Avg Loss: 0.4022\n",
      "Diff stats — min: -5.6850, max: 9.1467, mean: 1.5515, std: 1.7366\n",
      "\n",
      "Step 5441 — Test metrics:\n",
      "  precision@10: 0.005965909\n",
      "  recall@10: 0.005968111\n",
      "  ndcg@10: 0.006237384\n",
      "  map@10: 0.001952478\n",
      "Epoch 495 completed, Train Loss: 0.4016\n",
      "Epoch 496, Step 1, LR: 0.000080, Current Loss: 0.4010, Avg Loss: 0.4010\n",
      "Diff stats — min: -6.3232, max: 9.9464, mean: 1.5650, std: 1.7247\n",
      "\n",
      "Step 5443 — Test metrics:\n",
      "  precision@10: 0.005979123\n",
      "  recall@10: 0.005982059\n",
      "  ndcg@10: 0.006275006\n",
      "  map@10: 0.001971751\n",
      "Epoch 496, Step 10, LR: 0.000080, Current Loss: 0.4016, Avg Loss: 0.4007\n",
      "Diff stats — min: -5.7239, max: 10.4042, mean: 1.5775, std: 1.7462\n",
      "\n",
      "Step 5452 — Test metrics:\n",
      "  precision@10: 0.005932875\n",
      "  recall@10: 0.005935812\n",
      "  ndcg@10: 0.006265191\n",
      "  map@10: 0.001980553\n",
      "Epoch 496 completed, Train Loss: 0.4012\n",
      "Epoch 497, Step 1, LR: 0.000080, Current Loss: 0.4014, Avg Loss: 0.4014\n",
      "Diff stats — min: -5.9973, max: 9.7334, mean: 1.5736, std: 1.7373\n",
      "\n",
      "Step 5454 — Test metrics:\n",
      "  precision@10: 0.005899841\n",
      "  recall@10: 0.005902044\n",
      "  ndcg@10: 0.006216961\n",
      "  map@10: 0.001959651\n",
      "Epoch 497, Step 10, LR: 0.000080, Current Loss: 0.4048, Avg Loss: 0.4015\n",
      "Diff stats — min: -6.5592, max: 10.5210, mean: 1.5616, std: 1.7419\n",
      "\n",
      "Step 5463 — Test metrics:\n",
      "  precision@10: 0.005866808\n",
      "  recall@10: 0.005869744\n",
      "  ndcg@10: 0.006156044\n",
      "  map@10: 0.001932016\n",
      "Epoch 497 completed, Train Loss: 0.4011\n",
      "Epoch 498, Step 1, LR: 0.000080, Current Loss: 0.3993, Avg Loss: 0.3993\n",
      "Diff stats — min: -5.8601, max: 9.0861, mean: 1.5840, std: 1.7404\n",
      "\n",
      "Step 5465 — Test metrics:\n",
      "  precision@10: 0.005893235\n",
      "  recall@10: 0.005896171\n",
      "  ndcg@10: 0.006156764\n",
      "  map@10: 0.001925974\n",
      "Epoch 498, Step 10, LR: 0.000080, Current Loss: 0.3979, Avg Loss: 0.3995\n",
      "Diff stats — min: -5.6127, max: 8.8614, mean: 1.5889, std: 1.7425\n",
      "\n",
      "Step 5474 — Test metrics:\n",
      "  precision@10: 0.005959302\n",
      "  recall@10: 0.005962239\n",
      "  ndcg@10: 0.006250951\n",
      "  map@10: 0.001965892\n",
      "Epoch 498 completed, Train Loss: 0.3997\n",
      "Epoch 499, Step 1, LR: 0.000080, Current Loss: 0.4023, Avg Loss: 0.4023\n",
      "Diff stats — min: -6.5739, max: 9.6921, mean: 1.5727, std: 1.7401\n",
      "\n",
      "Step 5476 — Test metrics:\n",
      "  precision@10: 0.005965909\n",
      "  recall@10: 0.005968845\n",
      "  ndcg@10: 0.006249411\n",
      "  map@10: 0.001963522\n",
      "Epoch 499, Step 10, LR: 0.000080, Current Loss: 0.4074, Avg Loss: 0.4011\n",
      "Diff stats — min: -5.6214, max: 8.3478, mean: 1.5594, std: 1.7447\n",
      "\n",
      "Step 5485 — Test metrics:\n",
      "  precision@10: 0.005952696\n",
      "  recall@10: 0.005954898\n",
      "  ndcg@10: 0.006213349\n",
      "  map@10: 0.001948530\n",
      "Epoch 499 completed, Train Loss: 0.4005\n",
      "Epoch 500, Step 1, LR: 0.000080, Current Loss: 0.3962, Avg Loss: 0.3962\n",
      "Diff stats — min: -9.1053, max: 9.0345, mean: 1.5888, std: 1.7371\n",
      "\n",
      "Step 5487 — Test metrics:\n",
      "  precision@10: 0.005992336\n",
      "  recall@10: 0.005994538\n",
      "  ndcg@10: 0.006232329\n",
      "  map@10: 0.001948024\n",
      "Epoch 500, Step 10, LR: 0.000080, Current Loss: 0.4007, Avg Loss: 0.3990\n",
      "Diff stats — min: -5.3416, max: 9.3851, mean: 1.5703, std: 1.7302\n",
      "\n",
      "Step 5496 — Test metrics:\n",
      "  precision@10: 0.005998943\n",
      "  recall@10: 0.006001145\n",
      "  ndcg@10: 0.006286767\n",
      "  map@10: 0.001976247\n",
      "Epoch 500 completed, Train Loss: 0.3989\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model,\n",
    "                    data,\n",
    "                    edge_type=edge_type,\n",
    "                    num_epochs=num_epochs,\n",
    "                    lr=lr,\n",
    "                    batch_size=batch_size,\n",
    "                    print_every=print_every,\n",
    "                    test_every=test_every,\n",
    "                    top_k=top_k,\n",
    "                    test_batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T23:14:00.207212Z",
     "iopub.status.busy": "2025-06-24T23:14:00.206873Z",
     "iopub.status.idle": "2025-06-25T01:12:18.833109Z",
     "shell.execute_reply": "2025-06-25T01:12:18.832487Z",
     "shell.execute_reply.started": "2025-06-24T23:14:00.207186Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training examples: 359463\n",
      "Epoch 501, Step 1, LR: 0.000080, Current Loss: 0.3993, Avg Loss: 0.3993\n",
      "Diff stats — min: -5.6972, max: 11.0533, mean: 1.5775, std: 1.7362\n",
      "\n",
      "Step 5497 — Test metrics:\n",
      "  precision@10: 0.006031977\n",
      "  recall@10: 0.006034179\n",
      "  ndcg@10: 0.006330427\n",
      "  map@10: 0.001993567\n",
      "Epoch 501, Step 10, LR: 0.000080, Current Loss: 0.4030, Avg Loss: 0.3996\n",
      "Diff stats — min: -6.4241, max: 10.5434, mean: 1.5768, std: 1.7500\n",
      "\n",
      "Step 5506 — Test metrics:\n",
      "  precision@10: 0.005992336\n",
      "  recall@10: 0.005996007\n",
      "  ndcg@10: 0.006302921\n",
      "  map@10: 0.001986033\n",
      "Epoch 501 completed, Train Loss: 0.3993\n",
      "Epoch 502, Step 1, LR: 0.000080, Current Loss: 0.4035, Avg Loss: 0.4035\n",
      "Diff stats — min: -8.8749, max: 8.3995, mean: 1.5696, std: 1.7410\n",
      "\n",
      "Step 5508 — Test metrics:\n",
      "  precision@10: 0.005979123\n",
      "  recall@10: 0.005982793\n",
      "  ndcg@10: 0.006259778\n",
      "  map@10: 0.001963271\n",
      "Epoch 502, Step 10, LR: 0.000080, Current Loss: 0.3991, Avg Loss: 0.3988\n",
      "Diff stats — min: -6.0197, max: 9.0108, mean: 1.5832, std: 1.7364\n",
      "\n",
      "Step 5517 — Test metrics:\n",
      "  precision@10: 0.006005550\n",
      "  recall@10: 0.006008486\n",
      "  ndcg@10: 0.006243800\n",
      "  map@10: 0.001947998\n",
      "Epoch 502 completed, Train Loss: 0.3985\n",
      "Epoch 503, Step 1, LR: 0.000080, Current Loss: 0.4009, Avg Loss: 0.4009\n",
      "Diff stats — min: -6.2481, max: 9.9805, mean: 1.5842, std: 1.7515\n",
      "\n",
      "Step 5519 — Test metrics:\n",
      "  precision@10: 0.006005550\n",
      "  recall@10: 0.006008486\n",
      "  ndcg@10: 0.006249829\n",
      "  map@10: 0.001950565\n",
      "Epoch 503, Step 10, LR: 0.000080, Current Loss: 0.3949, Avg Loss: 0.3985\n",
      "Diff stats — min: -5.4439, max: 7.9260, mean: 1.6055, std: 1.7445\n",
      "\n",
      "Step 5528 — Test metrics:\n",
      "  precision@10: 0.005979123\n",
      "  recall@10: 0.005982793\n",
      "  ndcg@10: 0.006293413\n",
      "  map@10: 0.001985130\n",
      "Epoch 503 completed, Train Loss: 0.3984\n",
      "Epoch 504, Step 1, LR: 0.000080, Current Loss: 0.3963, Avg Loss: 0.3963\n",
      "Diff stats — min: -6.3394, max: 8.4933, mean: 1.5955, std: 1.7390\n",
      "\n",
      "Step 5530 — Test metrics:\n",
      "  precision@10: 0.005965909\n",
      "  recall@10: 0.005969580\n",
      "  ndcg@10: 0.006296757\n",
      "  map@10: 0.001991223\n",
      "Epoch 504, Step 10, LR: 0.000080, Current Loss: 0.3976, Avg Loss: 0.3968\n",
      "Diff stats — min: -5.4017, max: 8.5943, mean: 1.6028, std: 1.7546\n",
      "\n",
      "Step 5539 — Test metrics:\n",
      "  precision@10: 0.005992336\n",
      "  recall@10: 0.005996007\n",
      "  ndcg@10: 0.006296523\n",
      "  map@10: 0.001983266\n",
      "Epoch 504 completed, Train Loss: 0.3968\n",
      "Epoch 505, Step 1, LR: 0.000080, Current Loss: 0.4021, Avg Loss: 0.4021\n",
      "Diff stats — min: -6.5172, max: 8.7809, mean: 1.5844, std: 1.7535\n",
      "\n",
      "Step 5541 — Test metrics:\n",
      "  precision@10: 0.005979123\n",
      "  recall@10: 0.005982793\n",
      "  ndcg@10: 0.006289121\n",
      "  map@10: 0.001982860\n",
      "Epoch 505, Step 10, LR: 0.000080, Current Loss: 0.3967, Avg Loss: 0.3980\n",
      "Diff stats — min: -6.1645, max: 9.7778, mean: 1.6001, std: 1.7466\n",
      "\n",
      "Step 5550 — Test metrics:\n",
      "  precision@10: 0.005952696\n",
      "  recall@10: 0.005956366\n",
      "  ndcg@10: 0.006288248\n",
      "  map@10: 0.001988756\n",
      "Epoch 505 completed, Train Loss: 0.3974\n",
      "Epoch 506, Step 1, LR: 0.000080, Current Loss: 0.3946, Avg Loss: 0.3946\n",
      "Diff stats — min: -5.2242, max: 9.4650, mean: 1.6062, std: 1.7449\n",
      "\n",
      "Step 5552 — Test metrics:\n",
      "  precision@10: 0.005939482\n",
      "  recall@10: 0.005943152\n",
      "  ndcg@10: 0.006276650\n",
      "  map@10: 0.001985128\n",
      "Epoch 506, Step 10, LR: 0.000080, Current Loss: 0.4042, Avg Loss: 0.3958\n",
      "Diff stats — min: -5.7617, max: 9.4234, mean: 1.5821, std: 1.7596\n",
      "\n",
      "Step 5561 — Test metrics:\n",
      "  precision@10: 0.006065011\n",
      "  recall@10: 0.006068681\n",
      "  ndcg@10: 0.006336526\n",
      "  map@10: 0.001984567\n",
      "Epoch 506 completed, Train Loss: 0.3958\n",
      "Epoch 507, Step 1, LR: 0.000080, Current Loss: 0.3981, Avg Loss: 0.3981\n",
      "Diff stats — min: -6.0736, max: 12.3241, mean: 1.5926, std: 1.7453\n",
      "\n",
      "Step 5563 — Test metrics:\n",
      "  precision@10: 0.006091438\n",
      "  recall@10: 0.006095108\n",
      "  ndcg@10: 0.006357993\n",
      "  map@10: 0.001990547\n",
      "Epoch 507, Step 10, LR: 0.000080, Current Loss: 0.3981, Avg Loss: 0.3962\n",
      "Diff stats — min: -5.6476, max: 13.8476, mean: 1.6098, std: 1.7655\n",
      "\n",
      "Step 5572 — Test metrics:\n",
      "  precision@10: 0.006005550\n",
      "  recall@10: 0.006008486\n",
      "  ndcg@10: 0.006291281\n",
      "  map@10: 0.001977757\n",
      "Epoch 507 completed, Train Loss: 0.3964\n",
      "Epoch 508, Step 1, LR: 0.000080, Current Loss: 0.3941, Avg Loss: 0.3941\n",
      "Diff stats — min: -9.1428, max: 10.2049, mean: 1.6162, std: 1.7554\n",
      "\n",
      "Step 5574 — Test metrics:\n",
      "  precision@10: 0.005998943\n",
      "  recall@10: 0.006001879\n",
      "  ndcg@10: 0.006290904\n",
      "  map@10: 0.001978515\n",
      "Epoch 508, Step 10, LR: 0.000080, Current Loss: 0.3956, Avg Loss: 0.3956\n",
      "Diff stats — min: -5.2992, max: 10.9280, mean: 1.6071, std: 1.7482\n",
      "\n",
      "Step 5583 — Test metrics:\n",
      "  precision@10: 0.005998943\n",
      "  recall@10: 0.006002613\n",
      "  ndcg@10: 0.006303364\n",
      "  map@10: 0.001988903\n",
      "Epoch 508 completed, Train Loss: 0.3963\n",
      "Epoch 509, Step 1, LR: 0.000080, Current Loss: 0.3945, Avg Loss: 0.3945\n",
      "Diff stats — min: -6.5884, max: 9.5133, mean: 1.6100, std: 1.7459\n",
      "\n",
      "Step 5585 — Test metrics:\n",
      "  precision@10: 0.005998943\n",
      "  recall@10: 0.006002613\n",
      "  ndcg@10: 0.006297873\n",
      "  map@10: 0.001985835\n",
      "Epoch 509, Step 10, LR: 0.000080, Current Loss: 0.3941, Avg Loss: 0.3959\n",
      "Diff stats — min: -7.5883, max: 10.5041, mean: 1.6251, std: 1.7624\n",
      "\n",
      "Step 5594 — Test metrics:\n",
      "  precision@10: 0.006018763\n",
      "  recall@10: 0.006022434\n",
      "  ndcg@10: 0.006348587\n",
      "  map@10: 0.002006500\n",
      "Epoch 509 completed, Train Loss: 0.3960\n",
      "Epoch 510, Step 1, LR: 0.000080, Current Loss: 0.3930, Avg Loss: 0.3930\n",
      "Diff stats — min: -5.5783, max: 8.7149, mean: 1.6231, std: 1.7544\n",
      "\n",
      "Step 5596 — Test metrics:\n",
      "  precision@10: 0.006025370\n",
      "  recall@10: 0.006029040\n",
      "  ndcg@10: 0.006369951\n",
      "  map@10: 0.002016971\n",
      "Epoch 510, Step 10, LR: 0.000080, Current Loss: 0.3908, Avg Loss: 0.3938\n",
      "Diff stats — min: -6.3078, max: 10.6093, mean: 1.6208, std: 1.7448\n",
      "\n",
      "Step 5605 — Test metrics:\n",
      "  precision@10: 0.006098044\n",
      "  recall@10: 0.006101715\n",
      "  ndcg@10: 0.006446209\n",
      "  map@10: 0.002043767\n",
      "Epoch 510 completed, Train Loss: 0.3941\n",
      "Epoch 511, Step 1, LR: 0.000080, Current Loss: 0.3930, Avg Loss: 0.3930\n",
      "Diff stats — min: -5.4540, max: 8.3918, mean: 1.6216, std: 1.7537\n",
      "\n",
      "Step 5607 — Test metrics:\n",
      "  precision@10: 0.006078224\n",
      "  recall@10: 0.006081895\n",
      "  ndcg@10: 0.006417344\n",
      "  map@10: 0.002031270\n",
      "Epoch 511, Step 10, LR: 0.000080, Current Loss: 0.3955, Avg Loss: 0.3940\n",
      "Diff stats — min: -5.4518, max: 12.5901, mean: 1.6189, std: 1.7639\n",
      "\n",
      "Step 5616 — Test metrics:\n",
      "  precision@10: 0.006018763\n",
      "  recall@10: 0.006021700\n",
      "  ndcg@10: 0.006315315\n",
      "  map@10: 0.001983129\n",
      "Epoch 511 completed, Train Loss: 0.3941\n",
      "Epoch 512, Step 1, LR: 0.000080, Current Loss: 0.3921, Avg Loss: 0.3921\n",
      "Diff stats — min: -5.4661, max: 9.5542, mean: 1.6342, std: 1.7660\n",
      "\n",
      "Step 5618 — Test metrics:\n",
      "  precision@10: 0.005998943\n",
      "  recall@10: 0.006001879\n",
      "  ndcg@10: 0.006296983\n",
      "  map@10: 0.001977463\n",
      "Epoch 512, Step 10, LR: 0.000080, Current Loss: 0.3933, Avg Loss: 0.3929\n",
      "Diff stats — min: -5.6062, max: 10.8330, mean: 1.6285, std: 1.7646\n",
      "\n",
      "Step 5627 — Test metrics:\n",
      "  precision@10: 0.005979123\n",
      "  recall@10: 0.005982059\n",
      "  ndcg@10: 0.006300856\n",
      "  map@10: 0.001986748\n",
      "Epoch 512 completed, Train Loss: 0.3932\n",
      "Epoch 513, Step 1, LR: 0.000080, Current Loss: 0.3923, Avg Loss: 0.3923\n",
      "Diff stats — min: -5.6617, max: 10.9828, mean: 1.6316, std: 1.7629\n",
      "\n",
      "Step 5629 — Test metrics:\n",
      "  precision@10: 0.005985729\n",
      "  recall@10: 0.005988666\n",
      "  ndcg@10: 0.006307667\n",
      "  map@10: 0.001989265\n",
      "Epoch 513, Step 10, LR: 0.000080, Current Loss: 0.3911, Avg Loss: 0.3937\n",
      "Diff stats — min: -6.1272, max: 9.6322, mean: 1.6394, std: 1.7695\n",
      "\n",
      "Step 5638 — Test metrics:\n",
      "  precision@10: 0.005998943\n",
      "  recall@10: 0.006002613\n",
      "  ndcg@10: 0.006291137\n",
      "  map@10: 0.001977364\n",
      "Epoch 513 completed, Train Loss: 0.3943\n",
      "Epoch 514, Step 1, LR: 0.000080, Current Loss: 0.3922, Avg Loss: 0.3922\n",
      "Diff stats — min: -5.3021, max: 10.2707, mean: 1.6390, std: 1.7705\n",
      "\n",
      "Step 5640 — Test metrics:\n",
      "  precision@10: 0.005992336\n",
      "  recall@10: 0.005996007\n",
      "  ndcg@10: 0.006283704\n",
      "  map@10: 0.001975421\n",
      "Epoch 514, Step 10, LR: 0.000080, Current Loss: 0.3957, Avg Loss: 0.3942\n",
      "Diff stats — min: -5.4692, max: 11.9197, mean: 1.6262, std: 1.7706\n",
      "\n",
      "Step 5649 — Test metrics:\n",
      "  precision@10: 0.005992336\n",
      "  recall@10: 0.005996007\n",
      "  ndcg@10: 0.006334104\n",
      "  map@10: 0.002005841\n",
      "Epoch 514 completed, Train Loss: 0.3938\n",
      "Epoch 515, Step 1, LR: 0.000080, Current Loss: 0.3894, Avg Loss: 0.3894\n",
      "Diff stats — min: -6.7230, max: 9.1042, mean: 1.6454, std: 1.7640\n",
      "\n",
      "Step 5651 — Test metrics:\n",
      "  precision@10: 0.006012156\n",
      "  recall@10: 0.006015827\n",
      "  ndcg@10: 0.006348398\n",
      "  map@10: 0.002007535\n",
      "Epoch 515, Step 10, LR: 0.000080, Current Loss: 0.3965, Avg Loss: 0.3928\n",
      "Diff stats — min: -5.3107, max: 8.4883, mean: 1.6186, std: 1.7659\n",
      "\n",
      "Step 5660 — Test metrics:\n",
      "  precision@10: 0.006045190\n",
      "  recall@10: 0.006048861\n",
      "  ndcg@10: 0.006345499\n",
      "  map@10: 0.001996978\n",
      "Epoch 515 completed, Train Loss: 0.3931\n",
      "Epoch 516, Step 1, LR: 0.000080, Current Loss: 0.3935, Avg Loss: 0.3935\n",
      "Diff stats — min: -6.0613, max: 9.5575, mean: 1.6375, std: 1.7709\n",
      "\n",
      "Step 5662 — Test metrics:\n",
      "  precision@10: 0.006051797\n",
      "  recall@10: 0.006055467\n",
      "  ndcg@10: 0.006364431\n",
      "  map@10: 0.002006935\n",
      "Epoch 516, Step 10, LR: 0.000080, Current Loss: 0.3937, Avg Loss: 0.3929\n",
      "Diff stats — min: -5.2305, max: 8.6386, mean: 1.6490, std: 1.7867\n",
      "\n",
      "Step 5671 — Test metrics:\n",
      "  precision@10: 0.006150899\n",
      "  recall@10: 0.006154569\n",
      "  ndcg@10: 0.006469892\n",
      "  map@10: 0.002044197\n",
      "Epoch 516 completed, Train Loss: 0.3928\n",
      "Epoch 517, Step 1, LR: 0.000080, Current Loss: 0.3913, Avg Loss: 0.3913\n",
      "Diff stats — min: -6.9821, max: 10.2379, mean: 1.6439, std: 1.7744\n",
      "\n",
      "Step 5673 — Test metrics:\n",
      "  precision@10: 0.006131078\n",
      "  recall@10: 0.006134749\n",
      "  ndcg@10: 0.006442044\n",
      "  map@10: 0.002033243\n",
      "Epoch 517, Step 10, LR: 0.000080, Current Loss: 0.3896, Avg Loss: 0.3913\n",
      "Diff stats — min: -6.1541, max: 13.3447, mean: 1.6486, std: 1.7693\n",
      "\n",
      "Step 5682 — Test metrics:\n",
      "  precision@10: 0.006091438\n",
      "  recall@10: 0.006094374\n",
      "  ndcg@10: 0.006399240\n",
      "  map@10: 0.002017029\n",
      "Epoch 517 completed, Train Loss: 0.3918\n",
      "Epoch 518, Step 1, LR: 0.000080, Current Loss: 0.3937, Avg Loss: 0.3937\n",
      "Diff stats — min: -5.4677, max: 9.5085, mean: 1.6395, std: 1.7782\n",
      "\n",
      "Step 5684 — Test metrics:\n",
      "  precision@10: 0.006078224\n",
      "  recall@10: 0.006081895\n",
      "  ndcg@10: 0.006422280\n",
      "  map@10: 0.002033753\n",
      "Epoch 518, Step 10, LR: 0.000080, Current Loss: 0.3889, Avg Loss: 0.3918\n",
      "Diff stats — min: -5.8144, max: 9.6086, mean: 1.6502, std: 1.7729\n",
      "\n",
      "Step 5693 — Test metrics:\n",
      "  precision@10: 0.006071617\n",
      "  recall@10: 0.006075288\n",
      "  ndcg@10: 0.006433712\n",
      "  map@10: 0.002041846\n",
      "Epoch 518 completed, Train Loss: 0.3917\n",
      "Epoch 519, Step 1, LR: 0.000080, Current Loss: 0.3926, Avg Loss: 0.3926\n",
      "Diff stats — min: -5.6871, max: 9.1839, mean: 1.6397, std: 1.7698\n",
      "\n",
      "Step 5695 — Test metrics:\n",
      "  precision@10: 0.006084831\n",
      "  recall@10: 0.006088501\n",
      "  ndcg@10: 0.006441496\n",
      "  map@10: 0.002041751\n",
      "Epoch 519, Step 10, LR: 0.000080, Current Loss: 0.3932, Avg Loss: 0.3930\n",
      "Diff stats — min: -5.3126, max: 8.6000, mean: 1.6465, std: 1.7803\n",
      "\n",
      "Step 5704 — Test metrics:\n",
      "  precision@10: 0.006117865\n",
      "  recall@10: 0.006121535\n",
      "  ndcg@10: 0.006470745\n",
      "  map@10: 0.002054136\n",
      "Epoch 519 completed, Train Loss: 0.3929\n",
      "Epoch 520, Step 1, LR: 0.000080, Current Loss: 0.3942, Avg Loss: 0.3942\n",
      "Diff stats — min: -5.4729, max: 9.9237, mean: 1.6554, std: 1.7951\n",
      "\n",
      "Step 5706 — Test metrics:\n",
      "  precision@10: 0.006091438\n",
      "  recall@10: 0.006095108\n",
      "  ndcg@10: 0.006447370\n",
      "  map@10: 0.002048017\n",
      "Epoch 520, Step 10, LR: 0.000080, Current Loss: 0.3872, Avg Loss: 0.3920\n",
      "Diff stats — min: -6.8346, max: 8.5539, mean: 1.6609, std: 1.7721\n",
      "\n",
      "Step 5715 — Test metrics:\n",
      "  precision@10: 0.006164112\n",
      "  recall@10: 0.006167782\n",
      "  ndcg@10: 0.006460103\n",
      "  map@10: 0.002035017\n",
      "Epoch 520 completed, Train Loss: 0.3918\n",
      "Epoch 521, Step 1, LR: 0.000080, Current Loss: 0.3944, Avg Loss: 0.3944\n",
      "Diff stats — min: -5.4319, max: 10.5048, mean: 1.6520, std: 1.7909\n",
      "\n",
      "Step 5717 — Test metrics:\n",
      "  precision@10: 0.006137685\n",
      "  recall@10: 0.006141355\n",
      "  ndcg@10: 0.006453781\n",
      "  map@10: 0.002036498\n",
      "Epoch 521, Step 10, LR: 0.000080, Current Loss: 0.3904, Avg Loss: 0.3907\n",
      "Diff stats — min: -5.6620, max: 11.0822, mean: 1.6583, std: 1.7853\n",
      "\n",
      "Step 5726 — Test metrics:\n",
      "  precision@10: 0.006183932\n",
      "  recall@10: 0.006187603\n",
      "  ndcg@10: 0.006498074\n",
      "  map@10: 0.002051032\n",
      "Epoch 521 completed, Train Loss: 0.3905\n",
      "Epoch 522, Step 1, LR: 0.000080, Current Loss: 0.3946, Avg Loss: 0.3946\n",
      "Diff stats — min: -6.2313, max: 8.7715, mean: 1.6422, std: 1.7848\n",
      "\n",
      "Step 5728 — Test metrics:\n",
      "  precision@10: 0.006170719\n",
      "  recall@10: 0.006174389\n",
      "  ndcg@10: 0.006500579\n",
      "  map@10: 0.002057773\n",
      "Epoch 522, Step 10, LR: 0.000080, Current Loss: 0.3880, Avg Loss: 0.3908\n",
      "Diff stats — min: -6.3816, max: 9.4991, mean: 1.6614, std: 1.7772\n",
      "\n",
      "Step 5737 — Test metrics:\n",
      "  precision@10: 0.006203753\n",
      "  recall@10: 0.006207423\n",
      "  ndcg@10: 0.006513431\n",
      "  map@10: 0.002055512\n",
      "Epoch 522 completed, Train Loss: 0.3905\n",
      "Epoch 523, Step 1, LR: 0.000080, Current Loss: 0.3920, Avg Loss: 0.3920\n",
      "Diff stats — min: -5.3918, max: 10.4438, mean: 1.6508, std: 1.7807\n",
      "\n",
      "Step 5739 — Test metrics:\n",
      "  precision@10: 0.006183932\n",
      "  recall@10: 0.006187603\n",
      "  ndcg@10: 0.006499018\n",
      "  map@10: 0.002052049\n",
      "Epoch 523, Step 10, LR: 0.000080, Current Loss: 0.3895, Avg Loss: 0.3902\n",
      "Diff stats — min: -5.9452, max: 9.3206, mean: 1.6552, std: 1.7782\n",
      "\n",
      "Step 5748 — Test metrics:\n",
      "  precision@10: 0.006091438\n",
      "  recall@10: 0.006095108\n",
      "  ndcg@10: 0.006443043\n",
      "  map@10: 0.002043846\n",
      "Epoch 523 completed, Train Loss: 0.3901\n",
      "Epoch 524, Step 1, LR: 0.000080, Current Loss: 0.3890, Avg Loss: 0.3890\n",
      "Diff stats — min: -6.0763, max: 9.3121, mean: 1.6611, std: 1.7792\n",
      "\n",
      "Step 5750 — Test metrics:\n",
      "  precision@10: 0.006131078\n",
      "  recall@10: 0.006134749\n",
      "  ndcg@10: 0.006475370\n",
      "  map@10: 0.002052432\n",
      "Epoch 524, Step 10, LR: 0.000080, Current Loss: 0.3878, Avg Loss: 0.3892\n",
      "Diff stats — min: -5.2443, max: 8.9446, mean: 1.6712, std: 1.7866\n",
      "\n",
      "Step 5759 — Test metrics:\n",
      "  precision@10: 0.006236786\n",
      "  recall@10: 0.006240457\n",
      "  ndcg@10: 0.006649154\n",
      "  map@10: 0.002123629\n",
      "Epoch 524 completed, Train Loss: 0.3891\n",
      "Epoch 525, Step 1, LR: 0.000080, Current Loss: 0.3885, Avg Loss: 0.3885\n",
      "Diff stats — min: -5.2913, max: 9.5942, mean: 1.6655, std: 1.7834\n",
      "\n",
      "Step 5761 — Test metrics:\n",
      "  precision@10: 0.006243393\n",
      "  recall@10: 0.006247064\n",
      "  ndcg@10: 0.006637162\n",
      "  map@10: 0.002115203\n",
      "Epoch 525, Step 10, LR: 0.000080, Current Loss: 0.3909, Avg Loss: 0.3896\n",
      "Diff stats — min: -6.3054, max: 9.8287, mean: 1.6617, std: 1.7912\n",
      "\n",
      "Step 5770 — Test metrics:\n",
      "  precision@10: 0.006250000\n",
      "  recall@10: 0.006253670\n",
      "  ndcg@10: 0.006558897\n",
      "  map@10: 0.002068535\n",
      "Epoch 525 completed, Train Loss: 0.3896\n",
      "Epoch 526, Step 1, LR: 0.000080, Current Loss: 0.3905, Avg Loss: 0.3905\n",
      "Diff stats — min: -5.3449, max: 9.5351, mean: 1.6587, std: 1.7875\n",
      "\n",
      "Step 5772 — Test metrics:\n",
      "  precision@10: 0.006230180\n",
      "  recall@10: 0.006233850\n",
      "  ndcg@10: 0.006525722\n",
      "  map@10: 0.002054953\n",
      "Epoch 526, Step 10, LR: 0.000080, Current Loss: 0.3909, Avg Loss: 0.3892\n",
      "Diff stats — min: -5.6676, max: 11.0657, mean: 1.6567, std: 1.7839\n",
      "\n",
      "Step 5781 — Test metrics:\n",
      "  precision@10: 0.006197146\n",
      "  recall@10: 0.006200816\n",
      "  ndcg@10: 0.006457195\n",
      "  map@10: 0.002025448\n",
      "Epoch 526 completed, Train Loss: 0.3887\n",
      "Epoch 527, Step 1, LR: 0.000080, Current Loss: 0.3912, Avg Loss: 0.3912\n",
      "Diff stats — min: -8.9780, max: 9.6230, mean: 1.6660, std: 1.7947\n",
      "\n",
      "Step 5783 — Test metrics:\n",
      "  precision@10: 0.006177326\n",
      "  recall@10: 0.006180996\n",
      "  ndcg@10: 0.006432839\n",
      "  map@10: 0.002014960\n",
      "Epoch 527, Step 10, LR: 0.000080, Current Loss: 0.3912, Avg Loss: 0.3896\n",
      "Diff stats — min: -5.7747, max: 9.5354, mean: 1.6627, std: 1.7896\n",
      "\n",
      "Step 5792 — Test metrics:\n",
      "  precision@10: 0.006177326\n",
      "  recall@10: 0.006180996\n",
      "  ndcg@10: 0.006466577\n",
      "  map@10: 0.002034266\n",
      "Epoch 527 completed, Train Loss: 0.3892\n",
      "Epoch 528, Step 1, LR: 0.000080, Current Loss: 0.3837, Avg Loss: 0.3837\n",
      "Diff stats — min: -6.0567, max: 10.6733, mean: 1.6899, std: 1.7891\n",
      "\n",
      "Step 5794 — Test metrics:\n",
      "  precision@10: 0.006183932\n",
      "  recall@10: 0.006187603\n",
      "  ndcg@10: 0.006469222\n",
      "  map@10: 0.002034623\n",
      "Epoch 528, Step 10, LR: 0.000080, Current Loss: 0.3908, Avg Loss: 0.3877\n",
      "Diff stats — min: -5.2820, max: 10.8548, mean: 1.6737, std: 1.7985\n",
      "\n",
      "Step 5803 — Test metrics:\n",
      "  precision@10: 0.006170719\n",
      "  recall@10: 0.006174389\n",
      "  ndcg@10: 0.006472273\n",
      "  map@10: 0.002042053\n",
      "Epoch 528 completed, Train Loss: 0.3881\n",
      "Epoch 529, Step 1, LR: 0.000080, Current Loss: 0.3851, Avg Loss: 0.3851\n",
      "Diff stats — min: -5.2817, max: 9.3400, mean: 1.6898, std: 1.7943\n",
      "\n",
      "Step 5805 — Test metrics:\n",
      "  precision@10: 0.006183932\n",
      "  recall@10: 0.006187603\n",
      "  ndcg@10: 0.006486049\n",
      "  map@10: 0.002045288\n",
      "Epoch 529, Step 10, LR: 0.000080, Current Loss: 0.3923, Avg Loss: 0.3880\n",
      "Diff stats — min: -6.2317, max: 10.7741, mean: 1.6634, std: 1.7948\n",
      "\n",
      "Step 5814 — Test metrics:\n",
      "  precision@10: 0.006144292\n",
      "  recall@10: 0.006147962\n",
      "  ndcg@10: 0.006486584\n",
      "  map@10: 0.002053325\n",
      "Epoch 529 completed, Train Loss: 0.3877\n",
      "Epoch 530, Step 1, LR: 0.000080, Current Loss: 0.3802, Avg Loss: 0.3802\n",
      "Diff stats — min: -5.4499, max: 14.7553, mean: 1.6874, std: 1.7728\n",
      "\n",
      "Step 5816 — Test metrics:\n",
      "  precision@10: 0.006131078\n",
      "  recall@10: 0.006134749\n",
      "  ndcg@10: 0.006479127\n",
      "  map@10: 0.002051571\n",
      "Epoch 530, Step 10, LR: 0.000080, Current Loss: 0.3890, Avg Loss: 0.3877\n",
      "Diff stats — min: -6.0462, max: 12.1642, mean: 1.6786, std: 1.7979\n",
      "\n",
      "Step 5825 — Test metrics:\n",
      "  precision@10: 0.006117865\n",
      "  recall@10: 0.006121535\n",
      "  ndcg@10: 0.006450968\n",
      "  map@10: 0.002040290\n",
      "Epoch 530 completed, Train Loss: 0.3878\n",
      "Epoch 531, Step 1, LR: 0.000080, Current Loss: 0.3900, Avg Loss: 0.3900\n",
      "Diff stats — min: -6.1011, max: 9.8324, mean: 1.6902, std: 1.8150\n",
      "\n",
      "Step 5827 — Test metrics:\n",
      "  precision@10: 0.006137685\n",
      "  recall@10: 0.006141355\n",
      "  ndcg@10: 0.006443735\n",
      "  map@10: 0.002031405\n",
      "Epoch 531, Step 10, LR: 0.000080, Current Loss: 0.3870, Avg Loss: 0.3880\n",
      "Diff stats — min: -6.2745, max: 9.7040, mean: 1.6811, std: 1.7921\n",
      "\n",
      "Step 5836 — Test metrics:\n",
      "  precision@10: 0.006170719\n",
      "  recall@10: 0.006174389\n",
      "  ndcg@10: 0.006460989\n",
      "  map@10: 0.002032947\n",
      "Epoch 531 completed, Train Loss: 0.3873\n",
      "Epoch 532, Step 1, LR: 0.000080, Current Loss: 0.3896, Avg Loss: 0.3896\n",
      "Diff stats — min: -6.5457, max: 9.3636, mean: 1.6782, std: 1.8013\n",
      "\n",
      "Step 5838 — Test metrics:\n",
      "  precision@10: 0.006164112\n",
      "  recall@10: 0.006167782\n",
      "  ndcg@10: 0.006458310\n",
      "  map@10: 0.002032011\n",
      "Epoch 532, Step 10, LR: 0.000080, Current Loss: 0.3884, Avg Loss: 0.3881\n",
      "Diff stats — min: -6.1416, max: 9.7191, mean: 1.6911, std: 1.8094\n",
      "\n",
      "Step 5847 — Test metrics:\n",
      "  precision@10: 0.006210359\n",
      "  recall@10: 0.006214030\n",
      "  ndcg@10: 0.006473715\n",
      "  map@10: 0.002030677\n",
      "Epoch 532 completed, Train Loss: 0.3880\n",
      "Epoch 533, Step 1, LR: 0.000080, Current Loss: 0.3842, Avg Loss: 0.3842\n",
      "Diff stats — min: -5.4767, max: 9.6668, mean: 1.6992, std: 1.8016\n",
      "\n",
      "Step 5849 — Test metrics:\n",
      "  precision@10: 0.006223573\n",
      "  recall@10: 0.006227243\n",
      "  ndcg@10: 0.006506778\n",
      "  map@10: 0.002046169\n",
      "Epoch 533, Step 10, LR: 0.000080, Current Loss: 0.3890, Avg Loss: 0.3851\n",
      "Diff stats — min: -5.4343, max: 9.0865, mean: 1.6670, std: 1.7883\n",
      "\n",
      "Step 5858 — Test metrics:\n",
      "  precision@10: 0.006263214\n",
      "  recall@10: 0.006266884\n",
      "  ndcg@10: 0.006563142\n",
      "  map@10: 0.002067276\n",
      "Epoch 533 completed, Train Loss: 0.3847\n",
      "Epoch 534, Step 1, LR: 0.000080, Current Loss: 0.3904, Avg Loss: 0.3904\n",
      "Diff stats — min: -6.6478, max: 11.7920, mean: 1.6775, std: 1.8052\n",
      "\n",
      "Step 5860 — Test metrics:\n",
      "  precision@10: 0.006223573\n",
      "  recall@10: 0.006227243\n",
      "  ndcg@10: 0.006551167\n",
      "  map@10: 0.002070145\n",
      "Epoch 534, Step 10, LR: 0.000080, Current Loss: 0.3824, Avg Loss: 0.3850\n",
      "Diff stats — min: -5.8512, max: 10.8315, mean: 1.6973, std: 1.7895\n",
      "\n",
      "Step 5869 — Test metrics:\n",
      "  precision@10: 0.006157505\n",
      "  recall@10: 0.006161176\n",
      "  ndcg@10: 0.006534379\n",
      "  map@10: 0.002079592\n",
      "Epoch 534 completed, Train Loss: 0.3851\n",
      "Epoch 535, Step 1, LR: 0.000080, Current Loss: 0.3890, Avg Loss: 0.3890\n",
      "Diff stats — min: -5.2153, max: 9.3631, mean: 1.6879, std: 1.8121\n",
      "\n",
      "Step 5871 — Test metrics:\n",
      "  precision@10: 0.006170719\n",
      "  recall@10: 0.006174389\n",
      "  ndcg@10: 0.006547035\n",
      "  map@10: 0.002082942\n",
      "Epoch 535, Step 10, LR: 0.000080, Current Loss: 0.3894, Avg Loss: 0.3864\n",
      "Diff stats — min: -6.0443, max: 9.1931, mean: 1.6900, std: 1.8114\n",
      "\n",
      "Step 5880 — Test metrics:\n",
      "  precision@10: 0.006203753\n",
      "  recall@10: 0.006207423\n",
      "  ndcg@10: 0.006555809\n",
      "  map@10: 0.002080284\n",
      "Epoch 535 completed, Train Loss: 0.3863\n",
      "Epoch 536, Step 1, LR: 0.000080, Current Loss: 0.3888, Avg Loss: 0.3888\n",
      "Diff stats — min: -6.6046, max: 10.4372, mean: 1.6891, std: 1.8104\n",
      "\n",
      "Step 5882 — Test metrics:\n",
      "  precision@10: 0.006183932\n",
      "  recall@10: 0.006187603\n",
      "  ndcg@10: 0.006548622\n",
      "  map@10: 0.002080166\n",
      "Epoch 536, Step 10, LR: 0.000080, Current Loss: 0.3852, Avg Loss: 0.3846\n",
      "Diff stats — min: -6.2431, max: 8.9620, mean: 1.7105, std: 1.8103\n",
      "\n",
      "Step 5891 — Test metrics:\n",
      "  precision@10: 0.006131078\n",
      "  recall@10: 0.006134749\n",
      "  ndcg@10: 0.006501834\n",
      "  map@10: 0.002066522\n",
      "Epoch 536 completed, Train Loss: 0.3848\n",
      "Epoch 537, Step 1, LR: 0.000080, Current Loss: 0.3853, Avg Loss: 0.3853\n",
      "Diff stats — min: -5.7723, max: 8.7736, mean: 1.6881, std: 1.7959\n",
      "\n",
      "Step 5893 — Test metrics:\n",
      "  precision@10: 0.006144292\n",
      "  recall@10: 0.006147962\n",
      "  ndcg@10: 0.006507557\n",
      "  map@10: 0.002065379\n",
      "Epoch 537, Step 10, LR: 0.000080, Current Loss: 0.3840, Avg Loss: 0.3850\n",
      "Diff stats — min: -6.0778, max: 20.0958, mean: 1.7143, std: 1.8180\n",
      "\n",
      "Step 5902 — Test metrics:\n",
      "  precision@10: 0.006164112\n",
      "  recall@10: 0.006167782\n",
      "  ndcg@10: 0.006474037\n",
      "  map@10: 0.002039392\n",
      "Epoch 537 completed, Train Loss: 0.3852\n",
      "Epoch 538, Step 1, LR: 0.000080, Current Loss: 0.3861, Avg Loss: 0.3861\n",
      "Diff stats — min: -6.4529, max: 10.3037, mean: 1.6973, std: 1.8085\n",
      "\n",
      "Step 5904 — Test metrics:\n",
      "  precision@10: 0.006197146\n",
      "  recall@10: 0.006201550\n",
      "  ndcg@10: 0.006509058\n",
      "  map@10: 0.002050291\n",
      "Epoch 538, Step 10, LR: 0.000080, Current Loss: 0.3897, Avg Loss: 0.3840\n",
      "Diff stats — min: -6.0106, max: 8.7172, mean: 1.6894, std: 1.8116\n",
      "\n",
      "Step 5913 — Test metrics:\n",
      "  precision@10: 0.006269820\n",
      "  recall@10: 0.006274225\n",
      "  ndcg@10: 0.006625692\n",
      "  map@10: 0.002104331\n",
      "Epoch 538 completed, Train Loss: 0.3838\n",
      "Epoch 539, Step 1, LR: 0.000080, Current Loss: 0.3859, Avg Loss: 0.3859\n",
      "Diff stats — min: -5.3890, max: 9.7551, mean: 1.7044, std: 1.8134\n",
      "\n",
      "Step 5915 — Test metrics:\n",
      "  precision@10: 0.006250000\n",
      "  recall@10: 0.006253670\n",
      "  ndcg@10: 0.006607885\n",
      "  map@10: 0.002098798\n",
      "Epoch 539, Step 10, LR: 0.000080, Current Loss: 0.3813, Avg Loss: 0.3840\n",
      "Diff stats — min: -6.1012, max: 10.0200, mean: 1.7187, std: 1.8110\n",
      "\n",
      "Step 5924 — Test metrics:\n",
      "  precision@10: 0.006223573\n",
      "  recall@10: 0.006227243\n",
      "  ndcg@10: 0.006556904\n",
      "  map@10: 0.002073265\n",
      "Epoch 539 completed, Train Loss: 0.3839\n",
      "Epoch 540, Step 1, LR: 0.000080, Current Loss: 0.3830, Avg Loss: 0.3830\n",
      "Diff stats — min: -6.7870, max: 9.6014, mean: 1.7161, std: 1.8121\n",
      "\n",
      "Step 5926 — Test metrics:\n",
      "  precision@10: 0.006230180\n",
      "  recall@10: 0.006234584\n",
      "  ndcg@10: 0.006560608\n",
      "  map@10: 0.002074361\n",
      "Epoch 540, Step 10, LR: 0.000080, Current Loss: 0.3830, Avg Loss: 0.3828\n",
      "Diff stats — min: -5.6759, max: 9.8161, mean: 1.7036, std: 1.8011\n",
      "\n",
      "Step 5935 — Test metrics:\n",
      "  precision@10: 0.006190539\n",
      "  recall@10: 0.006194944\n",
      "  ndcg@10: 0.006549608\n",
      "  map@10: 0.002079744\n",
      "Epoch 540 completed, Train Loss: 0.3827\n",
      "Epoch 541, Step 1, LR: 0.000080, Current Loss: 0.3806, Avg Loss: 0.3806\n",
      "Diff stats — min: -5.4660, max: 10.2080, mean: 1.7223, std: 1.8138\n",
      "\n",
      "Step 5937 — Test metrics:\n",
      "  precision@10: 0.006210359\n",
      "  recall@10: 0.006214764\n",
      "  ndcg@10: 0.006530707\n",
      "  map@10: 0.002061967\n",
      "Epoch 541, Step 10, LR: 0.000080, Current Loss: 0.3836, Avg Loss: 0.3831\n",
      "Diff stats — min: -5.2359, max: 12.6365, mean: 1.7171, std: 1.8162\n",
      "\n",
      "Step 5946 — Test metrics:\n",
      "  precision@10: 0.006137685\n",
      "  recall@10: 0.006142089\n",
      "  ndcg@10: 0.006485158\n",
      "  map@10: 0.002053956\n",
      "Epoch 541 completed, Train Loss: 0.3831\n",
      "Epoch 542, Step 1, LR: 0.000080, Current Loss: 0.3890, Avg Loss: 0.3890\n",
      "Diff stats — min: -5.7226, max: 9.7547, mean: 1.7152, std: 1.8344\n",
      "\n",
      "Step 5948 — Test metrics:\n",
      "  precision@10: 0.006183932\n",
      "  recall@10: 0.006188337\n",
      "  ndcg@10: 0.006518706\n",
      "  map@10: 0.002061079\n",
      "Epoch 542, Step 10, LR: 0.000080, Current Loss: 0.3840, Avg Loss: 0.3821\n",
      "Diff stats — min: -5.7329, max: 10.7745, mean: 1.7100, std: 1.8090\n",
      "\n",
      "Step 5957 — Test metrics:\n",
      "  precision@10: 0.006250000\n",
      "  recall@10: 0.006254405\n",
      "  ndcg@10: 0.006564794\n",
      "  map@10: 0.002072726\n",
      "Epoch 542 completed, Train Loss: 0.3823\n",
      "Epoch 543, Step 1, LR: 0.000080, Current Loss: 0.3779, Avg Loss: 0.3779\n",
      "Diff stats — min: -6.0938, max: 10.9869, mean: 1.7270, std: 1.8080\n",
      "\n",
      "Step 5959 — Test metrics:\n",
      "  precision@10: 0.006276427\n",
      "  recall@10: 0.006280832\n",
      "  ndcg@10: 0.006574784\n",
      "  map@10: 0.002073555\n",
      "Epoch 543, Step 10, LR: 0.000080, Current Loss: 0.3842, Avg Loss: 0.3820\n",
      "Diff stats — min: -5.5123, max: 9.6048, mean: 1.7207, std: 1.8220\n",
      "\n",
      "Step 5968 — Test metrics:\n",
      "  precision@10: 0.006197146\n",
      "  recall@10: 0.006200816\n",
      "  ndcg@10: 0.006536914\n",
      "  map@10: 0.002074155\n",
      "Epoch 543 completed, Train Loss: 0.3819\n",
      "Epoch 544, Step 1, LR: 0.000080, Current Loss: 0.3822, Avg Loss: 0.3822\n",
      "Diff stats — min: -6.2634, max: 8.9527, mean: 1.7229, std: 1.8161\n",
      "\n",
      "Step 5970 — Test metrics:\n",
      "  precision@10: 0.006243393\n",
      "  recall@10: 0.006247798\n",
      "  ndcg@10: 0.006547314\n",
      "  map@10: 0.002067000\n",
      "Epoch 544, Step 10, LR: 0.000080, Current Loss: 0.3836, Avg Loss: 0.3820\n",
      "Diff stats — min: -5.4540, max: 9.6491, mean: 1.7146, std: 1.8207\n",
      "\n",
      "Step 5979 — Test metrics:\n",
      "  precision@10: 0.006263214\n",
      "  recall@10: 0.006267618\n",
      "  ndcg@10: 0.006560065\n",
      "  map@10: 0.002065807\n",
      "Epoch 544 completed, Train Loss: 0.3821\n",
      "Epoch 545, Step 1, LR: 0.000080, Current Loss: 0.3794, Avg Loss: 0.3794\n",
      "Diff stats — min: -5.4925, max: 11.4373, mean: 1.7345, std: 1.8156\n",
      "\n",
      "Step 5981 — Test metrics:\n",
      "  precision@10: 0.006236786\n",
      "  recall@10: 0.006241191\n",
      "  ndcg@10: 0.006537402\n",
      "  map@10: 0.002059519\n",
      "Epoch 545, Step 10, LR: 0.000080, Current Loss: 0.3881, Avg Loss: 0.3831\n",
      "Diff stats — min: -6.6452, max: 10.4373, mean: 1.7209, std: 1.8359\n",
      "\n",
      "Step 5990 — Test metrics:\n",
      "  precision@10: 0.006150899\n",
      "  recall@10: 0.006155303\n",
      "  ndcg@10: 0.006479913\n",
      "  map@10: 0.002045453\n",
      "Epoch 545 completed, Train Loss: 0.3831\n",
      "Epoch 546, Step 1, LR: 0.000080, Current Loss: 0.3813, Avg Loss: 0.3813\n",
      "Diff stats — min: -6.7927, max: 13.3661, mean: 1.7376, std: 1.8310\n",
      "\n",
      "Step 5992 — Test metrics:\n",
      "  precision@10: 0.006137685\n",
      "  recall@10: 0.006142089\n",
      "  ndcg@10: 0.006483126\n",
      "  map@10: 0.002052034\n",
      "Epoch 546, Step 10, LR: 0.000080, Current Loss: 0.3826, Avg Loss: 0.3820\n",
      "Diff stats — min: -5.6411, max: 9.7359, mean: 1.7290, std: 1.8250\n",
      "\n",
      "Step 6001 — Test metrics:\n",
      "  precision@10: 0.006177326\n",
      "  recall@10: 0.006181730\n",
      "  ndcg@10: 0.006524891\n",
      "  map@10: 0.002069921\n",
      "Epoch 546 completed, Train Loss: 0.3819\n",
      "Epoch 547, Step 1, LR: 0.000080, Current Loss: 0.3820, Avg Loss: 0.3820\n",
      "Diff stats — min: -5.4796, max: 10.8225, mean: 1.7239, std: 1.8194\n",
      "\n",
      "Step 6003 — Test metrics:\n",
      "  precision@10: 0.006190539\n",
      "  recall@10: 0.006194944\n",
      "  ndcg@10: 0.006526810\n",
      "  map@10: 0.002066402\n",
      "Epoch 547, Step 10, LR: 0.000080, Current Loss: 0.3785, Avg Loss: 0.3810\n",
      "Diff stats — min: -6.9817, max: 11.0663, mean: 1.7452, std: 1.8239\n",
      "\n",
      "Step 6012 — Test metrics:\n",
      "  precision@10: 0.006216966\n",
      "  recall@10: 0.006221371\n",
      "  ndcg@10: 0.006554457\n",
      "  map@10: 0.002074916\n",
      "Epoch 547 completed, Train Loss: 0.3811\n",
      "Epoch 548, Step 1, LR: 0.000080, Current Loss: 0.3775, Avg Loss: 0.3775\n",
      "Diff stats — min: -5.5007, max: 9.6399, mean: 1.7424, std: 1.8147\n",
      "\n",
      "Step 6014 — Test metrics:\n",
      "  precision@10: 0.006230180\n",
      "  recall@10: 0.006234584\n",
      "  ndcg@10: 0.006567115\n",
      "  map@10: 0.002079433\n",
      "Epoch 548, Step 10, LR: 0.000080, Current Loss: 0.3782, Avg Loss: 0.3806\n",
      "Diff stats — min: -6.1743, max: 10.4862, mean: 1.7540, std: 1.8321\n",
      "\n",
      "Step 6023 — Test metrics:\n",
      "  precision@10: 0.006243393\n",
      "  recall@10: 0.006247798\n",
      "  ndcg@10: 0.006595277\n",
      "  map@10: 0.002091652\n",
      "Epoch 548 completed, Train Loss: 0.3809\n",
      "Epoch 549, Step 1, LR: 0.000080, Current Loss: 0.3738, Avg Loss: 0.3738\n",
      "Diff stats — min: -5.3518, max: 10.5999, mean: 1.7646, std: 1.8246\n",
      "\n",
      "Step 6025 — Test metrics:\n",
      "  precision@10: 0.006230180\n",
      "  recall@10: 0.006234584\n",
      "  ndcg@10: 0.006573820\n",
      "  map@10: 0.002082326\n",
      "Epoch 549, Step 10, LR: 0.000080, Current Loss: 0.3815, Avg Loss: 0.3812\n",
      "Diff stats — min: -6.1963, max: 11.6256, mean: 1.7381, std: 1.8323\n",
      "\n",
      "Step 6034 — Test metrics:\n",
      "  precision@10: 0.006263214\n",
      "  recall@10: 0.006267618\n",
      "  ndcg@10: 0.006572661\n",
      "  map@10: 0.002069941\n",
      "Epoch 549 completed, Train Loss: 0.3806\n",
      "Epoch 550, Step 1, LR: 0.000080, Current Loss: 0.3828, Avg Loss: 0.3828\n",
      "Diff stats — min: -5.1219, max: 10.6763, mean: 1.7369, std: 1.8349\n",
      "\n",
      "Step 6036 — Test metrics:\n",
      "  precision@10: 0.006256607\n",
      "  recall@10: 0.006261011\n",
      "  ndcg@10: 0.006568015\n",
      "  map@10: 0.002068240\n",
      "Epoch 550, Step 10, LR: 0.000080, Current Loss: 0.3793, Avg Loss: 0.3809\n",
      "Diff stats — min: -5.9632, max: 9.9295, mean: 1.7519, std: 1.8340\n",
      "\n",
      "Step 6045 — Test metrics:\n",
      "  precision@10: 0.006236786\n",
      "  recall@10: 0.006241191\n",
      "  ndcg@10: 0.006596010\n",
      "  map@10: 0.002093485\n",
      "Epoch 550 completed, Train Loss: 0.3811\n",
      "Epoch 551, Step 1, LR: 0.000080, Current Loss: 0.3801, Avg Loss: 0.3801\n",
      "Diff stats — min: -6.2508, max: 10.1378, mean: 1.7382, std: 1.8266\n",
      "\n",
      "Step 6047 — Test metrics:\n",
      "  precision@10: 0.006210359\n",
      "  recall@10: 0.006214764\n",
      "  ndcg@10: 0.006594382\n",
      "  map@10: 0.002100034\n",
      "Epoch 551, Step 10, LR: 0.000080, Current Loss: 0.3818, Avg Loss: 0.3812\n",
      "Diff stats — min: -5.5501, max: 9.4942, mean: 1.7437, std: 1.8361\n",
      "\n",
      "Step 6056 — Test metrics:\n",
      "  precision@10: 0.006210359\n",
      "  recall@10: 0.006214764\n",
      "  ndcg@10: 0.006564140\n",
      "  map@10: 0.002081911\n",
      "Epoch 551 completed, Train Loss: 0.3812\n",
      "Epoch 552, Step 1, LR: 0.000080, Current Loss: 0.3744, Avg Loss: 0.3744\n",
      "Diff stats — min: -5.2329, max: 10.0033, mean: 1.7624, std: 1.8230\n",
      "\n",
      "Step 6058 — Test metrics:\n",
      "  precision@10: 0.006223573\n",
      "  recall@10: 0.006227977\n",
      "  ndcg@10: 0.006579716\n",
      "  map@10: 0.002087029\n",
      "Epoch 552, Step 10, LR: 0.000080, Current Loss: 0.3843, Avg Loss: 0.3797\n",
      "Diff stats — min: -5.2458, max: 12.9105, mean: 1.7333, std: 1.8372\n",
      "\n",
      "Step 6067 — Test metrics:\n",
      "  precision@10: 0.006316068\n",
      "  recall@10: 0.006320472\n",
      "  ndcg@10: 0.006707763\n",
      "  map@10: 0.002136387\n",
      "Epoch 552 completed, Train Loss: 0.3798\n",
      "Epoch 553, Step 1, LR: 0.000080, Current Loss: 0.3804, Avg Loss: 0.3804\n",
      "Diff stats — min: -6.2759, max: 10.0914, mean: 1.7633, std: 1.8509\n",
      "\n",
      "Step 6069 — Test metrics:\n",
      "  precision@10: 0.006335888\n",
      "  recall@10: 0.006340292\n",
      "  ndcg@10: 0.006715922\n",
      "  map@10: 0.002134499\n",
      "Epoch 553, Step 10, LR: 0.000080, Current Loss: 0.3799, Avg Loss: 0.3796\n",
      "Diff stats — min: -6.1228, max: 9.2788, mean: 1.7474, std: 1.8306\n",
      "\n",
      "Step 6078 — Test metrics:\n",
      "  precision@10: 0.006269820\n",
      "  recall@10: 0.006274225\n",
      "  ndcg@10: 0.006616822\n",
      "  map@10: 0.002094063\n",
      "Epoch 553 completed, Train Loss: 0.3800\n",
      "Epoch 554, Step 1, LR: 0.000080, Current Loss: 0.3827, Avg Loss: 0.3827\n",
      "Diff stats — min: -5.5720, max: 9.7913, mean: 1.7394, std: 1.8393\n",
      "\n",
      "Step 6080 — Test metrics:\n",
      "  precision@10: 0.006243393\n",
      "  recall@10: 0.006247798\n",
      "  ndcg@10: 0.006591961\n",
      "  map@10: 0.002086722\n",
      "Epoch 554, Step 10, LR: 0.000080, Current Loss: 0.3794, Avg Loss: 0.3793\n",
      "Diff stats — min: -5.7772, max: 9.7392, mean: 1.7613, std: 1.8431\n",
      "\n",
      "Step 6089 — Test metrics:\n",
      "  precision@10: 0.006256607\n",
      "  recall@10: 0.006261011\n",
      "  ndcg@10: 0.006603932\n",
      "  map@10: 0.002092584\n",
      "Epoch 554 completed, Train Loss: 0.3789\n",
      "Epoch 555, Step 1, LR: 0.000080, Current Loss: 0.3785, Avg Loss: 0.3785\n",
      "Diff stats — min: -5.8817, max: 9.6103, mean: 1.7496, std: 1.8273\n",
      "\n",
      "Step 6091 — Test metrics:\n",
      "  precision@10: 0.006263214\n",
      "  recall@10: 0.006267618\n",
      "  ndcg@10: 0.006616228\n",
      "  map@10: 0.002096116\n",
      "Epoch 555, Step 10, LR: 0.000080, Current Loss: 0.3804, Avg Loss: 0.3777\n",
      "Diff stats — min: -5.8799, max: 10.7309, mean: 1.7429, std: 1.8302\n",
      "\n",
      "Step 6100 — Test metrics:\n",
      "  precision@10: 0.006223573\n",
      "  recall@10: 0.006227977\n",
      "  ndcg@10: 0.006588678\n",
      "  map@10: 0.002095289\n",
      "Epoch 555 completed, Train Loss: 0.3779\n",
      "Epoch 556, Step 1, LR: 0.000080, Current Loss: 0.3747, Avg Loss: 0.3747\n",
      "Diff stats — min: -6.3876, max: 9.2608, mean: 1.7606, std: 1.8221\n",
      "\n",
      "Step 6102 — Test metrics:\n",
      "  precision@10: 0.006230180\n",
      "  recall@10: 0.006234584\n",
      "  ndcg@10: 0.006593759\n",
      "  map@10: 0.002096277\n",
      "Epoch 556, Step 10, LR: 0.000080, Current Loss: 0.3781, Avg Loss: 0.3780\n",
      "Diff stats — min: -6.9646, max: 9.9978, mean: 1.7618, std: 1.8418\n",
      "\n",
      "Step 6111 — Test metrics:\n",
      "  precision@10: 0.006216966\n",
      "  recall@10: 0.006221371\n",
      "  ndcg@10: 0.006518942\n",
      "  map@10: 0.002056105\n",
      "Epoch 556 completed, Train Loss: 0.3783\n",
      "Epoch 557, Step 1, LR: 0.000080, Current Loss: 0.3766, Avg Loss: 0.3766\n",
      "Diff stats — min: -5.8387, max: 10.5646, mean: 1.7581, std: 1.8313\n",
      "\n",
      "Step 6113 — Test metrics:\n",
      "  precision@10: 0.006230180\n",
      "  recall@10: 0.006234584\n",
      "  ndcg@10: 0.006539501\n",
      "  map@10: 0.002064851\n",
      "Epoch 557, Step 10, LR: 0.000080, Current Loss: 0.3773, Avg Loss: 0.3783\n",
      "Diff stats — min: -6.3483, max: 9.5982, mean: 1.7669, std: 1.8452\n",
      "\n",
      "Step 6122 — Test metrics:\n",
      "  precision@10: 0.006250000\n",
      "  recall@10: 0.006254405\n",
      "  ndcg@10: 0.006575719\n",
      "  map@10: 0.002076157\n",
      "Epoch 557 completed, Train Loss: 0.3779\n",
      "Epoch 558, Step 1, LR: 0.000080, Current Loss: 0.3786, Avg Loss: 0.3786\n",
      "Diff stats — min: -5.7773, max: 10.2491, mean: 1.7717, std: 1.8516\n",
      "\n",
      "Step 6124 — Test metrics:\n",
      "  precision@10: 0.006269820\n",
      "  recall@10: 0.006274225\n",
      "  ndcg@10: 0.006624043\n",
      "  map@10: 0.002100893\n",
      "Epoch 558, Step 10, LR: 0.000080, Current Loss: 0.3743, Avg Loss: 0.3760\n",
      "Diff stats — min: -5.3731, max: 9.3628, mean: 1.7750, std: 1.8370\n",
      "\n",
      "Step 6133 — Test metrics:\n",
      "  precision@10: 0.006309461\n",
      "  recall@10: 0.006313865\n",
      "  ndcg@10: 0.006678112\n",
      "  map@10: 0.002120929\n",
      "Epoch 558 completed, Train Loss: 0.3761\n",
      "Epoch 559, Step 1, LR: 0.000080, Current Loss: 0.3829, Avg Loss: 0.3829\n",
      "Diff stats — min: -5.7511, max: 9.6403, mean: 1.7487, std: 1.8459\n",
      "\n",
      "Step 6135 — Test metrics:\n",
      "  precision@10: 0.006296247\n",
      "  recall@10: 0.006300652\n",
      "  ndcg@10: 0.006665602\n",
      "  map@10: 0.002121927\n",
      "Epoch 559, Step 10, LR: 0.000080, Current Loss: 0.3773, Avg Loss: 0.3765\n",
      "Diff stats — min: -5.1345, max: 13.3829, mean: 1.7732, std: 1.8537\n",
      "\n",
      "Step 6144 — Test metrics:\n",
      "  precision@10: 0.006342495\n",
      "  recall@10: 0.006346899\n",
      "  ndcg@10: 0.006587260\n",
      "  map@10: 0.002059855\n",
      "Epoch 559 completed, Train Loss: 0.3762\n",
      "Epoch 560, Step 1, LR: 0.000080, Current Loss: 0.3761, Avg Loss: 0.3761\n",
      "Diff stats — min: -5.8754, max: 10.0539, mean: 1.7655, std: 1.8401\n",
      "\n",
      "Step 6146 — Test metrics:\n",
      "  precision@10: 0.006368922\n",
      "  recall@10: 0.006373326\n",
      "  ndcg@10: 0.006620077\n",
      "  map@10: 0.002072737\n",
      "Epoch 560, Step 10, LR: 0.000080, Current Loss: 0.3802, Avg Loss: 0.3774\n",
      "Diff stats — min: -6.4249, max: 9.4110, mean: 1.7663, std: 1.8541\n",
      "\n",
      "Step 6155 — Test metrics:\n",
      "  precision@10: 0.006342495\n",
      "  recall@10: 0.006346899\n",
      "  ndcg@10: 0.006750696\n",
      "  map@10: 0.002158950\n",
      "Epoch 560 completed, Train Loss: 0.3778\n",
      "Epoch 561, Step 1, LR: 0.000080, Current Loss: 0.3769, Avg Loss: 0.3769\n",
      "Diff stats — min: -5.4944, max: 10.4161, mean: 1.7668, std: 1.8415\n",
      "\n",
      "Step 6157 — Test metrics:\n",
      "  precision@10: 0.006342495\n",
      "  recall@10: 0.006346899\n",
      "  ndcg@10: 0.006763298\n",
      "  map@10: 0.002165373\n",
      "Epoch 561, Step 10, LR: 0.000080, Current Loss: 0.3770, Avg Loss: 0.3767\n",
      "Diff stats — min: -6.4986, max: 11.3438, mean: 1.7721, std: 1.8444\n",
      "\n",
      "Step 6166 — Test metrics:\n",
      "  precision@10: 0.006375529\n",
      "  recall@10: 0.006379933\n",
      "  ndcg@10: 0.006748501\n",
      "  map@10: 0.002144103\n",
      "Epoch 561 completed, Train Loss: 0.3766\n",
      "Epoch 562, Step 1, LR: 0.000080, Current Loss: 0.3743, Avg Loss: 0.3743\n",
      "Diff stats — min: -5.6988, max: 10.1762, mean: 1.7825, std: 1.8410\n",
      "\n",
      "Step 6168 — Test metrics:\n",
      "  precision@10: 0.006375529\n",
      "  recall@10: 0.006379933\n",
      "  ndcg@10: 0.006758648\n",
      "  map@10: 0.002149873\n",
      "Epoch 562, Step 10, LR: 0.000080, Current Loss: 0.3731, Avg Loss: 0.3779\n",
      "Diff stats — min: -5.9482, max: 9.9061, mean: 1.7746, std: 1.8321\n",
      "\n",
      "Step 6177 — Test metrics:\n",
      "  precision@10: 0.006322674\n",
      "  recall@10: 0.006327079\n",
      "  ndcg@10: 0.006687515\n",
      "  map@10: 0.002122439\n",
      "Epoch 562 completed, Train Loss: 0.3776\n",
      "Epoch 563, Step 1, LR: 0.000080, Current Loss: 0.3793, Avg Loss: 0.3793\n",
      "Diff stats — min: -6.3055, max: 10.5735, mean: 1.7704, std: 1.8522\n",
      "\n",
      "Step 6179 — Test metrics:\n",
      "  precision@10: 0.006296247\n",
      "  recall@10: 0.006300652\n",
      "  ndcg@10: 0.006669754\n",
      "  map@10: 0.002119547\n",
      "Epoch 563, Step 10, LR: 0.000080, Current Loss: 0.3807, Avg Loss: 0.3767\n",
      "Diff stats — min: -6.3138, max: 10.5295, mean: 1.7670, std: 1.8569\n",
      "\n",
      "Step 6188 — Test metrics:\n",
      "  precision@10: 0.006296247\n",
      "  recall@10: 0.006300652\n",
      "  ndcg@10: 0.006701823\n",
      "  map@10: 0.002140313\n",
      "Epoch 563 completed, Train Loss: 0.3769\n",
      "Epoch 564, Step 1, LR: 0.000080, Current Loss: 0.3764, Avg Loss: 0.3764\n",
      "Diff stats — min: -6.8869, max: 11.2944, mean: 1.7813, std: 1.8518\n",
      "\n",
      "Step 6190 — Test metrics:\n",
      "  precision@10: 0.006322674\n",
      "  recall@10: 0.006327079\n",
      "  ndcg@10: 0.006727705\n",
      "  map@10: 0.002147916\n",
      "Epoch 564, Step 10, LR: 0.000080, Current Loss: 0.3750, Avg Loss: 0.3753\n",
      "Diff stats — min: -5.6986, max: 11.3469, mean: 1.7812, std: 1.8431\n",
      "\n",
      "Step 6199 — Test metrics:\n",
      "  precision@10: 0.006441596\n",
      "  recall@10: 0.006446001\n",
      "  ndcg@10: 0.006792484\n",
      "  map@10: 0.002152855\n",
      "Epoch 564 completed, Train Loss: 0.3752\n",
      "Epoch 565, Step 1, LR: 0.000080, Current Loss: 0.3738, Avg Loss: 0.3738\n",
      "Diff stats — min: -5.9168, max: 10.0519, mean: 1.7884, std: 1.8470\n",
      "\n",
      "Step 6201 — Test metrics:\n",
      "  precision@10: 0.006448203\n",
      "  recall@10: 0.006452607\n",
      "  ndcg@10: 0.006777455\n",
      "  map@10: 0.002142520\n",
      "Epoch 565, Step 10, LR: 0.000080, Current Loss: 0.3727, Avg Loss: 0.3761\n",
      "Diff stats — min: -8.0943, max: 10.3386, mean: 1.7827, std: 1.8403\n",
      "\n",
      "Step 6210 — Test metrics:\n",
      "  precision@10: 0.006296247\n",
      "  recall@10: 0.006300652\n",
      "  ndcg@10: 0.006626972\n",
      "  map@10: 0.002092716\n",
      "Epoch 565 completed, Train Loss: 0.3756\n",
      "Epoch 566, Step 1, LR: 0.000080, Current Loss: 0.3785, Avg Loss: 0.3785\n",
      "Diff stats — min: -5.7792, max: 9.9333, mean: 1.7766, std: 1.8586\n",
      "\n",
      "Step 6212 — Test metrics:\n",
      "  precision@10: 0.006263214\n",
      "  recall@10: 0.006267618\n",
      "  ndcg@10: 0.006610595\n",
      "  map@10: 0.002092745\n",
      "Epoch 566, Step 10, LR: 0.000080, Current Loss: 0.3772, Avg Loss: 0.3764\n",
      "Diff stats — min: -6.1289, max: 10.2917, mean: 1.7822, std: 1.8537\n",
      "\n",
      "Step 6221 — Test metrics:\n",
      "  precision@10: 0.006296247\n",
      "  recall@10: 0.006300652\n",
      "  ndcg@10: 0.006687397\n",
      "  map@10: 0.002128478\n",
      "Epoch 566 completed, Train Loss: 0.3762\n",
      "Epoch 567, Step 1, LR: 0.000080, Current Loss: 0.3745, Avg Loss: 0.3745\n",
      "Diff stats — min: -5.6978, max: 8.8838, mean: 1.8000, std: 1.8613\n",
      "\n",
      "Step 6223 — Test metrics:\n",
      "  precision@10: 0.006302854\n",
      "  recall@10: 0.006307259\n",
      "  ndcg@10: 0.006688806\n",
      "  map@10: 0.002128614\n",
      "Epoch 567, Step 10, LR: 0.000080, Current Loss: 0.3740, Avg Loss: 0.3749\n",
      "Diff stats — min: -6.2973, max: 10.3910, mean: 1.7889, std: 1.8499\n",
      "\n",
      "Step 6232 — Test metrics:\n",
      "  precision@10: 0.006316068\n",
      "  recall@10: 0.006320472\n",
      "  ndcg@10: 0.006716712\n",
      "  map@10: 0.002141550\n",
      "Epoch 567 completed, Train Loss: 0.3749\n",
      "Epoch 568, Step 1, LR: 0.000080, Current Loss: 0.3757, Avg Loss: 0.3757\n",
      "Diff stats — min: -5.8867, max: 9.1225, mean: 1.7830, std: 1.8576\n",
      "\n",
      "Step 6234 — Test metrics:\n",
      "  precision@10: 0.006316068\n",
      "  recall@10: 0.006320472\n",
      "  ndcg@10: 0.006716282\n",
      "  map@10: 0.002140528\n",
      "Epoch 568, Step 10, LR: 0.000080, Current Loss: 0.3789, Avg Loss: 0.3755\n",
      "Diff stats — min: -5.7439, max: 10.9392, mean: 1.7812, std: 1.8630\n",
      "\n",
      "Step 6243 — Test metrics:\n",
      "  precision@10: 0.006408562\n",
      "  recall@10: 0.006412967\n",
      "  ndcg@10: 0.006749251\n",
      "  map@10: 0.002133175\n",
      "Epoch 568 completed, Train Loss: 0.3752\n",
      "Epoch 569, Step 1, LR: 0.000080, Current Loss: 0.3713, Avg Loss: 0.3713\n",
      "Diff stats — min: -6.2161, max: 10.1141, mean: 1.7949, std: 1.8433\n",
      "\n",
      "Step 6245 — Test metrics:\n",
      "  precision@10: 0.006434989\n",
      "  recall@10: 0.006439394\n",
      "  ndcg@10: 0.006778878\n",
      "  map@10: 0.002143571\n",
      "Epoch 569, Step 10, LR: 0.000080, Current Loss: 0.3737, Avg Loss: 0.3746\n",
      "Diff stats — min: -5.3527, max: 10.5573, mean: 1.7993, std: 1.8590\n",
      "\n",
      "Step 6254 — Test metrics:\n",
      "  precision@10: 0.006408562\n",
      "  recall@10: 0.006412967\n",
      "  ndcg@10: 0.006721350\n",
      "  map@10: 0.002116527\n",
      "Epoch 569 completed, Train Loss: 0.3747\n",
      "Epoch 570, Step 1, LR: 0.000080, Current Loss: 0.3730, Avg Loss: 0.3730\n",
      "Diff stats — min: -7.6140, max: 10.8397, mean: 1.7963, std: 1.8569\n",
      "\n",
      "Step 6256 — Test metrics:\n",
      "  precision@10: 0.006401956\n",
      "  recall@10: 0.006406360\n",
      "  ndcg@10: 0.006727062\n",
      "  map@10: 0.002122911\n",
      "Epoch 570, Step 10, LR: 0.000080, Current Loss: 0.3731, Avg Loss: 0.3738\n",
      "Diff stats — min: -6.3351, max: 10.7594, mean: 1.7985, std: 1.8603\n",
      "\n",
      "Step 6265 — Test metrics:\n",
      "  precision@10: 0.006335888\n",
      "  recall@10: 0.006340292\n",
      "  ndcg@10: 0.006716848\n",
      "  map@10: 0.002136246\n",
      "Epoch 570 completed, Train Loss: 0.3740\n",
      "Epoch 571, Step 1, LR: 0.000080, Current Loss: 0.3759, Avg Loss: 0.3759\n",
      "Diff stats — min: -5.6868, max: 9.7263, mean: 1.7841, std: 1.8513\n",
      "\n",
      "Step 6267 — Test metrics:\n",
      "  precision@10: 0.006349101\n",
      "  recall@10: 0.006353506\n",
      "  ndcg@10: 0.006715820\n",
      "  map@10: 0.002129778\n",
      "Epoch 571, Step 10, LR: 0.000080, Current Loss: 0.3750, Avg Loss: 0.3758\n",
      "Diff stats — min: -5.9423, max: 9.3491, mean: 1.8061, std: 1.8716\n",
      "\n",
      "Step 6276 — Test metrics:\n",
      "  precision@10: 0.006322674\n",
      "  recall@10: 0.006327079\n",
      "  ndcg@10: 0.006697780\n",
      "  map@10: 0.002129015\n",
      "Epoch 571 completed, Train Loss: 0.3754\n",
      "Epoch 572, Step 1, LR: 0.000080, Current Loss: 0.3760, Avg Loss: 0.3760\n",
      "Diff stats — min: -5.6952, max: 11.3037, mean: 1.7860, std: 1.8579\n",
      "\n",
      "Step 6278 — Test metrics:\n",
      "  precision@10: 0.006302854\n",
      "  recall@10: 0.006307259\n",
      "  ndcg@10: 0.006684638\n",
      "  map@10: 0.002128787\n",
      "Epoch 572, Step 10, LR: 0.000080, Current Loss: 0.3703, Avg Loss: 0.3739\n",
      "Diff stats — min: -6.6414, max: 9.8036, mean: 1.8155, std: 1.8604\n",
      "\n",
      "Step 6287 — Test metrics:\n",
      "  precision@10: 0.006302854\n",
      "  recall@10: 0.006307259\n",
      "  ndcg@10: 0.006695206\n",
      "  map@10: 0.002132321\n",
      "Epoch 572 completed, Train Loss: 0.3736\n",
      "Epoch 573, Step 1, LR: 0.000080, Current Loss: 0.3758, Avg Loss: 0.3758\n",
      "Diff stats — min: -5.9226, max: 10.5613, mean: 1.7887, std: 1.8602\n",
      "\n",
      "Step 6289 — Test metrics:\n",
      "  precision@10: 0.006276427\n",
      "  recall@10: 0.006280832\n",
      "  ndcg@10: 0.006676547\n",
      "  map@10: 0.002128019\n",
      "Epoch 573, Step 10, LR: 0.000080, Current Loss: 0.3748, Avg Loss: 0.3743\n",
      "Diff stats — min: -6.5874, max: 10.1391, mean: 1.7901, std: 1.8568\n",
      "\n",
      "Step 6298 — Test metrics:\n",
      "  precision@10: 0.006355708\n",
      "  recall@10: 0.006360113\n",
      "  ndcg@10: 0.006764639\n",
      "  map@10: 0.002158646\n",
      "Epoch 573 completed, Train Loss: 0.3743\n",
      "Epoch 574, Step 1, LR: 0.000080, Current Loss: 0.3719, Avg Loss: 0.3719\n",
      "Diff stats — min: -6.2990, max: 9.8023, mean: 1.8143, std: 1.8685\n",
      "\n",
      "Step 6300 — Test metrics:\n",
      "  precision@10: 0.006349101\n",
      "  recall@10: 0.006353506\n",
      "  ndcg@10: 0.006738544\n",
      "  map@10: 0.002146164\n",
      "Epoch 574, Step 10, LR: 0.000080, Current Loss: 0.3733, Avg Loss: 0.3735\n",
      "Diff stats — min: -6.3763, max: 10.5796, mean: 1.8007, std: 1.8615\n",
      "\n",
      "Step 6309 — Test metrics:\n",
      "  precision@10: 0.006395349\n",
      "  recall@10: 0.006399753\n",
      "  ndcg@10: 0.006741974\n",
      "  map@10: 0.002136477\n",
      "Epoch 574 completed, Train Loss: 0.3735\n",
      "Epoch 575, Step 1, LR: 0.000080, Current Loss: 0.3699, Avg Loss: 0.3699\n",
      "Diff stats — min: -6.5481, max: 10.0497, mean: 1.8119, std: 1.8589\n",
      "\n",
      "Step 6311 — Test metrics:\n",
      "  precision@10: 0.006388742\n",
      "  recall@10: 0.006393147\n",
      "  ndcg@10: 0.006736890\n",
      "  map@10: 0.002135072\n",
      "Epoch 575, Step 10, LR: 0.000080, Current Loss: 0.3742, Avg Loss: 0.3725\n",
      "Diff stats — min: -5.7024, max: 9.6929, mean: 1.7999, std: 1.8585\n",
      "\n",
      "Step 6320 — Test metrics:\n",
      "  precision@10: 0.006401956\n",
      "  recall@10: 0.006406360\n",
      "  ndcg@10: 0.006739208\n",
      "  map@10: 0.002128010\n",
      "Epoch 575 completed, Train Loss: 0.3727\n",
      "Epoch 576, Step 1, LR: 0.000080, Current Loss: 0.3732, Avg Loss: 0.3732\n",
      "Diff stats — min: -7.1158, max: 10.8274, mean: 1.8149, std: 1.8730\n",
      "\n",
      "Step 6322 — Test metrics:\n",
      "  precision@10: 0.006415169\n",
      "  recall@10: 0.006419574\n",
      "  ndcg@10: 0.006752261\n",
      "  map@10: 0.002133204\n",
      "Epoch 576, Step 10, LR: 0.000080, Current Loss: 0.3710, Avg Loss: 0.3726\n",
      "Diff stats — min: -5.3503, max: 10.1690, mean: 1.8183, std: 1.8653\n",
      "\n",
      "Step 6331 — Test metrics:\n",
      "  precision@10: 0.006441596\n",
      "  recall@10: 0.006446001\n",
      "  ndcg@10: 0.006801459\n",
      "  map@10: 0.002155025\n",
      "Epoch 576 completed, Train Loss: 0.3727\n",
      "Epoch 577, Step 1, LR: 0.000080, Current Loss: 0.3711, Avg Loss: 0.3711\n",
      "Diff stats — min: -5.8855, max: 9.2266, mean: 1.8193, std: 1.8685\n",
      "\n",
      "Step 6333 — Test metrics:\n",
      "  precision@10: 0.006428383\n",
      "  recall@10: 0.006432787\n",
      "  ndcg@10: 0.006802810\n",
      "  map@10: 0.002160335\n",
      "Epoch 577, Step 10, LR: 0.000080, Current Loss: 0.3766, Avg Loss: 0.3708\n",
      "Diff stats — min: -5.6809, max: 12.4490, mean: 1.8033, std: 1.8781\n",
      "\n",
      "Step 6342 — Test metrics:\n",
      "  precision@10: 0.006408562\n",
      "  recall@10: 0.006412967\n",
      "  ndcg@10: 0.006789781\n",
      "  map@10: 0.002158583\n",
      "Epoch 577 completed, Train Loss: 0.3705\n",
      "Epoch 578, Step 1, LR: 0.000080, Current Loss: 0.3744, Avg Loss: 0.3744\n",
      "Diff stats — min: -5.8011, max: 10.7001, mean: 1.8024, std: 1.8620\n",
      "\n",
      "Step 6344 — Test metrics:\n",
      "  precision@10: 0.006382135\n",
      "  recall@10: 0.006386540\n",
      "  ndcg@10: 0.006760162\n",
      "  map@10: 0.002148434\n",
      "Epoch 578, Step 10, LR: 0.000080, Current Loss: 0.3636, Avg Loss: 0.3709\n",
      "Diff stats — min: -5.6407, max: 10.4324, mean: 1.8286, std: 1.8465\n",
      "\n",
      "Step 6353 — Test metrics:\n",
      "  precision@10: 0.006342495\n",
      "  recall@10: 0.006346899\n",
      "  ndcg@10: 0.006686742\n",
      "  map@10: 0.002114346\n",
      "Epoch 578 completed, Train Loss: 0.3715\n",
      "Epoch 579, Step 1, LR: 0.000080, Current Loss: 0.3769, Avg Loss: 0.3769\n",
      "Diff stats — min: -5.9768, max: 10.1909, mean: 1.7984, std: 1.8701\n",
      "\n",
      "Step 6355 — Test metrics:\n",
      "  precision@10: 0.006355708\n",
      "  recall@10: 0.006360113\n",
      "  ndcg@10: 0.006705256\n",
      "  map@10: 0.002121512\n",
      "Epoch 579, Step 10, LR: 0.000080, Current Loss: 0.3754, Avg Loss: 0.3717\n",
      "Diff stats — min: -6.1673, max: 9.6605, mean: 1.8201, std: 1.8862\n",
      "\n",
      "Step 6364 — Test metrics:\n",
      "  precision@10: 0.006401956\n",
      "  recall@10: 0.006406360\n",
      "  ndcg@10: 0.006784180\n",
      "  map@10: 0.002158137\n",
      "Epoch 579 completed, Train Loss: 0.3717\n",
      "Epoch 580, Step 1, LR: 0.000080, Current Loss: 0.3798, Avg Loss: 0.3798\n",
      "Diff stats — min: -5.8650, max: 10.1430, mean: 1.8058, std: 1.8917\n",
      "\n",
      "Step 6366 — Test metrics:\n",
      "  precision@10: 0.006441596\n",
      "  recall@10: 0.006446001\n",
      "  ndcg@10: 0.006817444\n",
      "  map@10: 0.002168888\n",
      "Epoch 580, Step 10, LR: 0.000080, Current Loss: 0.3671, Avg Loss: 0.3700\n",
      "Diff stats — min: -5.9056, max: 9.5622, mean: 1.8433, std: 1.8746\n",
      "\n",
      "Step 6375 — Test metrics:\n",
      "  precision@10: 0.006415169\n",
      "  recall@10: 0.006419574\n",
      "  ndcg@10: 0.006767395\n",
      "  map@10: 0.002142827\n",
      "Epoch 580 completed, Train Loss: 0.3703\n",
      "Epoch 581, Step 1, LR: 0.000080, Current Loss: 0.3701, Avg Loss: 0.3701\n",
      "Diff stats — min: -5.4187, max: 10.0565, mean: 1.8190, std: 1.8663\n",
      "\n",
      "Step 6377 — Test metrics:\n",
      "  precision@10: 0.006421776\n",
      "  recall@10: 0.006426180\n",
      "  ndcg@10: 0.006774684\n",
      "  map@10: 0.002146599\n",
      "Epoch 581, Step 10, LR: 0.000080, Current Loss: 0.3691, Avg Loss: 0.3704\n",
      "Diff stats — min: -5.8572, max: 9.4613, mean: 1.8387, std: 1.8786\n",
      "\n",
      "Step 6386 — Test metrics:\n",
      "  precision@10: 0.006415169\n",
      "  recall@10: 0.006419574\n",
      "  ndcg@10: 0.006734125\n",
      "  map@10: 0.002124385\n",
      "Epoch 581 completed, Train Loss: 0.3700\n",
      "Epoch 582, Step 1, LR: 0.000080, Current Loss: 0.3693, Avg Loss: 0.3693\n",
      "Diff stats — min: -6.5460, max: 10.2035, mean: 1.8268, std: 1.8692\n",
      "\n",
      "Step 6388 — Test metrics:\n",
      "  precision@10: 0.006408562\n",
      "  recall@10: 0.006412967\n",
      "  ndcg@10: 0.006727331\n",
      "  map@10: 0.002120956\n",
      "Epoch 582, Step 10, LR: 0.000080, Current Loss: 0.3652, Avg Loss: 0.3696\n",
      "Diff stats — min: -6.1344, max: 10.1310, mean: 1.8408, std: 1.8674\n",
      "\n",
      "Step 6397 — Test metrics:\n",
      "  precision@10: 0.006441596\n",
      "  recall@10: 0.006446001\n",
      "  ndcg@10: 0.006761988\n",
      "  map@10: 0.002131569\n",
      "Epoch 582 completed, Train Loss: 0.3699\n",
      "Epoch 583, Step 1, LR: 0.000080, Current Loss: 0.3706, Avg Loss: 0.3706\n",
      "Diff stats — min: -5.4985, max: 11.4145, mean: 1.8270, std: 1.8763\n",
      "\n",
      "Step 6399 — Test metrics:\n",
      "  precision@10: 0.006448203\n",
      "  recall@10: 0.006452607\n",
      "  ndcg@10: 0.006760900\n",
      "  map@10: 0.002127513\n",
      "Epoch 583, Step 10, LR: 0.000080, Current Loss: 0.3712, Avg Loss: 0.3701\n",
      "Diff stats — min: -6.8055, max: 11.2115, mean: 1.8178, std: 1.8693\n",
      "\n",
      "Step 6408 — Test metrics:\n",
      "  precision@10: 0.006461416\n",
      "  recall@10: 0.006465821\n",
      "  ndcg@10: 0.006805958\n",
      "  map@10: 0.002151569\n",
      "Epoch 583 completed, Train Loss: 0.3699\n",
      "Epoch 584, Step 1, LR: 0.000080, Current Loss: 0.3618, Avg Loss: 0.3618\n",
      "Diff stats — min: -6.6124, max: 10.3661, mean: 1.8508, std: 1.8610\n",
      "\n",
      "Step 6410 — Test metrics:\n",
      "  precision@10: 0.006454810\n",
      "  recall@10: 0.006459214\n",
      "  ndcg@10: 0.006802701\n",
      "  map@10: 0.002151716\n",
      "Epoch 584, Step 10, LR: 0.000080, Current Loss: 0.3688, Avg Loss: 0.3690\n",
      "Diff stats — min: -6.7976, max: 10.0820, mean: 1.8267, std: 1.8631\n",
      "\n",
      "Step 6419 — Test metrics:\n",
      "  precision@10: 0.006461416\n",
      "  recall@10: 0.006465821\n",
      "  ndcg@10: 0.006861418\n",
      "  map@10: 0.002185689\n",
      "Epoch 584 completed, Train Loss: 0.3695\n",
      "Epoch 585, Step 1, LR: 0.000080, Current Loss: 0.3701, Avg Loss: 0.3701\n",
      "Diff stats — min: -5.6498, max: 9.5293, mean: 1.8223, std: 1.8696\n",
      "\n",
      "Step 6421 — Test metrics:\n",
      "  precision@10: 0.006454810\n",
      "  recall@10: 0.006459214\n",
      "  ndcg@10: 0.006864084\n",
      "  map@10: 0.002188633\n",
      "Epoch 585, Step 10, LR: 0.000080, Current Loss: 0.3678, Avg Loss: 0.3694\n",
      "Diff stats — min: -5.4271, max: 9.8340, mean: 1.8255, std: 1.8624\n",
      "\n",
      "Step 6430 — Test metrics:\n",
      "  precision@10: 0.006401956\n",
      "  recall@10: 0.006406360\n",
      "  ndcg@10: 0.006764608\n",
      "  map@10: 0.002143608\n",
      "Epoch 585 completed, Train Loss: 0.3696\n",
      "Epoch 586, Step 1, LR: 0.000080, Current Loss: 0.3691, Avg Loss: 0.3691\n",
      "Diff stats — min: -5.7326, max: 9.0872, mean: 1.8264, std: 1.8697\n",
      "\n",
      "Step 6432 — Test metrics:\n",
      "  precision@10: 0.006434989\n",
      "  recall@10: 0.006439394\n",
      "  ndcg@10: 0.006786618\n",
      "  map@10: 0.002147103\n",
      "Epoch 586, Step 10, LR: 0.000080, Current Loss: 0.3636, Avg Loss: 0.3676\n",
      "Diff stats — min: -5.6409, max: 9.6340, mean: 1.8503, std: 1.8651\n",
      "\n",
      "Step 6441 — Test metrics:\n",
      "  precision@10: 0.006468023\n",
      "  recall@10: 0.006472428\n",
      "  ndcg@10: 0.006830260\n",
      "  map@10: 0.002166508\n",
      "Epoch 586 completed, Train Loss: 0.3678\n",
      "Epoch 587, Step 1, LR: 0.000080, Current Loss: 0.3740, Avg Loss: 0.3740\n",
      "Diff stats — min: -10.1090, max: 11.0919, mean: 1.8212, std: 1.8861\n",
      "\n",
      "Step 6443 — Test metrics:\n",
      "  precision@10: 0.006434989\n",
      "  recall@10: 0.006439394\n",
      "  ndcg@10: 0.006799983\n",
      "  map@10: 0.002157657\n",
      "Epoch 587, Step 10, LR: 0.000080, Current Loss: 0.3685, Avg Loss: 0.3688\n",
      "Diff stats — min: -6.7096, max: 11.1165, mean: 1.8355, std: 1.8760\n",
      "\n",
      "Step 6452 — Test metrics:\n",
      "  precision@10: 0.006434989\n",
      "  recall@10: 0.006439394\n",
      "  ndcg@10: 0.006770956\n",
      "  map@10: 0.002140716\n",
      "Epoch 587 completed, Train Loss: 0.3683\n",
      "Epoch 588, Step 1, LR: 0.000080, Current Loss: 0.3700, Avg Loss: 0.3700\n",
      "Diff stats — min: -5.7068, max: 11.2176, mean: 1.8327, std: 1.8793\n",
      "\n",
      "Step 6454 — Test metrics:\n",
      "  precision@10: 0.006434989\n",
      "  recall@10: 0.006439394\n",
      "  ndcg@10: 0.006786062\n",
      "  map@10: 0.002147915\n",
      "Epoch 588, Step 10, LR: 0.000080, Current Loss: 0.3677, Avg Loss: 0.3696\n",
      "Diff stats — min: -6.2343, max: 11.2267, mean: 1.8410, std: 1.8788\n",
      "\n",
      "Step 6463 — Test metrics:\n",
      "  precision@10: 0.006487844\n",
      "  recall@10: 0.006492248\n",
      "  ndcg@10: 0.006867783\n",
      "  map@10: 0.002182564\n",
      "Epoch 588 completed, Train Loss: 0.3694\n",
      "Epoch 589, Step 1, LR: 0.000080, Current Loss: 0.3654, Avg Loss: 0.3654\n",
      "Diff stats — min: -5.7945, max: 10.3489, mean: 1.8577, std: 1.8877\n",
      "\n",
      "Step 6465 — Test metrics:\n",
      "  precision@10: 0.006474630\n",
      "  recall@10: 0.006479035\n",
      "  ndcg@10: 0.006853529\n",
      "  map@10: 0.002178068\n",
      "Epoch 589, Step 10, LR: 0.000080, Current Loss: 0.3676, Avg Loss: 0.3689\n",
      "Diff stats — min: -5.6381, max: 12.8942, mean: 1.8477, std: 1.8877\n",
      "\n",
      "Step 6474 — Test metrics:\n",
      "  precision@10: 0.006441596\n",
      "  recall@10: 0.006446001\n",
      "  ndcg@10: 0.006808483\n",
      "  map@10: 0.002159016\n",
      "Epoch 589 completed, Train Loss: 0.3684\n",
      "Epoch 590, Step 1, LR: 0.000080, Current Loss: 0.3596, Avg Loss: 0.3596\n",
      "Diff stats — min: -5.7257, max: 10.5475, mean: 1.8709, std: 1.8726\n",
      "\n",
      "Step 6476 — Test metrics:\n",
      "  precision@10: 0.006434989\n",
      "  recall@10: 0.006439394\n",
      "  ndcg@10: 0.006798126\n",
      "  map@10: 0.002154517\n",
      "Epoch 590, Step 10, LR: 0.000080, Current Loss: 0.3743, Avg Loss: 0.3665\n",
      "Diff stats — min: -6.4416, max: 10.4276, mean: 1.8238, std: 1.8881\n",
      "\n",
      "Step 6485 — Test metrics:\n",
      "  precision@10: 0.006408562\n",
      "  recall@10: 0.006412967\n",
      "  ndcg@10: 0.006784103\n",
      "  map@10: 0.002156003\n",
      "Epoch 590 completed, Train Loss: 0.3667\n",
      "Epoch 591, Step 1, LR: 0.000080, Current Loss: 0.3695, Avg Loss: 0.3695\n",
      "Diff stats — min: -5.6688, max: 10.5879, mean: 1.8514, std: 1.8991\n",
      "\n",
      "Step 6487 — Test metrics:\n",
      "  precision@10: 0.006448203\n",
      "  recall@10: 0.006452607\n",
      "  ndcg@10: 0.006817099\n",
      "  map@10: 0.002164814\n",
      "Epoch 591, Step 10, LR: 0.000080, Current Loss: 0.3681, Avg Loss: 0.3696\n",
      "Diff stats — min: -6.0507, max: 11.8419, mean: 1.8400, std: 1.8810\n",
      "\n",
      "Step 6496 — Test metrics:\n",
      "  precision@10: 0.006474630\n",
      "  recall@10: 0.006479035\n",
      "  ndcg@10: 0.006847888\n",
      "  map@10: 0.002174166\n",
      "Epoch 591 completed, Train Loss: 0.3696\n",
      "Epoch 592, Step 1, LR: 0.000080, Current Loss: 0.3634, Avg Loss: 0.3634\n",
      "Diff stats — min: -6.0636, max: 10.2016, mean: 1.8686, std: 1.8870\n",
      "\n",
      "Step 6498 — Test metrics:\n",
      "  precision@10: 0.006494450\n",
      "  recall@10: 0.006498855\n",
      "  ndcg@10: 0.006846491\n",
      "  map@10: 0.002167368\n",
      "Epoch 592, Step 10, LR: 0.000080, Current Loss: 0.3651, Avg Loss: 0.3678\n",
      "Diff stats — min: -7.7072, max: 10.7353, mean: 1.8582, std: 1.8866\n",
      "\n",
      "Step 6507 — Test metrics:\n",
      "  precision@10: 0.006448203\n",
      "  recall@10: 0.006452607\n",
      "  ndcg@10: 0.006776548\n",
      "  map@10: 0.002139433\n",
      "Epoch 592 completed, Train Loss: 0.3679\n",
      "Epoch 593, Step 1, LR: 0.000080, Current Loss: 0.3663, Avg Loss: 0.3663\n",
      "Diff stats — min: -5.8105, max: 10.6030, mean: 1.8496, std: 1.8812\n",
      "\n",
      "Step 6509 — Test metrics:\n",
      "  precision@10: 0.006448203\n",
      "  recall@10: 0.006452607\n",
      "  ndcg@10: 0.006768796\n",
      "  map@10: 0.002136886\n",
      "Epoch 593, Step 10, LR: 0.000080, Current Loss: 0.3658, Avg Loss: 0.3672\n",
      "Diff stats — min: -7.6723, max: 12.1067, mean: 1.8685, std: 1.8982\n",
      "\n",
      "Step 6518 — Test metrics:\n",
      "  precision@10: 0.006428383\n",
      "  recall@10: 0.006432787\n",
      "  ndcg@10: 0.006799166\n",
      "  map@10: 0.002160028\n",
      "Epoch 593 completed, Train Loss: 0.3673\n",
      "Epoch 594, Step 1, LR: 0.000080, Current Loss: 0.3704, Avg Loss: 0.3704\n",
      "Diff stats — min: -5.4501, max: 9.9410, mean: 1.8417, std: 1.8881\n",
      "\n",
      "Step 6520 — Test metrics:\n",
      "  precision@10: 0.006441596\n",
      "  recall@10: 0.006446001\n",
      "  ndcg@10: 0.006815773\n",
      "  map@10: 0.002166045\n",
      "Epoch 594, Step 10, LR: 0.000080, Current Loss: 0.3708, Avg Loss: 0.3678\n",
      "Diff stats — min: -6.4580, max: 10.6436, mean: 1.8403, std: 1.8926\n",
      "\n",
      "Step 6529 — Test metrics:\n",
      "  precision@10: 0.006468023\n",
      "  recall@10: 0.006472428\n",
      "  ndcg@10: 0.006824483\n",
      "  map@10: 0.002162597\n",
      "Epoch 594 completed, Train Loss: 0.3672\n",
      "Epoch 595, Step 1, LR: 0.000080, Current Loss: 0.3649, Avg Loss: 0.3649\n",
      "Diff stats — min: -5.6900, max: 10.8965, mean: 1.8642, std: 1.8906\n",
      "\n",
      "Step 6531 — Test metrics:\n",
      "  precision@10: 0.006454810\n",
      "  recall@10: 0.006459214\n",
      "  ndcg@10: 0.006810862\n",
      "  map@10: 0.002158088\n",
      "Epoch 595, Step 10, LR: 0.000080, Current Loss: 0.3689, Avg Loss: 0.3670\n",
      "Diff stats — min: -5.2702, max: 9.1614, mean: 1.8571, std: 1.9013\n",
      "\n",
      "Step 6540 — Test metrics:\n",
      "  precision@10: 0.006520877\n",
      "  recall@10: 0.006525282\n",
      "  ndcg@10: 0.006891843\n",
      "  map@10: 0.002187969\n",
      "Epoch 595 completed, Train Loss: 0.3668\n",
      "Epoch 596, Step 1, LR: 0.000080, Current Loss: 0.3663, Avg Loss: 0.3663\n",
      "Diff stats — min: -6.2005, max: 10.7818, mean: 1.8676, std: 1.9003\n",
      "\n",
      "Step 6542 — Test metrics:\n",
      "  precision@10: 0.006487844\n",
      "  recall@10: 0.006492248\n",
      "  ndcg@10: 0.006867752\n",
      "  map@10: 0.002182645\n",
      "Epoch 596, Step 10, LR: 0.000080, Current Loss: 0.3674, Avg Loss: 0.3663\n",
      "Diff stats — min: -5.4527, max: 9.6936, mean: 1.8602, std: 1.8994\n",
      "\n",
      "Step 6551 — Test metrics:\n",
      "  precision@10: 0.006454810\n",
      "  recall@10: 0.006459214\n",
      "  ndcg@10: 0.006814331\n",
      "  map@10: 0.002162305\n",
      "Epoch 596 completed, Train Loss: 0.3664\n",
      "Epoch 597, Step 1, LR: 0.000080, Current Loss: 0.3735, Avg Loss: 0.3735\n",
      "Diff stats — min: -5.6157, max: 9.9512, mean: 1.8501, std: 1.9064\n",
      "\n",
      "Step 6553 — Test metrics:\n",
      "  precision@10: 0.006448203\n",
      "  recall@10: 0.006452607\n",
      "  ndcg@10: 0.006807159\n",
      "  map@10: 0.002160056\n",
      "Epoch 597, Step 10, LR: 0.000080, Current Loss: 0.3675, Avg Loss: 0.3658\n",
      "Diff stats — min: -6.9541, max: 11.3808, mean: 1.8540, std: 1.8923\n",
      "\n",
      "Step 6562 — Test metrics:\n",
      "  precision@10: 0.006415169\n",
      "  recall@10: 0.006419574\n",
      "  ndcg@10: 0.006799793\n",
      "  map@10: 0.002166733\n",
      "Epoch 597 completed, Train Loss: 0.3660\n",
      "Epoch 598, Step 1, LR: 0.000080, Current Loss: 0.3671, Avg Loss: 0.3671\n",
      "Diff stats — min: -6.4474, max: 10.4599, mean: 1.8638, std: 1.9017\n",
      "\n",
      "Step 6564 — Test metrics:\n",
      "  precision@10: 0.006395349\n",
      "  recall@10: 0.006399753\n",
      "  ndcg@10: 0.006800856\n",
      "  map@10: 0.002172729\n",
      "Epoch 598, Step 10, LR: 0.000080, Current Loss: 0.3679, Avg Loss: 0.3653\n",
      "Diff stats — min: -7.3810, max: 9.4280, mean: 1.8666, std: 1.9027\n",
      "\n",
      "Step 6573 — Test metrics:\n",
      "  precision@10: 0.006520877\n",
      "  recall@10: 0.006525282\n",
      "  ndcg@10: 0.006925264\n",
      "  map@10: 0.002210477\n",
      "Epoch 598 completed, Train Loss: 0.3648\n",
      "Epoch 599, Step 1, LR: 0.000080, Current Loss: 0.3684, Avg Loss: 0.3684\n",
      "Diff stats — min: -6.3554, max: 12.1130, mean: 1.8565, std: 1.8955\n",
      "\n",
      "Step 6575 — Test metrics:\n",
      "  precision@10: 0.006540698\n",
      "  recall@10: 0.006545102\n",
      "  ndcg@10: 0.006949803\n",
      "  map@10: 0.002218287\n",
      "Epoch 599, Step 10, LR: 0.000080, Current Loss: 0.3601, Avg Loss: 0.3659\n",
      "Diff stats — min: -5.8055, max: 15.7592, mean: 1.8806, std: 1.8826\n",
      "\n",
      "Step 6584 — Test metrics:\n",
      "  precision@10: 0.006507664\n",
      "  recall@10: 0.006512068\n",
      "  ndcg@10: 0.006905966\n",
      "  map@10: 0.002199248\n",
      "Epoch 599 completed, Train Loss: 0.3658\n",
      "Epoch 600, Step 1, LR: 0.000080, Current Loss: 0.3600, Avg Loss: 0.3600\n",
      "Diff stats — min: -5.1805, max: 10.0756, mean: 1.8749, std: 1.8796\n",
      "\n",
      "Step 6586 — Test metrics:\n",
      "  precision@10: 0.006494450\n",
      "  recall@10: 0.006498855\n",
      "  ndcg@10: 0.006905685\n",
      "  map@10: 0.002202142\n",
      "Epoch 600, Step 10, LR: 0.000080, Current Loss: 0.3648, Avg Loss: 0.3654\n",
      "Diff stats — min: -6.5657, max: 10.2580, mean: 1.8567, std: 1.8848\n",
      "\n",
      "Step 6595 — Test metrics:\n",
      "  precision@10: 0.006534091\n",
      "  recall@10: 0.006538495\n",
      "  ndcg@10: 0.006921303\n",
      "  map@10: 0.002202677\n",
      "Epoch 600 completed, Train Loss: 0.3655\n",
      "Epoch 601, Step 1, LR: 0.000080, Current Loss: 0.3678, Avg Loss: 0.3678\n",
      "Diff stats — min: -6.1029, max: 10.6320, mean: 1.8564, std: 1.8977\n",
      "\n",
      "Step 6597 — Test metrics:\n",
      "  precision@10: 0.006547304\n",
      "  recall@10: 0.006551709\n",
      "  ndcg@10: 0.006920006\n",
      "  map@10: 0.002198732\n",
      "Epoch 601, Step 10, LR: 0.000080, Current Loss: 0.3668, Avg Loss: 0.3653\n",
      "Diff stats — min: -6.8304, max: 9.3758, mean: 1.8557, std: 1.8863\n",
      "\n",
      "Step 6606 — Test metrics:\n",
      "  precision@10: 0.006507664\n",
      "  recall@10: 0.006512068\n",
      "  ndcg@10: 0.006901428\n",
      "  map@10: 0.002199350\n",
      "Epoch 601 completed, Train Loss: 0.3654\n",
      "Epoch 602, Step 1, LR: 0.000080, Current Loss: 0.3737, Avg Loss: 0.3737\n",
      "Diff stats — min: -6.5832, max: 10.0101, mean: 1.8468, std: 1.9061\n",
      "\n",
      "Step 6608 — Test metrics:\n",
      "  precision@10: 0.006507664\n",
      "  recall@10: 0.006512068\n",
      "  ndcg@10: 0.006900644\n",
      "  map@10: 0.002197557\n",
      "Epoch 602, Step 10, LR: 0.000080, Current Loss: 0.3636, Avg Loss: 0.3664\n",
      "Diff stats — min: -6.1475, max: 10.6824, mean: 1.8833, std: 1.9032\n",
      "\n",
      "Step 6617 — Test metrics:\n",
      "  precision@10: 0.006487844\n",
      "  recall@10: 0.006492248\n",
      "  ndcg@10: 0.006846037\n",
      "  map@10: 0.002172020\n",
      "Epoch 602 completed, Train Loss: 0.3657\n",
      "Epoch 603, Step 1, LR: 0.000080, Current Loss: 0.3656, Avg Loss: 0.3656\n",
      "Diff stats — min: -6.8529, max: 10.1807, mean: 1.8624, std: 1.8918\n",
      "\n",
      "Step 6619 — Test metrics:\n",
      "  precision@10: 0.006448203\n",
      "  recall@10: 0.006452607\n",
      "  ndcg@10: 0.006819634\n",
      "  map@10: 0.002166858\n",
      "Epoch 603, Step 10, LR: 0.000080, Current Loss: 0.3611, Avg Loss: 0.3637\n",
      "Diff stats — min: -5.9406, max: 11.3897, mean: 1.8798, std: 1.8908\n",
      "\n",
      "Step 6628 — Test metrics:\n",
      "  precision@10: 0.006507664\n",
      "  recall@10: 0.006512068\n",
      "  ndcg@10: 0.006874245\n",
      "  map@10: 0.002180555\n",
      "Epoch 603 completed, Train Loss: 0.3639\n",
      "Epoch 604, Step 1, LR: 0.000080, Current Loss: 0.3608, Avg Loss: 0.3608\n",
      "Diff stats — min: -6.4146, max: 10.0561, mean: 1.8919, std: 1.8998\n",
      "\n",
      "Step 6630 — Test metrics:\n",
      "  precision@10: 0.006501057\n",
      "  recall@10: 0.006505462\n",
      "  ndcg@10: 0.006876602\n",
      "  map@10: 0.002183840\n",
      "Epoch 604, Step 10, LR: 0.000080, Current Loss: 0.3671, Avg Loss: 0.3644\n",
      "Diff stats — min: -5.6602, max: 10.1409, mean: 1.8768, std: 1.9123\n",
      "\n",
      "Step 6639 — Test metrics:\n",
      "  precision@10: 0.006540698\n",
      "  recall@10: 0.006545102\n",
      "  ndcg@10: 0.006971659\n",
      "  map@10: 0.002232144\n",
      "Epoch 604 completed, Train Loss: 0.3647\n",
      "Epoch 605, Step 1, LR: 0.000080, Current Loss: 0.3682, Avg Loss: 0.3682\n",
      "Diff stats — min: -5.7576, max: 10.9096, mean: 1.8734, std: 1.9140\n",
      "\n",
      "Step 6641 — Test metrics:\n",
      "  precision@10: 0.006520877\n",
      "  recall@10: 0.006525282\n",
      "  ndcg@10: 0.006973593\n",
      "  map@10: 0.002237807\n",
      "Epoch 605, Step 10, LR: 0.000080, Current Loss: 0.3651, Avg Loss: 0.3640\n",
      "Diff stats — min: -7.2835, max: 11.8648, mean: 1.8819, std: 1.9091\n",
      "\n",
      "Step 6650 — Test metrics:\n",
      "  precision@10: 0.006540698\n",
      "  recall@10: 0.006545102\n",
      "  ndcg@10: 0.006947218\n",
      "  map@10: 0.002213143\n",
      "Epoch 605 completed, Train Loss: 0.3639\n",
      "Epoch 606, Step 1, LR: 0.000080, Current Loss: 0.3663, Avg Loss: 0.3663\n",
      "Diff stats — min: -5.8640, max: 11.5025, mean: 1.8736, std: 1.9032\n",
      "\n",
      "Step 6652 — Test metrics:\n",
      "  precision@10: 0.006573732\n",
      "  recall@10: 0.006578136\n",
      "  ndcg@10: 0.006955582\n",
      "  map@10: 0.002211094\n",
      "Epoch 606, Step 10, LR: 0.000080, Current Loss: 0.3649, Avg Loss: 0.3643\n",
      "Diff stats — min: -6.4305, max: 10.0924, mean: 1.8820, std: 1.9053\n",
      "\n",
      "Step 6661 — Test metrics:\n",
      "  precision@10: 0.006507664\n",
      "  recall@10: 0.006512068\n",
      "  ndcg@10: 0.006942312\n",
      "  map@10: 0.002224740\n",
      "Epoch 606 completed, Train Loss: 0.3642\n",
      "Epoch 607, Step 1, LR: 0.000080, Current Loss: 0.3656, Avg Loss: 0.3656\n",
      "Diff stats — min: -5.6669, max: 10.9129, mean: 1.8703, std: 1.8995\n",
      "\n",
      "Step 6663 — Test metrics:\n",
      "  precision@10: 0.006520877\n",
      "  recall@10: 0.006525282\n",
      "  ndcg@10: 0.006944514\n",
      "  map@10: 0.002223099\n",
      "Epoch 607, Step 10, LR: 0.000080, Current Loss: 0.3628, Avg Loss: 0.3640\n",
      "Diff stats — min: -5.7570, max: 10.7883, mean: 1.8868, std: 1.9029\n",
      "\n",
      "Step 6672 — Test metrics:\n",
      "  precision@10: 0.006520877\n",
      "  recall@10: 0.006525282\n",
      "  ndcg@10: 0.006923295\n",
      "  map@10: 0.002211051\n",
      "Epoch 607 completed, Train Loss: 0.3639\n",
      "Epoch 608, Step 1, LR: 0.000080, Current Loss: 0.3635, Avg Loss: 0.3635\n",
      "Diff stats — min: -5.9459, max: 10.2881, mean: 1.8903, std: 1.9096\n",
      "\n",
      "Step 6674 — Test metrics:\n",
      "  precision@10: 0.006547304\n",
      "  recall@10: 0.006551709\n",
      "  ndcg@10: 0.006913660\n",
      "  map@10: 0.002196846\n",
      "Epoch 608, Step 10, LR: 0.000080, Current Loss: 0.3637, Avg Loss: 0.3629\n",
      "Diff stats — min: -5.9703, max: 10.7514, mean: 1.8888, std: 1.9090\n",
      "\n",
      "Step 6683 — Test metrics:\n",
      "  precision@10: 0.006593552\n",
      "  recall@10: 0.006597956\n",
      "  ndcg@10: 0.006923324\n",
      "  map@10: 0.002187276\n",
      "Epoch 608 completed, Train Loss: 0.3630\n",
      "Epoch 609, Step 1, LR: 0.000080, Current Loss: 0.3638, Avg Loss: 0.3638\n",
      "Diff stats — min: -5.5745, max: 10.0435, mean: 1.8961, std: 1.9153\n",
      "\n",
      "Step 6685 — Test metrics:\n",
      "  precision@10: 0.006613372\n",
      "  recall@10: 0.006617777\n",
      "  ndcg@10: 0.006929930\n",
      "  map@10: 0.002185059\n",
      "Epoch 609, Step 10, LR: 0.000080, Current Loss: 0.3605, Avg Loss: 0.3623\n",
      "Diff stats — min: -5.8241, max: 10.1671, mean: 1.8958, std: 1.9028\n",
      "\n",
      "Step 6694 — Test metrics:\n",
      "  precision@10: 0.006553911\n",
      "  recall@10: 0.006558316\n",
      "  ndcg@10: 0.006944089\n",
      "  map@10: 0.002209385\n",
      "Epoch 609 completed, Train Loss: 0.3623\n",
      "Epoch 610, Step 1, LR: 0.000080, Current Loss: 0.3648, Avg Loss: 0.3648\n",
      "Diff stats — min: -6.2485, max: 10.1650, mean: 1.8924, std: 1.9131\n",
      "\n",
      "Step 6696 — Test metrics:\n",
      "  precision@10: 0.006527484\n",
      "  recall@10: 0.006531889\n",
      "  ndcg@10: 0.006947547\n",
      "  map@10: 0.002220414\n",
      "Epoch 610, Step 10, LR: 0.000080, Current Loss: 0.3596, Avg Loss: 0.3614\n",
      "Diff stats — min: -5.6551, max: 9.6798, mean: 1.9076, std: 1.9109\n",
      "\n",
      "Step 6705 — Test metrics:\n",
      "  precision@10: 0.006534091\n",
      "  recall@10: 0.006538495\n",
      "  ndcg@10: 0.006936679\n",
      "  map@10: 0.002214964\n",
      "Epoch 610 completed, Train Loss: 0.3614\n",
      "Epoch 611, Step 1, LR: 0.000080, Current Loss: 0.3644, Avg Loss: 0.3644\n",
      "Diff stats — min: -6.0478, max: 10.3269, mean: 1.8806, std: 1.9020\n",
      "\n",
      "Step 6707 — Test metrics:\n",
      "  precision@10: 0.006474630\n",
      "  recall@10: 0.006479035\n",
      "  ndcg@10: 0.006890254\n",
      "  map@10: 0.002204275\n",
      "Epoch 611, Step 10, LR: 0.000080, Current Loss: 0.3626, Avg Loss: 0.3621\n",
      "Diff stats — min: -6.3778, max: 12.2753, mean: 1.8928, std: 1.9073\n",
      "\n",
      "Step 6716 — Test metrics:\n",
      "  precision@10: 0.006553911\n",
      "  recall@10: 0.006558316\n",
      "  ndcg@10: 0.006961595\n",
      "  map@10: 0.002222184\n",
      "Epoch 611 completed, Train Loss: 0.3619\n",
      "Epoch 612, Step 1, LR: 0.000080, Current Loss: 0.3709, Avg Loss: 0.3709\n",
      "Diff stats — min: -5.9357, max: 10.9754, mean: 1.8750, std: 1.9245\n",
      "\n",
      "Step 6718 — Test metrics:\n",
      "  precision@10: 0.006540698\n",
      "  recall@10: 0.006545102\n",
      "  ndcg@10: 0.006967158\n",
      "  map@10: 0.002228565\n",
      "Epoch 612, Step 10, LR: 0.000080, Current Loss: 0.3655, Avg Loss: 0.3627\n",
      "Diff stats — min: -6.1632, max: 11.1944, mean: 1.8857, std: 1.9169\n",
      "\n",
      "Step 6727 — Test metrics:\n",
      "  precision@10: 0.006520877\n",
      "  recall@10: 0.006525282\n",
      "  ndcg@10: 0.006927173\n",
      "  map@10: 0.002209363\n",
      "Epoch 612 completed, Train Loss: 0.3630\n",
      "Epoch 613, Step 1, LR: 0.000080, Current Loss: 0.3567, Avg Loss: 0.3567\n",
      "Diff stats — min: -6.4764, max: 9.9476, mean: 1.9093, std: 1.9018\n",
      "\n",
      "Step 6729 — Test metrics:\n",
      "  precision@10: 0.006567125\n",
      "  recall@10: 0.006571529\n",
      "  ndcg@10: 0.006971693\n",
      "  map@10: 0.002222347\n",
      "Epoch 613, Step 10, LR: 0.000080, Current Loss: 0.3651, Avg Loss: 0.3612\n",
      "Diff stats — min: -6.1153, max: 11.3620, mean: 1.8994, std: 1.9255\n",
      "\n",
      "Step 6738 — Test metrics:\n",
      "  precision@10: 0.006553911\n",
      "  recall@10: 0.006558316\n",
      "  ndcg@10: 0.006982577\n",
      "  map@10: 0.002232201\n",
      "Epoch 613 completed, Train Loss: 0.3616\n",
      "Epoch 614, Step 1, LR: 0.000080, Current Loss: 0.3631, Avg Loss: 0.3631\n",
      "Diff stats — min: -6.5704, max: 10.5339, mean: 1.8990, std: 1.9175\n",
      "\n",
      "Step 6740 — Test metrics:\n",
      "  precision@10: 0.006613372\n",
      "  recall@10: 0.006617777\n",
      "  ndcg@10: 0.007031860\n",
      "  map@10: 0.002245950\n",
      "Epoch 614, Step 10, LR: 0.000080, Current Loss: 0.3634, Avg Loss: 0.3618\n",
      "Diff stats — min: -5.7781, max: 12.5600, mean: 1.8916, std: 1.9140\n",
      "\n",
      "Step 6749 — Test metrics:\n",
      "  precision@10: 0.006534091\n",
      "  recall@10: 0.006538495\n",
      "  ndcg@10: 0.006972445\n",
      "  map@10: 0.002232419\n",
      "Epoch 614 completed, Train Loss: 0.3619\n",
      "Epoch 615, Step 1, LR: 0.000080, Current Loss: 0.3629, Avg Loss: 0.3629\n",
      "Diff stats — min: -5.6360, max: 11.3951, mean: 1.9018, std: 1.9234\n",
      "\n",
      "Step 6751 — Test metrics:\n",
      "  precision@10: 0.006501057\n",
      "  recall@10: 0.006505462\n",
      "  ndcg@10: 0.006941571\n",
      "  map@10: 0.002224452\n",
      "Epoch 615, Step 10, LR: 0.000080, Current Loss: 0.3631, Avg Loss: 0.3622\n",
      "Diff stats — min: -6.6158, max: 10.1740, mean: 1.9040, std: 1.9181\n",
      "\n",
      "Step 6760 — Test metrics:\n",
      "  precision@10: 0.006501057\n",
      "  recall@10: 0.006505462\n",
      "  ndcg@10: 0.006902340\n",
      "  map@10: 0.002202266\n",
      "Epoch 615 completed, Train Loss: 0.3621\n",
      "Epoch 616, Step 1, LR: 0.000080, Current Loss: 0.3558, Avg Loss: 0.3558\n",
      "Diff stats — min: -7.3218, max: 10.1402, mean: 1.9228, std: 1.9069\n",
      "\n",
      "Step 6762 — Test metrics:\n",
      "  precision@10: 0.006534091\n",
      "  recall@10: 0.006538495\n",
      "  ndcg@10: 0.006936402\n",
      "  map@10: 0.002214914\n",
      "Epoch 616, Step 10, LR: 0.000080, Current Loss: 0.3636, Avg Loss: 0.3609\n",
      "Diff stats — min: -7.0402, max: 12.2354, mean: 1.9034, std: 1.9236\n",
      "\n",
      "Step 6771 — Test metrics:\n",
      "  precision@10: 0.006540698\n",
      "  recall@10: 0.006545102\n",
      "  ndcg@10: 0.006976452\n",
      "  map@10: 0.002237461\n",
      "Epoch 616 completed, Train Loss: 0.3610\n",
      "Epoch 617, Step 1, LR: 0.000080, Current Loss: 0.3617, Avg Loss: 0.3617\n",
      "Diff stats — min: -5.7012, max: 11.7272, mean: 1.9075, std: 1.9192\n",
      "\n",
      "Step 6773 — Test metrics:\n",
      "  precision@10: 0.006560518\n",
      "  recall@10: 0.006564922\n",
      "  ndcg@10: 0.007001200\n",
      "  map@10: 0.002246933\n",
      "Epoch 617, Step 10, LR: 0.000080, Current Loss: 0.3593, Avg Loss: 0.3600\n",
      "Diff stats — min: -5.8839, max: 13.4148, mean: 1.9185, std: 1.9214\n",
      "\n",
      "Step 6782 — Test metrics:\n",
      "  precision@10: 0.006580338\n",
      "  recall@10: 0.006584743\n",
      "  ndcg@10: 0.007010206\n",
      "  map@10: 0.002245205\n",
      "Epoch 617 completed, Train Loss: 0.3603\n",
      "Epoch 618, Step 1, LR: 0.000080, Current Loss: 0.3643, Avg Loss: 0.3643\n",
      "Diff stats — min: -6.2790, max: 10.9661, mean: 1.8959, std: 1.9216\n",
      "\n",
      "Step 6784 — Test metrics:\n",
      "  precision@10: 0.006586945\n",
      "  recall@10: 0.006591350\n",
      "  ndcg@10: 0.007018816\n",
      "  map@10: 0.002247407\n",
      "Epoch 618, Step 10, LR: 0.000080, Current Loss: 0.3611, Avg Loss: 0.3624\n",
      "Diff stats — min: -5.9632, max: 10.7752, mean: 1.9135, std: 1.9170\n",
      "\n",
      "Step 6793 — Test metrics:\n",
      "  precision@10: 0.006646406\n",
      "  recall@10: 0.006650810\n",
      "  ndcg@10: 0.007090194\n",
      "  map@10: 0.002269587\n",
      "Epoch 618 completed, Train Loss: 0.3620\n",
      "Epoch 619, Step 1, LR: 0.000080, Current Loss: 0.3575, Avg Loss: 0.3575\n",
      "Diff stats — min: -5.8155, max: 10.1799, mean: 1.9155, std: 1.9110\n",
      "\n",
      "Step 6795 — Test metrics:\n",
      "  precision@10: 0.006633192\n",
      "  recall@10: 0.006637597\n",
      "  ndcg@10: 0.007090545\n",
      "  map@10: 0.002273635\n",
      "Epoch 619, Step 10, LR: 0.000080, Current Loss: 0.3643, Avg Loss: 0.3615\n",
      "Diff stats — min: -5.8442, max: 10.1032, mean: 1.8948, std: 1.9122\n",
      "\n",
      "Step 6804 — Test metrics:\n",
      "  precision@10: 0.006573732\n",
      "  recall@10: 0.006578136\n",
      "  ndcg@10: 0.006995212\n",
      "  map@10: 0.002235764\n",
      "Epoch 619 completed, Train Loss: 0.3611\n",
      "Epoch 620, Step 1, LR: 0.000080, Current Loss: 0.3565, Avg Loss: 0.3565\n",
      "Diff stats — min: -5.8759, max: 11.3245, mean: 1.9263, std: 1.9130\n",
      "\n",
      "Step 6806 — Test metrics:\n",
      "  precision@10: 0.006514271\n",
      "  recall@10: 0.006518675\n",
      "  ndcg@10: 0.006954637\n",
      "  map@10: 0.002228683\n",
      "Epoch 620, Step 10, LR: 0.000080, Current Loss: 0.3687, Avg Loss: 0.3599\n",
      "Diff stats — min: -6.3218, max: 10.4876, mean: 1.8989, std: 1.9414\n",
      "\n",
      "Step 6815 — Test metrics:\n",
      "  precision@10: 0.006553911\n",
      "  recall@10: 0.006558316\n",
      "  ndcg@10: 0.006961750\n",
      "  map@10: 0.002224577\n",
      "Epoch 620 completed, Train Loss: 0.3597\n",
      "Epoch 621, Step 1, LR: 0.000080, Current Loss: 0.3606, Avg Loss: 0.3606\n",
      "Diff stats — min: -6.1123, max: 12.6180, mean: 1.9226, std: 1.9272\n",
      "\n",
      "Step 6817 — Test metrics:\n",
      "  precision@10: 0.006520877\n",
      "  recall@10: 0.006525282\n",
      "  ndcg@10: 0.006935232\n",
      "  map@10: 0.002217119\n",
      "Epoch 621, Step 10, LR: 0.000080, Current Loss: 0.3599, Avg Loss: 0.3602\n",
      "Diff stats — min: -6.5054, max: 10.3760, mean: 1.9190, std: 1.9263\n",
      "\n",
      "Step 6826 — Test metrics:\n",
      "  precision@10: 0.006586945\n",
      "  recall@10: 0.006592084\n",
      "  ndcg@10: 0.006953548\n",
      "  map@10: 0.002209733\n",
      "Epoch 621 completed, Train Loss: 0.3606\n",
      "Epoch 622, Step 1, LR: 0.000080, Current Loss: 0.3592, Avg Loss: 0.3592\n",
      "Diff stats — min: -6.0973, max: 10.8763, mean: 1.9175, std: 1.9175\n",
      "\n",
      "Step 6828 — Test metrics:\n",
      "  precision@10: 0.006606765\n",
      "  recall@10: 0.006611904\n",
      "  ndcg@10: 0.006947941\n",
      "  map@10: 0.002201074\n",
      "Epoch 622, Step 10, LR: 0.000080, Current Loss: 0.3636, Avg Loss: 0.3599\n",
      "Diff stats — min: -6.4871, max: 10.3866, mean: 1.9135, std: 1.9302\n",
      "\n",
      "Step 6837 — Test metrics:\n",
      "  precision@10: 0.006606765\n",
      "  recall@10: 0.006611904\n",
      "  ndcg@10: 0.006992003\n",
      "  map@10: 0.002227718\n",
      "Epoch 622 completed, Train Loss: 0.3593\n",
      "Epoch 623, Step 1, LR: 0.000080, Current Loss: 0.3594, Avg Loss: 0.3594\n",
      "Diff stats — min: -5.8975, max: 9.7345, mean: 1.9186, std: 1.9187\n",
      "\n",
      "Step 6839 — Test metrics:\n",
      "  precision@10: 0.006646406\n",
      "  recall@10: 0.006651545\n",
      "  ndcg@10: 0.007034120\n",
      "  map@10: 0.002243163\n",
      "Epoch 623, Step 10, LR: 0.000080, Current Loss: 0.3550, Avg Loss: 0.3584\n",
      "Diff stats — min: -6.6699, max: 9.8660, mean: 1.9366, std: 1.9218\n",
      "\n",
      "Step 6848 — Test metrics:\n",
      "  precision@10: 0.006679440\n",
      "  recall@10: 0.006683844\n",
      "  ndcg@10: 0.007086864\n",
      "  map@10: 0.002262475\n",
      "Epoch 623 completed, Train Loss: 0.3584\n",
      "Epoch 624, Step 1, LR: 0.000080, Current Loss: 0.3561, Avg Loss: 0.3561\n",
      "Diff stats — min: -5.4751, max: 10.4332, mean: 1.9334, std: 1.9200\n",
      "\n",
      "Step 6850 — Test metrics:\n",
      "  precision@10: 0.006653013\n",
      "  recall@10: 0.006657417\n",
      "  ndcg@10: 0.007072276\n",
      "  map@10: 0.002261067\n",
      "Epoch 624, Step 10, LR: 0.000080, Current Loss: 0.3635, Avg Loss: 0.3601\n",
      "Diff stats — min: -6.0491, max: 10.6966, mean: 1.9161, std: 1.9322\n",
      "\n",
      "Step 6859 — Test metrics:\n",
      "  precision@10: 0.006653013\n",
      "  recall@10: 0.006657417\n",
      "  ndcg@10: 0.006997042\n",
      "  map@10: 0.002217389\n",
      "Epoch 624 completed, Train Loss: 0.3598\n",
      "Epoch 625, Step 1, LR: 0.000080, Current Loss: 0.3647, Avg Loss: 0.3647\n",
      "Diff stats — min: -6.2564, max: 11.2971, mean: 1.9187, std: 1.9406\n",
      "\n",
      "Step 6861 — Test metrics:\n",
      "  precision@10: 0.006646406\n",
      "  recall@10: 0.006650810\n",
      "  ndcg@10: 0.006988049\n",
      "  map@10: 0.002214623\n",
      "Epoch 625, Step 10, LR: 0.000080, Current Loss: 0.3571, Avg Loss: 0.3597\n",
      "Diff stats — min: -5.4530, max: 10.9865, mean: 1.9235, std: 1.9174\n",
      "\n",
      "Step 6870 — Test metrics:\n",
      "  precision@10: 0.006646406\n",
      "  recall@10: 0.006651545\n",
      "  ndcg@10: 0.007037289\n",
      "  map@10: 0.002241224\n",
      "Epoch 625 completed, Train Loss: 0.3599\n",
      "Epoch 626, Step 1, LR: 0.000080, Current Loss: 0.3609, Avg Loss: 0.3609\n",
      "Diff stats — min: -7.4210, max: 10.1468, mean: 1.9114, std: 1.9208\n",
      "\n",
      "Step 6872 — Test metrics:\n",
      "  precision@10: 0.006606765\n",
      "  recall@10: 0.006611170\n",
      "  ndcg@10: 0.007010199\n",
      "  map@10: 0.002236704\n",
      "Epoch 626, Step 10, LR: 0.000080, Current Loss: 0.3604, Avg Loss: 0.3599\n",
      "Diff stats — min: -5.9017, max: 11.3302, mean: 1.9292, std: 1.9350\n",
      "\n",
      "Step 6881 — Test metrics:\n",
      "  precision@10: 0.006600159\n",
      "  recall@10: 0.006604563\n",
      "  ndcg@10: 0.006966326\n",
      "  map@10: 0.002213802\n",
      "Epoch 626 completed, Train Loss: 0.3603\n",
      "Epoch 627, Step 1, LR: 0.000080, Current Loss: 0.3602, Avg Loss: 0.3602\n",
      "Diff stats — min: -5.6776, max: 9.8382, mean: 1.9340, std: 1.9370\n",
      "\n",
      "Step 6883 — Test metrics:\n",
      "  precision@10: 0.006580338\n",
      "  recall@10: 0.006584743\n",
      "  ndcg@10: 0.006930223\n",
      "  map@10: 0.002196989\n",
      "Epoch 627, Step 10, LR: 0.000080, Current Loss: 0.3563, Avg Loss: 0.3598\n",
      "Diff stats — min: -6.1409, max: 11.4141, mean: 1.9413, std: 1.9277\n",
      "\n",
      "Step 6892 — Test metrics:\n",
      "  precision@10: 0.006666226\n",
      "  recall@10: 0.006671365\n",
      "  ndcg@10: 0.007059436\n",
      "  map@10: 0.002252635\n",
      "Epoch 627 completed, Train Loss: 0.3600\n",
      "Epoch 628, Step 1, LR: 0.000080, Current Loss: 0.3563, Avg Loss: 0.3563\n",
      "Diff stats — min: -6.4930, max: 10.0685, mean: 1.9407, std: 1.9245\n",
      "\n",
      "Step 6894 — Test metrics:\n",
      "  precision@10: 0.006679440\n",
      "  recall@10: 0.006684578\n",
      "  ndcg@10: 0.007079285\n",
      "  map@10: 0.002259997\n",
      "Epoch 628, Step 10, LR: 0.000080, Current Loss: 0.3626, Avg Loss: 0.3586\n",
      "Diff stats — min: -7.5105, max: 10.7062, mean: 1.9167, std: 1.9350\n",
      "\n",
      "Step 6903 — Test metrics:\n",
      "  precision@10: 0.006613372\n",
      "  recall@10: 0.006618511\n",
      "  ndcg@10: 0.007047015\n",
      "  map@10: 0.002256114\n",
      "Epoch 628 completed, Train Loss: 0.3585\n",
      "Epoch 629, Step 1, LR: 0.000080, Current Loss: 0.3595, Avg Loss: 0.3595\n",
      "Diff stats — min: -5.9830, max: 10.8874, mean: 1.9320, std: 1.9352\n",
      "\n",
      "Step 6905 — Test metrics:\n",
      "  precision@10: 0.006606765\n",
      "  recall@10: 0.006611904\n",
      "  ndcg@10: 0.007046609\n",
      "  map@10: 0.002258031\n",
      "Epoch 629, Step 10, LR: 0.000080, Current Loss: 0.3538, Avg Loss: 0.3589\n",
      "Diff stats — min: -5.9826, max: 9.8933, mean: 1.9315, std: 1.9105\n",
      "\n",
      "Step 6914 — Test metrics:\n",
      "  precision@10: 0.006692653\n",
      "  recall@10: 0.006698526\n",
      "  ndcg@10: 0.007072248\n",
      "  map@10: 0.002249424\n",
      "Epoch 629 completed, Train Loss: 0.3587\n",
      "Epoch 630, Step 1, LR: 0.000080, Current Loss: 0.3623, Avg Loss: 0.3623\n",
      "Diff stats — min: -6.3204, max: 11.1999, mean: 1.9263, std: 1.9400\n",
      "\n",
      "Step 6916 — Test metrics:\n",
      "  precision@10: 0.006686047\n",
      "  recall@10: 0.006691919\n",
      "  ndcg@10: 0.007049132\n",
      "  map@10: 0.002236111\n",
      "Epoch 630, Step 10, LR: 0.000080, Current Loss: 0.3597, Avg Loss: 0.3592\n",
      "Diff stats — min: -6.2922, max: 9.6856, mean: 1.9388, std: 1.9400\n",
      "\n",
      "Step 6925 — Test metrics:\n",
      "  precision@10: 0.006666226\n",
      "  recall@10: 0.006671365\n",
      "  ndcg@10: 0.007080577\n",
      "  map@10: 0.002264112\n",
      "Epoch 630 completed, Train Loss: 0.3591\n",
      "Epoch 631, Step 1, LR: 0.000080, Current Loss: 0.3593, Avg Loss: 0.3593\n",
      "Diff stats — min: -6.1375, max: 12.6813, mean: 1.9372, std: 1.9376\n",
      "\n",
      "Step 6927 — Test metrics:\n",
      "  precision@10: 0.006692653\n",
      "  recall@10: 0.006697792\n",
      "  ndcg@10: 0.007082424\n",
      "  map@10: 0.002257358\n",
      "Epoch 631, Step 10, LR: 0.000080, Current Loss: 0.3576, Avg Loss: 0.3581\n",
      "Diff stats — min: -6.3938, max: 10.9006, mean: 1.9485, std: 1.9419\n",
      "\n",
      "Step 6936 — Test metrics:\n",
      "  precision@10: 0.006712474\n",
      "  recall@10: 0.006717612\n",
      "  ndcg@10: 0.007131367\n",
      "  map@10: 0.002280536\n",
      "Epoch 631 completed, Train Loss: 0.3583\n",
      "Epoch 632, Step 1, LR: 0.000080, Current Loss: 0.3597, Avg Loss: 0.3597\n",
      "Diff stats — min: -6.0670, max: 11.5131, mean: 1.9290, std: 1.9274\n",
      "\n",
      "Step 6938 — Test metrics:\n",
      "  precision@10: 0.006699260\n",
      "  recall@10: 0.006704399\n",
      "  ndcg@10: 0.007150242\n",
      "  map@10: 0.002297797\n",
      "Epoch 632, Step 10, LR: 0.000080, Current Loss: 0.3601, Avg Loss: 0.3574\n",
      "Diff stats — min: -6.0300, max: 10.4757, mean: 1.9334, std: 1.9359\n",
      "\n",
      "Step 6947 — Test metrics:\n",
      "  precision@10: 0.006699260\n",
      "  recall@10: 0.006703665\n",
      "  ndcg@10: 0.007135142\n",
      "  map@10: 0.002288466\n",
      "Epoch 632 completed, Train Loss: 0.3577\n",
      "Epoch 633, Step 1, LR: 0.000080, Current Loss: 0.3559, Avg Loss: 0.3559\n",
      "Diff stats — min: -5.5505, max: 11.1762, mean: 1.9437, std: 1.9290\n",
      "\n",
      "Step 6949 — Test metrics:\n",
      "  precision@10: 0.006719080\n",
      "  recall@10: 0.006723485\n",
      "  ndcg@10: 0.007144449\n",
      "  map@10: 0.002288068\n",
      "Epoch 633, Step 10, LR: 0.000080, Current Loss: 0.3553, Avg Loss: 0.3568\n",
      "Diff stats — min: -5.1453, max: 9.3667, mean: 1.9487, std: 1.9302\n",
      "\n",
      "Step 6958 — Test metrics:\n",
      "  precision@10: 0.006626586\n",
      "  recall@10: 0.006632458\n",
      "  ndcg@10: 0.007043082\n",
      "  map@10: 0.002249862\n",
      "Epoch 633 completed, Train Loss: 0.3569\n",
      "Epoch 634, Step 1, LR: 0.000080, Current Loss: 0.3534, Avg Loss: 0.3534\n",
      "Diff stats — min: -5.4368, max: 10.5787, mean: 1.9677, std: 1.9390\n",
      "\n",
      "Step 6960 — Test metrics:\n",
      "  precision@10: 0.006659619\n",
      "  recall@10: 0.006665492\n",
      "  ndcg@10: 0.007083617\n",
      "  map@10: 0.002265328\n",
      "Epoch 634, Step 10, LR: 0.000080, Current Loss: 0.3557, Avg Loss: 0.3576\n",
      "Diff stats — min: -7.3357, max: 10.3682, mean: 1.9463, std: 1.9322\n",
      "\n",
      "Step 6969 — Test metrics:\n",
      "  precision@10: 0.006738901\n",
      "  recall@10: 0.006744773\n",
      "  ndcg@10: 0.007111118\n",
      "  map@10: 0.002259442\n",
      "Epoch 634 completed, Train Loss: 0.3574\n",
      "Epoch 635, Step 1, LR: 0.000080, Current Loss: 0.3594, Avg Loss: 0.3594\n",
      "Diff stats — min: -5.3540, max: 12.8074, mean: 1.9243, std: 1.9258\n",
      "\n",
      "Step 6971 — Test metrics:\n",
      "  precision@10: 0.006719080\n",
      "  recall@10: 0.006724953\n",
      "  ndcg@10: 0.007078157\n",
      "  map@10: 0.002246923\n",
      "Epoch 635, Step 10, LR: 0.000080, Current Loss: 0.3499, Avg Loss: 0.3569\n",
      "Diff stats — min: -5.8849, max: 9.8943, mean: 1.9691, std: 1.9299\n",
      "\n",
      "Step 6980 — Test metrics:\n",
      "  precision@10: 0.006692653\n",
      "  recall@10: 0.006698526\n",
      "  ndcg@10: 0.007074854\n",
      "  map@10: 0.002250220\n",
      "Epoch 635 completed, Train Loss: 0.3567\n",
      "Epoch 636, Step 1, LR: 0.000080, Current Loss: 0.3580, Avg Loss: 0.3580\n",
      "Diff stats — min: -6.0140, max: 12.2448, mean: 1.9245, std: 1.9215\n",
      "\n",
      "Step 6982 — Test metrics:\n",
      "  precision@10: 0.006719080\n",
      "  recall@10: 0.006724953\n",
      "  ndcg@10: 0.007105175\n",
      "  map@10: 0.002260115\n",
      "Epoch 636, Step 10, LR: 0.000080, Current Loss: 0.3576, Avg Loss: 0.3575\n",
      "Diff stats — min: -5.9865, max: 10.1693, mean: 1.9607, std: 1.9570\n",
      "\n",
      "Step 6991 — Test metrics:\n",
      "  precision@10: 0.006659619\n",
      "  recall@10: 0.006665492\n",
      "  ndcg@10: 0.007104224\n",
      "  map@10: 0.002276210\n",
      "Epoch 636 completed, Train Loss: 0.3576\n",
      "Epoch 637, Step 1, LR: 0.000080, Current Loss: 0.3516, Avg Loss: 0.3516\n",
      "Diff stats — min: -5.9859, max: 10.5058, mean: 1.9699, std: 1.9371\n",
      "\n",
      "Step 6993 — Test metrics:\n",
      "  precision@10: 0.006679440\n",
      "  recall@10: 0.006685312\n",
      "  ndcg@10: 0.007112239\n",
      "  map@10: 0.002276417\n",
      "Epoch 637, Step 10, LR: 0.000080, Current Loss: 0.3563, Avg Loss: 0.3563\n",
      "Diff stats — min: -6.2993, max: 13.6152, mean: 1.9558, std: 1.9506\n",
      "\n",
      "Step 7002 — Test metrics:\n",
      "  precision@10: 0.006672833\n",
      "  recall@10: 0.006678706\n",
      "  ndcg@10: 0.007040260\n",
      "  map@10: 0.002233350\n",
      "Epoch 637 completed, Train Loss: 0.3561\n",
      "Epoch 638, Step 1, LR: 0.000080, Current Loss: 0.3559, Avg Loss: 0.3559\n",
      "Diff stats — min: -5.5538, max: 10.9508, mean: 1.9601, std: 1.9427\n",
      "\n",
      "Step 7004 — Test metrics:\n",
      "  precision@10: 0.006705867\n",
      "  recall@10: 0.006711739\n",
      "  ndcg@10: 0.007042706\n",
      "  map@10: 0.002228122\n",
      "Epoch 638, Step 10, LR: 0.000080, Current Loss: 0.3589, Avg Loss: 0.3562\n",
      "Diff stats — min: -5.7868, max: 11.6668, mean: 1.9530, std: 1.9562\n",
      "\n",
      "Step 7013 — Test metrics:\n",
      "  precision@10: 0.006752114\n",
      "  recall@10: 0.006757987\n",
      "  ndcg@10: 0.007084529\n",
      "  map@10: 0.002240348\n",
      "Epoch 638 completed, Train Loss: 0.3563\n",
      "Epoch 639, Step 1, LR: 0.000080, Current Loss: 0.3575, Avg Loss: 0.3575\n",
      "Diff stats — min: -5.4031, max: 10.5438, mean: 1.9565, std: 1.9524\n",
      "\n",
      "Step 7015 — Test metrics:\n",
      "  precision@10: 0.006692653\n",
      "  recall@10: 0.006698526\n",
      "  ndcg@10: 0.007055937\n",
      "  map@10: 0.002239371\n",
      "Epoch 639, Step 10, LR: 0.000080, Current Loss: 0.3551, Avg Loss: 0.3567\n",
      "Diff stats — min: -6.6856, max: 9.8761, mean: 1.9558, std: 1.9425\n",
      "\n",
      "Step 7024 — Test metrics:\n",
      "  precision@10: 0.006725687\n",
      "  recall@10: 0.006731560\n",
      "  ndcg@10: 0.007166778\n",
      "  map@10: 0.002294298\n",
      "Epoch 639 completed, Train Loss: 0.3569\n",
      "Epoch 640, Step 1, LR: 0.000080, Current Loss: 0.3566, Avg Loss: 0.3566\n",
      "Diff stats — min: -6.0536, max: 13.2166, mean: 1.9594, std: 1.9482\n",
      "\n",
      "Step 7026 — Test metrics:\n",
      "  precision@10: 0.006798362\n",
      "  recall@10: 0.006804234\n",
      "  ndcg@10: 0.007250547\n",
      "  map@10: 0.002328058\n",
      "Epoch 640, Step 10, LR: 0.000080, Current Loss: 0.3530, Avg Loss: 0.3554\n",
      "Diff stats — min: -6.1952, max: 12.0505, mean: 1.9631, std: 1.9358\n",
      "\n",
      "Step 7035 — Test metrics:\n",
      "  precision@10: 0.006692653\n",
      "  recall@10: 0.006698526\n",
      "  ndcg@10: 0.007126252\n",
      "  map@10: 0.002277951\n",
      "Epoch 640 completed, Train Loss: 0.3556\n",
      "Epoch 641, Step 1, LR: 0.000080, Current Loss: 0.3585, Avg Loss: 0.3585\n",
      "Diff stats — min: -6.0363, max: 10.2498, mean: 1.9493, std: 1.9484\n",
      "\n",
      "Step 7037 — Test metrics:\n",
      "  precision@10: 0.006626586\n",
      "  recall@10: 0.006632458\n",
      "  ndcg@10: 0.007043790\n",
      "  map@10: 0.002248179\n",
      "Epoch 641, Step 10, LR: 0.000080, Current Loss: 0.3531, Avg Loss: 0.3560\n",
      "Diff stats — min: -7.3812, max: 12.2508, mean: 1.9644, std: 1.9410\n",
      "\n",
      "Step 7046 — Test metrics:\n",
      "  precision@10: 0.006791755\n",
      "  recall@10: 0.006797627\n",
      "  ndcg@10: 0.007085983\n",
      "  map@10: 0.002227819\n",
      "Epoch 641 completed, Train Loss: 0.3559\n",
      "Epoch 642, Step 1, LR: 0.000080, Current Loss: 0.3578, Avg Loss: 0.3578\n",
      "Diff stats — min: -9.2431, max: 11.0536, mean: 1.9588, std: 1.9506\n",
      "\n",
      "Step 7048 — Test metrics:\n",
      "  precision@10: 0.006804968\n",
      "  recall@10: 0.006810841\n",
      "  ndcg@10: 0.007106805\n",
      "  map@10: 0.002236308\n",
      "Epoch 642, Step 10, LR: 0.000080, Current Loss: 0.3549, Avg Loss: 0.3554\n",
      "Diff stats — min: -6.5450, max: 10.2250, mean: 1.9613, std: 1.9466\n",
      "\n",
      "Step 7057 — Test metrics:\n",
      "  precision@10: 0.006765328\n",
      "  recall@10: 0.006771200\n",
      "  ndcg@10: 0.007193088\n",
      "  map@10: 0.002298268\n",
      "Epoch 642 completed, Train Loss: 0.3551\n",
      "Epoch 643, Step 1, LR: 0.000080, Current Loss: 0.3578, Avg Loss: 0.3578\n",
      "Diff stats — min: -6.5776, max: 9.7489, mean: 1.9447, std: 1.9417\n",
      "\n",
      "Step 7059 — Test metrics:\n",
      "  precision@10: 0.006758721\n",
      "  recall@10: 0.006764594\n",
      "  ndcg@10: 0.007183537\n",
      "  map@10: 0.002295464\n",
      "Epoch 643, Step 10, LR: 0.000080, Current Loss: 0.3524, Avg Loss: 0.3554\n",
      "Diff stats — min: -6.0973, max: 10.7215, mean: 1.9673, std: 1.9398\n",
      "\n",
      "Step 7068 — Test metrics:\n",
      "  precision@10: 0.006758721\n",
      "  recall@10: 0.006764594\n",
      "  ndcg@10: 0.007148430\n",
      "  map@10: 0.002274039\n",
      "Epoch 643 completed, Train Loss: 0.3549\n",
      "Epoch 644, Step 1, LR: 0.000080, Current Loss: 0.3564, Avg Loss: 0.3564\n",
      "Diff stats — min: -7.3416, max: 10.1661, mean: 1.9706, std: 1.9609\n",
      "\n",
      "Step 7070 — Test metrics:\n",
      "  precision@10: 0.006765328\n",
      "  recall@10: 0.006771200\n",
      "  ndcg@10: 0.007162773\n",
      "  map@10: 0.002282782\n",
      "Epoch 644, Step 10, LR: 0.000080, Current Loss: 0.3565, Avg Loss: 0.3549\n",
      "Diff stats — min: -5.8972, max: 11.7800, mean: 1.9665, std: 1.9599\n",
      "\n",
      "Step 7079 — Test metrics:\n",
      "  precision@10: 0.006804968\n",
      "  recall@10: 0.006810841\n",
      "  ndcg@10: 0.007118376\n",
      "  map@10: 0.002245700\n",
      "Epoch 644 completed, Train Loss: 0.3549\n",
      "Epoch 645, Step 1, LR: 0.000080, Current Loss: 0.3540, Avg Loss: 0.3540\n",
      "Diff stats — min: -6.4424, max: 10.8491, mean: 1.9703, std: 1.9476\n",
      "\n",
      "Step 7081 — Test metrics:\n",
      "  precision@10: 0.006844609\n",
      "  recall@10: 0.006850482\n",
      "  ndcg@10: 0.007125919\n",
      "  map@10: 0.002236893\n",
      "Epoch 645, Step 10, LR: 0.000080, Current Loss: 0.3630, Avg Loss: 0.3556\n",
      "Diff stats — min: -7.1179, max: 11.2059, mean: 1.9476, std: 1.9715\n",
      "\n",
      "Step 7090 — Test metrics:\n",
      "  precision@10: 0.006745507\n",
      "  recall@10: 0.006751380\n",
      "  ndcg@10: 0.007118263\n",
      "  map@10: 0.002261179\n",
      "Epoch 645 completed, Train Loss: 0.3554\n",
      "Epoch 646, Step 1, LR: 0.000080, Current Loss: 0.3604, Avg Loss: 0.3604\n",
      "Diff stats — min: -6.6710, max: 11.7525, mean: 1.9494, std: 1.9544\n",
      "\n",
      "Step 7092 — Test metrics:\n",
      "  precision@10: 0.006725687\n",
      "  recall@10: 0.006731560\n",
      "  ndcg@10: 0.007126768\n",
      "  map@10: 0.002272931\n",
      "Epoch 646, Step 10, LR: 0.000080, Current Loss: 0.3562, Avg Loss: 0.3550\n",
      "Diff stats — min: -5.1790, max: 10.7729, mean: 1.9639, std: 1.9524\n",
      "\n",
      "Step 7101 — Test metrics:\n",
      "  precision@10: 0.006765328\n",
      "  recall@10: 0.006771200\n",
      "  ndcg@10: 0.007182807\n",
      "  map@10: 0.002292968\n",
      "Epoch 646 completed, Train Loss: 0.3551\n",
      "Epoch 647, Step 1, LR: 0.000080, Current Loss: 0.3517, Avg Loss: 0.3517\n",
      "Diff stats — min: -6.5509, max: 10.4254, mean: 1.9784, std: 1.9470\n",
      "\n",
      "Step 7103 — Test metrics:\n",
      "  precision@10: 0.006791755\n",
      "  recall@10: 0.006797627\n",
      "  ndcg@10: 0.007215477\n",
      "  map@10: 0.002305416\n",
      "Epoch 647, Step 10, LR: 0.000080, Current Loss: 0.3599, Avg Loss: 0.3537\n",
      "Diff stats — min: -6.7571, max: 10.5211, mean: 1.9467, std: 1.9511\n",
      "\n",
      "Step 7112 — Test metrics:\n",
      "  precision@10: 0.006831395\n",
      "  recall@10: 0.006837268\n",
      "  ndcg@10: 0.007269150\n",
      "  map@10: 0.002327240\n",
      "Epoch 647 completed, Train Loss: 0.3537\n",
      "Epoch 648, Step 1, LR: 0.000080, Current Loss: 0.3543, Avg Loss: 0.3543\n",
      "Diff stats — min: -6.5517, max: 12.1489, mean: 1.9708, std: 1.9535\n",
      "\n",
      "Step 7114 — Test metrics:\n",
      "  precision@10: 0.006831395\n",
      "  recall@10: 0.006837268\n",
      "  ndcg@10: 0.007230115\n",
      "  map@10: 0.002304356\n",
      "Epoch 648, Step 10, LR: 0.000080, Current Loss: 0.3551, Avg Loss: 0.3554\n",
      "Diff stats — min: -5.7246, max: 11.1919, mean: 1.9770, std: 1.9606\n",
      "\n",
      "Step 7123 — Test metrics:\n",
      "  precision@10: 0.006778541\n",
      "  recall@10: 0.006784414\n",
      "  ndcg@10: 0.007132112\n",
      "  map@10: 0.002262039\n",
      "Epoch 648 completed, Train Loss: 0.3551\n",
      "Epoch 649, Step 1, LR: 0.000080, Current Loss: 0.3529, Avg Loss: 0.3529\n",
      "Diff stats — min: -6.3556, max: 11.2711, mean: 1.9710, std: 1.9463\n",
      "\n",
      "Step 7125 — Test metrics:\n",
      "  precision@10: 0.006798362\n",
      "  recall@10: 0.006804234\n",
      "  ndcg@10: 0.007141503\n",
      "  map@10: 0.002260285\n",
      "Epoch 649, Step 10, LR: 0.000080, Current Loss: 0.3539, Avg Loss: 0.3549\n",
      "Diff stats — min: -6.5757, max: 11.8551, mean: 1.9728, std: 1.9510\n",
      "\n",
      "Step 7134 — Test metrics:\n",
      "  precision@10: 0.006890856\n",
      "  recall@10: 0.006896729\n",
      "  ndcg@10: 0.007273329\n",
      "  map@10: 0.002316314\n",
      "Epoch 649 completed, Train Loss: 0.3546\n",
      "Epoch 650, Step 1, LR: 0.000080, Current Loss: 0.3553, Avg Loss: 0.3553\n",
      "Diff stats — min: -7.4533, max: 10.6594, mean: 1.9722, std: 1.9566\n",
      "\n",
      "Step 7136 — Test metrics:\n",
      "  precision@10: 0.006851216\n",
      "  recall@10: 0.006857088\n",
      "  ndcg@10: 0.007252735\n",
      "  map@10: 0.002313771\n",
      "Epoch 650, Step 10, LR: 0.000080, Current Loss: 0.3528, Avg Loss: 0.3540\n",
      "Diff stats — min: -6.6324, max: 10.4874, mean: 1.9754, std: 1.9486\n",
      "\n",
      "Step 7145 — Test metrics:\n",
      "  precision@10: 0.006824789\n",
      "  recall@10: 0.006830661\n",
      "  ndcg@10: 0.007255498\n",
      "  map@10: 0.002320988\n",
      "Epoch 650 completed, Train Loss: 0.3541\n",
      "Epoch 651, Step 1, LR: 0.000080, Current Loss: 0.3581, Avg Loss: 0.3581\n",
      "Diff stats — min: -6.9547, max: 10.2055, mean: 1.9623, std: 1.9570\n",
      "\n",
      "Step 7147 — Test metrics:\n",
      "  precision@10: 0.006778541\n",
      "  recall@10: 0.006784414\n",
      "  ndcg@10: 0.007197033\n",
      "  map@10: 0.002301166\n",
      "Epoch 651, Step 10, LR: 0.000080, Current Loss: 0.3513, Avg Loss: 0.3546\n",
      "Diff stats — min: -6.0431, max: 11.2471, mean: 1.9792, std: 1.9444\n",
      "\n",
      "Step 7156 — Test metrics:\n",
      "  precision@10: 0.006705867\n",
      "  recall@10: 0.006711739\n",
      "  ndcg@10: 0.007102085\n",
      "  map@10: 0.002263642\n",
      "Epoch 651 completed, Train Loss: 0.3545\n",
      "Epoch 652, Step 1, LR: 0.000080, Current Loss: 0.3556, Avg Loss: 0.3556\n",
      "Diff stats — min: -5.7078, max: 10.1878, mean: 1.9816, std: 1.9662\n",
      "\n",
      "Step 7158 — Test metrics:\n",
      "  precision@10: 0.006725687\n",
      "  recall@10: 0.006731560\n",
      "  ndcg@10: 0.007136876\n",
      "  map@10: 0.002278305\n",
      "Epoch 652, Step 10, LR: 0.000080, Current Loss: 0.3502, Avg Loss: 0.3544\n",
      "Diff stats — min: -6.3271, max: 12.2902, mean: 1.9872, std: 1.9513\n",
      "\n",
      "Step 7167 — Test metrics:\n",
      "  precision@10: 0.006818182\n",
      "  recall@10: 0.006824054\n",
      "  ndcg@10: 0.007220448\n",
      "  map@10: 0.002303352\n",
      "Epoch 652 completed, Train Loss: 0.3546\n",
      "Epoch 653, Step 1, LR: 0.000080, Current Loss: 0.3515, Avg Loss: 0.3515\n",
      "Diff stats — min: -5.4571, max: 11.0538, mean: 1.9902, std: 1.9571\n",
      "\n",
      "Step 7169 — Test metrics:\n",
      "  precision@10: 0.006765328\n",
      "  recall@10: 0.006771200\n",
      "  ndcg@10: 0.007173275\n",
      "  map@10: 0.002288880\n",
      "Epoch 653, Step 10, LR: 0.000080, Current Loss: 0.3500, Avg Loss: 0.3527\n",
      "Diff stats — min: -5.7621, max: 10.3585, mean: 1.9924, std: 1.9533\n",
      "\n",
      "Step 7178 — Test metrics:\n",
      "  precision@10: 0.006725687\n",
      "  recall@10: 0.006731560\n",
      "  ndcg@10: 0.007184907\n",
      "  map@10: 0.002307189\n",
      "Epoch 653 completed, Train Loss: 0.3528\n",
      "Epoch 654, Step 1, LR: 0.000080, Current Loss: 0.3526, Avg Loss: 0.3526\n",
      "Diff stats — min: -5.5560, max: 13.2100, mean: 1.9888, std: 1.9609\n",
      "\n",
      "Step 7180 — Test metrics:\n",
      "  precision@10: 0.006745507\n",
      "  recall@10: 0.006751380\n",
      "  ndcg@10: 0.007190850\n",
      "  map@10: 0.002305786\n",
      "Epoch 654, Step 10, LR: 0.000080, Current Loss: 0.3554, Avg Loss: 0.3540\n",
      "Diff stats — min: -5.7989, max: 11.3252, mean: 1.9765, std: 1.9590\n",
      "\n",
      "Step 7189 — Test metrics:\n",
      "  precision@10: 0.006732294\n",
      "  recall@10: 0.006738167\n",
      "  ndcg@10: 0.007161916\n",
      "  map@10: 0.002290226\n",
      "Epoch 654 completed, Train Loss: 0.3542\n",
      "Epoch 655, Step 1, LR: 0.000080, Current Loss: 0.3534, Avg Loss: 0.3534\n",
      "Diff stats — min: -11.3291, max: 11.0802, mean: 1.9876, std: 1.9638\n",
      "\n",
      "Step 7191 — Test metrics:\n",
      "  precision@10: 0.006785148\n",
      "  recall@10: 0.006791021\n",
      "  ndcg@10: 0.007182619\n",
      "  map@10: 0.002290884\n",
      "Epoch 655, Step 10, LR: 0.000080, Current Loss: 0.3533, Avg Loss: 0.3538\n",
      "Diff stats — min: -6.7135, max: 10.4386, mean: 1.9988, std: 1.9705\n",
      "\n",
      "Step 7200 — Test metrics:\n",
      "  precision@10: 0.006791755\n",
      "  recall@10: 0.006797627\n",
      "  ndcg@10: 0.007189203\n",
      "  map@10: 0.002293033\n",
      "Epoch 655 completed, Train Loss: 0.3537\n",
      "Epoch 656, Step 1, LR: 0.000080, Current Loss: 0.3507, Avg Loss: 0.3507\n",
      "Diff stats — min: -6.3525, max: 12.0258, mean: 1.9954, std: 1.9571\n",
      "\n",
      "Step 7202 — Test metrics:\n",
      "  precision@10: 0.006785148\n",
      "  recall@10: 0.006791021\n",
      "  ndcg@10: 0.007178530\n",
      "  map@10: 0.002286445\n",
      "Epoch 656, Step 10, LR: 0.000080, Current Loss: 0.3533, Avg Loss: 0.3524\n",
      "Diff stats — min: -6.9917, max: 10.9387, mean: 1.9907, std: 1.9622\n",
      "\n",
      "Step 7211 — Test metrics:\n",
      "  precision@10: 0.006758721\n",
      "  recall@10: 0.006764594\n",
      "  ndcg@10: 0.007222179\n",
      "  map@10: 0.002319479\n",
      "Epoch 656 completed, Train Loss: 0.3528\n",
      "Epoch 657, Step 1, LR: 0.000080, Current Loss: 0.3532, Avg Loss: 0.3532\n",
      "Diff stats — min: -6.3375, max: 13.0711, mean: 1.9923, std: 1.9657\n",
      "\n",
      "Step 7213 — Test metrics:\n",
      "  precision@10: 0.006758721\n",
      "  recall@10: 0.006764594\n",
      "  ndcg@10: 0.007251256\n",
      "  map@10: 0.002335296\n",
      "Epoch 657, Step 10, LR: 0.000080, Current Loss: 0.3510, Avg Loss: 0.3513\n",
      "Diff stats — min: -7.5594, max: 10.7562, mean: 1.9949, std: 1.9579\n",
      "\n",
      "Step 7222 — Test metrics:\n",
      "  precision@10: 0.006791755\n",
      "  recall@10: 0.006797627\n",
      "  ndcg@10: 0.007327072\n",
      "  map@10: 0.002374181\n",
      "Epoch 657 completed, Train Loss: 0.3517\n",
      "Epoch 658, Step 1, LR: 0.000080, Current Loss: 0.3565, Avg Loss: 0.3565\n",
      "Diff stats — min: -5.8451, max: 11.9444, mean: 1.9705, std: 1.9655\n",
      "\n",
      "Step 7224 — Test metrics:\n",
      "  precision@10: 0.006824789\n",
      "  recall@10: 0.006830661\n",
      "  ndcg@10: 0.007345168\n",
      "  map@10: 0.002374407\n",
      "Epoch 658, Step 10, LR: 0.000080, Current Loss: 0.3531, Avg Loss: 0.3522\n",
      "Diff stats — min: -5.8863, max: 11.4863, mean: 1.9865, std: 1.9617\n",
      "\n",
      "Step 7233 — Test metrics:\n",
      "  precision@10: 0.006818182\n",
      "  recall@10: 0.006824054\n",
      "  ndcg@10: 0.007269514\n",
      "  map@10: 0.002333908\n",
      "Epoch 658 completed, Train Loss: 0.3524\n",
      "Epoch 659, Step 1, LR: 0.000080, Current Loss: 0.3559, Avg Loss: 0.3559\n",
      "Diff stats — min: -5.9920, max: 11.1572, mean: 1.9760, std: 1.9615\n",
      "\n",
      "Step 7235 — Test metrics:\n",
      "  precision@10: 0.006818182\n",
      "  recall@10: 0.006824054\n",
      "  ndcg@10: 0.007226546\n",
      "  map@10: 0.002307355\n",
      "Epoch 659, Step 10, LR: 0.000080, Current Loss: 0.3555, Avg Loss: 0.3529\n",
      "Diff stats — min: -9.9128, max: 9.8964, mean: 1.9889, std: 1.9779\n",
      "\n",
      "Step 7244 — Test metrics:\n",
      "  precision@10: 0.006732294\n",
      "  recall@10: 0.006738167\n",
      "  ndcg@10: 0.007150548\n",
      "  map@10: 0.002284028\n",
      "Epoch 659 completed, Train Loss: 0.3531\n",
      "Epoch 660, Step 1, LR: 0.000080, Current Loss: 0.3518, Avg Loss: 0.3518\n",
      "Diff stats — min: -6.0264, max: 11.6546, mean: 2.0021, std: 1.9749\n",
      "\n",
      "Step 7246 — Test metrics:\n",
      "  precision@10: 0.006732294\n",
      "  recall@10: 0.006738167\n",
      "  ndcg@10: 0.007149632\n",
      "  map@10: 0.002279794\n",
      "Epoch 660, Step 10, LR: 0.000080, Current Loss: 0.3542, Avg Loss: 0.3531\n",
      "Diff stats — min: -5.2762, max: 11.6981, mean: 1.9856, std: 1.9668\n",
      "\n",
      "Step 7255 — Test metrics:\n",
      "  precision@10: 0.006745507\n",
      "  recall@10: 0.006750646\n",
      "  ndcg@10: 0.007148780\n",
      "  map@10: 0.002280936\n",
      "Epoch 660 completed, Train Loss: 0.3533\n",
      "Epoch 661, Step 1, LR: 0.000080, Current Loss: 0.3498, Avg Loss: 0.3498\n",
      "Diff stats — min: -6.4274, max: 11.4245, mean: 2.0089, std: 1.9704\n",
      "\n",
      "Step 7257 — Test metrics:\n",
      "  precision@10: 0.006705867\n",
      "  recall@10: 0.006711005\n",
      "  ndcg@10: 0.007125367\n",
      "  map@10: 0.002276246\n",
      "Epoch 661, Step 10, LR: 0.000080, Current Loss: 0.3513, Avg Loss: 0.3534\n",
      "Diff stats — min: -6.0903, max: 12.2214, mean: 2.0003, std: 1.9645\n",
      "\n",
      "Step 7266 — Test metrics:\n",
      "  precision@10: 0.006811575\n",
      "  recall@10: 0.006817448\n",
      "  ndcg@10: 0.007246583\n",
      "  map@10: 0.002318556\n",
      "Epoch 661 completed, Train Loss: 0.3534\n",
      "Epoch 662, Step 1, LR: 0.000080, Current Loss: 0.3561, Avg Loss: 0.3561\n",
      "Diff stats — min: -5.6233, max: 10.6753, mean: 1.9821, std: 1.9659\n",
      "\n",
      "Step 7268 — Test metrics:\n",
      "  precision@10: 0.006844609\n",
      "  recall@10: 0.006850482\n",
      "  ndcg@10: 0.007258950\n",
      "  map@10: 0.002319015\n",
      "Epoch 662, Step 10, LR: 0.000080, Current Loss: 0.3514, Avg Loss: 0.3513\n",
      "Diff stats — min: -6.2006, max: 10.0325, mean: 2.0016, std: 1.9656\n",
      "\n",
      "Step 7277 — Test metrics:\n",
      "  precision@10: 0.006831395\n",
      "  recall@10: 0.006837268\n",
      "  ndcg@10: 0.007231842\n",
      "  map@10: 0.002302339\n",
      "Epoch 662 completed, Train Loss: 0.3518\n",
      "Epoch 663, Step 1, LR: 0.000080, Current Loss: 0.3504, Avg Loss: 0.3504\n",
      "Diff stats — min: -6.4684, max: 11.4438, mean: 2.0039, std: 1.9673\n",
      "\n",
      "Step 7279 — Test metrics:\n",
      "  precision@10: 0.006838002\n",
      "  recall@10: 0.006843875\n",
      "  ndcg@10: 0.007219479\n",
      "  map@10: 0.002295096\n",
      "Epoch 663, Step 10, LR: 0.000080, Current Loss: 0.3513, Avg Loss: 0.3517\n",
      "Diff stats — min: -6.6882, max: 10.3823, mean: 1.9852, std: 1.9490\n",
      "\n",
      "Step 7288 — Test metrics:\n",
      "  precision@10: 0.006758721\n",
      "  recall@10: 0.006763860\n",
      "  ndcg@10: 0.007146208\n",
      "  map@10: 0.002271702\n",
      "Epoch 663 completed, Train Loss: 0.3517\n",
      "Epoch 664, Step 1, LR: 0.000080, Current Loss: 0.3494, Avg Loss: 0.3494\n",
      "Diff stats — min: -6.5407, max: 14.7096, mean: 2.0021, std: 1.9615\n",
      "\n",
      "Step 7290 — Test metrics:\n",
      "  precision@10: 0.006771934\n",
      "  recall@10: 0.006776339\n",
      "  ndcg@10: 0.007165851\n",
      "  map@10: 0.002280259\n",
      "Epoch 664, Step 10, LR: 0.000080, Current Loss: 0.3557, Avg Loss: 0.3522\n",
      "Diff stats — min: -5.4632, max: 11.0600, mean: 2.0015, std: 1.9861\n",
      "\n",
      "Step 7299 — Test metrics:\n",
      "  precision@10: 0.006818182\n",
      "  recall@10: 0.006823320\n",
      "  ndcg@10: 0.007173069\n",
      "  map@10: 0.002273412\n",
      "Epoch 664 completed, Train Loss: 0.3523\n",
      "Epoch 665, Step 1, LR: 0.000080, Current Loss: 0.3438, Avg Loss: 0.3438\n",
      "Diff stats — min: -5.5074, max: 10.8994, mean: 2.0232, std: 1.9555\n",
      "\n",
      "Step 7301 — Test metrics:\n",
      "  precision@10: 0.006804968\n",
      "  recall@10: 0.006810107\n",
      "  ndcg@10: 0.007145675\n",
      "  map@10: 0.002259863\n",
      "Epoch 665, Step 10, LR: 0.000080, Current Loss: 0.3501, Avg Loss: 0.3503\n",
      "Diff stats — min: -6.7488, max: 10.6759, mean: 1.9900, std: 1.9503\n",
      "\n",
      "Step 7310 — Test metrics:\n",
      "  precision@10: 0.006765328\n",
      "  recall@10: 0.006771200\n",
      "  ndcg@10: 0.007171369\n",
      "  map@10: 0.002287308\n",
      "Epoch 665 completed, Train Loss: 0.3502\n",
      "Epoch 666, Step 1, LR: 0.000080, Current Loss: 0.3519, Avg Loss: 0.3519\n",
      "Diff stats — min: -6.3051, max: 11.0712, mean: 1.9988, std: 1.9695\n",
      "\n",
      "Step 7312 — Test metrics:\n",
      "  precision@10: 0.006758721\n",
      "  recall@10: 0.006764594\n",
      "  ndcg@10: 0.007167417\n",
      "  map@10: 0.002289450\n",
      "Epoch 666, Step 10, LR: 0.000080, Current Loss: 0.3489, Avg Loss: 0.3507\n",
      "Diff stats — min: -7.5823, max: 10.5227, mean: 2.0067, std: 1.9648\n",
      "\n",
      "Step 7321 — Test metrics:\n",
      "  precision@10: 0.006778541\n",
      "  recall@10: 0.006784414\n",
      "  ndcg@10: 0.007309629\n",
      "  map@10: 0.002367255\n",
      "Epoch 666 completed, Train Loss: 0.3507\n",
      "Epoch 667, Step 1, LR: 0.000080, Current Loss: 0.3525, Avg Loss: 0.3525\n",
      "Diff stats — min: -7.1882, max: 9.9273, mean: 2.0037, std: 1.9747\n",
      "\n",
      "Step 7323 — Test metrics:\n",
      "  precision@10: 0.006778541\n",
      "  recall@10: 0.006784414\n",
      "  ndcg@10: 0.007301183\n",
      "  map@10: 0.002362492\n",
      "Epoch 667, Step 10, LR: 0.000080, Current Loss: 0.3499, Avg Loss: 0.3515\n",
      "Diff stats — min: -7.2979, max: 12.0263, mean: 2.0017, std: 1.9652\n",
      "\n",
      "Step 7332 — Test metrics:\n",
      "  precision@10: 0.006857822\n",
      "  recall@10: 0.006863695\n",
      "  ndcg@10: 0.007167343\n",
      "  map@10: 0.002257075\n",
      "Epoch 667 completed, Train Loss: 0.3513\n",
      "Epoch 668, Step 1, LR: 0.000080, Current Loss: 0.3515, Avg Loss: 0.3515\n",
      "Diff stats — min: -5.8300, max: 11.6082, mean: 2.0100, std: 1.9785\n",
      "\n",
      "Step 7334 — Test metrics:\n",
      "  precision@10: 0.006824789\n",
      "  recall@10: 0.006829927\n",
      "  ndcg@10: 0.007115014\n",
      "  map@10: 0.002234259\n",
      "Epoch 668, Step 10, LR: 0.000080, Current Loss: 0.3485, Avg Loss: 0.3510\n",
      "Diff stats — min: -5.8734, max: 11.4178, mean: 2.0172, std: 1.9757\n",
      "\n",
      "Step 7343 — Test metrics:\n",
      "  precision@10: 0.006811575\n",
      "  recall@10: 0.006817448\n",
      "  ndcg@10: 0.007200594\n",
      "  map@10: 0.002289732\n",
      "Epoch 668 completed, Train Loss: 0.3513\n",
      "Epoch 669, Step 1, LR: 0.000080, Current Loss: 0.3477, Avg Loss: 0.3477\n",
      "Diff stats — min: -7.6683, max: 11.1491, mean: 2.0191, std: 1.9705\n",
      "\n",
      "Step 7345 — Test metrics:\n",
      "  precision@10: 0.006844609\n",
      "  recall@10: 0.006850482\n",
      "  ndcg@10: 0.007251600\n",
      "  map@10: 0.002312270\n",
      "Epoch 669, Step 10, LR: 0.000080, Current Loss: 0.3488, Avg Loss: 0.3488\n",
      "Diff stats — min: -6.0725, max: 11.6163, mean: 2.0041, std: 1.9622\n",
      "\n",
      "Step 7354 — Test metrics:\n",
      "  precision@10: 0.006877643\n",
      "  recall@10: 0.006883515\n",
      "  ndcg@10: 0.007288484\n",
      "  map@10: 0.002328638\n",
      "Epoch 669 completed, Train Loss: 0.3489\n",
      "Epoch 670, Step 1, LR: 0.000080, Current Loss: 0.3481, Avg Loss: 0.3481\n",
      "Diff stats — min: -5.9765, max: 10.7106, mean: 2.0054, std: 1.9586\n",
      "\n",
      "Step 7356 — Test metrics:\n",
      "  precision@10: 0.006844609\n",
      "  recall@10: 0.006850482\n",
      "  ndcg@10: 0.007269633\n",
      "  map@10: 0.002325354\n",
      "Epoch 670, Step 10, LR: 0.000080, Current Loss: 0.3495, Avg Loss: 0.3504\n",
      "Diff stats — min: -6.3755, max: 10.3536, mean: 2.0161, std: 1.9727\n",
      "\n",
      "Step 7365 — Test metrics:\n",
      "  precision@10: 0.006884249\n",
      "  recall@10: 0.006890122\n",
      "  ndcg@10: 0.007215493\n",
      "  map@10: 0.002278615\n",
      "Epoch 670 completed, Train Loss: 0.3504\n",
      "Epoch 671, Step 1, LR: 0.000080, Current Loss: 0.3431, Avg Loss: 0.3431\n",
      "Diff stats — min: -5.5151, max: 11.4480, mean: 2.0290, std: 1.9633\n",
      "\n",
      "Step 7367 — Test metrics:\n",
      "  precision@10: 0.006857822\n",
      "  recall@10: 0.006863695\n",
      "  ndcg@10: 0.007223346\n",
      "  map@10: 0.002287777\n",
      "Epoch 671, Step 10, LR: 0.000080, Current Loss: 0.3520, Avg Loss: 0.3506\n",
      "Diff stats — min: -5.7841, max: 11.7302, mean: 2.0045, std: 1.9733\n",
      "\n",
      "Step 7376 — Test metrics:\n",
      "  precision@10: 0.006765328\n",
      "  recall@10: 0.006771200\n",
      "  ndcg@10: 0.007260134\n",
      "  map@10: 0.002340480\n",
      "Epoch 671 completed, Train Loss: 0.3503\n",
      "Epoch 672, Step 1, LR: 0.000080, Current Loss: 0.3568, Avg Loss: 0.3568\n",
      "Diff stats — min: -6.5453, max: 11.4585, mean: 1.9921, std: 1.9828\n",
      "\n",
      "Step 7378 — Test metrics:\n",
      "  precision@10: 0.006785148\n",
      "  recall@10: 0.006791021\n",
      "  ndcg@10: 0.007284111\n",
      "  map@10: 0.002349354\n",
      "Epoch 672, Step 10, LR: 0.000080, Current Loss: 0.3485, Avg Loss: 0.3487\n",
      "Diff stats — min: -5.4457, max: 10.3887, mean: 2.0023, std: 1.9600\n",
      "\n",
      "Step 7387 — Test metrics:\n",
      "  precision@10: 0.006851216\n",
      "  recall@10: 0.006857088\n",
      "  ndcg@10: 0.007302767\n",
      "  map@10: 0.002346034\n",
      "Epoch 672 completed, Train Loss: 0.3490\n",
      "Epoch 673, Step 1, LR: 0.000080, Current Loss: 0.3419, Avg Loss: 0.3419\n",
      "Diff stats — min: -6.2299, max: 11.7605, mean: 2.0403, std: 1.9632\n",
      "\n",
      "Step 7389 — Test metrics:\n",
      "  precision@10: 0.006844609\n",
      "  recall@10: 0.006850482\n",
      "  ndcg@10: 0.007300407\n",
      "  map@10: 0.002344369\n",
      "Epoch 673, Step 10, LR: 0.000080, Current Loss: 0.3508, Avg Loss: 0.3499\n",
      "Diff stats — min: -6.0622, max: 10.6154, mean: 2.0053, std: 1.9709\n",
      "\n",
      "Step 7398 — Test metrics:\n",
      "  precision@10: 0.006851216\n",
      "  recall@10: 0.006857088\n",
      "  ndcg@10: 0.007245892\n",
      "  map@10: 0.002308787\n",
      "Epoch 673 completed, Train Loss: 0.3495\n",
      "Epoch 674, Step 1, LR: 0.000080, Current Loss: 0.3509, Avg Loss: 0.3509\n",
      "Diff stats — min: -6.8390, max: 11.3869, mean: 2.0110, std: 1.9760\n",
      "\n",
      "Step 7400 — Test metrics:\n",
      "  precision@10: 0.006804968\n",
      "  recall@10: 0.006810841\n",
      "  ndcg@10: 0.007219424\n",
      "  map@10: 0.002304484\n",
      "Epoch 674, Step 10, LR: 0.000080, Current Loss: 0.3499, Avg Loss: 0.3493\n",
      "Diff stats — min: -6.1655, max: 10.2375, mean: 2.0183, std: 1.9755\n",
      "\n",
      "Step 7409 — Test metrics:\n",
      "  precision@10: 0.006838002\n",
      "  recall@10: 0.006843875\n",
      "  ndcg@10: 0.007301565\n",
      "  map@10: 0.002344542\n",
      "Epoch 674 completed, Train Loss: 0.3495\n",
      "Epoch 675, Step 1, LR: 0.000080, Current Loss: 0.3490, Avg Loss: 0.3490\n",
      "Diff stats — min: -7.0095, max: 11.6264, mean: 2.0145, std: 1.9711\n",
      "\n",
      "Step 7411 — Test metrics:\n",
      "  precision@10: 0.006811575\n",
      "  recall@10: 0.006817448\n",
      "  ndcg@10: 0.007281285\n",
      "  map@10: 0.002337976\n",
      "Epoch 675, Step 10, LR: 0.000080, Current Loss: 0.3465, Avg Loss: 0.3492\n",
      "Diff stats — min: -5.9119, max: 11.9727, mean: 2.0272, std: 1.9742\n",
      "\n",
      "Step 7420 — Test metrics:\n",
      "  precision@10: 0.006824789\n",
      "  recall@10: 0.006830661\n",
      "  ndcg@10: 0.007269151\n",
      "  map@10: 0.002326805\n",
      "Epoch 675 completed, Train Loss: 0.3490\n",
      "Epoch 676, Step 1, LR: 0.000080, Current Loss: 0.3536, Avg Loss: 0.3536\n",
      "Diff stats — min: -6.2718, max: 12.6124, mean: 2.0083, std: 1.9854\n",
      "\n",
      "Step 7422 — Test metrics:\n",
      "  precision@10: 0.006838002\n",
      "  recall@10: 0.006843875\n",
      "  ndcg@10: 0.007263941\n",
      "  map@10: 0.002321628\n",
      "Epoch 676, Step 10, LR: 0.000080, Current Loss: 0.3540, Avg Loss: 0.3500\n",
      "Diff stats — min: -5.8334, max: 12.4259, mean: 2.0086, std: 1.9886\n",
      "\n",
      "Step 7431 — Test metrics:\n",
      "  precision@10: 0.006910677\n",
      "  recall@10: 0.006916549\n",
      "  ndcg@10: 0.007340024\n",
      "  map@10: 0.002345679\n",
      "Epoch 676 completed, Train Loss: 0.3501\n",
      "Epoch 677, Step 1, LR: 0.000080, Current Loss: 0.3488, Avg Loss: 0.3488\n",
      "Diff stats — min: -6.5809, max: 11.3829, mean: 2.0236, std: 1.9794\n",
      "\n",
      "Step 7433 — Test metrics:\n",
      "  precision@10: 0.006890856\n",
      "  recall@10: 0.006896729\n",
      "  ndcg@10: 0.007347395\n",
      "  map@10: 0.002355786\n",
      "Epoch 677, Step 10, LR: 0.000080, Current Loss: 0.3416, Avg Loss: 0.3473\n",
      "Diff stats — min: -5.9775, max: 11.7121, mean: 2.0365, std: 1.9674\n",
      "\n",
      "Step 7442 — Test metrics:\n",
      "  precision@10: 0.006857822\n",
      "  recall@10: 0.006863695\n",
      "  ndcg@10: 0.007288093\n",
      "  map@10: 0.002329126\n",
      "Epoch 677 completed, Train Loss: 0.3476\n",
      "Epoch 678, Step 1, LR: 0.000080, Current Loss: 0.3479, Avg Loss: 0.3479\n",
      "Diff stats — min: -5.4466, max: 10.3256, mean: 2.0271, std: 1.9819\n",
      "\n",
      "Step 7444 — Test metrics:\n",
      "  precision@10: 0.006864429\n",
      "  recall@10: 0.006870302\n",
      "  ndcg@10: 0.007299572\n",
      "  map@10: 0.002336755\n",
      "Epoch 678, Step 10, LR: 0.000080, Current Loss: 0.3525, Avg Loss: 0.3484\n",
      "Diff stats — min: -5.6774, max: 13.2210, mean: 2.0082, std: 1.9776\n",
      "\n",
      "Step 7453 — Test metrics:\n",
      "  precision@10: 0.006884249\n",
      "  recall@10: 0.006890122\n",
      "  ndcg@10: 0.007343649\n",
      "  map@10: 0.002358611\n",
      "Epoch 678 completed, Train Loss: 0.3481\n",
      "Epoch 679, Step 1, LR: 0.000080, Current Loss: 0.3523, Avg Loss: 0.3523\n",
      "Diff stats — min: -5.8285, max: 10.2162, mean: 2.0154, std: 1.9852\n",
      "\n",
      "Step 7455 — Test metrics:\n",
      "  precision@10: 0.006904070\n",
      "  recall@10: 0.006909942\n",
      "  ndcg@10: 0.007332067\n",
      "  map@10: 0.002345579\n",
      "Epoch 679, Step 10, LR: 0.000080, Current Loss: 0.3506, Avg Loss: 0.3493\n",
      "Diff stats — min: -5.8342, max: 13.4552, mean: 2.0197, std: 1.9889\n",
      "\n",
      "Step 7464 — Test metrics:\n",
      "  precision@10: 0.006910677\n",
      "  recall@10: 0.006916549\n",
      "  ndcg@10: 0.007279342\n",
      "  map@10: 0.002308802\n",
      "Epoch 679 completed, Train Loss: 0.3491\n",
      "Epoch 680, Step 1, LR: 0.000080, Current Loss: 0.3530, Avg Loss: 0.3530\n",
      "Diff stats — min: -6.0632, max: 10.8064, mean: 2.0325, std: 1.9996\n",
      "\n",
      "Step 7466 — Test metrics:\n",
      "  precision@10: 0.006890856\n",
      "  recall@10: 0.006895995\n",
      "  ndcg@10: 0.007265218\n",
      "  map@10: 0.002306339\n",
      "Epoch 680, Step 10, LR: 0.000080, Current Loss: 0.3483, Avg Loss: 0.3488\n",
      "Diff stats — min: -9.8211, max: 10.4306, mean: 2.0338, std: 1.9917\n",
      "\n",
      "Step 7475 — Test metrics:\n",
      "  precision@10: 0.006838002\n",
      "  recall@10: 0.006843875\n",
      "  ndcg@10: 0.007234074\n",
      "  map@10: 0.002303714\n",
      "Epoch 680 completed, Train Loss: 0.3487\n",
      "Epoch 681, Step 1, LR: 0.000080, Current Loss: 0.3461, Avg Loss: 0.3461\n",
      "Diff stats — min: -6.1309, max: 11.2754, mean: 2.0358, std: 1.9810\n",
      "\n",
      "Step 7477 — Test metrics:\n",
      "  precision@10: 0.006857822\n",
      "  recall@10: 0.006862961\n",
      "  ndcg@10: 0.007249415\n",
      "  map@10: 0.002308069\n",
      "Epoch 681, Step 10, LR: 0.000080, Current Loss: 0.3475, Avg Loss: 0.3477\n",
      "Diff stats — min: -6.9022, max: 10.9364, mean: 2.0182, std: 1.9720\n",
      "\n",
      "Step 7486 — Test metrics:\n",
      "  precision@10: 0.006950317\n",
      "  recall@10: 0.006955456\n",
      "  ndcg@10: 0.007382045\n",
      "  map@10: 0.002359952\n",
      "Epoch 681 completed, Train Loss: 0.3470\n",
      "Epoch 682, Step 1, LR: 0.000080, Current Loss: 0.3497, Avg Loss: 0.3497\n",
      "Diff stats — min: -6.2473, max: 10.9225, mean: 2.0347, std: 1.9905\n",
      "\n",
      "Step 7488 — Test metrics:\n",
      "  precision@10: 0.006930497\n",
      "  recall@10: 0.006935635\n",
      "  ndcg@10: 0.007376521\n",
      "  map@10: 0.002362963\n",
      "Epoch 682, Step 10, LR: 0.000080, Current Loss: 0.3491, Avg Loss: 0.3468\n",
      "Diff stats — min: -5.4553, max: 11.8573, mean: 2.0261, std: 1.9863\n",
      "\n",
      "Step 7497 — Test metrics:\n",
      "  precision@10: 0.006956924\n",
      "  recall@10: 0.006962797\n",
      "  ndcg@10: 0.007342219\n",
      "  map@10: 0.002336588\n",
      "Epoch 682 completed, Train Loss: 0.3468\n",
      "Epoch 683, Step 1, LR: 0.000080, Current Loss: 0.3452, Avg Loss: 0.3452\n",
      "Diff stats — min: -6.1606, max: 14.2559, mean: 2.0397, std: 1.9831\n",
      "\n",
      "Step 7499 — Test metrics:\n",
      "  precision@10: 0.006950317\n",
      "  recall@10: 0.006956190\n",
      "  ndcg@10: 0.007322111\n",
      "  map@10: 0.002325320\n",
      "Epoch 683, Step 10, LR: 0.000080, Current Loss: 0.3506, Avg Loss: 0.3477\n",
      "Diff stats — min: -10.0729, max: 9.9289, mean: 2.0292, std: 1.9944\n",
      "\n",
      "Step 7508 — Test metrics:\n",
      "  precision@10: 0.006857822\n",
      "  recall@10: 0.006862227\n",
      "  ndcg@10: 0.007262764\n",
      "  map@10: 0.002314196\n",
      "Epoch 683 completed, Train Loss: 0.3477\n",
      "Epoch 684, Step 1, LR: 0.000080, Current Loss: 0.3455, Avg Loss: 0.3455\n",
      "Diff stats — min: -5.5582, max: 10.8585, mean: 2.0392, std: 1.9796\n",
      "\n",
      "Step 7510 — Test metrics:\n",
      "  precision@10: 0.006877643\n",
      "  recall@10: 0.006882047\n",
      "  ndcg@10: 0.007297526\n",
      "  map@10: 0.002327635\n",
      "Epoch 684, Step 10, LR: 0.000080, Current Loss: 0.3453, Avg Loss: 0.3472\n",
      "Diff stats — min: -6.5814, max: 11.5210, mean: 2.0531, std: 1.9967\n",
      "\n",
      "Step 7519 — Test metrics:\n",
      "  precision@10: 0.006904070\n",
      "  recall@10: 0.006909942\n",
      "  ndcg@10: 0.007318549\n",
      "  map@10: 0.002333239\n",
      "Epoch 684 completed, Train Loss: 0.3468\n",
      "Epoch 685, Step 1, LR: 0.000080, Current Loss: 0.3454, Avg Loss: 0.3454\n",
      "Diff stats — min: -6.2201, max: 11.0284, mean: 2.0481, std: 1.9899\n",
      "\n",
      "Step 7521 — Test metrics:\n",
      "  precision@10: 0.006930497\n",
      "  recall@10: 0.006936370\n",
      "  ndcg@10: 0.007321946\n",
      "  map@10: 0.002328512\n",
      "Epoch 685, Step 10, LR: 0.000080, Current Loss: 0.3513, Avg Loss: 0.3474\n",
      "Diff stats — min: -6.6205, max: 12.1627, mean: 2.0238, std: 1.9883\n",
      "\n",
      "Step 7530 — Test metrics:\n",
      "  precision@10: 0.006976744\n",
      "  recall@10: 0.006982617\n",
      "  ndcg@10: 0.007352829\n",
      "  map@10: 0.002336052\n",
      "Epoch 685 completed, Train Loss: 0.3472\n",
      "Epoch 686, Step 1, LR: 0.000080, Current Loss: 0.3456, Avg Loss: 0.3456\n",
      "Diff stats — min: -6.7276, max: 11.9364, mean: 2.0442, std: 1.9885\n",
      "\n",
      "Step 7532 — Test metrics:\n",
      "  precision@10: 0.006956924\n",
      "  recall@10: 0.006962797\n",
      "  ndcg@10: 0.007350860\n",
      "  map@10: 0.002341275\n",
      "Epoch 686, Step 10, LR: 0.000080, Current Loss: 0.3451, Avg Loss: 0.3465\n",
      "Diff stats — min: -6.9784, max: 10.4557, mean: 2.0461, std: 1.9835\n",
      "\n",
      "Step 7541 — Test metrics:\n",
      "  precision@10: 0.006910677\n",
      "  recall@10: 0.006915815\n",
      "  ndcg@10: 0.007272958\n",
      "  map@10: 0.002303448\n",
      "Epoch 686 completed, Train Loss: 0.3466\n",
      "Epoch 687, Step 1, LR: 0.000080, Current Loss: 0.3459, Avg Loss: 0.3459\n",
      "Diff stats — min: -5.8005, max: 10.7921, mean: 2.0554, std: 1.9992\n",
      "\n",
      "Step 7543 — Test metrics:\n",
      "  precision@10: 0.006877643\n",
      "  recall@10: 0.006882781\n",
      "  ndcg@10: 0.007254092\n",
      "  map@10: 0.002300584\n",
      "Epoch 687, Step 10, LR: 0.000080, Current Loss: 0.3521, Avg Loss: 0.3465\n",
      "Diff stats — min: -7.4146, max: 11.0568, mean: 2.0327, std: 2.0034\n",
      "\n",
      "Step 7552 — Test metrics:\n",
      "  precision@10: 0.006864429\n",
      "  recall@10: 0.006870302\n",
      "  ndcg@10: 0.007300850\n",
      "  map@10: 0.002332935\n",
      "Epoch 687 completed, Train Loss: 0.3466\n",
      "Epoch 688, Step 1, LR: 0.000080, Current Loss: 0.3458, Avg Loss: 0.3458\n",
      "Diff stats — min: -6.5671, max: 10.5691, mean: 2.0541, std: 1.9950\n",
      "\n",
      "Step 7554 — Test metrics:\n",
      "  precision@10: 0.006884249\n",
      "  recall@10: 0.006890122\n",
      "  ndcg@10: 0.007314657\n",
      "  map@10: 0.002339036\n",
      "Epoch 688, Step 10, LR: 0.000080, Current Loss: 0.3476, Avg Loss: 0.3467\n",
      "Diff stats — min: -6.8195, max: 14.3070, mean: 2.0439, std: 1.9940\n",
      "\n",
      "Step 7563 — Test metrics:\n",
      "  precision@10: 0.007003171\n",
      "  recall@10: 0.007009044\n",
      "  ndcg@10: 0.007436929\n",
      "  map@10: 0.002384041\n",
      "Epoch 688 completed, Train Loss: 0.3465\n",
      "Epoch 689, Step 1, LR: 0.000080, Current Loss: 0.3434, Avg Loss: 0.3434\n",
      "Diff stats — min: -6.6342, max: 10.1480, mean: 2.0582, std: 1.9905\n",
      "\n",
      "Step 7565 — Test metrics:\n",
      "  precision@10: 0.006989958\n",
      "  recall@10: 0.006995830\n",
      "  ndcg@10: 0.007438109\n",
      "  map@10: 0.002389719\n",
      "Epoch 689, Step 10, LR: 0.000080, Current Loss: 0.3464, Avg Loss: 0.3477\n",
      "Diff stats — min: -5.7318, max: 11.7875, mean: 2.0638, std: 2.0001\n",
      "\n",
      "Step 7574 — Test metrics:\n",
      "  precision@10: 0.006877643\n",
      "  recall@10: 0.006882781\n",
      "  ndcg@10: 0.007229496\n",
      "  map@10: 0.002290438\n",
      "Epoch 689 completed, Train Loss: 0.3476\n",
      "Epoch 690, Step 1, LR: 0.000080, Current Loss: 0.3464, Avg Loss: 0.3464\n",
      "Diff stats — min: -5.6335, max: 10.3827, mean: 2.0451, std: 1.9911\n",
      "\n",
      "Step 7576 — Test metrics:\n",
      "  precision@10: 0.006884249\n",
      "  recall@10: 0.006889388\n",
      "  ndcg@10: 0.007222378\n",
      "  map@10: 0.002283963\n",
      "Epoch 690, Step 10, LR: 0.000080, Current Loss: 0.3444, Avg Loss: 0.3459\n",
      "Diff stats — min: -6.1395, max: 11.9150, mean: 2.0578, std: 1.9921\n",
      "\n",
      "Step 7585 — Test metrics:\n",
      "  precision@10: 0.006877643\n",
      "  recall@10: 0.006882781\n",
      "  ndcg@10: 0.007200651\n",
      "  map@10: 0.002266740\n",
      "Epoch 690 completed, Train Loss: 0.3463\n",
      "Epoch 691, Step 1, LR: 0.000080, Current Loss: 0.3481, Avg Loss: 0.3481\n",
      "Diff stats — min: -7.1286, max: 10.5746, mean: 2.0401, std: 1.9908\n",
      "\n",
      "Step 7587 — Test metrics:\n",
      "  precision@10: 0.006930497\n",
      "  recall@10: 0.006935635\n",
      "  ndcg@10: 0.007264198\n",
      "  map@10: 0.002287667\n",
      "Epoch 691, Step 10, LR: 0.000080, Current Loss: 0.3475, Avg Loss: 0.3481\n",
      "Diff stats — min: -7.7498, max: 10.9530, mean: 2.0452, std: 1.9951\n",
      "\n",
      "Step 7596 — Test metrics:\n",
      "  precision@10: 0.006996564\n",
      "  recall@10: 0.007002437\n",
      "  ndcg@10: 0.007400950\n",
      "  map@10: 0.002360117\n",
      "Epoch 691 completed, Train Loss: 0.3479\n",
      "Epoch 692, Step 1, LR: 0.000080, Current Loss: 0.3479, Avg Loss: 0.3479\n",
      "Diff stats — min: -5.8493, max: 16.6783, mean: 2.0416, std: 1.9978\n",
      "\n",
      "Step 7598 — Test metrics:\n",
      "  precision@10: 0.006989958\n",
      "  recall@10: 0.006995830\n",
      "  ndcg@10: 0.007386627\n",
      "  map@10: 0.002354179\n",
      "Epoch 692, Step 10, LR: 0.000080, Current Loss: 0.3493, Avg Loss: 0.3461\n",
      "Diff stats — min: -8.3384, max: 12.2299, mean: 2.0525, std: 2.0102\n",
      "\n",
      "Step 7607 — Test metrics:\n",
      "  precision@10: 0.006983351\n",
      "  recall@10: 0.006988490\n",
      "  ndcg@10: 0.007363453\n",
      "  map@10: 0.002341919\n",
      "Epoch 692 completed, Train Loss: 0.3459\n",
      "Epoch 693, Step 1, LR: 0.000080, Current Loss: 0.3455, Avg Loss: 0.3455\n",
      "Diff stats — min: -6.6721, max: 13.7432, mean: 2.0540, std: 1.9937\n",
      "\n",
      "Step 7609 — Test metrics:\n",
      "  precision@10: 0.006956924\n",
      "  recall@10: 0.006962062\n",
      "  ndcg@10: 0.007340984\n",
      "  map@10: 0.002336036\n",
      "Epoch 693, Step 10, LR: 0.000080, Current Loss: 0.3437, Avg Loss: 0.3448\n",
      "Diff stats — min: -6.1950, max: 11.7196, mean: 2.0532, std: 1.9883\n",
      "\n",
      "Step 7618 — Test metrics:\n",
      "  precision@10: 0.006930497\n",
      "  recall@10: 0.006935635\n",
      "  ndcg@10: 0.007275842\n",
      "  map@10: 0.002299798\n",
      "Epoch 693 completed, Train Loss: 0.3452\n",
      "Epoch 694, Step 1, LR: 0.000080, Current Loss: 0.3508, Avg Loss: 0.3508\n",
      "Diff stats — min: -5.7534, max: 10.1302, mean: 2.0316, std: 1.9973\n",
      "\n",
      "Step 7620 — Test metrics:\n",
      "  precision@10: 0.006970137\n",
      "  recall@10: 0.006975276\n",
      "  ndcg@10: 0.007312216\n",
      "  map@10: 0.002311143\n",
      "Epoch 694, Step 10, LR: 0.000080, Current Loss: 0.3455, Avg Loss: 0.3453\n",
      "Diff stats — min: -5.6568, max: 11.2745, mean: 2.0588, std: 2.0036\n",
      "\n",
      "Step 7629 — Test metrics:\n",
      "  precision@10: 0.007089059\n",
      "  recall@10: 0.007094932\n",
      "  ndcg@10: 0.007373602\n",
      "  map@10: 0.002313359\n",
      "Epoch 694 completed, Train Loss: 0.3451\n",
      "Epoch 695, Step 1, LR: 0.000080, Current Loss: 0.3428, Avg Loss: 0.3428\n",
      "Diff stats — min: -5.8659, max: 12.2729, mean: 2.0601, std: 1.9908\n",
      "\n",
      "Step 7631 — Test metrics:\n",
      "  precision@10: 0.007049419\n",
      "  recall@10: 0.007055291\n",
      "  ndcg@10: 0.007372192\n",
      "  map@10: 0.002323440\n",
      "Epoch 695, Step 10, LR: 0.000080, Current Loss: 0.3419, Avg Loss: 0.3455\n",
      "Diff stats — min: -6.4036, max: 13.0664, mean: 2.0697, std: 1.9976\n",
      "\n",
      "Step 7640 — Test metrics:\n",
      "  precision@10: 0.006937104\n",
      "  recall@10: 0.006942242\n",
      "  ndcg@10: 0.007340979\n",
      "  map@10: 0.002337148\n",
      "Epoch 695 completed, Train Loss: 0.3453\n",
      "Epoch 696, Step 1, LR: 0.000080, Current Loss: 0.3486, Avg Loss: 0.3486\n",
      "Diff stats — min: -5.9166, max: 11.1014, mean: 2.0549, std: 2.0031\n",
      "\n",
      "Step 7642 — Test metrics:\n",
      "  precision@10: 0.007016385\n",
      "  recall@10: 0.007021523\n",
      "  ndcg@10: 0.007372865\n",
      "  map@10: 0.002334261\n",
      "Epoch 696, Step 10, LR: 0.000080, Current Loss: 0.3488, Avg Loss: 0.3460\n",
      "Diff stats — min: -8.1741, max: 11.8324, mean: 2.0479, std: 2.0061\n",
      "\n",
      "Step 7651 — Test metrics:\n",
      "  precision@10: 0.007029598\n",
      "  recall@10: 0.007035471\n",
      "  ndcg@10: 0.007428724\n",
      "  map@10: 0.002365794\n",
      "Epoch 696 completed, Train Loss: 0.3460\n",
      "Epoch 697, Step 1, LR: 0.000080, Current Loss: 0.3483, Avg Loss: 0.3483\n",
      "Diff stats — min: -7.1461, max: 10.2714, mean: 2.0526, std: 2.0078\n",
      "\n",
      "Step 7653 — Test metrics:\n",
      "  precision@10: 0.007029598\n",
      "  recall@10: 0.007035471\n",
      "  ndcg@10: 0.007386822\n",
      "  map@10: 0.002342444\n",
      "Epoch 697, Step 10, LR: 0.000080, Current Loss: 0.3438, Avg Loss: 0.3452\n",
      "Diff stats — min: -5.7600, max: 12.6019, mean: 2.0469, std: 1.9859\n",
      "\n",
      "Step 7662 — Test metrics:\n",
      "  precision@10: 0.007049419\n",
      "  recall@10: 0.007055291\n",
      "  ndcg@10: 0.007418023\n",
      "  map@10: 0.002354903\n",
      "Epoch 697 completed, Train Loss: 0.3448\n",
      "Epoch 698, Step 1, LR: 0.000080, Current Loss: 0.3393, Avg Loss: 0.3393\n",
      "Diff stats — min: -6.0951, max: 12.7771, mean: 2.0740, std: 1.9851\n",
      "\n",
      "Step 7664 — Test metrics:\n",
      "  precision@10: 0.007029598\n",
      "  recall@10: 0.007035471\n",
      "  ndcg@10: 0.007393641\n",
      "  map@10: 0.002344303\n",
      "Epoch 698, Step 10, LR: 0.000080, Current Loss: 0.3453, Avg Loss: 0.3452\n",
      "Diff stats — min: -6.5973, max: 13.1678, mean: 2.0611, std: 2.0005\n",
      "\n",
      "Step 7673 — Test metrics:\n",
      "  precision@10: 0.007003171\n",
      "  recall@10: 0.007009044\n",
      "  ndcg@10: 0.007382873\n",
      "  map@10: 0.002347416\n",
      "Epoch 698 completed, Train Loss: 0.3447\n",
      "Epoch 699, Step 1, LR: 0.000080, Current Loss: 0.3422, Avg Loss: 0.3422\n",
      "Diff stats — min: -5.9438, max: 10.7795, mean: 2.0727, std: 2.0022\n",
      "\n",
      "Step 7675 — Test metrics:\n",
      "  precision@10: 0.006970137\n",
      "  recall@10: 0.006975276\n",
      "  ndcg@10: 0.007361967\n",
      "  map@10: 0.002343629\n",
      "Epoch 699, Step 10, LR: 0.000080, Current Loss: 0.3457, Avg Loss: 0.3448\n",
      "Diff stats — min: -6.3455, max: 12.7741, mean: 2.0688, std: 2.0129\n",
      "\n",
      "Step 7684 — Test metrics:\n",
      "  precision@10: 0.006963531\n",
      "  recall@10: 0.006968669\n",
      "  ndcg@10: 0.007391087\n",
      "  map@10: 0.002359393\n",
      "Epoch 699 completed, Train Loss: 0.3445\n",
      "Epoch 700, Step 1, LR: 0.000080, Current Loss: 0.3408, Avg Loss: 0.3408\n",
      "Diff stats — min: -6.2191, max: 10.5840, mean: 2.0824, std: 1.9995\n",
      "\n",
      "Step 7686 — Test metrics:\n",
      "  precision@10: 0.006989958\n",
      "  recall@10: 0.006995096\n",
      "  ndcg@10: 0.007408841\n",
      "  map@10: 0.002360665\n",
      "Epoch 700, Step 10, LR: 0.000080, Current Loss: 0.3459, Avg Loss: 0.3450\n",
      "Diff stats — min: -6.3585, max: 10.9265, mean: 2.0627, std: 2.0059\n",
      "\n",
      "Step 7695 — Test metrics:\n",
      "  precision@10: 0.006970137\n",
      "  recall@10: 0.006975276\n",
      "  ndcg@10: 0.007308040\n",
      "  map@10: 0.002304924\n",
      "Epoch 700 completed, Train Loss: 0.3451\n",
      "Epoch 701, Step 1, LR: 0.000080, Current Loss: 0.3453, Avg Loss: 0.3453\n",
      "Diff stats — min: -5.5413, max: 11.6997, mean: 2.0545, std: 1.9973\n",
      "\n",
      "Step 7697 — Test metrics:\n",
      "  precision@10: 0.006983351\n",
      "  recall@10: 0.006988490\n",
      "  ndcg@10: 0.007325425\n",
      "  map@10: 0.002311140\n",
      "Epoch 701, Step 10, LR: 0.000080, Current Loss: 0.3453, Avg Loss: 0.3460\n",
      "Diff stats — min: -6.3461, max: 10.3307, mean: 2.0552, std: 1.9972\n",
      "\n",
      "Step 7706 — Test metrics:\n",
      "  precision@10: 0.007003171\n",
      "  recall@10: 0.007008310\n",
      "  ndcg@10: 0.007317643\n",
      "  map@10: 0.002303331\n",
      "Epoch 701 completed, Train Loss: 0.3453\n",
      "Epoch 702, Step 1, LR: 0.000080, Current Loss: 0.3470, Avg Loss: 0.3470\n",
      "Diff stats — min: -6.2728, max: 13.9416, mean: 2.0515, std: 2.0033\n",
      "\n",
      "Step 7708 — Test metrics:\n",
      "  precision@10: 0.006976744\n",
      "  recall@10: 0.006981883\n",
      "  ndcg@10: 0.007307234\n",
      "  map@10: 0.002301794\n",
      "Epoch 702, Step 10, LR: 0.000080, Current Loss: 0.3435, Avg Loss: 0.3444\n",
      "Diff stats — min: -5.8349, max: 11.1156, mean: 2.0699, std: 2.0022\n",
      "\n",
      "Step 7717 — Test metrics:\n",
      "  precision@10: 0.007042812\n",
      "  recall@10: 0.007047950\n",
      "  ndcg@10: 0.007373220\n",
      "  map@10: 0.002329483\n",
      "Epoch 702 completed, Train Loss: 0.3447\n",
      "Epoch 703, Step 1, LR: 0.000080, Current Loss: 0.3463, Avg Loss: 0.3463\n",
      "Diff stats — min: -5.7649, max: 11.6024, mean: 2.0747, std: 2.0209\n",
      "\n",
      "Step 7719 — Test metrics:\n",
      "  precision@10: 0.007082452\n",
      "  recall@10: 0.007087591\n",
      "  ndcg@10: 0.007418246\n",
      "  map@10: 0.002344932\n",
      "Epoch 703, Step 10, LR: 0.000080, Current Loss: 0.3420, Avg Loss: 0.3454\n",
      "Diff stats — min: -7.0278, max: 12.3325, mean: 2.0741, std: 1.9994\n",
      "\n",
      "Step 7728 — Test metrics:\n",
      "  precision@10: 0.007049419\n",
      "  recall@10: 0.007055291\n",
      "  ndcg@10: 0.007400992\n",
      "  map@10: 0.002341052\n",
      "Epoch 703 completed, Train Loss: 0.3452\n",
      "Epoch 704, Step 1, LR: 0.000080, Current Loss: 0.3463, Avg Loss: 0.3463\n",
      "Diff stats — min: -5.5520, max: 12.7693, mean: 2.0755, std: 2.0177\n",
      "\n",
      "Step 7730 — Test metrics:\n",
      "  precision@10: 0.007029598\n",
      "  recall@10: 0.007035471\n",
      "  ndcg@10: 0.007389087\n",
      "  map@10: 0.002338147\n",
      "Epoch 704, Step 10, LR: 0.000080, Current Loss: 0.3415, Avg Loss: 0.3445\n",
      "Diff stats — min: -6.4309, max: 10.6475, mean: 2.0829, std: 2.0099\n",
      "\n",
      "Step 7739 — Test metrics:\n",
      "  precision@10: 0.007089059\n",
      "  recall@10: 0.007094198\n",
      "  ndcg@10: 0.007400828\n",
      "  map@10: 0.002326780\n",
      "Epoch 704 completed, Train Loss: 0.3448\n",
      "Epoch 705, Step 1, LR: 0.000080, Current Loss: 0.3462, Avg Loss: 0.3462\n",
      "Diff stats — min: -6.5210, max: 12.2334, mean: 2.0672, std: 2.0140\n",
      "\n",
      "Step 7741 — Test metrics:\n",
      "  precision@10: 0.007069239\n",
      "  recall@10: 0.007074377\n",
      "  ndcg@10: 0.007387879\n",
      "  map@10: 0.002326001\n",
      "Epoch 705, Step 10, LR: 0.000080, Current Loss: 0.3435, Avg Loss: 0.3445\n",
      "Diff stats — min: -6.7499, max: 12.0084, mean: 2.0616, std: 1.9947\n",
      "\n",
      "Step 7750 — Test metrics:\n",
      "  precision@10: 0.007075846\n",
      "  recall@10: 0.007080984\n",
      "  ndcg@10: 0.007438741\n",
      "  map@10: 0.002357936\n",
      "Epoch 705 completed, Train Loss: 0.3440\n",
      "Epoch 706, Step 1, LR: 0.000080, Current Loss: 0.3425, Avg Loss: 0.3425\n",
      "Diff stats — min: -5.8562, max: 11.5455, mean: 2.0819, std: 2.0102\n",
      "\n",
      "Step 7752 — Test metrics:\n",
      "  precision@10: 0.007049419\n",
      "  recall@10: 0.007054557\n",
      "  ndcg@10: 0.007410705\n",
      "  map@10: 0.002348891\n",
      "Epoch 706, Step 10, LR: 0.000080, Current Loss: 0.3466, Avg Loss: 0.3441\n",
      "Diff stats — min: -6.0477, max: 12.4555, mean: 2.0752, std: 2.0190\n",
      "\n",
      "Step 7761 — Test metrics:\n",
      "  precision@10: 0.006963531\n",
      "  recall@10: 0.006967935\n",
      "  ndcg@10: 0.007326257\n",
      "  map@10: 0.002320239\n",
      "Epoch 706 completed, Train Loss: 0.3434\n",
      "Epoch 707, Step 1, LR: 0.000080, Current Loss: 0.3431, Avg Loss: 0.3431\n",
      "Diff stats — min: -6.2887, max: 10.3457, mean: 2.0737, std: 2.0062\n",
      "\n",
      "Step 7763 — Test metrics:\n",
      "  precision@10: 0.007016385\n",
      "  recall@10: 0.007020789\n",
      "  ndcg@10: 0.007370961\n",
      "  map@10: 0.002331017\n",
      "Epoch 707, Step 10, LR: 0.000080, Current Loss: 0.3431, Avg Loss: 0.3436\n",
      "Diff stats — min: -5.9007, max: 10.7341, mean: 2.0735, std: 1.9993\n",
      "\n",
      "Step 7772 — Test metrics:\n",
      "  precision@10: 0.007108879\n",
      "  recall@10: 0.007114018\n",
      "  ndcg@10: 0.007498638\n",
      "  map@10: 0.002380731\n",
      "Epoch 707 completed, Train Loss: 0.3433\n",
      "Epoch 708, Step 1, LR: 0.000080, Current Loss: 0.3442, Avg Loss: 0.3442\n",
      "Diff stats — min: -5.7628, max: 11.4251, mean: 2.0808, std: 2.0143\n",
      "\n",
      "Step 7774 — Test metrics:\n",
      "  precision@10: 0.007069239\n",
      "  recall@10: 0.007074377\n",
      "  ndcg@10: 0.007490051\n",
      "  map@10: 0.002386103\n",
      "Epoch 708, Step 10, LR: 0.000080, Current Loss: 0.3438, Avg Loss: 0.3435\n",
      "Diff stats — min: -6.6907, max: 11.4902, mean: 2.0654, std: 2.0063\n",
      "\n",
      "Step 7783 — Test metrics:\n",
      "  precision@10: 0.007056025\n",
      "  recall@10: 0.007061164\n",
      "  ndcg@10: 0.007446410\n",
      "  map@10: 0.002362476\n",
      "Epoch 708 completed, Train Loss: 0.3434\n",
      "Epoch 709, Step 1, LR: 0.000080, Current Loss: 0.3402, Avg Loss: 0.3402\n",
      "Diff stats — min: -6.6020, max: 10.8413, mean: 2.0954, std: 2.0079\n",
      "\n",
      "Step 7785 — Test metrics:\n",
      "  precision@10: 0.007049419\n",
      "  recall@10: 0.007054557\n",
      "  ndcg@10: 0.007435659\n",
      "  map@10: 0.002357516\n",
      "Epoch 709, Step 10, LR: 0.000080, Current Loss: 0.3468, Avg Loss: 0.3427\n",
      "Diff stats — min: -7.1649, max: 11.5675, mean: 2.0656, std: 2.0127\n",
      "\n",
      "Step 7794 — Test metrics:\n",
      "  precision@10: 0.007022992\n",
      "  recall@10: 0.007028130\n",
      "  ndcg@10: 0.007397993\n",
      "  map@10: 0.002346971\n",
      "Epoch 709 completed, Train Loss: 0.3427\n",
      "Epoch 710, Step 1, LR: 0.000080, Current Loss: 0.3409, Avg Loss: 0.3409\n",
      "Diff stats — min: -6.0337, max: 11.7065, mean: 2.0804, std: 2.0022\n",
      "\n",
      "Step 7796 — Test metrics:\n",
      "  precision@10: 0.007036205\n",
      "  recall@10: 0.007041344\n",
      "  ndcg@10: 0.007388694\n",
      "  map@10: 0.002335784\n",
      "Epoch 710, Step 10, LR: 0.000080, Current Loss: 0.3346, Avg Loss: 0.3417\n",
      "Diff stats — min: -6.6110, max: 15.3458, mean: 2.1033, std: 2.0018\n",
      "\n",
      "Step 7805 — Test metrics:\n",
      "  precision@10: 0.007069239\n",
      "  recall@10: 0.007074377\n",
      "  ndcg@10: 0.007412400\n",
      "  map@10: 0.002339680\n",
      "Epoch 710 completed, Train Loss: 0.3418\n",
      "Epoch 711, Step 1, LR: 0.000080, Current Loss: 0.3401, Avg Loss: 0.3401\n",
      "Diff stats — min: -6.0506, max: 11.6662, mean: 2.0887, std: 2.0039\n",
      "\n",
      "Step 7807 — Test metrics:\n",
      "  precision@10: 0.007075846\n",
      "  recall@10: 0.007080984\n",
      "  ndcg@10: 0.007440760\n",
      "  map@10: 0.002357274\n",
      "Epoch 711, Step 10, LR: 0.000080, Current Loss: 0.3407, Avg Loss: 0.3439\n",
      "Diff stats — min: -6.6096, max: 12.6647, mean: 2.0904, std: 2.0103\n",
      "\n",
      "Step 7816 — Test metrics:\n",
      "  precision@10: 0.007016385\n",
      "  recall@10: 0.007020789\n",
      "  ndcg@10: 0.007407991\n",
      "  map@10: 0.002350731\n",
      "Epoch 711 completed, Train Loss: 0.3435\n",
      "Epoch 712, Step 1, LR: 0.000080, Current Loss: 0.3412, Avg Loss: 0.3412\n",
      "Diff stats — min: -5.6543, max: 11.0608, mean: 2.0815, std: 2.0023\n",
      "\n",
      "Step 7818 — Test metrics:\n",
      "  precision@10: 0.007049419\n",
      "  recall@10: 0.007053823\n",
      "  ndcg@10: 0.007404429\n",
      "  map@10: 0.002339321\n",
      "Epoch 712, Step 10, LR: 0.000080, Current Loss: 0.3434, Avg Loss: 0.3430\n",
      "Diff stats — min: -6.6940, max: 10.7688, mean: 2.0757, std: 2.0133\n",
      "\n",
      "Step 7827 — Test metrics:\n",
      "  precision@10: 0.007042812\n",
      "  recall@10: 0.007048685\n",
      "  ndcg@10: 0.007439842\n",
      "  map@10: 0.002362898\n",
      "Epoch 712 completed, Train Loss: 0.3431\n",
      "Epoch 713, Step 1, LR: 0.000080, Current Loss: 0.3445, Avg Loss: 0.3445\n",
      "Diff stats — min: -8.2481, max: 10.8341, mean: 2.0766, std: 2.0136\n",
      "\n",
      "Step 7829 — Test metrics:\n",
      "  precision@10: 0.007062632\n",
      "  recall@10: 0.007068505\n",
      "  ndcg@10: 0.007455732\n",
      "  map@10: 0.002367635\n",
      "Epoch 713, Step 10, LR: 0.000080, Current Loss: 0.3455, Avg Loss: 0.3433\n",
      "Diff stats — min: -7.0459, max: 14.8256, mean: 2.0958, std: 2.0337\n",
      "\n",
      "Step 7838 — Test metrics:\n",
      "  precision@10: 0.007056025\n",
      "  recall@10: 0.007061898\n",
      "  ndcg@10: 0.007456919\n",
      "  map@10: 0.002370460\n",
      "Epoch 713 completed, Train Loss: 0.3430\n",
      "Epoch 714, Step 1, LR: 0.000080, Current Loss: 0.3430, Avg Loss: 0.3430\n",
      "Diff stats — min: -6.3076, max: 10.2121, mean: 2.0856, std: 2.0136\n",
      "\n",
      "Step 7840 — Test metrics:\n",
      "  precision@10: 0.007036205\n",
      "  recall@10: 0.007041344\n",
      "  ndcg@10: 0.007435901\n",
      "  map@10: 0.002363544\n",
      "Epoch 714, Step 10, LR: 0.000080, Current Loss: 0.3456, Avg Loss: 0.3436\n",
      "Diff stats — min: -6.0154, max: 12.1873, mean: 2.0713, std: 2.0178\n",
      "\n",
      "Step 7849 — Test metrics:\n",
      "  precision@10: 0.007089059\n",
      "  recall@10: 0.007094198\n",
      "  ndcg@10: 0.007429664\n",
      "  map@10: 0.002346143\n",
      "Epoch 714 completed, Train Loss: 0.3432\n",
      "Epoch 715, Step 1, LR: 0.000080, Current Loss: 0.3429, Avg Loss: 0.3429\n",
      "Diff stats — min: -6.1057, max: 11.6416, mean: 2.0810, std: 2.0160\n",
      "\n",
      "Step 7851 — Test metrics:\n",
      "  precision@10: 0.007135307\n",
      "  recall@10: 0.007140445\n",
      "  ndcg@10: 0.007455765\n",
      "  map@10: 0.002349022\n",
      "Epoch 715, Step 10, LR: 0.000080, Current Loss: 0.3387, Avg Loss: 0.3412\n",
      "Diff stats — min: -5.4202, max: 13.3522, mean: 2.0926, std: 2.0067\n",
      "\n",
      "Step 7860 — Test metrics:\n",
      "  precision@10: 0.007056025\n",
      "  recall@10: 0.007061898\n",
      "  ndcg@10: 0.007408902\n",
      "  map@10: 0.002339042\n",
      "Epoch 715 completed, Train Loss: 0.3410\n",
      "Epoch 716, Step 1, LR: 0.000080, Current Loss: 0.3387, Avg Loss: 0.3387\n",
      "Diff stats — min: -5.6962, max: 12.6051, mean: 2.0962, std: 2.0084\n",
      "\n",
      "Step 7862 — Test metrics:\n",
      "  precision@10: 0.007003171\n",
      "  recall@10: 0.007008310\n",
      "  ndcg@10: 0.007368205\n",
      "  map@10: 0.002328612\n",
      "Epoch 716, Step 10, LR: 0.000080, Current Loss: 0.3416, Avg Loss: 0.3412\n",
      "Diff stats — min: -5.6106, max: 11.1729, mean: 2.0971, std: 2.0228\n",
      "\n",
      "Step 7871 — Test metrics:\n",
      "  precision@10: 0.006956924\n",
      "  recall@10: 0.006961328\n",
      "  ndcg@10: 0.007342530\n",
      "  map@10: 0.002327909\n",
      "Epoch 716 completed, Train Loss: 0.3413\n",
      "Epoch 717, Step 1, LR: 0.000080, Current Loss: 0.3415, Avg Loss: 0.3415\n",
      "Diff stats — min: -6.0616, max: 11.7684, mean: 2.0978, std: 2.0266\n",
      "\n",
      "Step 7873 — Test metrics:\n",
      "  precision@10: 0.007016385\n",
      "  recall@10: 0.007020789\n",
      "  ndcg@10: 0.007365756\n",
      "  map@10: 0.002324254\n",
      "Epoch 717, Step 10, LR: 0.000080, Current Loss: 0.3446, Avg Loss: 0.3426\n",
      "Diff stats — min: -6.2799, max: 11.2723, mean: 2.0767, std: 2.0147\n",
      "\n",
      "Step 7882 — Test metrics:\n",
      "  precision@10: 0.007029598\n",
      "  recall@10: 0.007034737\n",
      "  ndcg@10: 0.007406172\n",
      "  map@10: 0.002346801\n",
      "Epoch 717 completed, Train Loss: 0.3425\n",
      "Epoch 718, Step 1, LR: 0.000080, Current Loss: 0.3375, Avg Loss: 0.3375\n",
      "Diff stats — min: -6.8163, max: 12.1642, mean: 2.1024, std: 2.0080\n",
      "\n",
      "Step 7884 — Test metrics:\n",
      "  precision@10: 0.007016385\n",
      "  recall@10: 0.007021523\n",
      "  ndcg@10: 0.007389741\n",
      "  map@10: 0.002340624\n",
      "Epoch 718, Step 10, LR: 0.000080, Current Loss: 0.3408, Avg Loss: 0.3418\n",
      "Diff stats — min: -5.9027, max: 13.4949, mean: 2.0931, std: 2.0165\n",
      "\n",
      "Step 7893 — Test metrics:\n",
      "  precision@10: 0.007082452\n",
      "  recall@10: 0.007086123\n",
      "  ndcg@10: 0.007429493\n",
      "  map@10: 0.002346809\n",
      "Epoch 718 completed, Train Loss: 0.3415\n",
      "Epoch 719, Step 1, LR: 0.000080, Current Loss: 0.3379, Avg Loss: 0.3379\n",
      "Diff stats — min: -6.2299, max: 11.9283, mean: 2.1105, std: 2.0194\n",
      "\n",
      "Step 7895 — Test metrics:\n",
      "  precision@10: 0.007062632\n",
      "  recall@10: 0.007067771\n",
      "  ndcg@10: 0.007398050\n",
      "  map@10: 0.002334019\n",
      "Epoch 719, Step 10, LR: 0.000080, Current Loss: 0.3453, Avg Loss: 0.3424\n",
      "Diff stats — min: -5.8762, max: 11.5853, mean: 2.0852, std: 2.0260\n",
      "\n",
      "Step 7904 — Test metrics:\n",
      "  precision@10: 0.007009778\n",
      "  recall@10: 0.007014183\n",
      "  ndcg@10: 0.007327617\n",
      "  map@10: 0.002305770\n",
      "Epoch 719 completed, Train Loss: 0.3425\n",
      "Epoch 720, Step 1, LR: 0.000080, Current Loss: 0.3398, Avg Loss: 0.3398\n",
      "Diff stats — min: -6.7988, max: 11.3519, mean: 2.1053, std: 2.0207\n",
      "\n",
      "Step 7906 — Test metrics:\n",
      "  precision@10: 0.007022992\n",
      "  recall@10: 0.007028130\n",
      "  ndcg@10: 0.007328666\n",
      "  map@10: 0.002301591\n",
      "Epoch 720, Step 10, LR: 0.000080, Current Loss: 0.3421, Avg Loss: 0.3407\n",
      "Diff stats — min: -6.8929, max: 10.6812, mean: 2.0983, std: 2.0244\n",
      "\n",
      "Step 7915 — Test metrics:\n",
      "  precision@10: 0.007089059\n",
      "  recall@10: 0.007093464\n",
      "  ndcg@10: 0.007422063\n",
      "  map@10: 0.002339680\n",
      "Epoch 720 completed, Train Loss: 0.3411\n",
      "Epoch 721, Step 1, LR: 0.000080, Current Loss: 0.3429, Avg Loss: 0.3429\n",
      "Diff stats — min: -6.3839, max: 12.4459, mean: 2.1071, std: 2.0389\n",
      "\n",
      "Step 7917 — Test metrics:\n",
      "  precision@10: 0.007108879\n",
      "  recall@10: 0.007113284\n",
      "  ndcg@10: 0.007462899\n",
      "  map@10: 0.002358569\n",
      "Epoch 721, Step 10, LR: 0.000080, Current Loss: 0.3444, Avg Loss: 0.3414\n",
      "Diff stats — min: -6.2388, max: 11.3111, mean: 2.0971, std: 2.0303\n",
      "\n",
      "Step 7926 — Test metrics:\n",
      "  precision@10: 0.007075846\n",
      "  recall@10: 0.007080250\n",
      "  ndcg@10: 0.007450409\n",
      "  map@10: 0.002355384\n",
      "Epoch 721 completed, Train Loss: 0.3417\n",
      "Epoch 722, Step 1, LR: 0.000080, Current Loss: 0.3429, Avg Loss: 0.3429\n",
      "Diff stats — min: -5.9934, max: 12.7880, mean: 2.0990, std: 2.0340\n",
      "\n",
      "Step 7928 — Test metrics:\n",
      "  precision@10: 0.007075846\n",
      "  recall@10: 0.007080250\n",
      "  ndcg@10: 0.007441647\n",
      "  map@10: 0.002351714\n",
      "Epoch 722, Step 10, LR: 0.000080, Current Loss: 0.3424, Avg Loss: 0.3408\n",
      "Diff stats — min: -6.0585, max: 14.1353, mean: 2.0991, std: 2.0290\n",
      "\n",
      "Step 7937 — Test metrics:\n",
      "  precision@10: 0.007128700\n",
      "  recall@10: 0.007133104\n",
      "  ndcg@10: 0.007457784\n",
      "  map@10: 0.002348384\n",
      "Epoch 722 completed, Train Loss: 0.3404\n",
      "Epoch 723, Step 1, LR: 0.000080, Current Loss: 0.3376, Avg Loss: 0.3376\n",
      "Diff stats — min: -5.9675, max: 12.1034, mean: 2.1021, std: 2.0106\n",
      "\n",
      "Step 7939 — Test metrics:\n",
      "  precision@10: 0.007141913\n",
      "  recall@10: 0.007145584\n",
      "  ndcg@10: 0.007476228\n",
      "  map@10: 0.002358019\n",
      "Epoch 723, Step 10, LR: 0.000080, Current Loss: 0.3434, Avg Loss: 0.3395\n",
      "Diff stats — min: -7.7026, max: 11.9560, mean: 2.0922, std: 2.0251\n",
      "\n",
      "Step 7948 — Test metrics:\n",
      "  precision@10: 0.007075846\n",
      "  recall@10: 0.007079516\n",
      "  ndcg@10: 0.007457643\n",
      "  map@10: 0.002364281\n",
      "Epoch 723 completed, Train Loss: 0.3397\n",
      "Epoch 724, Step 1, LR: 0.000080, Current Loss: 0.3422, Avg Loss: 0.3422\n",
      "Diff stats — min: -6.4813, max: 11.7897, mean: 2.0965, std: 2.0238\n",
      "\n",
      "Step 7950 — Test metrics:\n",
      "  precision@10: 0.007056025\n",
      "  recall@10: 0.007060430\n",
      "  ndcg@10: 0.007448348\n",
      "  map@10: 0.002363721\n",
      "Epoch 724, Step 10, LR: 0.000080, Current Loss: 0.3420, Avg Loss: 0.3408\n",
      "Diff stats — min: -6.9695, max: 13.2528, mean: 2.0928, std: 2.0235\n",
      "\n",
      "Step 7959 — Test metrics:\n",
      "  precision@10: 0.007128700\n",
      "  recall@10: 0.007132370\n",
      "  ndcg@10: 0.007479194\n",
      "  map@10: 0.002361507\n",
      "Epoch 724 completed, Train Loss: 0.3406\n",
      "Epoch 725, Step 1, LR: 0.000080, Current Loss: 0.3341, Avg Loss: 0.3341\n",
      "Diff stats — min: -6.6908, max: 12.9679, mean: 2.1252, std: 2.0152\n",
      "\n",
      "Step 7961 — Test metrics:\n",
      "  precision@10: 0.007115486\n",
      "  recall@10: 0.007119891\n",
      "  ndcg@10: 0.007449171\n",
      "  map@10: 0.002345971\n",
      "Epoch 725, Step 10, LR: 0.000080, Current Loss: 0.3324, Avg Loss: 0.3397\n",
      "Diff stats — min: -5.5891, max: 13.3603, mean: 2.1293, std: 2.0069\n",
      "\n",
      "Step 7970 — Test metrics:\n",
      "  precision@10: 0.007022992\n",
      "  recall@10: 0.007026662\n",
      "  ndcg@10: 0.007412409\n",
      "  map@10: 0.002349523\n",
      "Epoch 725 completed, Train Loss: 0.3400\n",
      "Epoch 726, Step 1, LR: 0.000080, Current Loss: 0.3423, Avg Loss: 0.3423\n",
      "Diff stats — min: -6.2661, max: 12.6518, mean: 2.1036, std: 2.0228\n",
      "\n",
      "Step 7972 — Test metrics:\n",
      "  precision@10: 0.007022992\n",
      "  recall@10: 0.007026662\n",
      "  ndcg@10: 0.007385142\n",
      "  map@10: 0.002334915\n",
      "Epoch 726, Step 10, LR: 0.000080, Current Loss: 0.3411, Avg Loss: 0.3406\n",
      "Diff stats — min: -5.5568, max: 10.4604, mean: 2.1095, std: 2.0320\n",
      "\n",
      "Step 7981 — Test metrics:\n",
      "  precision@10: 0.006976744\n",
      "  recall@10: 0.006980415\n",
      "  ndcg@10: 0.007342691\n",
      "  map@10: 0.002317805\n",
      "Epoch 726 completed, Train Loss: 0.3403\n",
      "Epoch 727, Step 1, LR: 0.000080, Current Loss: 0.3465, Avg Loss: 0.3465\n",
      "Diff stats — min: -6.9262, max: 12.3124, mean: 2.0962, std: 2.0476\n",
      "\n",
      "Step 7983 — Test metrics:\n",
      "  precision@10: 0.007016385\n",
      "  recall@10: 0.007020789\n",
      "  ndcg@10: 0.007372513\n",
      "  map@10: 0.002324847\n",
      "Epoch 727, Step 10, LR: 0.000080, Current Loss: 0.3406, Avg Loss: 0.3400\n",
      "Diff stats — min: -6.5246, max: 12.3965, mean: 2.1057, std: 2.0225\n",
      "\n",
      "Step 7992 — Test metrics:\n",
      "  precision@10: 0.007082452\n",
      "  recall@10: 0.007086857\n",
      "  ndcg@10: 0.007468427\n",
      "  map@10: 0.002365246\n",
      "Epoch 727 completed, Train Loss: 0.3399\n",
      "Epoch 728, Step 1, LR: 0.000080, Current Loss: 0.3402, Avg Loss: 0.3402\n",
      "Diff stats — min: -6.9852, max: 13.4576, mean: 2.1071, std: 2.0289\n",
      "\n",
      "Step 7994 — Test metrics:\n",
      "  precision@10: 0.007036205\n",
      "  recall@10: 0.007039875\n",
      "  ndcg@10: 0.007432531\n",
      "  map@10: 0.002357391\n",
      "Epoch 728, Step 10, LR: 0.000080, Current Loss: 0.3374, Avg Loss: 0.3409\n",
      "Diff stats — min: -5.4152, max: 11.7178, mean: 2.1245, std: 2.0264\n",
      "\n",
      "Step 8003 — Test metrics:\n",
      "  precision@10: 0.007128700\n",
      "  recall@10: 0.007133104\n",
      "  ndcg@10: 0.007473535\n",
      "  map@10: 0.002357553\n",
      "Epoch 728 completed, Train Loss: 0.3409\n",
      "Epoch 729, Step 1, LR: 0.000080, Current Loss: 0.3349, Avg Loss: 0.3349\n",
      "Diff stats — min: -6.3345, max: 13.2723, mean: 2.1290, std: 2.0255\n",
      "\n",
      "Step 8005 — Test metrics:\n",
      "  precision@10: 0.007135307\n",
      "  recall@10: 0.007139711\n",
      "  ndcg@10: 0.007482744\n",
      "  map@10: 0.002361884\n",
      "Epoch 729, Step 10, LR: 0.000080, Current Loss: 0.3366, Avg Loss: 0.3403\n",
      "Diff stats — min: -5.4271, max: 12.5023, mean: 2.1289, std: 2.0304\n",
      "\n",
      "Step 8014 — Test metrics:\n",
      "  precision@10: 0.007155127\n",
      "  recall@10: 0.007158797\n",
      "  ndcg@10: 0.007482913\n",
      "  map@10: 0.002357576\n",
      "Epoch 729 completed, Train Loss: 0.3399\n",
      "Epoch 730, Step 1, LR: 0.000080, Current Loss: 0.3402, Avg Loss: 0.3402\n",
      "Diff stats — min: -5.5160, max: 11.1577, mean: 2.1129, std: 2.0284\n",
      "\n",
      "Step 8016 — Test metrics:\n",
      "  precision@10: 0.007122093\n",
      "  recall@10: 0.007125763\n",
      "  ndcg@10: 0.007465891\n",
      "  map@10: 0.002351800\n",
      "Epoch 730, Step 10, LR: 0.000080, Current Loss: 0.3356, Avg Loss: 0.3408\n",
      "Diff stats — min: -6.1666, max: 10.7462, mean: 2.1254, std: 2.0205\n",
      "\n",
      "Step 8025 — Test metrics:\n",
      "  precision@10: 0.007082452\n",
      "  recall@10: 0.007086123\n",
      "  ndcg@10: 0.007453068\n",
      "  map@10: 0.002356984\n",
      "Epoch 730 completed, Train Loss: 0.3412\n",
      "Epoch 731, Step 1, LR: 0.000080, Current Loss: 0.3405, Avg Loss: 0.3405\n",
      "Diff stats — min: -6.4628, max: 10.7274, mean: 2.1038, std: 2.0297\n",
      "\n",
      "Step 8027 — Test metrics:\n",
      "  precision@10: 0.007082452\n",
      "  recall@10: 0.007086123\n",
      "  ndcg@10: 0.007445278\n",
      "  map@10: 0.002352178\n",
      "Epoch 731, Step 10, LR: 0.000080, Current Loss: 0.3440, Avg Loss: 0.3401\n",
      "Diff stats — min: -6.1664, max: 14.3291, mean: 2.1002, std: 2.0385\n",
      "\n",
      "Step 8036 — Test metrics:\n",
      "  precision@10: 0.007042812\n",
      "  recall@10: 0.007046482\n",
      "  ndcg@10: 0.007390796\n",
      "  map@10: 0.002329464\n",
      "Epoch 731 completed, Train Loss: 0.3400\n",
      "Epoch 732, Step 1, LR: 0.000080, Current Loss: 0.3387, Avg Loss: 0.3387\n",
      "Diff stats — min: -6.7080, max: 11.5693, mean: 2.1245, std: 2.0326\n",
      "\n",
      "Step 8038 — Test metrics:\n",
      "  precision@10: 0.007042812\n",
      "  recall@10: 0.007046482\n",
      "  ndcg@10: 0.007355651\n",
      "  map@10: 0.002308353\n",
      "Epoch 732, Step 10, LR: 0.000080, Current Loss: 0.3418, Avg Loss: 0.3406\n",
      "Diff stats — min: -6.2242, max: 10.8869, mean: 2.1084, std: 2.0361\n",
      "\n",
      "Step 8047 — Test metrics:\n",
      "  precision@10: 0.007241015\n",
      "  recall@10: 0.007244685\n",
      "  ndcg@10: 0.007521530\n",
      "  map@10: 0.002355845\n",
      "Epoch 732 completed, Train Loss: 0.3401\n",
      "Epoch 733, Step 1, LR: 0.000080, Current Loss: 0.3379, Avg Loss: 0.3379\n",
      "Diff stats — min: -9.1474, max: 10.2902, mean: 2.1206, std: 2.0297\n",
      "\n",
      "Step 8049 — Test metrics:\n",
      "  precision@10: 0.007194767\n",
      "  recall@10: 0.007198438\n",
      "  ndcg@10: 0.007513289\n",
      "  map@10: 0.002363618\n",
      "Epoch 733, Step 10, LR: 0.000080, Current Loss: 0.3437, Avg Loss: 0.3385\n",
      "Diff stats — min: -5.7234, max: 12.1591, mean: 2.1084, std: 2.0441\n",
      "\n",
      "Step 8058 — Test metrics:\n",
      "  precision@10: 0.007174947\n",
      "  recall@10: 0.007179352\n",
      "  ndcg@10: 0.007571555\n",
      "  map@10: 0.002401200\n",
      "Epoch 733 completed, Train Loss: 0.3388\n",
      "Epoch 734, Step 1, LR: 0.000080, Current Loss: 0.3371, Avg Loss: 0.3371\n",
      "Diff stats — min: -6.1729, max: 12.3266, mean: 2.1163, std: 2.0234\n",
      "\n",
      "Step 8060 — Test metrics:\n",
      "  precision@10: 0.007148520\n",
      "  recall@10: 0.007152191\n",
      "  ndcg@10: 0.007562247\n",
      "  map@10: 0.002401865\n",
      "Epoch 734, Step 10, LR: 0.000080, Current Loss: 0.3350, Avg Loss: 0.3396\n",
      "Diff stats — min: -6.5351, max: 11.2995, mean: 2.1251, std: 2.0207\n",
      "\n",
      "Step 8069 — Test metrics:\n",
      "  precision@10: 0.007214588\n",
      "  recall@10: 0.007218258\n",
      "  ndcg@10: 0.007606662\n",
      "  map@10: 0.002409966\n",
      "Epoch 734 completed, Train Loss: 0.3395\n",
      "Epoch 735, Step 1, LR: 0.000080, Current Loss: 0.3407, Avg Loss: 0.3407\n",
      "Diff stats — min: -6.6041, max: 11.1145, mean: 2.1130, std: 2.0302\n",
      "\n",
      "Step 8071 — Test metrics:\n",
      "  precision@10: 0.007214588\n",
      "  recall@10: 0.007218258\n",
      "  ndcg@10: 0.007611714\n",
      "  map@10: 0.002414604\n",
      "Epoch 735, Step 10, LR: 0.000080, Current Loss: 0.3398, Avg Loss: 0.3391\n",
      "Diff stats — min: -7.0814, max: 11.5747, mean: 2.1132, std: 2.0334\n",
      "\n",
      "Step 8080 — Test metrics:\n",
      "  precision@10: 0.007201374\n",
      "  recall@10: 0.007205045\n",
      "  ndcg@10: 0.007582523\n",
      "  map@10: 0.002398477\n",
      "Epoch 735 completed, Train Loss: 0.3394\n",
      "Epoch 736, Step 1, LR: 0.000080, Current Loss: 0.3388, Avg Loss: 0.3388\n",
      "Diff stats — min: -6.3677, max: 10.8406, mean: 2.1205, std: 2.0342\n",
      "\n",
      "Step 8082 — Test metrics:\n",
      "  precision@10: 0.007128700\n",
      "  recall@10: 0.007132370\n",
      "  ndcg@10: 0.007486830\n",
      "  map@10: 0.002361152\n",
      "Epoch 736, Step 10, LR: 0.000080, Current Loss: 0.3428, Avg Loss: 0.3397\n",
      "Diff stats — min: -6.0683, max: 11.4278, mean: 2.1047, std: 2.0407\n",
      "\n",
      "Step 8091 — Test metrics:\n",
      "  precision@10: 0.007148520\n",
      "  recall@10: 0.007152191\n",
      "  ndcg@10: 0.007505559\n",
      "  map@10: 0.002370983\n",
      "Epoch 736 completed, Train Loss: 0.3396\n",
      "Epoch 737, Step 1, LR: 0.000080, Current Loss: 0.3386, Avg Loss: 0.3386\n",
      "Diff stats — min: -7.7481, max: 12.7827, mean: 2.1228, std: 2.0302\n",
      "\n",
      "Step 8093 — Test metrics:\n",
      "  precision@10: 0.007174947\n",
      "  recall@10: 0.007178618\n",
      "  ndcg@10: 0.007538678\n",
      "  map@10: 0.002383509\n",
      "Epoch 737, Step 10, LR: 0.000080, Current Loss: 0.3379, Avg Loss: 0.3389\n",
      "Diff stats — min: -6.9271, max: 11.3516, mean: 2.1215, std: 2.0297\n",
      "\n",
      "Step 8102 — Test metrics:\n",
      "  precision@10: 0.007128700\n",
      "  recall@10: 0.007132370\n",
      "  ndcg@10: 0.007572186\n",
      "  map@10: 0.002412504\n",
      "Epoch 737 completed, Train Loss: 0.3387\n",
      "Epoch 738, Step 1, LR: 0.000080, Current Loss: 0.3424, Avg Loss: 0.3424\n",
      "Diff stats — min: -8.0685, max: 12.8260, mean: 2.1037, std: 2.0307\n",
      "\n",
      "Step 8104 — Test metrics:\n",
      "  precision@10: 0.007148520\n",
      "  recall@10: 0.007152191\n",
      "  ndcg@10: 0.007577603\n",
      "  map@10: 0.002411084\n",
      "Epoch 738, Step 10, LR: 0.000080, Current Loss: 0.3373, Avg Loss: 0.3384\n",
      "Diff stats — min: -6.7804, max: 12.0603, mean: 2.1325, std: 2.0333\n",
      "\n",
      "Step 8113 — Test metrics:\n",
      "  precision@10: 0.007221195\n",
      "  recall@10: 0.007224865\n",
      "  ndcg@10: 0.007536797\n",
      "  map@10: 0.002368611\n",
      "Epoch 738 completed, Train Loss: 0.3384\n",
      "Epoch 739, Step 1, LR: 0.000080, Current Loss: 0.3317, Avg Loss: 0.3317\n",
      "Diff stats — min: -6.2545, max: 13.1119, mean: 2.1488, std: 2.0345\n",
      "\n",
      "Step 8115 — Test metrics:\n",
      "  precision@10: 0.007247622\n",
      "  recall@10: 0.007251292\n",
      "  ndcg@10: 0.007568989\n",
      "  map@10: 0.002380322\n",
      "Epoch 739, Step 10, LR: 0.000080, Current Loss: 0.3335, Avg Loss: 0.3378\n",
      "Diff stats — min: -5.4678, max: 11.4048, mean: 2.1349, std: 2.0268\n",
      "\n",
      "Step 8124 — Test metrics:\n",
      "  precision@10: 0.007207981\n",
      "  recall@10: 0.007211651\n",
      "  ndcg@10: 0.007535031\n",
      "  map@10: 0.002370361\n",
      "Epoch 739 completed, Train Loss: 0.3380\n",
      "Epoch 740, Step 1, LR: 0.000080, Current Loss: 0.3361, Avg Loss: 0.3361\n",
      "Diff stats — min: -5.3609, max: 13.9692, mean: 2.1245, std: 2.0250\n",
      "\n",
      "Step 8126 — Test metrics:\n",
      "  precision@10: 0.007214588\n",
      "  recall@10: 0.007218258\n",
      "  ndcg@10: 0.007554426\n",
      "  map@10: 0.002381253\n",
      "Epoch 740, Step 10, LR: 0.000080, Current Loss: 0.3375, Avg Loss: 0.3376\n",
      "Diff stats — min: -6.2725, max: 12.5428, mean: 2.1292, std: 2.0388\n",
      "\n",
      "Step 8135 — Test metrics:\n",
      "  precision@10: 0.007141913\n",
      "  recall@10: 0.007145584\n",
      "  ndcg@10: 0.007510460\n",
      "  map@10: 0.002374716\n",
      "Epoch 740 completed, Train Loss: 0.3380\n",
      "Epoch 741, Step 1, LR: 0.000080, Current Loss: 0.3418, Avg Loss: 0.3418\n",
      "Diff stats — min: -6.1088, max: 16.0052, mean: 2.1212, std: 2.0536\n",
      "\n",
      "Step 8137 — Test metrics:\n",
      "  precision@10: 0.007108879\n",
      "  recall@10: 0.007112550\n",
      "  ndcg@10: 0.007478444\n",
      "  map@10: 0.002364431\n",
      "Epoch 741, Step 10, LR: 0.000080, Current Loss: 0.3379, Avg Loss: 0.3378\n",
      "Diff stats — min: -6.0229, max: 14.9480, mean: 2.1329, std: 2.0406\n",
      "\n",
      "Step 8146 — Test metrics:\n",
      "  precision@10: 0.007241015\n",
      "  recall@10: 0.007244685\n",
      "  ndcg@10: 0.007542962\n",
      "  map@10: 0.002366910\n",
      "Epoch 741 completed, Train Loss: 0.3378\n",
      "Epoch 742, Step 1, LR: 0.000080, Current Loss: 0.3390, Avg Loss: 0.3390\n",
      "Diff stats — min: -5.9251, max: 10.8539, mean: 2.1296, std: 2.0413\n",
      "\n",
      "Step 8148 — Test metrics:\n",
      "  precision@10: 0.007274049\n",
      "  recall@10: 0.007277719\n",
      "  ndcg@10: 0.007571557\n",
      "  map@10: 0.002374592\n",
      "Epoch 742, Step 10, LR: 0.000080, Current Loss: 0.3352, Avg Loss: 0.3386\n",
      "Diff stats — min: -5.6933, max: 10.8724, mean: 2.1276, std: 2.0283\n",
      "\n",
      "Step 8157 — Test metrics:\n",
      "  precision@10: 0.007267442\n",
      "  recall@10: 0.007271112\n",
      "  ndcg@10: 0.007583525\n",
      "  map@10: 0.002381400\n",
      "Epoch 742 completed, Train Loss: 0.3390\n",
      "Epoch 743, Step 1, LR: 0.000080, Current Loss: 0.3355, Avg Loss: 0.3355\n",
      "Diff stats — min: -5.8550, max: 11.6471, mean: 2.1416, std: 2.0395\n",
      "\n",
      "Step 8159 — Test metrics:\n",
      "  precision@10: 0.007234408\n",
      "  recall@10: 0.007238078\n",
      "  ndcg@10: 0.007545292\n",
      "  map@10: 0.002367064\n",
      "Epoch 743, Step 10, LR: 0.000080, Current Loss: 0.3382, Avg Loss: 0.3378\n",
      "Diff stats — min: -5.8269, max: 13.0711, mean: 2.1322, std: 2.0443\n",
      "\n",
      "Step 8168 — Test metrics:\n",
      "  precision@10: 0.007201374\n",
      "  recall@10: 0.007205045\n",
      "  ndcg@10: 0.007579566\n",
      "  map@10: 0.002396967\n",
      "Epoch 743 completed, Train Loss: 0.3375\n",
      "Epoch 744, Step 1, LR: 0.000080, Current Loss: 0.3356, Avg Loss: 0.3356\n",
      "Diff stats — min: -5.8651, max: 12.4666, mean: 2.1444, std: 2.0406\n",
      "\n",
      "Step 8170 — Test metrics:\n",
      "  precision@10: 0.007227801\n",
      "  recall@10: 0.007231472\n",
      "  ndcg@10: 0.007608174\n",
      "  map@10: 0.002407105\n",
      "Epoch 744, Step 10, LR: 0.000080, Current Loss: 0.3370, Avg Loss: 0.3378\n",
      "Diff stats — min: -7.1416, max: 12.0624, mean: 2.1285, std: 2.0299\n",
      "\n",
      "Step 8179 — Test metrics:\n",
      "  precision@10: 0.007247622\n",
      "  recall@10: 0.007251292\n",
      "  ndcg@10: 0.007588470\n",
      "  map@10: 0.002392423\n",
      "Epoch 744 completed, Train Loss: 0.3382\n",
      "Epoch 745, Step 1, LR: 0.000080, Current Loss: 0.3400, Avg Loss: 0.3400\n",
      "Diff stats — min: -7.1234, max: 12.7036, mean: 2.1316, std: 2.0487\n",
      "\n",
      "Step 8181 — Test metrics:\n",
      "  precision@10: 0.007260835\n",
      "  recall@10: 0.007264506\n",
      "  ndcg@10: 0.007637894\n",
      "  map@10: 0.002418329\n",
      "Epoch 745, Step 10, LR: 0.000080, Current Loss: 0.3404, Avg Loss: 0.3376\n",
      "Diff stats — min: -5.5595, max: 11.1549, mean: 2.1217, std: 2.0408\n",
      "\n",
      "Step 8190 — Test metrics:\n",
      "  precision@10: 0.007135307\n",
      "  recall@10: 0.007138977\n",
      "  ndcg@10: 0.007587551\n",
      "  map@10: 0.002420243\n",
      "Epoch 745 completed, Train Loss: 0.3381\n",
      "Epoch 746, Step 1, LR: 0.000080, Current Loss: 0.3358, Avg Loss: 0.3358\n",
      "Diff stats — min: -6.0792, max: 12.8611, mean: 2.1423, std: 2.0383\n",
      "\n",
      "Step 8192 — Test metrics:\n",
      "  precision@10: 0.007188161\n",
      "  recall@10: 0.007191831\n",
      "  ndcg@10: 0.007594261\n",
      "  map@10: 0.002408548\n",
      "Epoch 746, Step 10, LR: 0.000080, Current Loss: 0.3369, Avg Loss: 0.3377\n",
      "Diff stats — min: -5.9671, max: 11.5604, mean: 2.1530, std: 2.0546\n",
      "\n",
      "Step 8201 — Test metrics:\n",
      "  precision@10: 0.007260835\n",
      "  recall@10: 0.007264506\n",
      "  ndcg@10: 0.007698833\n",
      "  map@10: 0.002453256\n",
      "Epoch 746 completed, Train Loss: 0.3376\n",
      "Epoch 747, Step 1, LR: 0.000080, Current Loss: 0.3309, Avg Loss: 0.3309\n",
      "Diff stats — min: -5.9842, max: 12.6352, mean: 2.1599, std: 2.0393\n",
      "\n",
      "Step 8203 — Test metrics:\n",
      "  precision@10: 0.007280655\n",
      "  recall@10: 0.007284326\n",
      "  ndcg@10: 0.007685269\n",
      "  map@10: 0.002440701\n",
      "Epoch 747, Step 10, LR: 0.000080, Current Loss: 0.3364, Avg Loss: 0.3366\n",
      "Diff stats — min: -7.1485, max: 12.0952, mean: 2.1438, std: 2.0463\n",
      "\n",
      "Step 8212 — Test metrics:\n",
      "  precision@10: 0.007247622\n",
      "  recall@10: 0.007251292\n",
      "  ndcg@10: 0.007581644\n",
      "  map@10: 0.002387260\n",
      "Epoch 747 completed, Train Loss: 0.3369\n",
      "Epoch 748, Step 1, LR: 0.000080, Current Loss: 0.3417, Avg Loss: 0.3417\n",
      "Diff stats — min: -5.9354, max: 12.8411, mean: 2.1120, std: 2.0434\n",
      "\n",
      "Step 8214 — Test metrics:\n",
      "  precision@10: 0.007274049\n",
      "  recall@10: 0.007277719\n",
      "  ndcg@10: 0.007604647\n",
      "  map@10: 0.002393681\n",
      "Epoch 748, Step 10, LR: 0.000080, Current Loss: 0.3363, Avg Loss: 0.3382\n",
      "Diff stats — min: -6.6764, max: 11.9913, mean: 2.1335, std: 2.0362\n",
      "\n",
      "Step 8223 — Test metrics:\n",
      "  precision@10: 0.007207981\n",
      "  recall@10: 0.007211651\n",
      "  ndcg@10: 0.007578068\n",
      "  map@10: 0.002394176\n",
      "Epoch 748 completed, Train Loss: 0.3385\n",
      "Epoch 749, Step 1, LR: 0.000080, Current Loss: 0.3371, Avg Loss: 0.3371\n",
      "Diff stats — min: -5.7985, max: 12.2873, mean: 2.1344, std: 2.0383\n",
      "\n",
      "Step 8225 — Test metrics:\n",
      "  precision@10: 0.007254228\n",
      "  recall@10: 0.007257899\n",
      "  ndcg@10: 0.007618126\n",
      "  map@10: 0.002406038\n",
      "Epoch 749, Step 10, LR: 0.000080, Current Loss: 0.3369, Avg Loss: 0.3378\n",
      "Diff stats — min: -6.5762, max: 13.5080, mean: 2.1515, std: 2.0562\n",
      "\n",
      "Step 8234 — Test metrics:\n",
      "  precision@10: 0.007221195\n",
      "  recall@10: 0.007224865\n",
      "  ndcg@10: 0.007563131\n",
      "  map@10: 0.002383251\n",
      "Epoch 749 completed, Train Loss: 0.3381\n",
      "Epoch 750, Step 1, LR: 0.000080, Current Loss: 0.3328, Avg Loss: 0.3328\n",
      "Diff stats — min: -11.4946, max: 12.8150, mean: 2.1453, std: 2.0246\n",
      "\n",
      "Step 8236 — Test metrics:\n",
      "  precision@10: 0.007267442\n",
      "  recall@10: 0.007271112\n",
      "  ndcg@10: 0.007594304\n",
      "  map@10: 0.002388496\n",
      "Epoch 750, Step 10, LR: 0.000080, Current Loss: 0.3384, Avg Loss: 0.3378\n",
      "Diff stats — min: -6.3686, max: 14.6694, mean: 2.1375, std: 2.0501\n",
      "\n",
      "Step 8245 — Test metrics:\n",
      "  precision@10: 0.007326903\n",
      "  recall@10: 0.007330573\n",
      "  ndcg@10: 0.007737202\n",
      "  map@10: 0.002456380\n",
      "Epoch 750 completed, Train Loss: 0.3377\n",
      "Epoch 751, Step 1, LR: 0.000080, Current Loss: 0.3403, Avg Loss: 0.3403\n",
      "Diff stats — min: -6.2868, max: 15.8701, mean: 2.1357, std: 2.0564\n",
      "\n",
      "Step 8247 — Test metrics:\n",
      "  precision@10: 0.007340116\n",
      "  recall@10: 0.007343787\n",
      "  ndcg@10: 0.007751660\n",
      "  map@10: 0.002463680\n",
      "Epoch 751, Step 10, LR: 0.000080, Current Loss: 0.3379, Avg Loss: 0.3369\n",
      "Diff stats — min: -6.5448, max: 11.8977, mean: 2.1436, std: 2.0513\n",
      "\n",
      "Step 8256 — Test metrics:\n",
      "  precision@10: 0.007214588\n",
      "  recall@10: 0.007218258\n",
      "  ndcg@10: 0.007593228\n",
      "  map@10: 0.002401149\n",
      "Epoch 751 completed, Train Loss: 0.3371\n",
      "Epoch 752, Step 1, LR: 0.000080, Current Loss: 0.3355, Avg Loss: 0.3355\n",
      "Diff stats — min: -6.6876, max: 13.9869, mean: 2.1481, std: 2.0516\n",
      "\n",
      "Step 8258 — Test metrics:\n",
      "  precision@10: 0.007227801\n",
      "  recall@10: 0.007231472\n",
      "  ndcg@10: 0.007600872\n",
      "  map@10: 0.002403930\n",
      "Epoch 752, Step 10, LR: 0.000080, Current Loss: 0.3373, Avg Loss: 0.3376\n",
      "Diff stats — min: -6.4075, max: 12.1372, mean: 2.1363, std: 2.0434\n",
      "\n",
      "Step 8267 — Test metrics:\n",
      "  precision@10: 0.007260835\n",
      "  recall@10: 0.007264506\n",
      "  ndcg@10: 0.007612945\n",
      "  map@10: 0.002398759\n",
      "Epoch 752 completed, Train Loss: 0.3379\n",
      "Epoch 753, Step 1, LR: 0.000080, Current Loss: 0.3423, Avg Loss: 0.3423\n",
      "Diff stats — min: -6.4830, max: 13.8601, mean: 2.1199, std: 2.0501\n",
      "\n",
      "Step 8269 — Test metrics:\n",
      "  precision@10: 0.007287262\n",
      "  recall@10: 0.007290933\n",
      "  ndcg@10: 0.007644481\n",
      "  map@10: 0.002409659\n",
      "Epoch 753, Step 10, LR: 0.000080, Current Loss: 0.3349, Avg Loss: 0.3370\n",
      "Diff stats — min: -6.1077, max: 15.7269, mean: 2.1612, std: 2.0529\n",
      "\n",
      "Step 8278 — Test metrics:\n",
      "  precision@10: 0.007201374\n",
      "  recall@10: 0.007205045\n",
      "  ndcg@10: 0.007576437\n",
      "  map@10: 0.002396671\n",
      "Epoch 753 completed, Train Loss: 0.3371\n",
      "Epoch 754, Step 1, LR: 0.000080, Current Loss: 0.3337, Avg Loss: 0.3337\n",
      "Diff stats — min: -6.4905, max: 12.9253, mean: 2.1502, std: 2.0415\n",
      "\n",
      "Step 8280 — Test metrics:\n",
      "  precision@10: 0.007194767\n",
      "  recall@10: 0.007198438\n",
      "  ndcg@10: 0.007573733\n",
      "  map@10: 0.002396150\n",
      "Epoch 754, Step 10, LR: 0.000080, Current Loss: 0.3371, Avg Loss: 0.3371\n",
      "Diff stats — min: -6.3167, max: 13.7106, mean: 2.1389, std: 2.0429\n",
      "\n",
      "Step 8289 — Test metrics:\n",
      "  precision@10: 0.007241015\n",
      "  recall@10: 0.007244685\n",
      "  ndcg@10: 0.007606095\n",
      "  map@10: 0.002400577\n",
      "Epoch 754 completed, Train Loss: 0.3373\n",
      "Epoch 755, Step 1, LR: 0.000080, Current Loss: 0.3412, Avg Loss: 0.3412\n",
      "Diff stats — min: -6.0807, max: 10.5855, mean: 2.1423, std: 2.0611\n",
      "\n",
      "Step 8291 — Test metrics:\n",
      "  precision@10: 0.007260835\n",
      "  recall@10: 0.007264506\n",
      "  ndcg@10: 0.007604667\n",
      "  map@10: 0.002393334\n",
      "Epoch 755, Step 10, LR: 0.000080, Current Loss: 0.3365, Avg Loss: 0.3377\n",
      "Diff stats — min: -7.8718, max: 14.4658, mean: 2.1343, std: 2.0387\n",
      "\n",
      "Step 8300 — Test metrics:\n",
      "  precision@10: 0.007293869\n",
      "  recall@10: 0.007297539\n",
      "  ndcg@10: 0.007664947\n",
      "  map@10: 0.002418126\n",
      "Epoch 755 completed, Train Loss: 0.3377\n",
      "Epoch 756, Step 1, LR: 0.000080, Current Loss: 0.3415, Avg Loss: 0.3415\n",
      "Diff stats — min: -5.4875, max: 12.1689, mean: 2.1336, std: 2.0574\n",
      "\n",
      "Step 8302 — Test metrics:\n",
      "  precision@10: 0.007260835\n",
      "  recall@10: 0.007264506\n",
      "  ndcg@10: 0.007620860\n",
      "  map@10: 0.002402886\n",
      "Epoch 756, Step 10, LR: 0.000080, Current Loss: 0.3354, Avg Loss: 0.3368\n",
      "Diff stats — min: -6.4180, max: 13.5587, mean: 2.1501, std: 2.0505\n",
      "\n",
      "Step 8311 — Test metrics:\n",
      "  precision@10: 0.007280655\n",
      "  recall@10: 0.007284326\n",
      "  ndcg@10: 0.007707892\n",
      "  map@10: 0.002448088\n",
      "Epoch 756 completed, Train Loss: 0.3368\n",
      "Epoch 757, Step 1, LR: 0.000080, Current Loss: 0.3381, Avg Loss: 0.3381\n",
      "Diff stats — min: -6.3797, max: 13.9332, mean: 2.1408, std: 2.0536\n",
      "\n",
      "Step 8313 — Test metrics:\n",
      "  precision@10: 0.007300476\n",
      "  recall@10: 0.007304146\n",
      "  ndcg@10: 0.007717061\n",
      "  map@10: 0.002449108\n",
      "Epoch 757, Step 10, LR: 0.000080, Current Loss: 0.3399, Avg Loss: 0.3369\n",
      "Diff stats — min: -5.3703, max: 13.4422, mean: 2.1414, std: 2.0644\n",
      "\n",
      "Step 8322 — Test metrics:\n",
      "  precision@10: 0.007254228\n",
      "  recall@10: 0.007257899\n",
      "  ndcg@10: 0.007598362\n",
      "  map@10: 0.002392332\n",
      "Epoch 757 completed, Train Loss: 0.3370\n",
      "Epoch 758, Step 1, LR: 0.000080, Current Loss: 0.3377, Avg Loss: 0.3377\n",
      "Diff stats — min: -6.6107, max: 12.1937, mean: 2.1357, std: 2.0446\n",
      "\n",
      "Step 8324 — Test metrics:\n",
      "  precision@10: 0.007241015\n",
      "  recall@10: 0.007244685\n",
      "  ndcg@10: 0.007593074\n",
      "  map@10: 0.002392256\n",
      "Epoch 758, Step 10, LR: 0.000080, Current Loss: 0.3370, Avg Loss: 0.3365\n",
      "Diff stats — min: -6.7264, max: 11.6630, mean: 2.1606, std: 2.0611\n",
      "\n",
      "Step 8333 — Test metrics:\n",
      "  precision@10: 0.007274049\n",
      "  recall@10: 0.007277719\n",
      "  ndcg@10: 0.007596281\n",
      "  map@10: 0.002384509\n",
      "Epoch 758 completed, Train Loss: 0.3369\n",
      "Epoch 759, Step 1, LR: 0.000080, Current Loss: 0.3334, Avg Loss: 0.3334\n",
      "Diff stats — min: -6.0494, max: 12.8885, mean: 2.1571, std: 2.0519\n",
      "\n",
      "Step 8335 — Test metrics:\n",
      "  precision@10: 0.007234408\n",
      "  recall@10: 0.007238078\n",
      "  ndcg@10: 0.007579972\n",
      "  map@10: 0.002386046\n",
      "Epoch 759, Step 10, LR: 0.000080, Current Loss: 0.3423, Avg Loss: 0.3367\n",
      "Diff stats — min: -6.1567, max: 11.5004, mean: 2.1304, std: 2.0578\n",
      "\n",
      "Step 8344 — Test metrics:\n",
      "  precision@10: 0.007247622\n",
      "  recall@10: 0.007251292\n",
      "  ndcg@10: 0.007633904\n",
      "  map@10: 0.002414953\n",
      "Epoch 759 completed, Train Loss: 0.3369\n",
      "Epoch 760, Step 1, LR: 0.000080, Current Loss: 0.3392, Avg Loss: 0.3392\n",
      "Diff stats — min: -8.1581, max: 12.8932, mean: 2.1512, std: 2.0607\n",
      "\n",
      "Step 8346 — Test metrics:\n",
      "  precision@10: 0.007274049\n",
      "  recall@10: 0.007277719\n",
      "  ndcg@10: 0.007668647\n",
      "  map@10: 0.002426644\n",
      "Epoch 760, Step 10, LR: 0.000080, Current Loss: 0.3329, Avg Loss: 0.3368\n",
      "Diff stats — min: -5.7767, max: 13.7880, mean: 2.1688, std: 2.0593\n",
      "\n",
      "Step 8355 — Test metrics:\n",
      "  precision@10: 0.007379757\n",
      "  recall@10: 0.007383427\n",
      "  ndcg@10: 0.007797790\n",
      "  map@10: 0.002477750\n",
      "Epoch 760 completed, Train Loss: 0.3370\n",
      "Epoch 761, Step 1, LR: 0.000080, Current Loss: 0.3330, Avg Loss: 0.3330\n",
      "Diff stats — min: -6.6376, max: 16.0499, mean: 2.1636, std: 2.0531\n",
      "\n",
      "Step 8357 — Test metrics:\n",
      "  precision@10: 0.007313689\n",
      "  recall@10: 0.007317360\n",
      "  ndcg@10: 0.007704248\n",
      "  map@10: 0.002437018\n",
      "Epoch 761, Step 10, LR: 0.000080, Current Loss: 0.3335, Avg Loss: 0.3344\n",
      "Diff stats — min: -6.6759, max: 12.7031, mean: 2.1730, std: 2.0612\n",
      "\n",
      "Step 8366 — Test metrics:\n",
      "  precision@10: 0.007181554\n",
      "  recall@10: 0.007185224\n",
      "  ndcg@10: 0.007566104\n",
      "  map@10: 0.002391813\n",
      "Epoch 761 completed, Train Loss: 0.3342\n",
      "Epoch 762, Step 1, LR: 0.000080, Current Loss: 0.3280, Avg Loss: 0.3280\n",
      "Diff stats — min: -6.2414, max: 13.2783, mean: 2.1808, std: 2.0456\n",
      "\n",
      "Step 8368 — Test metrics:\n",
      "  precision@10: 0.007168340\n",
      "  recall@10: 0.007172011\n",
      "  ndcg@10: 0.007567764\n",
      "  map@10: 0.002396016\n",
      "Epoch 762, Step 10, LR: 0.000080, Current Loss: 0.3322, Avg Loss: 0.3346\n",
      "Diff stats — min: -6.2581, max: 11.9536, mean: 2.1598, std: 2.0388\n",
      "\n",
      "Step 8377 — Test metrics:\n",
      "  precision@10: 0.007267442\n",
      "  recall@10: 0.007271112\n",
      "  ndcg@10: 0.007672562\n",
      "  map@10: 0.002436085\n",
      "Epoch 762 completed, Train Loss: 0.3351\n",
      "Epoch 763, Step 1, LR: 0.000080, Current Loss: 0.3332, Avg Loss: 0.3332\n",
      "Diff stats — min: -8.3214, max: 11.8736, mean: 2.1651, std: 2.0479\n",
      "\n",
      "Step 8379 — Test metrics:\n",
      "  precision@10: 0.007274049\n",
      "  recall@10: 0.007277719\n",
      "  ndcg@10: 0.007675774\n",
      "  map@10: 0.002434297\n",
      "Epoch 763, Step 10, LR: 0.000080, Current Loss: 0.3370, Avg Loss: 0.3358\n",
      "Diff stats — min: -5.9578, max: 14.2510, mean: 2.1546, std: 2.0579\n",
      "\n",
      "Step 8388 — Test metrics:\n",
      "  precision@10: 0.007300476\n",
      "  recall@10: 0.007304146\n",
      "  ndcg@10: 0.007727819\n",
      "  map@10: 0.002453448\n",
      "Epoch 763 completed, Train Loss: 0.3353\n",
      "Epoch 764, Step 1, LR: 0.000080, Current Loss: 0.3337, Avg Loss: 0.3337\n",
      "Diff stats — min: -5.6567, max: 10.7046, mean: 2.1598, std: 2.0523\n",
      "\n",
      "Step 8390 — Test metrics:\n",
      "  precision@10: 0.007366543\n",
      "  recall@10: 0.007370214\n",
      "  ndcg@10: 0.007768757\n",
      "  map@10: 0.002460705\n",
      "Epoch 764, Step 10, LR: 0.000080, Current Loss: 0.3309, Avg Loss: 0.3347\n",
      "Diff stats — min: -6.2960, max: 16.7094, mean: 2.1654, std: 2.0459\n",
      "\n",
      "Step 8399 — Test metrics:\n",
      "  precision@10: 0.007274049\n",
      "  recall@10: 0.007277719\n",
      "  ndcg@10: 0.007661004\n",
      "  map@10: 0.002421990\n",
      "Epoch 764 completed, Train Loss: 0.3348\n",
      "Epoch 765, Step 1, LR: 0.000080, Current Loss: 0.3359, Avg Loss: 0.3359\n",
      "Diff stats — min: -6.9291, max: 11.4297, mean: 2.1557, std: 2.0520\n",
      "\n",
      "Step 8401 — Test metrics:\n",
      "  precision@10: 0.007293869\n",
      "  recall@10: 0.007297539\n",
      "  ndcg@10: 0.007684667\n",
      "  map@10: 0.002431919\n",
      "Epoch 765, Step 10, LR: 0.000080, Current Loss: 0.3374, Avg Loss: 0.3349\n",
      "Diff stats — min: -6.3400, max: 12.1418, mean: 2.1543, std: 2.0618\n",
      "\n",
      "Step 8410 — Test metrics:\n",
      "  precision@10: 0.007280655\n",
      "  recall@10: 0.007284326\n",
      "  ndcg@10: 0.007687792\n",
      "  map@10: 0.002441233\n",
      "Epoch 765 completed, Train Loss: 0.3348\n",
      "Epoch 766, Step 1, LR: 0.000080, Current Loss: 0.3388, Avg Loss: 0.3388\n",
      "Diff stats — min: -6.4865, max: 10.9368, mean: 2.1502, std: 2.0595\n",
      "\n",
      "Step 8412 — Test metrics:\n",
      "  precision@10: 0.007254228\n",
      "  recall@10: 0.007257899\n",
      "  ndcg@10: 0.007680526\n",
      "  map@10: 0.002443066\n",
      "Epoch 766, Step 10, LR: 0.000080, Current Loss: 0.3373, Avg Loss: 0.3368\n",
      "Diff stats — min: -6.1710, max: 12.7091, mean: 2.1561, std: 2.0584\n",
      "\n",
      "Step 8421 — Test metrics:\n",
      "  precision@10: 0.007260835\n",
      "  recall@10: 0.007264506\n",
      "  ndcg@10: 0.007700791\n",
      "  map@10: 0.002447364\n",
      "Epoch 766 completed, Train Loss: 0.3365\n",
      "Epoch 767, Step 1, LR: 0.000080, Current Loss: 0.3309, Avg Loss: 0.3309\n",
      "Diff stats — min: -5.4825, max: 18.6064, mean: 2.1771, std: 2.0504\n",
      "\n",
      "Step 8423 — Test metrics:\n",
      "  precision@10: 0.007241015\n",
      "  recall@10: 0.007244685\n",
      "  ndcg@10: 0.007686298\n",
      "  map@10: 0.002444335\n",
      "Epoch 767, Step 10, LR: 0.000080, Current Loss: 0.3338, Avg Loss: 0.3337\n",
      "Diff stats — min: -5.7444, max: 10.5023, mean: 2.1616, std: 2.0516\n",
      "\n",
      "Step 8432 — Test metrics:\n",
      "  precision@10: 0.007300476\n",
      "  recall@10: 0.007304146\n",
      "  ndcg@10: 0.007660915\n",
      "  map@10: 0.002412543\n",
      "Epoch 767 completed, Train Loss: 0.3342\n",
      "Epoch 768, Step 1, LR: 0.000080, Current Loss: 0.3325, Avg Loss: 0.3325\n",
      "Diff stats — min: -5.7920, max: 11.0773, mean: 2.1646, std: 2.0487\n",
      "\n",
      "Step 8434 — Test metrics:\n",
      "  precision@10: 0.007386364\n",
      "  recall@10: 0.007390034\n",
      "  ndcg@10: 0.007752797\n",
      "  map@10: 0.002445136\n",
      "Epoch 768, Step 10, LR: 0.000080, Current Loss: 0.3351, Avg Loss: 0.3347\n",
      "Diff stats — min: -5.3792, max: 12.5207, mean: 2.1627, std: 2.0561\n",
      "\n",
      "Step 8443 — Test metrics:\n",
      "  precision@10: 0.007340116\n",
      "  recall@10: 0.007343787\n",
      "  ndcg@10: 0.007763886\n",
      "  map@10: 0.002467138\n",
      "Epoch 768 completed, Train Loss: 0.3338\n",
      "Epoch 769, Step 1, LR: 0.000080, Current Loss: 0.3336, Avg Loss: 0.3336\n",
      "Diff stats — min: -7.3089, max: 12.1509, mean: 2.1650, std: 2.0536\n",
      "\n",
      "Step 8445 — Test metrics:\n",
      "  precision@10: 0.007313689\n",
      "  recall@10: 0.007317360\n",
      "  ndcg@10: 0.007753855\n",
      "  map@10: 0.002465867\n",
      "Epoch 769, Step 10, LR: 0.000080, Current Loss: 0.3288, Avg Loss: 0.3340\n",
      "Diff stats — min: -7.1642, max: 11.0595, mean: 2.1781, std: 2.0431\n",
      "\n",
      "Step 8454 — Test metrics:\n",
      "  precision@10: 0.007293869\n",
      "  recall@10: 0.007297539\n",
      "  ndcg@10: 0.007728164\n",
      "  map@10: 0.002460625\n",
      "Epoch 769 completed, Train Loss: 0.3342\n",
      "Epoch 770, Step 1, LR: 0.000080, Current Loss: 0.3371, Avg Loss: 0.3371\n",
      "Diff stats — min: -6.1052, max: 12.3152, mean: 2.1597, std: 2.0631\n",
      "\n",
      "Step 8456 — Test metrics:\n",
      "  precision@10: 0.007280655\n",
      "  recall@10: 0.007284326\n",
      "  ndcg@10: 0.007684232\n",
      "  map@10: 0.002439685\n",
      "Epoch 770, Step 10, LR: 0.000080, Current Loss: 0.3342, Avg Loss: 0.3350\n",
      "Diff stats — min: -5.8896, max: 11.6328, mean: 2.1704, std: 2.0652\n",
      "\n",
      "Step 8465 — Test metrics:\n",
      "  precision@10: 0.007260835\n",
      "  recall@10: 0.007264506\n",
      "  ndcg@10: 0.007660815\n",
      "  map@10: 0.002427359\n",
      "Epoch 770 completed, Train Loss: 0.3350\n",
      "Epoch 771, Step 1, LR: 0.000080, Current Loss: 0.3328, Avg Loss: 0.3328\n",
      "Diff stats — min: -6.3232, max: 12.4757, mean: 2.1762, std: 2.0623\n",
      "\n",
      "Step 8467 — Test metrics:\n",
      "  precision@10: 0.007287262\n",
      "  recall@10: 0.007290933\n",
      "  ndcg@10: 0.007681729\n",
      "  map@10: 0.002433100\n",
      "Epoch 771, Step 10, LR: 0.000080, Current Loss: 0.3367, Avg Loss: 0.3356\n",
      "Diff stats — min: -6.7089, max: 11.3974, mean: 2.1676, std: 2.0704\n",
      "\n",
      "Step 8476 — Test metrics:\n",
      "  precision@10: 0.007346723\n",
      "  recall@10: 0.007350393\n",
      "  ndcg@10: 0.007789024\n",
      "  map@10: 0.002479484\n",
      "Epoch 771 completed, Train Loss: 0.3353\n",
      "Epoch 772, Step 1, LR: 0.000080, Current Loss: 0.3314, Avg Loss: 0.3314\n",
      "Diff stats — min: -5.9608, max: 11.8793, mean: 2.1734, std: 2.0597\n",
      "\n",
      "Step 8478 — Test metrics:\n",
      "  precision@10: 0.007346723\n",
      "  recall@10: 0.007350393\n",
      "  ndcg@10: 0.007788867\n",
      "  map@10: 0.002479623\n",
      "Epoch 772, Step 10, LR: 0.000080, Current Loss: 0.3366, Avg Loss: 0.3337\n",
      "Diff stats — min: -6.2669, max: 13.2848, mean: 2.1713, std: 2.0759\n",
      "\n",
      "Step 8487 — Test metrics:\n",
      "  precision@10: 0.007346723\n",
      "  recall@10: 0.007350393\n",
      "  ndcg@10: 0.007753384\n",
      "  map@10: 0.002462073\n",
      "Epoch 772 completed, Train Loss: 0.3333\n",
      "Epoch 773, Step 1, LR: 0.000080, Current Loss: 0.3340, Avg Loss: 0.3340\n",
      "Diff stats — min: -5.8356, max: 12.1124, mean: 2.1621, std: 2.0545\n",
      "\n",
      "Step 8489 — Test metrics:\n",
      "  precision@10: 0.007346723\n",
      "  recall@10: 0.007350393\n",
      "  ndcg@10: 0.007747555\n",
      "  map@10: 0.002457974\n",
      "Epoch 773, Step 10, LR: 0.000080, Current Loss: 0.3301, Avg Loss: 0.3346\n",
      "Diff stats — min: -5.7145, max: 11.2634, mean: 2.1798, std: 2.0537\n",
      "\n",
      "Step 8498 — Test metrics:\n",
      "  precision@10: 0.007287262\n",
      "  recall@10: 0.007290933\n",
      "  ndcg@10: 0.007669530\n",
      "  map@10: 0.002427418\n",
      "Epoch 773 completed, Train Loss: 0.3343\n",
      "Epoch 774, Step 1, LR: 0.000080, Current Loss: 0.3342, Avg Loss: 0.3342\n",
      "Diff stats — min: -8.5543, max: 16.5228, mean: 2.1787, std: 2.0721\n",
      "\n",
      "Step 8500 — Test metrics:\n",
      "  precision@10: 0.007293869\n",
      "  recall@10: 0.007297539\n",
      "  ndcg@10: 0.007682821\n",
      "  map@10: 0.002433427\n",
      "Epoch 774, Step 10, LR: 0.000080, Current Loss: 0.3340, Avg Loss: 0.3331\n",
      "Diff stats — min: -6.9743, max: 11.3418, mean: 2.1787, std: 2.0721\n",
      "\n",
      "Step 8509 — Test metrics:\n",
      "  precision@10: 0.007280655\n",
      "  recall@10: 0.007284326\n",
      "  ndcg@10: 0.007694233\n",
      "  map@10: 0.002440866\n",
      "Epoch 774 completed, Train Loss: 0.3333\n",
      "Epoch 775, Step 1, LR: 0.000080, Current Loss: 0.3360, Avg Loss: 0.3360\n",
      "Diff stats — min: -6.9257, max: 12.5329, mean: 2.1661, std: 2.0637\n",
      "\n",
      "Step 8511 — Test metrics:\n",
      "  precision@10: 0.007267442\n",
      "  recall@10: 0.007271112\n",
      "  ndcg@10: 0.007699797\n",
      "  map@10: 0.002447218\n",
      "Epoch 775, Step 10, LR: 0.000080, Current Loss: 0.3340, Avg Loss: 0.3338\n",
      "Diff stats — min: -7.1794, max: 11.4615, mean: 2.1658, std: 2.0597\n",
      "\n",
      "Step 8520 — Test metrics:\n",
      "  precision@10: 0.007300476\n",
      "  recall@10: 0.007304146\n",
      "  ndcg@10: 0.007715664\n",
      "  map@10: 0.002450830\n",
      "Epoch 775 completed, Train Loss: 0.3341\n",
      "Epoch 776, Step 1, LR: 0.000080, Current Loss: 0.3305, Avg Loss: 0.3305\n",
      "Diff stats — min: -6.0190, max: 12.3374, mean: 2.1913, std: 2.0668\n",
      "\n",
      "Step 8522 — Test metrics:\n",
      "  precision@10: 0.007307082\n",
      "  recall@10: 0.007310753\n",
      "  ndcg@10: 0.007704591\n",
      "  map@10: 0.002443875\n",
      "Epoch 776, Step 10, LR: 0.000080, Current Loss: 0.3361, Avg Loss: 0.3330\n",
      "Diff stats — min: -6.9269, max: 10.5685, mean: 2.1770, std: 2.0786\n",
      "\n",
      "Step 8531 — Test metrics:\n",
      "  precision@10: 0.007280655\n",
      "  recall@10: 0.007284326\n",
      "  ndcg@10: 0.007671110\n",
      "  map@10: 0.002425376\n",
      "Epoch 776 completed, Train Loss: 0.3334\n",
      "Epoch 777, Step 1, LR: 0.000080, Current Loss: 0.3317, Avg Loss: 0.3317\n",
      "Diff stats — min: -6.0022, max: 11.8650, mean: 2.1736, std: 2.0559\n",
      "\n",
      "Step 8533 — Test metrics:\n",
      "  precision@10: 0.007247622\n",
      "  recall@10: 0.007251292\n",
      "  ndcg@10: 0.007670183\n",
      "  map@10: 0.002434259\n",
      "Epoch 777, Step 10, LR: 0.000080, Current Loss: 0.3345, Avg Loss: 0.3331\n",
      "Diff stats — min: -6.0022, max: 14.2219, mean: 2.1729, std: 2.0651\n",
      "\n",
      "Step 8542 — Test metrics:\n",
      "  precision@10: 0.007247622\n",
      "  recall@10: 0.007251292\n",
      "  ndcg@10: 0.007643994\n",
      "  map@10: 0.002422558\n",
      "Epoch 777 completed, Train Loss: 0.3329\n",
      "Epoch 778, Step 1, LR: 0.000080, Current Loss: 0.3342, Avg Loss: 0.3342\n",
      "Diff stats — min: -5.7907, max: 12.7007, mean: 2.1815, std: 2.0737\n",
      "\n",
      "Step 8544 — Test metrics:\n",
      "  precision@10: 0.007241015\n",
      "  recall@10: 0.007244685\n",
      "  ndcg@10: 0.007631869\n",
      "  map@10: 0.002416964\n",
      "Epoch 778, Step 10, LR: 0.000080, Current Loss: 0.3275, Avg Loss: 0.3322\n",
      "Diff stats — min: -7.8447, max: 11.1723, mean: 2.2001, std: 2.0666\n",
      "\n",
      "Step 8553 — Test metrics:\n",
      "  precision@10: 0.007313689\n",
      "  recall@10: 0.007317360\n",
      "  ndcg@10: 0.007708098\n",
      "  map@10: 0.002444466\n",
      "Epoch 778 completed, Train Loss: 0.3323\n",
      "Epoch 779, Step 1, LR: 0.000080, Current Loss: 0.3303, Avg Loss: 0.3303\n",
      "Diff stats — min: -5.8127, max: 13.1827, mean: 2.1896, std: 2.0616\n",
      "\n",
      "Step 8555 — Test metrics:\n",
      "  precision@10: 0.007366543\n",
      "  recall@10: 0.007370214\n",
      "  ndcg@10: 0.007778663\n",
      "  map@10: 0.002471898\n",
      "Epoch 779, Step 10, LR: 0.000080, Current Loss: 0.3300, Avg Loss: 0.3329\n",
      "Diff stats — min: -5.6986, max: 11.5493, mean: 2.1979, std: 2.0685\n",
      "\n",
      "Step 8564 — Test metrics:\n",
      "  precision@10: 0.007340116\n",
      "  recall@10: 0.007343787\n",
      "  ndcg@10: 0.007791295\n",
      "  map@10: 0.002486644\n",
      "Epoch 779 completed, Train Loss: 0.3333\n",
      "Epoch 780, Step 1, LR: 0.000080, Current Loss: 0.3359, Avg Loss: 0.3359\n",
      "Diff stats — min: -6.1508, max: 11.1000, mean: 2.1701, std: 2.0710\n",
      "\n",
      "Step 8566 — Test metrics:\n",
      "  precision@10: 0.007359937\n",
      "  recall@10: 0.007363607\n",
      "  ndcg@10: 0.007817070\n",
      "  map@10: 0.002495852\n",
      "Epoch 780, Step 10, LR: 0.000080, Current Loss: 0.3408, Avg Loss: 0.3349\n",
      "Diff stats — min: -6.5744, max: 13.5052, mean: 2.1606, std: 2.0824\n",
      "\n",
      "Step 8575 — Test metrics:\n",
      "  precision@10: 0.007326903\n",
      "  recall@10: 0.007330573\n",
      "  ndcg@10: 0.007767294\n",
      "  map@10: 0.002473404\n",
      "Epoch 780 completed, Train Loss: 0.3349\n",
      "Epoch 781, Step 1, LR: 0.000080, Current Loss: 0.3339, Avg Loss: 0.3339\n",
      "Diff stats — min: -5.6378, max: 11.5781, mean: 2.1773, std: 2.0678\n",
      "\n",
      "Step 8577 — Test metrics:\n",
      "  precision@10: 0.007307082\n",
      "  recall@10: 0.007310753\n",
      "  ndcg@10: 0.007735032\n",
      "  map@10: 0.002460186\n",
      "Epoch 781, Step 10, LR: 0.000080, Current Loss: 0.3326, Avg Loss: 0.3321\n",
      "Diff stats — min: -5.9369, max: 14.7224, mean: 2.1831, std: 2.0759\n",
      "\n",
      "Step 8586 — Test metrics:\n",
      "  precision@10: 0.007307082\n",
      "  recall@10: 0.007310753\n",
      "  ndcg@10: 0.007688720\n",
      "  map@10: 0.002433374\n",
      "Epoch 781 completed, Train Loss: 0.3319\n",
      "Epoch 782, Step 1, LR: 0.000080, Current Loss: 0.3359, Avg Loss: 0.3359\n",
      "Diff stats — min: -5.9124, max: 12.3541, mean: 2.1705, std: 2.0700\n",
      "\n",
      "Step 8588 — Test metrics:\n",
      "  precision@10: 0.007313689\n",
      "  recall@10: 0.007317360\n",
      "  ndcg@10: 0.007674891\n",
      "  map@10: 0.002422073\n",
      "Epoch 782, Step 10, LR: 0.000080, Current Loss: 0.3327, Avg Loss: 0.3324\n",
      "Diff stats — min: -7.3379, max: 11.9688, mean: 2.1869, std: 2.0734\n",
      "\n",
      "Step 8597 — Test metrics:\n",
      "  precision@10: 0.007353330\n",
      "  recall@10: 0.007357000\n",
      "  ndcg@10: 0.007741608\n",
      "  map@10: 0.002450210\n",
      "Epoch 782 completed, Train Loss: 0.3329\n",
      "Epoch 783, Step 1, LR: 0.000080, Current Loss: 0.3382, Avg Loss: 0.3382\n",
      "Diff stats — min: -6.4835, max: 13.4493, mean: 2.1726, std: 2.0829\n",
      "\n",
      "Step 8599 — Test metrics:\n",
      "  precision@10: 0.007392970\n",
      "  recall@10: 0.007396641\n",
      "  ndcg@10: 0.007812381\n",
      "  map@10: 0.002482816\n",
      "Epoch 783, Step 10, LR: 0.000080, Current Loss: 0.3312, Avg Loss: 0.3327\n",
      "Diff stats — min: -6.2633, max: 12.0920, mean: 2.1938, std: 2.0739\n",
      "\n",
      "Step 8608 — Test metrics:\n",
      "  precision@10: 0.007373150\n",
      "  recall@10: 0.007376821\n",
      "  ndcg@10: 0.007771002\n",
      "  map@10: 0.002465328\n",
      "Epoch 783 completed, Train Loss: 0.3330\n",
      "Epoch 784, Step 1, LR: 0.000080, Current Loss: 0.3303, Avg Loss: 0.3303\n",
      "Diff stats — min: -6.0772, max: 13.8399, mean: 2.1922, std: 2.0692\n",
      "\n",
      "Step 8610 — Test metrics:\n",
      "  precision@10: 0.007333510\n",
      "  recall@10: 0.007337180\n",
      "  ndcg@10: 0.007704248\n",
      "  map@10: 0.002434322\n",
      "Epoch 784, Step 10, LR: 0.000080, Current Loss: 0.3362, Avg Loss: 0.3328\n",
      "Diff stats — min: -6.4259, max: 10.6766, mean: 2.1734, std: 2.0729\n",
      "\n",
      "Step 8619 — Test metrics:\n",
      "  precision@10: 0.007320296\n",
      "  recall@10: 0.007323966\n",
      "  ndcg@10: 0.007743848\n",
      "  map@10: 0.002466805\n",
      "Epoch 784 completed, Train Loss: 0.3328\n",
      "Epoch 785, Step 1, LR: 0.000080, Current Loss: 0.3335, Avg Loss: 0.3335\n",
      "Diff stats — min: -5.5583, max: 11.3282, mean: 2.1976, std: 2.0845\n",
      "\n",
      "Step 8621 — Test metrics:\n",
      "  precision@10: 0.007353330\n",
      "  recall@10: 0.007357000\n",
      "  ndcg@10: 0.007790747\n",
      "  map@10: 0.002485887\n",
      "Epoch 785, Step 10, LR: 0.000080, Current Loss: 0.3328, Avg Loss: 0.3330\n",
      "Diff stats — min: -5.9752, max: 15.5385, mean: 2.1910, std: 2.0812\n",
      "\n",
      "Step 8630 — Test metrics:\n",
      "  precision@10: 0.007392970\n",
      "  recall@10: 0.007396641\n",
      "  ndcg@10: 0.007853025\n",
      "  map@10: 0.002506829\n",
      "Epoch 785 completed, Train Loss: 0.3329\n",
      "Epoch 786, Step 1, LR: 0.000080, Current Loss: 0.3315, Avg Loss: 0.3315\n",
      "Diff stats — min: -6.0332, max: 11.1417, mean: 2.2083, std: 2.0847\n",
      "\n",
      "Step 8632 — Test metrics:\n",
      "  precision@10: 0.007359937\n",
      "  recall@10: 0.007363607\n",
      "  ndcg@10: 0.007849899\n",
      "  map@10: 0.002515732\n",
      "Epoch 786, Step 10, LR: 0.000080, Current Loss: 0.3329, Avg Loss: 0.3333\n",
      "Diff stats — min: -6.0914, max: 12.5752, mean: 2.1951, std: 2.0776\n",
      "\n",
      "Step 8641 — Test metrics:\n",
      "  precision@10: 0.007313689\n",
      "  recall@10: 0.007317360\n",
      "  ndcg@10: 0.007704645\n",
      "  map@10: 0.002445180\n",
      "Epoch 786 completed, Train Loss: 0.3326\n",
      "Epoch 787, Step 1, LR: 0.000080, Current Loss: 0.3302, Avg Loss: 0.3302\n",
      "Diff stats — min: -6.0860, max: 11.6582, mean: 2.1845, std: 2.0555\n",
      "\n",
      "Step 8643 — Test metrics:\n",
      "  precision@10: 0.007333510\n",
      "  recall@10: 0.007337180\n",
      "  ndcg@10: 0.007695658\n",
      "  map@10: 0.002434554\n",
      "Epoch 787, Step 10, LR: 0.000080, Current Loss: 0.3229, Avg Loss: 0.3335\n",
      "Diff stats — min: -6.0970, max: 13.4389, mean: 2.2159, std: 2.0602\n",
      "\n",
      "Step 8652 — Test metrics:\n",
      "  precision@10: 0.007379757\n",
      "  recall@10: 0.007383427\n",
      "  ndcg@10: 0.007785569\n",
      "  map@10: 0.002471763\n",
      "Epoch 787 completed, Train Loss: 0.3334\n",
      "Epoch 788, Step 1, LR: 0.000080, Current Loss: 0.3369, Avg Loss: 0.3369\n",
      "Diff stats — min: -6.6552, max: 11.4696, mean: 2.1870, std: 2.0924\n",
      "\n",
      "Step 8654 — Test metrics:\n",
      "  precision@10: 0.007326903\n",
      "  recall@10: 0.007330573\n",
      "  ndcg@10: 0.007771701\n",
      "  map@10: 0.002477337\n",
      "Epoch 788, Step 10, LR: 0.000080, Current Loss: 0.3331, Avg Loss: 0.3335\n",
      "Diff stats — min: -6.5801, max: 11.7490, mean: 2.2027, std: 2.0850\n",
      "\n",
      "Step 8663 — Test metrics:\n",
      "  precision@10: 0.007313689\n",
      "  recall@10: 0.007317360\n",
      "  ndcg@10: 0.007737783\n",
      "  map@10: 0.002463825\n",
      "Epoch 788 completed, Train Loss: 0.3333\n",
      "Epoch 789, Step 1, LR: 0.000080, Current Loss: 0.3290, Avg Loss: 0.3290\n",
      "Diff stats — min: -6.6381, max: 12.5942, mean: 2.2014, std: 2.0710\n",
      "\n",
      "Step 8665 — Test metrics:\n",
      "  precision@10: 0.007320296\n",
      "  recall@10: 0.007323966\n",
      "  ndcg@10: 0.007749061\n",
      "  map@10: 0.002466164\n",
      "Epoch 789, Step 10, LR: 0.000080, Current Loss: 0.3323, Avg Loss: 0.3313\n",
      "Diff stats — min: -6.9432, max: 15.6693, mean: 2.1837, std: 2.0726\n",
      "\n",
      "Step 8674 — Test metrics:\n",
      "  precision@10: 0.007340116\n",
      "  recall@10: 0.007343787\n",
      "  ndcg@10: 0.007735299\n",
      "  map@10: 0.002454898\n",
      "Epoch 789 completed, Train Loss: 0.3318\n",
      "Epoch 790, Step 1, LR: 0.000080, Current Loss: 0.3338, Avg Loss: 0.3338\n",
      "Diff stats — min: -6.5735, max: 12.4349, mean: 2.1965, std: 2.0857\n",
      "\n",
      "Step 8676 — Test metrics:\n",
      "  precision@10: 0.007379757\n",
      "  recall@10: 0.007383427\n",
      "  ndcg@10: 0.007728419\n",
      "  map@10: 0.002439101\n",
      "Epoch 790, Step 10, LR: 0.000080, Current Loss: 0.3331, Avg Loss: 0.3311\n",
      "Diff stats — min: -6.3734, max: 11.9440, mean: 2.1882, std: 2.0722\n",
      "\n",
      "Step 8685 — Test metrics:\n",
      "  precision@10: 0.007300476\n",
      "  recall@10: 0.007304146\n",
      "  ndcg@10: 0.007661026\n",
      "  map@10: 0.002417151\n",
      "Epoch 790 completed, Train Loss: 0.3314\n",
      "Epoch 791, Step 1, LR: 0.000080, Current Loss: 0.3295, Avg Loss: 0.3295\n",
      "Diff stats — min: -6.2988, max: 11.6262, mean: 2.1949, std: 2.0682\n",
      "\n",
      "Step 8687 — Test metrics:\n",
      "  precision@10: 0.007326903\n",
      "  recall@10: 0.007330573\n",
      "  ndcg@10: 0.007674403\n",
      "  map@10: 0.002422205\n",
      "Epoch 791, Step 10, LR: 0.000080, Current Loss: 0.3301, Avg Loss: 0.3311\n",
      "Diff stats — min: -7.2623, max: 12.6996, mean: 2.1988, std: 2.0727\n",
      "\n",
      "Step 8696 — Test metrics:\n",
      "  precision@10: 0.007439218\n",
      "  recall@10: 0.007442888\n",
      "  ndcg@10: 0.007832614\n",
      "  map@10: 0.002485447\n",
      "Epoch 791 completed, Train Loss: 0.3313\n",
      "Epoch 792, Step 1, LR: 0.000080, Current Loss: 0.3326, Avg Loss: 0.3326\n",
      "Diff stats — min: -8.1831, max: 12.4200, mean: 2.1907, std: 2.0697\n",
      "\n",
      "Step 8698 — Test metrics:\n",
      "  precision@10: 0.007439218\n",
      "  recall@10: 0.007442888\n",
      "  ndcg@10: 0.007838443\n",
      "  map@10: 0.002488180\n",
      "Epoch 792, Step 10, LR: 0.000080, Current Loss: 0.3347, Avg Loss: 0.3315\n",
      "Diff stats — min: -6.6073, max: 10.6943, mean: 2.1943, std: 2.0851\n",
      "\n",
      "Step 8707 — Test metrics:\n",
      "  precision@10: 0.007406184\n",
      "  recall@10: 0.007409854\n",
      "  ndcg@10: 0.007736288\n",
      "  map@10: 0.002437517\n",
      "Epoch 792 completed, Train Loss: 0.3316\n",
      "Epoch 793, Step 1, LR: 0.000080, Current Loss: 0.3290, Avg Loss: 0.3290\n",
      "Diff stats — min: -6.3946, max: 13.1122, mean: 2.2148, std: 2.0883\n",
      "\n",
      "Step 8709 — Test metrics:\n",
      "  precision@10: 0.007386364\n",
      "  recall@10: 0.007390034\n",
      "  ndcg@10: 0.007710431\n",
      "  map@10: 0.002428955\n",
      "Epoch 793, Step 10, LR: 0.000080, Current Loss: 0.3280, Avg Loss: 0.3310\n",
      "Diff stats — min: -6.5745, max: 12.5094, mean: 2.2055, std: 2.0656\n",
      "\n",
      "Step 8718 — Test metrics:\n",
      "  precision@10: 0.007346723\n",
      "  recall@10: 0.007350393\n",
      "  ndcg@10: 0.007672901\n",
      "  map@10: 0.002415718\n",
      "Epoch 793 completed, Train Loss: 0.3310\n",
      "Epoch 794, Step 1, LR: 0.000080, Current Loss: 0.3290, Avg Loss: 0.3290\n",
      "Diff stats — min: -5.8899, max: 12.5397, mean: 2.2070, std: 2.0779\n",
      "\n",
      "Step 8720 — Test metrics:\n",
      "  precision@10: 0.007359937\n",
      "  recall@10: 0.007363607\n",
      "  ndcg@10: 0.007718622\n",
      "  map@10: 0.002441876\n",
      "Epoch 794, Step 10, LR: 0.000080, Current Loss: 0.3297, Avg Loss: 0.3311\n",
      "Diff stats — min: -6.2467, max: 13.7069, mean: 2.2145, std: 2.0880\n",
      "\n",
      "Step 8729 — Test metrics:\n",
      "  precision@10: 0.007333510\n",
      "  recall@10: 0.007337180\n",
      "  ndcg@10: 0.007711142\n",
      "  map@10: 0.002439575\n",
      "Epoch 794 completed, Train Loss: 0.3309\n",
      "Epoch 795, Step 1, LR: 0.000080, Current Loss: 0.3381, Avg Loss: 0.3381\n",
      "Diff stats — min: -5.7660, max: 11.5270, mean: 2.1834, std: 2.0908\n",
      "\n",
      "Step 8731 — Test metrics:\n",
      "  precision@10: 0.007293869\n",
      "  recall@10: 0.007297539\n",
      "  ndcg@10: 0.007682612\n",
      "  map@10: 0.002431159\n",
      "Epoch 795, Step 10, LR: 0.000080, Current Loss: 0.3311, Avg Loss: 0.3316\n",
      "Diff stats — min: -6.8688, max: 11.3018, mean: 2.1948, std: 2.0723\n",
      "\n",
      "Step 8740 — Test metrics:\n",
      "  precision@10: 0.007320296\n",
      "  recall@10: 0.007323966\n",
      "  ndcg@10: 0.007632142\n",
      "  map@10: 0.002398011\n",
      "Epoch 795 completed, Train Loss: 0.3319\n",
      "Epoch 796, Step 1, LR: 0.000080, Current Loss: 0.3331, Avg Loss: 0.3331\n",
      "Diff stats — min: -6.6939, max: 17.9040, mean: 2.1872, std: 2.0750\n",
      "\n",
      "Step 8742 — Test metrics:\n",
      "  precision@10: 0.007320296\n",
      "  recall@10: 0.007323966\n",
      "  ndcg@10: 0.007646489\n",
      "  map@10: 0.002406794\n",
      "Epoch 796, Step 10, LR: 0.000080, Current Loss: 0.3288, Avg Loss: 0.3304\n",
      "Diff stats — min: -6.2325, max: 14.0158, mean: 2.2052, std: 2.0792\n",
      "\n",
      "Step 8751 — Test metrics:\n",
      "  precision@10: 0.007346723\n",
      "  recall@10: 0.007350393\n",
      "  ndcg@10: 0.007660046\n",
      "  map@10: 0.002408627\n",
      "Epoch 796 completed, Train Loss: 0.3300\n",
      "Epoch 797, Step 1, LR: 0.000080, Current Loss: 0.3339, Avg Loss: 0.3339\n",
      "Diff stats — min: -5.9644, max: 14.2159, mean: 2.2135, std: 2.1018\n",
      "\n",
      "Step 8753 — Test metrics:\n",
      "  precision@10: 0.007333510\n",
      "  recall@10: 0.007337180\n",
      "  ndcg@10: 0.007686175\n",
      "  map@10: 0.002431337\n",
      "Epoch 797, Step 10, LR: 0.000080, Current Loss: 0.3305, Avg Loss: 0.3317\n",
      "Diff stats — min: -6.0476, max: 11.8591, mean: 2.1961, std: 2.0758\n",
      "\n",
      "Step 8762 — Test metrics:\n",
      "  precision@10: 0.007386364\n",
      "  recall@10: 0.007390034\n",
      "  ndcg@10: 0.007771464\n",
      "  map@10: 0.002466667\n",
      "Epoch 797 completed, Train Loss: 0.3315\n",
      "Epoch 798, Step 1, LR: 0.000080, Current Loss: 0.3329, Avg Loss: 0.3329\n",
      "Diff stats — min: -5.8561, max: 13.4703, mean: 2.1987, std: 2.0853\n",
      "\n",
      "Step 8764 — Test metrics:\n",
      "  precision@10: 0.007406184\n",
      "  recall@10: 0.007409854\n",
      "  ndcg@10: 0.007775644\n",
      "  map@10: 0.002462399\n",
      "Epoch 798, Step 10, LR: 0.000080, Current Loss: 0.3351, Avg Loss: 0.3332\n",
      "Diff stats — min: -5.7310, max: 14.6805, mean: 2.2119, std: 2.1099\n",
      "\n",
      "Step 8773 — Test metrics:\n",
      "  precision@10: 0.007373150\n",
      "  recall@10: 0.007376821\n",
      "  ndcg@10: 0.007740833\n",
      "  map@10: 0.002447881\n",
      "Epoch 798 completed, Train Loss: 0.3331\n",
      "Epoch 799, Step 1, LR: 0.000080, Current Loss: 0.3319, Avg Loss: 0.3319\n",
      "Diff stats — min: -6.3540, max: 14.5827, mean: 2.2007, std: 2.0872\n",
      "\n",
      "Step 8775 — Test metrics:\n",
      "  precision@10: 0.007346723\n",
      "  recall@10: 0.007350393\n",
      "  ndcg@10: 0.007684747\n",
      "  map@10: 0.002423020\n",
      "Epoch 799, Step 10, LR: 0.000080, Current Loss: 0.3328, Avg Loss: 0.3318\n",
      "Diff stats — min: -6.9301, max: 12.8228, mean: 2.2041, std: 2.0921\n",
      "\n",
      "Step 8784 — Test metrics:\n",
      "  precision@10: 0.007293869\n",
      "  recall@10: 0.007297539\n",
      "  ndcg@10: 0.007619909\n",
      "  map@10: 0.002399316\n",
      "Epoch 799 completed, Train Loss: 0.3315\n",
      "Epoch 800, Step 1, LR: 0.000080, Current Loss: 0.3272, Avg Loss: 0.3272\n",
      "Diff stats — min: -5.8054, max: 11.4060, mean: 2.2140, std: 2.0740\n",
      "\n",
      "Step 8786 — Test metrics:\n",
      "  precision@10: 0.007287262\n",
      "  recall@10: 0.007290933\n",
      "  ndcg@10: 0.007607096\n",
      "  map@10: 0.002393592\n",
      "Epoch 800, Step 10, LR: 0.000080, Current Loss: 0.3322, Avg Loss: 0.3301\n",
      "Diff stats — min: -6.4000, max: 11.8520, mean: 2.2117, std: 2.0949\n",
      "\n",
      "Step 8795 — Test metrics:\n",
      "  precision@10: 0.007320296\n",
      "  recall@10: 0.007323966\n",
      "  ndcg@10: 0.007682724\n",
      "  map@10: 0.002433377\n",
      "Epoch 800 completed, Train Loss: 0.3300\n",
      "Epoch 801, Step 1, LR: 0.000080, Current Loss: 0.3327, Avg Loss: 0.3327\n",
      "Diff stats — min: -5.9089, max: 13.1769, mean: 2.1901, std: 2.0781\n",
      "\n",
      "Step 8797 — Test metrics:\n",
      "  precision@10: 0.007353330\n",
      "  recall@10: 0.007357000\n",
      "  ndcg@10: 0.007700528\n",
      "  map@10: 0.002435881\n",
      "Epoch 801, Step 10, LR: 0.000080, Current Loss: 0.3299, Avg Loss: 0.3312\n",
      "Diff stats — min: -5.7202, max: 13.6955, mean: 2.2133, std: 2.0823\n",
      "\n",
      "Step 8806 — Test metrics:\n",
      "  precision@10: 0.007307082\n",
      "  recall@10: 0.007310753\n",
      "  ndcg@10: 0.007654628\n",
      "  map@10: 0.002416758\n",
      "Epoch 801 completed, Train Loss: 0.3305\n",
      "Epoch 802, Step 1, LR: 0.000080, Current Loss: 0.3306, Avg Loss: 0.3306\n",
      "Diff stats — min: -6.4764, max: 11.1801, mean: 2.2191, std: 2.0934\n",
      "\n",
      "Step 8808 — Test metrics:\n",
      "  precision@10: 0.007366543\n",
      "  recall@10: 0.007370214\n",
      "  ndcg@10: 0.007704015\n",
      "  map@10: 0.002428792\n",
      "Epoch 802, Step 10, LR: 0.000080, Current Loss: 0.3359, Avg Loss: 0.3306\n",
      "Diff stats — min: -6.7312, max: 13.3449, mean: 2.1940, std: 2.0916\n",
      "\n",
      "Step 8817 — Test metrics:\n",
      "  precision@10: 0.007373150\n",
      "  recall@10: 0.007376821\n",
      "  ndcg@10: 0.007780642\n",
      "  map@10: 0.002474262\n",
      "Epoch 802 completed, Train Loss: 0.3305\n",
      "Epoch 803, Step 1, LR: 0.000080, Current Loss: 0.3290, Avg Loss: 0.3290\n",
      "Diff stats — min: -5.9700, max: 12.7511, mean: 2.2193, std: 2.0879\n",
      "\n",
      "Step 8819 — Test metrics:\n",
      "  precision@10: 0.007366543\n",
      "  recall@10: 0.007370214\n",
      "  ndcg@10: 0.007739646\n",
      "  map@10: 0.002449629\n",
      "Epoch 803, Step 10, LR: 0.000080, Current Loss: 0.3298, Avg Loss: 0.3299\n",
      "Diff stats — min: -6.6205, max: 13.7492, mean: 2.2142, std: 2.0886\n",
      "\n",
      "Step 8828 — Test metrics:\n",
      "  precision@10: 0.007366543\n",
      "  recall@10: 0.007370214\n",
      "  ndcg@10: 0.007715156\n",
      "  map@10: 0.002434950\n",
      "Epoch 803 completed, Train Loss: 0.3300\n",
      "Epoch 804, Step 1, LR: 0.000080, Current Loss: 0.3267, Avg Loss: 0.3267\n",
      "Diff stats — min: -6.4185, max: 12.1262, mean: 2.2371, std: 2.1000\n",
      "\n",
      "Step 8830 — Test metrics:\n",
      "  precision@10: 0.007333510\n",
      "  recall@10: 0.007337180\n",
      "  ndcg@10: 0.007695303\n",
      "  map@10: 0.002432511\n",
      "Epoch 804, Step 10, LR: 0.000080, Current Loss: 0.3275, Avg Loss: 0.3297\n",
      "Diff stats — min: -5.8130, max: 12.9729, mean: 2.2224, std: 2.0807\n",
      "\n",
      "Step 8839 — Test metrics:\n",
      "  precision@10: 0.007340116\n",
      "  recall@10: 0.007343787\n",
      "  ndcg@10: 0.007687534\n",
      "  map@10: 0.002425098\n",
      "Epoch 804 completed, Train Loss: 0.3302\n",
      "Epoch 805, Step 1, LR: 0.000080, Current Loss: 0.3335, Avg Loss: 0.3335\n",
      "Diff stats — min: -6.2184, max: 11.9355, mean: 2.2161, std: 2.1034\n",
      "\n",
      "Step 8841 — Test metrics:\n",
      "  precision@10: 0.007326903\n",
      "  recall@10: 0.007330573\n",
      "  ndcg@10: 0.007680693\n",
      "  map@10: 0.002426655\n",
      "Epoch 805, Step 10, LR: 0.000080, Current Loss: 0.3287, Avg Loss: 0.3306\n",
      "Diff stats — min: -5.6945, max: 11.0950, mean: 2.2201, std: 2.0884\n",
      "\n",
      "Step 8850 — Test metrics:\n",
      "  precision@10: 0.007379757\n",
      "  recall@10: 0.007383427\n",
      "  ndcg@10: 0.007724180\n",
      "  map@10: 0.002439662\n",
      "Epoch 805 completed, Train Loss: 0.3305\n",
      "Epoch 806, Step 1, LR: 0.000080, Current Loss: 0.3338, Avg Loss: 0.3338\n",
      "Diff stats — min: -6.6214, max: 11.5934, mean: 2.1998, std: 2.0956\n",
      "\n",
      "Step 8852 — Test metrics:\n",
      "  precision@10: 0.007399577\n",
      "  recall@10: 0.007403248\n",
      "  ndcg@10: 0.007733465\n",
      "  map@10: 0.002440703\n",
      "Epoch 806, Step 10, LR: 0.000080, Current Loss: 0.3293, Avg Loss: 0.3291\n",
      "Diff stats — min: -6.3181, max: 13.4872, mean: 2.2135, std: 2.0828\n",
      "\n",
      "Step 8861 — Test metrics:\n",
      "  precision@10: 0.007340116\n",
      "  recall@10: 0.007343787\n",
      "  ndcg@10: 0.007671906\n",
      "  map@10: 0.002418815\n",
      "Epoch 806 completed, Train Loss: 0.3288\n",
      "Epoch 807, Step 1, LR: 0.000080, Current Loss: 0.3247, Avg Loss: 0.3247\n",
      "Diff stats — min: -5.9435, max: 14.8106, mean: 2.2358, std: 2.0844\n",
      "\n",
      "Step 8863 — Test metrics:\n",
      "  precision@10: 0.007320296\n",
      "  recall@10: 0.007323966\n",
      "  ndcg@10: 0.007635866\n",
      "  map@10: 0.002402508\n",
      "Epoch 807, Step 10, LR: 0.000080, Current Loss: 0.3286, Avg Loss: 0.3294\n",
      "Diff stats — min: -6.5986, max: 11.7709, mean: 2.2144, std: 2.0814\n",
      "\n",
      "Step 8872 — Test metrics:\n",
      "  precision@10: 0.007340116\n",
      "  recall@10: 0.007343787\n",
      "  ndcg@10: 0.007685495\n",
      "  map@10: 0.002427596\n",
      "Epoch 807 completed, Train Loss: 0.3293\n",
      "Epoch 808, Step 1, LR: 0.000080, Current Loss: 0.3314, Avg Loss: 0.3314\n",
      "Diff stats — min: -6.2859, max: 15.5632, mean: 2.2170, std: 2.0922\n",
      "\n",
      "Step 8874 — Test metrics:\n",
      "  precision@10: 0.007359937\n",
      "  recall@10: 0.007363607\n",
      "  ndcg@10: 0.007725145\n",
      "  map@10: 0.002446572\n",
      "Epoch 808, Step 10, LR: 0.000080, Current Loss: 0.3292, Avg Loss: 0.3276\n",
      "Diff stats — min: -5.6626, max: 13.6605, mean: 2.2379, std: 2.1052\n",
      "\n",
      "Step 8883 — Test metrics:\n",
      "  precision@10: 0.007379757\n",
      "  recall@10: 0.007383427\n",
      "  ndcg@10: 0.007723336\n",
      "  map@10: 0.002439897\n",
      "Epoch 808 completed, Train Loss: 0.3281\n",
      "Epoch 809, Step 1, LR: 0.000080, Current Loss: 0.3272, Avg Loss: 0.3272\n",
      "Diff stats — min: -6.5663, max: 11.3434, mean: 2.2300, std: 2.0895\n",
      "\n",
      "Step 8885 — Test metrics:\n",
      "  precision@10: 0.007406184\n",
      "  recall@10: 0.007409854\n",
      "  ndcg@10: 0.007721691\n",
      "  map@10: 0.002431460\n",
      "Epoch 809, Step 10, LR: 0.000080, Current Loss: 0.3321, Avg Loss: 0.3306\n",
      "Diff stats — min: -6.3603, max: 11.9159, mean: 2.2104, std: 2.0957\n",
      "\n",
      "Step 8894 — Test metrics:\n",
      "  precision@10: 0.007353330\n",
      "  recall@10: 0.007357000\n",
      "  ndcg@10: 0.007682152\n",
      "  map@10: 0.002420281\n",
      "Epoch 809 completed, Train Loss: 0.3304\n",
      "Epoch 810, Step 1, LR: 0.000080, Current Loss: 0.3315, Avg Loss: 0.3315\n",
      "Diff stats — min: -6.6099, max: 12.5311, mean: 2.2145, std: 2.0998\n",
      "\n",
      "Step 8896 — Test metrics:\n",
      "  precision@10: 0.007326903\n",
      "  recall@10: 0.007330573\n",
      "  ndcg@10: 0.007657222\n",
      "  map@10: 0.002411490\n",
      "Epoch 810, Step 10, LR: 0.000080, Current Loss: 0.3356, Avg Loss: 0.3296\n",
      "Diff stats — min: -6.6695, max: 12.7680, mean: 2.1982, std: 2.1028\n",
      "\n",
      "Step 8905 — Test metrics:\n",
      "  precision@10: 0.007280655\n",
      "  recall@10: 0.007284326\n",
      "  ndcg@10: 0.007586572\n",
      "  map@10: 0.002381042\n",
      "Epoch 810 completed, Train Loss: 0.3294\n",
      "Epoch 811, Step 1, LR: 0.000080, Current Loss: 0.3336, Avg Loss: 0.3336\n",
      "Diff stats — min: -11.5017, max: 12.6199, mean: 2.2104, std: 2.0967\n",
      "\n",
      "Step 8907 — Test metrics:\n",
      "  precision@10: 0.007307082\n",
      "  recall@10: 0.007310753\n",
      "  ndcg@10: 0.007581246\n",
      "  map@10: 0.002373915\n",
      "Epoch 811, Step 10, LR: 0.000080, Current Loss: 0.3253, Avg Loss: 0.3286\n",
      "Diff stats — min: -6.7444, max: 12.6324, mean: 2.2423, std: 2.0946\n",
      "\n",
      "Step 8916 — Test metrics:\n",
      "  precision@10: 0.007373150\n",
      "  recall@10: 0.007376821\n",
      "  ndcg@10: 0.007686077\n",
      "  map@10: 0.002416640\n",
      "Epoch 811 completed, Train Loss: 0.3288\n",
      "Epoch 812, Step 1, LR: 0.000080, Current Loss: 0.3302, Avg Loss: 0.3302\n",
      "Diff stats — min: -7.4774, max: 14.0077, mean: 2.2205, std: 2.1005\n",
      "\n",
      "Step 8918 — Test metrics:\n",
      "  precision@10: 0.007359937\n",
      "  recall@10: 0.007363607\n",
      "  ndcg@10: 0.007659464\n",
      "  map@10: 0.002404863\n",
      "Epoch 812, Step 10, LR: 0.000080, Current Loss: 0.3236, Avg Loss: 0.3292\n",
      "Diff stats — min: -5.7400, max: 12.8414, mean: 2.2542, std: 2.0973\n",
      "\n",
      "Step 8927 — Test metrics:\n",
      "  precision@10: 0.007333510\n",
      "  recall@10: 0.007337180\n",
      "  ndcg@10: 0.007663012\n",
      "  map@10: 0.002418114\n",
      "Epoch 812 completed, Train Loss: 0.3294\n",
      "Epoch 813, Step 1, LR: 0.000080, Current Loss: 0.3333, Avg Loss: 0.3333\n",
      "Diff stats — min: -6.6760, max: 13.5642, mean: 2.2168, std: 2.1053\n",
      "\n",
      "Step 8929 — Test metrics:\n",
      "  precision@10: 0.007320296\n",
      "  recall@10: 0.007323966\n",
      "  ndcg@10: 0.007672403\n",
      "  map@10: 0.002428113\n",
      "Epoch 813, Step 10, LR: 0.000080, Current Loss: 0.3286, Avg Loss: 0.3298\n",
      "Diff stats — min: -5.7757, max: 12.1770, mean: 2.2421, std: 2.1106\n",
      "\n",
      "Step 8938 — Test metrics:\n",
      "  precision@10: 0.007287262\n",
      "  recall@10: 0.007290933\n",
      "  ndcg@10: 0.007654967\n",
      "  map@10: 0.002425686\n",
      "Epoch 813 completed, Train Loss: 0.3300\n",
      "Epoch 814, Step 1, LR: 0.000080, Current Loss: 0.3305, Avg Loss: 0.3305\n",
      "Diff stats — min: -7.4942, max: 14.3019, mean: 2.2182, std: 2.0974\n",
      "\n",
      "Step 8940 — Test metrics:\n",
      "  precision@10: 0.007307082\n",
      "  recall@10: 0.007310753\n",
      "  ndcg@10: 0.007662001\n",
      "  map@10: 0.002425568\n",
      "Epoch 814, Step 10, LR: 0.000080, Current Loss: 0.3299, Avg Loss: 0.3286\n",
      "Diff stats — min: -5.9364, max: 14.2921, mean: 2.2213, std: 2.0929\n",
      "\n",
      "Step 8949 — Test metrics:\n",
      "  precision@10: 0.007340116\n",
      "  recall@10: 0.007343787\n",
      "  ndcg@10: 0.007649328\n",
      "  map@10: 0.002409582\n",
      "Epoch 814 completed, Train Loss: 0.3290\n",
      "Epoch 815, Step 1, LR: 0.000080, Current Loss: 0.3305, Avg Loss: 0.3305\n",
      "Diff stats — min: -6.8652, max: 12.0043, mean: 2.2167, std: 2.0922\n",
      "\n",
      "Step 8951 — Test metrics:\n",
      "  precision@10: 0.007373150\n",
      "  recall@10: 0.007376821\n",
      "  ndcg@10: 0.007688319\n",
      "  map@10: 0.002423149\n",
      "Epoch 815, Step 10, LR: 0.000080, Current Loss: 0.3279, Avg Loss: 0.3290\n",
      "Diff stats — min: -5.7265, max: 12.3757, mean: 2.2310, std: 2.0954\n",
      "\n",
      "Step 8960 — Test metrics:\n",
      "  precision@10: 0.007340116\n",
      "  recall@10: 0.007343787\n",
      "  ndcg@10: 0.007664523\n",
      "  map@10: 0.002415303\n",
      "Epoch 815 completed, Train Loss: 0.3285\n",
      "Epoch 816, Step 1, LR: 0.000080, Current Loss: 0.3261, Avg Loss: 0.3261\n",
      "Diff stats — min: -7.4467, max: 11.6919, mean: 2.2279, std: 2.0864\n",
      "\n",
      "Step 8962 — Test metrics:\n",
      "  precision@10: 0.007353330\n",
      "  recall@10: 0.007357000\n",
      "  ndcg@10: 0.007662940\n",
      "  map@10: 0.002412178\n",
      "Epoch 816, Step 10, LR: 0.000080, Current Loss: 0.3341, Avg Loss: 0.3299\n",
      "Diff stats — min: -7.5688, max: 12.2852, mean: 2.2160, std: 2.1028\n",
      "\n",
      "Step 8971 — Test metrics:\n",
      "  precision@10: 0.007386364\n",
      "  recall@10: 0.007390034\n",
      "  ndcg@10: 0.007747898\n",
      "  map@10: 0.002448961\n",
      "Epoch 816 completed, Train Loss: 0.3300\n",
      "Epoch 817, Step 1, LR: 0.000080, Current Loss: 0.3270, Avg Loss: 0.3270\n",
      "Diff stats — min: -5.6888, max: 12.3494, mean: 2.2441, std: 2.1054\n",
      "\n",
      "Step 8973 — Test metrics:\n",
      "  precision@10: 0.007399577\n",
      "  recall@10: 0.007403248\n",
      "  ndcg@10: 0.007757981\n",
      "  map@10: 0.002450417\n",
      "Epoch 817, Step 10, LR: 0.000080, Current Loss: 0.3264, Avg Loss: 0.3279\n",
      "Diff stats — min: -6.7701, max: 12.1085, mean: 2.2379, std: 2.0867\n",
      "\n",
      "Step 8982 — Test metrics:\n",
      "  precision@10: 0.007300476\n",
      "  recall@10: 0.007304146\n",
      "  ndcg@10: 0.007659486\n",
      "  map@10: 0.002424141\n",
      "Epoch 817 completed, Train Loss: 0.3281\n",
      "Epoch 818, Step 1, LR: 0.000080, Current Loss: 0.3272, Avg Loss: 0.3272\n",
      "Diff stats — min: -5.7164, max: 13.9759, mean: 2.2392, std: 2.1004\n",
      "\n",
      "Step 8984 — Test metrics:\n",
      "  precision@10: 0.007313689\n",
      "  recall@10: 0.007317360\n",
      "  ndcg@10: 0.007673460\n",
      "  map@10: 0.002428705\n",
      "Epoch 818, Step 10, LR: 0.000080, Current Loss: 0.3330, Avg Loss: 0.3296\n",
      "Diff stats — min: -6.4745, max: 11.7889, mean: 2.2168, std: 2.1005\n",
      "\n",
      "Step 8993 — Test metrics:\n",
      "  precision@10: 0.007346723\n",
      "  recall@10: 0.007350393\n",
      "  ndcg@10: 0.007667495\n",
      "  map@10: 0.002415142\n",
      "Epoch 818 completed, Train Loss: 0.3293\n",
      "Epoch 819, Step 1, LR: 0.000080, Current Loss: 0.3305, Avg Loss: 0.3305\n",
      "Diff stats — min: -6.1846, max: 11.4466, mean: 2.2324, std: 2.1109\n",
      "\n",
      "Step 8995 — Test metrics:\n",
      "  precision@10: 0.007346723\n",
      "  recall@10: 0.007350393\n",
      "  ndcg@10: 0.007678939\n",
      "  map@10: 0.002423097\n",
      "Epoch 819, Step 10, LR: 0.000080, Current Loss: 0.3321, Avg Loss: 0.3277\n",
      "Diff stats — min: -6.4009, max: 13.0408, mean: 2.2148, std: 2.0984\n",
      "\n",
      "Step 9004 — Test metrics:\n",
      "  precision@10: 0.007412791\n",
      "  recall@10: 0.007416461\n",
      "  ndcg@10: 0.007694731\n",
      "  map@10: 0.002414980\n",
      "Epoch 819 completed, Train Loss: 0.3282\n",
      "Epoch 820, Step 1, LR: 0.000080, Current Loss: 0.3282, Avg Loss: 0.3282\n",
      "Diff stats — min: -6.2590, max: 12.2389, mean: 2.2367, std: 2.1031\n",
      "\n",
      "Step 9006 — Test metrics:\n",
      "  precision@10: 0.007373150\n",
      "  recall@10: 0.007376821\n",
      "  ndcg@10: 0.007677016\n",
      "  map@10: 0.002414993\n",
      "Epoch 820, Step 10, LR: 0.000080, Current Loss: 0.3308, Avg Loss: 0.3288\n",
      "Diff stats — min: -6.1797, max: 13.3515, mean: 2.2393, std: 2.1200\n",
      "\n",
      "Step 9015 — Test metrics:\n",
      "  precision@10: 0.007366543\n",
      "  recall@10: 0.007370214\n",
      "  ndcg@10: 0.007710578\n",
      "  map@10: 0.002436049\n",
      "Epoch 820 completed, Train Loss: 0.3283\n",
      "Epoch 821, Step 1, LR: 0.000080, Current Loss: 0.3328, Avg Loss: 0.3328\n",
      "Diff stats — min: -6.7272, max: 12.5787, mean: 2.2344, std: 2.1207\n",
      "\n",
      "Step 9017 — Test metrics:\n",
      "  precision@10: 0.007426004\n",
      "  recall@10: 0.007429675\n",
      "  ndcg@10: 0.007751670\n",
      "  map@10: 0.002442538\n",
      "Epoch 821, Step 10, LR: 0.000080, Current Loss: 0.3272, Avg Loss: 0.3292\n",
      "Diff stats — min: -6.9552, max: 11.6042, mean: 2.2376, std: 2.0972\n",
      "\n",
      "Step 9026 — Test metrics:\n",
      "  precision@10: 0.007432611\n",
      "  recall@10: 0.007436281\n",
      "  ndcg@10: 0.007792964\n",
      "  map@10: 0.002466472\n",
      "Epoch 821 completed, Train Loss: 0.3295\n",
      "Epoch 822, Step 1, LR: 0.000080, Current Loss: 0.3302, Avg Loss: 0.3302\n",
      "Diff stats — min: -6.3645, max: 15.8575, mean: 2.2422, std: 2.1207\n",
      "\n",
      "Step 9028 — Test metrics:\n",
      "  precision@10: 0.007399577\n",
      "  recall@10: 0.007403248\n",
      "  ndcg@10: 0.007745882\n",
      "  map@10: 0.002448216\n",
      "Epoch 822, Step 10, LR: 0.000080, Current Loss: 0.3269, Avg Loss: 0.3266\n",
      "Diff stats — min: -5.9438, max: 11.9353, mean: 2.2370, std: 2.0995\n",
      "\n",
      "Step 9037 — Test metrics:\n",
      "  precision@10: 0.007340116\n",
      "  recall@10: 0.007343787\n",
      "  ndcg@10: 0.007677449\n",
      "  map@10: 0.002423550\n",
      "Epoch 822 completed, Train Loss: 0.3269\n",
      "Epoch 823, Step 1, LR: 0.000080, Current Loss: 0.3237, Avg Loss: 0.3237\n",
      "Diff stats — min: -6.5401, max: 14.1224, mean: 2.2503, std: 2.0920\n",
      "\n",
      "Step 9039 — Test metrics:\n",
      "  precision@10: 0.007340116\n",
      "  recall@10: 0.007343787\n",
      "  ndcg@10: 0.007680551\n",
      "  map@10: 0.002426332\n",
      "Epoch 823, Step 10, LR: 0.000080, Current Loss: 0.3292, Avg Loss: 0.3287\n",
      "Diff stats — min: -6.6695, max: 13.8066, mean: 2.2313, std: 2.0997\n",
      "\n",
      "Step 9048 — Test metrics:\n",
      "  precision@10: 0.007399577\n",
      "  recall@10: 0.007403248\n",
      "  ndcg@10: 0.007693489\n",
      "  map@10: 0.002419411\n",
      "Epoch 823 completed, Train Loss: 0.3287\n",
      "Epoch 824, Step 1, LR: 0.000080, Current Loss: 0.3263, Avg Loss: 0.3263\n",
      "Diff stats — min: -5.5862, max: 11.9004, mean: 2.2437, std: 2.1001\n",
      "\n",
      "Step 9050 — Test metrics:\n",
      "  precision@10: 0.007412791\n",
      "  recall@10: 0.007416461\n",
      "  ndcg@10: 0.007738461\n",
      "  map@10: 0.002444300\n",
      "Epoch 824, Step 10, LR: 0.000080, Current Loss: 0.3290, Avg Loss: 0.3272\n",
      "Diff stats — min: -5.6448, max: 14.9850, mean: 2.2234, std: 2.0985\n",
      "\n",
      "Step 9059 — Test metrics:\n",
      "  precision@10: 0.007465645\n",
      "  recall@10: 0.007469315\n",
      "  ndcg@10: 0.007804186\n",
      "  map@10: 0.002465697\n",
      "Epoch 824 completed, Train Loss: 0.3270\n",
      "Epoch 825, Step 1, LR: 0.000080, Current Loss: 0.3252, Avg Loss: 0.3252\n",
      "Diff stats — min: -5.7286, max: 12.6865, mean: 2.2605, std: 2.1072\n",
      "\n",
      "Step 9061 — Test metrics:\n",
      "  precision@10: 0.007465645\n",
      "  recall@10: 0.007469315\n",
      "  ndcg@10: 0.007785920\n",
      "  map@10: 0.002456205\n",
      "Epoch 825, Step 10, LR: 0.000080, Current Loss: 0.3301, Avg Loss: 0.3280\n",
      "Diff stats — min: -5.7858, max: 13.0535, mean: 2.2364, std: 2.1104\n",
      "\n",
      "Step 9070 — Test metrics:\n",
      "  precision@10: 0.007445825\n",
      "  recall@10: 0.007449495\n",
      "  ndcg@10: 0.007726480\n",
      "  map@10: 0.002423926\n",
      "Epoch 825 completed, Train Loss: 0.3282\n",
      "Epoch 826, Step 1, LR: 0.000080, Current Loss: 0.3299, Avg Loss: 0.3299\n",
      "Diff stats — min: -5.9019, max: 12.9794, mean: 2.2210, std: 2.0954\n",
      "\n",
      "Step 9072 — Test metrics:\n",
      "  precision@10: 0.007426004\n",
      "  recall@10: 0.007429675\n",
      "  ndcg@10: 0.007742841\n",
      "  map@10: 0.002440084\n",
      "Epoch 826, Step 10, LR: 0.000080, Current Loss: 0.3272, Avg Loss: 0.3272\n",
      "Diff stats — min: -5.5506, max: 10.5991, mean: 2.2443, std: 2.1048\n",
      "\n",
      "Step 9081 — Test metrics:\n",
      "  precision@10: 0.007366543\n",
      "  recall@10: 0.007370214\n",
      "  ndcg@10: 0.007685810\n",
      "  map@10: 0.002424683\n",
      "Epoch 826 completed, Train Loss: 0.3276\n",
      "Epoch 827, Step 1, LR: 0.000080, Current Loss: 0.3340, Avg Loss: 0.3340\n",
      "Diff stats — min: -6.6828, max: 12.5257, mean: 2.2173, std: 2.1118\n",
      "\n",
      "Step 9083 — Test metrics:\n",
      "  precision@10: 0.007326903\n",
      "  recall@10: 0.007330573\n",
      "  ndcg@10: 0.007662232\n",
      "  map@10: 0.002420590\n",
      "Epoch 827, Step 10, LR: 0.000080, Current Loss: 0.3285, Avg Loss: 0.3285\n",
      "Diff stats — min: -6.8023, max: 14.1296, mean: 2.2320, std: 2.1039\n",
      "\n",
      "Step 9092 — Test metrics:\n",
      "  precision@10: 0.007353330\n",
      "  recall@10: 0.007357000\n",
      "  ndcg@10: 0.007700654\n",
      "  map@10: 0.002435308\n",
      "Epoch 827 completed, Train Loss: 0.3279\n",
      "Epoch 828, Step 1, LR: 0.000080, Current Loss: 0.3275, Avg Loss: 0.3275\n",
      "Diff stats — min: -5.5085, max: 12.4602, mean: 2.2446, std: 2.1069\n",
      "\n",
      "Step 9094 — Test metrics:\n",
      "  precision@10: 0.007406184\n",
      "  recall@10: 0.007409854\n",
      "  ndcg@10: 0.007733427\n",
      "  map@10: 0.002440869\n",
      "Epoch 828, Step 10, LR: 0.000080, Current Loss: 0.3227, Avg Loss: 0.3271\n",
      "Diff stats — min: -6.6248, max: 14.5061, mean: 2.2627, std: 2.1084\n",
      "\n",
      "Step 9103 — Test metrics:\n",
      "  precision@10: 0.007459038\n",
      "  recall@10: 0.007462708\n",
      "  ndcg@10: 0.007787844\n",
      "  map@10: 0.002458486\n",
      "Epoch 828 completed, Train Loss: 0.3275\n",
      "Epoch 829, Step 1, LR: 0.000080, Current Loss: 0.3270, Avg Loss: 0.3270\n",
      "Diff stats — min: -6.4291, max: 17.2076, mean: 2.2544, std: 2.1157\n",
      "\n",
      "Step 9105 — Test metrics:\n",
      "  precision@10: 0.007465645\n",
      "  recall@10: 0.007469315\n",
      "  ndcg@10: 0.007797559\n",
      "  map@10: 0.002461388\n",
      "Epoch 829, Step 10, LR: 0.000080, Current Loss: 0.3281, Avg Loss: 0.3285\n",
      "Diff stats — min: -6.7834, max: 14.2788, mean: 2.2399, std: 2.1075\n",
      "\n",
      "Step 9114 — Test metrics:\n",
      "  precision@10: 0.007452431\n",
      "  recall@10: 0.007456102\n",
      "  ndcg@10: 0.007791125\n",
      "  map@10: 0.002462308\n",
      "Epoch 829 completed, Train Loss: 0.3284\n",
      "Epoch 830, Step 1, LR: 0.000080, Current Loss: 0.3271, Avg Loss: 0.3271\n",
      "Diff stats — min: -6.1277, max: 16.4872, mean: 2.2538, std: 2.1139\n",
      "\n",
      "Step 9116 — Test metrics:\n",
      "  precision@10: 0.007432611\n",
      "  recall@10: 0.007436281\n",
      "  ndcg@10: 0.007776329\n",
      "  map@10: 0.002458451\n",
      "Epoch 830, Step 10, LR: 0.000080, Current Loss: 0.3281, Avg Loss: 0.3283\n",
      "Diff stats — min: -6.3544, max: 12.0801, mean: 2.2432, std: 2.1079\n",
      "\n",
      "Step 9125 — Test metrics:\n",
      "  precision@10: 0.007544926\n",
      "  recall@10: 0.007548596\n",
      "  ndcg@10: 0.007868580\n",
      "  map@10: 0.002484831\n",
      "Epoch 830 completed, Train Loss: 0.3286\n",
      "Epoch 831, Step 1, LR: 0.000080, Current Loss: 0.3283, Avg Loss: 0.3283\n",
      "Diff stats — min: -6.2381, max: 11.9644, mean: 2.2352, std: 2.1008\n",
      "\n",
      "Step 9127 — Test metrics:\n",
      "  precision@10: 0.007505285\n",
      "  recall@10: 0.007508956\n",
      "  ndcg@10: 0.007834608\n",
      "  map@10: 0.002475109\n",
      "Epoch 831, Step 10, LR: 0.000080, Current Loss: 0.3278, Avg Loss: 0.3282\n",
      "Diff stats — min: -5.5722, max: 12.7257, mean: 2.2414, std: 2.1075\n",
      "\n",
      "Step 9136 — Test metrics:\n",
      "  precision@10: 0.007419397\n",
      "  recall@10: 0.007423068\n",
      "  ndcg@10: 0.007747614\n",
      "  map@10: 0.002447951\n",
      "Epoch 831 completed, Train Loss: 0.3278\n",
      "Epoch 832, Step 1, LR: 0.000080, Current Loss: 0.3247, Avg Loss: 0.3247\n",
      "Diff stats — min: -6.8893, max: 11.6976, mean: 2.2661, std: 2.1195\n",
      "\n",
      "Step 9138 — Test metrics:\n",
      "  precision@10: 0.007459038\n",
      "  recall@10: 0.007462708\n",
      "  ndcg@10: 0.007771340\n",
      "  map@10: 0.002451562\n",
      "Epoch 832, Step 10, LR: 0.000080, Current Loss: 0.3249, Avg Loss: 0.3262\n",
      "Diff stats — min: -8.8426, max: 12.5673, mean: 2.2507, std: 2.1063\n",
      "\n",
      "Step 9147 — Test metrics:\n",
      "  precision@10: 0.007452431\n",
      "  recall@10: 0.007456102\n",
      "  ndcg@10: 0.007780860\n",
      "  map@10: 0.002456307\n",
      "Epoch 832 completed, Train Loss: 0.3267\n",
      "Epoch 833, Step 1, LR: 0.000080, Current Loss: 0.3252, Avg Loss: 0.3252\n",
      "Diff stats — min: -7.9105, max: 12.1321, mean: 2.2590, std: 2.1091\n",
      "\n",
      "Step 9149 — Test metrics:\n",
      "  precision@10: 0.007452431\n",
      "  recall@10: 0.007456102\n",
      "  ndcg@10: 0.007779712\n",
      "  map@10: 0.002453935\n",
      "Epoch 833, Step 10, LR: 0.000080, Current Loss: 0.3263, Avg Loss: 0.3262\n",
      "Diff stats — min: -6.7160, max: 11.9149, mean: 2.2653, std: 2.1160\n",
      "\n",
      "Step 9158 — Test metrics:\n",
      "  precision@10: 0.007465645\n",
      "  recall@10: 0.007469315\n",
      "  ndcg@10: 0.007782823\n",
      "  map@10: 0.002451535\n",
      "Epoch 833 completed, Train Loss: 0.3266\n",
      "Epoch 834, Step 1, LR: 0.000080, Current Loss: 0.3276, Avg Loss: 0.3276\n",
      "Diff stats — min: -6.3521, max: 11.3391, mean: 2.2438, std: 2.1078\n",
      "\n",
      "Step 9160 — Test metrics:\n",
      "  precision@10: 0.007452431\n",
      "  recall@10: 0.007456102\n",
      "  ndcg@10: 0.007766644\n",
      "  map@10: 0.002447041\n",
      "Epoch 834, Step 10, LR: 0.000080, Current Loss: 0.3259, Avg Loss: 0.3259\n",
      "Diff stats — min: -6.0602, max: 12.4077, mean: 2.2553, std: 2.1152\n",
      "\n",
      "Step 9169 — Test metrics:\n",
      "  precision@10: 0.007419397\n",
      "  recall@10: 0.007423068\n",
      "  ndcg@10: 0.007681219\n",
      "  map@10: 0.002406842\n",
      "Epoch 834 completed, Train Loss: 0.3262\n",
      "Epoch 835, Step 1, LR: 0.000080, Current Loss: 0.3269, Avg Loss: 0.3269\n",
      "Diff stats — min: -6.5991, max: 11.6243, mean: 2.2599, std: 2.1145\n",
      "\n",
      "Step 9171 — Test metrics:\n",
      "  precision@10: 0.007419397\n",
      "  recall@10: 0.007423068\n",
      "  ndcg@10: 0.007663068\n",
      "  map@10: 0.002395941\n",
      "Epoch 835, Step 10, LR: 0.000080, Current Loss: 0.3241, Avg Loss: 0.3272\n",
      "Diff stats — min: -6.2306, max: 13.5257, mean: 2.2664, std: 2.1053\n",
      "\n",
      "Step 9180 — Test metrics:\n",
      "  precision@10: 0.007392970\n",
      "  recall@10: 0.007396641\n",
      "  ndcg@10: 0.007679574\n",
      "  map@10: 0.002413039\n",
      "Epoch 835 completed, Train Loss: 0.3275\n",
      "Epoch 836, Step 1, LR: 0.000080, Current Loss: 0.3286, Avg Loss: 0.3286\n",
      "Diff stats — min: -5.1274, max: 11.4132, mean: 2.2473, std: 2.1161\n",
      "\n",
      "Step 9182 — Test metrics:\n",
      "  precision@10: 0.007379757\n",
      "  recall@10: 0.007383427\n",
      "  ndcg@10: 0.007670443\n",
      "  map@10: 0.002411238\n",
      "Epoch 836, Step 10, LR: 0.000080, Current Loss: 0.3351, Avg Loss: 0.3282\n",
      "Diff stats — min: -5.9892, max: 11.3874, mean: 2.2360, std: 2.1278\n",
      "\n",
      "Step 9191 — Test metrics:\n",
      "  precision@10: 0.007346723\n",
      "  recall@10: 0.007350393\n",
      "  ndcg@10: 0.007657132\n",
      "  map@10: 0.002409364\n",
      "Epoch 836 completed, Train Loss: 0.3278\n",
      "Epoch 837, Step 1, LR: 0.000080, Current Loss: 0.3289, Avg Loss: 0.3289\n",
      "Diff stats — min: -7.1521, max: 11.6648, mean: 2.2527, std: 2.1201\n",
      "\n",
      "Step 9193 — Test metrics:\n",
      "  precision@10: 0.007340116\n",
      "  recall@10: 0.007343787\n",
      "  ndcg@10: 0.007650534\n",
      "  map@10: 0.002406926\n",
      "Epoch 837, Step 10, LR: 0.000080, Current Loss: 0.3281, Avg Loss: 0.3269\n",
      "Diff stats — min: -6.3074, max: 13.2252, mean: 2.2551, std: 2.1264\n",
      "\n",
      "Step 9202 — Test metrics:\n",
      "  precision@10: 0.007340116\n",
      "  recall@10: 0.007343787\n",
      "  ndcg@10: 0.007667117\n",
      "  map@10: 0.002419603\n",
      "Epoch 837 completed, Train Loss: 0.3268\n",
      "Epoch 838, Step 1, LR: 0.000080, Current Loss: 0.3254, Avg Loss: 0.3254\n",
      "Diff stats — min: -6.8608, max: 12.4242, mean: 2.2506, std: 2.1026\n",
      "\n",
      "Step 9204 — Test metrics:\n",
      "  precision@10: 0.007386364\n",
      "  recall@10: 0.007390034\n",
      "  ndcg@10: 0.007702225\n",
      "  map@10: 0.002427974\n",
      "Epoch 838, Step 10, LR: 0.000080, Current Loss: 0.3294, Avg Loss: 0.3259\n",
      "Diff stats — min: -5.8022, max: 13.2913, mean: 2.2553, std: 2.1224\n",
      "\n",
      "Step 9213 — Test metrics:\n",
      "  precision@10: 0.007426004\n",
      "  recall@10: 0.007429675\n",
      "  ndcg@10: 0.007698769\n",
      "  map@10: 0.002415554\n",
      "Epoch 838 completed, Train Loss: 0.3258\n",
      "Epoch 839, Step 1, LR: 0.000080, Current Loss: 0.3284, Avg Loss: 0.3284\n",
      "Diff stats — min: -6.0513, max: 11.7915, mean: 2.2528, std: 2.1193\n",
      "\n",
      "Step 9215 — Test metrics:\n",
      "  precision@10: 0.007432611\n",
      "  recall@10: 0.007436281\n",
      "  ndcg@10: 0.007714812\n",
      "  map@10: 0.002422488\n",
      "Epoch 839, Step 10, LR: 0.000080, Current Loss: 0.3255, Avg Loss: 0.3267\n",
      "Diff stats — min: -7.2080, max: 11.3252, mean: 2.2566, std: 2.1095\n",
      "\n",
      "Step 9224 — Test metrics:\n",
      "  precision@10: 0.007333510\n",
      "  recall@10: 0.007337180\n",
      "  ndcg@10: 0.007629559\n",
      "  map@10: 0.002398258\n",
      "Epoch 839 completed, Train Loss: 0.3263\n",
      "Epoch 840, Step 1, LR: 0.000080, Current Loss: 0.3281, Avg Loss: 0.3281\n",
      "Diff stats — min: -6.1535, max: 13.5045, mean: 2.2512, std: 2.1158\n",
      "\n",
      "Step 9226 — Test metrics:\n",
      "  precision@10: 0.007267442\n",
      "  recall@10: 0.007271112\n",
      "  ndcg@10: 0.007584198\n",
      "  map@10: 0.002392179\n",
      "Epoch 840, Step 10, LR: 0.000080, Current Loss: 0.3250, Avg Loss: 0.3265\n",
      "Diff stats — min: -6.0927, max: 13.8284, mean: 2.2620, std: 2.1138\n",
      "\n",
      "Step 9235 — Test metrics:\n",
      "  precision@10: 0.007485465\n",
      "  recall@10: 0.007489136\n",
      "  ndcg@10: 0.007766414\n",
      "  map@10: 0.002441139\n",
      "Epoch 840 completed, Train Loss: 0.3264\n",
      "Epoch 841, Step 1, LR: 0.000080, Current Loss: 0.3330, Avg Loss: 0.3330\n",
      "Diff stats — min: -6.7408, max: 12.0777, mean: 2.2465, std: 2.1381\n",
      "\n",
      "Step 9237 — Test metrics:\n",
      "  precision@10: 0.007485465\n",
      "  recall@10: 0.007489136\n",
      "  ndcg@10: 0.007767013\n",
      "  map@10: 0.002441320\n",
      "Epoch 841, Step 10, LR: 0.000080, Current Loss: 0.3269, Avg Loss: 0.3263\n",
      "Diff stats — min: -6.1174, max: 13.0457, mean: 2.2644, std: 2.1263\n",
      "\n",
      "Step 9246 — Test metrics:\n",
      "  precision@10: 0.007406184\n",
      "  recall@10: 0.007409854\n",
      "  ndcg@10: 0.007682609\n",
      "  map@10: 0.002408936\n",
      "Epoch 841 completed, Train Loss: 0.3266\n",
      "Epoch 842, Step 1, LR: 0.000080, Current Loss: 0.3268, Avg Loss: 0.3268\n",
      "Diff stats — min: -6.0734, max: 12.2693, mean: 2.2633, std: 2.1195\n",
      "\n",
      "Step 9248 — Test metrics:\n",
      "  precision@10: 0.007432611\n",
      "  recall@10: 0.007436281\n",
      "  ndcg@10: 0.007713348\n",
      "  map@10: 0.002419505\n",
      "Epoch 842, Step 10, LR: 0.000080, Current Loss: 0.3269, Avg Loss: 0.3252\n",
      "Diff stats — min: -6.7219, max: 16.1314, mean: 2.2574, std: 2.1143\n",
      "\n",
      "Step 9257 — Test metrics:\n",
      "  precision@10: 0.007373150\n",
      "  recall@10: 0.007376821\n",
      "  ndcg@10: 0.007656156\n",
      "  map@10: 0.002401331\n",
      "Epoch 842 completed, Train Loss: 0.3254\n",
      "Epoch 843, Step 1, LR: 0.000080, Current Loss: 0.3244, Avg Loss: 0.3244\n",
      "Diff stats — min: -6.3461, max: 12.3468, mean: 2.2673, std: 2.1145\n",
      "\n",
      "Step 9259 — Test metrics:\n",
      "  precision@10: 0.007386364\n",
      "  recall@10: 0.007390034\n",
      "  ndcg@10: 0.007663367\n",
      "  map@10: 0.002403979\n",
      "Epoch 843, Step 10, LR: 0.000080, Current Loss: 0.3295, Avg Loss: 0.3264\n",
      "Diff stats — min: -6.1269, max: 11.9231, mean: 2.2470, std: 2.1197\n",
      "\n",
      "Step 9268 — Test metrics:\n",
      "  precision@10: 0.007379757\n",
      "  recall@10: 0.007383427\n",
      "  ndcg@10: 0.007667745\n",
      "  map@10: 0.002410714\n",
      "Epoch 843 completed, Train Loss: 0.3267\n",
      "Epoch 844, Step 1, LR: 0.000080, Current Loss: 0.3236, Avg Loss: 0.3236\n",
      "Diff stats — min: -6.2079, max: 10.9320, mean: 2.2669, std: 2.1094\n",
      "\n",
      "Step 9270 — Test metrics:\n",
      "  precision@10: 0.007379757\n",
      "  recall@10: 0.007383427\n",
      "  ndcg@10: 0.007680897\n",
      "  map@10: 0.002418582\n",
      "Epoch 844, Step 10, LR: 0.000080, Current Loss: 0.3276, Avg Loss: 0.3276\n",
      "Diff stats — min: -7.6990, max: 14.3057, mean: 2.2564, std: 2.1245\n",
      "\n",
      "Step 9279 — Test metrics:\n",
      "  precision@10: 0.007406184\n",
      "  recall@10: 0.007409854\n",
      "  ndcg@10: 0.007653013\n",
      "  map@10: 0.002396135\n",
      "Epoch 844 completed, Train Loss: 0.3271\n",
      "Epoch 845, Step 1, LR: 0.000080, Current Loss: 0.3249, Avg Loss: 0.3249\n",
      "Diff stats — min: -7.4083, max: 12.2222, mean: 2.2631, std: 2.1187\n",
      "\n",
      "Step 9281 — Test metrics:\n",
      "  precision@10: 0.007379757\n",
      "  recall@10: 0.007383427\n",
      "  ndcg@10: 0.007648116\n",
      "  map@10: 0.002397789\n",
      "Epoch 845, Step 10, LR: 0.000080, Current Loss: 0.3293, Avg Loss: 0.3277\n",
      "Diff stats — min: -6.3241, max: 11.6109, mean: 2.2530, std: 2.1215\n",
      "\n",
      "Step 9290 — Test metrics:\n",
      "  precision@10: 0.007485465\n",
      "  recall@10: 0.007489136\n",
      "  ndcg@10: 0.007787837\n",
      "  map@10: 0.002453588\n",
      "Epoch 845 completed, Train Loss: 0.3274\n",
      "Epoch 846, Step 1, LR: 0.000080, Current Loss: 0.3232, Avg Loss: 0.3232\n",
      "Diff stats — min: -6.9207, max: 12.8036, mean: 2.2618, std: 2.1035\n",
      "\n",
      "Step 9292 — Test metrics:\n",
      "  precision@10: 0.007459038\n",
      "  recall@10: 0.007462708\n",
      "  ndcg@10: 0.007750688\n",
      "  map@10: 0.002436394\n",
      "Epoch 846, Step 10, LR: 0.000080, Current Loss: 0.3289, Avg Loss: 0.3266\n",
      "Diff stats — min: -8.2755, max: 11.3090, mean: 2.2534, std: 2.1292\n",
      "\n",
      "Step 9301 — Test metrics:\n",
      "  precision@10: 0.007459038\n",
      "  recall@10: 0.007462708\n",
      "  ndcg@10: 0.007789007\n",
      "  map@10: 0.002459673\n",
      "Epoch 846 completed, Train Loss: 0.3266\n",
      "Epoch 847, Step 1, LR: 0.000080, Current Loss: 0.3259, Avg Loss: 0.3259\n",
      "Diff stats — min: -6.1418, max: 12.6430, mean: 2.2527, std: 2.1123\n",
      "\n",
      "Step 9303 — Test metrics:\n",
      "  precision@10: 0.007452431\n",
      "  recall@10: 0.007456102\n",
      "  ndcg@10: 0.007787476\n",
      "  map@10: 0.002458330\n",
      "Epoch 847, Step 10, LR: 0.000080, Current Loss: 0.3185, Avg Loss: 0.3260\n",
      "Diff stats — min: -7.4398, max: 14.0434, mean: 2.2877, std: 2.1165\n",
      "\n",
      "Step 9312 — Test metrics:\n",
      "  precision@10: 0.007419397\n",
      "  recall@10: 0.007423068\n",
      "  ndcg@10: 0.007705448\n",
      "  map@10: 0.002420378\n",
      "Epoch 847 completed, Train Loss: 0.3257\n",
      "Epoch 848, Step 1, LR: 0.000080, Current Loss: 0.3158, Avg Loss: 0.3158\n",
      "Diff stats — min: -6.2012, max: 12.5231, mean: 2.2784, std: 2.0875\n",
      "\n",
      "Step 9314 — Test metrics:\n",
      "  precision@10: 0.007412791\n",
      "  recall@10: 0.007416461\n",
      "  ndcg@10: 0.007690545\n",
      "  map@10: 0.002415944\n",
      "Epoch 848, Step 10, LR: 0.000080, Current Loss: 0.3198, Avg Loss: 0.3237\n",
      "Diff stats — min: -6.6461, max: 13.1717, mean: 2.2818, std: 2.1145\n",
      "\n",
      "Step 9323 — Test metrics:\n",
      "  precision@10: 0.007373150\n",
      "  recall@10: 0.007376821\n",
      "  ndcg@10: 0.007656835\n",
      "  map@10: 0.002401902\n",
      "Epoch 848 completed, Train Loss: 0.3238\n",
      "Epoch 849, Step 1, LR: 0.000080, Current Loss: 0.3273, Avg Loss: 0.3273\n",
      "Diff stats — min: -6.0271, max: 12.6951, mean: 2.2468, std: 2.1068\n",
      "\n",
      "Step 9325 — Test metrics:\n",
      "  precision@10: 0.007386364\n",
      "  recall@10: 0.007390034\n",
      "  ndcg@10: 0.007672327\n",
      "  map@10: 0.002408861\n",
      "Epoch 849, Step 10, LR: 0.000080, Current Loss: 0.3237, Avg Loss: 0.3253\n",
      "Diff stats — min: -5.9685, max: 11.3531, mean: 2.2886, std: 2.1348\n",
      "\n",
      "Step 9334 — Test metrics:\n",
      "  precision@10: 0.007492072\n",
      "  recall@10: 0.007495742\n",
      "  ndcg@10: 0.007833686\n",
      "  map@10: 0.002479721\n",
      "Epoch 849 completed, Train Loss: 0.3254\n",
      "Epoch 850, Step 1, LR: 0.000080, Current Loss: 0.3204, Avg Loss: 0.3204\n",
      "Diff stats — min: -6.0974, max: 13.4302, mean: 2.2878, std: 2.1169\n",
      "\n",
      "Step 9336 — Test metrics:\n",
      "  precision@10: 0.007478858\n",
      "  recall@10: 0.007482529\n",
      "  ndcg@10: 0.007822777\n",
      "  map@10: 0.002476191\n",
      "Epoch 850, Step 10, LR: 0.000080, Current Loss: 0.3213, Avg Loss: 0.3240\n",
      "Diff stats — min: -5.3591, max: 13.0365, mean: 2.2678, std: 2.0973\n",
      "\n",
      "Step 9345 — Test metrics:\n",
      "  precision@10: 0.007439218\n",
      "  recall@10: 0.007442888\n",
      "  ndcg@10: 0.007644978\n",
      "  map@10: 0.002380778\n",
      "Epoch 850 completed, Train Loss: 0.3241\n",
      "Epoch 851, Step 1, LR: 0.000080, Current Loss: 0.3270, Avg Loss: 0.3270\n",
      "Diff stats — min: -6.0866, max: 11.5015, mean: 2.2628, std: 2.1243\n",
      "\n",
      "Step 9347 — Test metrics:\n",
      "  precision@10: 0.007406184\n",
      "  recall@10: 0.007409854\n",
      "  ndcg@10: 0.007594183\n",
      "  map@10: 0.002359022\n",
      "Epoch 851, Step 10, LR: 0.000080, Current Loss: 0.3278, Avg Loss: 0.3255\n",
      "Diff stats — min: -7.2440, max: 12.1399, mean: 2.2626, std: 2.1296\n",
      "\n",
      "Step 9356 — Test metrics:\n",
      "  precision@10: 0.007505285\n",
      "  recall@10: 0.007508956\n",
      "  ndcg@10: 0.007734897\n",
      "  map@10: 0.002418800\n",
      "Epoch 851 completed, Train Loss: 0.3252\n",
      "Epoch 852, Step 1, LR: 0.000080, Current Loss: 0.3231, Avg Loss: 0.3231\n",
      "Diff stats — min: -5.9869, max: 12.9178, mean: 2.2804, std: 2.1230\n",
      "\n",
      "Step 9358 — Test metrics:\n",
      "  precision@10: 0.007492072\n",
      "  recall@10: 0.007495742\n",
      "  ndcg@10: 0.007753404\n",
      "  map@10: 0.002431675\n",
      "Epoch 852, Step 10, LR: 0.000080, Current Loss: 0.3251, Avg Loss: 0.3243\n",
      "Diff stats — min: -5.9272, max: 13.7486, mean: 2.2684, std: 2.1201\n",
      "\n",
      "Step 9367 — Test metrics:\n",
      "  precision@10: 0.007472252\n",
      "  recall@10: 0.007475922\n",
      "  ndcg@10: 0.007742608\n",
      "  map@10: 0.002428880\n",
      "Epoch 852 completed, Train Loss: 0.3241\n",
      "Epoch 853, Step 1, LR: 0.000080, Current Loss: 0.3293, Avg Loss: 0.3293\n",
      "Diff stats — min: -6.5605, max: 14.5484, mean: 2.2526, std: 2.1333\n",
      "\n",
      "Step 9369 — Test metrics:\n",
      "  precision@10: 0.007439218\n",
      "  recall@10: 0.007442888\n",
      "  ndcg@10: 0.007724928\n",
      "  map@10: 0.002428201\n",
      "Epoch 853, Step 10, LR: 0.000080, Current Loss: 0.3245, Avg Loss: 0.3253\n",
      "Diff stats — min: -6.5739, max: 14.3834, mean: 2.2780, std: 2.1278\n",
      "\n",
      "Step 9378 — Test metrics:\n",
      "  precision@10: 0.007406184\n",
      "  recall@10: 0.007409854\n",
      "  ndcg@10: 0.007618490\n",
      "  map@10: 0.002373962\n",
      "Epoch 853 completed, Train Loss: 0.3252\n",
      "Epoch 854, Step 1, LR: 0.000080, Current Loss: 0.3234, Avg Loss: 0.3234\n",
      "Diff stats — min: -7.0720, max: 13.7242, mean: 2.2680, std: 2.1162\n",
      "\n",
      "Step 9380 — Test metrics:\n",
      "  precision@10: 0.007379757\n",
      "  recall@10: 0.007383427\n",
      "  ndcg@10: 0.007589802\n",
      "  map@10: 0.002362057\n",
      "Epoch 854, Step 10, LR: 0.000080, Current Loss: 0.3245, Avg Loss: 0.3242\n",
      "Diff stats — min: -8.2108, max: 14.0960, mean: 2.2841, std: 2.1321\n",
      "\n",
      "Step 9389 — Test metrics:\n",
      "  precision@10: 0.007412791\n",
      "  recall@10: 0.007416461\n",
      "  ndcg@10: 0.007712354\n",
      "  map@10: 0.002428502\n",
      "Epoch 854 completed, Train Loss: 0.3244\n",
      "Epoch 855, Step 1, LR: 0.000080, Current Loss: 0.3241, Avg Loss: 0.3241\n",
      "Diff stats — min: -6.1188, max: 11.8126, mean: 2.2842, std: 2.1275\n",
      "\n",
      "Step 9391 — Test metrics:\n",
      "  precision@10: 0.007406184\n",
      "  recall@10: 0.007409854\n",
      "  ndcg@10: 0.007731715\n",
      "  map@10: 0.002443226\n",
      "Epoch 855, Step 10, LR: 0.000080, Current Loss: 0.3243, Avg Loss: 0.3252\n",
      "Diff stats — min: -6.8648, max: 14.6033, mean: 2.2704, std: 2.1244\n",
      "\n",
      "Step 9400 — Test metrics:\n",
      "  precision@10: 0.007472252\n",
      "  recall@10: 0.007475922\n",
      "  ndcg@10: 0.007731352\n",
      "  map@10: 0.002425388\n",
      "Epoch 855 completed, Train Loss: 0.3246\n",
      "Epoch 856, Step 1, LR: 0.000080, Current Loss: 0.3243, Avg Loss: 0.3243\n",
      "Diff stats — min: -6.3900, max: 12.8901, mean: 2.2882, std: 2.1382\n",
      "\n",
      "Step 9402 — Test metrics:\n",
      "  precision@10: 0.007472252\n",
      "  recall@10: 0.007475922\n",
      "  ndcg@10: 0.007716264\n",
      "  map@10: 0.002416433\n",
      "Epoch 856, Step 10, LR: 0.000080, Current Loss: 0.3266, Avg Loss: 0.3251\n",
      "Diff stats — min: -6.3033, max: 13.4714, mean: 2.2774, std: 2.1334\n",
      "\n",
      "Step 9411 — Test metrics:\n",
      "  precision@10: 0.007445825\n",
      "  recall@10: 0.007449495\n",
      "  ndcg@10: 0.007712057\n",
      "  map@10: 0.002416227\n",
      "Epoch 856 completed, Train Loss: 0.3255\n",
      "Epoch 857, Step 1, LR: 0.000080, Current Loss: 0.3231, Avg Loss: 0.3231\n",
      "Diff stats — min: -6.4127, max: 12.5478, mean: 2.2924, std: 2.1241\n",
      "\n",
      "Step 9413 — Test metrics:\n",
      "  precision@10: 0.007392970\n",
      "  recall@10: 0.007396641\n",
      "  ndcg@10: 0.007686533\n",
      "  map@10: 0.002417701\n",
      "Epoch 857, Step 10, LR: 0.000080, Current Loss: 0.3297, Avg Loss: 0.3238\n",
      "Diff stats — min: -6.2667, max: 11.9861, mean: 2.2663, std: 2.1409\n",
      "\n",
      "Step 9422 — Test metrics:\n",
      "  precision@10: 0.007426004\n",
      "  recall@10: 0.007429675\n",
      "  ndcg@10: 0.007687539\n",
      "  map@10: 0.002410934\n",
      "Epoch 857 completed, Train Loss: 0.3242\n",
      "Epoch 858, Step 1, LR: 0.000080, Current Loss: 0.3224, Avg Loss: 0.3224\n",
      "Diff stats — min: -6.8587, max: 13.2003, mean: 2.2987, std: 2.1351\n",
      "\n",
      "Step 9424 — Test metrics:\n",
      "  precision@10: 0.007419397\n",
      "  recall@10: 0.007423068\n",
      "  ndcg@10: 0.007696168\n",
      "  map@10: 0.002416144\n",
      "Epoch 858, Step 10, LR: 0.000080, Current Loss: 0.3271, Avg Loss: 0.3248\n",
      "Diff stats — min: -7.3687, max: 14.6897, mean: 2.2822, std: 2.1450\n",
      "\n",
      "Step 9433 — Test metrics:\n",
      "  precision@10: 0.007432611\n",
      "  recall@10: 0.007436281\n",
      "  ndcg@10: 0.007718011\n",
      "  map@10: 0.002429966\n",
      "Epoch 858 completed, Train Loss: 0.3248\n",
      "Epoch 859, Step 1, LR: 0.000080, Current Loss: 0.3228, Avg Loss: 0.3228\n",
      "Diff stats — min: -6.7008, max: 13.5231, mean: 2.2911, std: 2.1314\n",
      "\n",
      "Step 9435 — Test metrics:\n",
      "  precision@10: 0.007419397\n",
      "  recall@10: 0.007423068\n",
      "  ndcg@10: 0.007725481\n",
      "  map@10: 0.002435977\n",
      "Epoch 859, Step 10, LR: 0.000080, Current Loss: 0.3253, Avg Loss: 0.3236\n",
      "Diff stats — min: -7.9292, max: 13.6195, mean: 2.2915, std: 2.1414\n",
      "\n",
      "Step 9444 — Test metrics:\n",
      "  precision@10: 0.007439218\n",
      "  recall@10: 0.007442888\n",
      "  ndcg@10: 0.007698349\n",
      "  map@10: 0.002412654\n",
      "Epoch 859 completed, Train Loss: 0.3241\n",
      "Epoch 860, Step 1, LR: 0.000080, Current Loss: 0.3284, Avg Loss: 0.3284\n",
      "Diff stats — min: -6.5403, max: 11.4116, mean: 2.2716, std: 2.1399\n",
      "\n",
      "Step 9446 — Test metrics:\n",
      "  precision@10: 0.007459038\n",
      "  recall@10: 0.007462708\n",
      "  ndcg@10: 0.007697003\n",
      "  map@10: 0.002406002\n",
      "Epoch 860, Step 10, LR: 0.000080, Current Loss: 0.3226, Avg Loss: 0.3225\n",
      "Diff stats — min: -6.6400, max: 11.6273, mean: 2.3023, std: 2.1381\n",
      "\n",
      "Step 9455 — Test metrics:\n",
      "  precision@10: 0.007472252\n",
      "  recall@10: 0.007475922\n",
      "  ndcg@10: 0.007768780\n",
      "  map@10: 0.002449217\n",
      "Epoch 860 completed, Train Loss: 0.3231\n",
      "Epoch 861, Step 1, LR: 0.000080, Current Loss: 0.3228, Avg Loss: 0.3228\n",
      "Diff stats — min: -9.0006, max: 12.8314, mean: 2.2852, std: 2.1263\n",
      "\n",
      "Step 9457 — Test metrics:\n",
      "  precision@10: 0.007445825\n",
      "  recall@10: 0.007449495\n",
      "  ndcg@10: 0.007754832\n",
      "  map@10: 0.002447241\n",
      "Epoch 861, Step 10, LR: 0.000080, Current Loss: 0.3264, Avg Loss: 0.3238\n",
      "Diff stats — min: -9.3843, max: 13.0210, mean: 2.2799, std: 2.1434\n",
      "\n",
      "Step 9466 — Test metrics:\n",
      "  precision@10: 0.007439218\n",
      "  recall@10: 0.007442888\n",
      "  ndcg@10: 0.007686088\n",
      "  map@10: 0.002401289\n",
      "Epoch 861 completed, Train Loss: 0.3234\n",
      "Epoch 862, Step 1, LR: 0.000080, Current Loss: 0.3247, Avg Loss: 0.3247\n",
      "Diff stats — min: -7.7206, max: 14.4780, mean: 2.2840, std: 2.1316\n",
      "\n",
      "Step 9468 — Test metrics:\n",
      "  precision@10: 0.007445825\n",
      "  recall@10: 0.007449495\n",
      "  ndcg@10: 0.007670742\n",
      "  map@10: 0.002391344\n",
      "Epoch 862, Step 10, LR: 0.000080, Current Loss: 0.3237, Avg Loss: 0.3242\n",
      "Diff stats — min: -6.4408, max: 15.2754, mean: 2.2951, std: 2.1424\n",
      "\n",
      "Step 9477 — Test metrics:\n",
      "  precision@10: 0.007439218\n",
      "  recall@10: 0.007442888\n",
      "  ndcg@10: 0.007637793\n",
      "  map@10: 0.002377641\n",
      "Epoch 862 completed, Train Loss: 0.3241\n",
      "Epoch 863, Step 1, LR: 0.000080, Current Loss: 0.3241, Avg Loss: 0.3241\n",
      "Diff stats — min: -5.6537, max: 12.9993, mean: 2.2824, std: 2.1360\n",
      "\n",
      "Step 9479 — Test metrics:\n",
      "  precision@10: 0.007406184\n",
      "  recall@10: 0.007409854\n",
      "  ndcg@10: 0.007629853\n",
      "  map@10: 0.002381941\n",
      "Epoch 863, Step 10, LR: 0.000080, Current Loss: 0.3288, Avg Loss: 0.3250\n",
      "Diff stats — min: -6.0770, max: 14.3240, mean: 2.2824, std: 2.1500\n",
      "\n",
      "Step 9488 — Test metrics:\n",
      "  precision@10: 0.007505285\n",
      "  recall@10: 0.007508956\n",
      "  ndcg@10: 0.007797421\n",
      "  map@10: 0.002453868\n",
      "Epoch 863 completed, Train Loss: 0.3249\n",
      "Epoch 864, Step 1, LR: 0.000080, Current Loss: 0.3276, Avg Loss: 0.3276\n",
      "Diff stats — min: -5.9481, max: 15.7356, mean: 2.2690, std: 2.1397\n",
      "\n",
      "Step 9490 — Test metrics:\n",
      "  precision@10: 0.007472252\n",
      "  recall@10: 0.007475922\n",
      "  ndcg@10: 0.007772336\n",
      "  map@10: 0.002449729\n",
      "Epoch 864, Step 10, LR: 0.000080, Current Loss: 0.3196, Avg Loss: 0.3230\n",
      "Diff stats — min: -5.9279, max: 11.4271, mean: 2.2948, std: 2.1257\n",
      "\n",
      "Step 9499 — Test metrics:\n",
      "  precision@10: 0.007445825\n",
      "  recall@10: 0.007449495\n",
      "  ndcg@10: 0.007710292\n",
      "  map@10: 0.002420502\n",
      "Epoch 864 completed, Train Loss: 0.3229\n",
      "Epoch 865, Step 1, LR: 0.000080, Current Loss: 0.3254, Avg Loss: 0.3254\n",
      "Diff stats — min: -6.0235, max: 12.2088, mean: 2.2710, std: 2.1227\n",
      "\n",
      "Step 9501 — Test metrics:\n",
      "  precision@10: 0.007518499\n",
      "  recall@10: 0.007522169\n",
      "  ndcg@10: 0.007764977\n",
      "  map@10: 0.002435321\n",
      "Epoch 865, Step 10, LR: 0.000080, Current Loss: 0.3218, Avg Loss: 0.3238\n",
      "Diff stats — min: -6.5501, max: 13.3672, mean: 2.3069, std: 2.1438\n",
      "\n",
      "Step 9510 — Test metrics:\n",
      "  precision@10: 0.007432611\n",
      "  recall@10: 0.007436281\n",
      "  ndcg@10: 0.007684263\n",
      "  map@10: 0.002405667\n",
      "Epoch 865 completed, Train Loss: 0.3236\n",
      "Epoch 866, Step 1, LR: 0.000080, Current Loss: 0.3188, Avg Loss: 0.3188\n",
      "Diff stats — min: -6.0782, max: 13.9577, mean: 2.3032, std: 2.1307\n",
      "\n",
      "Step 9512 — Test metrics:\n",
      "  precision@10: 0.007478858\n",
      "  recall@10: 0.007482529\n",
      "  ndcg@10: 0.007713189\n",
      "  map@10: 0.002410997\n",
      "Epoch 866, Step 10, LR: 0.000080, Current Loss: 0.3191, Avg Loss: 0.3227\n",
      "Diff stats — min: -6.6640, max: 13.0541, mean: 2.3057, std: 2.1249\n",
      "\n",
      "Step 9521 — Test metrics:\n",
      "  precision@10: 0.007478858\n",
      "  recall@10: 0.007482529\n",
      "  ndcg@10: 0.007787613\n",
      "  map@10: 0.002455234\n",
      "Epoch 866 completed, Train Loss: 0.3232\n",
      "Epoch 867, Step 1, LR: 0.000080, Current Loss: 0.3229, Avg Loss: 0.3229\n",
      "Diff stats — min: -6.5171, max: 12.9625, mean: 2.2927, std: 2.1318\n",
      "\n",
      "Step 9523 — Test metrics:\n",
      "  precision@10: 0.007445825\n",
      "  recall@10: 0.007449495\n",
      "  ndcg@10: 0.007752405\n",
      "  map@10: 0.002441331\n",
      "Epoch 867, Step 10, LR: 0.000080, Current Loss: 0.3209, Avg Loss: 0.3228\n",
      "Diff stats — min: -5.7547, max: 12.2797, mean: 2.3078, std: 2.1411\n",
      "\n",
      "Step 9532 — Test metrics:\n",
      "  precision@10: 0.007432611\n",
      "  recall@10: 0.007436281\n",
      "  ndcg@10: 0.007673388\n",
      "  map@10: 0.002400616\n",
      "Epoch 867 completed, Train Loss: 0.3227\n",
      "Epoch 868, Step 1, LR: 0.000080, Current Loss: 0.3200, Avg Loss: 0.3200\n",
      "Diff stats — min: -6.0296, max: 14.0618, mean: 2.2960, std: 2.1257\n",
      "\n",
      "Step 9534 — Test metrics:\n",
      "  precision@10: 0.007445825\n",
      "  recall@10: 0.007449495\n",
      "  ndcg@10: 0.007700941\n",
      "  map@10: 0.002414497\n",
      "Epoch 868, Step 10, LR: 0.000080, Current Loss: 0.3237, Avg Loss: 0.3234\n",
      "Diff stats — min: -7.2471, max: 13.0886, mean: 2.2889, std: 2.1319\n",
      "\n",
      "Step 9543 — Test metrics:\n",
      "  precision@10: 0.007525106\n",
      "  recall@10: 0.007528776\n",
      "  ndcg@10: 0.007770969\n",
      "  map@10: 0.002434486\n",
      "Epoch 868 completed, Train Loss: 0.3235\n",
      "Epoch 869, Step 1, LR: 0.000080, Current Loss: 0.3275, Avg Loss: 0.3275\n",
      "Diff stats — min: -5.9931, max: 13.0378, mean: 2.2852, std: 2.1480\n",
      "\n",
      "Step 9545 — Test metrics:\n",
      "  precision@10: 0.007525106\n",
      "  recall@10: 0.007528776\n",
      "  ndcg@10: 0.007782162\n",
      "  map@10: 0.002437818\n",
      "Epoch 869, Step 10, LR: 0.000080, Current Loss: 0.3232, Avg Loss: 0.3244\n",
      "Diff stats — min: -6.1791, max: 11.9094, mean: 2.3029, std: 2.1440\n",
      "\n",
      "Step 9554 — Test metrics:\n",
      "  precision@10: 0.007551533\n",
      "  recall@10: 0.007555203\n",
      "  ndcg@10: 0.007780622\n",
      "  map@10: 0.002430527\n",
      "Epoch 869 completed, Train Loss: 0.3239\n",
      "Epoch 870, Step 1, LR: 0.000080, Current Loss: 0.3208, Avg Loss: 0.3208\n",
      "Diff stats — min: -6.4579, max: 14.7343, mean: 2.3045, std: 2.1492\n",
      "\n",
      "Step 9556 — Test metrics:\n",
      "  precision@10: 0.007478858\n",
      "  recall@10: 0.007482529\n",
      "  ndcg@10: 0.007715013\n",
      "  map@10: 0.002409055\n",
      "Epoch 870, Step 10, LR: 0.000080, Current Loss: 0.3216, Avg Loss: 0.3238\n",
      "Diff stats — min: -5.9738, max: 14.3444, mean: 2.3048, std: 2.1391\n",
      "\n",
      "Step 9565 — Test metrics:\n",
      "  precision@10: 0.007511892\n",
      "  recall@10: 0.007515563\n",
      "  ndcg@10: 0.007735087\n",
      "  map@10: 0.002415313\n",
      "Epoch 870 completed, Train Loss: 0.3236\n",
      "Epoch 871, Step 1, LR: 0.000080, Current Loss: 0.3173, Avg Loss: 0.3173\n",
      "Diff stats — min: -5.4854, max: 13.2138, mean: 2.3156, std: 2.1291\n",
      "\n",
      "Step 9567 — Test metrics:\n",
      "  precision@10: 0.007498679\n",
      "  recall@10: 0.007502349\n",
      "  ndcg@10: 0.007724303\n",
      "  map@10: 0.002412080\n",
      "Epoch 871, Step 10, LR: 0.000080, Current Loss: 0.3256, Avg Loss: 0.3241\n",
      "Diff stats — min: -6.3368, max: 11.6233, mean: 2.2947, std: 2.1460\n",
      "\n",
      "Step 9576 — Test metrics:\n",
      "  precision@10: 0.007419397\n",
      "  recall@10: 0.007423068\n",
      "  ndcg@10: 0.007698427\n",
      "  map@10: 0.002419143\n",
      "Epoch 871 completed, Train Loss: 0.3243\n",
      "Epoch 872, Step 1, LR: 0.000080, Current Loss: 0.3247, Avg Loss: 0.3247\n",
      "Diff stats — min: -8.1846, max: 12.8735, mean: 2.2839, std: 2.1330\n",
      "\n",
      "Step 9578 — Test metrics:\n",
      "  precision@10: 0.007445825\n",
      "  recall@10: 0.007449495\n",
      "  ndcg@10: 0.007709921\n",
      "  map@10: 0.002421264\n",
      "Epoch 872, Step 10, LR: 0.000080, Current Loss: 0.3292, Avg Loss: 0.3245\n",
      "Diff stats — min: -6.2815, max: 12.4066, mean: 2.2779, std: 2.1488\n",
      "\n",
      "Step 9587 — Test metrics:\n",
      "  precision@10: 0.007478858\n",
      "  recall@10: 0.007482529\n",
      "  ndcg@10: 0.007753691\n",
      "  map@10: 0.002438096\n",
      "Epoch 872 completed, Train Loss: 0.3243\n",
      "Epoch 873, Step 1, LR: 0.000080, Current Loss: 0.3257, Avg Loss: 0.3257\n",
      "Diff stats — min: -6.1595, max: 15.2793, mean: 2.2925, std: 2.1484\n",
      "\n",
      "Step 9589 — Test metrics:\n",
      "  precision@10: 0.007432611\n",
      "  recall@10: 0.007436281\n",
      "  ndcg@10: 0.007688718\n",
      "  map@10: 0.002411344\n",
      "Epoch 873, Step 10, LR: 0.000080, Current Loss: 0.3252, Avg Loss: 0.3244\n",
      "Diff stats — min: -6.3587, max: 13.0647, mean: 2.2773, std: 2.1275\n",
      "\n",
      "Step 9598 — Test metrics:\n",
      "  precision@10: 0.007406184\n",
      "  recall@10: 0.007409854\n",
      "  ndcg@10: 0.007616008\n",
      "  map@10: 0.002371407\n",
      "Epoch 873 completed, Train Loss: 0.3247\n",
      "Epoch 874, Step 1, LR: 0.000080, Current Loss: 0.3230, Avg Loss: 0.3230\n",
      "Diff stats — min: -6.7423, max: 13.2050, mean: 2.2992, std: 2.1367\n",
      "\n",
      "Step 9600 — Test metrics:\n",
      "  precision@10: 0.007359937\n",
      "  recall@10: 0.007363607\n",
      "  ndcg@10: 0.007569728\n",
      "  map@10: 0.002355532\n",
      "Epoch 874, Step 10, LR: 0.000080, Current Loss: 0.3212, Avg Loss: 0.3227\n",
      "Diff stats — min: -6.2535, max: 12.8861, mean: 2.3058, std: 2.1452\n",
      "\n",
      "Step 9609 — Test metrics:\n",
      "  precision@10: 0.007459038\n",
      "  recall@10: 0.007462708\n",
      "  ndcg@10: 0.007739087\n",
      "  map@10: 0.002428681\n",
      "Epoch 874 completed, Train Loss: 0.3222\n",
      "Epoch 875, Step 1, LR: 0.000080, Current Loss: 0.3296, Avg Loss: 0.3296\n",
      "Diff stats — min: -6.0634, max: 12.8400, mean: 2.2890, std: 2.1612\n",
      "\n",
      "Step 9611 — Test metrics:\n",
      "  precision@10: 0.007485465\n",
      "  recall@10: 0.007489136\n",
      "  ndcg@10: 0.007764065\n",
      "  map@10: 0.002438273\n",
      "Epoch 875, Step 10, LR: 0.000080, Current Loss: 0.3272, Avg Loss: 0.3221\n",
      "Diff stats — min: -5.8869, max: 13.0044, mean: 2.2788, std: 2.1424\n",
      "\n",
      "Step 9620 — Test metrics:\n",
      "  precision@10: 0.007465645\n",
      "  recall@10: 0.007469315\n",
      "  ndcg@10: 0.007752167\n",
      "  map@10: 0.002433862\n",
      "Epoch 875 completed, Train Loss: 0.3225\n",
      "Epoch 876, Step 1, LR: 0.000080, Current Loss: 0.3230, Avg Loss: 0.3230\n",
      "Diff stats — min: -6.3168, max: 12.9463, mean: 2.2922, std: 2.1307\n",
      "\n",
      "Step 9622 — Test metrics:\n",
      "  precision@10: 0.007492072\n",
      "  recall@10: 0.007495742\n",
      "  ndcg@10: 0.007765964\n",
      "  map@10: 0.002437640\n",
      "Epoch 876, Step 10, LR: 0.000080, Current Loss: 0.3212, Avg Loss: 0.3225\n",
      "Diff stats — min: -7.0962, max: 14.4665, mean: 2.2981, std: 2.1311\n",
      "\n",
      "Step 9631 — Test metrics:\n",
      "  precision@10: 0.007511892\n",
      "  recall@10: 0.007515563\n",
      "  ndcg@10: 0.007789986\n",
      "  map@10: 0.002447817\n",
      "Epoch 876 completed, Train Loss: 0.3225\n",
      "Epoch 877, Step 1, LR: 0.000080, Current Loss: 0.3225, Avg Loss: 0.3225\n",
      "Diff stats — min: -5.8873, max: 16.0408, mean: 2.2998, std: 2.1365\n",
      "\n",
      "Step 9633 — Test metrics:\n",
      "  precision@10: 0.007485465\n",
      "  recall@10: 0.007489136\n",
      "  ndcg@10: 0.007787118\n",
      "  map@10: 0.002453934\n",
      "Epoch 877, Step 10, LR: 0.000080, Current Loss: 0.3250, Avg Loss: 0.3246\n",
      "Diff stats — min: -6.2350, max: 13.9306, mean: 2.2929, std: 2.1370\n",
      "\n",
      "Step 9642 — Test metrics:\n",
      "  precision@10: 0.007379757\n",
      "  recall@10: 0.007383427\n",
      "  ndcg@10: 0.007615949\n",
      "  map@10: 0.002379212\n",
      "Epoch 877 completed, Train Loss: 0.3242\n",
      "Epoch 878, Step 1, LR: 0.000080, Current Loss: 0.3228, Avg Loss: 0.3228\n",
      "Diff stats — min: -5.7565, max: 13.9229, mean: 2.3206, std: 2.1566\n",
      "\n",
      "Step 9644 — Test metrics:\n",
      "  precision@10: 0.007406184\n",
      "  recall@10: 0.007409854\n",
      "  ndcg@10: 0.007629331\n",
      "  map@10: 0.002380407\n",
      "Epoch 878, Step 10, LR: 0.000080, Current Loss: 0.3271, Avg Loss: 0.3224\n",
      "Diff stats — min: -7.3654, max: 13.9817, mean: 2.2851, std: 2.1510\n",
      "\n",
      "Step 9653 — Test metrics:\n",
      "  precision@10: 0.007498679\n",
      "  recall@10: 0.007502349\n",
      "  ndcg@10: 0.007738077\n",
      "  map@10: 0.002422712\n",
      "Epoch 878 completed, Train Loss: 0.3222\n",
      "Epoch 879, Step 1, LR: 0.000080, Current Loss: 0.3219, Avg Loss: 0.3219\n",
      "Diff stats — min: -7.7525, max: 11.1080, mean: 2.3084, std: 2.1410\n",
      "\n",
      "Step 9655 — Test metrics:\n",
      "  precision@10: 0.007518499\n",
      "  recall@10: 0.007522169\n",
      "  ndcg@10: 0.007774597\n",
      "  map@10: 0.002441950\n",
      "Epoch 879, Step 10, LR: 0.000080, Current Loss: 0.3230, Avg Loss: 0.3216\n",
      "Diff stats — min: -5.2552, max: 12.7775, mean: 2.3042, std: 2.1491\n",
      "\n",
      "Step 9664 — Test metrics:\n",
      "  precision@10: 0.007544926\n",
      "  recall@10: 0.007548596\n",
      "  ndcg@10: 0.007830300\n",
      "  map@10: 0.002460871\n",
      "Epoch 879 completed, Train Loss: 0.3221\n",
      "Epoch 880, Step 1, LR: 0.000080, Current Loss: 0.3237, Avg Loss: 0.3237\n",
      "Diff stats — min: -8.4403, max: 13.9721, mean: 2.2989, std: 2.1402\n",
      "\n",
      "Step 9666 — Test metrics:\n",
      "  precision@10: 0.007505285\n",
      "  recall@10: 0.007508956\n",
      "  ndcg@10: 0.007781622\n",
      "  map@10: 0.002443465\n",
      "Epoch 880, Step 10, LR: 0.000080, Current Loss: 0.3247, Avg Loss: 0.3236\n",
      "Diff stats — min: -6.3848, max: 14.7356, mean: 2.3104, std: 2.1664\n",
      "\n",
      "Step 9675 — Test metrics:\n",
      "  precision@10: 0.007571353\n",
      "  recall@10: 0.007575023\n",
      "  ndcg@10: 0.007813334\n",
      "  map@10: 0.002449228\n",
      "Epoch 880 completed, Train Loss: 0.3233\n",
      "Epoch 881, Step 1, LR: 0.000080, Current Loss: 0.3235, Avg Loss: 0.3235\n",
      "Diff stats — min: -7.0957, max: 12.9445, mean: 2.3034, std: 2.1512\n",
      "\n",
      "Step 9677 — Test metrics:\n",
      "  precision@10: 0.007538319\n",
      "  recall@10: 0.007541990\n",
      "  ndcg@10: 0.007779497\n",
      "  map@10: 0.002437189\n",
      "Epoch 881, Step 10, LR: 0.000080, Current Loss: 0.3223, Avg Loss: 0.3216\n",
      "Diff stats — min: -7.1368, max: 14.0989, mean: 2.2955, std: 2.1394\n",
      "\n",
      "Step 9686 — Test metrics:\n",
      "  precision@10: 0.007511892\n",
      "  recall@10: 0.007515563\n",
      "  ndcg@10: 0.007756692\n",
      "  map@10: 0.002428153\n",
      "Epoch 881 completed, Train Loss: 0.3218\n",
      "Epoch 882, Step 1, LR: 0.000080, Current Loss: 0.3246, Avg Loss: 0.3246\n",
      "Diff stats — min: -6.7079, max: 12.2412, mean: 2.2953, std: 2.1478\n",
      "\n",
      "Step 9688 — Test metrics:\n",
      "  precision@10: 0.007498679\n",
      "  recall@10: 0.007502349\n",
      "  ndcg@10: 0.007741352\n",
      "  map@10: 0.002421316\n",
      "Epoch 882, Step 10, LR: 0.000080, Current Loss: 0.3171, Avg Loss: 0.3208\n",
      "Diff stats — min: -5.8255, max: 15.9253, mean: 2.3103, std: 2.1280\n",
      "\n",
      "Step 9697 — Test metrics:\n",
      "  precision@10: 0.007505285\n",
      "  recall@10: 0.007508956\n",
      "  ndcg@10: 0.007782153\n",
      "  map@10: 0.002445758\n",
      "Epoch 882 completed, Train Loss: 0.3207\n",
      "Epoch 883, Step 1, LR: 0.000080, Current Loss: 0.3213, Avg Loss: 0.3213\n",
      "Diff stats — min: -6.2290, max: 12.1476, mean: 2.3133, std: 2.1545\n",
      "\n",
      "Step 9699 — Test metrics:\n",
      "  precision@10: 0.007459038\n",
      "  recall@10: 0.007462708\n",
      "  ndcg@10: 0.007761440\n",
      "  map@10: 0.002447636\n",
      "Epoch 883, Step 10, LR: 0.000080, Current Loss: 0.3261, Avg Loss: 0.3222\n",
      "Diff stats — min: -6.1343, max: 13.5270, mean: 2.2953, std: 2.1508\n",
      "\n",
      "Step 9708 — Test metrics:\n",
      "  precision@10: 0.007478858\n",
      "  recall@10: 0.007482529\n",
      "  ndcg@10: 0.007747599\n",
      "  map@10: 0.002431463\n",
      "Epoch 883 completed, Train Loss: 0.3219\n",
      "Epoch 884, Step 1, LR: 0.000080, Current Loss: 0.3205, Avg Loss: 0.3205\n",
      "Diff stats — min: -6.1508, max: 12.5626, mean: 2.3154, std: 2.1495\n",
      "\n",
      "Step 9710 — Test metrics:\n",
      "  precision@10: 0.007472252\n",
      "  recall@10: 0.007475922\n",
      "  ndcg@10: 0.007745236\n",
      "  map@10: 0.002434724\n",
      "Epoch 884, Step 10, LR: 0.000080, Current Loss: 0.3232, Avg Loss: 0.3219\n",
      "Diff stats — min: -6.3251, max: 12.4428, mean: 2.3047, std: 2.1460\n",
      "\n",
      "Step 9719 — Test metrics:\n",
      "  precision@10: 0.007492072\n",
      "  recall@10: 0.007495742\n",
      "  ndcg@10: 0.007713218\n",
      "  map@10: 0.002413781\n",
      "Epoch 884 completed, Train Loss: 0.3221\n",
      "Epoch 885, Step 1, LR: 0.000080, Current Loss: 0.3224, Avg Loss: 0.3224\n",
      "Diff stats — min: -8.4853, max: 14.1290, mean: 2.2974, std: 2.1405\n",
      "\n",
      "Step 9721 — Test metrics:\n",
      "  precision@10: 0.007511892\n",
      "  recall@10: 0.007515563\n",
      "  ndcg@10: 0.007740032\n",
      "  map@10: 0.002424161\n",
      "Epoch 885, Step 10, LR: 0.000080, Current Loss: 0.3217, Avg Loss: 0.3211\n",
      "Diff stats — min: -5.7607, max: 12.9945, mean: 2.3058, std: 2.1431\n",
      "\n",
      "Step 9730 — Test metrics:\n",
      "  precision@10: 0.007538319\n",
      "  recall@10: 0.007541990\n",
      "  ndcg@10: 0.007799039\n",
      "  map@10: 0.002449637\n",
      "Epoch 885 completed, Train Loss: 0.3210\n",
      "Epoch 886, Step 1, LR: 0.000080, Current Loss: 0.3133, Avg Loss: 0.3133\n",
      "Diff stats — min: -6.3237, max: 13.8236, mean: 2.3455, std: 2.1433\n",
      "\n",
      "Step 9732 — Test metrics:\n",
      "  precision@10: 0.007525106\n",
      "  recall@10: 0.007528776\n",
      "  ndcg@10: 0.007773496\n",
      "  map@10: 0.002440233\n",
      "Epoch 886, Step 10, LR: 0.000080, Current Loss: 0.3207, Avg Loss: 0.3214\n",
      "Diff stats — min: -5.6231, max: 12.7323, mean: 2.2919, std: 2.1290\n",
      "\n",
      "Step 9741 — Test metrics:\n",
      "  precision@10: 0.007472252\n",
      "  recall@10: 0.007475922\n",
      "  ndcg@10: 0.007671784\n",
      "  map@10: 0.002394324\n",
      "Epoch 886 completed, Train Loss: 0.3216\n",
      "Epoch 887, Step 1, LR: 0.000080, Current Loss: 0.3224, Avg Loss: 0.3224\n",
      "Diff stats — min: -6.6095, max: 12.3271, mean: 2.3278, std: 2.1623\n",
      "\n",
      "Step 9743 — Test metrics:\n",
      "  precision@10: 0.007492072\n",
      "  recall@10: 0.007495742\n",
      "  ndcg@10: 0.007684631\n",
      "  map@10: 0.002396093\n",
      "Epoch 887, Step 10, LR: 0.000080, Current Loss: 0.3218, Avg Loss: 0.3207\n",
      "Diff stats — min: -6.1557, max: 13.8325, mean: 2.3032, std: 2.1494\n",
      "\n",
      "Step 9752 — Test metrics:\n",
      "  precision@10: 0.007558140\n",
      "  recall@10: 0.007561810\n",
      "  ndcg@10: 0.007795399\n",
      "  map@10: 0.002437706\n",
      "Epoch 887 completed, Train Loss: 0.3208\n",
      "Epoch 888, Step 1, LR: 0.000080, Current Loss: 0.3231, Avg Loss: 0.3231\n",
      "Diff stats — min: -7.6460, max: 13.2058, mean: 2.2937, std: 2.1401\n",
      "\n",
      "Step 9754 — Test metrics:\n",
      "  precision@10: 0.007531712\n",
      "  recall@10: 0.007535383\n",
      "  ndcg@10: 0.007790068\n",
      "  map@10: 0.002442417\n",
      "Epoch 888, Step 10, LR: 0.000080, Current Loss: 0.3231, Avg Loss: 0.3215\n",
      "Diff stats — min: -5.9826, max: 13.1282, mean: 2.3024, std: 2.1475\n",
      "\n",
      "Step 9763 — Test metrics:\n",
      "  precision@10: 0.007617600\n",
      "  recall@10: 0.007621271\n",
      "  ndcg@10: 0.007832096\n",
      "  map@10: 0.002446069\n",
      "Epoch 888 completed, Train Loss: 0.3214\n",
      "Epoch 889, Step 1, LR: 0.000080, Current Loss: 0.3234, Avg Loss: 0.3234\n",
      "Diff stats — min: -6.0801, max: 12.3032, mean: 2.3015, std: 2.1431\n",
      "\n",
      "Step 9765 — Test metrics:\n",
      "  precision@10: 0.007597780\n",
      "  recall@10: 0.007601451\n",
      "  ndcg@10: 0.007820944\n",
      "  map@10: 0.002446100\n",
      "Epoch 889, Step 10, LR: 0.000080, Current Loss: 0.3191, Avg Loss: 0.3222\n",
      "Diff stats — min: -6.1121, max: 11.4126, mean: 2.3185, std: 2.1468\n",
      "\n",
      "Step 9774 — Test metrics:\n",
      "  precision@10: 0.007531712\n",
      "  recall@10: 0.007535383\n",
      "  ndcg@10: 0.007734269\n",
      "  map@10: 0.002412649\n",
      "Epoch 889 completed, Train Loss: 0.3214\n",
      "Epoch 890, Step 1, LR: 0.000080, Current Loss: 0.3207, Avg Loss: 0.3207\n",
      "Diff stats — min: -6.3057, max: 14.4638, mean: 2.3150, std: 2.1482\n",
      "\n",
      "Step 9776 — Test metrics:\n",
      "  precision@10: 0.007525106\n",
      "  recall@10: 0.007528776\n",
      "  ndcg@10: 0.007723429\n",
      "  map@10: 0.002406192\n",
      "Epoch 890, Step 10, LR: 0.000080, Current Loss: 0.3224, Avg Loss: 0.3218\n",
      "Diff stats — min: -8.1503, max: 12.3787, mean: 2.3152, std: 2.1522\n",
      "\n",
      "Step 9785 — Test metrics:\n",
      "  precision@10: 0.007551533\n",
      "  recall@10: 0.007555203\n",
      "  ndcg@10: 0.007800387\n",
      "  map@10: 0.002444962\n",
      "Epoch 890 completed, Train Loss: 0.3219\n",
      "Epoch 891, Step 1, LR: 0.000080, Current Loss: 0.3204, Avg Loss: 0.3204\n",
      "Diff stats — min: -7.3214, max: 11.8678, mean: 2.3261, std: 2.1541\n",
      "\n",
      "Step 9787 — Test metrics:\n",
      "  precision@10: 0.007538319\n",
      "  recall@10: 0.007541990\n",
      "  ndcg@10: 0.007790565\n",
      "  map@10: 0.002442881\n",
      "Epoch 891, Step 10, LR: 0.000080, Current Loss: 0.3164, Avg Loss: 0.3205\n",
      "Diff stats — min: -6.3125, max: 14.8795, mean: 2.3308, std: 2.1449\n",
      "\n",
      "Step 9796 — Test metrics:\n",
      "  precision@10: 0.007591173\n",
      "  recall@10: 0.007594844\n",
      "  ndcg@10: 0.007802424\n",
      "  map@10: 0.002441153\n",
      "Epoch 891 completed, Train Loss: 0.3207\n",
      "Epoch 892, Step 1, LR: 0.000080, Current Loss: 0.3249, Avg Loss: 0.3249\n",
      "Diff stats — min: -5.8226, max: 14.7027, mean: 2.3169, std: 2.1664\n",
      "\n",
      "Step 9798 — Test metrics:\n",
      "  precision@10: 0.007597780\n",
      "  recall@10: 0.007601451\n",
      "  ndcg@10: 0.007815802\n",
      "  map@10: 0.002446336\n",
      "Epoch 892, Step 10, LR: 0.000080, Current Loss: 0.3215, Avg Loss: 0.3208\n",
      "Diff stats — min: -6.8454, max: 14.1931, mean: 2.3131, std: 2.1511\n",
      "\n",
      "Step 9807 — Test metrics:\n",
      "  precision@10: 0.007558140\n",
      "  recall@10: 0.007561810\n",
      "  ndcg@10: 0.007819688\n",
      "  map@10: 0.002458063\n",
      "Epoch 892 completed, Train Loss: 0.3208\n",
      "Epoch 893, Step 1, LR: 0.000080, Current Loss: 0.3216, Avg Loss: 0.3216\n",
      "Diff stats — min: -6.1134, max: 16.8425, mean: 2.3206, std: 2.1590\n",
      "\n",
      "Step 9809 — Test metrics:\n",
      "  precision@10: 0.007610994\n",
      "  recall@10: 0.007614664\n",
      "  ndcg@10: 0.007820437\n",
      "  map@10: 0.002445025\n",
      "Epoch 893, Step 10, LR: 0.000080, Current Loss: 0.3211, Avg Loss: 0.3213\n",
      "Diff stats — min: -5.5665, max: 11.1793, mean: 2.3135, std: 2.1409\n",
      "\n",
      "Step 9818 — Test metrics:\n",
      "  precision@10: 0.007478858\n",
      "  recall@10: 0.007482529\n",
      "  ndcg@10: 0.007687817\n",
      "  map@10: 0.002400657\n",
      "Epoch 893 completed, Train Loss: 0.3211\n",
      "Epoch 894, Step 1, LR: 0.000080, Current Loss: 0.3208, Avg Loss: 0.3208\n",
      "Diff stats — min: -5.7193, max: 12.4359, mean: 2.3250, std: 2.1528\n",
      "\n",
      "Step 9820 — Test metrics:\n",
      "  precision@10: 0.007452431\n",
      "  recall@10: 0.007456102\n",
      "  ndcg@10: 0.007696670\n",
      "  map@10: 0.002411776\n",
      "Epoch 894, Step 10, LR: 0.000080, Current Loss: 0.3242, Avg Loss: 0.3202\n",
      "Diff stats — min: -6.7603, max: 12.1949, mean: 2.3078, std: 2.1537\n",
      "\n",
      "Step 9829 — Test metrics:\n",
      "  precision@10: 0.007617600\n",
      "  recall@10: 0.007621271\n",
      "  ndcg@10: 0.007838142\n",
      "  map@10: 0.002450362\n",
      "Epoch 894 completed, Train Loss: 0.3203\n",
      "Epoch 895, Step 1, LR: 0.000080, Current Loss: 0.3240, Avg Loss: 0.3240\n",
      "Diff stats — min: -6.9578, max: 13.5591, mean: 2.3116, std: 2.1601\n",
      "\n",
      "Step 9831 — Test metrics:\n",
      "  precision@10: 0.007571353\n",
      "  recall@10: 0.007575023\n",
      "  ndcg@10: 0.007785441\n",
      "  map@10: 0.002430822\n",
      "Epoch 895, Step 10, LR: 0.000080, Current Loss: 0.3207, Avg Loss: 0.3202\n",
      "Diff stats — min: -6.1141, max: 12.0761, mean: 2.3253, std: 2.1507\n",
      "\n",
      "Step 9840 — Test metrics:\n",
      "  precision@10: 0.007551533\n",
      "  recall@10: 0.007555203\n",
      "  ndcg@10: 0.007773550\n",
      "  map@10: 0.002433007\n",
      "Epoch 895 completed, Train Loss: 0.3200\n",
      "Epoch 896, Step 1, LR: 0.000080, Current Loss: 0.3170, Avg Loss: 0.3170\n",
      "Diff stats — min: -7.5513, max: 12.5044, mean: 2.3281, std: 2.1421\n",
      "\n",
      "Step 9842 — Test metrics:\n",
      "  precision@10: 0.007591173\n",
      "  recall@10: 0.007594844\n",
      "  ndcg@10: 0.007791174\n",
      "  map@10: 0.002432284\n",
      "Epoch 896, Step 10, LR: 0.000080, Current Loss: 0.3238, Avg Loss: 0.3196\n",
      "Diff stats — min: -6.3252, max: 14.0066, mean: 2.3078, std: 2.1615\n",
      "\n",
      "Step 9851 — Test metrics:\n",
      "  precision@10: 0.007564746\n",
      "  recall@10: 0.007568417\n",
      "  ndcg@10: 0.007822369\n",
      "  map@10: 0.002453521\n",
      "Epoch 896 completed, Train Loss: 0.3199\n",
      "Epoch 897, Step 1, LR: 0.000080, Current Loss: 0.3162, Avg Loss: 0.3162\n",
      "Diff stats — min: -5.9220, max: 14.0497, mean: 2.3363, std: 2.1458\n",
      "\n",
      "Step 9853 — Test metrics:\n",
      "  precision@10: 0.007571353\n",
      "  recall@10: 0.007575023\n",
      "  ndcg@10: 0.007826303\n",
      "  map@10: 0.002455349\n",
      "Epoch 897, Step 10, LR: 0.000080, Current Loss: 0.3237, Avg Loss: 0.3207\n",
      "Diff stats — min: -6.0960, max: 15.7393, mean: 2.3219, std: 2.1704\n",
      "\n",
      "Step 9862 — Test metrics:\n",
      "  precision@10: 0.007624207\n",
      "  recall@10: 0.007627878\n",
      "  ndcg@10: 0.007852714\n",
      "  map@10: 0.002457599\n",
      "Epoch 897 completed, Train Loss: 0.3206\n",
      "Epoch 898, Step 1, LR: 0.000080, Current Loss: 0.3221, Avg Loss: 0.3221\n",
      "Diff stats — min: -5.6654, max: 13.4378, mean: 2.3279, std: 2.1675\n",
      "\n",
      "Step 9864 — Test metrics:\n",
      "  precision@10: 0.007624207\n",
      "  recall@10: 0.007627878\n",
      "  ndcg@10: 0.007846832\n",
      "  map@10: 0.002453698\n",
      "Epoch 898, Step 10, LR: 0.000080, Current Loss: 0.3251, Avg Loss: 0.3211\n",
      "Diff stats — min: -8.4897, max: 12.6603, mean: 2.3216, std: 2.1666\n",
      "\n",
      "Step 9873 — Test metrics:\n",
      "  precision@10: 0.007525106\n",
      "  recall@10: 0.007528776\n",
      "  ndcg@10: 0.007753613\n",
      "  map@10: 0.002425739\n",
      "Epoch 898 completed, Train Loss: 0.3212\n",
      "Epoch 899, Step 1, LR: 0.000080, Current Loss: 0.3250, Avg Loss: 0.3250\n",
      "Diff stats — min: -6.2134, max: 13.2828, mean: 2.3114, std: 2.1633\n",
      "\n",
      "Step 9875 — Test metrics:\n",
      "  precision@10: 0.007518499\n",
      "  recall@10: 0.007522169\n",
      "  ndcg@10: 0.007743638\n",
      "  map@10: 0.002423715\n",
      "Epoch 899, Step 10, LR: 0.000080, Current Loss: 0.3232, Avg Loss: 0.3212\n",
      "Diff stats — min: -5.6219, max: 12.0963, mean: 2.3125, std: 2.1626\n",
      "\n",
      "Step 9884 — Test metrics:\n",
      "  precision@10: 0.007498679\n",
      "  recall@10: 0.007502349\n",
      "  ndcg@10: 0.007662603\n",
      "  map@10: 0.002378082\n",
      "Epoch 899 completed, Train Loss: 0.3210\n",
      "Epoch 900, Step 1, LR: 0.000080, Current Loss: 0.3212, Avg Loss: 0.3212\n",
      "Diff stats — min: -6.6094, max: 12.7941, mean: 2.3191, std: 2.1523\n",
      "\n",
      "Step 9886 — Test metrics:\n",
      "  precision@10: 0.007492072\n",
      "  recall@10: 0.007495742\n",
      "  ndcg@10: 0.007677518\n",
      "  map@10: 0.002392381\n",
      "Epoch 900, Step 10, LR: 0.000080, Current Loss: 0.3199, Avg Loss: 0.3213\n",
      "Diff stats — min: -6.3026, max: 12.8983, mean: 2.3313, std: 2.1593\n",
      "\n",
      "Step 9895 — Test metrics:\n",
      "  precision@10: 0.007584567\n",
      "  recall@10: 0.007588237\n",
      "  ndcg@10: 0.007820892\n",
      "  map@10: 0.002448929\n",
      "Epoch 900 completed, Train Loss: 0.3210\n",
      "Epoch 901, Step 1, LR: 0.000080, Current Loss: 0.3241, Avg Loss: 0.3241\n",
      "Diff stats — min: -6.9245, max: 12.4969, mean: 2.3243, std: 2.1741\n",
      "\n",
      "Step 9897 — Test metrics:\n",
      "  precision@10: 0.007577960\n",
      "  recall@10: 0.007581630\n",
      "  ndcg@10: 0.007807583\n",
      "  map@10: 0.002444637\n",
      "Epoch 901, Step 10, LR: 0.000080, Current Loss: 0.3199, Avg Loss: 0.3214\n",
      "Diff stats — min: -6.7398, max: 13.9812, mean: 2.3198, std: 2.1477\n",
      "\n",
      "Step 9906 — Test metrics:\n",
      "  precision@10: 0.007577960\n",
      "  recall@10: 0.007581630\n",
      "  ndcg@10: 0.007782305\n",
      "  map@10: 0.002427541\n",
      "Epoch 901 completed, Train Loss: 0.3208\n",
      "Epoch 902, Step 1, LR: 0.000080, Current Loss: 0.3201, Avg Loss: 0.3201\n",
      "Diff stats — min: -5.7486, max: 11.8963, mean: 2.3249, std: 2.1557\n",
      "\n",
      "Step 9908 — Test metrics:\n",
      "  precision@10: 0.007544926\n",
      "  recall@10: 0.007548596\n",
      "  ndcg@10: 0.007745126\n",
      "  map@10: 0.002415004\n",
      "Epoch 902, Step 10, LR: 0.000080, Current Loss: 0.3242, Avg Loss: 0.3188\n",
      "Diff stats — min: -6.1229, max: 11.4056, mean: 2.3118, std: 2.1607\n",
      "\n",
      "Step 9917 — Test metrics:\n",
      "  precision@10: 0.007498679\n",
      "  recall@10: 0.007502349\n",
      "  ndcg@10: 0.007729185\n",
      "  map@10: 0.002419322\n",
      "Epoch 902 completed, Train Loss: 0.3184\n",
      "Epoch 903, Step 1, LR: 0.000080, Current Loss: 0.3191, Avg Loss: 0.3191\n",
      "Diff stats — min: -7.0053, max: 13.5866, mean: 2.3316, std: 2.1525\n",
      "\n",
      "Step 9919 — Test metrics:\n",
      "  precision@10: 0.007485465\n",
      "  recall@10: 0.007489136\n",
      "  ndcg@10: 0.007734958\n",
      "  map@10: 0.002425994\n",
      "Epoch 903, Step 10, LR: 0.000080, Current Loss: 0.3219, Avg Loss: 0.3212\n",
      "Diff stats — min: -6.9186, max: 13.0111, mean: 2.3376, std: 2.1756\n",
      "\n",
      "Step 9928 — Test metrics:\n",
      "  precision@10: 0.007459038\n",
      "  recall@10: 0.007462708\n",
      "  ndcg@10: 0.007654529\n",
      "  map@10: 0.002385505\n",
      "Epoch 903 completed, Train Loss: 0.3210\n",
      "Epoch 904, Step 1, LR: 0.000080, Current Loss: 0.3233, Avg Loss: 0.3233\n",
      "Diff stats — min: -5.9489, max: 14.8386, mean: 2.3071, std: 2.1530\n",
      "\n",
      "Step 9930 — Test metrics:\n",
      "  precision@10: 0.007485465\n",
      "  recall@10: 0.007489136\n",
      "  ndcg@10: 0.007644318\n",
      "  map@10: 0.002372226\n",
      "Epoch 904, Step 10, LR: 0.000080, Current Loss: 0.3179, Avg Loss: 0.3202\n",
      "Diff stats — min: -6.4272, max: 12.9204, mean: 2.3274, std: 2.1503\n",
      "\n",
      "Step 9939 — Test metrics:\n",
      "  precision@10: 0.007577960\n",
      "  recall@10: 0.007581630\n",
      "  ndcg@10: 0.007757154\n",
      "  map@10: 0.002413947\n",
      "Epoch 904 completed, Train Loss: 0.3204\n",
      "Epoch 905, Step 1, LR: 0.000080, Current Loss: 0.3239, Avg Loss: 0.3239\n",
      "Diff stats — min: -7.6099, max: 13.8193, mean: 2.3043, std: 2.1537\n",
      "\n",
      "Step 9941 — Test metrics:\n",
      "  precision@10: 0.007597780\n",
      "  recall@10: 0.007601451\n",
      "  ndcg@10: 0.007768975\n",
      "  map@10: 0.002414466\n",
      "Epoch 905, Step 10, LR: 0.000080, Current Loss: 0.3243, Avg Loss: 0.3208\n",
      "Diff stats — min: -5.9765, max: 13.7173, mean: 2.3173, std: 2.1699\n",
      "\n",
      "Step 9950 — Test metrics:\n",
      "  precision@10: 0.007617600\n",
      "  recall@10: 0.007621271\n",
      "  ndcg@10: 0.007808659\n",
      "  map@10: 0.002435925\n",
      "Epoch 905 completed, Train Loss: 0.3205\n",
      "Epoch 906, Step 1, LR: 0.000080, Current Loss: 0.3185, Avg Loss: 0.3185\n",
      "Diff stats — min: -5.3956, max: 11.8368, mean: 2.3340, std: 2.1571\n",
      "\n",
      "Step 9952 — Test metrics:\n",
      "  precision@10: 0.007577960\n",
      "  recall@10: 0.007581630\n",
      "  ndcg@10: 0.007780632\n",
      "  map@10: 0.002429559\n",
      "Epoch 906, Step 10, LR: 0.000080, Current Loss: 0.3176, Avg Loss: 0.3189\n",
      "Diff stats — min: -5.6960, max: 13.3025, mean: 2.3428, std: 2.1617\n",
      "\n",
      "Step 9961 — Test metrics:\n",
      "  precision@10: 0.007584567\n",
      "  recall@10: 0.007588237\n",
      "  ndcg@10: 0.007816580\n",
      "  map@10: 0.002450415\n",
      "Epoch 906 completed, Train Loss: 0.3190\n",
      "Epoch 907, Step 1, LR: 0.000080, Current Loss: 0.3215, Avg Loss: 0.3215\n",
      "Diff stats — min: -6.3067, max: 13.7379, mean: 2.3213, std: 2.1626\n",
      "\n",
      "Step 9963 — Test metrics:\n",
      "  precision@10: 0.007617600\n",
      "  recall@10: 0.007621271\n",
      "  ndcg@10: 0.007824476\n",
      "  map@10: 0.002446178\n",
      "Epoch 907, Step 10, LR: 0.000080, Current Loss: 0.3197, Avg Loss: 0.3202\n",
      "Diff stats — min: -7.4869, max: 16.8153, mean: 2.3356, std: 2.1665\n",
      "\n",
      "Step 9972 — Test metrics:\n",
      "  precision@10: 0.007511892\n",
      "  recall@10: 0.007515563\n",
      "  ndcg@10: 0.007723856\n",
      "  map@10: 0.002414063\n",
      "Epoch 907 completed, Train Loss: 0.3197\n",
      "Epoch 908, Step 1, LR: 0.000080, Current Loss: 0.3191, Avg Loss: 0.3191\n",
      "Diff stats — min: -6.3669, max: 12.1553, mean: 2.3453, std: 2.1697\n",
      "\n",
      "Step 9974 — Test metrics:\n",
      "  precision@10: 0.007459038\n",
      "  recall@10: 0.007462708\n",
      "  ndcg@10: 0.007696173\n",
      "  map@10: 0.002410411\n",
      "Epoch 908, Step 10, LR: 0.000080, Current Loss: 0.3190, Avg Loss: 0.3209\n",
      "Diff stats — min: -6.3841, max: 11.2478, mean: 2.3394, std: 2.1653\n",
      "\n",
      "Step 9983 — Test metrics:\n",
      "  precision@10: 0.007591173\n",
      "  recall@10: 0.007594844\n",
      "  ndcg@10: 0.007796764\n",
      "  map@10: 0.002432430\n",
      "Epoch 908 completed, Train Loss: 0.3208\n",
      "Epoch 909, Step 1, LR: 0.000080, Current Loss: 0.3174, Avg Loss: 0.3174\n",
      "Diff stats — min: -6.0295, max: 12.0407, mean: 2.3279, std: 2.1477\n",
      "\n",
      "Step 9985 — Test metrics:\n",
      "  precision@10: 0.007644027\n",
      "  recall@10: 0.007647698\n",
      "  ndcg@10: 0.007818195\n",
      "  map@10: 0.002434363\n",
      "Epoch 909, Step 10, LR: 0.000080, Current Loss: 0.3222, Avg Loss: 0.3179\n",
      "Diff stats — min: -6.2795, max: 13.1871, mean: 2.3262, std: 2.1689\n",
      "\n",
      "Step 9994 — Test metrics:\n",
      "  precision@10: 0.007472252\n",
      "  recall@10: 0.007475922\n",
      "  ndcg@10: 0.007698029\n",
      "  map@10: 0.002404542\n",
      "Epoch 909 completed, Train Loss: 0.3180\n",
      "Epoch 910, Step 1, LR: 0.000080, Current Loss: 0.3148, Avg Loss: 0.3148\n",
      "Diff stats — min: -6.6840, max: 12.5635, mean: 2.3474, std: 2.1542\n",
      "\n",
      "Step 9996 — Test metrics:\n",
      "  precision@10: 0.007505285\n",
      "  recall@10: 0.007508956\n",
      "  ndcg@10: 0.007725834\n",
      "  map@10: 0.002413611\n",
      "Epoch 910, Step 10, LR: 0.000080, Current Loss: 0.3165, Avg Loss: 0.3199\n",
      "Diff stats — min: -5.3439, max: 12.0976, mean: 2.3395, std: 2.1525\n",
      "\n",
      "Step 10005 — Test metrics:\n",
      "  precision@10: 0.007525106\n",
      "  recall@10: 0.007528776\n",
      "  ndcg@10: 0.007747941\n",
      "  map@10: 0.002423304\n",
      "Epoch 910 completed, Train Loss: 0.3195\n",
      "Epoch 911, Step 1, LR: 0.000080, Current Loss: 0.3212, Avg Loss: 0.3212\n",
      "Diff stats — min: -6.5158, max: 13.4095, mean: 2.3185, std: 2.1632\n",
      "\n",
      "Step 10007 — Test metrics:\n",
      "  precision@10: 0.007551533\n",
      "  recall@10: 0.007555203\n",
      "  ndcg@10: 0.007780845\n",
      "  map@10: 0.002435136\n",
      "Epoch 911, Step 10, LR: 0.000080, Current Loss: 0.3187, Avg Loss: 0.3178\n",
      "Diff stats — min: -6.1683, max: 14.1150, mean: 2.3435, std: 2.1635\n",
      "\n",
      "Step 10016 — Test metrics:\n",
      "  precision@10: 0.007571353\n",
      "  recall@10: 0.007575023\n",
      "  ndcg@10: 0.007752348\n",
      "  map@10: 0.002414286\n",
      "Epoch 911 completed, Train Loss: 0.3181\n",
      "Epoch 912, Step 1, LR: 0.000080, Current Loss: 0.3198, Avg Loss: 0.3198\n",
      "Diff stats — min: -5.4893, max: 13.4753, mean: 2.3342, std: 2.1697\n",
      "\n",
      "Step 10018 — Test metrics:\n",
      "  precision@10: 0.007624207\n",
      "  recall@10: 0.007627878\n",
      "  ndcg@10: 0.007782915\n",
      "  map@10: 0.002418719\n",
      "Epoch 912, Step 10, LR: 0.000080, Current Loss: 0.3142, Avg Loss: 0.3185\n",
      "Diff stats — min: -7.6609, max: 17.0638, mean: 2.3506, std: 2.1591\n",
      "\n",
      "Step 10027 — Test metrics:\n",
      "  precision@10: 0.007492072\n",
      "  recall@10: 0.007495742\n",
      "  ndcg@10: 0.007684858\n",
      "  map@10: 0.002395715\n",
      "Epoch 912 completed, Train Loss: 0.3186\n",
      "Epoch 913, Step 1, LR: 0.000080, Current Loss: 0.3187, Avg Loss: 0.3187\n",
      "Diff stats — min: -5.6779, max: 16.0695, mean: 2.3315, std: 2.1514\n",
      "\n",
      "Step 10029 — Test metrics:\n",
      "  precision@10: 0.007492072\n",
      "  recall@10: 0.007495742\n",
      "  ndcg@10: 0.007704801\n",
      "  map@10: 0.002405670\n",
      "Epoch 913, Step 10, LR: 0.000080, Current Loss: 0.3204, Avg Loss: 0.3200\n",
      "Diff stats — min: -5.7804, max: 14.1795, mean: 2.3515, std: 2.1830\n",
      "\n",
      "Step 10038 — Test metrics:\n",
      "  precision@10: 0.007610994\n",
      "  recall@10: 0.007614664\n",
      "  ndcg@10: 0.007829304\n",
      "  map@10: 0.002448886\n",
      "Epoch 913 completed, Train Loss: 0.3198\n",
      "Epoch 914, Step 1, LR: 0.000080, Current Loss: 0.3216, Avg Loss: 0.3216\n",
      "Diff stats — min: -7.1026, max: 14.4767, mean: 2.3245, std: 2.1634\n",
      "\n",
      "Step 10040 — Test metrics:\n",
      "  precision@10: 0.007597780\n",
      "  recall@10: 0.007601451\n",
      "  ndcg@10: 0.007812489\n",
      "  map@10: 0.002443196\n",
      "Epoch 914, Step 10, LR: 0.000080, Current Loss: 0.3170, Avg Loss: 0.3188\n",
      "Diff stats — min: -6.3286, max: 14.7873, mean: 2.3440, std: 2.1666\n",
      "\n",
      "Step 10049 — Test metrics:\n",
      "  precision@10: 0.007577960\n",
      "  recall@10: 0.007580896\n",
      "  ndcg@10: 0.007741956\n",
      "  map@10: 0.002403825\n",
      "Epoch 914 completed, Train Loss: 0.3188\n",
      "Epoch 915, Step 1, LR: 0.000080, Current Loss: 0.3227, Avg Loss: 0.3227\n",
      "Diff stats — min: -7.0418, max: 13.6576, mean: 2.3378, std: 2.1768\n",
      "\n",
      "Step 10051 — Test metrics:\n",
      "  precision@10: 0.007591173\n",
      "  recall@10: 0.007594110\n",
      "  ndcg@10: 0.007751699\n",
      "  map@10: 0.002405867\n",
      "Epoch 915, Step 10, LR: 0.000080, Current Loss: 0.3120, Avg Loss: 0.3174\n",
      "Diff stats — min: -5.9872, max: 13.0749, mean: 2.3625, std: 2.1562\n",
      "\n",
      "Step 10060 — Test metrics:\n",
      "  precision@10: 0.007551533\n",
      "  recall@10: 0.007555203\n",
      "  ndcg@10: 0.007725156\n",
      "  map@10: 0.002401417\n",
      "Epoch 915 completed, Train Loss: 0.3174\n",
      "Epoch 916, Step 1, LR: 0.000080, Current Loss: 0.3130, Avg Loss: 0.3130\n",
      "Diff stats — min: -7.0336, max: 14.1374, mean: 2.3657, std: 2.1631\n",
      "\n",
      "Step 10062 — Test metrics:\n",
      "  precision@10: 0.007551533\n",
      "  recall@10: 0.007555203\n",
      "  ndcg@10: 0.007718599\n",
      "  map@10: 0.002396795\n",
      "Epoch 916, Step 10, LR: 0.000080, Current Loss: 0.3130, Avg Loss: 0.3177\n",
      "Diff stats — min: -6.1985, max: 13.5445, mean: 2.3577, std: 2.1580\n",
      "\n",
      "Step 10071 — Test metrics:\n",
      "  precision@10: 0.007492072\n",
      "  recall@10: 0.007495742\n",
      "  ndcg@10: 0.007660974\n",
      "  map@10: 0.002378292\n",
      "Epoch 916 completed, Train Loss: 0.3178\n",
      "Epoch 917, Step 1, LR: 0.000080, Current Loss: 0.3192, Avg Loss: 0.3192\n",
      "Diff stats — min: -7.2571, max: 12.3704, mean: 2.3421, std: 2.1627\n",
      "\n",
      "Step 10073 — Test metrics:\n",
      "  precision@10: 0.007518499\n",
      "  recall@10: 0.007522169\n",
      "  ndcg@10: 0.007687638\n",
      "  map@10: 0.002387985\n",
      "Epoch 917, Step 10, LR: 0.000080, Current Loss: 0.3181, Avg Loss: 0.3190\n",
      "Diff stats — min: -7.2720, max: 13.2804, mean: 2.3468, std: 2.1670\n",
      "\n",
      "Step 10082 — Test metrics:\n",
      "  precision@10: 0.007604387\n",
      "  recall@10: 0.007608057\n",
      "  ndcg@10: 0.007769477\n",
      "  map@10: 0.002413691\n",
      "Epoch 917 completed, Train Loss: 0.3188\n",
      "Epoch 918, Step 1, LR: 0.000080, Current Loss: 0.3202, Avg Loss: 0.3202\n",
      "Diff stats — min: -6.2481, max: 11.8460, mean: 2.3419, std: 2.1644\n",
      "\n",
      "Step 10084 — Test metrics:\n",
      "  precision@10: 0.007610994\n",
      "  recall@10: 0.007614664\n",
      "  ndcg@10: 0.007802709\n",
      "  map@10: 0.002431894\n",
      "Epoch 918, Step 10, LR: 0.000080, Current Loss: 0.3161, Avg Loss: 0.3183\n",
      "Diff stats — min: -7.1529, max: 15.0904, mean: 2.3583, std: 2.1683\n",
      "\n",
      "Step 10093 — Test metrics:\n",
      "  precision@10: 0.007571353\n",
      "  recall@10: 0.007575023\n",
      "  ndcg@10: 0.007747451\n",
      "  map@10: 0.002406969\n",
      "Epoch 918 completed, Train Loss: 0.3182\n",
      "Epoch 919, Step 1, LR: 0.000080, Current Loss: 0.3224, Avg Loss: 0.3224\n",
      "Diff stats — min: -6.3973, max: 12.7979, mean: 2.3287, std: 2.1710\n",
      "\n",
      "Step 10095 — Test metrics:\n",
      "  precision@10: 0.007558140\n",
      "  recall@10: 0.007561810\n",
      "  ndcg@10: 0.007734975\n",
      "  map@10: 0.002404275\n",
      "Epoch 919, Step 10, LR: 0.000080, Current Loss: 0.3209, Avg Loss: 0.3192\n",
      "Diff stats — min: -6.2897, max: 14.4791, mean: 2.3477, std: 2.1824\n",
      "\n",
      "Step 10104 — Test metrics:\n",
      "  precision@10: 0.007597780\n",
      "  recall@10: 0.007601451\n",
      "  ndcg@10: 0.007750290\n",
      "  map@10: 0.002405519\n",
      "Epoch 919 completed, Train Loss: 0.3188\n",
      "Epoch 920, Step 1, LR: 0.000080, Current Loss: 0.3166, Avg Loss: 0.3166\n",
      "Diff stats — min: -5.8589, max: 12.0903, mean: 2.3546, std: 2.1661\n",
      "\n",
      "Step 10106 — Test metrics:\n",
      "  precision@10: 0.007577960\n",
      "  recall@10: 0.007581630\n",
      "  ndcg@10: 0.007754269\n",
      "  map@10: 0.002412655\n",
      "Epoch 920, Step 10, LR: 0.000080, Current Loss: 0.3160, Avg Loss: 0.3183\n",
      "Diff stats — min: -6.3731, max: 12.6565, mean: 2.3582, std: 2.1681\n",
      "\n",
      "Step 10115 — Test metrics:\n",
      "  precision@10: 0.007558140\n",
      "  recall@10: 0.007561810\n",
      "  ndcg@10: 0.007759502\n",
      "  map@10: 0.002421197\n",
      "Epoch 920 completed, Train Loss: 0.3183\n",
      "Epoch 921, Step 1, LR: 0.000080, Current Loss: 0.3142, Avg Loss: 0.3142\n",
      "Diff stats — min: -8.9235, max: 12.7112, mean: 2.3559, std: 2.1579\n",
      "\n",
      "Step 10117 — Test metrics:\n",
      "  precision@10: 0.007544926\n",
      "  recall@10: 0.007548596\n",
      "  ndcg@10: 0.007725286\n",
      "  map@10: 0.002403762\n",
      "Epoch 921, Step 10, LR: 0.000080, Current Loss: 0.3159, Avg Loss: 0.3166\n",
      "Diff stats — min: -5.7094, max: 12.2262, mean: 2.3544, std: 2.1649\n",
      "\n",
      "Step 10126 — Test metrics:\n",
      "  precision@10: 0.007511892\n",
      "  recall@10: 0.007514829\n",
      "  ndcg@10: 0.007664261\n",
      "  map@10: 0.002376034\n",
      "Epoch 921 completed, Train Loss: 0.3169\n",
      "Epoch 922, Step 1, LR: 0.000080, Current Loss: 0.3214, Avg Loss: 0.3214\n",
      "Diff stats — min: -6.0400, max: 14.1284, mean: 2.3434, std: 2.1835\n",
      "\n",
      "Step 10128 — Test metrics:\n",
      "  precision@10: 0.007617600\n",
      "  recall@10: 0.007621271\n",
      "  ndcg@10: 0.007724801\n",
      "  map@10: 0.002383336\n",
      "Epoch 922, Step 10, LR: 0.000080, Current Loss: 0.3171, Avg Loss: 0.3194\n",
      "Diff stats — min: -5.9381, max: 13.9985, mean: 2.3560, std: 2.1766\n",
      "\n",
      "Step 10137 — Test metrics:\n",
      "  precision@10: 0.007716702\n",
      "  recall@10: 0.007720372\n",
      "  ndcg@10: 0.007872268\n",
      "  map@10: 0.002446040\n",
      "Epoch 922 completed, Train Loss: 0.3191\n",
      "Epoch 923, Step 1, LR: 0.000080, Current Loss: 0.3176, Avg Loss: 0.3176\n",
      "Diff stats — min: -5.3988, max: 14.6644, mean: 2.3493, std: 2.1727\n",
      "\n",
      "Step 10139 — Test metrics:\n",
      "  precision@10: 0.007650634\n",
      "  recall@10: 0.007654305\n",
      "  ndcg@10: 0.007821391\n",
      "  map@10: 0.002433002\n",
      "Epoch 923, Step 10, LR: 0.000080, Current Loss: 0.3188, Avg Loss: 0.3185\n",
      "Diff stats — min: -7.2742, max: 12.5951, mean: 2.3543, std: 2.1821\n",
      "\n",
      "Step 10148 — Test metrics:\n",
      "  precision@10: 0.007610994\n",
      "  recall@10: 0.007614664\n",
      "  ndcg@10: 0.007800458\n",
      "  map@10: 0.002426917\n",
      "Epoch 923 completed, Train Loss: 0.3186\n",
      "Epoch 924, Step 1, LR: 0.000080, Current Loss: 0.3202, Avg Loss: 0.3202\n",
      "Diff stats — min: -5.8463, max: 13.1651, mean: 2.3236, std: 2.1535\n",
      "\n",
      "Step 10150 — Test metrics:\n",
      "  precision@10: 0.007650634\n",
      "  recall@10: 0.007654305\n",
      "  ndcg@10: 0.007809973\n",
      "  map@10: 0.002421566\n",
      "Epoch 924, Step 10, LR: 0.000080, Current Loss: 0.3198, Avg Loss: 0.3179\n",
      "Diff stats — min: -6.4777, max: 13.5750, mean: 2.3439, std: 2.1764\n",
      "\n",
      "Step 10159 — Test metrics:\n",
      "  precision@10: 0.007492072\n",
      "  recall@10: 0.007495008\n",
      "  ndcg@10: 0.007661679\n",
      "  map@10: 0.002374333\n",
      "Epoch 924 completed, Train Loss: 0.3178\n",
      "Epoch 925, Step 1, LR: 0.000080, Current Loss: 0.3157, Avg Loss: 0.3157\n",
      "Diff stats — min: -5.8424, max: 14.1387, mean: 2.3566, std: 2.1722\n",
      "\n",
      "Step 10161 — Test metrics:\n",
      "  precision@10: 0.007551533\n",
      "  recall@10: 0.007554469\n",
      "  ndcg@10: 0.007702315\n",
      "  map@10: 0.002382251\n",
      "Epoch 925, Step 10, LR: 0.000080, Current Loss: 0.3182, Avg Loss: 0.3188\n",
      "Diff stats — min: -5.5855, max: 13.3548, mean: 2.3562, std: 2.1784\n",
      "\n",
      "Step 10170 — Test metrics:\n",
      "  precision@10: 0.007663848\n",
      "  recall@10: 0.007667518\n",
      "  ndcg@10: 0.007870935\n",
      "  map@10: 0.002458740\n",
      "Epoch 925 completed, Train Loss: 0.3185\n",
      "Epoch 926, Step 1, LR: 0.000080, Current Loss: 0.3189, Avg Loss: 0.3189\n",
      "Diff stats — min: -7.2881, max: 12.7582, mean: 2.3441, std: 2.1724\n",
      "\n",
      "Step 10172 — Test metrics:\n",
      "  precision@10: 0.007624207\n",
      "  recall@10: 0.007627878\n",
      "  ndcg@10: 0.007835212\n",
      "  map@10: 0.002447055\n",
      "Epoch 926, Step 10, LR: 0.000080, Current Loss: 0.3168, Avg Loss: 0.3190\n",
      "Diff stats — min: -6.5106, max: 13.3001, mean: 2.3639, std: 2.1747\n",
      "\n",
      "Step 10181 — Test metrics:\n",
      "  precision@10: 0.007591173\n",
      "  recall@10: 0.007594844\n",
      "  ndcg@10: 0.007766478\n",
      "  map@10: 0.002420312\n",
      "Epoch 926 completed, Train Loss: 0.3186\n",
      "Epoch 927, Step 1, LR: 0.000080, Current Loss: 0.3159, Avg Loss: 0.3159\n",
      "Diff stats — min: -6.0491, max: 13.4563, mean: 2.3671, std: 2.1764\n",
      "\n",
      "Step 10183 — Test metrics:\n",
      "  precision@10: 0.007624207\n",
      "  recall@10: 0.007627878\n",
      "  ndcg@10: 0.007764490\n",
      "  map@10: 0.002409369\n",
      "Epoch 927, Step 10, LR: 0.000080, Current Loss: 0.3154, Avg Loss: 0.3174\n",
      "Diff stats — min: -5.5949, max: 17.0853, mean: 2.3718, std: 2.1778\n",
      "\n",
      "Step 10192 — Test metrics:\n",
      "  precision@10: 0.007617600\n",
      "  recall@10: 0.007620537\n",
      "  ndcg@10: 0.007751384\n",
      "  map@10: 0.002402322\n",
      "Epoch 927 completed, Train Loss: 0.3174\n",
      "Epoch 928, Step 1, LR: 0.000080, Current Loss: 0.3182, Avg Loss: 0.3182\n",
      "Diff stats — min: -6.4578, max: 13.4005, mean: 2.3595, std: 2.1764\n",
      "\n",
      "Step 10194 — Test metrics:\n",
      "  precision@10: 0.007604387\n",
      "  recall@10: 0.007607323\n",
      "  ndcg@10: 0.007712888\n",
      "  map@10: 0.002382791\n",
      "Epoch 928, Step 10, LR: 0.000080, Current Loss: 0.3175, Avg Loss: 0.3169\n",
      "Diff stats — min: -6.5296, max: 14.8665, mean: 2.3557, std: 2.1709\n",
      "\n",
      "Step 10203 — Test metrics:\n",
      "  precision@10: 0.007637421\n",
      "  recall@10: 0.007641091\n",
      "  ndcg@10: 0.007754832\n",
      "  map@10: 0.002394978\n",
      "Epoch 928 completed, Train Loss: 0.3169\n",
      "Epoch 929, Step 1, LR: 0.000080, Current Loss: 0.3201, Avg Loss: 0.3201\n",
      "Diff stats — min: -6.4993, max: 14.3622, mean: 2.3475, std: 2.1867\n",
      "\n",
      "Step 10205 — Test metrics:\n",
      "  precision@10: 0.007597780\n",
      "  recall@10: 0.007600716\n",
      "  ndcg@10: 0.007730515\n",
      "  map@10: 0.002391620\n",
      "Epoch 929, Step 10, LR: 0.000080, Current Loss: 0.3161, Avg Loss: 0.3175\n",
      "Diff stats — min: -6.8517, max: 11.6429, mean: 2.3672, std: 2.1733\n",
      "\n",
      "Step 10214 — Test metrics:\n",
      "  precision@10: 0.007577960\n",
      "  recall@10: 0.007580896\n",
      "  ndcg@10: 0.007719841\n",
      "  map@10: 0.002394339\n",
      "Epoch 929 completed, Train Loss: 0.3179\n",
      "Epoch 930, Step 1, LR: 0.000080, Current Loss: 0.3179, Avg Loss: 0.3179\n",
      "Diff stats — min: -6.1807, max: 15.4485, mean: 2.3579, std: 2.1816\n",
      "\n",
      "Step 10216 — Test metrics:\n",
      "  precision@10: 0.007577960\n",
      "  recall@10: 0.007581630\n",
      "  ndcg@10: 0.007724657\n",
      "  map@10: 0.002399608\n",
      "Epoch 930, Step 10, LR: 0.000080, Current Loss: 0.3154, Avg Loss: 0.3183\n",
      "Diff stats — min: -6.8432, max: 13.3163, mean: 2.3597, std: 2.1672\n",
      "\n",
      "Step 10225 — Test metrics:\n",
      "  precision@10: 0.007571353\n",
      "  recall@10: 0.007575023\n",
      "  ndcg@10: 0.007727897\n",
      "  map@10: 0.002399295\n",
      "Epoch 930 completed, Train Loss: 0.3184\n",
      "Epoch 931, Step 1, LR: 0.000080, Current Loss: 0.3155, Avg Loss: 0.3155\n",
      "Diff stats — min: -6.3580, max: 15.6870, mean: 2.3547, std: 2.1681\n",
      "\n",
      "Step 10227 — Test metrics:\n",
      "  precision@10: 0.007610994\n",
      "  recall@10: 0.007614664\n",
      "  ndcg@10: 0.007775589\n",
      "  map@10: 0.002416926\n",
      "Epoch 931, Step 10, LR: 0.000080, Current Loss: 0.3211, Avg Loss: 0.3177\n",
      "Diff stats — min: -6.6591, max: 12.1038, mean: 2.3548, std: 2.1843\n",
      "\n",
      "Step 10236 — Test metrics:\n",
      "  precision@10: 0.007591173\n",
      "  recall@10: 0.007594844\n",
      "  ndcg@10: 0.007781432\n",
      "  map@10: 0.002424170\n",
      "Epoch 931 completed, Train Loss: 0.3174\n",
      "Epoch 932, Step 1, LR: 0.000080, Current Loss: 0.3172, Avg Loss: 0.3172\n",
      "Diff stats — min: -5.5577, max: 13.5022, mean: 2.3457, std: 2.1682\n",
      "\n",
      "Step 10238 — Test metrics:\n",
      "  precision@10: 0.007597780\n",
      "  recall@10: 0.007601451\n",
      "  ndcg@10: 0.007778233\n",
      "  map@10: 0.002420431\n",
      "Epoch 932, Step 10, LR: 0.000080, Current Loss: 0.3161, Avg Loss: 0.3161\n",
      "Diff stats — min: -5.9493, max: 12.1081, mean: 2.3515, std: 2.1675\n",
      "\n",
      "Step 10247 — Test metrics:\n",
      "  precision@10: 0.007577960\n",
      "  recall@10: 0.007580896\n",
      "  ndcg@10: 0.007737595\n",
      "  map@10: 0.002404440\n",
      "Epoch 932 completed, Train Loss: 0.3162\n",
      "Epoch 933, Step 1, LR: 0.000080, Current Loss: 0.3178, Avg Loss: 0.3178\n",
      "Diff stats — min: -6.8509, max: 16.3599, mean: 2.3650, std: 2.1789\n",
      "\n",
      "Step 10249 — Test metrics:\n",
      "  precision@10: 0.007577960\n",
      "  recall@10: 0.007580896\n",
      "  ndcg@10: 0.007731435\n",
      "  map@10: 0.002402695\n",
      "Epoch 933, Step 10, LR: 0.000080, Current Loss: 0.3194, Avg Loss: 0.3178\n",
      "Diff stats — min: -7.9335, max: 12.8617, mean: 2.3553, std: 2.1823\n",
      "\n",
      "Step 10258 — Test metrics:\n",
      "  precision@10: 0.007558140\n",
      "  recall@10: 0.007561076\n",
      "  ndcg@10: 0.007704361\n",
      "  map@10: 0.002388949\n",
      "Epoch 933 completed, Train Loss: 0.3175\n",
      "Epoch 934, Step 1, LR: 0.000080, Current Loss: 0.3182, Avg Loss: 0.3182\n",
      "Diff stats — min: -8.2115, max: 15.5455, mean: 2.3683, std: 2.1854\n",
      "\n",
      "Step 10260 — Test metrics:\n",
      "  precision@10: 0.007558140\n",
      "  recall@10: 0.007561076\n",
      "  ndcg@10: 0.007721772\n",
      "  map@10: 0.002399438\n",
      "Epoch 934, Step 10, LR: 0.000080, Current Loss: 0.3145, Avg Loss: 0.3185\n",
      "Diff stats — min: -6.2945, max: 13.3784, mean: 2.3721, std: 2.1779\n",
      "\n",
      "Step 10269 — Test metrics:\n",
      "  precision@10: 0.007637421\n",
      "  recall@10: 0.007641091\n",
      "  ndcg@10: 0.007808902\n",
      "  map@10: 0.002430145\n",
      "Epoch 934 completed, Train Loss: 0.3187\n",
      "Epoch 935, Step 1, LR: 0.000080, Current Loss: 0.3149, Avg Loss: 0.3149\n",
      "Diff stats — min: -5.6210, max: 15.8491, mean: 2.3766, std: 2.1781\n",
      "\n",
      "Step 10271 — Test metrics:\n",
      "  precision@10: 0.007630814\n",
      "  recall@10: 0.007634484\n",
      "  ndcg@10: 0.007833171\n",
      "  map@10: 0.002444493\n",
      "Epoch 935, Step 10, LR: 0.000080, Current Loss: 0.3166, Avg Loss: 0.3166\n",
      "Diff stats — min: -6.4347, max: 16.6164, mean: 2.3683, std: 2.1824\n",
      "\n",
      "Step 10280 — Test metrics:\n",
      "  precision@10: 0.007630814\n",
      "  recall@10: 0.007634484\n",
      "  ndcg@10: 0.007805169\n",
      "  map@10: 0.002427949\n",
      "Epoch 935 completed, Train Loss: 0.3164\n",
      "Epoch 936, Step 1, LR: 0.000080, Current Loss: 0.3170, Avg Loss: 0.3170\n",
      "Diff stats — min: -6.9293, max: 14.2382, mean: 2.3631, std: 2.1722\n",
      "\n",
      "Step 10282 — Test metrics:\n",
      "  precision@10: 0.007630814\n",
      "  recall@10: 0.007634484\n",
      "  ndcg@10: 0.007804952\n",
      "  map@10: 0.002428139\n",
      "Epoch 936, Step 10, LR: 0.000080, Current Loss: 0.3141, Avg Loss: 0.3156\n",
      "Diff stats — min: -6.3875, max: 15.9084, mean: 2.3602, std: 2.1688\n",
      "\n",
      "Step 10291 — Test metrics:\n",
      "  precision@10: 0.007597780\n",
      "  recall@10: 0.007600716\n",
      "  ndcg@10: 0.007756920\n",
      "  map@10: 0.002410547\n",
      "Epoch 936 completed, Train Loss: 0.3158\n",
      "Epoch 937, Step 1, LR: 0.000080, Current Loss: 0.3152, Avg Loss: 0.3152\n",
      "Diff stats — min: -5.9565, max: 14.0303, mean: 2.3819, std: 2.1877\n",
      "\n",
      "Step 10293 — Test metrics:\n",
      "  precision@10: 0.007597780\n",
      "  recall@10: 0.007600716\n",
      "  ndcg@10: 0.007725135\n",
      "  map@10: 0.002393340\n",
      "Epoch 937, Step 10, LR: 0.000080, Current Loss: 0.3198, Avg Loss: 0.3182\n",
      "Diff stats — min: -6.5543, max: 12.8846, mean: 2.3576, std: 2.1810\n",
      "\n",
      "Step 10302 — Test metrics:\n",
      "  precision@10: 0.007492072\n",
      "  recall@10: 0.007495008\n",
      "  ndcg@10: 0.007623015\n",
      "  map@10: 0.002358272\n",
      "Epoch 937 completed, Train Loss: 0.3181\n",
      "Epoch 938, Step 1, LR: 0.000080, Current Loss: 0.3154, Avg Loss: 0.3154\n",
      "Diff stats — min: -6.3782, max: 14.6861, mean: 2.3679, std: 2.1766\n",
      "\n",
      "Step 10304 — Test metrics:\n",
      "  precision@10: 0.007492072\n",
      "  recall@10: 0.007495008\n",
      "  ndcg@10: 0.007646794\n",
      "  map@10: 0.002374778\n",
      "Epoch 938, Step 10, LR: 0.000080, Current Loss: 0.3111, Avg Loss: 0.3159\n",
      "Diff stats — min: -6.2768, max: 13.6183, mean: 2.3822, std: 2.1717\n",
      "\n",
      "Step 10313 — Test metrics:\n",
      "  precision@10: 0.007558140\n",
      "  recall@10: 0.007561810\n",
      "  ndcg@10: 0.007709303\n",
      "  map@10: 0.002393138\n",
      "Epoch 938 completed, Train Loss: 0.3160\n",
      "Epoch 939, Step 1, LR: 0.000080, Current Loss: 0.3174, Avg Loss: 0.3174\n",
      "Diff stats — min: -7.5822, max: 14.0792, mean: 2.3546, std: 2.1776\n",
      "\n",
      "Step 10315 — Test metrics:\n",
      "  precision@10: 0.007551533\n",
      "  recall@10: 0.007555203\n",
      "  ndcg@10: 0.007729352\n",
      "  map@10: 0.002406981\n",
      "Epoch 939, Step 10, LR: 0.000080, Current Loss: 0.3172, Avg Loss: 0.3159\n",
      "Diff stats — min: -5.9565, max: 14.4487, mean: 2.3738, std: 2.1933\n",
      "\n",
      "Step 10324 — Test metrics:\n",
      "  precision@10: 0.007525106\n",
      "  recall@10: 0.007528042\n",
      "  ndcg@10: 0.007705068\n",
      "  map@10: 0.002400975\n",
      "Epoch 939 completed, Train Loss: 0.3163\n",
      "Epoch 940, Step 1, LR: 0.000080, Current Loss: 0.3164, Avg Loss: 0.3164\n",
      "Diff stats — min: -5.9736, max: 12.9601, mean: 2.3803, std: 2.1945\n",
      "\n",
      "Step 10326 — Test metrics:\n",
      "  precision@10: 0.007498679\n",
      "  recall@10: 0.007501615\n",
      "  ndcg@10: 0.007690423\n",
      "  map@10: 0.002398880\n",
      "Epoch 940, Step 10, LR: 0.000080, Current Loss: 0.3127, Avg Loss: 0.3178\n",
      "Diff stats — min: -9.5348, max: 11.6937, mean: 2.3655, std: 2.1659\n",
      "\n",
      "Step 10335 — Test metrics:\n",
      "  precision@10: 0.007591173\n",
      "  recall@10: 0.007594110\n",
      "  ndcg@10: 0.007798539\n",
      "  map@10: 0.002435978\n",
      "Epoch 940 completed, Train Loss: 0.3177\n",
      "Epoch 941, Step 1, LR: 0.000080, Current Loss: 0.3154, Avg Loss: 0.3154\n",
      "Diff stats — min: -6.0741, max: 13.4799, mean: 2.3676, std: 2.1791\n",
      "\n",
      "Step 10337 — Test metrics:\n",
      "  precision@10: 0.007610994\n",
      "  recall@10: 0.007613930\n",
      "  ndcg@10: 0.007807313\n",
      "  map@10: 0.002436628\n",
      "Epoch 941, Step 10, LR: 0.000080, Current Loss: 0.3108, Avg Loss: 0.3165\n",
      "Diff stats — min: -6.7597, max: 15.6398, mean: 2.3905, std: 2.1780\n",
      "\n",
      "Step 10346 — Test metrics:\n",
      "  precision@10: 0.007597780\n",
      "  recall@10: 0.007600716\n",
      "  ndcg@10: 0.007712801\n",
      "  map@10: 0.002381952\n",
      "Epoch 941 completed, Train Loss: 0.3168\n",
      "Epoch 942, Step 1, LR: 0.000080, Current Loss: 0.3133, Avg Loss: 0.3133\n",
      "Diff stats — min: -6.3337, max: 12.6187, mean: 2.3836, std: 2.1793\n",
      "\n",
      "Step 10348 — Test metrics:\n",
      "  precision@10: 0.007571353\n",
      "  recall@10: 0.007574289\n",
      "  ndcg@10: 0.007701494\n",
      "  map@10: 0.002384272\n",
      "Epoch 942, Step 10, LR: 0.000080, Current Loss: 0.3162, Avg Loss: 0.3171\n",
      "Diff stats — min: -6.1532, max: 12.5110, mean: 2.3744, std: 2.1841\n",
      "\n",
      "Step 10357 — Test metrics:\n",
      "  precision@10: 0.007551533\n",
      "  recall@10: 0.007555203\n",
      "  ndcg@10: 0.007709288\n",
      "  map@10: 0.002394169\n",
      "Epoch 942 completed, Train Loss: 0.3171\n",
      "Epoch 943, Step 1, LR: 0.000080, Current Loss: 0.3154, Avg Loss: 0.3154\n",
      "Diff stats — min: -6.2147, max: 13.0060, mean: 2.3779, std: 2.1939\n",
      "\n",
      "Step 10359 — Test metrics:\n",
      "  precision@10: 0.007644027\n",
      "  recall@10: 0.007647698\n",
      "  ndcg@10: 0.007773298\n",
      "  map@10: 0.002410568\n",
      "Epoch 943, Step 10, LR: 0.000080, Current Loss: 0.3188, Avg Loss: 0.3165\n",
      "Diff stats — min: -6.7004, max: 13.8367, mean: 2.3689, std: 2.1905\n",
      "\n",
      "Step 10368 — Test metrics:\n",
      "  precision@10: 0.007544926\n",
      "  recall@10: 0.007547862\n",
      "  ndcg@10: 0.007698892\n",
      "  map@10: 0.002392299\n",
      "Epoch 943 completed, Train Loss: 0.3163\n",
      "Epoch 944, Step 1, LR: 0.000080, Current Loss: 0.3140, Avg Loss: 0.3140\n",
      "Diff stats — min: -6.1901, max: 12.6677, mean: 2.3852, std: 2.1805\n",
      "\n",
      "Step 10370 — Test metrics:\n",
      "  precision@10: 0.007531712\n",
      "  recall@10: 0.007534649\n",
      "  ndcg@10: 0.007673188\n",
      "  map@10: 0.002379410\n",
      "Epoch 944, Step 10, LR: 0.000080, Current Loss: 0.3192, Avg Loss: 0.3164\n",
      "Diff stats — min: -8.8332, max: 14.6235, mean: 2.3666, std: 2.1918\n",
      "\n",
      "Step 10379 — Test metrics:\n",
      "  precision@10: 0.007531712\n",
      "  recall@10: 0.007534649\n",
      "  ndcg@10: 0.007683137\n",
      "  map@10: 0.002384567\n",
      "Epoch 944 completed, Train Loss: 0.3163\n",
      "Epoch 945, Step 1, LR: 0.000080, Current Loss: 0.3141, Avg Loss: 0.3141\n",
      "Diff stats — min: -5.2208, max: 14.7105, mean: 2.3797, std: 2.1863\n",
      "\n",
      "Step 10381 — Test metrics:\n",
      "  precision@10: 0.007558140\n",
      "  recall@10: 0.007561076\n",
      "  ndcg@10: 0.007696318\n",
      "  map@10: 0.002386575\n",
      "Epoch 945, Step 10, LR: 0.000080, Current Loss: 0.3200, Avg Loss: 0.3168\n",
      "Diff stats — min: -6.0182, max: 12.1582, mean: 2.3573, std: 2.1787\n",
      "\n",
      "Step 10390 — Test metrics:\n",
      "  precision@10: 0.007604387\n",
      "  recall@10: 0.007608057\n",
      "  ndcg@10: 0.007785565\n",
      "  map@10: 0.002423602\n",
      "Epoch 945 completed, Train Loss: 0.3166\n",
      "Epoch 946, Step 1, LR: 0.000080, Current Loss: 0.3131, Avg Loss: 0.3131\n",
      "Diff stats — min: -6.0939, max: 13.8273, mean: 2.3769, std: 2.1783\n",
      "\n",
      "Step 10392 — Test metrics:\n",
      "  precision@10: 0.007591173\n",
      "  recall@10: 0.007594844\n",
      "  ndcg@10: 0.007793540\n",
      "  map@10: 0.002432066\n",
      "Epoch 946, Step 10, LR: 0.000080, Current Loss: 0.3169, Avg Loss: 0.3155\n",
      "Diff stats — min: -6.4444, max: 13.3269, mean: 2.3726, std: 2.1908\n",
      "\n",
      "Step 10401 — Test metrics:\n",
      "  precision@10: 0.007505285\n",
      "  recall@10: 0.007508222\n",
      "  ndcg@10: 0.007703166\n",
      "  map@10: 0.002401932\n",
      "Epoch 946 completed, Train Loss: 0.3155\n",
      "Epoch 947, Step 1, LR: 0.000080, Current Loss: 0.3102, Avg Loss: 0.3102\n",
      "Diff stats — min: -6.0136, max: 15.1260, mean: 2.3912, std: 2.1862\n",
      "\n",
      "Step 10403 — Test metrics:\n",
      "  precision@10: 0.007511892\n",
      "  recall@10: 0.007514829\n",
      "  ndcg@10: 0.007695602\n",
      "  map@10: 0.002395267\n",
      "Epoch 947, Step 10, LR: 0.000080, Current Loss: 0.3113, Avg Loss: 0.3146\n",
      "Diff stats — min: -6.4081, max: 13.5316, mean: 2.3926, std: 2.1813\n",
      "\n",
      "Step 10412 — Test metrics:\n",
      "  precision@10: 0.007571353\n",
      "  recall@10: 0.007574289\n",
      "  ndcg@10: 0.007713387\n",
      "  map@10: 0.002389570\n",
      "Epoch 947 completed, Train Loss: 0.3147\n",
      "Epoch 948, Step 1, LR: 0.000080, Current Loss: 0.3186, Avg Loss: 0.3186\n",
      "Diff stats — min: -6.5419, max: 13.6272, mean: 2.3737, std: 2.1970\n",
      "\n",
      "Step 10414 — Test metrics:\n",
      "  precision@10: 0.007591173\n",
      "  recall@10: 0.007594110\n",
      "  ndcg@10: 0.007720046\n",
      "  map@10: 0.002389119\n",
      "Epoch 948, Step 10, LR: 0.000080, Current Loss: 0.3124, Avg Loss: 0.3161\n",
      "Diff stats — min: -5.8813, max: 13.8826, mean: 2.3800, std: 2.1763\n",
      "\n",
      "Step 10423 — Test metrics:\n",
      "  precision@10: 0.007558140\n",
      "  recall@10: 0.007561076\n",
      "  ndcg@10: 0.007673028\n",
      "  map@10: 0.002373313\n",
      "Epoch 948 completed, Train Loss: 0.3160\n",
      "Epoch 949, Step 1, LR: 0.000080, Current Loss: 0.3186, Avg Loss: 0.3186\n",
      "Diff stats — min: -6.4072, max: 11.7442, mean: 2.3805, std: 2.2018\n",
      "\n",
      "Step 10425 — Test metrics:\n",
      "  precision@10: 0.007591173\n",
      "  recall@10: 0.007594110\n",
      "  ndcg@10: 0.007706293\n",
      "  map@10: 0.002384227\n",
      "Epoch 949, Step 10, LR: 0.000080, Current Loss: 0.3103, Avg Loss: 0.3156\n",
      "Diff stats — min: -6.1309, max: 17.6477, mean: 2.3982, std: 2.1870\n",
      "\n",
      "Step 10434 — Test metrics:\n",
      "  precision@10: 0.007551533\n",
      "  recall@10: 0.007555203\n",
      "  ndcg@10: 0.007749231\n",
      "  map@10: 0.002417319\n",
      "Epoch 949 completed, Train Loss: 0.3155\n",
      "Epoch 950, Step 1, LR: 0.000080, Current Loss: 0.3133, Avg Loss: 0.3133\n",
      "Diff stats — min: -6.7472, max: 15.3203, mean: 2.3785, std: 2.1790\n",
      "\n",
      "Step 10436 — Test metrics:\n",
      "  precision@10: 0.007577960\n",
      "  recall@10: 0.007581630\n",
      "  ndcg@10: 0.007743588\n",
      "  map@10: 0.002408625\n",
      "Epoch 950, Step 10, LR: 0.000080, Current Loss: 0.3172, Avg Loss: 0.3158\n",
      "Diff stats — min: -6.5071, max: 14.8652, mean: 2.3814, std: 2.1957\n",
      "\n",
      "Step 10445 — Test metrics:\n",
      "  precision@10: 0.007544926\n",
      "  recall@10: 0.007547862\n",
      "  ndcg@10: 0.007659535\n",
      "  map@10: 0.002371365\n",
      "Epoch 950 completed, Train Loss: 0.3158\n",
      "Epoch 951, Step 1, LR: 0.000080, Current Loss: 0.3139, Avg Loss: 0.3139\n",
      "Diff stats — min: -7.3582, max: 13.0496, mean: 2.3821, std: 2.1801\n",
      "\n",
      "Step 10447 — Test metrics:\n",
      "  precision@10: 0.007505285\n",
      "  recall@10: 0.007508222\n",
      "  ndcg@10: 0.007647652\n",
      "  map@10: 0.002373732\n",
      "Epoch 951, Step 10, LR: 0.000080, Current Loss: 0.3198, Avg Loss: 0.3144\n",
      "Diff stats — min: -5.6167, max: 14.9654, mean: 2.3698, std: 2.1979\n",
      "\n",
      "Step 10456 — Test metrics:\n",
      "  precision@10: 0.007617600\n",
      "  recall@10: 0.007620537\n",
      "  ndcg@10: 0.007792278\n",
      "  map@10: 0.002426159\n",
      "Epoch 951 completed, Train Loss: 0.3143\n",
      "Epoch 952, Step 1, LR: 0.000080, Current Loss: 0.3182, Avg Loss: 0.3182\n",
      "Diff stats — min: -7.1396, max: 14.0018, mean: 2.3660, std: 2.1897\n",
      "\n",
      "Step 10458 — Test metrics:\n",
      "  precision@10: 0.007617600\n",
      "  recall@10: 0.007621271\n",
      "  ndcg@10: 0.007821960\n",
      "  map@10: 0.002442884\n",
      "Epoch 952, Step 10, LR: 0.000080, Current Loss: 0.3160, Avg Loss: 0.3154\n",
      "Diff stats — min: -5.9520, max: 14.1472, mean: 2.3847, std: 2.1943\n",
      "\n",
      "Step 10467 — Test metrics:\n",
      "  precision@10: 0.007591173\n",
      "  recall@10: 0.007594844\n",
      "  ndcg@10: 0.007816054\n",
      "  map@10: 0.002448504\n",
      "Epoch 952 completed, Train Loss: 0.3151\n",
      "Epoch 953, Step 1, LR: 0.000080, Current Loss: 0.3151, Avg Loss: 0.3151\n",
      "Diff stats — min: -6.2672, max: 13.9747, mean: 2.3790, std: 2.1910\n",
      "\n",
      "Step 10469 — Test metrics:\n",
      "  precision@10: 0.007617600\n",
      "  recall@10: 0.007621271\n",
      "  ndcg@10: 0.007816541\n",
      "  map@10: 0.002442920\n",
      "Epoch 953, Step 10, LR: 0.000080, Current Loss: 0.3113, Avg Loss: 0.3158\n",
      "Diff stats — min: -6.2754, max: 17.1363, mean: 2.4047, std: 2.2020\n",
      "\n",
      "Step 10478 — Test metrics:\n",
      "  precision@10: 0.007558140\n",
      "  recall@10: 0.007561076\n",
      "  ndcg@10: 0.007692107\n",
      "  map@10: 0.002384174\n",
      "Epoch 953 completed, Train Loss: 0.3159\n",
      "Epoch 954, Step 1, LR: 0.000080, Current Loss: 0.3166, Avg Loss: 0.3166\n",
      "Diff stats — min: -6.2510, max: 14.9208, mean: 2.3621, std: 2.1802\n",
      "\n",
      "Step 10480 — Test metrics:\n",
      "  precision@10: 0.007538319\n",
      "  recall@10: 0.007541256\n",
      "  ndcg@10: 0.007670727\n",
      "  map@10: 0.002375850\n",
      "Epoch 954, Step 10, LR: 0.000080, Current Loss: 0.3141, Avg Loss: 0.3157\n",
      "Diff stats — min: -6.2630, max: 12.7643, mean: 2.3955, std: 2.2019\n",
      "\n",
      "Step 10489 — Test metrics:\n",
      "  precision@10: 0.007657241\n",
      "  recall@10: 0.007660177\n",
      "  ndcg@10: 0.007853450\n",
      "  map@10: 0.002453884\n",
      "Epoch 954 completed, Train Loss: 0.3153\n",
      "Epoch 955, Step 1, LR: 0.000080, Current Loss: 0.3170, Avg Loss: 0.3170\n",
      "Diff stats — min: -6.5870, max: 20.4605, mean: 2.3761, std: 2.1964\n",
      "\n",
      "Step 10491 — Test metrics:\n",
      "  precision@10: 0.007657241\n",
      "  recall@10: 0.007660911\n",
      "  ndcg@10: 0.007868829\n",
      "  map@10: 0.002461568\n",
      "Epoch 955, Step 10, LR: 0.000080, Current Loss: 0.3135, Avg Loss: 0.3162\n",
      "Diff stats — min: -6.4401, max: 16.4512, mean: 2.3960, std: 2.1970\n",
      "\n",
      "Step 10500 — Test metrics:\n",
      "  precision@10: 0.007591173\n",
      "  recall@10: 0.007594844\n",
      "  ndcg@10: 0.007842864\n",
      "  map@10: 0.002464306\n",
      "Epoch 955 completed, Train Loss: 0.3161\n",
      "Epoch 956, Step 1, LR: 0.000080, Current Loss: 0.3187, Avg Loss: 0.3187\n",
      "Diff stats — min: -6.1079, max: 13.0462, mean: 2.3783, std: 2.2000\n",
      "\n",
      "Step 10502 — Test metrics:\n",
      "  precision@10: 0.007551533\n",
      "  recall@10: 0.007554469\n",
      "  ndcg@10: 0.007753851\n",
      "  map@10: 0.002424033\n",
      "Epoch 956, Step 10, LR: 0.000080, Current Loss: 0.3128, Avg Loss: 0.3149\n",
      "Diff stats — min: -5.6449, max: 18.4402, mean: 2.3896, std: 2.1930\n",
      "\n",
      "Step 10511 — Test metrics:\n",
      "  precision@10: 0.007432611\n",
      "  recall@10: 0.007435547\n",
      "  ndcg@10: 0.007576370\n",
      "  map@10: 0.002350584\n",
      "Epoch 956 completed, Train Loss: 0.3150\n",
      "Epoch 957, Step 1, LR: 0.000080, Current Loss: 0.3171, Avg Loss: 0.3171\n",
      "Diff stats — min: -6.2851, max: 12.4633, mean: 2.3854, std: 2.2051\n",
      "\n",
      "Step 10513 — Test metrics:\n",
      "  precision@10: 0.007439218\n",
      "  recall@10: 0.007442154\n",
      "  ndcg@10: 0.007582829\n",
      "  map@10: 0.002350543\n",
      "Epoch 957, Step 10, LR: 0.000080, Current Loss: 0.3128, Avg Loss: 0.3142\n",
      "Diff stats — min: -7.4795, max: 13.1237, mean: 2.3977, std: 2.1986\n",
      "\n",
      "Step 10522 — Test metrics:\n",
      "  precision@10: 0.007617600\n",
      "  recall@10: 0.007621271\n",
      "  ndcg@10: 0.007811352\n",
      "  map@10: 0.002439520\n",
      "Epoch 957 completed, Train Loss: 0.3145\n",
      "Epoch 958, Step 1, LR: 0.000080, Current Loss: 0.3133, Avg Loss: 0.3133\n",
      "Diff stats — min: -7.0121, max: 13.2490, mean: 2.3846, std: 2.1835\n",
      "\n",
      "Step 10524 — Test metrics:\n",
      "  precision@10: 0.007591173\n",
      "  recall@10: 0.007594844\n",
      "  ndcg@10: 0.007811218\n",
      "  map@10: 0.002448311\n",
      "Epoch 958, Step 10, LR: 0.000080, Current Loss: 0.3174, Avg Loss: 0.3138\n",
      "Diff stats — min: -6.2359, max: 13.9125, mean: 2.3844, std: 2.2043\n",
      "\n",
      "Step 10533 — Test metrics:\n",
      "  precision@10: 0.007544926\n",
      "  recall@10: 0.007548596\n",
      "  ndcg@10: 0.007737969\n",
      "  map@10: 0.002417662\n",
      "Epoch 958 completed, Train Loss: 0.3144\n",
      "Epoch 959, Step 1, LR: 0.000080, Current Loss: 0.3123, Avg Loss: 0.3123\n",
      "Diff stats — min: -6.6981, max: 13.5207, mean: 2.4181, std: 2.2127\n",
      "\n",
      "Step 10535 — Test metrics:\n",
      "  precision@10: 0.007577960\n",
      "  recall@10: 0.007581630\n",
      "  ndcg@10: 0.007761940\n",
      "  map@10: 0.002424524\n",
      "Epoch 959, Step 10, LR: 0.000080, Current Loss: 0.3127, Avg Loss: 0.3143\n",
      "Diff stats — min: -6.0067, max: 13.9470, mean: 2.3949, std: 2.1938\n",
      "\n",
      "Step 10544 — Test metrics:\n",
      "  precision@10: 0.007485465\n",
      "  recall@10: 0.007488401\n",
      "  ndcg@10: 0.007710592\n",
      "  map@10: 0.002418441\n",
      "Epoch 959 completed, Train Loss: 0.3142\n",
      "Epoch 960, Step 1, LR: 0.000080, Current Loss: 0.3134, Avg Loss: 0.3134\n",
      "Diff stats — min: -6.7786, max: 12.9641, mean: 2.3854, std: 2.1819\n",
      "\n",
      "Step 10546 — Test metrics:\n",
      "  precision@10: 0.007459038\n",
      "  recall@10: 0.007461974\n",
      "  ndcg@10: 0.007696614\n",
      "  map@10: 0.002415005\n",
      "Epoch 960, Step 10, LR: 0.000080, Current Loss: 0.3124, Avg Loss: 0.3153\n",
      "Diff stats — min: -6.9585, max: 14.0753, mean: 2.4070, std: 2.2023\n",
      "\n",
      "Step 10555 — Test metrics:\n",
      "  precision@10: 0.007505285\n",
      "  recall@10: 0.007508222\n",
      "  ndcg@10: 0.007618796\n",
      "  map@10: 0.002355268\n",
      "Epoch 960 completed, Train Loss: 0.3149\n",
      "Epoch 961, Step 1, LR: 0.000080, Current Loss: 0.3137, Avg Loss: 0.3137\n",
      "Diff stats — min: -5.9847, max: 12.8025, mean: 2.3914, std: 2.1935\n",
      "\n",
      "Step 10557 — Test metrics:\n",
      "  precision@10: 0.007472252\n",
      "  recall@10: 0.007475188\n",
      "  ndcg@10: 0.007588722\n",
      "  map@10: 0.002347274\n",
      "Epoch 961, Step 10, LR: 0.000080, Current Loss: 0.3123, Avg Loss: 0.3147\n",
      "Diff stats — min: -6.1470, max: 13.3459, mean: 2.3904, std: 2.1831\n",
      "\n",
      "Step 10566 — Test metrics:\n",
      "  precision@10: 0.007485465\n",
      "  recall@10: 0.007488401\n",
      "  ndcg@10: 0.007602096\n",
      "  map@10: 0.002351523\n",
      "Epoch 961 completed, Train Loss: 0.3148\n",
      "Epoch 962, Step 1, LR: 0.000080, Current Loss: 0.3160, Avg Loss: 0.3160\n",
      "Diff stats — min: -6.4716, max: 13.5096, mean: 2.3848, std: 2.2005\n",
      "\n",
      "Step 10568 — Test metrics:\n",
      "  precision@10: 0.007505285\n",
      "  recall@10: 0.007508222\n",
      "  ndcg@10: 0.007623675\n",
      "  map@10: 0.002357792\n",
      "Epoch 962, Step 10, LR: 0.000080, Current Loss: 0.3119, Avg Loss: 0.3142\n",
      "Diff stats — min: -7.0421, max: 13.3983, mean: 2.4023, std: 2.2003\n",
      "\n",
      "Step 10577 — Test metrics:\n",
      "  precision@10: 0.007544926\n",
      "  recall@10: 0.007548596\n",
      "  ndcg@10: 0.007721874\n",
      "  map@10: 0.002408404\n",
      "Epoch 962 completed, Train Loss: 0.3144\n",
      "Epoch 963, Step 1, LR: 0.000080, Current Loss: 0.3174, Avg Loss: 0.3174\n",
      "Diff stats — min: -6.8985, max: 12.1430, mean: 2.3948, std: 2.2060\n",
      "\n",
      "Step 10579 — Test metrics:\n",
      "  precision@10: 0.007525106\n",
      "  recall@10: 0.007528776\n",
      "  ndcg@10: 0.007715282\n",
      "  map@10: 0.002408449\n",
      "Epoch 963, Step 10, LR: 0.000080, Current Loss: 0.3209, Avg Loss: 0.3158\n",
      "Diff stats — min: -6.5792, max: 13.5447, mean: 2.3707, std: 2.2048\n",
      "\n",
      "Step 10588 — Test metrics:\n",
      "  precision@10: 0.007498679\n",
      "  recall@10: 0.007501615\n",
      "  ndcg@10: 0.007707180\n",
      "  map@10: 0.002406695\n",
      "Epoch 963 completed, Train Loss: 0.3163\n",
      "Epoch 964, Step 1, LR: 0.000080, Current Loss: 0.3123, Avg Loss: 0.3123\n",
      "Diff stats — min: -6.7555, max: 15.3034, mean: 2.3988, std: 2.1924\n",
      "\n",
      "Step 10590 — Test metrics:\n",
      "  precision@10: 0.007538319\n",
      "  recall@10: 0.007541256\n",
      "  ndcg@10: 0.007718213\n",
      "  map@10: 0.002402627\n",
      "Epoch 964, Step 10, LR: 0.000080, Current Loss: 0.3128, Avg Loss: 0.3138\n",
      "Diff stats — min: -6.0999, max: 13.5329, mean: 2.3960, std: 2.1927\n",
      "\n",
      "Step 10599 — Test metrics:\n",
      "  precision@10: 0.007459038\n",
      "  recall@10: 0.007461240\n",
      "  ndcg@10: 0.007611306\n",
      "  map@10: 0.002364538\n",
      "Epoch 964 completed, Train Loss: 0.3140\n",
      "Epoch 965, Step 1, LR: 0.000080, Current Loss: 0.3068, Avg Loss: 0.3068\n",
      "Diff stats — min: -6.7409, max: 14.5017, mean: 2.4189, std: 2.1850\n",
      "\n",
      "Step 10601 — Test metrics:\n",
      "  precision@10: 0.007452431\n",
      "  recall@10: 0.007455368\n",
      "  ndcg@10: 0.007614283\n",
      "  map@10: 0.002369449\n",
      "Epoch 965, Step 10, LR: 0.000080, Current Loss: 0.3138, Avg Loss: 0.3149\n",
      "Diff stats — min: -6.6079, max: 13.0682, mean: 2.3963, std: 2.1998\n",
      "\n",
      "Step 10610 — Test metrics:\n",
      "  precision@10: 0.007498679\n",
      "  recall@10: 0.007502349\n",
      "  ndcg@10: 0.007707118\n",
      "  map@10: 0.002412650\n",
      "Epoch 965 completed, Train Loss: 0.3147\n",
      "Epoch 966, Step 1, LR: 0.000080, Current Loss: 0.3150, Avg Loss: 0.3150\n",
      "Diff stats — min: -6.7944, max: 13.6559, mean: 2.3990, std: 2.2041\n",
      "\n",
      "Step 10612 — Test metrics:\n",
      "  precision@10: 0.007492072\n",
      "  recall@10: 0.007495742\n",
      "  ndcg@10: 0.007694323\n",
      "  map@10: 0.002408085\n",
      "Epoch 966, Step 10, LR: 0.000080, Current Loss: 0.3142, Avg Loss: 0.3141\n",
      "Diff stats — min: -6.4702, max: 15.3000, mean: 2.3954, std: 2.1988\n",
      "\n",
      "Step 10621 — Test metrics:\n",
      "  precision@10: 0.007511892\n",
      "  recall@10: 0.007514829\n",
      "  ndcg@10: 0.007659145\n",
      "  map@10: 0.002379755\n",
      "Epoch 966 completed, Train Loss: 0.3140\n",
      "Epoch 967, Step 1, LR: 0.000080, Current Loss: 0.3131, Avg Loss: 0.3131\n",
      "Diff stats — min: -6.1499, max: 13.3961, mean: 2.4018, std: 2.2036\n",
      "\n",
      "Step 10623 — Test metrics:\n",
      "  precision@10: 0.007577960\n",
      "  recall@10: 0.007580896\n",
      "  ndcg@10: 0.007714754\n",
      "  map@10: 0.002394198\n",
      "Epoch 967, Step 10, LR: 0.000080, Current Loss: 0.3094, Avg Loss: 0.3127\n",
      "Diff stats — min: -6.1799, max: 15.0517, mean: 2.4240, std: 2.2031\n",
      "\n",
      "Step 10632 — Test metrics:\n",
      "  precision@10: 0.007432611\n",
      "  recall@10: 0.007435547\n",
      "  ndcg@10: 0.007631485\n",
      "  map@10: 0.002381280\n",
      "Epoch 967 completed, Train Loss: 0.3130\n",
      "Epoch 968, Step 1, LR: 0.000080, Current Loss: 0.3104, Avg Loss: 0.3104\n",
      "Diff stats — min: -6.5514, max: 15.7570, mean: 2.4085, std: 2.2000\n",
      "\n",
      "Step 10634 — Test metrics:\n",
      "  precision@10: 0.007412791\n",
      "  recall@10: 0.007415727\n",
      "  ndcg@10: 0.007611136\n",
      "  map@10: 0.002375459\n",
      "Epoch 968, Step 10, LR: 0.000080, Current Loss: 0.3081, Avg Loss: 0.3142\n",
      "Diff stats — min: -6.1556, max: 16.7871, mean: 2.4176, std: 2.1973\n",
      "\n",
      "Step 10643 — Test metrics:\n",
      "  precision@10: 0.007432611\n",
      "  recall@10: 0.007435547\n",
      "  ndcg@10: 0.007568863\n",
      "  map@10: 0.002345156\n",
      "Epoch 968 completed, Train Loss: 0.3144\n",
      "Epoch 969, Step 1, LR: 0.000080, Current Loss: 0.3151, Avg Loss: 0.3151\n",
      "Diff stats — min: -7.3242, max: 15.8794, mean: 2.3958, std: 2.2088\n",
      "\n",
      "Step 10645 — Test metrics:\n",
      "  precision@10: 0.007452431\n",
      "  recall@10: 0.007455368\n",
      "  ndcg@10: 0.007591719\n",
      "  map@10: 0.002353223\n",
      "Epoch 969, Step 10, LR: 0.000080, Current Loss: 0.3152, Avg Loss: 0.3156\n",
      "Diff stats — min: -6.7144, max: 12.7956, mean: 2.4074, std: 2.2127\n",
      "\n",
      "Step 10654 — Test metrics:\n",
      "  precision@10: 0.007577960\n",
      "  recall@10: 0.007580896\n",
      "  ndcg@10: 0.007781116\n",
      "  map@10: 0.002433301\n",
      "Epoch 969 completed, Train Loss: 0.3154\n",
      "Epoch 970, Step 1, LR: 0.000080, Current Loss: 0.3163, Avg Loss: 0.3163\n",
      "Diff stats — min: -8.2105, max: 14.8561, mean: 2.3960, std: 2.2006\n",
      "\n",
      "Step 10656 — Test metrics:\n",
      "  precision@10: 0.007571353\n",
      "  recall@10: 0.007574289\n",
      "  ndcg@10: 0.007771794\n",
      "  map@10: 0.002426742\n",
      "Epoch 970, Step 10, LR: 0.000080, Current Loss: 0.3126, Avg Loss: 0.3140\n",
      "Diff stats — min: -5.6941, max: 12.9507, mean: 2.4054, std: 2.2072\n",
      "\n",
      "Step 10665 — Test metrics:\n",
      "  precision@10: 0.007498679\n",
      "  recall@10: 0.007501615\n",
      "  ndcg@10: 0.007679560\n",
      "  map@10: 0.002395939\n",
      "Epoch 970 completed, Train Loss: 0.3137\n",
      "Epoch 971, Step 1, LR: 0.000080, Current Loss: 0.3083, Avg Loss: 0.3083\n",
      "Diff stats — min: -5.9024, max: 12.1756, mean: 2.4041, std: 2.1912\n",
      "\n",
      "Step 10667 — Test metrics:\n",
      "  precision@10: 0.007511892\n",
      "  recall@10: 0.007514829\n",
      "  ndcg@10: 0.007678688\n",
      "  map@10: 0.002394489\n",
      "Epoch 971, Step 10, LR: 0.000080, Current Loss: 0.3161, Avg Loss: 0.3148\n",
      "Diff stats — min: -5.9551, max: 12.2724, mean: 2.3925, std: 2.2027\n",
      "\n",
      "Step 10676 — Test metrics:\n",
      "  precision@10: 0.007525106\n",
      "  recall@10: 0.007528042\n",
      "  ndcg@10: 0.007678912\n",
      "  map@10: 0.002385428\n",
      "Epoch 971 completed, Train Loss: 0.3151\n",
      "Epoch 972, Step 1, LR: 0.000080, Current Loss: 0.3095, Avg Loss: 0.3095\n",
      "Diff stats — min: -6.7592, max: 15.2497, mean: 2.4127, std: 2.1957\n",
      "\n",
      "Step 10678 — Test metrics:\n",
      "  precision@10: 0.007439218\n",
      "  recall@10: 0.007442154\n",
      "  ndcg@10: 0.007622141\n",
      "  map@10: 0.002374092\n",
      "Epoch 972, Step 10, LR: 0.000080, Current Loss: 0.3165, Avg Loss: 0.3137\n",
      "Diff stats — min: -7.0874, max: 14.2776, mean: 2.4009, std: 2.2210\n",
      "\n",
      "Step 10687 — Test metrics:\n",
      "  precision@10: 0.007452431\n",
      "  recall@10: 0.007455368\n",
      "  ndcg@10: 0.007637793\n",
      "  map@10: 0.002380263\n",
      "Epoch 972 completed, Train Loss: 0.3140\n",
      "Epoch 973, Step 1, LR: 0.000080, Current Loss: 0.3198, Avg Loss: 0.3198\n",
      "Diff stats — min: -6.8025, max: 13.7225, mean: 2.3818, std: 2.2157\n",
      "\n",
      "Step 10689 — Test metrics:\n",
      "  precision@10: 0.007445825\n",
      "  recall@10: 0.007448761\n",
      "  ndcg@10: 0.007626050\n",
      "  map@10: 0.002375809\n",
      "Epoch 973, Step 10, LR: 0.000080, Current Loss: 0.3031, Avg Loss: 0.3133\n",
      "Diff stats — min: -6.4011, max: 12.9084, mean: 2.4370, std: 2.1875\n",
      "\n",
      "Step 10698 — Test metrics:\n",
      "  precision@10: 0.007492072\n",
      "  recall@10: 0.007495008\n",
      "  ndcg@10: 0.007652476\n",
      "  map@10: 0.002383241\n",
      "Epoch 973 completed, Train Loss: 0.3129\n",
      "Epoch 974, Step 1, LR: 0.000080, Current Loss: 0.3166, Avg Loss: 0.3166\n",
      "Diff stats — min: -6.6478, max: 16.4188, mean: 2.3923, std: 2.2077\n",
      "\n",
      "Step 10700 — Test metrics:\n",
      "  precision@10: 0.007419397\n",
      "  recall@10: 0.007422334\n",
      "  ndcg@10: 0.007607647\n",
      "  map@10: 0.002378394\n",
      "Epoch 974, Step 10, LR: 0.000080, Current Loss: 0.3103, Avg Loss: 0.3136\n",
      "Diff stats — min: -6.0346, max: 14.2309, mean: 2.4248, std: 2.2080\n",
      "\n",
      "Step 10709 — Test metrics:\n",
      "  precision@10: 0.007366543\n",
      "  recall@10: 0.007369480\n",
      "  ndcg@10: 0.007535672\n",
      "  map@10: 0.002346351\n",
      "Epoch 974 completed, Train Loss: 0.3133\n",
      "Epoch 975, Step 1, LR: 0.000080, Current Loss: 0.3162, Avg Loss: 0.3162\n",
      "Diff stats — min: -6.1960, max: 15.8131, mean: 2.3991, std: 2.2086\n",
      "\n",
      "Step 10711 — Test metrics:\n",
      "  precision@10: 0.007379757\n",
      "  recall@10: 0.007382693\n",
      "  ndcg@10: 0.007514947\n",
      "  map@10: 0.002331195\n",
      "Epoch 975, Step 10, LR: 0.000080, Current Loss: 0.3091, Avg Loss: 0.3138\n",
      "Diff stats — min: -6.0569, max: 12.2089, mean: 2.4206, std: 2.1985\n",
      "\n",
      "Step 10720 — Test metrics:\n",
      "  precision@10: 0.007472252\n",
      "  recall@10: 0.007475188\n",
      "  ndcg@10: 0.007646983\n",
      "  map@10: 0.002382714\n",
      "Epoch 975 completed, Train Loss: 0.3138\n",
      "Epoch 976, Step 1, LR: 0.000080, Current Loss: 0.3125, Avg Loss: 0.3125\n",
      "Diff stats — min: -6.2218, max: 12.7187, mean: 2.3952, std: 2.1982\n",
      "\n",
      "Step 10722 — Test metrics:\n",
      "  precision@10: 0.007478858\n",
      "  recall@10: 0.007481795\n",
      "  ndcg@10: 0.007641258\n",
      "  map@10: 0.002373515\n",
      "Epoch 976, Step 10, LR: 0.000080, Current Loss: 0.3092, Avg Loss: 0.3125\n",
      "Diff stats — min: -7.2654, max: 14.6326, mean: 2.4189, std: 2.1982\n",
      "\n",
      "Step 10731 — Test metrics:\n",
      "  precision@10: 0.007406184\n",
      "  recall@10: 0.007409120\n",
      "  ndcg@10: 0.007600057\n",
      "  map@10: 0.002368861\n",
      "Epoch 976 completed, Train Loss: 0.3122\n",
      "Epoch 977, Step 1, LR: 0.000080, Current Loss: 0.3178, Avg Loss: 0.3178\n",
      "Diff stats — min: -6.2195, max: 12.9217, mean: 2.3804, std: 2.2029\n",
      "\n",
      "Step 10733 — Test metrics:\n",
      "  precision@10: 0.007399577\n",
      "  recall@10: 0.007402514\n",
      "  ndcg@10: 0.007560302\n",
      "  map@10: 0.002349534\n",
      "Epoch 977, Step 10, LR: 0.000080, Current Loss: 0.3151, Avg Loss: 0.3133\n",
      "Diff stats — min: -6.3261, max: 13.8819, mean: 2.4002, std: 2.2192\n",
      "\n",
      "Step 10742 — Test metrics:\n",
      "  precision@10: 0.007399577\n",
      "  recall@10: 0.007402514\n",
      "  ndcg@10: 0.007527390\n",
      "  map@10: 0.002334901\n",
      "Epoch 977 completed, Train Loss: 0.3135\n",
      "Epoch 978, Step 1, LR: 0.000080, Current Loss: 0.3122, Avg Loss: 0.3122\n",
      "Diff stats — min: -6.6559, max: 14.0189, mean: 2.4131, std: 2.2072\n",
      "\n",
      "Step 10744 — Test metrics:\n",
      "  precision@10: 0.007379757\n",
      "  recall@10: 0.007382693\n",
      "  ndcg@10: 0.007498081\n",
      "  map@10: 0.002323904\n",
      "Epoch 978, Step 10, LR: 0.000080, Current Loss: 0.3180, Avg Loss: 0.3129\n",
      "Diff stats — min: -5.7411, max: 16.9913, mean: 2.3958, std: 2.2196\n",
      "\n",
      "Step 10753 — Test metrics:\n",
      "  precision@10: 0.007426004\n",
      "  recall@10: 0.007428941\n",
      "  ndcg@10: 0.007597638\n",
      "  map@10: 0.002368313\n",
      "Epoch 978 completed, Train Loss: 0.3128\n",
      "Epoch 979, Step 1, LR: 0.000080, Current Loss: 0.3153, Avg Loss: 0.3153\n",
      "Diff stats — min: -6.4551, max: 13.3208, mean: 2.4218, std: 2.2327\n",
      "\n",
      "Step 10755 — Test metrics:\n",
      "  precision@10: 0.007439218\n",
      "  recall@10: 0.007442154\n",
      "  ndcg@10: 0.007642353\n",
      "  map@10: 0.002393201\n",
      "Epoch 979, Step 10, LR: 0.000080, Current Loss: 0.3192, Avg Loss: 0.3143\n",
      "Diff stats — min: -5.5843, max: 13.3337, mean: 2.3892, std: 2.2141\n",
      "\n",
      "Step 10764 — Test metrics:\n",
      "  precision@10: 0.007459038\n",
      "  recall@10: 0.007461974\n",
      "  ndcg@10: 0.007679243\n",
      "  map@10: 0.002407770\n",
      "Epoch 979 completed, Train Loss: 0.3144\n",
      "Epoch 980, Step 1, LR: 0.000080, Current Loss: 0.3149, Avg Loss: 0.3149\n",
      "Diff stats — min: -6.4624, max: 13.3742, mean: 2.4037, std: 2.2134\n",
      "\n",
      "Step 10766 — Test metrics:\n",
      "  precision@10: 0.007386364\n",
      "  recall@10: 0.007389300\n",
      "  ndcg@10: 0.007620523\n",
      "  map@10: 0.002391924\n",
      "Epoch 980, Step 10, LR: 0.000080, Current Loss: 0.3091, Avg Loss: 0.3112\n",
      "Diff stats — min: -6.4208, max: 13.5134, mean: 2.4349, std: 2.2109\n",
      "\n",
      "Step 10775 — Test metrics:\n",
      "  precision@10: 0.007379757\n",
      "  recall@10: 0.007382693\n",
      "  ndcg@10: 0.007562752\n",
      "  map@10: 0.002357285\n",
      "Epoch 980 completed, Train Loss: 0.3115\n",
      "Epoch 981, Step 1, LR: 0.000080, Current Loss: 0.3167, Avg Loss: 0.3167\n",
      "Diff stats — min: -6.0330, max: 13.5759, mean: 2.3938, std: 2.2064\n",
      "\n",
      "Step 10777 — Test metrics:\n",
      "  precision@10: 0.007326903\n",
      "  recall@10: 0.007329839\n",
      "  ndcg@10: 0.007506648\n",
      "  map@10: 0.002339182\n",
      "Epoch 981, Step 10, LR: 0.000080, Current Loss: 0.3112, Avg Loss: 0.3141\n",
      "Diff stats — min: -6.7677, max: 12.5668, mean: 2.4346, std: 2.2185\n",
      "\n",
      "Step 10786 — Test metrics:\n",
      "  precision@10: 0.007412791\n",
      "  recall@10: 0.007415727\n",
      "  ndcg@10: 0.007521021\n",
      "  map@10: 0.002325312\n",
      "Epoch 981 completed, Train Loss: 0.3140\n",
      "Epoch 982, Step 1, LR: 0.000080, Current Loss: 0.3152, Avg Loss: 0.3152\n",
      "Diff stats — min: -6.3840, max: 12.5622, mean: 2.3924, std: 2.2006\n",
      "\n",
      "Step 10788 — Test metrics:\n",
      "  precision@10: 0.007373150\n",
      "  recall@10: 0.007376086\n",
      "  ndcg@10: 0.007481413\n",
      "  map@10: 0.002309508\n",
      "Epoch 982, Step 10, LR: 0.000080, Current Loss: 0.3099, Avg Loss: 0.3120\n",
      "Diff stats — min: -5.8872, max: 13.4077, mean: 2.4274, std: 2.2135\n",
      "\n",
      "Step 10797 — Test metrics:\n",
      "  precision@10: 0.007346723\n",
      "  recall@10: 0.007349659\n",
      "  ndcg@10: 0.007565131\n",
      "  map@10: 0.002368340\n",
      "Epoch 982 completed, Train Loss: 0.3121\n",
      "Epoch 983, Step 1, LR: 0.000080, Current Loss: 0.3153, Avg Loss: 0.3153\n",
      "Diff stats — min: -6.1276, max: 15.3044, mean: 2.4041, std: 2.2114\n",
      "\n",
      "Step 10799 — Test metrics:\n",
      "  precision@10: 0.007392970\n",
      "  recall@10: 0.007395907\n",
      "  ndcg@10: 0.007603563\n",
      "  map@10: 0.002377007\n",
      "Epoch 983, Step 10, LR: 0.000080, Current Loss: 0.3131, Avg Loss: 0.3116\n",
      "Diff stats — min: -5.8046, max: 14.4791, mean: 2.4024, std: 2.2063\n",
      "\n",
      "Step 10808 — Test metrics:\n",
      "  precision@10: 0.007432611\n",
      "  recall@10: 0.007435547\n",
      "  ndcg@10: 0.007628731\n",
      "  map@10: 0.002381941\n",
      "Epoch 983 completed, Train Loss: 0.3115\n",
      "Epoch 984, Step 1, LR: 0.000080, Current Loss: 0.3137, Avg Loss: 0.3137\n",
      "Diff stats — min: -6.8294, max: 12.3890, mean: 2.4150, std: 2.2059\n",
      "\n",
      "Step 10810 — Test metrics:\n",
      "  precision@10: 0.007445825\n",
      "  recall@10: 0.007448761\n",
      "  ndcg@10: 0.007649927\n",
      "  map@10: 0.002392147\n",
      "Epoch 984, Step 10, LR: 0.000080, Current Loss: 0.3123, Avg Loss: 0.3118\n",
      "Diff stats — min: -5.7378, max: 14.0308, mean: 2.4183, std: 2.2144\n",
      "\n",
      "Step 10819 — Test metrics:\n",
      "  precision@10: 0.007353330\n",
      "  recall@10: 0.007356266\n",
      "  ndcg@10: 0.007515151\n",
      "  map@10: 0.002337618\n",
      "Epoch 984 completed, Train Loss: 0.3117\n",
      "Epoch 985, Step 1, LR: 0.000080, Current Loss: 0.3099, Avg Loss: 0.3099\n",
      "Diff stats — min: -6.7968, max: 13.0465, mean: 2.4290, std: 2.2119\n",
      "\n",
      "Step 10821 — Test metrics:\n",
      "  precision@10: 0.007373150\n",
      "  recall@10: 0.007376086\n",
      "  ndcg@10: 0.007538208\n",
      "  map@10: 0.002346259\n",
      "Epoch 985, Step 10, LR: 0.000080, Current Loss: 0.3124, Avg Loss: 0.3123\n",
      "Diff stats — min: -6.0425, max: 13.6494, mean: 2.4150, std: 2.2037\n",
      "\n",
      "Step 10830 — Test metrics:\n",
      "  precision@10: 0.007353330\n",
      "  recall@10: 0.007356266\n",
      "  ndcg@10: 0.007546091\n",
      "  map@10: 0.002356683\n",
      "Epoch 985 completed, Train Loss: 0.3123\n",
      "Epoch 986, Step 1, LR: 0.000080, Current Loss: 0.3096, Avg Loss: 0.3096\n",
      "Diff stats — min: -7.6017, max: 14.0100, mean: 2.4278, std: 2.2142\n",
      "\n",
      "Step 10832 — Test metrics:\n",
      "  precision@10: 0.007412791\n",
      "  recall@10: 0.007415727\n",
      "  ndcg@10: 0.007588059\n",
      "  map@10: 0.002364286\n",
      "Epoch 986, Step 10, LR: 0.000080, Current Loss: 0.3117, Avg Loss: 0.3116\n",
      "Diff stats — min: -6.4450, max: 13.4192, mean: 2.4233, std: 2.2087\n",
      "\n",
      "Step 10841 — Test metrics:\n",
      "  precision@10: 0.007412791\n",
      "  recall@10: 0.007415727\n",
      "  ndcg@10: 0.007574782\n",
      "  map@10: 0.002356337\n",
      "Epoch 986 completed, Train Loss: 0.3115\n",
      "Epoch 987, Step 1, LR: 0.000080, Current Loss: 0.3107, Avg Loss: 0.3107\n",
      "Diff stats — min: -7.0215, max: 13.8953, mean: 2.4301, std: 2.2190\n",
      "\n",
      "Step 10843 — Test metrics:\n",
      "  precision@10: 0.007432611\n",
      "  recall@10: 0.007435547\n",
      "  ndcg@10: 0.007573031\n",
      "  map@10: 0.002352195\n",
      "Epoch 987, Step 10, LR: 0.000080, Current Loss: 0.3093, Avg Loss: 0.3126\n",
      "Diff stats — min: -6.2430, max: 13.3443, mean: 2.4214, std: 2.2052\n",
      "\n",
      "Step 10852 — Test metrics:\n",
      "  precision@10: 0.007419397\n",
      "  recall@10: 0.007422334\n",
      "  ndcg@10: 0.007555016\n",
      "  map@10: 0.002342101\n",
      "Epoch 987 completed, Train Loss: 0.3124\n",
      "Epoch 988, Step 1, LR: 0.000080, Current Loss: 0.3118, Avg Loss: 0.3118\n",
      "Diff stats — min: -6.0210, max: 13.3607, mean: 2.4098, std: 2.2014\n",
      "\n",
      "Step 10854 — Test metrics:\n",
      "  precision@10: 0.007392970\n",
      "  recall@10: 0.007395907\n",
      "  ndcg@10: 0.007511920\n",
      "  map@10: 0.002321471\n",
      "Epoch 988, Step 10, LR: 0.000080, Current Loss: 0.3135, Avg Loss: 0.3111\n",
      "Diff stats — min: -7.4156, max: 16.5261, mean: 2.4134, std: 2.2114\n",
      "\n",
      "Step 10863 — Test metrics:\n",
      "  precision@10: 0.007340116\n",
      "  recall@10: 0.007342319\n",
      "  ndcg@10: 0.007486014\n",
      "  map@10: 0.002323707\n",
      "Epoch 988 completed, Train Loss: 0.3114\n",
      "Epoch 989, Step 1, LR: 0.000080, Current Loss: 0.3088, Avg Loss: 0.3088\n",
      "Diff stats — min: -5.9086, max: 14.0283, mean: 2.4324, std: 2.2140\n",
      "\n",
      "Step 10865 — Test metrics:\n",
      "  precision@10: 0.007346723\n",
      "  recall@10: 0.007348925\n",
      "  ndcg@10: 0.007499798\n",
      "  map@10: 0.002328156\n",
      "Epoch 989, Step 10, LR: 0.000080, Current Loss: 0.3114, Avg Loss: 0.3124\n",
      "Diff stats — min: -6.2178, max: 13.6201, mean: 2.4300, std: 2.2246\n",
      "\n",
      "Step 10874 — Test metrics:\n",
      "  precision@10: 0.007386364\n",
      "  recall@10: 0.007389300\n",
      "  ndcg@10: 0.007618753\n",
      "  map@10: 0.002386555\n",
      "Epoch 989 completed, Train Loss: 0.3123\n",
      "Epoch 990, Step 1, LR: 0.000080, Current Loss: 0.3111, Avg Loss: 0.3111\n",
      "Diff stats — min: -6.2100, max: 13.9954, mean: 2.4327, std: 2.2231\n",
      "\n",
      "Step 10876 — Test metrics:\n",
      "  precision@10: 0.007392970\n",
      "  recall@10: 0.007395907\n",
      "  ndcg@10: 0.007611355\n",
      "  map@10: 0.002381540\n",
      "Epoch 990, Step 10, LR: 0.000080, Current Loss: 0.3068, Avg Loss: 0.3115\n",
      "Diff stats — min: -6.0412, max: 12.5459, mean: 2.4443, std: 2.2157\n",
      "\n",
      "Step 10885 — Test metrics:\n",
      "  precision@10: 0.007406184\n",
      "  recall@10: 0.007409120\n",
      "  ndcg@10: 0.007609666\n",
      "  map@10: 0.002378176\n",
      "Epoch 990 completed, Train Loss: 0.3115\n",
      "Epoch 991, Step 1, LR: 0.000080, Current Loss: 0.3061, Avg Loss: 0.3061\n",
      "Diff stats — min: -7.3773, max: 15.1995, mean: 2.4357, std: 2.1994\n",
      "\n",
      "Step 10887 — Test metrics:\n",
      "  precision@10: 0.007426004\n",
      "  recall@10: 0.007428941\n",
      "  ndcg@10: 0.007620105\n",
      "  map@10: 0.002378108\n",
      "Epoch 991, Step 10, LR: 0.000080, Current Loss: 0.3143, Avg Loss: 0.3114\n",
      "Diff stats — min: -6.5046, max: 16.4054, mean: 2.4183, std: 2.2248\n",
      "\n",
      "Step 10896 — Test metrics:\n",
      "  precision@10: 0.007326903\n",
      "  recall@10: 0.007329105\n",
      "  ndcg@10: 0.007521794\n",
      "  map@10: 0.002348591\n",
      "Epoch 991 completed, Train Loss: 0.3114\n",
      "Epoch 992, Step 1, LR: 0.000080, Current Loss: 0.3137, Avg Loss: 0.3137\n",
      "Diff stats — min: -6.9350, max: 13.8330, mean: 2.4347, std: 2.2334\n",
      "\n",
      "Step 10898 — Test metrics:\n",
      "  precision@10: 0.007293869\n",
      "  recall@10: 0.007296071\n",
      "  ndcg@10: 0.007512805\n",
      "  map@10: 0.002349958\n",
      "Epoch 992, Step 10, LR: 0.000080, Current Loss: 0.3115, Avg Loss: 0.3129\n",
      "Diff stats — min: -5.9854, max: 14.9740, mean: 2.4231, std: 2.2199\n",
      "\n",
      "Step 10907 — Test metrics:\n",
      "  precision@10: 0.007366543\n",
      "  recall@10: 0.007369480\n",
      "  ndcg@10: 0.007567494\n",
      "  map@10: 0.002364734\n",
      "Epoch 992 completed, Train Loss: 0.3134\n",
      "Epoch 993, Step 1, LR: 0.000080, Current Loss: 0.3125, Avg Loss: 0.3125\n",
      "Diff stats — min: -5.7680, max: 12.7118, mean: 2.4337, std: 2.2265\n",
      "\n",
      "Step 10909 — Test metrics:\n",
      "  precision@10: 0.007419397\n",
      "  recall@10: 0.007422334\n",
      "  ndcg@10: 0.007612363\n",
      "  map@10: 0.002375200\n",
      "Epoch 993, Step 10, LR: 0.000080, Current Loss: 0.3145, Avg Loss: 0.3127\n",
      "Diff stats — min: -5.6498, max: 16.3487, mean: 2.4219, std: 2.2280\n",
      "\n",
      "Step 10918 — Test metrics:\n",
      "  precision@10: 0.007445825\n",
      "  recall@10: 0.007448761\n",
      "  ndcg@10: 0.007617057\n",
      "  map@10: 0.002370381\n",
      "Epoch 993 completed, Train Loss: 0.3124\n",
      "Epoch 994, Step 1, LR: 0.000080, Current Loss: 0.3094, Avg Loss: 0.3094\n",
      "Diff stats — min: -6.0624, max: 13.2898, mean: 2.4317, std: 2.2166\n",
      "\n",
      "Step 10920 — Test metrics:\n",
      "  precision@10: 0.007392970\n",
      "  recall@10: 0.007395907\n",
      "  ndcg@10: 0.007581095\n",
      "  map@10: 0.002361923\n",
      "Epoch 994, Step 10, LR: 0.000080, Current Loss: 0.3119, Avg Loss: 0.3123\n",
      "Diff stats — min: -6.9304, max: 14.4208, mean: 2.4264, std: 2.2198\n",
      "\n",
      "Step 10929 — Test metrics:\n",
      "  precision@10: 0.007432611\n",
      "  recall@10: 0.007435547\n",
      "  ndcg@10: 0.007617755\n",
      "  map@10: 0.002375384\n",
      "Epoch 994 completed, Train Loss: 0.3124\n",
      "Epoch 995, Step 1, LR: 0.000080, Current Loss: 0.3184, Avg Loss: 0.3184\n",
      "Diff stats — min: -6.6580, max: 13.0900, mean: 2.4032, std: 2.2322\n",
      "\n",
      "Step 10931 — Test metrics:\n",
      "  precision@10: 0.007505285\n",
      "  recall@10: 0.007507488\n",
      "  ndcg@10: 0.007679221\n",
      "  map@10: 0.002393534\n",
      "Epoch 995, Step 10, LR: 0.000080, Current Loss: 0.3117, Avg Loss: 0.3124\n",
      "Diff stats — min: -7.1499, max: 13.2899, mean: 2.4343, std: 2.2315\n",
      "\n",
      "Step 10940 — Test metrics:\n",
      "  precision@10: 0.007399577\n",
      "  recall@10: 0.007402514\n",
      "  ndcg@10: 0.007580152\n",
      "  map@10: 0.002361650\n",
      "Epoch 995 completed, Train Loss: 0.3125\n",
      "Epoch 996, Step 1, LR: 0.000080, Current Loss: 0.3145, Avg Loss: 0.3145\n",
      "Diff stats — min: -5.6294, max: 17.6310, mean: 2.4112, std: 2.2157\n",
      "\n",
      "Step 10942 — Test metrics:\n",
      "  precision@10: 0.007419397\n",
      "  recall@10: 0.007422334\n",
      "  ndcg@10: 0.007586592\n",
      "  map@10: 0.002360882\n",
      "Epoch 996, Step 10, LR: 0.000080, Current Loss: 0.3081, Avg Loss: 0.3120\n",
      "Diff stats — min: -6.3476, max: 14.9615, mean: 2.4381, std: 2.2188\n",
      "\n",
      "Step 10951 — Test metrics:\n",
      "  precision@10: 0.007445825\n",
      "  recall@10: 0.007448761\n",
      "  ndcg@10: 0.007666444\n",
      "  map@10: 0.002402954\n",
      "Epoch 996 completed, Train Loss: 0.3124\n",
      "Epoch 997, Step 1, LR: 0.000080, Current Loss: 0.3035, Avg Loss: 0.3035\n",
      "Diff stats — min: -6.5955, max: 12.8258, mean: 2.4489, std: 2.2077\n",
      "\n",
      "Step 10953 — Test metrics:\n",
      "  precision@10: 0.007459038\n",
      "  recall@10: 0.007461974\n",
      "  ndcg@10: 0.007686895\n",
      "  map@10: 0.002411997\n",
      "Epoch 997, Step 10, LR: 0.000080, Current Loss: 0.3150, Avg Loss: 0.3119\n",
      "Diff stats — min: -7.2041, max: 12.8202, mean: 2.4202, std: 2.2246\n",
      "\n",
      "Step 10962 — Test metrics:\n",
      "  precision@10: 0.007293869\n",
      "  recall@10: 0.007295337\n",
      "  ndcg@10: 0.007537612\n",
      "  map@10: 0.002364370\n",
      "Epoch 997 completed, Train Loss: 0.3122\n",
      "Epoch 998, Step 1, LR: 0.000080, Current Loss: 0.3093, Avg Loss: 0.3093\n",
      "Diff stats — min: -6.6443, max: 14.7083, mean: 2.4385, std: 2.2239\n",
      "\n",
      "Step 10964 — Test metrics:\n",
      "  precision@10: 0.007307082\n",
      "  recall@10: 0.007308551\n",
      "  ndcg@10: 0.007541347\n",
      "  map@10: 0.002363707\n",
      "Epoch 998, Step 10, LR: 0.000080, Current Loss: 0.3083, Avg Loss: 0.3127\n",
      "Diff stats — min: -5.5664, max: 14.7074, mean: 2.4331, std: 2.2079\n",
      "\n",
      "Step 10973 — Test metrics:\n",
      "  precision@10: 0.007379757\n",
      "  recall@10: 0.007382693\n",
      "  ndcg@10: 0.007563184\n",
      "  map@10: 0.002360418\n",
      "Epoch 998 completed, Train Loss: 0.3121\n",
      "Epoch 999, Step 1, LR: 0.000080, Current Loss: 0.3119, Avg Loss: 0.3119\n",
      "Diff stats — min: -6.9517, max: 15.2856, mean: 2.4447, std: 2.2336\n",
      "\n",
      "Step 10975 — Test metrics:\n",
      "  precision@10: 0.007373150\n",
      "  recall@10: 0.007376086\n",
      "  ndcg@10: 0.007566320\n",
      "  map@10: 0.002365336\n",
      "Epoch 999, Step 10, LR: 0.000080, Current Loss: 0.3143, Avg Loss: 0.3118\n",
      "Diff stats — min: -5.9576, max: 13.7042, mean: 2.4102, std: 2.2110\n",
      "\n",
      "Step 10984 — Test metrics:\n",
      "  precision@10: 0.007439218\n",
      "  recall@10: 0.007442154\n",
      "  ndcg@10: 0.007605862\n",
      "  map@10: 0.002366695\n",
      "Epoch 999 completed, Train Loss: 0.3119\n",
      "Epoch 1000, Step 1, LR: 0.000080, Current Loss: 0.3147, Avg Loss: 0.3147\n",
      "Diff stats — min: -6.5219, max: 11.9588, mean: 2.4172, std: 2.2201\n",
      "\n",
      "Step 10986 — Test metrics:\n",
      "  precision@10: 0.007459038\n",
      "  recall@10: 0.007461974\n",
      "  ndcg@10: 0.007613842\n",
      "  map@10: 0.002366908\n",
      "Epoch 1000, Step 10, LR: 0.000080, Current Loss: 0.3133, Avg Loss: 0.3110\n",
      "Diff stats — min: -6.3920, max: 15.9276, mean: 2.4249, std: 2.2246\n",
      "\n",
      "Step 10995 — Test metrics:\n",
      "  precision@10: 0.007439218\n",
      "  recall@10: 0.007442154\n",
      "  ndcg@10: 0.007652414\n",
      "  map@10: 0.002393112\n",
      "Epoch 1000 completed, Train Loss: 0.3106\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model,\n",
    "                    data,\n",
    "                    edge_type=edge_type,\n",
    "                    num_epochs=num_epochs,\n",
    "                    lr=lr,\n",
    "                    batch_size=batch_size,\n",
    "                    print_every=print_every,\n",
    "                    test_every=test_every,\n",
    "                    top_k=top_k,\n",
    "                    test_batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:48:32.917270Z",
     "iopub.status.busy": "2025-06-24T18:48:32.917071Z",
     "iopub.status.idle": "2025-06-24T18:48:32.949214Z",
     "shell.execute_reply": "2025-06-24T18:48:32.948537Z",
     "shell.execute_reply.started": "2025-06-24T18:48:32.917256Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='gnn_model_mvl.model' target='_blank'>gnn_model_mvl.model</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/gnn_model_mvl.model"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, \"gnn_model_mvl.model\")\n",
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('gnn_model_mvl.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:48:32.950310Z",
     "iopub.status.busy": "2025-06-24T18:48:32.950017Z",
     "iopub.status.idle": "2025-06-24T18:48:33.197954Z",
     "shell.execute_reply": "2025-06-24T18:48:33.197135Z",
     "shell.execute_reply.started": "2025-06-24T18:48:32.950292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:48:33.199922Z",
     "iopub.status.busy": "2025-06-24T18:48:33.199462Z",
     "iopub.status.idle": "2025-06-24T18:48:33.330961Z",
     "shell.execute_reply": "2025-06-24T18:48:33.330213Z",
     "shell.execute_reply.started": "2025-06-24T18:48:33.199896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "log_model(\n",
    "    experiment=experiment,\n",
    "    model=model,\n",
    "    model_name=\"GNN\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:48:33.332062Z",
     "iopub.status.busy": "2025-06-24T18:48:33.331817Z",
     "iopub.status.idle": "2025-06-24T18:48:35.289981Z",
     "shell.execute_reply": "2025-06-24T18:48:35.289441Z",
     "shell.execute_reply.started": "2025-06-24T18:48:33.332040Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : diffGATGraphModel-movielens\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/annanet/gnn-recommender/527798220a1140c5b8dfc2d8f2ce1335\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Diff stats (mean) vs step [1166] : (-0.2983660101890564, 2.9147939682006836)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Diff stats (std) vs step [1166]  : (0.8144240379333496, 5.913432598114014)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test map@10 vs step [1166]       : (0.0017786384421318198, 0.013094419040611092)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test ndcg@10 vs step [1166]      : (0.005354564317200823, 0.03636796341204262)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test precision@10 vs step [1166] : (0.004668874172185431, 0.03586092715231788)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test recall@10 vs step [1166]    : (0.004668874172185431, 0.03586460632818249)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Train BPR Loss vs step [10107]   : (0.23755714297294617, 2.6491403579711914)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Train Loss vs epoch [194]        : (0.2615285231894746, 2.2075705844999534)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [1010]                      : (0.2453610897064209, 2.6262528896331787)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : diffGATGraphModel-movielens\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed              : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_batch_size   : 2048\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_topk         : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_batch_size  : 4096\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_edge_type   : ('item', 'to_feedback_explicit_positive', 'explicit_positive')\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_lr          : 8e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_num_epochs  : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_print_every : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_test_every  : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     types_of_feedback : ['explicit_positive', 'expliсit_negative', 'implicit_positive', 'implicit_negative']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 2 (4.29 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m All assets have been sent, waiting for delivery confirmation\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7705289,
     "sourceId": 12229447,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
