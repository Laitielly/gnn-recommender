{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-24T22:11:03.441726Z",
     "iopub.status.busy": "2025-06-24T22:11:03.441551Z",
     "iopub.status.idle": "2025-06-24T22:11:18.158967Z",
     "shell.execute_reply": "2025-06-24T22:11:18.158150Z",
     "shell.execute_reply.started": "2025-06-24T22:11:03.441711Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.1/727.1 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install torch_geometric rectools\n",
    "!pip -q install comet_ml\n",
    "!pip -q install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:11:18.160373Z",
     "iopub.status.busy": "2025-06-24T22:11:18.160111Z",
     "iopub.status.idle": "2025-06-24T22:11:24.170589Z",
     "shell.execute_reply": "2025-06-24T22:11:24.169754Z",
     "shell.execute_reply.started": "2025-06-24T22:11:18.160348Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:11:24.172547Z",
     "iopub.status.busy": "2025-06-24T22:11:24.172026Z",
     "iopub.status.idle": "2025-06-24T22:11:24.178443Z",
     "shell.execute_reply": "2025-06-24T22:11:24.177754Z",
     "shell.execute_reply.started": "2025-06-24T22:11:24.172520Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:11:24.179577Z",
     "iopub.status.busy": "2025-06-24T22:11:24.179309Z",
     "iopub.status.idle": "2025-06-24T22:11:29.151734Z",
     "shell.execute_reply": "2025-06-24T22:11:29.151005Z",
     "shell.execute_reply.started": "2025-06-24T22:11:24.179552Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/annanet/gnn-recommender/5321f7ecb6044c33a138b28b232b1381\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "  api_key=os.getenv('API_KEY'),\n",
    "  project_name=\"gnn-recommender\",\n",
    "  workspace=\"annanet\",\n",
    "  log_code=True\n",
    ")\n",
    "\n",
    "experiment.set_name('emoSAGE+THP-books')\n",
    "experiment.add_tags(['books', 'leave-n-out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.comet.com/annanet/gnn-recommender/5321f7ecb6044c33a138b28b232b1381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:11:29.153878Z",
     "iopub.status.busy": "2025-06-24T22:11:29.153052Z",
     "iopub.status.idle": "2025-06-24T22:11:29.158695Z",
     "shell.execute_reply": "2025-06-24T22:11:29.157983Z",
     "shell.execute_reply.started": "2025-06-24T22:11:29.153859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'seed': 42,\n",
    "    'types_of_feedback': [\"explicit_positive\", \"expliсit_negative\",\n",
    "                          \"implicit_positive\", \"implicit_negative\"],\n",
    "    'max_len_of_thp_history': 100,\n",
    "    'pad_id': 0,         \n",
    "    'cls_id': None,  # filled in at the stage of creating a story for thp\n",
    "    'thp_dmodel': 64,  # размер эмбеддингов\n",
    "    'thp_n_head': 4,  # число attention-голов\n",
    "    'thp_window_size': 101,  # окно THP\n",
    "    'thp_decay': 1.0,  # скорость экспоненциального затухания\n",
    "    'thp_dropout': 0.2,  # dropout\n",
    "    'train_edge_type': [('item','to_feedback_explicit_positive','explicit_positive'), \n",
    "                        ('item','to_feedback_implicit_positive','implicit_positive')],\n",
    "    'train_num_epochs': 300,\n",
    "    'train_lr': 1e-3,\n",
    "    'train_batch_size': 4096,\n",
    "    'train_print_every': 20,  # раз в сколько шагов печатаем статистику\n",
    "    'train_test_every': 50,\n",
    "    'test_topk': 10,\n",
    "    'test_batch_size': 8192,\n",
    "    'train_scheduler_step_size': 150,\n",
    "    'train_scheduler_gamma': 0.98\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:11:29.159819Z",
     "iopub.status.busy": "2025-06-24T22:11:29.159480Z",
     "iopub.status.idle": "2025-06-24T22:11:29.214128Z",
     "shell.execute_reply": "2025-06-24T22:11:29.213600Z",
     "shell.execute_reply.started": "2025-06-24T22:11:29.159796Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv', 'test.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/kaggle/input/data/leave-n-out/books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:11:29.214875Z",
     "iopub.status.busy": "2025-06-24T22:11:29.214707Z",
     "iopub.status.idle": "2025-06-24T22:11:39.638141Z",
     "shell.execute_reply": "2025-06-24T22:11:39.637371Z",
     "shell.execute_reply.started": "2025-06-24T22:11:29.214861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from rectools import Columns\n",
    "from rectools.metrics import MAP, Precision, Recall, NDCG, calc_metrics\n",
    "\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:11:39.639356Z",
     "iopub.status.busy": "2025-06-24T22:11:39.638926Z",
     "iopub.status.idle": "2025-06-24T22:11:39.648864Z",
     "shell.execute_reply": "2025-06-24T22:11:39.648217Z",
     "shell.execute_reply.started": "2025-06-24T22:11:39.639335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = hyperparameters['seed']\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:11:39.653398Z",
     "iopub.status.busy": "2025-06-24T22:11:39.653176Z",
     "iopub.status.idle": "2025-06-24T22:12:11.133756Z",
     "shell.execute_reply": "2025-06-24T22:12:11.132669Z",
     "shell.execute_reply.started": "2025-06-24T22:11:39.653381Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            user_id  book_id  rating  \\\n",
      "0  000883382802f2d95a3dd545bb953882  8525590       3   \n",
      "1  000883382802f2d95a3dd545bb953882  2767052       5   \n",
      "2  000883382802f2d95a3dd545bb953882  3236307       5   \n",
      "3  000883382802f2d95a3dd545bb953882   256683       4   \n",
      "4  000883382802f2d95a3dd545bb953882  6001758       5   \n",
      "\n",
      "                  date_added                       date  \n",
      "0  2011-10-31 18:37:56-07:00  2011-10-31 18:37:56-07:00  \n",
      "1  2011-10-31 18:40:33-07:00  2011-10-31 18:40:33-07:00  \n",
      "2  2011-11-02 08:30:30-07:00  2011-11-02 08:30:30-07:00  \n",
      "3  2011-11-02 08:55:16-07:00  2011-11-02 08:55:16-07:00  \n",
      "4  2011-11-02 08:57:21-07:00  2011-11-02 08:57:21-07:00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/4238775169.py:5: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  train['date'] = pd.to_datetime(train['date_added'])\n"
     ]
    }
   ],
   "source": [
    "rootpath = '/kaggle/input/data/leave-n-out/books/'\n",
    "train = pd.read_csv(\n",
    "    rootpath+'train.csv'\n",
    ")\n",
    "train['date'] = pd.to_datetime(train['date_added'])\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:11.135004Z",
     "iopub.status.busy": "2025-06-24T22:12:11.134709Z",
     "iopub.status.idle": "2025-06-24T22:12:11.224681Z",
     "shell.execute_reply": "2025-06-24T22:12:11.223920Z",
     "shell.execute_reply.started": "2025-06-24T22:12:11.134983Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество explicit позитивного фидбека 359463\n",
      "Количество explicit негативного фидбека 178217\n"
     ]
    }
   ],
   "source": [
    "explicit_positive = train[(train[\"rating\"] == 5)].index\n",
    "explisit_negative = train[(train[\"rating\"] <= 2)].index\n",
    "\n",
    "explicit_combined_feedback = explicit_positive.union(explisit_negative)\n",
    "print('Количество explicit позитивного фидбека', explicit_positive.shape[0])\n",
    "print('Количество explicit негативного фидбека', explisit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:11.225778Z",
     "iopub.status.busy": "2025-06-24T22:12:11.225509Z",
     "iopub.status.idle": "2025-06-24T22:12:11.320543Z",
     "shell.execute_reply": "2025-06-24T22:12:11.319892Z",
     "shell.execute_reply.started": "2025-06-24T22:12:11.225753Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество implicit позитивного фидбека 430342\n",
      "Количество implicit негативного фидбека 258651\n"
     ]
    }
   ],
   "source": [
    "implicit_positive = train[(train[\"rating\"] == 4)].index\n",
    "implicit_negative = train[(train[\"rating\"] == 3)].index\n",
    "\n",
    "implicit_combined_feedback = implicit_positive.union(implicit_negative)\n",
    "print('Количество implicit позитивного фидбека', implicit_positive.shape[0])\n",
    "print('Количество implicit негативного фидбека', implicit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:11.321496Z",
     "iopub.status.busy": "2025-06-24T22:12:11.321241Z",
     "iopub.status.idle": "2025-06-24T22:12:11.532193Z",
     "shell.execute_reply": "2025-06-24T22:12:11.531559Z",
     "shell.execute_reply.started": "2025-06-24T22:12:11.321478Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>8525590</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2011-10-31 18:37:56-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>2767052</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2011-10-31 18:40:33-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>3236307</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2011-11-02 08:30:30-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>256683</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2011-11-02 08:55:16-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>6001758</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2011-11-02 08:57:21-07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id  book_id             target  \\\n",
       "0  000883382802f2d95a3dd545bb953882  8525590  implicit_negative   \n",
       "1  000883382802f2d95a3dd545bb953882  2767052  explicit_positive   \n",
       "2  000883382802f2d95a3dd545bb953882  3236307  explicit_positive   \n",
       "3  000883382802f2d95a3dd545bb953882   256683  implicit_positive   \n",
       "4  000883382802f2d95a3dd545bb953882  6001758  explicit_positive   \n",
       "\n",
       "                        date  \n",
       "0  2011-10-31 18:37:56-07:00  \n",
       "1  2011-10-31 18:40:33-07:00  \n",
       "2  2011-11-02 08:30:30-07:00  \n",
       "3  2011-11-02 08:55:16-07:00  \n",
       "4  2011-11-02 08:57:21-07:00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:, \"target\"] = \"\"\n",
    "train.loc[explicit_positive, \"target\"] = \"explicit_positive\"\n",
    "train.loc[explisit_negative, \"target\"] = \"expliсit_negative\"\n",
    "train.loc[implicit_positive, \"target\"] = \"implicit_positive\"\n",
    "train.loc[implicit_negative, \"target\"] = \"implicit_negative\"\n",
    "\n",
    "train = train[['user_id','book_id','target','date']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:11.533583Z",
     "iopub.status.busy": "2025-06-24T22:12:11.532871Z",
     "iopub.status.idle": "2025-06-24T22:12:16.530832Z",
     "shell.execute_reply": "2025-06-24T22:12:16.530238Z",
     "shell.execute_reply.started": "2025-06-24T22:12:11.533560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = train.sort_values(by=[\"user_id\", \"date\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:16.531894Z",
     "iopub.status.busy": "2025-06-24T22:12:16.531593Z",
     "iopub.status.idle": "2025-06-24T22:12:16.541659Z",
     "shell.execute_reply": "2025-06-24T22:12:16.540975Z",
     "shell.execute_reply.started": "2025-06-24T22:12:16.531871Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>8525590</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2011-10-31 18:37:56-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>2767052</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2011-10-31 18:40:33-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>3236307</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2011-11-02 08:30:30-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>256683</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2011-11-02 08:55:16-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>6001758</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2011-11-02 08:57:21-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226668</th>\n",
       "      <td>ffff7cafdaf5196383cb2efca08fb6fe</td>\n",
       "      <td>17131869</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2015-08-26 16:40:00-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226669</th>\n",
       "      <td>ffff7cafdaf5196383cb2efca08fb6fe</td>\n",
       "      <td>19358975</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2015-08-26 16:40:01-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226670</th>\n",
       "      <td>ffff7cafdaf5196383cb2efca08fb6fe</td>\n",
       "      <td>20578940</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2015-08-28 10:23:50-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226671</th>\n",
       "      <td>ffff7cafdaf5196383cb2efca08fb6fe</td>\n",
       "      <td>18630542</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2015-08-31 18:03:52-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226672</th>\n",
       "      <td>ffff7cafdaf5196383cb2efca08fb6fe</td>\n",
       "      <td>23281652</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2015-09-11 17:06:28-07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1226673 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  user_id   book_id             target  \\\n",
       "0        000883382802f2d95a3dd545bb953882   8525590  implicit_negative   \n",
       "1        000883382802f2d95a3dd545bb953882   2767052  explicit_positive   \n",
       "2        000883382802f2d95a3dd545bb953882   3236307  explicit_positive   \n",
       "3        000883382802f2d95a3dd545bb953882    256683  implicit_positive   \n",
       "4        000883382802f2d95a3dd545bb953882   6001758  explicit_positive   \n",
       "...                                   ...       ...                ...   \n",
       "1226668  ffff7cafdaf5196383cb2efca08fb6fe  17131869  implicit_negative   \n",
       "1226669  ffff7cafdaf5196383cb2efca08fb6fe  19358975  implicit_positive   \n",
       "1226670  ffff7cafdaf5196383cb2efca08fb6fe  20578940  implicit_positive   \n",
       "1226671  ffff7cafdaf5196383cb2efca08fb6fe  18630542  implicit_positive   \n",
       "1226672  ffff7cafdaf5196383cb2efca08fb6fe  23281652  implicit_negative   \n",
       "\n",
       "                              date  \n",
       "0        2011-10-31 18:37:56-07:00  \n",
       "1        2011-10-31 18:40:33-07:00  \n",
       "2        2011-11-02 08:30:30-07:00  \n",
       "3        2011-11-02 08:55:16-07:00  \n",
       "4        2011-11-02 08:57:21-07:00  \n",
       "...                            ...  \n",
       "1226668  2015-08-26 16:40:00-07:00  \n",
       "1226669  2015-08-26 16:40:01-07:00  \n",
       "1226670  2015-08-28 10:23:50-07:00  \n",
       "1226671  2015-08-31 18:03:52-07:00  \n",
       "1226672  2015-09-11 17:06:28-07:00  \n",
       "\n",
       "[1226673 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:16.542681Z",
     "iopub.status.busy": "2025-06-24T22:12:16.542427Z",
     "iopub.status.idle": "2025-06-24T22:12:16.556662Z",
     "shell.execute_reply": "2025-06-24T22:12:16.555936Z",
     "shell.execute_reply.started": "2025-06-24T22:12:16.542658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.columns = ['user_id', 'item_id', 'target', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:16.557611Z",
     "iopub.status.busy": "2025-06-24T22:12:16.557415Z",
     "iopub.status.idle": "2025-06-24T22:12:20.186433Z",
     "shell.execute_reply": "2025-06-24T22:12:20.185627Z",
     "shell.execute_reply.started": "2025-06-24T22:12:16.557596Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            user_id   book_id  rating  \\\n",
      "0  000883382802f2d95a3dd545bb953882   8135807       4   \n",
      "1  000883382802f2d95a3dd545bb953882  18301124       5   \n",
      "2  000883382802f2d95a3dd545bb953882  18220354       4   \n",
      "3  000883382802f2d95a3dd545bb953882  17383918       5   \n",
      "4  000883382802f2d95a3dd545bb953882  13188676       5   \n",
      "\n",
      "                  date_added                       date  \n",
      "0  2013-08-13 09:37:39-07:00  2013-08-13 09:37:39-07:00  \n",
      "1  2013-10-27 22:18:01-07:00  2013-10-27 22:18:01-07:00  \n",
      "2  2013-12-09 22:20:59-08:00  2013-12-09 22:20:59-08:00  \n",
      "3  2013-12-22 20:57:14-08:00  2013-12-22 20:57:14-08:00  \n",
      "4  2013-12-22 20:58:15-08:00  2013-12-22 20:58:15-08:00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/2717431719.py:4: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  test['date'] = pd.to_datetime(test['date_added'])\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\n",
    "    rootpath+'test.csv'\n",
    ")\n",
    "test['date'] = pd.to_datetime(test['date_added'])\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:20.187438Z",
     "iopub.status.busy": "2025-06-24T22:12:20.187205Z",
     "iopub.status.idle": "2025-06-24T22:12:20.201877Z",
     "shell.execute_reply": "2025-06-24T22:12:20.201256Z",
     "shell.execute_reply.started": "2025-06-24T22:12:20.187421Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>8135807</td>\n",
       "      <td>2013-08-13 09:37:39-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>18301124</td>\n",
       "      <td>2013-10-27 22:18:01-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>18220354</td>\n",
       "      <td>2013-12-09 22:20:59-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>17383918</td>\n",
       "      <td>2013-12-22 20:57:14-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>13188676</td>\n",
       "      <td>2013-12-22 20:58:15-08:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id   book_id                       date\n",
       "0  000883382802f2d95a3dd545bb953882   8135807  2013-08-13 09:37:39-07:00\n",
       "1  000883382802f2d95a3dd545bb953882  18301124  2013-10-27 22:18:01-07:00\n",
       "2  000883382802f2d95a3dd545bb953882  18220354  2013-12-09 22:20:59-08:00\n",
       "3  000883382802f2d95a3dd545bb953882  17383918  2013-12-22 20:57:14-08:00\n",
       "4  000883382802f2d95a3dd545bb953882  13188676  2013-12-22 20:58:15-08:00"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[['user_id','book_id', 'date']]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:20.202857Z",
     "iopub.status.busy": "2025-06-24T22:12:20.202615Z",
     "iopub.status.idle": "2025-06-24T22:12:20.208946Z",
     "shell.execute_reply": "2025-06-24T22:12:20.208248Z",
     "shell.execute_reply.started": "2025-06-24T22:12:20.202833Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test.columns = ['user_id', 'item_id', 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP model v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:20.210214Z",
     "iopub.status.busy": "2025-06-24T22:12:20.209765Z",
     "iopub.status.idle": "2025-06-24T22:12:20.393381Z",
     "shell.execute_reply": "2025-06-24T22:12:20.392724Z",
     "shell.execute_reply.started": "2025-06-24T22:12:20.210195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.loc[:, \"event\"] = 0\n",
    "train.loc[(train[\"target\"] == \"explicit_positive\") | (train[\"target\"] == \"implicit_positive\"), \"event\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:20.398819Z",
     "iopub.status.busy": "2025-06-24T22:12:20.398612Z",
     "iopub.status.idle": "2025-06-24T22:12:20.464269Z",
     "shell.execute_reply": "2025-06-24T22:12:20.463620Z",
     "shell.execute_reply.started": "2025-06-24T22:12:20.398803Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151126, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[(test.user_id.isin(train.user_id)) & (test.item_id.isin(train.item_id))].copy()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:20.465124Z",
     "iopub.status.busy": "2025-06-24T22:12:20.464881Z",
     "iopub.status.idle": "2025-06-24T22:12:20.895905Z",
     "shell.execute_reply": "2025-06-24T22:12:20.895016Z",
     "shell.execute_reply.started": "2025-06-24T22:12:20.465101Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. Преобразование данных - для куарека не особо нужно, но для других - напоминалка\n",
    "# делаем всегда! чтобы не сломать ничего дальше и чтобы все индексы были от 0 до N без пропусков\n",
    "user_encoder = LabelEncoder()\n",
    "video_encoder = LabelEncoder()\n",
    "\n",
    "train.loc[:, 'user_id'] = user_encoder.fit_transform(train['user_id'])\n",
    "train.loc[:, 'item_id'] = video_encoder.fit_transform(train['item_id'])\n",
    "\n",
    "test.loc[:, 'user_id'] = user_encoder.transform(test['user_id'])\n",
    "test.loc[:, 'item_id'] = video_encoder.transform(test['item_id'])\n",
    "\n",
    "train['user_id'] = train['user_id'].astype(int)\n",
    "train['item_id'] = train['item_id'].astype(int)\n",
    "test['user_id'] = test['user_id'].astype(int)\n",
    "test['item_id'] = test['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:20.897504Z",
     "iopub.status.busy": "2025-06-24T22:12:20.896796Z",
     "iopub.status.idle": "2025-06-24T22:12:20.920161Z",
     "shell.execute_reply": "2025-06-24T22:12:20.919385Z",
     "shell.execute_reply.started": "2025-06-24T22:12:20.897479Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных item_id 25456\n",
      "Количество уникальных user_id 18892\n"
     ]
    }
   ],
   "source": [
    "# т.е. сразу знаем количество и в каких пределах изменяется user_id и video_id\n",
    "num_videos = train['item_id'].nunique()\n",
    "num_users = train['user_id'].nunique()\n",
    "\n",
    "print('Количество уникальных item_id', num_videos)\n",
    "print('Количество уникальных user_id', num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:20.921162Z",
     "iopub.status.busy": "2025-06-24T22:12:20.920903Z",
     "iopub.status.idle": "2025-06-24T22:12:20.932532Z",
     "shell.execute_reply": "2025-06-24T22:12:20.931941Z",
     "shell.execute_reply.started": "2025-06-24T22:12:20.921144Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# так как используем pad, то нумерацию item_id начинаем с 1 до max + 1, чтобы для pad забить 0\n",
    "train.loc[:, 'item_id'] += 1\n",
    "test.loc[:, 'item_id'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:20.933466Z",
     "iopub.status.busy": "2025-06-24T22:12:20.933233Z",
     "iopub.status.idle": "2025-06-24T22:12:20.941300Z",
     "shell.execute_reply": "2025-06-24T22:12:20.940694Z",
     "shell.execute_reply.started": "2025-06-24T22:12:20.933451Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "\n",
    "def prepare_hetero_data(df: pd.DataFrame) -> HeteroData:\n",
    "    \"\"\"\n",
    "    Build a heterogeneous graph dataset from interaction records.\n",
    "\n",
    "    This function constructs a PyTorch Geometric HeteroData object with three types of nodes:\n",
    "      - 'user': representing each unique user in the dataset\n",
    "      - 'item': representing each unique item (formerly movie)\n",
    "      - one node set per feedback type (target), representing feedback interaction events\n",
    "\n",
    "    Edges are created as follows:\n",
    "      1) item -> feedback: connecting items to feedback events of type ft\n",
    "      2) feedback -> item: reverse link from feedback events back to items (for message passing)\n",
    "      3) feedback -> user: linking each feedback event of type ft to its corresponding user (one-to-one)\n",
    "      4) user -> user: a complete graph among all users under the relation 'interacts'\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame must contain the following columns:\n",
    "          - 'user_id' : integer identifiers for users (0-indexed or otherwise)\n",
    "          - 'item_id' : integer identifiers for items (e.g. movies), values must be in [0, max(item_id)]\n",
    "          - 'target' : categorical or numeric label indicating feedback type (e.g. click, purchase)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    data : torch_geometric.data.HeteroData\n",
    "        A heterogeneous graph with node types 'user', 'item', and one per feedback label, and edge_index\n",
    "        tensors appropriately set for message passing in a GNN.\n",
    "    \"\"\"\n",
    "    # Determine the number of users and items\n",
    "    num_users = df['user_id'].nunique()\n",
    "    num_items = int(df['item_id'].max()) + 1\n",
    "    feedback_types = df['target'].unique().tolist()\n",
    "\n",
    "    # Initialize HeteroData\n",
    "    data = HeteroData()\n",
    "    data['user'].node_id = torch.arange(num_users)\n",
    "    data['item'].node_id = torch.arange(num_items)\n",
    "    for ft in feedback_types:\n",
    "        data[ft].node_id = torch.arange(num_users)\n",
    "\n",
    "    # Build edges: item <-> feedback <-> user\n",
    "    for ft in feedback_types:\n",
    "        mask = df['target'] == ft\n",
    "        items = torch.LongTensor(df.loc[mask, 'item_id'].values)\n",
    "        users_idx = torch.LongTensor(df.loc[mask, 'user_id'].values)\n",
    "\n",
    "        # item -> feedback\n",
    "        data['item', f'to_feedback_{ft}', ft].edge_index = torch.stack([items, users_idx], dim=0)\n",
    "        # feedback -> item\n",
    "        data[ft, f'feedback_to_item_{ft}', 'item'].edge_index = torch.stack([users_idx, items], dim=0)\n",
    "        # feedback -> user (1:1 mapping)\n",
    "        idx = torch.arange(num_users)\n",
    "        data[ft, f'to_user_{ft}', 'user'].edge_index = torch.stack([idx, idx], dim=0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:20.942198Z",
     "iopub.status.busy": "2025-06-24T22:12:20.941969Z",
     "iopub.status.idle": "2025-06-24T22:12:21.393062Z",
     "shell.execute_reply": "2025-06-24T22:12:21.392428Z",
     "shell.execute_reply.started": "2025-06-24T22:12:20.942175Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ node_id=[18892] },\n",
       "  item={ node_id=[25457] },\n",
       "  implicit_negative={ node_id=[18892] },\n",
       "  explicit_positive={ node_id=[18892] },\n",
       "  implicit_positive={ node_id=[18892] },\n",
       "  expliсit_negative={ node_id=[18892] },\n",
       "  (item, to_feedback_implicit_negative, implicit_negative)={ edge_index=[2, 258651] },\n",
       "  (implicit_negative, feedback_to_item_implicit_negative, item)={ edge_index=[2, 258651] },\n",
       "  (implicit_negative, to_user_implicit_negative, user)={ edge_index=[2, 18892] },\n",
       "  (item, to_feedback_explicit_positive, explicit_positive)={ edge_index=[2, 359463] },\n",
       "  (explicit_positive, feedback_to_item_explicit_positive, item)={ edge_index=[2, 359463] },\n",
       "  (explicit_positive, to_user_explicit_positive, user)={ edge_index=[2, 18892] },\n",
       "  (item, to_feedback_implicit_positive, implicit_positive)={ edge_index=[2, 430342] },\n",
       "  (implicit_positive, feedback_to_item_implicit_positive, item)={ edge_index=[2, 430342] },\n",
       "  (implicit_positive, to_user_implicit_positive, user)={ edge_index=[2, 18892] },\n",
       "  (item, to_feedback_expliсit_negative, expliсit_negative)={ edge_index=[2, 178217] },\n",
       "  (expliсit_negative, feedback_to_item_expliсit_negative, item)={ edge_index=[2, 178217] },\n",
       "  (expliсit_negative, to_user_expliсit_negative, user)={ edge_index=[2, 18892] }\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = prepare_hetero_data(train)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:12:21.394108Z",
     "iopub.status.busy": "2025-06-24T22:12:21.393840Z",
     "iopub.status.idle": "2025-06-24T22:12:21.406551Z",
     "shell.execute_reply": "2025-06-24T22:12:21.405972Z",
     "shell.execute_reply.started": "2025-06-24T22:12:21.394090Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     1,     2,  ..., 25454, 25455, 25456])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['item'].node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:13:27.610641Z",
     "iopub.status.busy": "2025-06-24T22:13:27.610361Z",
     "iopub.status.idle": "2025-06-24T22:13:27.618892Z",
     "shell.execute_reply": "2025-06-24T22:13:27.618103Z",
     "shell.execute_reply.started": "2025-06-24T22:13:27.610620Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_thp_data(df: pd.DataFrame, max_len: int, pad: int, cls_id: int):\n",
    "    \"\"\"\n",
    "    Build sequences of item ids, event types and timestamps per user for THP training.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame with columns ['user_id','item_id','event','date']\n",
    "    max_len : int, maximum sequence length (pad or truncate to this length)\n",
    "    pad : int, padding token value (left-padding)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    seq_ids   : LongTensor [num_users, max_len]\n",
    "    event_type: LongTensor [num_users, max_len]\n",
    "    seq_times : FloatTensor [num_users, max_len]\n",
    "    seq_mask  : BoolTensor [num_users, max_len]\n",
    "    \"\"\"\n",
    "    users = df['user_id'].unique()\n",
    "    num_users = len(users)\n",
    "\n",
    "    # +1 for the [CLS] token\n",
    "    new_max_len = max_len + 1\n",
    "    \n",
    "    seq_ids    = torch.full((num_users, new_max_len), pad, dtype=torch.long)\n",
    "    event_type = torch.full((num_users, new_max_len), pad, dtype=torch.long)\n",
    "    seq_times  = torch.zeros((num_users, new_max_len), dtype=torch.float)\n",
    "    seq_mask   = torch.zeros((num_users, new_max_len), dtype=torch.bool)\n",
    "\n",
    "    # map event labels to ints\n",
    "    label2idx = {label: idx for idx, label in enumerate(df['event'].unique())}\n",
    "\n",
    "    # устанавливаем CLS-токен в позицию 0\n",
    "    seq_ids[:, 0]  = cls_id\n",
    "    event_type[:,0] = cls_id   \n",
    "    seq_mask[:, 0] = True\n",
    "\n",
    "    for i, u in enumerate(users):\n",
    "        user_df = df[df['user_id'] == u].sort_values('date')\n",
    "        items = user_df['item_id'].values\n",
    "        types = user_df['event'].map(label2idx).values\n",
    "        times = pd.to_datetime(user_df['date'], utc=True).values.astype('datetime64[ns]').astype(np.int64) / 1e9\n",
    "        \n",
    "        seq = len(items)\n",
    "        if seq == 0:\n",
    "            continue\n",
    "\n",
    "        # вставляем реальные события **cдвинутые на 1** вправо из-за CLS,\n",
    "        # чтобы первые new_max_len-lengt...new_max_len-1 оказались данными\n",
    "        length = min(seq, max_len)\n",
    "        start = max(0, new_max_len - length)\n",
    "        seq_ids[i, start:]    = torch.tensor(items[-length:],    dtype=torch.long)\n",
    "        event_type[i, start:] = torch.tensor(types[-length:],    dtype=torch.long)\n",
    "        seq_times[i, start:]  = torch.tensor(times[-length:],    dtype=torch.float)\n",
    "        seq_mask[i, start:]   = True\n",
    "\n",
    "    return seq_ids, event_type, seq_times, seq_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:13:29.377173Z",
     "iopub.status.busy": "2025-06-24T22:13:29.376509Z",
     "iopub.status.idle": "2025-06-24T22:14:16.395292Z",
     "shell.execute_reply": "2025-06-24T22:14:16.394653Z",
     "shell.execute_reply.started": "2025-06-24T22:13:29.377145Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([25457,  9001,  8173,  4688, 10179,  8313,  7560,  7999, 10156,  9017,\n",
       "         10317,  9527, 10657, 10465,  9430, 10118,  7847,  8615,  8499, 10624,\n",
       "          8549,  6047,  2227,  3964,  8672,  6956, 10461,  4306,  9188,  7244,\n",
       "          9085,  8347, 10637, 10044,  9356, 11191,  4878,  3952,  2054,  4613,\n",
       "          5456,  6701,  6336,  5633,  9084, 10119,  5372, 10850, 11443,  3245,\n",
       "          5680,  6149,  4990, 10387,  5511,  9814, 12165,  6265,  7985,  8194,\n",
       "         12013,  9450,  4163,  5100,  6254,  8927, 10016, 11673, 10982,  7593,\n",
       "         12154, 13183, 13064, 13201, 13101, 11279, 12593,  4304, 12793, 13370,\n",
       "          7890, 11610, 13748, 12131, 10526, 11708, 10737,  8000, 14611, 14119,\n",
       "         12326, 11518, 14413, 12696,   137,  1451,  2228,  4871,   448,   426,\n",
       "          8821]),\n",
       " tensor([25457,     1,     0,     1,     0,     1,     1,     1,     0,     0,\n",
       "             0,     1,     1,     1,     1,     1,     1,     0,     0,     1,\n",
       "             1,     1,     0,     1,     0,     1,     1,     1,     0,     0,\n",
       "             1,     0,     1,     0,     0,     1,     0,     0,     0,     0,\n",
       "             0,     0,     0,     1,     1,     1,     1,     1,     1,     0,\n",
       "             0,     0,     0,     1,     0,     0,     1,     1,     0,     0,\n",
       "             0,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             0,     1,     0,     1,     1,     1,     1,     0,     0,     1,\n",
       "             1,     1,     1,     0,     0,     1,     0,     1,     1,     1,\n",
       "             0,     1,     1,     1,     0,     0,     0,     0,     1,     0,\n",
       "             1]),\n",
       " tensor([0.0000e+00, 1.3210e+09, 1.3216e+09, 1.3220e+09, 1.3225e+09, 1.3225e+09,\n",
       "         1.3225e+09, 1.3225e+09, 1.3225e+09, 1.3225e+09, 1.3225e+09, 1.3225e+09,\n",
       "         1.3225e+09, 1.3225e+09, 1.3225e+09, 1.3225e+09, 1.3225e+09, 1.3225e+09,\n",
       "         1.3227e+09, 1.3228e+09, 1.3228e+09, 1.3230e+09, 1.3230e+09, 1.3234e+09,\n",
       "         1.3250e+09, 1.3262e+09, 1.3272e+09, 1.3284e+09, 1.3291e+09, 1.3299e+09,\n",
       "         1.3306e+09, 1.3315e+09, 1.3315e+09, 1.3321e+09, 1.3324e+09, 1.3332e+09,\n",
       "         1.3334e+09, 1.3336e+09, 1.3336e+09, 1.3336e+09, 1.3336e+09, 1.3336e+09,\n",
       "         1.3336e+09, 1.3345e+09, 1.3345e+09, 1.3354e+09, 1.3368e+09, 1.3369e+09,\n",
       "         1.3380e+09, 1.3387e+09, 1.3387e+09, 1.3387e+09, 1.3401e+09, 1.3414e+09,\n",
       "         1.3420e+09, 1.3430e+09, 1.3434e+09, 1.3441e+09, 1.3444e+09, 1.3448e+09,\n",
       "         1.3468e+09, 1.3472e+09, 1.3479e+09, 1.3484e+09, 1.3493e+09, 1.3505e+09,\n",
       "         1.3525e+09, 1.3525e+09, 1.3528e+09, 1.3535e+09, 1.3541e+09, 1.3545e+09,\n",
       "         1.3545e+09, 1.3547e+09, 1.3553e+09, 1.3555e+09, 1.3558e+09, 1.3574e+09,\n",
       "         1.3574e+09, 1.3574e+09, 1.3574e+09, 1.3578e+09, 1.3579e+09, 1.3606e+09,\n",
       "         1.3615e+09, 1.3621e+09, 1.3625e+09, 1.3628e+09, 1.3642e+09, 1.3642e+09,\n",
       "         1.3648e+09, 1.3667e+09, 1.3687e+09, 1.3741e+09, 1.3758e+09, 1.3758e+09,\n",
       "         1.3758e+09, 1.3758e+09, 1.3758e+09, 1.3759e+09, 1.3764e+09]),\n",
       " tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_ID = hyperparameters['pad_id'] \n",
    "CLS_ID = data['item'].node_id.shape[0]  \n",
    "hyperparameters['cls_id'] = CLS_ID\n",
    "max_len = hyperparameters['max_len_of_thp_history']\n",
    "\n",
    "seq_ids, event_type, seq_times, seq_mask = prepare_thp_data(train, \n",
    "                                                            max_len=max_len, \n",
    "                                                            pad=PAD_ID,\n",
    "                                                            cls_id=CLS_ID)\n",
    "seq_ids[0], event_type[0], seq_times[0], seq_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:16.396959Z",
     "iopub.status.busy": "2025-06-24T22:14:16.396693Z",
     "iopub.status.idle": "2025-06-24T22:14:16.412606Z",
     "shell.execute_reply": "2025-06-24T22:14:16.411900Z",
     "shell.execute_reply.started": "2025-06-24T22:14:16.396943Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class THPEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head Transformer Hawkes-inspired encoder with local window.\n",
    "    Integrates exponential decay kernel within last `window_size` events.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, n_head: int, window_size: int = 50, \n",
    "                 decay: float = 1.0, dropout: float = 0.1, max_len: int = 101):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_len = max_len\n",
    "        # Learnable positional embeddings\n",
    "        self.pos_emb = nn.Embedding(max_len, d_model)\n",
    "        # Temporal (time) embedding: simple linear projection from scalar to d_model\n",
    "        self.time_emb = nn.Linear(1, d_model)\n",
    "        \n",
    "        self.heads = nn.ModuleList([\n",
    "            _THPHead(d_model, decay, window_size, dropout) for _ in range(n_head)\n",
    "        ])\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "                nn.LayerNorm(d_model),\n",
    "                nn.Linear(d_model, d_model * 4),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(d_model * 4, d_model),\n",
    "                nn.Dropout(dropout)\n",
    "            )\n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, emb: torch.Tensor, times: torch.Tensor, mask: torch.BoolTensor = None):\n",
    "        # emb: [B, L, D], times: [B, L], mask: [B, L]\n",
    "        B, L, D = emb.shape\n",
    "        \n",
    "        positions = torch.arange(L, device=emb.device).unsqueeze(0).expand(B, -1)  # [B, L]\n",
    "        pe = self.pos_emb(positions)  # [B, L, D]\n",
    "        te = self.time_emb(times.unsqueeze(-1))  # [B, L, D]\n",
    "        x = emb + pe + te\n",
    "        \n",
    "        attn_out = torch.stack([head(x, times, mask) for head in self.heads], dim=0).sum(0)\n",
    "        \n",
    "        # Residual connection + normalization\n",
    "        x = x + attn_out\n",
    "        x = x + self.ffn(x)\n",
    "        \n",
    "        return self.final_norm(x)  # [B, L, D]\n",
    "\n",
    "class _THPHead(nn.Module):\n",
    "    def __init__(self, d_model: int, decay: float, window_size: int, dropout: float,\n",
    "                pos_lambda: float = None):\n",
    "        super().__init__()\n",
    "        self.linear_v = nn.Linear(d_model, d_model, bias=False)\n",
    "        nn.init.xavier_uniform_(self.linear_v.weight)\n",
    "        self.temperature = d_model ** 0.5\n",
    "        self.decay = decay\n",
    "        self.window_size = window_size\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.input_norm = nn.LayerNorm(d_model)\n",
    "        self.pos_lambda = pos_lambda or (1.0 / window_size)\n",
    "\n",
    "    def forward(self, emb: torch.Tensor, times: torch.Tensor, mask: torch.BoolTensor = None):\n",
    "        B, L, D = emb.size()\n",
    "        emb_norm = self.input_norm(emb)\n",
    "        q = emb_norm / self.temperature           # [B, L, D]\n",
    "        k = emb_norm                              # [B, L, D]\n",
    "        v = F.elu(self.linear_v(emb_norm))        # [B, L, D]\n",
    "\n",
    "        if not torch.isfinite(q).all():\n",
    "            print(\"NaN/Inf в q:\", torch.isnan(q).sum().item(), torch.isinf(q).sum().item())\n",
    "        if not torch.isfinite(k).all():\n",
    "            print(\"NaN/Inf в k:\", torch.isnan(k).sum().item(), torch.isinf(k).sum().item())\n",
    "        if not torch.isfinite(v).all():\n",
    "            print(\"NaN/Inf в v:\", torch.isnan(v).sum().item(), torch.isinf(v).sum().item())\n",
    "\n",
    "        # 3) Build pad mask only\n",
    "        if mask is not None:\n",
    "            pad_mask = ~mask.unsqueeze(1).expand(-1, L, -1)  # [B, L, L]\n",
    "        else:\n",
    "            pad_mask = torch.zeros((B, L, L), dtype=torch.bool, device=emb.device)\n",
    "\n",
    "        # Always allow self-attention for pad_mask diagonal\n",
    "        idx = torch.arange(L, device=emb.device)\n",
    "        pad_mask[:, idx, idx] = False\n",
    "\n",
    "        scores = torch.bmm(q, k.transpose(1, 2))  # [B, L, L]\n",
    "\n",
    "        # Apply temporal decay kernel\n",
    "        delta = (times.unsqueeze(-1) - times.unsqueeze(-2)).clamp(min=0)\n",
    "        scores = scores * torch.exp(-self.decay * delta)\n",
    "\n",
    "        # Apply smooth positional decay\n",
    "        dist = (idx.unsqueeze(0) - idx.unsqueeze(1)).abs().float()  # [L, L]\n",
    "        pos_decay = torch.exp(-self.pos_lambda * dist).unsqueeze(0)    # [1, L, L]\n",
    "        scores = scores * pos_decay\n",
    "\n",
    "        scores = torch.clamp(scores, min=-1e3, max=1e3)\n",
    "        scores = scores.masked_fill(pad_mask, float('-inf'))\n",
    "\n",
    "        # Debug range\n",
    "        finite = scores[~pad_mask]\n",
    "        # if finite.numel() > 0:\n",
    "        #     print(f\"Диапазон scores до softmax: min={finite.min().item():.3e}, max={finite.max().item():.3e}\")\n",
    "\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        if not torch.isfinite(attn).all():\n",
    "            print(\"NaN/Inf в attn после softmax:\", torch.isnan(attn).sum().item(), torch.isinf(attn).sum().item())\n",
    "        \n",
    "        attn = torch.nan_to_num(attn, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.bmm(attn, v)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:16.413629Z",
     "iopub.status.busy": "2025-06-24T22:14:16.413388Z",
     "iopub.status.idle": "2025-06-24T22:14:16.437633Z",
     "shell.execute_reply": "2025-06-24T22:14:16.437107Z",
     "shell.execute_reply.started": "2025-06-24T22:14:16.413605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HeteroGNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 feedback_types: list,\n",
    "                 emb_dim: int = 32,\n",
    "                 hidden_dim: int = 16,\n",
    "                 dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.feedback_types = feedback_types\n",
    "        # Embeddings\n",
    "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
    "        # 0 - padding, все остальное - item_id\n",
    "        self.item_emb = nn.Embedding(num_items + 1, emb_dim, padding_idx=0)  \n",
    "        self.fb_emb = nn.ModuleDict({ft: nn.Embedding(num_users, emb_dim)\n",
    "                                     for ft in feedback_types})\n",
    "        # LayerNorms\n",
    "        types = ['user', 'item'] + feedback_types\n",
    "        self.norm1 = nn.ModuleDict({t: nn.LayerNorm(hidden_dim) for t in types})\n",
    "        self.norm2 = nn.ModuleDict({t: nn.LayerNorm(emb_dim) for t in types})\n",
    "        # Convolutions\n",
    "        conv1, conv2 = {}, {}\n",
    "        for ft in feedback_types:\n",
    "            conv1[('item', f'to_feedback_{ft}', ft)] = SAGEConv(emb_dim, hidden_dim)\n",
    "            conv1[(ft, f'feedback_to_item_{ft}', 'item')] = SAGEConv(emb_dim, hidden_dim)\n",
    "            conv1[(ft, f'to_user_{ft}', 'user')] = SAGEConv(emb_dim, hidden_dim)\n",
    "            conv2[('item', f'to_feedback_{ft}', ft)] = SAGEConv(hidden_dim, emb_dim)\n",
    "            conv2[(ft, f'feedback_to_item_{ft}', 'item')] = SAGEConv(hidden_dim, emb_dim)\n",
    "            conv2[(ft, f'to_user_{ft}', 'user')] = SAGEConv(hidden_dim, emb_dim)\n",
    "        # user-user\n",
    "        conv1[('user', 'interacts', 'user')] = SAGEConv(emb_dim, hidden_dim)\n",
    "        conv2[('user', 'interacts', 'user')] = SAGEConv(hidden_dim, emb_dim)\n",
    "        self.conv1 = HeteroConv(conv1, aggr='mean')\n",
    "        self.conv2 = HeteroConv(conv2, aggr='mean')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Node features\n",
    "        x = {\n",
    "            'user': self.user_emb(data['user'].node_id),\n",
    "            'item': self.item_emb(data['item'].node_id)\n",
    "        }\n",
    "        for ft in self.feedback_types:\n",
    "            x[ft] = self.fb_emb[ft](data[ft].node_id)\n",
    "            \n",
    "        h1 = self.conv1(x, data.edge_index_dict)\n",
    "        h1 = {t: self.dropout(F.leaky_relu(self.norm1[t](h1[t]))) for t in h1}\n",
    "        \n",
    "        h2 = self.conv2(h1, data.edge_index_dict)\n",
    "        out = {t: self.norm2[t](h2[t]) for t in h2}\n",
    "        return out['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:16.439026Z",
     "iopub.status.busy": "2025-06-24T22:14:16.438813Z",
     "iopub.status.idle": "2025-06-24T22:14:16.457392Z",
     "shell.execute_reply": "2025-06-24T22:14:16.456706Z",
     "shell.execute_reply.started": "2025-06-24T22:14:16.439010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 feedback_types: list,\n",
    "                 d_model: int = 32,\n",
    "                 n_head: int = 4,\n",
    "                 window_size: int = 50,\n",
    "                 decay: float = 1.0,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        # Static graph encoder\n",
    "        self.gnn = HeteroGNN(num_users, num_items, feedback_types,\n",
    "                             emb_dim=d_model, hidden_dim=d_model//2,\n",
    "                             dropout=dropout)\n",
    "        # Inlined THP sequence encoder\n",
    "        self.thp = THPEncoder(d_model=d_model,\n",
    "                              n_head=n_head,\n",
    "                              window_size=window_size,\n",
    "                              decay=decay,\n",
    "                              dropout=dropout)\n",
    "\n",
    "    def forward(self, data, seq_ids, seq_times, seq_mask, batch_users):\n",
    "        # Static graph embeddings\n",
    "        user_embs = self.gnn(data)          # [num_users, d_model]\n",
    "        # Sequence encoding\n",
    "        seq_item_emb = self.gnn.item_emb(seq_ids)  # [B, L, d_model]\n",
    "        attn_out = self.thp(seq_item_emb, seq_times, seq_mask)\n",
    "        seq_rep = attn_out[:, -1, :]        # [B, d_model]\n",
    "        # Get static user embeddings\n",
    "        gnn_rep = user_embs[batch_users]   # [B, d_model]\n",
    "        # Updated user embedding\n",
    "        updated_user_emb = seq_rep + gnn_rep\n",
    "        return updated_user_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:16.458390Z",
     "iopub.status.busy": "2025-06-24T22:14:16.458162Z",
     "iopub.status.idle": "2025-06-24T22:14:16.665685Z",
     "shell.execute_reply": "2025-06-24T22:14:16.664893Z",
     "shell.execute_reply.started": "2025-06-24T22:14:16.458376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_users = data['user'].node_id.shape[0]      \n",
    "num_items = data['item'].node_id.shape[0]      \n",
    "feedback_types = train['target'].unique().tolist()\n",
    "data.user_idx = data['user'].node_id\n",
    "d_model = hyperparameters['thp_dmodel']             \n",
    "n_head = hyperparameters['thp_n_head']          \n",
    "window_size = hyperparameters['thp_window_size']     \n",
    "decay = hyperparameters['thp_decay']         \n",
    "dropout = hyperparameters['thp_dropout']           \n",
    "\n",
    "model = Model(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    feedback_types=feedback_types,\n",
    "    d_model=d_model,\n",
    "    n_head=n_head,\n",
    "    window_size=window_size,\n",
    "    decay=decay,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:16.666808Z",
     "iopub.status.busy": "2025-06-24T22:14:16.666601Z",
     "iopub.status.idle": "2025-06-24T22:14:16.671641Z",
     "shell.execute_reply": "2025-06-24T22:14:16.670980Z",
     "shell.execute_reply.started": "2025-06-24T22:14:16.666793Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25457"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:20.101272Z",
     "iopub.status.busy": "2025-06-24T22:14:20.100695Z",
     "iopub.status.idle": "2025-06-24T22:14:20.909563Z",
     "shell.execute_reply": "2025-06-24T22:14:20.908932Z",
     "shell.execute_reply.started": "2025-06-24T22:14:20.101249Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THPEncoder output shape: torch.Size([32, 101, 64])\n"
     ]
    }
   ],
   "source": [
    "B = 32\n",
    "seq_ids_batch   = seq_ids[:B]     # [B, L]\n",
    "seq_times_batch = seq_times[:B]   # [B, L]\n",
    "seq_mask_batch  = seq_mask[:B]    # [B, L]\n",
    "\n",
    "item_emb = model.gnn.item_emb \n",
    "d_model = item_emb.embedding_dim\n",
    "\n",
    "# Получаем seq_item_emb: [B, L, D]\n",
    "seq_item_emb = item_emb(seq_ids_batch)\n",
    "\n",
    "thp_encoder = THPEncoder(\n",
    "    d_model=d_model,\n",
    "    n_head=4,\n",
    "    window_size=50,\n",
    "    decay=1.0,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "thp_encoder.to(device)\n",
    "seq_item_emb   = seq_item_emb.to(device)\n",
    "seq_times_batch= seq_times_batch.to(device)\n",
    "seq_mask_batch = seq_mask_batch.to(device)\n",
    "\n",
    "out = thp_encoder(\n",
    "    emb=seq_item_emb,\n",
    "    times=seq_times_batch,\n",
    "    mask=seq_mask_batch\n",
    ")\n",
    "\n",
    "print(\"THPEncoder output shape:\", out.shape)  # ожидаем [B, L, D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:20.910934Z",
     "iopub.status.busy": "2025-06-24T22:14:20.910682Z",
     "iopub.status.idle": "2025-06-24T22:14:21.027524Z",
     "shell.execute_reply": "2025-06-24T22:14:21.026876Z",
     "shell.execute_reply.started": "2025-06-24T22:14:20.910913Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated user embeddings: torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "B = 32\n",
    "batch_seq_ids   = seq_ids[:B].to(device)    # [B, L]\n",
    "batch_seq_times = seq_times[:B].to(device)  # [B, L]\n",
    "batch_seq_mask  = seq_mask[:B].to(device)   # [B, L]\n",
    "\n",
    "# data.user_idx = data['user'].node_id[:B]\n",
    "batch_users = data.user_idx[:B].to(device)\n",
    "model.to(device)\n",
    "data.to(device)\n",
    "\n",
    "updated_user_emb = model(\n",
    "    data=data,\n",
    "    seq_ids=batch_seq_ids,\n",
    "    seq_times=batch_seq_times,\n",
    "    seq_mask=batch_seq_mask,\n",
    "    batch_users=batch_users\n",
    ")  # [B, d_model]\n",
    "\n",
    "print(\"Updated user embeddings:\", updated_user_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:21.593826Z",
     "iopub.status.busy": "2025-06-24T22:14:21.593570Z",
     "iopub.status.idle": "2025-06-24T22:14:21.616348Z",
     "shell.execute_reply": "2025-06-24T22:14:21.615801Z",
     "shell.execute_reply.started": "2025-06-24T22:14:21.593808Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25456, 1, 25456)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.item_id.nunique(), train.item_id.min(), train.item_id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:23.182877Z",
     "iopub.status.busy": "2025-06-24T22:14:23.182238Z",
     "iopub.status.idle": "2025-06-24T22:14:23.187925Z",
     "shell.execute_reply": "2025-06-24T22:14:23.187339Z",
     "shell.execute_reply.started": "2025-06-24T22:14:23.182853Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (gnn): HeteroGNN(\n",
       "    (user_emb): Embedding(18892, 64)\n",
       "    (item_emb): Embedding(25458, 64, padding_idx=0)\n",
       "    (fb_emb): ModuleDict(\n",
       "      (implicit_negative): Embedding(18892, 64)\n",
       "      (explicit_positive): Embedding(18892, 64)\n",
       "      (implicit_positive): Embedding(18892, 64)\n",
       "      (expliсit_negative): Embedding(18892, 64)\n",
       "    )\n",
       "    (norm1): ModuleDict(\n",
       "      (user): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (item): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_negative): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (explicit_positive): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_positive): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (expliсit_negative): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (norm2): ModuleDict(\n",
       "      (user): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (item): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_negative): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (explicit_positive): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_positive): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (expliсit_negative): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (conv1): HeteroConv(num_relations=13)\n",
       "    (conv2): HeteroConv(num_relations=13)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (thp): THPEncoder(\n",
       "    (pos_emb): Embedding(101, 64)\n",
       "    (time_emb): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (heads): ModuleList(\n",
       "      (0-3): 4 x _THPHead(\n",
       "        (linear_v): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (input_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ffn): Sequential(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=64, out_features=256, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (4): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (final_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:24.797438Z",
     "iopub.status.busy": "2025-06-24T22:14:24.796815Z",
     "iopub.status.idle": "2025-06-24T22:14:25.326036Z",
     "shell.execute_reply": "2025-06-24T22:14:25.325447Z",
     "shell.execute_reply.started": "2025-06-24T22:14:24.797414Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = test[['user_id', 'item_id']]\n",
    "interactions = test_df.rename(columns={\n",
    "    'user_id': Columns.User,\n",
    "    'item_id': Columns.Item,\n",
    "})\n",
    "\n",
    "viewed_items = train.groupby(\"user_id\")[\"item_id\"].agg(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:25.788172Z",
     "iopub.status.busy": "2025-06-24T22:14:25.787496Z",
     "iopub.status.idle": "2025-06-24T22:14:25.792731Z",
     "shell.execute_reply": "2025-06-24T22:14:25.792061Z",
     "shell.execute_reply.started": "2025-06-24T22:14:25.788151Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLS_ID == model.gnn.item_emb.weight.shape[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:27.444622Z",
     "iopub.status.busy": "2025-06-24T22:14:27.444347Z",
     "iopub.status.idle": "2025-06-24T22:14:27.459837Z",
     "shell.execute_reply": "2025-06-24T22:14:27.458901Z",
     "shell.execute_reply.started": "2025-06-24T22:14:27.444601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, train_data, seq_train_data,\n",
    "             test_batch_size, top_k,\n",
    "             viewed_items, interactions,\n",
    "             device, test_step):\n",
    "    \"\"\"\n",
    "    Оцениваем модель по всем пользователям:\n",
    "    - строим топ-K рекомендации\n",
    "    - фильтруем уже просмотренные\n",
    "    - считаем recall@K, precision@K, map@K\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    seq_ids, event_type, seq_times, seq_mask = seq_train_data\n",
    "    num_users = seq_ids.size(0)\n",
    "    test_top_k = top_k * 150\n",
    "\n",
    "    item_emb = model.gnn.item_emb.weight\n",
    "    num_items = item_emb.shape[0]\n",
    "    item_emb_t = item_emb.t().detach()\n",
    "    del item_emb\n",
    "    gc.collect()\n",
    "\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_users, test_batch_size):\n",
    "            end = min(i + test_batch_size, num_users)\n",
    "            batch_users = torch.arange(i, end).to(device)\n",
    "            s_ids   = seq_ids[i:end].to(device)\n",
    "            s_times = seq_times[i:end].to(device)\n",
    "            s_mask  = seq_mask[i:end].to(device)\n",
    "            user_e = model(\n",
    "                data=train_data.to(device),\n",
    "                seq_ids=s_ids,\n",
    "                seq_times=s_times,\n",
    "                seq_mask=s_mask,\n",
    "                batch_users=batch_users\n",
    "            )\n",
    "            rating = torch.mm(user_e.detach(), item_emb_t)\n",
    "            _, topk = torch.topk(rating, k=test_top_k, dim=1)\n",
    "            all_scores.append(topk)\n",
    "\n",
    "            del user_e, rating\n",
    "            gc.collect()\n",
    "    all_scores = torch.cat(all_scores, dim=0).cpu().numpy()\n",
    "\n",
    "    users_list, items, ranks = [], [], []\n",
    "    for u in range(num_users):\n",
    "        seen = viewed_items.get(u, set())\n",
    "        recs = all_scores[u]\n",
    "        mask = (\n",
    "            (~np.isin(recs, list(seen)))   \n",
    "            & (recs != 0)                  \n",
    "            & (recs != num_items - 1)     \n",
    "            )\n",
    "        filtered = recs[mask][:top_k]\n",
    "        for rank, it in enumerate(filtered, 1):\n",
    "            users_list.append(u)\n",
    "            items.append(int(it))\n",
    "            ranks.append(rank)\n",
    "    reco_df = pd.DataFrame({\n",
    "        'user_id': users_list,\n",
    "        'item_id': items,\n",
    "        'rank': ranks\n",
    "    })\n",
    "\n",
    "    metrics = {\n",
    "        f'map@{top_k}': MAP(k=top_k),\n",
    "        f'precision@{top_k}': Precision(k=top_k),\n",
    "        f'recall@{top_k}': Recall(k=top_k),\n",
    "        f'ndcg@{top_k}': NDCG(k=top_k)\n",
    "    }\n",
    "    results = calc_metrics(metrics=metrics,\n",
    "                           reco=reco_df,\n",
    "                           interactions=interactions)\n",
    "    print(f\"Step {test_step} — Test metrics:\")\n",
    "    for name, val in results.items():\n",
    "        print(f\"  {name}: {val:.9f}\")\n",
    "        experiment.log_metric(f\"Test {name} vs step\", val, step=test_step)\n",
    "    del all_scores\n",
    "    gc.collect()\n",
    "\n",
    "    model.to(device)\n",
    "    train_data.to(device)\n",
    "    model.train()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:29.584106Z",
     "iopub.status.busy": "2025-06-24T22:14:29.583225Z",
     "iopub.status.idle": "2025-06-24T22:14:29.599090Z",
     "shell.execute_reply": "2025-06-24T22:14:29.598330Z",
     "shell.execute_reply.started": "2025-06-24T22:14:29.584039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model: HeteroGNN,\n",
    "                train_data: HeteroData,\n",
    "                seq_train_data: tuple,\n",
    "                edge_type: tuple,\n",
    "                num_epochs: int = 10,\n",
    "                lr: float = 1e-3,\n",
    "                batch_size: int = 1024,\n",
    "                device: str = None,\n",
    "                print_every: int = 100,\n",
    "                test_every: int = 500,\n",
    "                top_k: int = 10,\n",
    "                test_batch_size=2048,\n",
    "                scheduler_step_size: int = 1,\n",
    "                scheduler_gamma: float = 0.9) -> Model:\n",
    "    seq_ids, event_type, seq_times, seq_mask = seq_train_data\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    train_data = train_data.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma)\n",
    "\n",
    "    if isinstance(edge_type, list):\n",
    "        src_list, dst_list = [], []\n",
    "        for et in edge_type:\n",
    "            s, d = train_data[et].edge_index\n",
    "            src_list.append(s)\n",
    "            dst_list.append(d)\n",
    "        src = torch.cat(src_list, dim=0)\n",
    "        dst = torch.cat(dst_list, dim=0)\n",
    "    else:\n",
    "        src, dst = train_data[edge_type].edge_index\n",
    "    \n",
    "    num_train = src.size(0)\n",
    "    test_top_k = top_k * 150\n",
    "    total_steps = 0\n",
    "    \n",
    "    print(f\"Num of training examples: {num_train}\")\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        perm = torch.randperm(num_train, device=device)\n",
    "        total_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        running_steps = 0\n",
    "        step = 0\n",
    "\n",
    "        for i in range(0, num_train, batch_size):\n",
    "            idx = perm[i:i + batch_size]\n",
    "            users = dst[idx]\n",
    "            cpu_users = users.to('cpu')\n",
    "\n",
    "            seq_ids_batch = seq_ids[cpu_users].to(device)\n",
    "            seq_times_batch = seq_times[cpu_users].to(device)\n",
    "            seq_mask_batch = seq_mask[cpu_users].to(device)\n",
    "            \n",
    "            pos_items = src[idx]\n",
    "            neg_items = torch.randint(1, model.gnn.item_emb.num_embeddings - 1,\n",
    "                                      size=pos_items.size(), device=device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            user_embs = model(data=train_data, \n",
    "                              seq_ids=seq_ids_batch,\n",
    "                              seq_times=seq_times_batch,\n",
    "                              seq_mask=seq_mask_batch,\n",
    "                              batch_users=users)\n",
    "            \n",
    "            pos_emb = model.gnn.item_emb(pos_items)\n",
    "            neg_emb = model.gnn.item_emb(neg_items)\n",
    "            pos_score = (user_embs * pos_emb).sum(dim=1)\n",
    "            neg_score = (user_embs * neg_emb).sum(dim=1)\n",
    "            diff = pos_score - neg_score\n",
    "            diff = torch.clamp(diff, -10.0, 10.0)\n",
    "            loss = -torch.log(torch.sigmoid(diff) + 1e-15).mean()\n",
    "            \n",
    "            nan_mask = torch.isnan(diff)            \n",
    "            if nan_mask.any():\n",
    "                idxs = torch.nonzero(nan_mask).squeeze()\n",
    "                print(f\"!!! FOUND {nan_mask.sum().item()} NaN(s) in diff at positions: {idxs.tolist()}\")\n",
    "\n",
    "            # with torch.autograd.detect_anomaly():\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            running_loss += loss.item()\n",
    "            running_steps += 1\n",
    "            step += 1\n",
    "\n",
    "            experiment.log_metric('Train Loss vs step', loss.item(), step=total_steps)\n",
    "            \n",
    "            if step % print_every == 0 or step == 1:\n",
    "                avg_loss = running_loss / running_steps\n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                d = diff.detach().cpu()\n",
    "                print(f\"Epoch {epoch}, Step {step}, LR: {current_lr:.6f}, Current Loss: {loss.item():.4f}, Avg Loss: {avg_loss:.4f}\")\n",
    "                print(f\"Diff stats — min: {d.min():.4f}, max: {d.max():.4f}, mean: {d.mean():.4f}, std: {d.std():.4f}\")\n",
    "                print()\n",
    "\n",
    "                experiment.log_metric('Diff stats (mean) vs step', d.mean(), step=total_steps)\n",
    "                experiment.log_metric('Diff stats (std) vs step', d.std(), step=total_steps)\n",
    "\n",
    "            del user_embs, pos_emb, neg_emb, pos_score, neg_score,\\\n",
    "            seq_ids_batch, seq_times_batch, seq_mask_batch\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            scheduler.step()\n",
    "            \n",
    "            if step % test_every == 0 or step == 1:\n",
    "                evaluate(model, train_data, seq_train_data,\n",
    "                         test_batch_size, top_k,\n",
    "                         viewed_items, interactions,\n",
    "                         device, test_step=total_steps)\n",
    "            total_steps += 1\n",
    "        epoch_loss = total_loss / num_train\n",
    "        experiment.log_metric(f'Train Loss vs epoch', epoch_loss, epoch=epoch)\n",
    "        print(f\"Epoch {epoch} completed, Train Loss: {epoch_loss:.6f}\")\n",
    "        print()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:31.645708Z",
     "iopub.status.busy": "2025-06-24T22:14:31.645033Z",
     "iopub.status.idle": "2025-06-24T22:14:31.818610Z",
     "shell.execute_reply": "2025-06-24T22:14:31.818008Z",
     "shell.execute_reply.started": "2025-06-24T22:14:31.645683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "experiment.log_parameters(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:32.327839Z",
     "iopub.status.busy": "2025-06-24T22:14:32.327085Z",
     "iopub.status.idle": "2025-06-24T22:14:32.331655Z",
     "shell.execute_reply": "2025-06-24T22:14:32.330781Z",
     "shell.execute_reply.started": "2025-06-24T22:14:32.327810Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:14:33.768483Z",
     "iopub.status.busy": "2025-06-24T22:14:33.768204Z",
     "iopub.status.idle": "2025-06-25T02:27:41.207309Z",
     "shell.execute_reply": "2025-06-25T02:27:41.206047Z",
     "shell.execute_reply.started": "2025-06-24T22:14:33.768463Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training examples: 789805\n",
      "Epoch 1, Step 1, LR: 0.001000, Current Loss: 3.7312, Avg Loss: 3.7312\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 0.0042, std: 8.0775\n",
      "\n",
      "Step 0 — Test metrics:\n",
      "  precision@10: 0.000508721\n",
      "  recall@10: 0.000510923\n",
      "  ndcg@10: 0.000502022\n",
      "  map@10: 0.000144033\n",
      "Epoch 1, Step 20, LR: 0.001000, Current Loss: 3.0158, Avg Loss: 3.4238\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: -0.0352, std: 6.7506\n",
      "\n",
      "Epoch 1, Step 40, LR: 0.001000, Current Loss: 1.9504, Avg Loss: 2.8849\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: -0.0518, std: 4.4267\n",
      "\n",
      "Step 49 — Test metrics:\n",
      "  precision@10: 0.000336945\n",
      "  recall@10: 0.000337679\n",
      "  ndcg@10: 0.000314029\n",
      "  map@10: 0.000085259\n",
      "Epoch 1, Step 60, LR: 0.001000, Current Loss: 1.3061, Avg Loss: 2.4324\n",
      "Diff stats — min: -10.0000, max: 9.6958, mean: 0.0591, std: 2.8453\n",
      "\n",
      "Epoch 1, Step 80, LR: 0.001000, Current Loss: 1.0685, Avg Loss: 2.1215\n",
      "Diff stats — min: -6.9760, max: 7.6592, mean: 0.0973, std: 2.1675\n",
      "\n",
      "Epoch 1, Step 100, LR: 0.001000, Current Loss: 0.9600, Avg Loss: 1.9040\n",
      "Diff stats — min: -5.6974, max: 6.2222, mean: 0.0632, std: 1.7458\n",
      "\n",
      "Step 99 — Test metrics:\n",
      "  precision@10: 0.000416226\n",
      "  recall@10: 0.000416960\n",
      "  ndcg@10: 0.000413216\n",
      "  map@10: 0.000120147\n",
      "Epoch 1, Step 120, LR: 0.001000, Current Loss: 0.9197, Avg Loss: 1.7444\n",
      "Diff stats — min: -6.4402, max: 6.4413, mean: 0.0475, std: 1.5736\n",
      "\n",
      "Epoch 1, Step 140, LR: 0.001000, Current Loss: 0.8622, Avg Loss: 1.6224\n",
      "Diff stats — min: -5.7691, max: 6.3816, mean: 0.0732, std: 1.4045\n",
      "\n",
      "Step 149 — Test metrics:\n",
      "  precision@10: 0.000376586\n",
      "  recall@10: 0.000376586\n",
      "  ndcg@10: 0.000392842\n",
      "  map@10: 0.000118961\n",
      "Epoch 1, Step 160, LR: 0.000980, Current Loss: 0.8293, Avg Loss: 1.5260\n",
      "Diff stats — min: -5.0089, max: 5.0258, mean: 0.0687, std: 1.2591\n",
      "\n",
      "Epoch 1, Step 180, LR: 0.000980, Current Loss: 0.8229, Avg Loss: 1.4479\n",
      "Diff stats — min: -4.7919, max: 3.8846, mean: 0.0388, std: 1.1699\n",
      "\n",
      "Epoch 1 completed, Train Loss: 0.000343\n",
      "\n",
      "Epoch 2, Step 1, LR: 0.000980, Current Loss: 0.7857, Avg Loss: 0.7857\n",
      "Diff stats — min: -4.1977, max: 4.3531, mean: 0.0753, std: 1.0818\n",
      "\n",
      "Step 193 — Test metrics:\n",
      "  precision@10: 0.000376586\n",
      "  recall@10: 0.000376586\n",
      "  ndcg@10: 0.000377386\n",
      "  map@10: 0.000111217\n",
      "Epoch 2, Step 20, LR: 0.000980, Current Loss: 0.7812, Avg Loss: 0.7798\n",
      "Diff stats — min: -4.1382, max: 4.3750, mean: 0.0551, std: 1.0154\n",
      "\n",
      "Epoch 2, Step 40, LR: 0.000980, Current Loss: 0.7745, Avg Loss: 0.7738\n",
      "Diff stats — min: -3.3216, max: 3.9150, mean: 0.0462, std: 0.9589\n",
      "\n",
      "Step 242 — Test metrics:\n",
      "  precision@10: 0.000422833\n",
      "  recall@10: 0.000422833\n",
      "  ndcg@10: 0.000434089\n",
      "  map@10: 0.000130392\n",
      "Epoch 2, Step 60, LR: 0.000980, Current Loss: 0.7476, Avg Loss: 0.7683\n",
      "Diff stats — min: -3.3029, max: 3.3736, mean: 0.0814, std: 0.9091\n",
      "\n",
      "Epoch 2, Step 80, LR: 0.000980, Current Loss: 0.7494, Avg Loss: 0.7628\n",
      "Diff stats — min: -2.9293, max: 3.5178, mean: 0.0648, std: 0.8752\n",
      "\n",
      "Epoch 2, Step 100, LR: 0.000980, Current Loss: 0.7320, Avg Loss: 0.7576\n",
      "Diff stats — min: -2.8905, max: 3.2122, mean: 0.0757, std: 0.8104\n",
      "\n",
      "Step 292 — Test metrics:\n",
      "  precision@10: 0.000495507\n",
      "  recall@10: 0.000495507\n",
      "  ndcg@10: 0.000522083\n",
      "  map@10: 0.000159296\n",
      "Epoch 2, Step 120, LR: 0.000960, Current Loss: 0.7276, Avg Loss: 0.7529\n",
      "Diff stats — min: -3.2480, max: 3.2880, mean: 0.0808, std: 0.7990\n",
      "\n",
      "Epoch 2, Step 140, LR: 0.000960, Current Loss: 0.7238, Avg Loss: 0.7492\n",
      "Diff stats — min: -2.7154, max: 4.0160, mean: 0.0875, std: 0.7974\n",
      "\n",
      "Step 342 — Test metrics:\n",
      "  precision@10: 0.000475687\n",
      "  recall@10: 0.000475687\n",
      "  ndcg@10: 0.000516238\n",
      "  map@10: 0.000161978\n",
      "Epoch 2, Step 160, LR: 0.000960, Current Loss: 0.7170, Avg Loss: 0.7456\n",
      "Diff stats — min: -2.7832, max: 3.3645, mean: 0.0892, std: 0.7609\n",
      "\n",
      "Epoch 2, Step 180, LR: 0.000960, Current Loss: 0.7086, Avg Loss: 0.7419\n",
      "Diff stats — min: -2.9509, max: 3.5472, mean: 0.0974, std: 0.7328\n",
      "\n",
      "Epoch 2 completed, Train Loss: 0.000181\n",
      "\n",
      "Epoch 3, Step 1, LR: 0.000960, Current Loss: 0.7035, Avg Loss: 0.7035\n",
      "Diff stats — min: -2.4388, max: 3.3633, mean: 0.1018, std: 0.7141\n",
      "\n",
      "Step 386 — Test metrics:\n",
      "  precision@10: 0.000568182\n",
      "  recall@10: 0.000568182\n",
      "  ndcg@10: 0.000628679\n",
      "  map@10: 0.000202204\n",
      "Epoch 3, Step 20, LR: 0.000960, Current Loss: 0.6896, Avg Loss: 0.7002\n",
      "Diff stats — min: -3.0236, max: 3.0584, mean: 0.1328, std: 0.7197\n",
      "\n",
      "Epoch 3, Step 40, LR: 0.000960, Current Loss: 0.6998, Avg Loss: 0.6989\n",
      "Diff stats — min: -3.0951, max: 3.1910, mean: 0.1060, std: 0.7044\n",
      "\n",
      "Step 435 — Test metrics:\n",
      "  precision@10: 0.000687104\n",
      "  recall@10: 0.000687104\n",
      "  ndcg@10: 0.000758530\n",
      "  map@10: 0.000243090\n",
      "Epoch 3, Step 60, LR: 0.000960, Current Loss: 0.6820, Avg Loss: 0.6964\n",
      "Diff stats — min: -2.5196, max: 2.8813, mean: 0.1396, std: 0.6918\n",
      "\n",
      "Epoch 3, Step 80, LR: 0.000941, Current Loss: 0.6923, Avg Loss: 0.6946\n",
      "Diff stats — min: -2.4252, max: 2.6506, mean: 0.1155, std: 0.6846\n",
      "\n",
      "Epoch 3, Step 100, LR: 0.000941, Current Loss: 0.6796, Avg Loss: 0.6929\n",
      "Diff stats — min: -2.4294, max: 3.5118, mean: 0.1432, std: 0.6870\n",
      "\n",
      "Step 485 — Test metrics:\n",
      "  precision@10: 0.000706924\n",
      "  recall@10: 0.000706924\n",
      "  ndcg@10: 0.000715950\n",
      "  map@10: 0.000213852\n",
      "Epoch 3, Step 120, LR: 0.000941, Current Loss: 0.6892, Avg Loss: 0.6914\n",
      "Diff stats — min: -2.3025, max: 3.0488, mean: 0.1217, std: 0.6835\n",
      "\n",
      "Epoch 3, Step 140, LR: 0.000941, Current Loss: 0.6747, Avg Loss: 0.6895\n",
      "Diff stats — min: -2.5001, max: 3.0169, mean: 0.1559, std: 0.6941\n",
      "\n",
      "Step 535 — Test metrics:\n",
      "  precision@10: 0.000812632\n",
      "  recall@10: 0.000812632\n",
      "  ndcg@10: 0.000803791\n",
      "  map@10: 0.000234952\n",
      "Epoch 3, Step 160, LR: 0.000941, Current Loss: 0.6742, Avg Loss: 0.6878\n",
      "Diff stats — min: -2.6615, max: 2.8778, mean: 0.1582, std: 0.6977\n",
      "\n",
      "Epoch 3, Step 180, LR: 0.000941, Current Loss: 0.6671, Avg Loss: 0.6861\n",
      "Diff stats — min: -3.2708, max: 3.3677, mean: 0.1850, std: 0.7301\n",
      "\n",
      "Epoch 3 completed, Train Loss: 0.000167\n",
      "\n",
      "Epoch 4, Step 1, LR: 0.000941, Current Loss: 0.6638, Avg Loss: 0.6638\n",
      "Diff stats — min: -2.1192, max: 2.4450, mean: 0.1780, std: 0.6891\n",
      "\n",
      "Step 579 — Test metrics:\n",
      "  precision@10: 0.000918340\n",
      "  recall@10: 0.000919074\n",
      "  ndcg@10: 0.000884924\n",
      "  map@10: 0.000250451\n",
      "Epoch 4, Step 20, LR: 0.000941, Current Loss: 0.6567, Avg Loss: 0.6636\n",
      "Diff stats — min: -2.3561, max: 4.4088, mean: 0.2049, std: 0.7231\n",
      "\n",
      "Epoch 4, Step 40, LR: 0.000922, Current Loss: 0.6675, Avg Loss: 0.6612\n",
      "Diff stats — min: -2.7355, max: 3.6828, mean: 0.1880, std: 0.7421\n",
      "\n",
      "Step 628 — Test metrics:\n",
      "  precision@10: 0.001156184\n",
      "  recall@10: 0.001157652\n",
      "  ndcg@10: 0.001150745\n",
      "  map@10: 0.000334558\n",
      "Epoch 4, Step 60, LR: 0.000922, Current Loss: 0.6581, Avg Loss: 0.6587\n",
      "Diff stats — min: -2.6850, max: 3.4042, mean: 0.2214, std: 0.7766\n",
      "\n",
      "Epoch 4, Step 80, LR: 0.000922, Current Loss: 0.6514, Avg Loss: 0.6570\n",
      "Diff stats — min: -2.8660, max: 3.1628, mean: 0.2272, std: 0.7514\n",
      "\n",
      "Epoch 4, Step 100, LR: 0.000922, Current Loss: 0.6411, Avg Loss: 0.6549\n",
      "Diff stats — min: -2.8121, max: 3.5090, mean: 0.2651, std: 0.7901\n",
      "\n",
      "Step 678 — Test metrics:\n",
      "  precision@10: 0.001585624\n",
      "  recall@10: 0.001586358\n",
      "  ndcg@10: 0.001583637\n",
      "  map@10: 0.000464256\n",
      "Epoch 4, Step 120, LR: 0.000922, Current Loss: 0.6460, Avg Loss: 0.6528\n",
      "Diff stats — min: -3.1870, max: 4.0328, mean: 0.2622, std: 0.8134\n",
      "\n",
      "Epoch 4, Step 140, LR: 0.000922, Current Loss: 0.6351, Avg Loss: 0.6509\n",
      "Diff stats — min: -2.6246, max: 3.7153, mean: 0.2874, std: 0.8145\n",
      "\n",
      "Step 728 — Test metrics:\n",
      "  precision@10: 0.001955603\n",
      "  recall@10: 0.001956337\n",
      "  ndcg@10: 0.002036460\n",
      "  map@10: 0.000616694\n",
      "Epoch 4, Step 160, LR: 0.000922, Current Loss: 0.6322, Avg Loss: 0.6487\n",
      "Diff stats — min: -2.5159, max: 3.6326, mean: 0.3003, std: 0.8285\n",
      "\n",
      "Epoch 4, Step 180, LR: 0.000904, Current Loss: 0.6237, Avg Loss: 0.6464\n",
      "Diff stats — min: -3.3115, max: 3.9905, mean: 0.3407, std: 0.8810\n",
      "\n",
      "Epoch 4 completed, Train Loss: 0.000158\n",
      "\n",
      "Epoch 5, Step 1, LR: 0.000904, Current Loss: 0.6202, Avg Loss: 0.6202\n",
      "Diff stats — min: -2.4872, max: 4.6320, mean: 0.3458, std: 0.8723\n",
      "\n",
      "Step 772 — Test metrics:\n",
      "  precision@10: 0.002431290\n",
      "  recall@10: 0.002432024\n",
      "  ndcg@10: 0.002547131\n",
      "  map@10: 0.000783052\n",
      "Epoch 5, Step 20, LR: 0.000904, Current Loss: 0.6141, Avg Loss: 0.6168\n",
      "Diff stats — min: -2.7862, max: 4.1917, mean: 0.3801, std: 0.9185\n",
      "\n",
      "Epoch 5, Step 40, LR: 0.000904, Current Loss: 0.6114, Avg Loss: 0.6145\n",
      "Diff stats — min: -2.9463, max: 4.2218, mean: 0.3983, std: 0.9437\n",
      "\n",
      "Step 821 — Test metrics:\n",
      "  precision@10: 0.002827696\n",
      "  recall@10: 0.002828430\n",
      "  ndcg@10: 0.003044376\n",
      "  map@10: 0.000958635\n",
      "Epoch 5, Step 60, LR: 0.000904, Current Loss: 0.5955, Avg Loss: 0.6114\n",
      "Diff stats — min: -3.0900, max: 4.1983, mean: 0.4302, std: 0.9330\n",
      "\n",
      "Epoch 5, Step 80, LR: 0.000904, Current Loss: 0.5925, Avg Loss: 0.6085\n",
      "Diff stats — min: -3.2964, max: 4.9012, mean: 0.4680, std: 0.9986\n",
      "\n",
      "Epoch 5, Step 100, LR: 0.000904, Current Loss: 0.5936, Avg Loss: 0.6052\n",
      "Diff stats — min: -3.0167, max: 4.4773, mean: 0.4808, std: 1.0309\n",
      "\n",
      "Step 871 — Test metrics:\n",
      "  precision@10: 0.003587474\n",
      "  recall@10: 0.003588942\n",
      "  ndcg@10: 0.004041464\n",
      "  map@10: 0.001323717\n",
      "Epoch 5, Step 120, LR: 0.000904, Current Loss: 0.5886, Avg Loss: 0.6023\n",
      "Diff stats — min: -2.8225, max: 5.1697, mean: 0.5081, std: 1.0560\n",
      "\n",
      "Epoch 5, Step 140, LR: 0.000886, Current Loss: 0.5731, Avg Loss: 0.5994\n",
      "Diff stats — min: -2.7395, max: 5.6865, mean: 0.5481, std: 1.0641\n",
      "\n",
      "Step 921 — Test metrics:\n",
      "  precision@10: 0.003752643\n",
      "  recall@10: 0.003753377\n",
      "  ndcg@10: 0.004167065\n",
      "  map@10: 0.001367458\n",
      "Epoch 5, Step 160, LR: 0.000886, Current Loss: 0.5834, Avg Loss: 0.5963\n",
      "Diff stats — min: -3.6715, max: 5.8083, mean: 0.5473, std: 1.1153\n",
      "\n",
      "Epoch 5, Step 180, LR: 0.000886, Current Loss: 0.5676, Avg Loss: 0.5933\n",
      "Diff stats — min: -4.0426, max: 5.2445, mean: 0.5972, std: 1.1249\n",
      "\n",
      "Epoch 5 completed, Train Loss: 0.000144\n",
      "\n",
      "Epoch 6, Step 1, LR: 0.000886, Current Loss: 0.5683, Avg Loss: 0.5683\n",
      "Diff stats — min: -3.6891, max: 6.5972, mean: 0.6361, std: 1.2068\n",
      "\n",
      "Step 965 — Test metrics:\n",
      "  precision@10: 0.004413319\n",
      "  recall@10: 0.004414787\n",
      "  ndcg@10: 0.004819983\n",
      "  map@10: 0.001561163\n",
      "Epoch 6, Step 20, LR: 0.000886, Current Loss: 0.5497, Avg Loss: 0.5560\n",
      "Diff stats — min: -4.2961, max: 5.7600, mean: 0.6808, std: 1.1953\n",
      "\n",
      "Epoch 6, Step 40, LR: 0.000886, Current Loss: 0.5517, Avg Loss: 0.5539\n",
      "Diff stats — min: -4.2642, max: 6.6779, mean: 0.6811, std: 1.2095\n",
      "\n",
      "Step 1014 — Test metrics:\n",
      "  precision@10: 0.004869186\n",
      "  recall@10: 0.004870654\n",
      "  ndcg@10: 0.005312078\n",
      "  map@10: 0.001724961\n",
      "Epoch 6, Step 60, LR: 0.000886, Current Loss: 0.5329, Avg Loss: 0.5495\n",
      "Diff stats — min: -3.8521, max: 7.2218, mean: 0.7781, std: 1.2845\n",
      "\n",
      "Epoch 6, Step 80, LR: 0.000886, Current Loss: 0.5348, Avg Loss: 0.5465\n",
      "Diff stats — min: -4.0756, max: 8.0563, mean: 0.7812, std: 1.3068\n",
      "\n",
      "Epoch 6, Step 100, LR: 0.000868, Current Loss: 0.5211, Avg Loss: 0.5434\n",
      "Diff stats — min: -4.1988, max: 7.3975, mean: 0.8550, std: 1.3674\n",
      "\n",
      "Step 1064 — Test metrics:\n",
      "  precision@10: 0.005305233\n",
      "  recall@10: 0.005307435\n",
      "  ndcg@10: 0.005789660\n",
      "  map@10: 0.001895958\n",
      "Epoch 6, Step 120, LR: 0.000868, Current Loss: 0.5333, Avg Loss: 0.5405\n",
      "Diff stats — min: -3.5108, max: 6.0621, mean: 0.8158, std: 1.3580\n",
      "\n",
      "Epoch 6, Step 140, LR: 0.000868, Current Loss: 0.5149, Avg Loss: 0.5381\n",
      "Diff stats — min: -3.8807, max: 7.8815, mean: 0.9055, std: 1.4148\n",
      "\n",
      "Step 1114 — Test metrics:\n",
      "  precision@10: 0.005972516\n",
      "  recall@10: 0.005973984\n",
      "  ndcg@10: 0.006280597\n",
      "  map@10: 0.001997202\n",
      "Epoch 6, Step 160, LR: 0.000868, Current Loss: 0.5079, Avg Loss: 0.5353\n",
      "Diff stats — min: -5.4410, max: 7.9534, mean: 0.9301, std: 1.4245\n",
      "\n",
      "Epoch 6, Step 180, LR: 0.000868, Current Loss: 0.5200, Avg Loss: 0.5327\n",
      "Diff stats — min: -5.8380, max: 7.0630, mean: 0.9074, std: 1.4437\n",
      "\n",
      "Epoch 6 completed, Train Loss: 0.000130\n",
      "\n",
      "Epoch 7, Step 1, LR: 0.000868, Current Loss: 0.4837, Avg Loss: 0.4837\n",
      "Diff stats — min: -4.7499, max: 6.8846, mean: 1.0107, std: 1.4393\n",
      "\n",
      "Step 1158 — Test metrics:\n",
      "  precision@10: 0.006448203\n",
      "  recall@10: 0.006451139\n",
      "  ndcg@10: 0.006775709\n",
      "  map@10: 0.002147408\n",
      "Epoch 7, Step 20, LR: 0.000868, Current Loss: 0.5090, Avg Loss: 0.4998\n",
      "Diff stats — min: -4.1860, max: 7.0880, mean: 1.0112, std: 1.5453\n",
      "\n",
      "Epoch 7, Step 40, LR: 0.000868, Current Loss: 0.4971, Avg Loss: 0.4965\n",
      "Diff stats — min: -4.3188, max: 7.8773, mean: 1.0464, std: 1.5524\n",
      "\n",
      "Step 1207 — Test metrics:\n",
      "  precision@10: 0.006989958\n",
      "  recall@10: 0.006994546\n",
      "  ndcg@10: 0.007156411\n",
      "  map@10: 0.002213065\n",
      "Epoch 7, Step 60, LR: 0.000851, Current Loss: 0.5001, Avg Loss: 0.4948\n",
      "Diff stats — min: -3.6143, max: 7.4098, mean: 1.0583, std: 1.5843\n",
      "\n",
      "Epoch 7, Step 80, LR: 0.000851, Current Loss: 0.4870, Avg Loss: 0.4938\n",
      "Diff stats — min: -4.3299, max: 8.1599, mean: 1.0608, std: 1.5391\n",
      "\n",
      "Epoch 7, Step 100, LR: 0.000851, Current Loss: 0.4716, Avg Loss: 0.4917\n",
      "Diff stats — min: -4.4120, max: 7.5311, mean: 1.1666, std: 1.6179\n",
      "\n",
      "Step 1257 — Test metrics:\n",
      "  precision@10: 0.007069239\n",
      "  recall@10: 0.007072909\n",
      "  ndcg@10: 0.007261871\n",
      "  map@10: 0.002263704\n",
      "Epoch 7, Step 120, LR: 0.000851, Current Loss: 0.4775, Avg Loss: 0.4901\n",
      "Diff stats — min: -4.2528, max: 9.2071, mean: 1.1411, std: 1.6135\n",
      "\n",
      "Epoch 7, Step 140, LR: 0.000851, Current Loss: 0.4687, Avg Loss: 0.4881\n",
      "Diff stats — min: -5.1769, max: 9.5842, mean: 1.1774, std: 1.6260\n",
      "\n",
      "Step 1307 — Test metrics:\n",
      "  precision@10: 0.007392970\n",
      "  recall@10: 0.007395907\n",
      "  ndcg@10: 0.007581090\n",
      "  map@10: 0.002363877\n",
      "Epoch 7, Step 160, LR: 0.000851, Current Loss: 0.4694, Avg Loss: 0.4867\n",
      "Diff stats — min: -4.8618, max: 7.7795, mean: 1.1838, std: 1.6373\n",
      "\n",
      "Epoch 7, Step 180, LR: 0.000851, Current Loss: 0.4768, Avg Loss: 0.4851\n",
      "Diff stats — min: -5.3189, max: 8.0108, mean: 1.1944, std: 1.6817\n",
      "\n",
      "Epoch 7 completed, Train Loss: 0.000118\n",
      "\n",
      "Epoch 8, Step 1, LR: 0.000834, Current Loss: 0.4499, Avg Loss: 0.4499\n",
      "Diff stats — min: -4.8904, max: 8.4575, mean: 1.3291, std: 1.7403\n",
      "\n",
      "Step 1351 — Test metrics:\n",
      "  precision@10: 0.007525106\n",
      "  recall@10: 0.007527308\n",
      "  ndcg@10: 0.007746370\n",
      "  map@10: 0.002434128\n",
      "Epoch 8, Step 20, LR: 0.000834, Current Loss: 0.4554, Avg Loss: 0.4611\n",
      "Diff stats — min: -4.3298, max: 8.3830, mean: 1.2942, std: 1.7178\n",
      "\n",
      "Epoch 8, Step 40, LR: 0.000834, Current Loss: 0.4402, Avg Loss: 0.4591\n",
      "Diff stats — min: -3.6455, max: 8.9993, mean: 1.3321, std: 1.7036\n",
      "\n",
      "Step 1400 — Test metrics:\n",
      "  precision@10: 0.007498679\n",
      "  recall@10: 0.007501615\n",
      "  ndcg@10: 0.007704013\n",
      "  map@10: 0.002429124\n",
      "Epoch 8, Step 60, LR: 0.000834, Current Loss: 0.4650, Avg Loss: 0.4584\n",
      "Diff stats — min: -5.1593, max: 7.5857, mean: 1.2759, std: 1.7346\n",
      "\n",
      "Epoch 8, Step 80, LR: 0.000834, Current Loss: 0.4576, Avg Loss: 0.4572\n",
      "Diff stats — min: -5.0064, max: 8.6327, mean: 1.3112, std: 1.7542\n",
      "\n",
      "Epoch 8, Step 100, LR: 0.000834, Current Loss: 0.4332, Avg Loss: 0.4560\n",
      "Diff stats — min: -3.7744, max: 7.8356, mean: 1.3771, std: 1.7257\n",
      "\n",
      "Step 1450 — Test metrics:\n",
      "  precision@10: 0.007485465\n",
      "  recall@10: 0.007487667\n",
      "  ndcg@10: 0.007782804\n",
      "  map@10: 0.002466051\n",
      "Epoch 8, Step 120, LR: 0.000834, Current Loss: 0.4524, Avg Loss: 0.4550\n",
      "Diff stats — min: -4.7318, max: 8.8989, mean: 1.3430, std: 1.7719\n",
      "\n",
      "Epoch 8, Step 140, LR: 0.000834, Current Loss: 0.4446, Avg Loss: 0.4538\n",
      "Diff stats — min: -4.9681, max: 9.6136, mean: 1.3991, std: 1.8036\n",
      "\n",
      "Step 1500 — Test metrics:\n",
      "  precision@10: 0.007875264\n",
      "  recall@10: 0.007879852\n",
      "  ndcg@10: 0.008193166\n",
      "  map@10: 0.002624664\n",
      "Epoch 8, Step 160, LR: 0.000817, Current Loss: 0.4364, Avg Loss: 0.4521\n",
      "Diff stats — min: -5.6664, max: 8.8934, mean: 1.4390, std: 1.8241\n",
      "\n",
      "Epoch 8, Step 180, LR: 0.000817, Current Loss: 0.4358, Avg Loss: 0.4505\n",
      "Diff stats — min: -3.8322, max: 9.6355, mean: 1.4310, std: 1.8120\n",
      "\n",
      "Epoch 8 completed, Train Loss: 0.000110\n",
      "\n",
      "Epoch 9, Step 1, LR: 0.000817, Current Loss: 0.4446, Avg Loss: 0.4446\n",
      "Diff stats — min: -4.2821, max: 10.0000, mean: 1.4292, std: 1.8342\n",
      "\n",
      "Step 1544 — Test metrics:\n",
      "  precision@10: 0.007584567\n",
      "  recall@10: 0.007586769\n",
      "  ndcg@10: 0.007817701\n",
      "  map@10: 0.002485610\n",
      "Epoch 9, Step 20, LR: 0.000817, Current Loss: 0.4203, Avg Loss: 0.4335\n",
      "Diff stats — min: -4.1587, max: 10.0000, mean: 1.5079, std: 1.8295\n",
      "\n",
      "Epoch 9, Step 40, LR: 0.000817, Current Loss: 0.4337, Avg Loss: 0.4334\n",
      "Diff stats — min: -5.3352, max: 10.0000, mean: 1.5078, std: 1.8903\n",
      "\n",
      "Step 1593 — Test metrics:\n",
      "  precision@10: 0.008258457\n",
      "  recall@10: 0.008261393\n",
      "  ndcg@10: 0.008580450\n",
      "  map@10: 0.002741520\n",
      "Epoch 9, Step 60, LR: 0.000817, Current Loss: 0.4333, Avg Loss: 0.4317\n",
      "Diff stats — min: -5.1512, max: 9.6271, mean: 1.5471, std: 1.9390\n",
      "\n",
      "Epoch 9, Step 80, LR: 0.000817, Current Loss: 0.4353, Avg Loss: 0.4312\n",
      "Diff stats — min: -5.6859, max: 9.7392, mean: 1.5199, std: 1.8956\n",
      "\n",
      "Epoch 9, Step 100, LR: 0.000817, Current Loss: 0.4269, Avg Loss: 0.4300\n",
      "Diff stats — min: -5.3613, max: 8.6503, mean: 1.5790, std: 1.9516\n",
      "\n",
      "Step 1643 — Test metrics:\n",
      "  precision@10: 0.008357558\n",
      "  recall@10: 0.008359760\n",
      "  ndcg@10: 0.008580288\n",
      "  map@10: 0.002696447\n",
      "Epoch 9, Step 120, LR: 0.000801, Current Loss: 0.4256, Avg Loss: 0.4292\n",
      "Diff stats — min: -4.8744, max: 8.6298, mean: 1.5424, std: 1.8875\n",
      "\n",
      "Epoch 9, Step 140, LR: 0.000801, Current Loss: 0.4183, Avg Loss: 0.4282\n",
      "Diff stats — min: -7.0044, max: 10.0000, mean: 1.5895, std: 1.9273\n",
      "\n",
      "Step 1693 — Test metrics:\n",
      "  precision@10: 0.008047040\n",
      "  recall@10: 0.008049977\n",
      "  ndcg@10: 0.008282727\n",
      "  map@10: 0.002632661\n",
      "Epoch 9, Step 160, LR: 0.000801, Current Loss: 0.4105, Avg Loss: 0.4275\n",
      "Diff stats — min: -4.5780, max: 8.9270, mean: 1.5858, std: 1.8875\n",
      "\n",
      "Epoch 9, Step 180, LR: 0.000801, Current Loss: 0.4170, Avg Loss: 0.4261\n",
      "Diff stats — min: -4.1192, max: 9.0199, mean: 1.6207, std: 1.9718\n",
      "\n",
      "Epoch 9 completed, Train Loss: 0.000104\n",
      "\n",
      "Epoch 10, Step 1, LR: 0.000801, Current Loss: 0.4015, Avg Loss: 0.4015\n",
      "Diff stats — min: -5.5004, max: 9.7742, mean: 1.6776, std: 1.9606\n",
      "\n",
      "Step 1737 — Test metrics:\n",
      "  precision@10: 0.008238636\n",
      "  recall@10: 0.008242307\n",
      "  ndcg@10: 0.008314533\n",
      "  map@10: 0.002583877\n",
      "Epoch 10, Step 20, LR: 0.000801, Current Loss: 0.4074, Avg Loss: 0.4115\n",
      "Diff stats — min: -4.2910, max: 9.3845, mean: 1.6754, std: 1.9871\n",
      "\n",
      "Epoch 10, Step 40, LR: 0.000801, Current Loss: 0.4212, Avg Loss: 0.4108\n",
      "Diff stats — min: -6.2375, max: 10.0000, mean: 1.6486, std: 2.0073\n",
      "\n",
      "Step 1786 — Test metrics:\n",
      "  precision@10: 0.008383985\n",
      "  recall@10: 0.008386187\n",
      "  ndcg@10: 0.008542239\n",
      "  map@10: 0.002702490\n",
      "Epoch 10, Step 60, LR: 0.000801, Current Loss: 0.3993, Avg Loss: 0.4115\n",
      "Diff stats — min: -4.8457, max: 10.0000, mean: 1.6918, std: 1.9713\n",
      "\n",
      "Epoch 10, Step 80, LR: 0.000785, Current Loss: 0.4018, Avg Loss: 0.4114\n",
      "Diff stats — min: -5.4153, max: 9.6316, mean: 1.7022, std: 2.0048\n",
      "\n",
      "Epoch 10, Step 100, LR: 0.000785, Current Loss: 0.4097, Avg Loss: 0.4103\n",
      "Diff stats — min: -4.6230, max: 9.5199, mean: 1.7277, std: 2.0369\n",
      "\n",
      "Step 1836 — Test metrics:\n",
      "  precision@10: 0.008258457\n",
      "  recall@10: 0.008260659\n",
      "  ndcg@10: 0.008238715\n",
      "  map@10: 0.002565774\n",
      "Epoch 10, Step 120, LR: 0.000785, Current Loss: 0.3969, Avg Loss: 0.4096\n",
      "Diff stats — min: -5.2123, max: 9.2440, mean: 1.7742, std: 2.0208\n",
      "\n",
      "Epoch 10, Step 140, LR: 0.000785, Current Loss: 0.4073, Avg Loss: 0.4096\n",
      "Diff stats — min: -5.2821, max: 10.0000, mean: 1.6975, std: 1.9985\n",
      "\n",
      "Step 1886 — Test metrics:\n",
      "  precision@10: 0.008542548\n",
      "  recall@10: 0.008544750\n",
      "  ndcg@10: 0.008635942\n",
      "  map@10: 0.002705041\n",
      "Epoch 10, Step 160, LR: 0.000785, Current Loss: 0.4117, Avg Loss: 0.4089\n",
      "Diff stats — min: -5.0271, max: 10.0000, mean: 1.6817, std: 2.0132\n",
      "\n",
      "Epoch 10, Step 180, LR: 0.000785, Current Loss: 0.4140, Avg Loss: 0.4086\n",
      "Diff stats — min: -6.7381, max: 10.0000, mean: 1.6629, std: 2.0052\n",
      "\n",
      "Epoch 10 completed, Train Loss: 0.000100\n",
      "\n",
      "Epoch 11, Step 1, LR: 0.000785, Current Loss: 0.4037, Avg Loss: 0.4037\n",
      "Diff stats — min: -7.1288, max: 9.8097, mean: 1.7347, std: 2.0314\n",
      "\n",
      "Step 1930 — Test metrics:\n",
      "  precision@10: 0.008258457\n",
      "  recall@10: 0.008259925\n",
      "  ndcg@10: 0.008205032\n",
      "  map@10: 0.002543938\n",
      "Epoch 11, Step 20, LR: 0.000785, Current Loss: 0.3946, Avg Loss: 0.3983\n",
      "Diff stats — min: -4.7498, max: 10.0000, mean: 1.7872, std: 2.0372\n",
      "\n",
      "Epoch 11, Step 40, LR: 0.000769, Current Loss: 0.3788, Avg Loss: 0.3963\n",
      "Diff stats — min: -6.1579, max: 9.4702, mean: 1.8269, std: 2.0296\n",
      "\n",
      "Step 1979 — Test metrics:\n",
      "  precision@10: 0.008165962\n",
      "  recall@10: 0.008172018\n",
      "  ndcg@10: 0.008161528\n",
      "  map@10: 0.002536196\n",
      "Epoch 11, Step 60, LR: 0.000769, Current Loss: 0.3944, Avg Loss: 0.3958\n",
      "Diff stats — min: -6.7360, max: 10.0000, mean: 1.7962, std: 2.0587\n",
      "\n",
      "Epoch 11, Step 80, LR: 0.000769, Current Loss: 0.3883, Avg Loss: 0.3958\n",
      "Diff stats — min: -3.9544, max: 10.0000, mean: 1.7979, std: 2.0382\n",
      "\n",
      "Epoch 11, Step 100, LR: 0.000769, Current Loss: 0.3952, Avg Loss: 0.3957\n",
      "Diff stats — min: -4.5018, max: 10.0000, mean: 1.8108, std: 2.0856\n",
      "\n",
      "Step 2029 — Test metrics:\n",
      "  precision@10: 0.008172569\n",
      "  recall@10: 0.008177157\n",
      "  ndcg@10: 0.008081736\n",
      "  map@10: 0.002492727\n",
      "Epoch 11, Step 120, LR: 0.000769, Current Loss: 0.4065, Avg Loss: 0.3957\n",
      "Diff stats — min: -4.5722, max: 10.0000, mean: 1.7414, std: 2.0498\n",
      "\n",
      "Epoch 11, Step 140, LR: 0.000769, Current Loss: 0.3994, Avg Loss: 0.3955\n",
      "Diff stats — min: -5.7372, max: 10.0000, mean: 1.8348, std: 2.1071\n",
      "\n",
      "Step 2079 — Test metrics:\n",
      "  precision@10: 0.008714323\n",
      "  recall@10: 0.008717260\n",
      "  ndcg@10: 0.008610520\n",
      "  map@10: 0.002652663\n",
      "Epoch 11, Step 160, LR: 0.000769, Current Loss: 0.4008, Avg Loss: 0.3955\n",
      "Diff stats — min: -5.0498, max: 10.0000, mean: 1.7613, std: 2.0604\n",
      "\n",
      "Epoch 11, Step 180, LR: 0.000754, Current Loss: 0.3966, Avg Loss: 0.3953\n",
      "Diff stats — min: -6.0437, max: 9.7637, mean: 1.7981, std: 2.0622\n",
      "\n",
      "Epoch 11 completed, Train Loss: 0.000097\n",
      "\n",
      "Epoch 12, Step 1, LR: 0.000754, Current Loss: 0.3811, Avg Loss: 0.3811\n",
      "Diff stats — min: -5.4615, max: 9.5194, mean: 1.8765, std: 2.0826\n",
      "\n",
      "Step 2123 — Test metrics:\n",
      "  precision@10: 0.008007400\n",
      "  recall@10: 0.008010336\n",
      "  ndcg@10: 0.007826601\n",
      "  map@10: 0.002380767\n",
      "Epoch 12, Step 20, LR: 0.000754, Current Loss: 0.3821, Avg Loss: 0.3884\n",
      "Diff stats — min: -5.4084, max: 10.0000, mean: 1.8684, std: 2.0850\n",
      "\n",
      "Epoch 12, Step 40, LR: 0.000754, Current Loss: 0.3901, Avg Loss: 0.3889\n",
      "Diff stats — min: -5.8803, max: 9.9881, mean: 1.8452, std: 2.0757\n",
      "\n",
      "Step 2172 — Test metrics:\n",
      "  precision@10: 0.008450053\n",
      "  recall@10: 0.008452989\n",
      "  ndcg@10: 0.008447180\n",
      "  map@10: 0.002613200\n",
      "Epoch 12, Step 60, LR: 0.000754, Current Loss: 0.3919, Avg Loss: 0.3884\n",
      "Diff stats — min: -5.2892, max: 10.0000, mean: 1.8405, std: 2.0920\n",
      "\n",
      "Epoch 12, Step 80, LR: 0.000754, Current Loss: 0.3938, Avg Loss: 0.3871\n",
      "Diff stats — min: -4.7555, max: 10.0000, mean: 1.8726, std: 2.1374\n",
      "\n",
      "Epoch 12, Step 100, LR: 0.000754, Current Loss: 0.3852, Avg Loss: 0.3864\n",
      "Diff stats — min: -5.4378, max: 10.0000, mean: 1.8994, std: 2.1189\n",
      "\n",
      "Step 2222 — Test metrics:\n",
      "  precision@10: 0.008172569\n",
      "  recall@10: 0.008175505\n",
      "  ndcg@10: 0.008353507\n",
      "  map@10: 0.002646720\n",
      "Epoch 12, Step 120, LR: 0.000754, Current Loss: 0.3835, Avg Loss: 0.3859\n",
      "Diff stats — min: -5.2278, max: 10.0000, mean: 1.8900, std: 2.1240\n",
      "\n",
      "Epoch 12, Step 140, LR: 0.000739, Current Loss: 0.3831, Avg Loss: 0.3858\n",
      "Diff stats — min: -6.0161, max: 10.0000, mean: 1.8989, std: 2.0987\n",
      "\n",
      "Step 2272 — Test metrics:\n",
      "  precision@10: 0.008258457\n",
      "  recall@10: 0.008262311\n",
      "  ndcg@10: 0.008174570\n",
      "  map@10: 0.002518420\n",
      "Epoch 12, Step 160, LR: 0.000739, Current Loss: 0.3884, Avg Loss: 0.3858\n",
      "Diff stats — min: -5.4801, max: 9.6074, mean: 1.8920, std: 2.1273\n",
      "\n",
      "Epoch 12, Step 180, LR: 0.000739, Current Loss: 0.3758, Avg Loss: 0.3855\n",
      "Diff stats — min: -4.6705, max: 10.0000, mean: 1.9614, std: 2.1430\n",
      "\n",
      "Epoch 12 completed, Train Loss: 0.000094\n",
      "\n",
      "Epoch 13, Step 1, LR: 0.000739, Current Loss: 0.3802, Avg Loss: 0.3802\n",
      "Diff stats — min: -4.8097, max: 9.5127, mean: 1.8990, std: 2.1113\n",
      "\n",
      "Step 2316 — Test metrics:\n",
      "  precision@10: 0.007855444\n",
      "  recall@10: 0.007859114\n",
      "  ndcg@10: 0.007931594\n",
      "  map@10: 0.002490408\n",
      "Epoch 13, Step 20, LR: 0.000739, Current Loss: 0.3760, Avg Loss: 0.3791\n",
      "Diff stats — min: -5.6620, max: 10.0000, mean: 1.9403, std: 2.1247\n",
      "\n",
      "Epoch 13, Step 40, LR: 0.000739, Current Loss: 0.3714, Avg Loss: 0.3783\n",
      "Diff stats — min: -6.0196, max: 9.1585, mean: 1.9755, std: 2.1394\n",
      "\n",
      "Step 2365 — Test metrics:\n",
      "  precision@10: 0.008179175\n",
      "  recall@10: 0.008181378\n",
      "  ndcg@10: 0.008288228\n",
      "  map@10: 0.002592388\n",
      "Epoch 13, Step 60, LR: 0.000739, Current Loss: 0.3782, Avg Loss: 0.3771\n",
      "Diff stats — min: -6.4022, max: 9.7792, mean: 1.9963, std: 2.1821\n",
      "\n",
      "Epoch 13, Step 80, LR: 0.000739, Current Loss: 0.3834, Avg Loss: 0.3768\n",
      "Diff stats — min: -5.6669, max: 10.0000, mean: 1.9234, std: 2.1177\n",
      "\n",
      "Epoch 13, Step 100, LR: 0.000724, Current Loss: 0.3686, Avg Loss: 0.3767\n",
      "Diff stats — min: -6.1715, max: 10.0000, mean: 2.0092, std: 2.1572\n",
      "\n",
      "Step 2415 — Test metrics:\n",
      "  precision@10: 0.008714323\n",
      "  recall@10: 0.008719462\n",
      "  ndcg@10: 0.008621851\n",
      "  map@10: 0.002640015\n",
      "Epoch 13, Step 120, LR: 0.000724, Current Loss: 0.3908, Avg Loss: 0.3768\n",
      "Diff stats — min: -5.9333, max: 10.0000, mean: 1.9018, std: 2.1348\n",
      "\n",
      "Epoch 13, Step 140, LR: 0.000724, Current Loss: 0.3662, Avg Loss: 0.3765\n",
      "Diff stats — min: -5.1036, max: 9.5411, mean: 1.9948, std: 2.1307\n",
      "\n",
      "Step 2465 — Test metrics:\n",
      "  precision@10: 0.008364165\n",
      "  recall@10: 0.008369304\n",
      "  ndcg@10: 0.008400140\n",
      "  map@10: 0.002582461\n",
      "Epoch 13, Step 160, LR: 0.000724, Current Loss: 0.3741, Avg Loss: 0.3763\n",
      "Diff stats — min: -6.4117, max: 10.0000, mean: 2.0241, std: 2.2000\n",
      "\n",
      "Epoch 13, Step 180, LR: 0.000724, Current Loss: 0.3776, Avg Loss: 0.3759\n",
      "Diff stats — min: -5.8577, max: 9.8226, mean: 1.9777, std: 2.1502\n",
      "\n",
      "Epoch 13 completed, Train Loss: 0.000092\n",
      "\n",
      "Epoch 14, Step 1, LR: 0.000724, Current Loss: 0.3566, Avg Loss: 0.3566\n",
      "Diff stats — min: -5.4528, max: 10.0000, mean: 1.9917, std: 2.0853\n",
      "\n",
      "Step 2509 — Test metrics:\n",
      "  precision@10: 0.008436839\n",
      "  recall@10: 0.008441244\n",
      "  ndcg@10: 0.008520825\n",
      "  map@10: 0.002638322\n",
      "Epoch 14, Step 20, LR: 0.000724, Current Loss: 0.3690, Avg Loss: 0.3682\n",
      "Diff stats — min: -4.9423, max: 10.0000, mean: 2.0308, std: 2.2092\n",
      "\n",
      "Epoch 14, Step 40, LR: 0.000724, Current Loss: 0.3649, Avg Loss: 0.3691\n",
      "Diff stats — min: -5.8108, max: 9.6390, mean: 1.9625, std: 2.0924\n",
      "\n",
      "Step 2558 — Test metrics:\n",
      "  precision@10: 0.008456660\n",
      "  recall@10: 0.008460330\n",
      "  ndcg@10: 0.008414616\n",
      "  map@10: 0.002568179\n",
      "Epoch 14, Step 60, LR: 0.000709, Current Loss: 0.3552, Avg Loss: 0.3685\n",
      "Diff stats — min: -5.6966, max: 9.9107, mean: 2.0514, std: 2.1514\n",
      "\n",
      "Epoch 14, Step 80, LR: 0.000709, Current Loss: 0.3627, Avg Loss: 0.3683\n",
      "Diff stats — min: -5.3625, max: 10.0000, mean: 2.0433, std: 2.1638\n",
      "\n",
      "Epoch 14, Step 100, LR: 0.000709, Current Loss: 0.3737, Avg Loss: 0.3686\n",
      "Diff stats — min: -5.0450, max: 10.0000, mean: 2.0306, std: 2.2027\n",
      "\n",
      "Step 2608 — Test metrics:\n",
      "  precision@10: 0.008020613\n",
      "  recall@10: 0.008025752\n",
      "  ndcg@10: 0.007966630\n",
      "  map@10: 0.002426463\n",
      "Epoch 14, Step 120, LR: 0.000709, Current Loss: 0.3685, Avg Loss: 0.3686\n",
      "Diff stats — min: -4.7980, max: 10.0000, mean: 2.0243, std: 2.1774\n",
      "\n",
      "Epoch 14, Step 140, LR: 0.000709, Current Loss: 0.3714, Avg Loss: 0.3684\n",
      "Diff stats — min: -4.5891, max: 9.7980, mean: 2.0042, std: 2.1603\n",
      "\n",
      "Step 2658 — Test metrics:\n",
      "  precision@10: 0.008350951\n",
      "  recall@10: 0.008355356\n",
      "  ndcg@10: 0.008318478\n",
      "  map@10: 0.002551815\n",
      "Epoch 14, Step 160, LR: 0.000709, Current Loss: 0.3572, Avg Loss: 0.3687\n",
      "Diff stats — min: -4.7875, max: 10.0000, mean: 2.0401, std: 2.1322\n",
      "\n",
      "Epoch 14, Step 180, LR: 0.000709, Current Loss: 0.3709, Avg Loss: 0.3686\n",
      "Diff stats — min: -5.2005, max: 10.0000, mean: 2.0657, std: 2.2305\n",
      "\n",
      "Epoch 14 completed, Train Loss: 0.000090\n",
      "\n",
      "Epoch 15, Step 1, LR: 0.000695, Current Loss: 0.3634, Avg Loss: 0.3634\n",
      "Diff stats — min: -5.3484, max: 10.0000, mean: 2.0070, std: 2.1245\n",
      "\n",
      "Step 2702 — Test metrics:\n",
      "  precision@10: 0.008496300\n",
      "  recall@10: 0.008502356\n",
      "  ndcg@10: 0.008443153\n",
      "  map@10: 0.002605515\n",
      "Epoch 15, Step 20, LR: 0.000695, Current Loss: 0.3544, Avg Loss: 0.3624\n",
      "Diff stats — min: -5.4247, max: 10.0000, mean: 2.0965, std: 2.1852\n",
      "\n",
      "Epoch 15, Step 40, LR: 0.000695, Current Loss: 0.3680, Avg Loss: 0.3618\n",
      "Diff stats — min: -4.8289, max: 10.0000, mean: 2.0494, std: 2.2031\n",
      "\n",
      "Step 2751 — Test metrics:\n",
      "  precision@10: 0.008205603\n",
      "  recall@10: 0.008208539\n",
      "  ndcg@10: 0.008125718\n",
      "  map@10: 0.002478400\n",
      "Epoch 15, Step 60, LR: 0.000695, Current Loss: 0.3554, Avg Loss: 0.3616\n",
      "Diff stats — min: -4.8510, max: 9.9931, mean: 2.0927, std: 2.1743\n",
      "\n",
      "Epoch 15, Step 80, LR: 0.000695, Current Loss: 0.3585, Avg Loss: 0.3614\n",
      "Diff stats — min: -6.2455, max: 10.0000, mean: 2.1233, std: 2.2364\n",
      "\n",
      "Epoch 15, Step 100, LR: 0.000695, Current Loss: 0.3626, Avg Loss: 0.3611\n",
      "Diff stats — min: -5.0125, max: 10.0000, mean: 2.1452, std: 2.2683\n",
      "\n",
      "Step 2801 — Test metrics:\n",
      "  precision@10: 0.007637421\n",
      "  recall@10: 0.007641825\n",
      "  ndcg@10: 0.007568242\n",
      "  map@10: 0.002311298\n",
      "Epoch 15, Step 120, LR: 0.000695, Current Loss: 0.3552, Avg Loss: 0.3609\n",
      "Diff stats — min: -5.1683, max: 10.0000, mean: 2.1080, std: 2.2091\n",
      "\n",
      "Epoch 15, Step 140, LR: 0.000695, Current Loss: 0.3613, Avg Loss: 0.3611\n",
      "Diff stats — min: -6.6383, max: 10.0000, mean: 2.1043, std: 2.2130\n",
      "\n",
      "Step 2851 — Test metrics:\n",
      "  precision@10: 0.008033827\n",
      "  recall@10: 0.008038231\n",
      "  ndcg@10: 0.007973754\n",
      "  map@10: 0.002431702\n",
      "Epoch 15, Step 160, LR: 0.000681, Current Loss: 0.3565, Avg Loss: 0.3611\n",
      "Diff stats — min: -5.3099, max: 10.0000, mean: 2.0858, std: 2.1800\n",
      "\n",
      "Epoch 15, Step 180, LR: 0.000681, Current Loss: 0.3594, Avg Loss: 0.3615\n",
      "Diff stats — min: -5.2248, max: 10.0000, mean: 2.0972, std: 2.2136\n",
      "\n",
      "Epoch 15 completed, Train Loss: 0.000088\n",
      "\n",
      "Epoch 16, Step 1, LR: 0.000681, Current Loss: 0.3571, Avg Loss: 0.3571\n",
      "Diff stats — min: -4.6658, max: 10.0000, mean: 2.1065, std: 2.2073\n",
      "\n",
      "Step 2895 — Test metrics:\n",
      "  precision@10: 0.008066860\n",
      "  recall@10: 0.008071265\n",
      "  ndcg@10: 0.008055392\n",
      "  map@10: 0.002464932\n",
      "Epoch 16, Step 20, LR: 0.000681, Current Loss: 0.3585, Avg Loss: 0.3555\n",
      "Diff stats — min: -5.4981, max: 10.0000, mean: 2.0827, std: 2.1757\n",
      "\n",
      "Epoch 16, Step 40, LR: 0.000681, Current Loss: 0.3505, Avg Loss: 0.3565\n",
      "Diff stats — min: -4.5413, max: 10.0000, mean: 2.1171, std: 2.1903\n",
      "\n",
      "Step 2944 — Test metrics:\n",
      "  precision@10: 0.008185782\n",
      "  recall@10: 0.008190187\n",
      "  ndcg@10: 0.008113129\n",
      "  map@10: 0.002456756\n",
      "Epoch 16, Step 60, LR: 0.000681, Current Loss: 0.3466, Avg Loss: 0.3547\n",
      "Diff stats — min: -4.4861, max: 10.0000, mean: 2.1521, std: 2.1880\n",
      "\n",
      "Epoch 16, Step 80, LR: 0.000681, Current Loss: 0.3548, Avg Loss: 0.3549\n",
      "Diff stats — min: -5.3979, max: 9.8016, mean: 2.1328, std: 2.2002\n",
      "\n",
      "Epoch 16, Step 100, LR: 0.000681, Current Loss: 0.3651, Avg Loss: 0.3552\n",
      "Diff stats — min: -5.9450, max: 10.0000, mean: 2.1036, std: 2.2417\n",
      "\n",
      "Step 2994 — Test metrics:\n",
      "  precision@10: 0.008238636\n",
      "  recall@10: 0.008242307\n",
      "  ndcg@10: 0.008124678\n",
      "  map@10: 0.002449392\n",
      "Epoch 16, Step 120, LR: 0.000668, Current Loss: 0.3467, Avg Loss: 0.3546\n",
      "Diff stats — min: -5.9290, max: 9.9262, mean: 2.1663, std: 2.2204\n",
      "\n",
      "Epoch 16, Step 140, LR: 0.000668, Current Loss: 0.3446, Avg Loss: 0.3541\n",
      "Diff stats — min: -6.8752, max: 10.0000, mean: 2.2328, std: 2.2815\n",
      "\n",
      "Step 3044 — Test metrics:\n",
      "  precision@10: 0.008066860\n",
      "  recall@10: 0.008073467\n",
      "  ndcg@10: 0.007809030\n",
      "  map@10: 0.002308754\n",
      "Epoch 16, Step 160, LR: 0.000668, Current Loss: 0.3400, Avg Loss: 0.3539\n",
      "Diff stats — min: -4.9772, max: 10.0000, mean: 2.1938, std: 2.2168\n",
      "\n",
      "Epoch 16, Step 180, LR: 0.000668, Current Loss: 0.3465, Avg Loss: 0.3531\n",
      "Diff stats — min: -4.9533, max: 10.0000, mean: 2.1710, std: 2.2317\n",
      "\n",
      "Epoch 16 completed, Train Loss: 0.000086\n",
      "\n",
      "Epoch 17, Step 1, LR: 0.000668, Current Loss: 0.3496, Avg Loss: 0.3496\n",
      "Diff stats — min: -5.0214, max: 10.0000, mean: 2.1788, std: 2.2605\n",
      "\n",
      "Step 3088 — Test metrics:\n",
      "  precision@10: 0.008093288\n",
      "  recall@10: 0.008098426\n",
      "  ndcg@10: 0.007952878\n",
      "  map@10: 0.002416045\n",
      "Epoch 17, Step 20, LR: 0.000668, Current Loss: 0.3593, Avg Loss: 0.3460\n",
      "Diff stats — min: -6.1049, max: 10.0000, mean: 2.1739, std: 2.2758\n",
      "\n",
      "Epoch 17, Step 40, LR: 0.000668, Current Loss: 0.3397, Avg Loss: 0.3482\n",
      "Diff stats — min: -4.3597, max: 10.0000, mean: 2.2259, std: 2.2263\n",
      "\n",
      "Step 3137 — Test metrics:\n",
      "  precision@10: 0.008377378\n",
      "  recall@10: 0.008381783\n",
      "  ndcg@10: 0.008107585\n",
      "  map@10: 0.002400691\n",
      "Epoch 17, Step 60, LR: 0.000668, Current Loss: 0.3491, Avg Loss: 0.3491\n",
      "Diff stats — min: -5.1432, max: 10.0000, mean: 2.1240, std: 2.1815\n",
      "\n",
      "Epoch 17, Step 80, LR: 0.000654, Current Loss: 0.3486, Avg Loss: 0.3487\n",
      "Diff stats — min: -5.1075, max: 10.0000, mean: 2.1670, std: 2.2336\n",
      "\n",
      "Epoch 17, Step 100, LR: 0.000654, Current Loss: 0.3505, Avg Loss: 0.3486\n",
      "Diff stats — min: -4.5945, max: 9.7783, mean: 2.1448, std: 2.2114\n",
      "\n",
      "Step 3187 — Test metrics:\n",
      "  precision@10: 0.008126321\n",
      "  recall@10: 0.008131460\n",
      "  ndcg@10: 0.008049152\n",
      "  map@10: 0.002447626\n",
      "Epoch 17, Step 120, LR: 0.000654, Current Loss: 0.3489, Avg Loss: 0.3482\n",
      "Diff stats — min: -6.0400, max: 10.0000, mean: 2.1688, std: 2.2170\n",
      "\n",
      "Epoch 17, Step 140, LR: 0.000654, Current Loss: 0.3528, Avg Loss: 0.3478\n",
      "Diff stats — min: -5.0573, max: 10.0000, mean: 2.2138, std: 2.2563\n",
      "\n",
      "Step 3237 — Test metrics:\n",
      "  precision@10: 0.008225423\n",
      "  recall@10: 0.008230561\n",
      "  ndcg@10: 0.008038972\n",
      "  map@10: 0.002411136\n",
      "Epoch 17, Step 160, LR: 0.000654, Current Loss: 0.3483, Avg Loss: 0.3475\n",
      "Diff stats — min: -5.4306, max: 10.0000, mean: 2.2047, std: 2.2453\n",
      "\n",
      "Epoch 17, Step 180, LR: 0.000654, Current Loss: 0.3385, Avg Loss: 0.3471\n",
      "Diff stats — min: -5.7891, max: 10.0000, mean: 2.2605, std: 2.2605\n",
      "\n",
      "Epoch 17 completed, Train Loss: 0.000085\n",
      "\n",
      "Epoch 18, Step 1, LR: 0.000654, Current Loss: 0.3390, Avg Loss: 0.3390\n",
      "Diff stats — min: -4.7108, max: 10.0000, mean: 2.2404, std: 2.2494\n",
      "\n",
      "Step 3281 — Test metrics:\n",
      "  precision@10: 0.008364165\n",
      "  recall@10: 0.008369304\n",
      "  ndcg@10: 0.008200764\n",
      "  map@10: 0.002459603\n",
      "Epoch 18, Step 20, LR: 0.000641, Current Loss: 0.3384, Avg Loss: 0.3400\n",
      "Diff stats — min: -5.9530, max: 9.9070, mean: 2.2557, std: 2.2553\n",
      "\n",
      "Epoch 18, Step 40, LR: 0.000641, Current Loss: 0.3551, Avg Loss: 0.3394\n",
      "Diff stats — min: -6.5364, max: 10.0000, mean: 2.2278, std: 2.2826\n",
      "\n",
      "Step 3330 — Test metrics:\n",
      "  precision@10: 0.008304704\n",
      "  recall@10: 0.008309843\n",
      "  ndcg@10: 0.008110503\n",
      "  map@10: 0.002429645\n",
      "Epoch 18, Step 60, LR: 0.000641, Current Loss: 0.3399, Avg Loss: 0.3393\n",
      "Diff stats — min: -4.9083, max: 10.0000, mean: 2.2264, std: 2.2230\n",
      "\n",
      "Epoch 18, Step 80, LR: 0.000641, Current Loss: 0.3385, Avg Loss: 0.3399\n",
      "Diff stats — min: -5.6523, max: 9.9521, mean: 2.2441, std: 2.2459\n",
      "\n",
      "Epoch 18, Step 100, LR: 0.000641, Current Loss: 0.3325, Avg Loss: 0.3394\n",
      "Diff stats — min: -9.5630, max: 10.0000, mean: 2.3063, std: 2.3013\n",
      "\n",
      "Step 3380 — Test metrics:\n",
      "  precision@10: 0.008423626\n",
      "  recall@10: 0.008428764\n",
      "  ndcg@10: 0.008252785\n",
      "  map@10: 0.002471603\n",
      "Epoch 18, Step 120, LR: 0.000641, Current Loss: 0.3326, Avg Loss: 0.3393\n",
      "Diff stats — min: -6.0859, max: 10.0000, mean: 2.2404, std: 2.1994\n",
      "\n",
      "Epoch 18, Step 140, LR: 0.000641, Current Loss: 0.3407, Avg Loss: 0.3391\n",
      "Diff stats — min: -4.5855, max: 10.0000, mean: 2.2528, std: 2.2787\n",
      "\n",
      "Step 3430 — Test metrics:\n",
      "  precision@10: 0.008734144\n",
      "  recall@10: 0.008737814\n",
      "  ndcg@10: 0.008648755\n",
      "  map@10: 0.002619703\n",
      "Epoch 18, Step 160, LR: 0.000641, Current Loss: 0.3463, Avg Loss: 0.3394\n",
      "Diff stats — min: -6.2705, max: 9.7927, mean: 2.2341, std: 2.2511\n",
      "\n",
      "Epoch 18, Step 180, LR: 0.000628, Current Loss: 0.3315, Avg Loss: 0.3394\n",
      "Diff stats — min: -5.3520, max: 10.0000, mean: 2.3059, std: 2.2774\n",
      "\n",
      "Epoch 18 completed, Train Loss: 0.000083\n",
      "\n",
      "Epoch 19, Step 1, LR: 0.000628, Current Loss: 0.3345, Avg Loss: 0.3345\n",
      "Diff stats — min: -4.8547, max: 10.0000, mean: 2.2773, std: 2.2456\n",
      "\n",
      "Step 3474 — Test metrics:\n",
      "  precision@10: 0.008668076\n",
      "  recall@10: 0.008673949\n",
      "  ndcg@10: 0.008525931\n",
      "  map@10: 0.002572867\n",
      "Epoch 19, Step 20, LR: 0.000628, Current Loss: 0.3165, Avg Loss: 0.3323\n",
      "Diff stats — min: -5.1670, max: 10.0000, mean: 2.3087, std: 2.2047\n",
      "\n",
      "Epoch 19, Step 40, LR: 0.000628, Current Loss: 0.3380, Avg Loss: 0.3317\n",
      "Diff stats — min: -5.9401, max: 10.0000, mean: 2.3205, std: 2.3010\n",
      "\n",
      "Step 3523 — Test metrics:\n",
      "  precision@10: 0.008324524\n",
      "  recall@10: 0.008330397\n",
      "  ndcg@10: 0.008307606\n",
      "  map@10: 0.002554391\n",
      "Epoch 19, Step 60, LR: 0.000628, Current Loss: 0.3307, Avg Loss: 0.3310\n",
      "Diff stats — min: -5.1613, max: 10.0000, mean: 2.3562, std: 2.3068\n",
      "\n",
      "Epoch 19, Step 80, LR: 0.000628, Current Loss: 0.3341, Avg Loss: 0.3315\n",
      "Diff stats — min: -5.1251, max: 10.0000, mean: 2.3142, std: 2.2811\n",
      "\n",
      "Epoch 19, Step 100, LR: 0.000628, Current Loss: 0.3316, Avg Loss: 0.3304\n",
      "Diff stats — min: -6.2094, max: 10.0000, mean: 2.3835, std: 2.3403\n",
      "\n",
      "Step 3573 — Test metrics:\n",
      "  precision@10: 0.008364165\n",
      "  recall@10: 0.008370038\n",
      "  ndcg@10: 0.008445335\n",
      "  map@10: 0.002602652\n",
      "Epoch 19, Step 120, LR: 0.000628, Current Loss: 0.3347, Avg Loss: 0.3302\n",
      "Diff stats — min: -5.5375, max: 10.0000, mean: 2.3787, std: 2.3636\n",
      "\n",
      "Epoch 19, Step 140, LR: 0.000616, Current Loss: 0.3304, Avg Loss: 0.3304\n",
      "Diff stats — min: -5.1940, max: 10.0000, mean: 2.3460, std: 2.3047\n",
      "\n",
      "Step 3623 — Test metrics:\n",
      "  precision@10: 0.008635042\n",
      "  recall@10: 0.008641098\n",
      "  ndcg@10: 0.008599804\n",
      "  map@10: 0.002628737\n",
      "Epoch 19, Step 160, LR: 0.000616, Current Loss: 0.3242, Avg Loss: 0.3304\n",
      "Diff stats — min: -5.4459, max: 10.0000, mean: 2.3416, std: 2.2592\n",
      "\n",
      "Epoch 19, Step 180, LR: 0.000616, Current Loss: 0.3328, Avg Loss: 0.3303\n",
      "Diff stats — min: -6.2445, max: 10.0000, mean: 2.3604, std: 2.3211\n",
      "\n",
      "Epoch 19 completed, Train Loss: 0.000081\n",
      "\n",
      "Epoch 20, Step 1, LR: 0.000616, Current Loss: 0.3496, Avg Loss: 0.3496\n",
      "Diff stats — min: -5.3003, max: 10.0000, mean: 2.3232, std: 2.3542\n",
      "\n",
      "Step 3667 — Test metrics:\n",
      "  precision@10: 0.008562368\n",
      "  recall@10: 0.008568424\n",
      "  ndcg@10: 0.008586129\n",
      "  map@10: 0.002631517\n",
      "Epoch 20, Step 20, LR: 0.000616, Current Loss: 0.3248, Avg Loss: 0.3251\n",
      "Diff stats — min: -5.9225, max: 10.0000, mean: 2.4018, std: 2.3130\n",
      "\n",
      "Epoch 20, Step 40, LR: 0.000616, Current Loss: 0.3153, Avg Loss: 0.3243\n",
      "Diff stats — min: -5.9424, max: 10.0000, mean: 2.3586, std: 2.2354\n",
      "\n",
      "Step 3716 — Test metrics:\n",
      "  precision@10: 0.008681290\n",
      "  recall@10: 0.008688080\n",
      "  ndcg@10: 0.008661110\n",
      "  map@10: 0.002650907\n",
      "Epoch 20, Step 60, LR: 0.000616, Current Loss: 0.3370, Avg Loss: 0.3235\n",
      "Diff stats — min: -7.2407, max: 10.0000, mean: 2.3722, std: 2.3706\n",
      "\n",
      "Epoch 20, Step 80, LR: 0.000616, Current Loss: 0.3166, Avg Loss: 0.3238\n",
      "Diff stats — min: -5.9743, max: 10.0000, mean: 2.4039, std: 2.3027\n",
      "\n",
      "Epoch 20, Step 100, LR: 0.000603, Current Loss: 0.3291, Avg Loss: 0.3240\n",
      "Diff stats — min: -5.5974, max: 10.0000, mean: 2.4092, std: 2.3555\n",
      "\n",
      "Step 3766 — Test metrics:\n",
      "  precision@10: 0.008469873\n",
      "  recall@10: 0.008478132\n",
      "  ndcg@10: 0.008349647\n",
      "  map@10: 0.002512251\n",
      "Epoch 20, Step 120, LR: 0.000603, Current Loss: 0.3187, Avg Loss: 0.3233\n",
      "Diff stats — min: -5.0005, max: 10.0000, mean: 2.4473, std: 2.3394\n",
      "\n",
      "Epoch 20, Step 140, LR: 0.000603, Current Loss: 0.3288, Avg Loss: 0.3231\n",
      "Diff stats — min: -4.9892, max: 10.0000, mean: 2.3780, std: 2.3133\n",
      "\n",
      "Step 3816 — Test metrics:\n",
      "  precision@10: 0.008159355\n",
      "  recall@10: 0.008166145\n",
      "  ndcg@10: 0.008223597\n",
      "  map@10: 0.002523389\n",
      "Epoch 20, Step 160, LR: 0.000603, Current Loss: 0.3197, Avg Loss: 0.3231\n",
      "Diff stats — min: -4.8827, max: 10.0000, mean: 2.4367, std: 2.3361\n",
      "\n",
      "Epoch 20, Step 180, LR: 0.000603, Current Loss: 0.3213, Avg Loss: 0.3233\n",
      "Diff stats — min: -6.2166, max: 10.0000, mean: 2.4441, std: 2.3338\n",
      "\n",
      "Epoch 20 completed, Train Loss: 0.000079\n",
      "\n",
      "Epoch 21, Step 1, LR: 0.000603, Current Loss: 0.3076, Avg Loss: 0.3076\n",
      "Diff stats — min: -6.3428, max: 10.0000, mean: 2.5001, std: 2.3324\n",
      "\n",
      "Step 3860 — Test metrics:\n",
      "  precision@10: 0.008185782\n",
      "  recall@10: 0.008193307\n",
      "  ndcg@10: 0.008282783\n",
      "  map@10: 0.002551912\n",
      "Epoch 21, Step 20, LR: 0.000603, Current Loss: 0.3257, Avg Loss: 0.3142\n",
      "Diff stats — min: -6.0167, max: 10.0000, mean: 2.4661, std: 2.3777\n",
      "\n",
      "Epoch 21, Step 40, LR: 0.000603, Current Loss: 0.2985, Avg Loss: 0.3141\n",
      "Diff stats — min: -5.0436, max: 10.0000, mean: 2.6175, std: 2.4062\n",
      "\n",
      "Step 3909 — Test metrics:\n",
      "  precision@10: 0.008436839\n",
      "  recall@10: 0.008445098\n",
      "  ndcg@10: 0.008450338\n",
      "  map@10: 0.002590613\n",
      "Epoch 21, Step 60, LR: 0.000591, Current Loss: 0.3197, Avg Loss: 0.3145\n",
      "Diff stats — min: -6.0641, max: 10.0000, mean: 2.5008, std: 2.3645\n",
      "\n",
      "Epoch 21, Step 80, LR: 0.000591, Current Loss: 0.3337, Avg Loss: 0.3151\n",
      "Diff stats — min: -5.2957, max: 10.0000, mean: 2.4838, std: 2.4289\n",
      "\n",
      "Epoch 21, Step 100, LR: 0.000591, Current Loss: 0.3043, Avg Loss: 0.3151\n",
      "Diff stats — min: -8.1441, max: 10.0000, mean: 2.5359, std: 2.3468\n",
      "\n",
      "Step 3959 — Test metrics:\n",
      "  precision@10: 0.008496300\n",
      "  recall@10: 0.008504559\n",
      "  ndcg@10: 0.008439051\n",
      "  map@10: 0.002557837\n",
      "Epoch 21, Step 120, LR: 0.000591, Current Loss: 0.2993, Avg Loss: 0.3147\n",
      "Diff stats — min: -5.2155, max: 10.0000, mean: 2.5500, std: 2.3140\n",
      "\n",
      "Epoch 21, Step 140, LR: 0.000591, Current Loss: 0.3116, Avg Loss: 0.3144\n",
      "Diff stats — min: -4.9535, max: 10.0000, mean: 2.4973, std: 2.3521\n",
      "\n",
      "Step 4009 — Test metrics:\n",
      "  precision@10: 0.008265063\n",
      "  recall@10: 0.008272588\n",
      "  ndcg@10: 0.008305945\n",
      "  map@10: 0.002537239\n",
      "Epoch 21, Step 160, LR: 0.000591, Current Loss: 0.3210, Avg Loss: 0.3146\n",
      "Diff stats — min: -5.6053, max: 10.0000, mean: 2.5239, std: 2.4042\n",
      "\n",
      "Epoch 21, Step 180, LR: 0.000591, Current Loss: 0.3204, Avg Loss: 0.3143\n",
      "Diff stats — min: -5.4161, max: 10.0000, mean: 2.4994, std: 2.3783\n",
      "\n",
      "Epoch 21 completed, Train Loss: 0.000077\n",
      "\n",
      "Epoch 22, Step 1, LR: 0.000580, Current Loss: 0.3185, Avg Loss: 0.3185\n",
      "Diff stats — min: -5.0135, max: 10.0000, mean: 2.5775, std: 2.4177\n",
      "\n",
      "Step 4053 — Test metrics:\n",
      "  precision@10: 0.008093288\n",
      "  recall@10: 0.008101546\n",
      "  ndcg@10: 0.008094713\n",
      "  map@10: 0.002457001\n",
      "Epoch 22, Step 20, LR: 0.000580, Current Loss: 0.3089, Avg Loss: 0.3092\n",
      "Diff stats — min: -5.4759, max: 10.0000, mean: 2.5302, std: 2.3590\n",
      "\n",
      "Epoch 22, Step 40, LR: 0.000580, Current Loss: 0.3056, Avg Loss: 0.3083\n",
      "Diff stats — min: -7.8597, max: 10.0000, mean: 2.5977, std: 2.3901\n",
      "\n",
      "Step 4102 — Test metrics:\n",
      "  precision@10: 0.008317918\n",
      "  recall@10: 0.008326176\n",
      "  ndcg@10: 0.008327802\n",
      "  map@10: 0.002521124\n",
      "Epoch 22, Step 60, LR: 0.000580, Current Loss: 0.3140, Avg Loss: 0.3083\n",
      "Diff stats — min: -5.0523, max: 10.0000, mean: 2.5505, std: 2.4083\n",
      "\n",
      "Epoch 22, Step 80, LR: 0.000580, Current Loss: 0.3207, Avg Loss: 0.3082\n",
      "Diff stats — min: -6.3792, max: 10.0000, mean: 2.5257, std: 2.4051\n",
      "\n",
      "Epoch 22, Step 100, LR: 0.000580, Current Loss: 0.3085, Avg Loss: 0.3076\n",
      "Diff stats — min: -6.1278, max: 10.0000, mean: 2.5996, std: 2.4206\n",
      "\n",
      "Step 4152 — Test metrics:\n",
      "  precision@10: 0.008496300\n",
      "  recall@10: 0.008504559\n",
      "  ndcg@10: 0.008473320\n",
      "  map@10: 0.002564407\n",
      "Epoch 22, Step 120, LR: 0.000580, Current Loss: 0.3008, Avg Loss: 0.3073\n",
      "Diff stats — min: -4.8554, max: 10.0000, mean: 2.6169, std: 2.3968\n",
      "\n",
      "Epoch 22, Step 140, LR: 0.000580, Current Loss: 0.3077, Avg Loss: 0.3068\n",
      "Diff stats — min: -5.2455, max: 10.0000, mean: 2.5833, std: 2.4034\n",
      "\n",
      "Step 4202 — Test metrics:\n",
      "  precision@10: 0.008463266\n",
      "  recall@10: 0.008472993\n",
      "  ndcg@10: 0.008558144\n",
      "  map@10: 0.002623422\n",
      "Epoch 22, Step 160, LR: 0.000568, Current Loss: 0.3093, Avg Loss: 0.3069\n",
      "Diff stats — min: -4.4847, max: 10.0000, mean: 2.5892, std: 2.4222\n",
      "\n",
      "Epoch 22, Step 180, LR: 0.000568, Current Loss: 0.3188, Avg Loss: 0.3071\n",
      "Diff stats — min: -6.2834, max: 10.0000, mean: 2.5351, std: 2.3942\n",
      "\n",
      "Epoch 22 completed, Train Loss: 0.000075\n",
      "\n",
      "Epoch 23, Step 1, LR: 0.000568, Current Loss: 0.3028, Avg Loss: 0.3028\n",
      "Diff stats — min: -7.2181, max: 10.0000, mean: 2.5800, std: 2.3795\n",
      "\n",
      "Step 4246 — Test metrics:\n",
      "  precision@10: 0.008284884\n",
      "  recall@10: 0.008291674\n",
      "  ndcg@10: 0.008314555\n",
      "  map@10: 0.002525701\n",
      "Epoch 23, Step 20, LR: 0.000568, Current Loss: 0.3009, Avg Loss: 0.3001\n",
      "Diff stats — min: -7.0092, max: 10.0000, mean: 2.6358, std: 2.4082\n",
      "\n",
      "Epoch 23, Step 40, LR: 0.000568, Current Loss: 0.2880, Avg Loss: 0.3011\n",
      "Diff stats — min: -5.9761, max: 10.0000, mean: 2.6469, std: 2.3633\n",
      "\n",
      "Step 4295 — Test metrics:\n",
      "  precision@10: 0.008423626\n",
      "  recall@10: 0.008431884\n",
      "  ndcg@10: 0.008561486\n",
      "  map@10: 0.002632884\n",
      "Epoch 23, Step 60, LR: 0.000568, Current Loss: 0.2960, Avg Loss: 0.2992\n",
      "Diff stats — min: -6.3432, max: 10.0000, mean: 2.6585, std: 2.4222\n",
      "\n",
      "Epoch 23, Step 80, LR: 0.000568, Current Loss: 0.2867, Avg Loss: 0.2990\n",
      "Diff stats — min: -4.8636, max: 10.0000, mean: 2.7080, std: 2.3945\n",
      "\n",
      "Epoch 23, Step 100, LR: 0.000568, Current Loss: 0.3060, Avg Loss: 0.2991\n",
      "Diff stats — min: -5.9511, max: 10.0000, mean: 2.6232, std: 2.4213\n",
      "\n",
      "Step 4345 — Test metrics:\n",
      "  precision@10: 0.008496300\n",
      "  recall@10: 0.008502356\n",
      "  ndcg@10: 0.008607770\n",
      "  map@10: 0.002665389\n",
      "Epoch 23, Step 120, LR: 0.000557, Current Loss: 0.3002, Avg Loss: 0.2986\n",
      "Diff stats — min: -7.3145, max: 10.0000, mean: 2.6963, std: 2.4566\n",
      "\n",
      "Epoch 23, Step 140, LR: 0.000557, Current Loss: 0.3063, Avg Loss: 0.2984\n",
      "Diff stats — min: -5.8045, max: 10.0000, mean: 2.6844, std: 2.4817\n",
      "\n",
      "Step 4395 — Test metrics:\n",
      "  precision@10: 0.008370772\n",
      "  recall@10: 0.008376094\n",
      "  ndcg@10: 0.008364041\n",
      "  map@10: 0.002547878\n",
      "Epoch 23, Step 160, LR: 0.000557, Current Loss: 0.2966, Avg Loss: 0.2980\n",
      "Diff stats — min: -6.2858, max: 10.0000, mean: 2.7478, std: 2.4662\n",
      "\n",
      "Epoch 23, Step 180, LR: 0.000557, Current Loss: 0.2746, Avg Loss: 0.2983\n",
      "Diff stats — min: -4.8550, max: 10.0000, mean: 2.7375, std: 2.3715\n",
      "\n",
      "Epoch 23 completed, Train Loss: 0.000073\n",
      "\n",
      "Epoch 24, Step 1, LR: 0.000557, Current Loss: 0.3052, Avg Loss: 0.3052\n",
      "Diff stats — min: -7.3261, max: 10.0000, mean: 2.6313, std: 2.4106\n",
      "\n",
      "Step 4439 — Test metrics:\n",
      "  precision@10: 0.008205603\n",
      "  recall@10: 0.008210007\n",
      "  ndcg@10: 0.008253621\n",
      "  map@10: 0.002514398\n",
      "Epoch 24, Step 20, LR: 0.000557, Current Loss: 0.3058, Avg Loss: 0.2956\n",
      "Diff stats — min: -6.5499, max: 10.0000, mean: 2.6620, std: 2.4594\n",
      "\n",
      "Epoch 24, Step 40, LR: 0.000557, Current Loss: 0.2915, Avg Loss: 0.2945\n",
      "Diff stats — min: -4.8526, max: 10.0000, mean: 2.7058, std: 2.4060\n",
      "\n",
      "Step 4488 — Test metrics:\n",
      "  precision@10: 0.008641649\n",
      "  recall@10: 0.008649908\n",
      "  ndcg@10: 0.008816336\n",
      "  map@10: 0.002729423\n",
      "Epoch 24, Step 60, LR: 0.000557, Current Loss: 0.3016, Avg Loss: 0.2938\n",
      "Diff stats — min: -5.1165, max: 10.0000, mean: 2.6901, std: 2.4645\n",
      "\n",
      "Epoch 24, Step 80, LR: 0.000545, Current Loss: 0.3056, Avg Loss: 0.2938\n",
      "Diff stats — min: -6.2135, max: 10.0000, mean: 2.6993, std: 2.4907\n",
      "\n",
      "Epoch 24, Step 100, LR: 0.000545, Current Loss: 0.2925, Avg Loss: 0.2937\n",
      "Diff stats — min: -6.4131, max: 10.0000, mean: 2.7090, std: 2.4207\n",
      "\n",
      "Step 4538 — Test metrics:\n",
      "  precision@10: 0.008403805\n",
      "  recall@10: 0.008412798\n",
      "  ndcg@10: 0.008530680\n",
      "  map@10: 0.002627879\n",
      "Epoch 24, Step 120, LR: 0.000545, Current Loss: 0.2958, Avg Loss: 0.2937\n",
      "Diff stats — min: -5.7308, max: 10.0000, mean: 2.7483, std: 2.4676\n",
      "\n",
      "Epoch 24, Step 140, LR: 0.000545, Current Loss: 0.3088, Avg Loss: 0.2938\n",
      "Diff stats — min: -6.2130, max: 10.0000, mean: 2.6800, std: 2.4631\n",
      "\n",
      "Step 4588 — Test metrics:\n",
      "  precision@10: 0.008648256\n",
      "  recall@10: 0.008659451\n",
      "  ndcg@10: 0.008674999\n",
      "  map@10: 0.002646779\n",
      "Epoch 24, Step 160, LR: 0.000545, Current Loss: 0.3051, Avg Loss: 0.2935\n",
      "Diff stats — min: -5.5605, max: 10.0000, mean: 2.6822, std: 2.4594\n",
      "\n",
      "Epoch 24, Step 180, LR: 0.000545, Current Loss: 0.2941, Avg Loss: 0.2935\n",
      "Diff stats — min: -5.7367, max: 10.0000, mean: 2.7286, std: 2.4549\n",
      "\n",
      "Epoch 24 completed, Train Loss: 0.000072\n",
      "\n",
      "Epoch 25, Step 1, LR: 0.000545, Current Loss: 0.2931, Avg Loss: 0.2931\n",
      "Diff stats — min: -7.2209, max: 10.0000, mean: 2.7434, std: 2.4549\n",
      "\n",
      "Step 4632 — Test metrics:\n",
      "  precision@10: 0.008793605\n",
      "  recall@10: 0.008804065\n",
      "  ndcg@10: 0.008869327\n",
      "  map@10: 0.002722922\n",
      "Epoch 25, Step 20, LR: 0.000535, Current Loss: 0.2849, Avg Loss: 0.2869\n",
      "Diff stats — min: -5.0591, max: 10.0000, mean: 2.7886, std: 2.4802\n",
      "\n",
      "Epoch 25, Step 40, LR: 0.000535, Current Loss: 0.2757, Avg Loss: 0.2855\n",
      "Diff stats — min: -5.9652, max: 10.0000, mean: 2.8552, std: 2.4745\n",
      "\n",
      "Step 4681 — Test metrics:\n",
      "  precision@10: 0.008542548\n",
      "  recall@10: 0.008550072\n",
      "  ndcg@10: 0.008582157\n",
      "  map@10: 0.002630963\n",
      "Epoch 25, Step 60, LR: 0.000535, Current Loss: 0.2896, Avg Loss: 0.2868\n",
      "Diff stats — min: -5.3497, max: 10.0000, mean: 2.7463, std: 2.4258\n",
      "\n",
      "Epoch 25, Step 80, LR: 0.000535, Current Loss: 0.2749, Avg Loss: 0.2864\n",
      "Diff stats — min: -5.3213, max: 10.0000, mean: 2.8079, std: 2.4532\n",
      "\n",
      "Epoch 25, Step 100, LR: 0.000535, Current Loss: 0.2841, Avg Loss: 0.2861\n",
      "Diff stats — min: -4.9428, max: 10.0000, mean: 2.8481, std: 2.5009\n",
      "\n",
      "Step 4731 — Test metrics:\n",
      "  precision@10: 0.008496300\n",
      "  recall@10: 0.008504559\n",
      "  ndcg@10: 0.008551102\n",
      "  map@10: 0.002617153\n",
      "Epoch 25, Step 120, LR: 0.000535, Current Loss: 0.2740, Avg Loss: 0.2855\n",
      "Diff stats — min: -5.9090, max: 10.0000, mean: 2.8703, std: 2.4614\n",
      "\n",
      "Epoch 25, Step 140, LR: 0.000535, Current Loss: 0.2883, Avg Loss: 0.2856\n",
      "Diff stats — min: -7.8644, max: 10.0000, mean: 2.8014, std: 2.4916\n",
      "\n",
      "Step 4781 — Test metrics:\n",
      "  precision@10: 0.008727537\n",
      "  recall@10: 0.008735795\n",
      "  ndcg@10: 0.008782909\n",
      "  map@10: 0.002699714\n",
      "Epoch 25, Step 160, LR: 0.000535, Current Loss: 0.2813, Avg Loss: 0.2858\n",
      "Diff stats — min: -5.3387, max: 10.0000, mean: 2.8319, std: 2.4825\n",
      "\n",
      "Epoch 25, Step 180, LR: 0.000524, Current Loss: 0.2966, Avg Loss: 0.2859\n",
      "Diff stats — min: -4.7712, max: 10.0000, mean: 2.7160, std: 2.4348\n",
      "\n",
      "Epoch 25 completed, Train Loss: 0.000070\n",
      "\n",
      "Epoch 26, Step 1, LR: 0.000524, Current Loss: 0.2942, Avg Loss: 0.2942\n",
      "Diff stats — min: -4.6062, max: 10.0000, mean: 2.7340, std: 2.4681\n",
      "\n",
      "Step 4825 — Test metrics:\n",
      "  precision@10: 0.008595402\n",
      "  recall@10: 0.008602192\n",
      "  ndcg@10: 0.008653504\n",
      "  map@10: 0.002657386\n",
      "Epoch 26, Step 20, LR: 0.000524, Current Loss: 0.2848, Avg Loss: 0.2840\n",
      "Diff stats — min: -5.6436, max: 10.0000, mean: 2.8572, std: 2.5080\n",
      "\n",
      "Epoch 26, Step 40, LR: 0.000524, Current Loss: 0.2917, Avg Loss: 0.2832\n",
      "Diff stats — min: -6.2515, max: 10.0000, mean: 2.8298, std: 2.4932\n",
      "\n",
      "Step 4874 — Test metrics:\n",
      "  precision@10: 0.008826638\n",
      "  recall@10: 0.008834163\n",
      "  ndcg@10: 0.008783137\n",
      "  map@10: 0.002677415\n",
      "Epoch 26, Step 60, LR: 0.000524, Current Loss: 0.2846, Avg Loss: 0.2824\n",
      "Diff stats — min: -6.5783, max: 10.0000, mean: 2.8181, std: 2.4751\n",
      "\n",
      "Epoch 26, Step 80, LR: 0.000524, Current Loss: 0.2838, Avg Loss: 0.2816\n",
      "Diff stats — min: -6.1647, max: 10.0000, mean: 2.8292, std: 2.4928\n",
      "\n",
      "Epoch 26, Step 100, LR: 0.000524, Current Loss: 0.2854, Avg Loss: 0.2824\n",
      "Diff stats — min: -5.7398, max: 10.0000, mean: 2.8082, std: 2.4793\n",
      "\n",
      "Step 4924 — Test metrics:\n",
      "  precision@10: 0.008793605\n",
      "  recall@10: 0.008801863\n",
      "  ndcg@10: 0.008861704\n",
      "  map@10: 0.002713026\n",
      "Epoch 26, Step 120, LR: 0.000524, Current Loss: 0.2732, Avg Loss: 0.2821\n",
      "Diff stats — min: -6.5238, max: 10.0000, mean: 2.8870, std: 2.4746\n",
      "\n",
      "Epoch 26, Step 140, LR: 0.000513, Current Loss: 0.2896, Avg Loss: 0.2816\n",
      "Diff stats — min: -5.9859, max: 10.0000, mean: 2.8659, std: 2.5333\n",
      "\n",
      "Step 4974 — Test metrics:\n",
      "  precision@10: 0.008648256\n",
      "  recall@10: 0.008656514\n",
      "  ndcg@10: 0.008827982\n",
      "  map@10: 0.002740346\n",
      "Epoch 26, Step 160, LR: 0.000513, Current Loss: 0.2718, Avg Loss: 0.2815\n",
      "Diff stats — min: -4.9519, max: 10.0000, mean: 2.9259, std: 2.5233\n",
      "\n",
      "Epoch 26, Step 180, LR: 0.000513, Current Loss: 0.2905, Avg Loss: 0.2818\n",
      "Diff stats — min: -6.3747, max: 10.0000, mean: 2.8617, std: 2.5257\n",
      "\n",
      "Epoch 26 completed, Train Loss: 0.000069\n",
      "\n",
      "Epoch 27, Step 1, LR: 0.000513, Current Loss: 0.2817, Avg Loss: 0.2817\n",
      "Diff stats — min: -5.3126, max: 10.0000, mean: 2.8126, std: 2.4539\n",
      "\n",
      "Step 5018 — Test metrics:\n",
      "  precision@10: 0.008872886\n",
      "  recall@10: 0.008881878\n",
      "  ndcg@10: 0.008883636\n",
      "  map@10: 0.002710410\n",
      "Epoch 27, Step 20, LR: 0.000513, Current Loss: 0.2766, Avg Loss: 0.2776\n",
      "Diff stats — min: -4.5224, max: 10.0000, mean: 2.9115, std: 2.5012\n",
      "\n",
      "Epoch 27, Step 40, LR: 0.000513, Current Loss: 0.2815, Avg Loss: 0.2763\n",
      "Diff stats — min: -5.5828, max: 10.0000, mean: 2.8941, std: 2.5484\n",
      "\n",
      "Step 5067 — Test metrics:\n",
      "  precision@10: 0.009057875\n",
      "  recall@10: 0.009065400\n",
      "  ndcg@10: 0.009111342\n",
      "  map@10: 0.002798561\n",
      "Epoch 27, Step 60, LR: 0.000513, Current Loss: 0.2759, Avg Loss: 0.2751\n",
      "Diff stats — min: -5.7071, max: 10.0000, mean: 2.9461, std: 2.5409\n",
      "\n",
      "Epoch 27, Step 80, LR: 0.000513, Current Loss: 0.2821, Avg Loss: 0.2754\n",
      "Diff stats — min: -6.4087, max: 10.0000, mean: 2.9523, std: 2.5951\n",
      "\n",
      "Epoch 27, Step 100, LR: 0.000503, Current Loss: 0.2649, Avg Loss: 0.2751\n",
      "Diff stats — min: -5.7789, max: 10.0000, mean: 2.9597, std: 2.4927\n",
      "\n",
      "Step 5117 — Test metrics:\n",
      "  precision@10: 0.008853066\n",
      "  recall@10: 0.008861324\n",
      "  ndcg@10: 0.008793361\n",
      "  map@10: 0.002661713\n",
      "Epoch 27, Step 120, LR: 0.000503, Current Loss: 0.2701, Avg Loss: 0.2747\n",
      "Diff stats — min: -5.4194, max: 10.0000, mean: 2.9398, std: 2.4979\n",
      "\n",
      "Epoch 27, Step 140, LR: 0.000503, Current Loss: 0.2748, Avg Loss: 0.2745\n",
      "Diff stats — min: -6.8269, max: 10.0000, mean: 2.9624, std: 2.5605\n",
      "\n",
      "Step 5167 — Test metrics:\n",
      "  precision@10: 0.008965381\n",
      "  recall@10: 0.008973639\n",
      "  ndcg@10: 0.008969990\n",
      "  map@10: 0.002739297\n",
      "Epoch 27, Step 160, LR: 0.000503, Current Loss: 0.2728, Avg Loss: 0.2746\n",
      "Diff stats — min: -5.3710, max: 10.0000, mean: 2.9162, std: 2.4972\n",
      "\n",
      "Epoch 27, Step 180, LR: 0.000503, Current Loss: 0.2812, Avg Loss: 0.2745\n",
      "Diff stats — min: -5.1865, max: 10.0000, mean: 2.9154, std: 2.5528\n",
      "\n",
      "Epoch 27 completed, Train Loss: 0.000067\n",
      "\n",
      "Epoch 28, Step 1, LR: 0.000503, Current Loss: 0.2576, Avg Loss: 0.2576\n",
      "Diff stats — min: -5.5454, max: 10.0000, mean: 3.0252, std: 2.5374\n",
      "\n",
      "Step 5211 — Test metrics:\n",
      "  precision@10: 0.008793605\n",
      "  recall@10: 0.008802597\n",
      "  ndcg@10: 0.008643131\n",
      "  map@10: 0.002588662\n",
      "Epoch 28, Step 20, LR: 0.000503, Current Loss: 0.2668, Avg Loss: 0.2678\n",
      "Diff stats — min: -5.5896, max: 10.0000, mean: 2.9952, std: 2.5548\n",
      "\n",
      "Epoch 28, Step 40, LR: 0.000493, Current Loss: 0.2744, Avg Loss: 0.2685\n",
      "Diff stats — min: -6.8553, max: 10.0000, mean: 2.9951, std: 2.5724\n",
      "\n",
      "Step 5260 — Test metrics:\n",
      "  precision@10: 0.009163584\n",
      "  recall@10: 0.009171842\n",
      "  ndcg@10: 0.009099115\n",
      "  map@10: 0.002756647\n",
      "Epoch 28, Step 60, LR: 0.000493, Current Loss: 0.2836, Avg Loss: 0.2684\n",
      "Diff stats — min: -6.0669, max: 10.0000, mean: 2.9507, std: 2.5925\n",
      "\n",
      "Epoch 28, Step 80, LR: 0.000493, Current Loss: 0.2707, Avg Loss: 0.2688\n",
      "Diff stats — min: -5.1121, max: 10.0000, mean: 3.0222, std: 2.6065\n",
      "\n",
      "Epoch 28, Step 100, LR: 0.000493, Current Loss: 0.2695, Avg Loss: 0.2698\n",
      "Diff stats — min: -5.6340, max: 10.0000, mean: 2.9843, std: 2.5455\n",
      "\n",
      "Step 5310 — Test metrics:\n",
      "  precision@10: 0.009229651\n",
      "  recall@10: 0.009237910\n",
      "  ndcg@10: 0.009288371\n",
      "  map@10: 0.002847706\n",
      "Epoch 28, Step 120, LR: 0.000493, Current Loss: 0.2657, Avg Loss: 0.2694\n",
      "Diff stats — min: -4.8630, max: 10.0000, mean: 3.0277, std: 2.5717\n",
      "\n",
      "Epoch 28, Step 140, LR: 0.000493, Current Loss: 0.2597, Avg Loss: 0.2697\n",
      "Diff stats — min: -5.3088, max: 10.0000, mean: 3.0068, std: 2.5133\n",
      "\n",
      "Step 5360 — Test metrics:\n",
      "  precision@10: 0.009381607\n",
      "  recall@10: 0.009391333\n",
      "  ndcg@10: 0.009381372\n",
      "  map@10: 0.002865934\n",
      "Epoch 28, Step 160, LR: 0.000493, Current Loss: 0.2609, Avg Loss: 0.2695\n",
      "Diff stats — min: -6.1556, max: 10.0000, mean: 3.0491, std: 2.5547\n",
      "\n",
      "Epoch 28, Step 180, LR: 0.000493, Current Loss: 0.2538, Avg Loss: 0.2695\n",
      "Diff stats — min: -5.9959, max: 10.0000, mean: 3.0400, std: 2.5255\n",
      "\n",
      "Epoch 28 completed, Train Loss: 0.000066\n",
      "\n",
      "Epoch 29, Step 1, LR: 0.000483, Current Loss: 0.2647, Avg Loss: 0.2647\n",
      "Diff stats — min: -5.9270, max: 10.0000, mean: 3.0157, std: 2.5481\n",
      "\n",
      "Step 5404 — Test metrics:\n",
      "  precision@10: 0.009401427\n",
      "  recall@10: 0.009409686\n",
      "  ndcg@10: 0.009337927\n",
      "  map@10: 0.002843787\n",
      "Epoch 29, Step 20, LR: 0.000483, Current Loss: 0.2721, Avg Loss: 0.2654\n",
      "Diff stats — min: -5.7629, max: 10.0000, mean: 2.9684, std: 2.5580\n",
      "\n",
      "Epoch 29, Step 40, LR: 0.000483, Current Loss: 0.2685, Avg Loss: 0.2670\n",
      "Diff stats — min: -5.2665, max: 10.0000, mean: 2.9782, std: 2.5154\n",
      "\n",
      "Step 5453 — Test metrics:\n",
      "  precision@10: 0.009540169\n",
      "  recall@10: 0.009548428\n",
      "  ndcg@10: 0.009591273\n",
      "  map@10: 0.002944072\n",
      "Epoch 29, Step 60, LR: 0.000483, Current Loss: 0.2552, Avg Loss: 0.2669\n",
      "Diff stats — min: -5.9299, max: 10.0000, mean: 3.1280, std: 2.5809\n",
      "\n",
      "Epoch 29, Step 80, LR: 0.000483, Current Loss: 0.2653, Avg Loss: 0.2667\n",
      "Diff stats — min: -5.3409, max: 10.0000, mean: 3.0734, std: 2.6120\n",
      "\n",
      "Epoch 29, Step 100, LR: 0.000483, Current Loss: 0.2673, Avg Loss: 0.2658\n",
      "Diff stats — min: -5.5058, max: 10.0000, mean: 3.0576, std: 2.5884\n",
      "\n",
      "Step 5503 — Test metrics:\n",
      "  precision@10: 0.009368393\n",
      "  recall@10: 0.009377386\n",
      "  ndcg@10: 0.009461956\n",
      "  map@10: 0.002914503\n",
      "Epoch 29, Step 120, LR: 0.000483, Current Loss: 0.2602, Avg Loss: 0.2657\n",
      "Diff stats — min: -6.6641, max: 10.0000, mean: 3.0867, std: 2.5780\n",
      "\n",
      "Epoch 29, Step 140, LR: 0.000483, Current Loss: 0.2610, Avg Loss: 0.2650\n",
      "Diff stats — min: -6.0748, max: 10.0000, mean: 3.0834, std: 2.5842\n",
      "\n",
      "Step 5553 — Test metrics:\n",
      "  precision@10: 0.009533562\n",
      "  recall@10: 0.009541821\n",
      "  ndcg@10: 0.009659474\n",
      "  map@10: 0.002980813\n",
      "Epoch 29, Step 160, LR: 0.000474, Current Loss: 0.2605, Avg Loss: 0.2650\n",
      "Diff stats — min: -5.0578, max: 10.0000, mean: 3.0177, std: 2.5201\n",
      "\n",
      "Epoch 29, Step 180, LR: 0.000474, Current Loss: 0.2672, Avg Loss: 0.2649\n",
      "Diff stats — min: -7.5481, max: 10.0000, mean: 3.0570, std: 2.5877\n",
      "\n",
      "Epoch 29 completed, Train Loss: 0.000065\n",
      "\n",
      "Epoch 30, Step 1, LR: 0.000474, Current Loss: 0.2739, Avg Loss: 0.2739\n",
      "Diff stats — min: -6.5615, max: 10.0000, mean: 3.0096, std: 2.5913\n",
      "\n",
      "Step 5597 — Test metrics:\n",
      "  precision@10: 0.008985201\n",
      "  recall@10: 0.008991991\n",
      "  ndcg@10: 0.009136842\n",
      "  map@10: 0.002825823\n",
      "Epoch 30, Step 20, LR: 0.000474, Current Loss: 0.2723, Avg Loss: 0.2625\n",
      "Diff stats — min: -6.5126, max: 10.0000, mean: 3.0352, std: 2.5843\n",
      "\n",
      "Epoch 30, Step 40, LR: 0.000474, Current Loss: 0.2498, Avg Loss: 0.2617\n",
      "Diff stats — min: -5.2753, max: 10.0000, mean: 3.1473, std: 2.5872\n",
      "\n",
      "Step 5646 — Test metrics:\n",
      "  precision@10: 0.009130550\n",
      "  recall@10: 0.009136606\n",
      "  ndcg@10: 0.009088225\n",
      "  map@10: 0.002757478\n",
      "Epoch 30, Step 60, LR: 0.000474, Current Loss: 0.2576, Avg Loss: 0.2603\n",
      "Diff stats — min: -5.4281, max: 10.0000, mean: 3.1362, std: 2.6160\n",
      "\n",
      "Epoch 30, Step 80, LR: 0.000474, Current Loss: 0.2548, Avg Loss: 0.2601\n",
      "Diff stats — min: -7.2238, max: 10.0000, mean: 3.2138, std: 2.6459\n",
      "\n",
      "Epoch 30, Step 100, LR: 0.000474, Current Loss: 0.2735, Avg Loss: 0.2602\n",
      "Diff stats — min: -6.1511, max: 10.0000, mean: 3.0793, std: 2.6420\n",
      "\n",
      "Step 5696 — Test metrics:\n",
      "  precision@10: 0.009368393\n",
      "  recall@10: 0.009377386\n",
      "  ndcg@10: 0.009456052\n",
      "  map@10: 0.002908372\n",
      "Epoch 30, Step 120, LR: 0.000464, Current Loss: 0.2690, Avg Loss: 0.2604\n",
      "Diff stats — min: -5.8776, max: 10.0000, mean: 3.0982, std: 2.6359\n",
      "\n",
      "Epoch 30, Step 140, LR: 0.000464, Current Loss: 0.2621, Avg Loss: 0.2605\n",
      "Diff stats — min: -5.1169, max: 10.0000, mean: 3.1103, std: 2.6092\n",
      "\n",
      "Step 5746 — Test metrics:\n",
      "  precision@10: 0.009104123\n",
      "  recall@10: 0.009110913\n",
      "  ndcg@10: 0.009194587\n",
      "  map@10: 0.002839694\n",
      "Epoch 30, Step 160, LR: 0.000464, Current Loss: 0.2688, Avg Loss: 0.2605\n",
      "Diff stats — min: -8.9137, max: 10.0000, mean: 3.1141, std: 2.6318\n",
      "\n",
      "Epoch 30, Step 180, LR: 0.000464, Current Loss: 0.2531, Avg Loss: 0.2604\n",
      "Diff stats — min: -6.4441, max: 10.0000, mean: 3.1791, std: 2.5850\n",
      "\n",
      "Epoch 30 completed, Train Loss: 0.000064\n",
      "\n",
      "Epoch 31, Step 1, LR: 0.000464, Current Loss: 0.2600, Avg Loss: 0.2600\n",
      "Diff stats — min: -5.5970, max: 10.0000, mean: 3.1421, std: 2.6509\n",
      "\n",
      "Step 5790 — Test metrics:\n",
      "  precision@10: 0.009216438\n",
      "  recall@10: 0.009225430\n",
      "  ndcg@10: 0.009359274\n",
      "  map@10: 0.002891789\n",
      "Epoch 31, Step 20, LR: 0.000464, Current Loss: 0.2426, Avg Loss: 0.2561\n",
      "Diff stats — min: -5.4943, max: 10.0000, mean: 3.2112, std: 2.5799\n",
      "\n",
      "Epoch 31, Step 40, LR: 0.000464, Current Loss: 0.2443, Avg Loss: 0.2555\n",
      "Diff stats — min: -4.8646, max: 10.0000, mean: 3.2035, std: 2.6019\n",
      "\n",
      "Step 5839 — Test metrics:\n",
      "  precision@10: 0.009163584\n",
      "  recall@10: 0.009171108\n",
      "  ndcg@10: 0.009199740\n",
      "  map@10: 0.002812960\n",
      "Epoch 31, Step 60, LR: 0.000464, Current Loss: 0.2645, Avg Loss: 0.2564\n",
      "Diff stats — min: -4.8341, max: 10.0000, mean: 3.1606, std: 2.6633\n",
      "\n",
      "Epoch 31, Step 80, LR: 0.000455, Current Loss: 0.2527, Avg Loss: 0.2568\n",
      "Diff stats — min: -5.7385, max: 10.0000, mean: 3.1993, std: 2.6253\n",
      "\n",
      "Epoch 31, Step 100, LR: 0.000455, Current Loss: 0.2561, Avg Loss: 0.2572\n",
      "Diff stats — min: -5.4036, max: 10.0000, mean: 3.2012, std: 2.6341\n",
      "\n",
      "Step 5889 — Test metrics:\n",
      "  precision@10: 0.009302326\n",
      "  recall@10: 0.009311318\n",
      "  ndcg@10: 0.009259345\n",
      "  map@10: 0.002815084\n",
      "Epoch 31, Step 120, LR: 0.000455, Current Loss: 0.2652, Avg Loss: 0.2574\n",
      "Diff stats — min: -6.6924, max: 10.0000, mean: 3.1434, std: 2.6249\n",
      "\n",
      "Epoch 31, Step 140, LR: 0.000455, Current Loss: 0.2689, Avg Loss: 0.2574\n",
      "Diff stats — min: -5.8365, max: 10.0000, mean: 3.1638, std: 2.6984\n",
      "\n",
      "Step 5939 — Test metrics:\n",
      "  precision@10: 0.009731765\n",
      "  recall@10: 0.009742226\n",
      "  ndcg@10: 0.009796764\n",
      "  map@10: 0.003005358\n",
      "Epoch 31, Step 160, LR: 0.000455, Current Loss: 0.2625, Avg Loss: 0.2572\n",
      "Diff stats — min: -5.6024, max: 10.0000, mean: 3.1568, std: 2.6388\n",
      "\n",
      "Epoch 31, Step 180, LR: 0.000455, Current Loss: 0.2639, Avg Loss: 0.2569\n",
      "Diff stats — min: -5.5431, max: 10.0000, mean: 3.2151, std: 2.6745\n",
      "\n",
      "Epoch 31 completed, Train Loss: 0.000063\n",
      "\n",
      "Epoch 32, Step 1, LR: 0.000455, Current Loss: 0.2400, Avg Loss: 0.2400\n",
      "Diff stats — min: -5.1079, max: 10.0000, mean: 3.2552, std: 2.6171\n",
      "\n",
      "Step 5983 — Test metrics:\n",
      "  precision@10: 0.009348573\n",
      "  recall@10: 0.009354446\n",
      "  ndcg@10: 0.009311173\n",
      "  map@10: 0.002831697\n",
      "Epoch 32, Step 20, LR: 0.000446, Current Loss: 0.2509, Avg Loss: 0.2514\n",
      "Diff stats — min: -5.4361, max: 10.0000, mean: 3.2642, std: 2.6679\n",
      "\n",
      "Epoch 32, Step 40, LR: 0.000446, Current Loss: 0.2401, Avg Loss: 0.2532\n",
      "Diff stats — min: -6.1630, max: 10.0000, mean: 3.2499, std: 2.6246\n",
      "\n",
      "Step 6032 — Test metrics:\n",
      "  precision@10: 0.009414641\n",
      "  recall@10: 0.009425101\n",
      "  ndcg@10: 0.009435712\n",
      "  map@10: 0.002898699\n",
      "Epoch 32, Step 60, LR: 0.000446, Current Loss: 0.2687, Avg Loss: 0.2528\n",
      "Diff stats — min: -7.2101, max: 10.0000, mean: 3.1919, std: 2.6861\n",
      "\n",
      "Epoch 32, Step 80, LR: 0.000446, Current Loss: 0.2448, Avg Loss: 0.2524\n",
      "Diff stats — min: -6.2030, max: 10.0000, mean: 3.2588, std: 2.6229\n",
      "\n",
      "Epoch 32, Step 100, LR: 0.000446, Current Loss: 0.2474, Avg Loss: 0.2533\n",
      "Diff stats — min: -5.6859, max: 10.0000, mean: 3.2299, std: 2.6300\n",
      "\n",
      "Step 6082 — Test metrics:\n",
      "  precision@10: 0.009348573\n",
      "  recall@10: 0.009356097\n",
      "  ndcg@10: 0.009385756\n",
      "  map@10: 0.002881793\n",
      "Epoch 32, Step 120, LR: 0.000446, Current Loss: 0.2533, Avg Loss: 0.2531\n",
      "Diff stats — min: -8.2284, max: 10.0000, mean: 3.2509, std: 2.6643\n",
      "\n",
      "Epoch 32, Step 140, LR: 0.000446, Current Loss: 0.2559, Avg Loss: 0.2528\n",
      "Diff stats — min: -9.5506, max: 10.0000, mean: 3.2120, std: 2.6490\n",
      "\n",
      "Step 6132 — Test metrics:\n",
      "  precision@10: 0.009209831\n",
      "  recall@10: 0.009218089\n",
      "  ndcg@10: 0.009241505\n",
      "  map@10: 0.002836896\n",
      "Epoch 32, Step 160, LR: 0.000446, Current Loss: 0.2537, Avg Loss: 0.2529\n",
      "Diff stats — min: -5.0787, max: 10.0000, mean: 3.1588, std: 2.6245\n",
      "\n",
      "Epoch 32, Step 180, LR: 0.000437, Current Loss: 0.2544, Avg Loss: 0.2530\n",
      "Diff stats — min: -6.8532, max: 10.0000, mean: 3.2147, std: 2.6315\n",
      "\n",
      "Epoch 32 completed, Train Loss: 0.000062\n",
      "\n",
      "Epoch 33, Step 1, LR: 0.000437, Current Loss: 0.2557, Avg Loss: 0.2557\n",
      "Diff stats — min: -5.5527, max: 10.0000, mean: 3.2079, std: 2.6686\n",
      "\n",
      "Step 6176 — Test metrics:\n",
      "  precision@10: 0.009454281\n",
      "  recall@10: 0.009463274\n",
      "  ndcg@10: 0.009596962\n",
      "  map@10: 0.002970883\n",
      "Epoch 33, Step 20, LR: 0.000437, Current Loss: 0.2486, Avg Loss: 0.2504\n",
      "Diff stats — min: -4.9758, max: 10.0000, mean: 3.2484, std: 2.6384\n",
      "\n",
      "Epoch 33, Step 40, LR: 0.000437, Current Loss: 0.2523, Avg Loss: 0.2508\n",
      "Diff stats — min: -6.0004, max: 10.0000, mean: 3.2760, std: 2.6680\n",
      "\n",
      "Step 6225 — Test metrics:\n",
      "  precision@10: 0.009480708\n",
      "  recall@10: 0.009488967\n",
      "  ndcg@10: 0.009614970\n",
      "  map@10: 0.002977794\n",
      "Epoch 33, Step 60, LR: 0.000437, Current Loss: 0.2450, Avg Loss: 0.2501\n",
      "Diff stats — min: -5.6979, max: 10.0000, mean: 3.2514, std: 2.6353\n",
      "\n",
      "Epoch 33, Step 80, LR: 0.000437, Current Loss: 0.2515, Avg Loss: 0.2499\n",
      "Diff stats — min: -5.9518, max: 10.0000, mean: 3.2377, std: 2.6575\n",
      "\n",
      "Epoch 33, Step 100, LR: 0.000437, Current Loss: 0.2361, Avg Loss: 0.2499\n",
      "Diff stats — min: -5.5828, max: 10.0000, mean: 3.3197, std: 2.6311\n",
      "\n",
      "Step 6275 — Test metrics:\n",
      "  precision@10: 0.009500529\n",
      "  recall@10: 0.009508787\n",
      "  ndcg@10: 0.009552134\n",
      "  map@10: 0.002924294\n",
      "Epoch 33, Step 120, LR: 0.000437, Current Loss: 0.2602, Avg Loss: 0.2502\n",
      "Diff stats — min: -5.6337, max: 10.0000, mean: 3.2529, std: 2.7210\n",
      "\n",
      "Epoch 33, Step 140, LR: 0.000428, Current Loss: 0.2503, Avg Loss: 0.2501\n",
      "Diff stats — min: -6.8262, max: 10.0000, mean: 3.2419, std: 2.6386\n",
      "\n",
      "Step 6325 — Test metrics:\n",
      "  precision@10: 0.009738372\n",
      "  recall@10: 0.009747365\n",
      "  ndcg@10: 0.009882246\n",
      "  map@10: 0.003060541\n",
      "Epoch 33, Step 160, LR: 0.000428, Current Loss: 0.2451, Avg Loss: 0.2499\n",
      "Diff stats — min: -5.9572, max: 10.0000, mean: 3.3506, std: 2.7088\n",
      "\n",
      "Epoch 33, Step 180, LR: 0.000428, Current Loss: 0.2307, Avg Loss: 0.2497\n",
      "Diff stats — min: -6.2028, max: 10.0000, mean: 3.3529, std: 2.6525\n",
      "\n",
      "Epoch 33 completed, Train Loss: 0.000061\n",
      "\n",
      "Epoch 34, Step 1, LR: 0.000428, Current Loss: 0.2425, Avg Loss: 0.2425\n",
      "Diff stats — min: -5.5351, max: 10.0000, mean: 3.3477, std: 2.7010\n",
      "\n",
      "Step 6369 — Test metrics:\n",
      "  precision@10: 0.009216438\n",
      "  recall@10: 0.009225430\n",
      "  ndcg@10: 0.009383549\n",
      "  map@10: 0.002903063\n",
      "Epoch 34, Step 20, LR: 0.000428, Current Loss: 0.2295, Avg Loss: 0.2444\n",
      "Diff stats — min: -4.6195, max: 10.0000, mean: 3.3074, std: 2.5851\n",
      "\n",
      "Epoch 34, Step 40, LR: 0.000428, Current Loss: 0.2441, Avg Loss: 0.2467\n",
      "Diff stats — min: -5.0104, max: 10.0000, mean: 3.3113, std: 2.6791\n",
      "\n",
      "Step 6418 — Test metrics:\n",
      "  precision@10: 0.009573203\n",
      "  recall@10: 0.009582930\n",
      "  ndcg@10: 0.009769257\n",
      "  map@10: 0.003039303\n",
      "Epoch 34, Step 60, LR: 0.000428, Current Loss: 0.2408, Avg Loss: 0.2458\n",
      "Diff stats — min: -6.6997, max: 10.0000, mean: 3.3227, std: 2.6812\n",
      "\n",
      "Epoch 34, Step 80, LR: 0.000428, Current Loss: 0.2402, Avg Loss: 0.2457\n",
      "Diff stats — min: -4.5441, max: 10.0000, mean: 3.3125, std: 2.6675\n",
      "\n",
      "Epoch 34, Step 100, LR: 0.000419, Current Loss: 0.2481, Avg Loss: 0.2458\n",
      "Diff stats — min: -6.7614, max: 10.0000, mean: 3.3602, std: 2.7170\n",
      "\n",
      "Step 6468 — Test metrics:\n",
      "  precision@10: 0.009493922\n",
      "  recall@10: 0.009503648\n",
      "  ndcg@10: 0.009563012\n",
      "  map@10: 0.002935184\n",
      "Epoch 34, Step 120, LR: 0.000419, Current Loss: 0.2674, Avg Loss: 0.2459\n",
      "Diff stats — min: -5.8259, max: 10.0000, mean: 3.2350, std: 2.7208\n",
      "\n",
      "Epoch 34, Step 140, LR: 0.000419, Current Loss: 0.2428, Avg Loss: 0.2461\n",
      "Diff stats — min: -5.5154, max: 10.0000, mean: 3.2610, std: 2.6119\n",
      "\n",
      "Step 6518 — Test metrics:\n",
      "  precision@10: 0.009758192\n",
      "  recall@10: 0.009768653\n",
      "  ndcg@10: 0.009772742\n",
      "  map@10: 0.002990507\n",
      "Epoch 34, Step 160, LR: 0.000419, Current Loss: 0.2450, Avg Loss: 0.2457\n",
      "Diff stats — min: -6.9689, max: 10.0000, mean: 3.3192, std: 2.6971\n",
      "\n",
      "Epoch 34, Step 180, LR: 0.000419, Current Loss: 0.2585, Avg Loss: 0.2459\n",
      "Diff stats — min: -5.5728, max: 10.0000, mean: 3.2635, std: 2.7374\n",
      "\n",
      "Epoch 34 completed, Train Loss: 0.000060\n",
      "\n",
      "Epoch 35, Step 1, LR: 0.000419, Current Loss: 0.2375, Avg Loss: 0.2375\n",
      "Diff stats — min: -4.5824, max: 10.0000, mean: 3.3618, std: 2.6948\n",
      "\n",
      "Step 6562 — Test metrics:\n",
      "  precision@10: 0.009778013\n",
      "  recall@10: 0.009787739\n",
      "  ndcg@10: 0.009908388\n",
      "  map@10: 0.003052203\n",
      "Epoch 35, Step 20, LR: 0.000419, Current Loss: 0.2442, Avg Loss: 0.2423\n",
      "Diff stats — min: -5.5892, max: 10.0000, mean: 3.2983, std: 2.6616\n",
      "\n",
      "Epoch 35, Step 40, LR: 0.000411, Current Loss: 0.2362, Avg Loss: 0.2424\n",
      "Diff stats — min: -5.2528, max: 10.0000, mean: 3.3572, std: 2.6692\n",
      "\n",
      "Step 6611 — Test metrics:\n",
      "  precision@10: 0.009388214\n",
      "  recall@10: 0.009397206\n",
      "  ndcg@10: 0.009435144\n",
      "  map@10: 0.002894247\n",
      "Epoch 35, Step 60, LR: 0.000411, Current Loss: 0.2485, Avg Loss: 0.2428\n",
      "Diff stats — min: -6.4286, max: 10.0000, mean: 3.3433, std: 2.7352\n",
      "\n",
      "Epoch 35, Step 80, LR: 0.000411, Current Loss: 0.2502, Avg Loss: 0.2440\n",
      "Diff stats — min: -5.3841, max: 10.0000, mean: 3.3154, std: 2.6970\n",
      "\n",
      "Epoch 35, Step 100, LR: 0.000411, Current Loss: 0.2564, Avg Loss: 0.2435\n",
      "Diff stats — min: -5.9914, max: 10.0000, mean: 3.3221, std: 2.7337\n",
      "\n",
      "Step 6661 — Test metrics:\n",
      "  precision@10: 0.009599630\n",
      "  recall@10: 0.009608623\n",
      "  ndcg@10: 0.009803897\n",
      "  map@10: 0.003047227\n",
      "Epoch 35, Step 120, LR: 0.000411, Current Loss: 0.2429, Avg Loss: 0.2432\n",
      "Diff stats — min: -5.9408, max: 10.0000, mean: 3.3838, std: 2.7112\n",
      "\n",
      "Epoch 35, Step 140, LR: 0.000411, Current Loss: 0.2464, Avg Loss: 0.2427\n",
      "Diff stats — min: -7.4017, max: 10.0000, mean: 3.3373, std: 2.7123\n",
      "\n",
      "Step 6711 — Test metrics:\n",
      "  precision@10: 0.009692125\n",
      "  recall@10: 0.009701117\n",
      "  ndcg@10: 0.009822572\n",
      "  map@10: 0.003032890\n",
      "Epoch 35, Step 160, LR: 0.000411, Current Loss: 0.2383, Avg Loss: 0.2429\n",
      "Diff stats — min: -4.3179, max: 10.0000, mean: 3.4075, std: 2.7312\n",
      "\n",
      "Epoch 35, Step 180, LR: 0.000411, Current Loss: 0.2500, Avg Loss: 0.2428\n",
      "Diff stats — min: -5.5787, max: 10.0000, mean: 3.4078, std: 2.7905\n",
      "\n",
      "Epoch 35 completed, Train Loss: 0.000059\n",
      "\n",
      "Epoch 36, Step 1, LR: 0.000403, Current Loss: 0.2373, Avg Loss: 0.2373\n",
      "Diff stats — min: -4.7978, max: 10.0000, mean: 3.3502, std: 2.6605\n",
      "\n",
      "Step 6755 — Test metrics:\n",
      "  precision@10: 0.009612844\n",
      "  recall@10: 0.009622570\n",
      "  ndcg@10: 0.009800838\n",
      "  map@10: 0.003044853\n",
      "Epoch 36, Step 20, LR: 0.000403, Current Loss: 0.2400, Avg Loss: 0.2373\n",
      "Diff stats — min: -5.1407, max: 10.0000, mean: 3.4070, std: 2.7377\n",
      "\n",
      "Epoch 36, Step 40, LR: 0.000403, Current Loss: 0.2332, Avg Loss: 0.2385\n",
      "Diff stats — min: -6.5126, max: 10.0000, mean: 3.4431, std: 2.7304\n",
      "\n",
      "Step 6804 — Test metrics:\n",
      "  precision@10: 0.009910148\n",
      "  recall@10: 0.009922077\n",
      "  ndcg@10: 0.010134300\n",
      "  map@10: 0.003158397\n",
      "Epoch 36, Step 60, LR: 0.000403, Current Loss: 0.2377, Avg Loss: 0.2384\n",
      "Diff stats — min: -6.2493, max: 10.0000, mean: 3.4332, std: 2.7552\n",
      "\n",
      "Epoch 36, Step 80, LR: 0.000403, Current Loss: 0.2435, Avg Loss: 0.2383\n",
      "Diff stats — min: -8.1561, max: 10.0000, mean: 3.3885, std: 2.7491\n",
      "\n",
      "Epoch 36, Step 100, LR: 0.000403, Current Loss: 0.2361, Avg Loss: 0.2388\n",
      "Diff stats — min: -5.7901, max: 10.0000, mean: 3.4263, std: 2.7406\n",
      "\n",
      "Step 6854 — Test metrics:\n",
      "  precision@10: 0.009929968\n",
      "  recall@10: 0.009939695\n",
      "  ndcg@10: 0.010026495\n",
      "  map@10: 0.003094170\n",
      "Epoch 36, Step 120, LR: 0.000403, Current Loss: 0.2436, Avg Loss: 0.2389\n",
      "Diff stats — min: -6.8481, max: 10.0000, mean: 3.4295, std: 2.7440\n",
      "\n",
      "Epoch 36, Step 140, LR: 0.000403, Current Loss: 0.2356, Avg Loss: 0.2391\n",
      "Diff stats — min: -5.1328, max: 10.0000, mean: 3.3978, std: 2.6978\n",
      "\n",
      "Step 6904 — Test metrics:\n",
      "  precision@10: 0.009910148\n",
      "  recall@10: 0.009918223\n",
      "  ndcg@10: 0.010110059\n",
      "  map@10: 0.003143438\n",
      "Epoch 36, Step 160, LR: 0.000395, Current Loss: 0.2427, Avg Loss: 0.2393\n",
      "Diff stats — min: -5.4160, max: 10.0000, mean: 3.4170, std: 2.7390\n",
      "\n",
      "Epoch 36, Step 180, LR: 0.000395, Current Loss: 0.2455, Avg Loss: 0.2393\n",
      "Diff stats — min: -6.4419, max: 10.0000, mean: 3.3690, std: 2.7175\n",
      "\n",
      "Epoch 36 completed, Train Loss: 0.000059\n",
      "\n",
      "Epoch 37, Step 1, LR: 0.000395, Current Loss: 0.2315, Avg Loss: 0.2315\n",
      "Diff stats — min: -6.2026, max: 10.0000, mean: 3.4449, std: 2.7254\n",
      "\n",
      "Step 6948 — Test metrics:\n",
      "  precision@10: 0.010055497\n",
      "  recall@10: 0.010064489\n",
      "  ndcg@10: 0.010275741\n",
      "  map@10: 0.003217403\n",
      "Epoch 37, Step 20, LR: 0.000395, Current Loss: 0.2466, Avg Loss: 0.2370\n",
      "Diff stats — min: -6.2543, max: 10.0000, mean: 3.4041, std: 2.7762\n",
      "\n",
      "Epoch 37, Step 40, LR: 0.000395, Current Loss: 0.2425, Avg Loss: 0.2378\n",
      "Diff stats — min: -5.5788, max: 10.0000, mean: 3.3843, std: 2.7209\n",
      "\n",
      "Step 6997 — Test metrics:\n",
      "  precision@10: 0.010062104\n",
      "  recall@10: 0.010072564\n",
      "  ndcg@10: 0.010058617\n",
      "  map@10: 0.003089719\n",
      "Epoch 37, Step 60, LR: 0.000395, Current Loss: 0.2405, Avg Loss: 0.2365\n",
      "Diff stats — min: -5.1520, max: 10.0000, mean: 3.4008, std: 2.7227\n",
      "\n",
      "Epoch 37, Step 80, LR: 0.000395, Current Loss: 0.2335, Avg Loss: 0.2366\n",
      "Diff stats — min: -5.6104, max: 10.0000, mean: 3.4669, std: 2.7377\n",
      "\n",
      "Epoch 37, Step 100, LR: 0.000395, Current Loss: 0.2276, Avg Loss: 0.2368\n",
      "Diff stats — min: -7.1313, max: 10.0000, mean: 3.5419, std: 2.7740\n",
      "\n",
      "Step 7047 — Test metrics:\n",
      "  precision@10: 0.010088531\n",
      "  recall@10: 0.010096606\n",
      "  ndcg@10: 0.010035150\n",
      "  map@10: 0.003071433\n",
      "Epoch 37, Step 120, LR: 0.000387, Current Loss: 0.2196, Avg Loss: 0.2365\n",
      "Diff stats — min: -6.7612, max: 10.0000, mean: 3.5257, std: 2.6974\n",
      "\n",
      "Epoch 37, Step 140, LR: 0.000387, Current Loss: 0.2272, Avg Loss: 0.2366\n",
      "Diff stats — min: -5.7616, max: 10.0000, mean: 3.4938, std: 2.7614\n",
      "\n",
      "Step 7097 — Test metrics:\n",
      "  precision@10: 0.010181025\n",
      "  recall@10: 0.010190752\n",
      "  ndcg@10: 0.010328875\n",
      "  map@10: 0.003207130\n",
      "Epoch 37, Step 160, LR: 0.000387, Current Loss: 0.2441, Avg Loss: 0.2364\n",
      "Diff stats — min: -5.6337, max: 10.0000, mean: 3.4549, std: 2.7908\n",
      "\n",
      "Epoch 37, Step 180, LR: 0.000387, Current Loss: 0.2293, Avg Loss: 0.2363\n",
      "Diff stats — min: -6.0519, max: 10.0000, mean: 3.4617, std: 2.7422\n",
      "\n",
      "Epoch 37 completed, Train Loss: 0.000058\n",
      "\n",
      "Epoch 38, Step 1, LR: 0.000387, Current Loss: 0.2308, Avg Loss: 0.2308\n",
      "Diff stats — min: -6.6301, max: 10.0000, mean: 3.5437, std: 2.7698\n",
      "\n",
      "Step 7141 — Test metrics:\n",
      "  precision@10: 0.010280127\n",
      "  recall@10: 0.010287468\n",
      "  ndcg@10: 0.010432673\n",
      "  map@10: 0.003241339\n",
      "Epoch 38, Step 20, LR: 0.000387, Current Loss: 0.2368, Avg Loss: 0.2331\n",
      "Diff stats — min: -5.0457, max: 10.0000, mean: 3.4458, std: 2.7281\n",
      "\n",
      "Epoch 38, Step 40, LR: 0.000387, Current Loss: 0.2450, Avg Loss: 0.2333\n",
      "Diff stats — min: -5.8172, max: 10.0000, mean: 3.4863, std: 2.8306\n",
      "\n",
      "Step 7190 — Test metrics:\n",
      "  precision@10: 0.009916755\n",
      "  recall@10: 0.009923362\n",
      "  ndcg@10: 0.010062126\n",
      "  map@10: 0.003132212\n",
      "Epoch 38, Step 60, LR: 0.000379, Current Loss: 0.2307, Avg Loss: 0.2346\n",
      "Diff stats — min: -6.2491, max: 10.0000, mean: 3.4558, std: 2.7267\n",
      "\n",
      "Epoch 38, Step 80, LR: 0.000379, Current Loss: 0.2346, Avg Loss: 0.2345\n",
      "Diff stats — min: -6.2383, max: 10.0000, mean: 3.4472, std: 2.7366\n",
      "\n",
      "Epoch 38, Step 100, LR: 0.000379, Current Loss: 0.2406, Avg Loss: 0.2345\n",
      "Diff stats — min: -4.8540, max: 10.0000, mean: 3.4873, std: 2.7771\n",
      "\n",
      "Step 7240 — Test metrics:\n",
      "  precision@10: 0.010154598\n",
      "  recall@10: 0.010161205\n",
      "  ndcg@10: 0.010269776\n",
      "  map@10: 0.003190655\n",
      "Epoch 38, Step 120, LR: 0.000379, Current Loss: 0.2400, Avg Loss: 0.2347\n",
      "Diff stats — min: -6.7043, max: 10.0000, mean: 3.4654, std: 2.7831\n",
      "\n",
      "Epoch 38, Step 140, LR: 0.000379, Current Loss: 0.2540, Avg Loss: 0.2349\n",
      "Diff stats — min: -8.0247, max: 10.0000, mean: 3.4022, std: 2.7976\n",
      "\n",
      "Step 7290 — Test metrics:\n",
      "  precision@10: 0.010273520\n",
      "  recall@10: 0.010280127\n",
      "  ndcg@10: 0.010416569\n",
      "  map@10: 0.003239085\n",
      "Epoch 38, Step 160, LR: 0.000379, Current Loss: 0.2349, Avg Loss: 0.2351\n",
      "Diff stats — min: -6.0446, max: 10.0000, mean: 3.4673, std: 2.7533\n",
      "\n",
      "Epoch 38, Step 180, LR: 0.000379, Current Loss: 0.2351, Avg Loss: 0.2348\n",
      "Diff stats — min: -6.1617, max: 10.0000, mean: 3.4766, std: 2.7464\n",
      "\n",
      "Epoch 38 completed, Train Loss: 0.000057\n",
      "\n",
      "Epoch 39, Step 1, LR: 0.000379, Current Loss: 0.2341, Avg Loss: 0.2341\n",
      "Diff stats — min: -5.1584, max: 10.0000, mean: 3.5386, std: 2.8049\n",
      "\n",
      "Step 7334 — Test metrics:\n",
      "  precision@10: 0.010181025\n",
      "  recall@10: 0.010188366\n",
      "  ndcg@10: 0.010138045\n",
      "  map@10: 0.003092675\n",
      "Epoch 39, Step 20, LR: 0.000372, Current Loss: 0.2333, Avg Loss: 0.2320\n",
      "Diff stats — min: -5.2601, max: 10.0000, mean: 3.5376, std: 2.8015\n",
      "\n",
      "Epoch 39, Step 40, LR: 0.000372, Current Loss: 0.2234, Avg Loss: 0.2311\n",
      "Diff stats — min: -6.2033, max: 10.0000, mean: 3.5134, std: 2.7573\n",
      "\n",
      "Step 7383 — Test metrics:\n",
      "  precision@10: 0.010412262\n",
      "  recall@10: 0.010420337\n",
      "  ndcg@10: 0.010645747\n",
      "  map@10: 0.003332872\n",
      "Epoch 39, Step 60, LR: 0.000372, Current Loss: 0.2360, Avg Loss: 0.2316\n",
      "Diff stats — min: -4.9178, max: 10.0000, mean: 3.5379, std: 2.7975\n",
      "\n",
      "Epoch 39, Step 80, LR: 0.000372, Current Loss: 0.2341, Avg Loss: 0.2317\n",
      "Diff stats — min: -5.6814, max: 10.0000, mean: 3.5078, std: 2.7943\n",
      "\n",
      "Epoch 39, Step 100, LR: 0.000372, Current Loss: 0.2455, Avg Loss: 0.2326\n",
      "Diff stats — min: -5.4529, max: 10.0000, mean: 3.3905, std: 2.7593\n",
      "\n",
      "Step 7433 — Test metrics:\n",
      "  precision@10: 0.010379228\n",
      "  recall@10: 0.010387303\n",
      "  ndcg@10: 0.010551980\n",
      "  map@10: 0.003280583\n",
      "Epoch 39, Step 120, LR: 0.000372, Current Loss: 0.2335, Avg Loss: 0.2320\n",
      "Diff stats — min: -7.1018, max: 10.0000, mean: 3.5196, std: 2.7827\n",
      "\n",
      "Epoch 39, Step 140, LR: 0.000372, Current Loss: 0.2361, Avg Loss: 0.2317\n",
      "Diff stats — min: -5.8625, max: 10.0000, mean: 3.5274, std: 2.7767\n",
      "\n",
      "Step 7483 — Test metrics:\n",
      "  precision@10: 0.010280127\n",
      "  recall@10: 0.010290404\n",
      "  ndcg@10: 0.010421965\n",
      "  map@10: 0.003231480\n",
      "Epoch 39, Step 160, LR: 0.000372, Current Loss: 0.2398, Avg Loss: 0.2315\n",
      "Diff stats — min: -6.1772, max: 10.0000, mean: 3.5559, std: 2.8293\n",
      "\n",
      "Epoch 39, Step 180, LR: 0.000364, Current Loss: 0.2279, Avg Loss: 0.2316\n",
      "Diff stats — min: -6.4650, max: 10.0000, mean: 3.5618, std: 2.7719\n",
      "\n",
      "Epoch 39 completed, Train Loss: 0.000057\n",
      "\n",
      "Epoch 40, Step 1, LR: 0.000364, Current Loss: 0.2367, Avg Loss: 0.2367\n",
      "Diff stats — min: -5.6031, max: 10.0000, mean: 3.5360, std: 2.8090\n",
      "\n",
      "Step 7527 — Test metrics:\n",
      "  precision@10: 0.010260307\n",
      "  recall@10: 0.010268381\n",
      "  ndcg@10: 0.010382305\n",
      "  map@10: 0.003215598\n",
      "Epoch 40, Step 20, LR: 0.000364, Current Loss: 0.2318, Avg Loss: 0.2312\n",
      "Diff stats — min: -7.6583, max: 10.0000, mean: 3.5709, std: 2.7997\n",
      "\n",
      "Epoch 40, Step 40, LR: 0.000364, Current Loss: 0.2419, Avg Loss: 0.2315\n",
      "Diff stats — min: -6.4152, max: 10.0000, mean: 3.4378, std: 2.7613\n",
      "\n",
      "Step 7576 — Test metrics:\n",
      "  precision@10: 0.009936575\n",
      "  recall@10: 0.009945384\n",
      "  ndcg@10: 0.010064691\n",
      "  map@10: 0.003106273\n",
      "Epoch 40, Step 60, LR: 0.000364, Current Loss: 0.2286, Avg Loss: 0.2302\n",
      "Diff stats — min: -5.8590, max: 10.0000, mean: 3.5892, std: 2.8102\n",
      "\n",
      "Epoch 40, Step 80, LR: 0.000364, Current Loss: 0.2496, Avg Loss: 0.2305\n",
      "Diff stats — min: -6.7109, max: 10.0000, mean: 3.5673, std: 2.8723\n",
      "\n",
      "Epoch 40, Step 100, LR: 0.000364, Current Loss: 0.2315, Avg Loss: 0.2308\n",
      "Diff stats — min: -6.0435, max: 10.0000, mean: 3.4714, std: 2.7473\n",
      "\n",
      "Step 7626 — Test metrics:\n",
      "  precision@10: 0.010240486\n",
      "  recall@10: 0.010247827\n",
      "  ndcg@10: 0.010437695\n",
      "  map@10: 0.003261059\n",
      "Epoch 40, Step 120, LR: 0.000364, Current Loss: 0.2277, Avg Loss: 0.2304\n",
      "Diff stats — min: -5.6423, max: 10.0000, mean: 3.5579, std: 2.8074\n",
      "\n",
      "Epoch 40, Step 140, LR: 0.000357, Current Loss: 0.2293, Avg Loss: 0.2308\n",
      "Diff stats — min: -6.9685, max: 10.0000, mean: 3.6078, std: 2.8476\n",
      "\n",
      "Step 7676 — Test metrics:\n",
      "  precision@10: 0.010610465\n",
      "  recall@10: 0.010620008\n",
      "  ndcg@10: 0.010775850\n",
      "  map@10: 0.003349205\n",
      "Epoch 40, Step 160, LR: 0.000357, Current Loss: 0.2362, Avg Loss: 0.2308\n",
      "Diff stats — min: -6.1513, max: 10.0000, mean: 3.5207, std: 2.7916\n",
      "\n",
      "Epoch 40, Step 180, LR: 0.000357, Current Loss: 0.2286, Avg Loss: 0.2308\n",
      "Diff stats — min: -5.2312, max: 10.0000, mean: 3.4891, std: 2.7581\n",
      "\n",
      "Epoch 40 completed, Train Loss: 0.000056\n",
      "\n",
      "Epoch 41, Step 1, LR: 0.000357, Current Loss: 0.2209, Avg Loss: 0.2209\n",
      "Diff stats — min: -5.7012, max: 10.0000, mean: 3.6317, std: 2.8029\n",
      "\n",
      "Step 7720 — Test metrics:\n",
      "  precision@10: 0.010551004\n",
      "  recall@10: 0.010560547\n",
      "  ndcg@10: 0.010755620\n",
      "  map@10: 0.003352956\n",
      "Epoch 41, Step 20, LR: 0.000357, Current Loss: 0.2461, Avg Loss: 0.2280\n",
      "Diff stats — min: -7.9266, max: 10.0000, mean: 3.5124, std: 2.8670\n",
      "\n",
      "Epoch 41, Step 40, LR: 0.000357, Current Loss: 0.2257, Avg Loss: 0.2282\n",
      "Diff stats — min: -6.3873, max: 10.0000, mean: 3.6030, std: 2.8021\n",
      "\n",
      "Step 7769 — Test metrics:\n",
      "  precision@10: 0.010517970\n",
      "  recall@10: 0.010526045\n",
      "  ndcg@10: 0.010732825\n",
      "  map@10: 0.003343179\n",
      "Epoch 41, Step 60, LR: 0.000357, Current Loss: 0.2235, Avg Loss: 0.2283\n",
      "Diff stats — min: -5.8737, max: 10.0000, mean: 3.6525, std: 2.8187\n",
      "\n",
      "Epoch 41, Step 80, LR: 0.000357, Current Loss: 0.2244, Avg Loss: 0.2283\n",
      "Diff stats — min: -7.4810, max: 10.0000, mean: 3.5635, std: 2.7685\n",
      "\n",
      "Epoch 41, Step 100, LR: 0.000350, Current Loss: 0.2431, Avg Loss: 0.2289\n",
      "Diff stats — min: -6.1414, max: 10.0000, mean: 3.6079, std: 2.8441\n",
      "\n",
      "Step 7819 — Test metrics:\n",
      "  precision@10: 0.010802061\n",
      "  recall@10: 0.010810870\n",
      "  ndcg@10: 0.011011743\n",
      "  map@10: 0.003450495\n",
      "Epoch 41, Step 120, LR: 0.000350, Current Loss: 0.2243, Avg Loss: 0.2286\n",
      "Diff stats — min: -5.7624, max: 10.0000, mean: 3.6475, std: 2.8547\n",
      "\n",
      "Epoch 41, Step 140, LR: 0.000350, Current Loss: 0.2249, Avg Loss: 0.2288\n",
      "Diff stats — min: -5.9220, max: 10.0000, mean: 3.6019, std: 2.7879\n",
      "\n",
      "Step 7869 — Test metrics:\n",
      "  precision@10: 0.010504757\n",
      "  recall@10: 0.010514300\n",
      "  ndcg@10: 0.010650496\n",
      "  map@10: 0.003310008\n",
      "Epoch 41, Step 160, LR: 0.000350, Current Loss: 0.2162, Avg Loss: 0.2288\n",
      "Diff stats — min: -6.5626, max: 10.0000, mean: 3.6655, std: 2.7917\n",
      "\n",
      "Epoch 41, Step 180, LR: 0.000350, Current Loss: 0.2242, Avg Loss: 0.2287\n",
      "Diff stats — min: -5.5743, max: 10.0000, mean: 3.6141, std: 2.8132\n",
      "\n",
      "Epoch 41 completed, Train Loss: 0.000056\n",
      "\n",
      "Epoch 42, Step 1, LR: 0.000350, Current Loss: 0.2325, Avg Loss: 0.2325\n",
      "Diff stats — min: -5.7185, max: 10.0000, mean: 3.5907, std: 2.8213\n",
      "\n",
      "Step 7913 — Test metrics:\n",
      "  precision@10: 0.010214059\n",
      "  recall@10: 0.010222868\n",
      "  ndcg@10: 0.010345193\n",
      "  map@10: 0.003215612\n",
      "Epoch 42, Step 20, LR: 0.000350, Current Loss: 0.2201, Avg Loss: 0.2251\n",
      "Diff stats — min: -4.9011, max: 10.0000, mean: 3.5869, std: 2.7754\n",
      "\n",
      "Epoch 42, Step 40, LR: 0.000343, Current Loss: 0.2298, Avg Loss: 0.2245\n",
      "Diff stats — min: -5.4317, max: 10.0000, mean: 3.6314, std: 2.8329\n",
      "\n",
      "Step 7962 — Test metrics:\n",
      "  precision@10: 0.010584038\n",
      "  recall@10: 0.010593581\n",
      "  ndcg@10: 0.010707790\n",
      "  map@10: 0.003327645\n",
      "Epoch 42, Step 60, LR: 0.000343, Current Loss: 0.2255, Avg Loss: 0.2240\n",
      "Diff stats — min: -5.4429, max: 10.0000, mean: 3.6644, std: 2.8439\n",
      "\n",
      "Epoch 42, Step 80, LR: 0.000343, Current Loss: 0.2206, Avg Loss: 0.2241\n",
      "Diff stats — min: -5.7981, max: 10.0000, mean: 3.6499, std: 2.8072\n",
      "\n",
      "Epoch 42, Step 100, LR: 0.000343, Current Loss: 0.2364, Avg Loss: 0.2245\n",
      "Diff stats — min: -6.2662, max: 10.0000, mean: 3.5691, std: 2.8377\n",
      "\n",
      "Step 8012 — Test metrics:\n",
      "  precision@10: 0.010689746\n",
      "  recall@10: 0.010697821\n",
      "  ndcg@10: 0.010781523\n",
      "  map@10: 0.003348091\n",
      "Epoch 42, Step 120, LR: 0.000343, Current Loss: 0.2220, Avg Loss: 0.2252\n",
      "Diff stats — min: -5.8018, max: 10.0000, mean: 3.6354, std: 2.8415\n",
      "\n",
      "Epoch 42, Step 140, LR: 0.000343, Current Loss: 0.2302, Avg Loss: 0.2254\n",
      "Diff stats — min: -5.1678, max: 10.0000, mean: 3.6737, std: 2.8559\n",
      "\n",
      "Step 8062 — Test metrics:\n",
      "  precision@10: 0.010458510\n",
      "  recall@10: 0.010466584\n",
      "  ndcg@10: 0.010647783\n",
      "  map@10: 0.003330503\n",
      "Epoch 42, Step 160, LR: 0.000343, Current Loss: 0.2257, Avg Loss: 0.2251\n",
      "Diff stats — min: -5.2269, max: 10.0000, mean: 3.6158, std: 2.8180\n",
      "\n",
      "Epoch 42, Step 180, LR: 0.000343, Current Loss: 0.2330, Avg Loss: 0.2254\n",
      "Diff stats — min: -6.6809, max: 10.0000, mean: 3.5821, std: 2.8436\n",
      "\n",
      "Epoch 42 completed, Train Loss: 0.000055\n",
      "\n",
      "Epoch 43, Step 1, LR: 0.000336, Current Loss: 0.2330, Avg Loss: 0.2330\n",
      "Diff stats — min: -5.4949, max: 10.0000, mean: 3.6120, std: 2.8432\n",
      "\n",
      "Step 8106 — Test metrics:\n",
      "  precision@10: 0.010280127\n",
      "  recall@10: 0.010288202\n",
      "  ndcg@10: 0.010554467\n",
      "  map@10: 0.003313562\n",
      "Epoch 43, Step 20, LR: 0.000336, Current Loss: 0.2247, Avg Loss: 0.2233\n",
      "Diff stats — min: -5.8430, max: 10.0000, mean: 3.6198, std: 2.8099\n",
      "\n",
      "Epoch 43, Step 40, LR: 0.000336, Current Loss: 0.2247, Avg Loss: 0.2241\n",
      "Diff stats — min: -5.9653, max: 10.0000, mean: 3.6362, std: 2.8235\n",
      "\n",
      "Step 8155 — Test metrics:\n",
      "  precision@10: 0.010557611\n",
      "  recall@10: 0.010564952\n",
      "  ndcg@10: 0.010829804\n",
      "  map@10: 0.003399915\n",
      "Epoch 43, Step 60, LR: 0.000336, Current Loss: 0.2265, Avg Loss: 0.2246\n",
      "Diff stats — min: -6.9092, max: 10.0000, mean: 3.6272, std: 2.8183\n",
      "\n",
      "Epoch 43, Step 80, LR: 0.000336, Current Loss: 0.2236, Avg Loss: 0.2241\n",
      "Diff stats — min: -7.5250, max: 10.0000, mean: 3.6567, std: 2.8371\n",
      "\n",
      "Epoch 43, Step 100, LR: 0.000336, Current Loss: 0.2239, Avg Loss: 0.2242\n",
      "Diff stats — min: -5.6916, max: 10.0000, mean: 3.7020, std: 2.8482\n",
      "\n",
      "Step 8205 — Test metrics:\n",
      "  precision@10: 0.010623679\n",
      "  recall@10: 0.010631754\n",
      "  ndcg@10: 0.010883472\n",
      "  map@10: 0.003415197\n",
      "Epoch 43, Step 120, LR: 0.000336, Current Loss: 0.2276, Avg Loss: 0.2241\n",
      "Diff stats — min: -5.9284, max: 10.0000, mean: 3.6386, std: 2.8516\n",
      "\n",
      "Epoch 43, Step 140, LR: 0.000336, Current Loss: 0.2199, Avg Loss: 0.2239\n",
      "Diff stats — min: -7.0941, max: 10.0000, mean: 3.6734, std: 2.8461\n",
      "\n",
      "Step 8255 — Test metrics:\n",
      "  precision@10: 0.010517970\n",
      "  recall@10: 0.010525311\n",
      "  ndcg@10: 0.010811956\n",
      "  map@10: 0.003399748\n",
      "Epoch 43, Step 160, LR: 0.000329, Current Loss: 0.2237, Avg Loss: 0.2241\n",
      "Diff stats — min: -5.6058, max: 10.0000, mean: 3.6554, std: 2.8305\n",
      "\n",
      "Epoch 43, Step 180, LR: 0.000329, Current Loss: 0.2119, Avg Loss: 0.2241\n",
      "Diff stats — min: -7.2203, max: 10.0000, mean: 3.6903, std: 2.8178\n",
      "\n",
      "Epoch 43 completed, Train Loss: 0.000055\n",
      "\n",
      "Epoch 44, Step 1, LR: 0.000329, Current Loss: 0.2235, Avg Loss: 0.2235\n",
      "Diff stats — min: -5.5813, max: 10.0000, mean: 3.6398, std: 2.8057\n",
      "\n",
      "Step 8299 — Test metrics:\n",
      "  precision@10: 0.010498150\n",
      "  recall@10: 0.010506959\n",
      "  ndcg@10: 0.010709502\n",
      "  map@10: 0.003338399\n",
      "Epoch 44, Step 20, LR: 0.000329, Current Loss: 0.2279, Avg Loss: 0.2202\n",
      "Diff stats — min: -7.0366, max: 10.0000, mean: 3.6428, std: 2.8274\n",
      "\n",
      "Epoch 44, Step 40, LR: 0.000329, Current Loss: 0.2251, Avg Loss: 0.2198\n",
      "Diff stats — min: -7.1538, max: 10.0000, mean: 3.6975, std: 2.8754\n",
      "\n",
      "Step 8348 — Test metrics:\n",
      "  precision@10: 0.010696353\n",
      "  recall@10: 0.010703694\n",
      "  ndcg@10: 0.011001226\n",
      "  map@10: 0.003459653\n",
      "Epoch 44, Step 60, LR: 0.000329, Current Loss: 0.2299, Avg Loss: 0.2204\n",
      "Diff stats — min: -6.3094, max: 10.0000, mean: 3.6973, std: 2.8663\n",
      "\n",
      "Epoch 44, Step 80, LR: 0.000329, Current Loss: 0.2190, Avg Loss: 0.2202\n",
      "Diff stats — min: -5.9979, max: 10.0000, mean: 3.6950, std: 2.8303\n",
      "\n",
      "Epoch 44, Step 100, LR: 0.000329, Current Loss: 0.2313, Avg Loss: 0.2208\n",
      "Diff stats — min: -5.3224, max: 10.0000, mean: 3.6388, std: 2.8530\n",
      "\n",
      "Step 8398 — Test metrics:\n",
      "  precision@10: 0.010451903\n",
      "  recall@10: 0.010460712\n",
      "  ndcg@10: 0.010722072\n",
      "  map@10: 0.003370168\n",
      "Epoch 44, Step 120, LR: 0.000323, Current Loss: 0.2298, Avg Loss: 0.2213\n",
      "Diff stats — min: -6.4337, max: 10.0000, mean: 3.6395, std: 2.8344\n",
      "\n",
      "Epoch 44, Step 140, LR: 0.000323, Current Loss: 0.2240, Avg Loss: 0.2213\n",
      "Diff stats — min: -5.3131, max: 10.0000, mean: 3.6785, std: 2.8536\n",
      "\n",
      "Step 8448 — Test metrics:\n",
      "  precision@10: 0.010227273\n",
      "  recall@10: 0.010233879\n",
      "  ndcg@10: 0.010466982\n",
      "  map@10: 0.003277596\n",
      "Epoch 44, Step 160, LR: 0.000323, Current Loss: 0.2334, Avg Loss: 0.2212\n",
      "Diff stats — min: -6.0895, max: 10.0000, mean: 3.7329, std: 2.9277\n",
      "\n",
      "Epoch 44, Step 180, LR: 0.000323, Current Loss: 0.2144, Avg Loss: 0.2212\n",
      "Diff stats — min: -4.6441, max: 10.0000, mean: 3.7184, std: 2.8458\n",
      "\n",
      "Epoch 44 completed, Train Loss: 0.000054\n",
      "\n",
      "Epoch 45, Step 1, LR: 0.000323, Current Loss: 0.2176, Avg Loss: 0.2176\n",
      "Diff stats — min: -5.7524, max: 10.0000, mean: 3.7032, std: 2.8582\n",
      "\n",
      "Step 8492 — Test metrics:\n",
      "  precision@10: 0.010683140\n",
      "  recall@10: 0.010691214\n",
      "  ndcg@10: 0.010901285\n",
      "  map@10: 0.003414241\n",
      "Epoch 45, Step 20, LR: 0.000323, Current Loss: 0.2343, Avg Loss: 0.2191\n",
      "Diff stats — min: -6.2497, max: 10.0000, mean: 3.6683, std: 2.9062\n",
      "\n",
      "Epoch 45, Step 40, LR: 0.000323, Current Loss: 0.2275, Avg Loss: 0.2201\n",
      "Diff stats — min: -6.6070, max: 10.0000, mean: 3.6514, std: 2.8561\n",
      "\n",
      "Step 8541 — Test metrics:\n",
      "  precision@10: 0.010293340\n",
      "  recall@10: 0.010300681\n",
      "  ndcg@10: 0.010537531\n",
      "  map@10: 0.003297694\n",
      "Epoch 45, Step 60, LR: 0.000316, Current Loss: 0.2324, Avg Loss: 0.2202\n",
      "Diff stats — min: -5.6896, max: 10.0000, mean: 3.7379, std: 2.9239\n",
      "\n",
      "Epoch 45, Step 80, LR: 0.000316, Current Loss: 0.2282, Avg Loss: 0.2209\n",
      "Diff stats — min: -5.8887, max: 10.0000, mean: 3.6871, std: 2.8816\n",
      "\n",
      "Epoch 45, Step 100, LR: 0.000316, Current Loss: 0.2151, Avg Loss: 0.2205\n",
      "Diff stats — min: -5.9097, max: 10.0000, mean: 3.7313, std: 2.8069\n",
      "\n",
      "Step 8591 — Test metrics:\n",
      "  precision@10: 0.010425476\n",
      "  recall@10: 0.010433551\n",
      "  ndcg@10: 0.010591851\n",
      "  map@10: 0.003300322\n",
      "Epoch 45, Step 120, LR: 0.000316, Current Loss: 0.2261, Avg Loss: 0.2206\n",
      "Diff stats — min: -6.3464, max: 10.0000, mean: 3.6909, std: 2.8632\n",
      "\n",
      "Epoch 45, Step 140, LR: 0.000316, Current Loss: 0.2227, Avg Loss: 0.2210\n",
      "Diff stats — min: -5.8534, max: 10.0000, mean: 3.7285, std: 2.8780\n",
      "\n",
      "Step 8641 — Test metrics:\n",
      "  precision@10: 0.010531184\n",
      "  recall@10: 0.010538525\n",
      "  ndcg@10: 0.010696404\n",
      "  map@10: 0.003325484\n",
      "Epoch 45, Step 160, LR: 0.000316, Current Loss: 0.2251, Avg Loss: 0.2213\n",
      "Diff stats — min: -5.3707, max: 10.0000, mean: 3.7093, std: 2.8823\n",
      "\n",
      "Epoch 45, Step 180, LR: 0.000316, Current Loss: 0.2319, Avg Loss: 0.2213\n",
      "Diff stats — min: -5.7090, max: 10.0000, mean: 3.7630, std: 2.9342\n",
      "\n",
      "Epoch 45 completed, Train Loss: 0.000054\n",
      "\n",
      "Epoch 46, Step 1, LR: 0.000316, Current Loss: 0.2266, Avg Loss: 0.2266\n",
      "Diff stats — min: -6.8052, max: 10.0000, mean: 3.6685, std: 2.8248\n",
      "\n",
      "Step 8685 — Test metrics:\n",
      "  precision@10: 0.010564218\n",
      "  recall@10: 0.010572293\n",
      "  ndcg@10: 0.010734651\n",
      "  map@10: 0.003342671\n",
      "Epoch 46, Step 20, LR: 0.000310, Current Loss: 0.2212, Avg Loss: 0.2216\n",
      "Diff stats — min: -5.3386, max: 10.0000, mean: 3.7386, std: 2.9077\n",
      "\n",
      "Epoch 46, Step 40, LR: 0.000310, Current Loss: 0.2207, Avg Loss: 0.2198\n",
      "Diff stats — min: -8.2095, max: 10.0000, mean: 3.6946, std: 2.8862\n",
      "\n",
      "Step 8734 — Test metrics:\n",
      "  precision@10: 0.010603858\n",
      "  recall@10: 0.010612667\n",
      "  ndcg@10: 0.010793829\n",
      "  map@10: 0.003361168\n",
      "Epoch 46, Step 60, LR: 0.000310, Current Loss: 0.2106, Avg Loss: 0.2196\n",
      "Diff stats — min: -7.7696, max: 10.0000, mean: 3.7446, std: 2.8587\n",
      "\n",
      "Epoch 46, Step 80, LR: 0.000310, Current Loss: 0.2157, Avg Loss: 0.2190\n",
      "Diff stats — min: -4.6138, max: 10.0000, mean: 3.7747, std: 2.8707\n",
      "\n",
      "Epoch 46, Step 100, LR: 0.000310, Current Loss: 0.2273, Avg Loss: 0.2189\n",
      "Diff stats — min: -5.2696, max: 10.0000, mean: 3.6874, std: 2.8783\n",
      "\n",
      "Step 8784 — Test metrics:\n",
      "  precision@10: 0.010603858\n",
      "  recall@10: 0.010611933\n",
      "  ndcg@10: 0.010867042\n",
      "  map@10: 0.003416064\n",
      "Epoch 46, Step 120, LR: 0.000310, Current Loss: 0.2149, Avg Loss: 0.2192\n",
      "Diff stats — min: -5.1073, max: 10.0000, mean: 3.7742, std: 2.8512\n",
      "\n",
      "Epoch 46, Step 140, LR: 0.000310, Current Loss: 0.2147, Avg Loss: 0.2189\n",
      "Diff stats — min: -5.7381, max: 10.0000, mean: 3.8188, std: 2.8680\n",
      "\n",
      "Step 8834 — Test metrics:\n",
      "  precision@10: 0.010696353\n",
      "  recall@10: 0.010704428\n",
      "  ndcg@10: 0.010992002\n",
      "  map@10: 0.003469395\n",
      "Epoch 46, Step 160, LR: 0.000310, Current Loss: 0.2001, Avg Loss: 0.2187\n",
      "Diff stats — min: -4.9544, max: 10.0000, mean: 3.8166, std: 2.8412\n",
      "\n",
      "Epoch 46, Step 180, LR: 0.000304, Current Loss: 0.2218, Avg Loss: 0.2188\n",
      "Diff stats — min: -5.1439, max: 10.0000, mean: 3.8007, std: 2.9246\n",
      "\n",
      "Epoch 46 completed, Train Loss: 0.000054\n",
      "\n",
      "Epoch 47, Step 1, LR: 0.000304, Current Loss: 0.2109, Avg Loss: 0.2109\n",
      "Diff stats — min: -4.8703, max: 10.0000, mean: 3.8321, std: 2.8992\n",
      "\n",
      "Step 8878 — Test metrics:\n",
      "  precision@10: 0.010392442\n",
      "  recall@10: 0.010400517\n",
      "  ndcg@10: 0.010773491\n",
      "  map@10: 0.003400835\n",
      "Epoch 47, Step 20, LR: 0.000304, Current Loss: 0.2055, Avg Loss: 0.2123\n",
      "Diff stats — min: -4.8339, max: 10.0000, mean: 3.8823, std: 2.8966\n",
      "\n",
      "Epoch 47, Step 40, LR: 0.000304, Current Loss: 0.2150, Avg Loss: 0.2149\n",
      "Diff stats — min: -6.0959, max: 10.0000, mean: 3.7789, std: 2.8701\n",
      "\n",
      "Step 8927 — Test metrics:\n",
      "  precision@10: 0.010808668\n",
      "  recall@10: 0.010816743\n",
      "  ndcg@10: 0.011079997\n",
      "  map@10: 0.003477092\n",
      "Epoch 47, Step 60, LR: 0.000304, Current Loss: 0.2120, Avg Loss: 0.2163\n",
      "Diff stats — min: -8.7626, max: 10.0000, mean: 3.7938, std: 2.8559\n",
      "\n",
      "Epoch 47, Step 80, LR: 0.000304, Current Loss: 0.2168, Avg Loss: 0.2163\n",
      "Diff stats — min: -6.0945, max: 10.0000, mean: 3.7197, std: 2.8308\n",
      "\n",
      "Epoch 47, Step 100, LR: 0.000304, Current Loss: 0.2155, Avg Loss: 0.2159\n",
      "Diff stats — min: -5.8402, max: 10.0000, mean: 3.8009, std: 2.8860\n",
      "\n",
      "Step 8977 — Test metrics:\n",
      "  precision@10: 0.010517970\n",
      "  recall@10: 0.010523843\n",
      "  ndcg@10: 0.010856172\n",
      "  map@10: 0.003433476\n",
      "Epoch 47, Step 120, LR: 0.000304, Current Loss: 0.2237, Avg Loss: 0.2162\n",
      "Diff stats — min: -9.1455, max: 10.0000, mean: 3.7584, std: 2.8890\n",
      "\n",
      "Epoch 47, Step 140, LR: 0.000298, Current Loss: 0.2227, Avg Loss: 0.2164\n",
      "Diff stats — min: -8.0462, max: 10.0000, mean: 3.7203, std: 2.8792\n",
      "\n",
      "Step 9027 — Test metrics:\n",
      "  precision@10: 0.010247093\n",
      "  recall@10: 0.010255168\n",
      "  ndcg@10: 0.010565957\n",
      "  map@10: 0.003323246\n",
      "Epoch 47, Step 160, LR: 0.000298, Current Loss: 0.2137, Avg Loss: 0.2165\n",
      "Diff stats — min: -5.7426, max: 10.0000, mean: 3.7648, std: 2.8839\n",
      "\n",
      "Epoch 47, Step 180, LR: 0.000298, Current Loss: 0.2303, Avg Loss: 0.2164\n",
      "Diff stats — min: -7.2146, max: 10.0000, mean: 3.7956, std: 2.9511\n",
      "\n",
      "Epoch 47 completed, Train Loss: 0.000053\n",
      "\n",
      "Epoch 48, Step 1, LR: 0.000298, Current Loss: 0.1986, Avg Loss: 0.1986\n",
      "Diff stats — min: -5.1267, max: 10.0000, mean: 3.8887, std: 2.8603\n",
      "\n",
      "Step 9071 — Test metrics:\n",
      "  precision@10: 0.010524577\n",
      "  recall@10: 0.010531918\n",
      "  ndcg@10: 0.010872882\n",
      "  map@10: 0.003432807\n",
      "Epoch 48, Step 20, LR: 0.000298, Current Loss: 0.2039, Avg Loss: 0.2141\n",
      "Diff stats — min: -4.5528, max: 10.0000, mean: 3.7731, std: 2.8371\n",
      "\n",
      "Epoch 48, Step 40, LR: 0.000298, Current Loss: 0.2189, Avg Loss: 0.2140\n",
      "Diff stats — min: -5.5095, max: 10.0000, mean: 3.7511, std: 2.8473\n",
      "\n",
      "Step 9120 — Test metrics:\n",
      "  precision@10: 0.010491543\n",
      "  recall@10: 0.010500352\n",
      "  ndcg@10: 0.010717871\n",
      "  map@10: 0.003344568\n",
      "Epoch 48, Step 60, LR: 0.000298, Current Loss: 0.2118, Avg Loss: 0.2149\n",
      "Diff stats — min: -6.9885, max: 10.0000, mean: 3.7899, std: 2.8913\n",
      "\n",
      "Epoch 48, Step 80, LR: 0.000292, Current Loss: 0.2048, Avg Loss: 0.2140\n",
      "Diff stats — min: -5.2205, max: 10.0000, mean: 3.8357, std: 2.8605\n",
      "\n",
      "Epoch 48, Step 100, LR: 0.000292, Current Loss: 0.2115, Avg Loss: 0.2141\n",
      "Diff stats — min: -6.3698, max: 10.0000, mean: 3.8636, std: 2.9492\n",
      "\n",
      "Step 9170 — Test metrics:\n",
      "  precision@10: 0.010425476\n",
      "  recall@10: 0.010432817\n",
      "  ndcg@10: 0.010648098\n",
      "  map@10: 0.003336220\n",
      "Epoch 48, Step 120, LR: 0.000292, Current Loss: 0.2309, Avg Loss: 0.2146\n",
      "Diff stats — min: -5.7592, max: 10.0000, mean: 3.8236, std: 2.9866\n",
      "\n",
      "Epoch 48, Step 140, LR: 0.000292, Current Loss: 0.2214, Avg Loss: 0.2147\n",
      "Diff stats — min: -5.5172, max: 10.0000, mean: 3.8008, std: 2.9210\n",
      "\n",
      "Step 9220 — Test metrics:\n",
      "  precision@10: 0.010504757\n",
      "  recall@10: 0.010511364\n",
      "  ndcg@10: 0.010863875\n",
      "  map@10: 0.003446186\n",
      "Epoch 48, Step 160, LR: 0.000292, Current Loss: 0.2066, Avg Loss: 0.2148\n",
      "Diff stats — min: -6.5029, max: 10.0000, mean: 3.8399, std: 2.9136\n",
      "\n",
      "Epoch 48, Step 180, LR: 0.000292, Current Loss: 0.2150, Avg Loss: 0.2147\n",
      "Diff stats — min: -6.8920, max: 10.0000, mean: 3.8120, std: 2.9210\n",
      "\n",
      "Epoch 48 completed, Train Loss: 0.000053\n",
      "\n",
      "Epoch 49, Step 1, LR: 0.000292, Current Loss: 0.2146, Avg Loss: 0.2146\n",
      "Diff stats — min: -8.8229, max: 10.0000, mean: 3.8007, std: 2.8962\n",
      "\n",
      "Step 9264 — Test metrics:\n",
      "  precision@10: 0.010075317\n",
      "  recall@10: 0.010082658\n",
      "  ndcg@10: 0.010334749\n",
      "  map@10: 0.003240465\n",
      "Epoch 49, Step 20, LR: 0.000292, Current Loss: 0.2071, Avg Loss: 0.2168\n",
      "Diff stats — min: -5.5688, max: 10.0000, mean: 3.8482, std: 2.8855\n",
      "\n",
      "Epoch 49, Step 40, LR: 0.000286, Current Loss: 0.2385, Avg Loss: 0.2161\n",
      "Diff stats — min: -5.7004, max: 10.0000, mean: 3.7323, std: 2.9539\n",
      "\n",
      "Step 9313 — Test metrics:\n",
      "  precision@10: 0.010299947\n",
      "  recall@10: 0.010308022\n",
      "  ndcg@10: 0.010577081\n",
      "  map@10: 0.003333009\n",
      "Epoch 49, Step 60, LR: 0.000286, Current Loss: 0.2220, Avg Loss: 0.2164\n",
      "Diff stats — min: -7.1571, max: 10.0000, mean: 3.8455, std: 2.9421\n",
      "\n",
      "Epoch 49, Step 80, LR: 0.000286, Current Loss: 0.2116, Avg Loss: 0.2158\n",
      "Diff stats — min: -4.9513, max: 10.0000, mean: 3.8614, std: 2.9070\n",
      "\n",
      "Epoch 49, Step 100, LR: 0.000286, Current Loss: 0.2120, Avg Loss: 0.2148\n",
      "Diff stats — min: -5.3869, max: 10.0000, mean: 3.8029, std: 2.8900\n",
      "\n",
      "Step 9363 — Test metrics:\n",
      "  precision@10: 0.010451903\n",
      "  recall@10: 0.010459244\n",
      "  ndcg@10: 0.010698050\n",
      "  map@10: 0.003365314\n",
      "Epoch 49, Step 120, LR: 0.000286, Current Loss: 0.2152, Avg Loss: 0.2146\n",
      "Diff stats — min: -5.7169, max: 10.0000, mean: 3.8697, std: 2.9494\n",
      "\n",
      "Epoch 49, Step 140, LR: 0.000286, Current Loss: 0.2222, Avg Loss: 0.2148\n",
      "Diff stats — min: -6.0844, max: 10.0000, mean: 3.8811, std: 2.9603\n",
      "\n",
      "Step 9413 — Test metrics:\n",
      "  precision@10: 0.010332981\n",
      "  recall@10: 0.010338854\n",
      "  ndcg@10: 0.010595190\n",
      "  map@10: 0.003324388\n",
      "Epoch 49, Step 160, LR: 0.000286, Current Loss: 0.2180, Avg Loss: 0.2149\n",
      "Diff stats — min: -5.5080, max: 10.0000, mean: 3.8827, std: 2.9715\n",
      "\n",
      "Epoch 49, Step 180, LR: 0.000286, Current Loss: 0.2151, Avg Loss: 0.2150\n",
      "Diff stats — min: -5.9420, max: 10.0000, mean: 3.8892, std: 2.9543\n",
      "\n",
      "Epoch 49 completed, Train Loss: 0.000053\n",
      "\n",
      "Epoch 50, Step 1, LR: 0.000280, Current Loss: 0.2054, Avg Loss: 0.2054\n",
      "Diff stats — min: -6.2365, max: 10.0000, mean: 3.8452, std: 2.8988\n",
      "\n",
      "Step 9457 — Test metrics:\n",
      "  precision@10: 0.010504757\n",
      "  recall@10: 0.010509895\n",
      "  ndcg@10: 0.010794299\n",
      "  map@10: 0.003402584\n",
      "Epoch 50, Step 20, LR: 0.000280, Current Loss: 0.2165, Avg Loss: 0.2132\n",
      "Diff stats — min: -7.0534, max: 10.0000, mean: 3.8828, std: 2.9718\n",
      "\n",
      "Epoch 50, Step 40, LR: 0.000280, Current Loss: 0.2195, Avg Loss: 0.2122\n",
      "Diff stats — min: -6.2067, max: 10.0000, mean: 3.8666, std: 2.9456\n",
      "\n",
      "Step 9506 — Test metrics:\n",
      "  precision@10: 0.010531184\n",
      "  recall@10: 0.010538525\n",
      "  ndcg@10: 0.010678457\n",
      "  map@10: 0.003324186\n",
      "Epoch 50, Step 60, LR: 0.000280, Current Loss: 0.2152, Avg Loss: 0.2119\n",
      "Diff stats — min: -7.5439, max: 10.0000, mean: 3.8434, std: 2.9248\n",
      "\n",
      "Epoch 50, Step 80, LR: 0.000280, Current Loss: 0.2082, Avg Loss: 0.2111\n",
      "Diff stats — min: -6.0492, max: 10.0000, mean: 3.9164, std: 2.9694\n",
      "\n",
      "Epoch 50, Step 100, LR: 0.000280, Current Loss: 0.2205, Avg Loss: 0.2118\n",
      "Diff stats — min: -6.0157, max: 10.0000, mean: 3.8257, std: 2.9507\n",
      "\n",
      "Step 9556 — Test metrics:\n",
      "  precision@10: 0.010484937\n",
      "  recall@10: 0.010490809\n",
      "  ndcg@10: 0.010665524\n",
      "  map@10: 0.003325570\n",
      "Epoch 50, Step 120, LR: 0.000280, Current Loss: 0.2136, Avg Loss: 0.2116\n",
      "Diff stats — min: -7.0930, max: 10.0000, mean: 3.9029, std: 2.9524\n",
      "\n",
      "Epoch 50, Step 140, LR: 0.000280, Current Loss: 0.2157, Avg Loss: 0.2118\n",
      "Diff stats — min: -5.5489, max: 10.0000, mean: 3.8401, std: 2.9382\n",
      "\n",
      "Step 9606 — Test metrics:\n",
      "  precision@10: 0.010524577\n",
      "  recall@10: 0.010531184\n",
      "  ndcg@10: 0.010723142\n",
      "  map@10: 0.003353405\n",
      "Epoch 50, Step 160, LR: 0.000274, Current Loss: 0.2245, Avg Loss: 0.2119\n",
      "Diff stats — min: -8.1600, max: 10.0000, mean: 3.8840, std: 2.9853\n",
      "\n",
      "Epoch 50, Step 180, LR: 0.000274, Current Loss: 0.2172, Avg Loss: 0.2122\n",
      "Diff stats — min: -7.6009, max: 10.0000, mean: 3.8645, std: 2.9567\n",
      "\n",
      "Epoch 50 completed, Train Loss: 0.000052\n",
      "\n",
      "Epoch 51, Step 1, LR: 0.000274, Current Loss: 0.2042, Avg Loss: 0.2042\n",
      "Diff stats — min: -6.5773, max: 10.0000, mean: 3.9108, std: 2.9068\n",
      "\n",
      "Step 9650 — Test metrics:\n",
      "  precision@10: 0.010405655\n",
      "  recall@10: 0.010411528\n",
      "  ndcg@10: 0.010589364\n",
      "  map@10: 0.003306158\n",
      "Epoch 51, Step 20, LR: 0.000274, Current Loss: 0.2182, Avg Loss: 0.2098\n",
      "Diff stats — min: -4.7660, max: 10.0000, mean: 3.8202, std: 2.9237\n",
      "\n",
      "Epoch 51, Step 40, LR: 0.000274, Current Loss: 0.2124, Avg Loss: 0.2105\n",
      "Diff stats — min: -5.6213, max: 10.0000, mean: 3.9094, std: 2.9468\n",
      "\n",
      "Step 9699 — Test metrics:\n",
      "  precision@10: 0.010412262\n",
      "  recall@10: 0.010419603\n",
      "  ndcg@10: 0.010628232\n",
      "  map@10: 0.003322729\n",
      "Epoch 51, Step 60, LR: 0.000274, Current Loss: 0.2104, Avg Loss: 0.2104\n",
      "Diff stats — min: -7.0781, max: 10.0000, mean: 3.9091, std: 2.9239\n",
      "\n",
      "Epoch 51, Step 80, LR: 0.000274, Current Loss: 0.2201, Avg Loss: 0.2104\n",
      "Diff stats — min: -6.7137, max: 10.0000, mean: 3.8611, std: 2.9468\n",
      "\n",
      "Epoch 51, Step 100, LR: 0.000274, Current Loss: 0.2212, Avg Loss: 0.2108\n",
      "Diff stats — min: -8.0143, max: 10.0000, mean: 3.8417, std: 2.9616\n",
      "\n",
      "Step 9749 — Test metrics:\n",
      "  precision@10: 0.010590645\n",
      "  recall@10: 0.010597252\n",
      "  ndcg@10: 0.010874592\n",
      "  map@10: 0.003432476\n",
      "Epoch 51, Step 120, LR: 0.000269, Current Loss: 0.2186, Avg Loss: 0.2113\n",
      "Diff stats — min: -6.4447, max: 10.0000, mean: 3.8140, std: 2.9430\n",
      "\n",
      "Epoch 51, Step 140, LR: 0.000269, Current Loss: 0.2035, Avg Loss: 0.2113\n",
      "Diff stats — min: -5.0487, max: 10.0000, mean: 3.8851, std: 2.9103\n",
      "\n",
      "Step 9799 — Test metrics:\n",
      "  precision@10: 0.010570825\n",
      "  recall@10: 0.010577431\n",
      "  ndcg@10: 0.010826039\n",
      "  map@10: 0.003394650\n",
      "Epoch 51, Step 160, LR: 0.000269, Current Loss: 0.2036, Avg Loss: 0.2113\n",
      "Diff stats — min: -5.3199, max: 10.0000, mean: 3.9048, std: 2.9109\n",
      "\n",
      "Epoch 51, Step 180, LR: 0.000269, Current Loss: 0.2107, Avg Loss: 0.2115\n",
      "Diff stats — min: -5.8277, max: 10.0000, mean: 3.8196, std: 2.8961\n",
      "\n",
      "Epoch 51 completed, Train Loss: 0.000052\n",
      "\n",
      "Epoch 52, Step 1, LR: 0.000269, Current Loss: 0.2086, Avg Loss: 0.2086\n",
      "Diff stats — min: -5.0081, max: 10.0000, mean: 3.9249, std: 2.9037\n",
      "\n",
      "Step 9843 — Test metrics:\n",
      "  precision@10: 0.010491543\n",
      "  recall@10: 0.010499618\n",
      "  ndcg@10: 0.010745748\n",
      "  map@10: 0.003370799\n",
      "Epoch 52, Step 20, LR: 0.000269, Current Loss: 0.2106, Avg Loss: 0.2081\n",
      "Diff stats — min: -6.8542, max: 10.0000, mean: 3.8829, std: 2.9375\n",
      "\n",
      "Epoch 52, Step 40, LR: 0.000269, Current Loss: 0.2124, Avg Loss: 0.2104\n",
      "Diff stats — min: -5.9435, max: 10.0000, mean: 3.9147, std: 2.9470\n",
      "\n",
      "Step 9892 — Test metrics:\n",
      "  precision@10: 0.010504757\n",
      "  recall@10: 0.010512098\n",
      "  ndcg@10: 0.010764384\n",
      "  map@10: 0.003379656\n",
      "Epoch 52, Step 60, LR: 0.000264, Current Loss: 0.2126, Avg Loss: 0.2105\n",
      "Diff stats — min: -5.0851, max: 10.0000, mean: 3.9087, std: 2.9755\n",
      "\n",
      "Epoch 52, Step 80, LR: 0.000264, Current Loss: 0.2141, Avg Loss: 0.2111\n",
      "Diff stats — min: -5.1575, max: 10.0000, mean: 3.8224, std: 2.9098\n",
      "\n",
      "Epoch 52, Step 100, LR: 0.000264, Current Loss: 0.2013, Avg Loss: 0.2105\n",
      "Diff stats — min: -5.3900, max: 10.0000, mean: 3.9804, std: 2.9788\n",
      "\n",
      "Step 9942 — Test metrics:\n",
      "  precision@10: 0.010517970\n",
      "  recall@10: 0.010524577\n",
      "  ndcg@10: 0.010813156\n",
      "  map@10: 0.003405200\n",
      "Epoch 52, Step 120, LR: 0.000264, Current Loss: 0.2080, Avg Loss: 0.2109\n",
      "Diff stats — min: -6.1265, max: 10.0000, mean: 3.9343, std: 2.9798\n",
      "\n",
      "Epoch 52, Step 140, LR: 0.000264, Current Loss: 0.2199, Avg Loss: 0.2111\n",
      "Diff stats — min: -6.4782, max: 10.0000, mean: 3.8540, std: 2.9991\n",
      "\n",
      "Step 9992 — Test metrics:\n",
      "  precision@10: 0.010465116\n",
      "  recall@10: 0.010472457\n",
      "  ndcg@10: 0.010777514\n",
      "  map@10: 0.003397455\n",
      "Epoch 52, Step 160, LR: 0.000264, Current Loss: 0.2033, Avg Loss: 0.2110\n",
      "Diff stats — min: -5.4942, max: 10.0000, mean: 3.9345, std: 2.9470\n",
      "\n",
      "Epoch 52, Step 180, LR: 0.000264, Current Loss: 0.2114, Avg Loss: 0.2110\n",
      "Diff stats — min: -8.6262, max: 10.0000, mean: 3.9345, std: 2.9907\n",
      "\n",
      "Epoch 52 completed, Train Loss: 0.000052\n",
      "\n",
      "Epoch 53, Step 1, LR: 0.000264, Current Loss: 0.2143, Avg Loss: 0.2143\n",
      "Diff stats — min: -5.4244, max: 10.0000, mean: 3.8630, std: 2.9443\n",
      "\n",
      "Step 10036 — Test metrics:\n",
      "  precision@10: 0.010451903\n",
      "  recall@10: 0.010459978\n",
      "  ndcg@10: 0.010708042\n",
      "  map@10: 0.003365842\n",
      "Epoch 53, Step 20, LR: 0.000258, Current Loss: 0.2146, Avg Loss: 0.2061\n",
      "Diff stats — min: -4.6714, max: 10.0000, mean: 3.8618, std: 2.9340\n",
      "\n",
      "Epoch 53, Step 40, LR: 0.000258, Current Loss: 0.2065, Avg Loss: 0.2078\n",
      "Diff stats — min: -5.7267, max: 10.0000, mean: 3.9209, std: 2.9417\n",
      "\n",
      "Step 10085 — Test metrics:\n",
      "  precision@10: 0.010412262\n",
      "  recall@10: 0.010419603\n",
      "  ndcg@10: 0.010673570\n",
      "  map@10: 0.003354913\n",
      "Epoch 53, Step 60, LR: 0.000258, Current Loss: 0.2032, Avg Loss: 0.2084\n",
      "Diff stats — min: -8.3190, max: 10.0000, mean: 3.9273, std: 2.8974\n",
      "\n",
      "Epoch 53, Step 80, LR: 0.000258, Current Loss: 0.2156, Avg Loss: 0.2090\n",
      "Diff stats — min: -5.6618, max: 10.0000, mean: 3.9473, std: 2.9828\n",
      "\n",
      "Epoch 53, Step 100, LR: 0.000258, Current Loss: 0.2044, Avg Loss: 0.2094\n",
      "Diff stats — min: -5.7197, max: 10.0000, mean: 3.9352, std: 2.9357\n",
      "\n",
      "Step 10135 — Test metrics:\n",
      "  precision@10: 0.010676533\n",
      "  recall@10: 0.010683874\n",
      "  ndcg@10: 0.010785336\n",
      "  map@10: 0.003354571\n",
      "Epoch 53, Step 120, LR: 0.000258, Current Loss: 0.1996, Avg Loss: 0.2097\n",
      "Diff stats — min: -5.6507, max: 10.0000, mean: 3.9686, std: 2.9236\n",
      "\n",
      "Epoch 53, Step 140, LR: 0.000258, Current Loss: 0.2043, Avg Loss: 0.2096\n",
      "Diff stats — min: -6.4231, max: 10.0000, mean: 3.9434, std: 2.9360\n",
      "\n",
      "Step 10185 — Test metrics:\n",
      "  precision@10: 0.010802061\n",
      "  recall@10: 0.010810136\n",
      "  ndcg@10: 0.011237575\n",
      "  map@10: 0.003581538\n",
      "Epoch 53, Step 160, LR: 0.000258, Current Loss: 0.1955, Avg Loss: 0.2093\n",
      "Diff stats — min: -5.3144, max: 10.0000, mean: 4.0369, std: 2.9668\n",
      "\n",
      "Epoch 53, Step 180, LR: 0.000253, Current Loss: 0.2056, Avg Loss: 0.2093\n",
      "Diff stats — min: -6.2696, max: 10.0000, mean: 3.9537, std: 2.9441\n",
      "\n",
      "Epoch 53 completed, Train Loss: 0.000051\n",
      "\n",
      "Epoch 54, Step 1, LR: 0.000253, Current Loss: 0.1973, Avg Loss: 0.1973\n",
      "Diff stats — min: -4.7793, max: 10.0000, mean: 4.0224, std: 2.9414\n",
      "\n",
      "Step 10229 — Test metrics:\n",
      "  precision@10: 0.010887949\n",
      "  recall@10: 0.010894556\n",
      "  ndcg@10: 0.011188950\n",
      "  map@10: 0.003530839\n",
      "Epoch 54, Step 20, LR: 0.000253, Current Loss: 0.2053, Avg Loss: 0.2085\n",
      "Diff stats — min: -6.0658, max: 10.0000, mean: 3.8967, std: 2.9206\n",
      "\n",
      "Epoch 54, Step 40, LR: 0.000253, Current Loss: 0.2081, Avg Loss: 0.2080\n",
      "Diff stats — min: -7.0987, max: 10.0000, mean: 3.9260, std: 2.9336\n",
      "\n",
      "Step 10278 — Test metrics:\n",
      "  precision@10: 0.010683140\n",
      "  recall@10: 0.010689746\n",
      "  ndcg@10: 0.011056977\n",
      "  map@10: 0.003501101\n",
      "Epoch 54, Step 60, LR: 0.000253, Current Loss: 0.2094, Avg Loss: 0.2089\n",
      "Diff stats — min: -7.3841, max: 10.0000, mean: 3.9712, std: 3.0004\n",
      "\n",
      "Epoch 54, Step 80, LR: 0.000253, Current Loss: 0.2201, Avg Loss: 0.2083\n",
      "Diff stats — min: -6.8230, max: 10.0000, mean: 3.9328, std: 2.9913\n",
      "\n",
      "Epoch 54, Step 100, LR: 0.000253, Current Loss: 0.2054, Avg Loss: 0.2077\n",
      "Diff stats — min: -7.2741, max: 10.0000, mean: 3.9735, std: 2.9485\n",
      "\n",
      "Step 10328 — Test metrics:\n",
      "  precision@10: 0.010841702\n",
      "  recall@10: 0.010849043\n",
      "  ndcg@10: 0.011088048\n",
      "  map@10: 0.003470510\n",
      "Epoch 54, Step 120, LR: 0.000253, Current Loss: 0.2171, Avg Loss: 0.2080\n",
      "Diff stats — min: -6.7549, max: 10.0000, mean: 3.9468, std: 3.0096\n",
      "\n",
      "Epoch 54, Step 140, LR: 0.000248, Current Loss: 0.2153, Avg Loss: 0.2083\n",
      "Diff stats — min: -5.8112, max: 10.0000, mean: 3.9571, std: 2.9922\n",
      "\n",
      "Step 10378 — Test metrics:\n",
      "  precision@10: 0.010947410\n",
      "  recall@10: 0.010954017\n",
      "  ndcg@10: 0.011334217\n",
      "  map@10: 0.003596258\n",
      "Epoch 54, Step 160, LR: 0.000248, Current Loss: 0.1968, Avg Loss: 0.2082\n",
      "Diff stats — min: -5.1848, max: 10.0000, mean: 3.9628, std: 2.9080\n",
      "\n",
      "Epoch 54, Step 180, LR: 0.000248, Current Loss: 0.2139, Avg Loss: 0.2080\n",
      "Diff stats — min: -5.8271, max: 10.0000, mean: 3.9245, std: 2.9829\n",
      "\n",
      "Epoch 54 completed, Train Loss: 0.000051\n",
      "\n",
      "Epoch 55, Step 1, LR: 0.000248, Current Loss: 0.1944, Avg Loss: 0.1944\n",
      "Diff stats — min: -5.4888, max: 10.0000, mean: 4.0230, std: 2.9502\n",
      "\n",
      "Step 10422 — Test metrics:\n",
      "  precision@10: 0.010815275\n",
      "  recall@10: 0.010821882\n",
      "  ndcg@10: 0.011161413\n",
      "  map@10: 0.003534053\n",
      "Epoch 55, Step 20, LR: 0.000248, Current Loss: 0.2165, Avg Loss: 0.2057\n",
      "Diff stats — min: -6.6400, max: 10.0000, mean: 3.9005, std: 2.9979\n",
      "\n",
      "Epoch 55, Step 40, LR: 0.000248, Current Loss: 0.2219, Avg Loss: 0.2063\n",
      "Diff stats — min: -4.7164, max: 10.0000, mean: 3.9212, std: 3.0246\n",
      "\n",
      "Step 10471 — Test metrics:\n",
      "  precision@10: 0.010610465\n",
      "  recall@10: 0.010616338\n",
      "  ndcg@10: 0.010942955\n",
      "  map@10: 0.003449524\n",
      "Epoch 55, Step 60, LR: 0.000248, Current Loss: 0.1936, Avg Loss: 0.2070\n",
      "Diff stats — min: -6.3370, max: 10.0000, mean: 3.9825, std: 2.9059\n",
      "\n",
      "Epoch 55, Step 80, LR: 0.000243, Current Loss: 0.1996, Avg Loss: 0.2071\n",
      "Diff stats — min: -5.3861, max: 10.0000, mean: 3.9797, std: 2.9362\n",
      "\n",
      "Epoch 55, Step 100, LR: 0.000243, Current Loss: 0.2176, Avg Loss: 0.2064\n",
      "Diff stats — min: -5.8385, max: 10.0000, mean: 3.9842, std: 3.0385\n",
      "\n",
      "Step 10521 — Test metrics:\n",
      "  precision@10: 0.010802061\n",
      "  recall@10: 0.010809402\n",
      "  ndcg@10: 0.011162006\n",
      "  map@10: 0.003527304\n",
      "Epoch 55, Step 120, LR: 0.000243, Current Loss: 0.1959, Avg Loss: 0.2063\n",
      "Diff stats — min: -7.6909, max: 10.0000, mean: 3.9988, std: 2.9434\n",
      "\n",
      "Epoch 55, Step 140, LR: 0.000243, Current Loss: 0.2093, Avg Loss: 0.2068\n",
      "Diff stats — min: -5.6970, max: 10.0000, mean: 3.9124, std: 2.9503\n",
      "\n",
      "Step 10571 — Test metrics:\n",
      "  precision@10: 0.010564218\n",
      "  recall@10: 0.010570825\n",
      "  ndcg@10: 0.010954477\n",
      "  map@10: 0.003475847\n",
      "Epoch 55, Step 160, LR: 0.000243, Current Loss: 0.1912, Avg Loss: 0.2068\n",
      "Diff stats — min: -4.7385, max: 10.0000, mean: 3.9908, std: 2.9479\n",
      "\n",
      "Epoch 55, Step 180, LR: 0.000243, Current Loss: 0.2127, Avg Loss: 0.2068\n",
      "Diff stats — min: -6.3885, max: 10.0000, mean: 3.9571, std: 2.9831\n",
      "\n",
      "Epoch 55 completed, Train Loss: 0.000051\n",
      "\n",
      "Epoch 56, Step 1, LR: 0.000243, Current Loss: 0.2100, Avg Loss: 0.2100\n",
      "Diff stats — min: -6.4321, max: 10.0000, mean: 3.9132, std: 2.9174\n",
      "\n",
      "Step 10615 — Test metrics:\n",
      "  precision@10: 0.010742600\n",
      "  recall@10: 0.010749207\n",
      "  ndcg@10: 0.011073693\n",
      "  map@10: 0.003505721\n",
      "Epoch 56, Step 20, LR: 0.000243, Current Loss: 0.2060, Avg Loss: 0.2054\n",
      "Diff stats — min: -7.2622, max: 10.0000, mean: 4.0082, std: 3.0044\n",
      "\n",
      "Epoch 56, Step 40, LR: 0.000238, Current Loss: 0.1985, Avg Loss: 0.2042\n",
      "Diff stats — min: -7.1092, max: 10.0000, mean: 3.9657, std: 2.9091\n",
      "\n",
      "Step 10664 — Test metrics:\n",
      "  precision@10: 0.010570825\n",
      "  recall@10: 0.010577431\n",
      "  ndcg@10: 0.010919396\n",
      "  map@10: 0.003462195\n",
      "Epoch 56, Step 60, LR: 0.000238, Current Loss: 0.2058, Avg Loss: 0.2050\n",
      "Diff stats — min: -5.2436, max: 10.0000, mean: 4.0078, std: 2.9840\n",
      "\n",
      "Epoch 56, Step 80, LR: 0.000238, Current Loss: 0.2092, Avg Loss: 0.2053\n",
      "Diff stats — min: -6.2089, max: 10.0000, mean: 3.9680, std: 2.9683\n",
      "\n",
      "Epoch 56, Step 100, LR: 0.000238, Current Loss: 0.2144, Avg Loss: 0.2059\n",
      "Diff stats — min: -5.9702, max: 10.0000, mean: 3.9826, std: 3.0147\n",
      "\n",
      "Step 10714 — Test metrics:\n",
      "  precision@10: 0.010861522\n",
      "  recall@10: 0.010868129\n",
      "  ndcg@10: 0.011147863\n",
      "  map@10: 0.003505738\n",
      "Epoch 56, Step 120, LR: 0.000238, Current Loss: 0.1948, Avg Loss: 0.2061\n",
      "Diff stats — min: -5.7323, max: 10.0000, mean: 4.0879, std: 2.9831\n",
      "\n",
      "Epoch 56, Step 140, LR: 0.000238, Current Loss: 0.2159, Avg Loss: 0.2060\n",
      "Diff stats — min: -6.8564, max: 10.0000, mean: 3.9251, std: 2.9734\n",
      "\n",
      "Step 10764 — Test metrics:\n",
      "  precision@10: 0.010643499\n",
      "  recall@10: 0.010650840\n",
      "  ndcg@10: 0.011021309\n",
      "  map@10: 0.003484735\n",
      "Epoch 56, Step 160, LR: 0.000238, Current Loss: 0.2178, Avg Loss: 0.2060\n",
      "Diff stats — min: -5.8676, max: 10.0000, mean: 3.8782, std: 2.9508\n",
      "\n",
      "Epoch 56, Step 180, LR: 0.000238, Current Loss: 0.2055, Avg Loss: 0.2059\n",
      "Diff stats — min: -6.1842, max: 10.0000, mean: 3.9774, std: 2.9508\n",
      "\n",
      "Epoch 56 completed, Train Loss: 0.000050\n",
      "\n",
      "Epoch 57, Step 1, LR: 0.000233, Current Loss: 0.2069, Avg Loss: 0.2069\n",
      "Diff stats — min: -5.6025, max: 10.0000, mean: 3.9312, std: 2.9475\n",
      "\n",
      "Step 10808 — Test metrics:\n",
      "  precision@10: 0.010623679\n",
      "  recall@10: 0.010630285\n",
      "  ndcg@10: 0.010824101\n",
      "  map@10: 0.003370916\n",
      "Epoch 57, Step 20, LR: 0.000233, Current Loss: 0.2025, Avg Loss: 0.2080\n",
      "Diff stats — min: -7.0568, max: 10.0000, mean: 4.0190, std: 3.0094\n",
      "\n",
      "Epoch 57, Step 40, LR: 0.000233, Current Loss: 0.2113, Avg Loss: 0.2063\n",
      "Diff stats — min: -5.4544, max: 10.0000, mean: 3.9578, std: 3.0105\n",
      "\n",
      "Step 10857 — Test metrics:\n",
      "  precision@10: 0.010854915\n",
      "  recall@10: 0.010861522\n",
      "  ndcg@10: 0.011193572\n",
      "  map@10: 0.003533968\n",
      "Epoch 57, Step 60, LR: 0.000233, Current Loss: 0.1966, Avg Loss: 0.2062\n",
      "Diff stats — min: -6.4468, max: 10.0000, mean: 3.9929, std: 2.9231\n",
      "\n",
      "Epoch 57, Step 80, LR: 0.000233, Current Loss: 0.2119, Avg Loss: 0.2065\n",
      "Diff stats — min: -5.3046, max: 10.0000, mean: 3.9460, std: 2.9751\n",
      "\n",
      "Epoch 57, Step 100, LR: 0.000233, Current Loss: 0.1985, Avg Loss: 0.2058\n",
      "Diff stats — min: -5.5877, max: 10.0000, mean: 3.9832, std: 2.9664\n",
      "\n",
      "Step 10907 — Test metrics:\n",
      "  precision@10: 0.010729387\n",
      "  recall@10: 0.010735994\n",
      "  ndcg@10: 0.011025242\n",
      "  map@10: 0.003469652\n",
      "Epoch 57, Step 120, LR: 0.000233, Current Loss: 0.1963, Avg Loss: 0.2059\n",
      "Diff stats — min: -5.3719, max: 10.0000, mean: 3.9881, std: 2.9219\n",
      "\n",
      "Epoch 57, Step 140, LR: 0.000233, Current Loss: 0.2019, Avg Loss: 0.2053\n",
      "Diff stats — min: -5.8935, max: 10.0000, mean: 4.0280, std: 2.9981\n",
      "\n",
      "Step 10957 — Test metrics:\n",
      "  precision@10: 0.010729387\n",
      "  recall@10: 0.010735994\n",
      "  ndcg@10: 0.011199042\n",
      "  map@10: 0.003572311\n",
      "Epoch 57, Step 160, LR: 0.000229, Current Loss: 0.2136, Avg Loss: 0.2053\n",
      "Diff stats — min: -5.9899, max: 10.0000, mean: 4.0479, std: 3.0369\n",
      "\n",
      "Epoch 57, Step 180, LR: 0.000229, Current Loss: 0.1988, Avg Loss: 0.2051\n",
      "Diff stats — min: -5.6462, max: 10.0000, mean: 4.1025, std: 2.9975\n",
      "\n",
      "Epoch 57 completed, Train Loss: 0.000050\n",
      "\n",
      "Epoch 58, Step 1, LR: 0.000229, Current Loss: 0.1925, Avg Loss: 0.1925\n",
      "Diff stats — min: -5.5511, max: 10.0000, mean: 4.0660, std: 2.9623\n",
      "\n",
      "Step 11001 — Test metrics:\n",
      "  precision@10: 0.011218288\n",
      "  recall@10: 0.011223426\n",
      "  ndcg@10: 0.011515633\n",
      "  map@10: 0.003625238\n",
      "Epoch 58, Step 20, LR: 0.000229, Current Loss: 0.1955, Avg Loss: 0.2003\n",
      "Diff stats — min: -7.2783, max: 10.0000, mean: 4.0365, std: 2.9485\n",
      "\n",
      "Epoch 58, Step 40, LR: 0.000229, Current Loss: 0.2153, Avg Loss: 0.2025\n",
      "Diff stats — min: -5.9763, max: 10.0000, mean: 3.9805, std: 3.0318\n",
      "\n",
      "Step 11050 — Test metrics:\n",
      "  precision@10: 0.010597252\n",
      "  recall@10: 0.010604592\n",
      "  ndcg@10: 0.010982979\n",
      "  map@10: 0.003489488\n",
      "Epoch 58, Step 60, LR: 0.000229, Current Loss: 0.2007, Avg Loss: 0.2033\n",
      "Diff stats — min: -5.5435, max: 10.0000, mean: 3.9940, std: 2.9810\n",
      "\n",
      "Epoch 58, Step 80, LR: 0.000229, Current Loss: 0.2028, Avg Loss: 0.2036\n",
      "Diff stats — min: -6.5216, max: 10.0000, mean: 4.0102, std: 2.9418\n",
      "\n",
      "Epoch 58, Step 100, LR: 0.000224, Current Loss: 0.2101, Avg Loss: 0.2043\n",
      "Diff stats — min: -6.9460, max: 10.0000, mean: 3.9796, std: 3.0111\n",
      "\n",
      "Step 11100 — Test metrics:\n",
      "  precision@10: 0.010716173\n",
      "  recall@10: 0.010720578\n",
      "  ndcg@10: 0.011131903\n",
      "  map@10: 0.003534952\n",
      "Epoch 58, Step 120, LR: 0.000224, Current Loss: 0.2044, Avg Loss: 0.2046\n",
      "Diff stats — min: -5.7459, max: 10.0000, mean: 3.9332, std: 2.9578\n",
      "\n",
      "Epoch 58, Step 140, LR: 0.000224, Current Loss: 0.2113, Avg Loss: 0.2044\n",
      "Diff stats — min: -8.4567, max: 10.0000, mean: 3.9798, std: 3.0200\n",
      "\n",
      "Step 11150 — Test metrics:\n",
      "  precision@10: 0.010861522\n",
      "  recall@10: 0.010867395\n",
      "  ndcg@10: 0.011378653\n",
      "  map@10: 0.003641558\n",
      "Epoch 58, Step 160, LR: 0.000224, Current Loss: 0.2023, Avg Loss: 0.2041\n",
      "Diff stats — min: -5.3657, max: 10.0000, mean: 4.0028, std: 2.9621\n",
      "\n",
      "Epoch 58, Step 180, LR: 0.000224, Current Loss: 0.2003, Avg Loss: 0.2040\n",
      "Diff stats — min: -5.8589, max: 10.0000, mean: 4.0901, std: 2.9935\n",
      "\n",
      "Epoch 58 completed, Train Loss: 0.000050\n",
      "\n",
      "Epoch 59, Step 1, LR: 0.000224, Current Loss: 0.1876, Avg Loss: 0.1876\n",
      "Diff stats — min: -5.3248, max: 10.0000, mean: 4.0785, std: 2.9346\n",
      "\n",
      "Step 11194 — Test metrics:\n",
      "  precision@10: 0.010722780\n",
      "  recall@10: 0.010730121\n",
      "  ndcg@10: 0.011117976\n",
      "  map@10: 0.003533222\n",
      "Epoch 59, Step 20, LR: 0.000224, Current Loss: 0.2011, Avg Loss: 0.2019\n",
      "Diff stats — min: -5.6307, max: 10.0000, mean: 4.0136, std: 2.9602\n",
      "\n",
      "Epoch 59, Step 40, LR: 0.000224, Current Loss: 0.2083, Avg Loss: 0.2052\n",
      "Diff stats — min: -5.1940, max: 10.0000, mean: 4.0148, std: 3.0023\n",
      "\n",
      "Step 11243 — Test metrics:\n",
      "  precision@10: 0.011105973\n",
      "  recall@10: 0.011112579\n",
      "  ndcg@10: 0.011474126\n",
      "  map@10: 0.003628080\n",
      "Epoch 59, Step 60, LR: 0.000220, Current Loss: 0.2183, Avg Loss: 0.2048\n",
      "Diff stats — min: -5.3505, max: 10.0000, mean: 3.9407, std: 3.0331\n",
      "\n",
      "Epoch 59, Step 80, LR: 0.000220, Current Loss: 0.2014, Avg Loss: 0.2048\n",
      "Diff stats — min: -5.7574, max: 10.0000, mean: 4.0444, std: 2.9949\n",
      "\n",
      "Epoch 59, Step 100, LR: 0.000220, Current Loss: 0.2045, Avg Loss: 0.2038\n",
      "Diff stats — min: -5.3936, max: 10.0000, mean: 4.0064, std: 2.9877\n",
      "\n",
      "Step 11293 — Test metrics:\n",
      "  precision@10: 0.010729387\n",
      "  recall@10: 0.010735994\n",
      "  ndcg@10: 0.011102975\n",
      "  map@10: 0.003509277\n",
      "Epoch 59, Step 120, LR: 0.000220, Current Loss: 0.2053, Avg Loss: 0.2036\n",
      "Diff stats — min: -4.5497, max: 10.0000, mean: 4.0046, std: 2.9714\n",
      "\n",
      "Epoch 59, Step 140, LR: 0.000220, Current Loss: 0.2004, Avg Loss: 0.2034\n",
      "Diff stats — min: -4.6688, max: 10.0000, mean: 4.0328, std: 2.9829\n",
      "\n",
      "Step 11343 — Test metrics:\n",
      "  precision@10: 0.010894556\n",
      "  recall@10: 0.010901163\n",
      "  ndcg@10: 0.011341587\n",
      "  map@10: 0.003617521\n",
      "Epoch 59, Step 160, LR: 0.000220, Current Loss: 0.2034, Avg Loss: 0.2038\n",
      "Diff stats — min: -8.1185, max: 10.0000, mean: 4.0155, std: 2.9884\n",
      "\n",
      "Epoch 59, Step 180, LR: 0.000220, Current Loss: 0.2172, Avg Loss: 0.2037\n",
      "Diff stats — min: -4.8030, max: 10.0000, mean: 3.9370, std: 3.0014\n",
      "\n",
      "Epoch 59 completed, Train Loss: 0.000050\n",
      "\n",
      "Epoch 60, Step 1, LR: 0.000220, Current Loss: 0.1898, Avg Loss: 0.1898\n",
      "Diff stats — min: -7.2644, max: 10.0000, mean: 4.0715, std: 2.9764\n",
      "\n",
      "Step 11387 — Test metrics:\n",
      "  precision@10: 0.010584038\n",
      "  recall@10: 0.010590645\n",
      "  ndcg@10: 0.010964007\n",
      "  map@10: 0.003474212\n",
      "Epoch 60, Step 20, LR: 0.000215, Current Loss: 0.1945, Avg Loss: 0.2018\n",
      "Diff stats — min: -6.6565, max: 10.0000, mean: 4.0891, std: 2.9973\n",
      "\n",
      "Epoch 60, Step 40, LR: 0.000215, Current Loss: 0.2124, Avg Loss: 0.2009\n",
      "Diff stats — min: -5.2604, max: 10.0000, mean: 4.0243, std: 3.0261\n",
      "\n",
      "Step 11436 — Test metrics:\n",
      "  precision@10: 0.011013478\n",
      "  recall@10: 0.011020085\n",
      "  ndcg@10: 0.011481711\n",
      "  map@10: 0.003668978\n",
      "Epoch 60, Step 60, LR: 0.000215, Current Loss: 0.2094, Avg Loss: 0.2012\n",
      "Diff stats — min: -6.5751, max: 10.0000, mean: 4.1216, std: 3.0887\n",
      "\n",
      "Epoch 60, Step 80, LR: 0.000215, Current Loss: 0.1858, Avg Loss: 0.2012\n",
      "Diff stats — min: -7.2455, max: 10.0000, mean: 4.0946, std: 2.9285\n",
      "\n",
      "Epoch 60, Step 100, LR: 0.000215, Current Loss: 0.2025, Avg Loss: 0.2017\n",
      "Diff stats — min: -6.9032, max: 10.0000, mean: 4.0522, std: 2.9930\n",
      "\n",
      "Step 11486 — Test metrics:\n",
      "  precision@10: 0.010841702\n",
      "  recall@10: 0.010848309\n",
      "  ndcg@10: 0.011178250\n",
      "  map@10: 0.003536114\n",
      "Epoch 60, Step 120, LR: 0.000215, Current Loss: 0.2092, Avg Loss: 0.2021\n",
      "Diff stats — min: -6.1291, max: 10.0000, mean: 4.0447, std: 3.0411\n",
      "\n",
      "Epoch 60, Step 140, LR: 0.000215, Current Loss: 0.2183, Avg Loss: 0.2023\n",
      "Diff stats — min: -5.3573, max: 10.0000, mean: 3.9642, std: 3.0584\n",
      "\n",
      "Step 11536 — Test metrics:\n",
      "  precision@10: 0.010716173\n",
      "  recall@10: 0.010722046\n",
      "  ndcg@10: 0.011152565\n",
      "  map@10: 0.003552263\n",
      "Epoch 60, Step 160, LR: 0.000215, Current Loss: 0.2015, Avg Loss: 0.2025\n",
      "Diff stats — min: -6.9434, max: 10.0000, mean: 3.9636, std: 2.9507\n",
      "\n",
      "Epoch 60, Step 180, LR: 0.000211, Current Loss: 0.2009, Avg Loss: 0.2027\n",
      "Diff stats — min: -5.3617, max: 10.0000, mean: 4.0786, std: 2.9839\n",
      "\n",
      "Epoch 60 completed, Train Loss: 0.000050\n",
      "\n",
      "Epoch 61, Step 1, LR: 0.000211, Current Loss: 0.2008, Avg Loss: 0.2008\n",
      "Diff stats — min: -6.5769, max: 10.0000, mean: 4.0092, std: 2.9918\n",
      "\n",
      "Step 11580 — Test metrics:\n",
      "  precision@10: 0.010894556\n",
      "  recall@10: 0.010900429\n",
      "  ndcg@10: 0.011323148\n",
      "  map@10: 0.003614208\n",
      "Epoch 61, Step 20, LR: 0.000211, Current Loss: 0.1951, Avg Loss: 0.2022\n",
      "Diff stats — min: -7.5033, max: 10.0000, mean: 4.1461, std: 3.0067\n",
      "\n",
      "Epoch 61, Step 40, LR: 0.000211, Current Loss: 0.2026, Avg Loss: 0.2034\n",
      "Diff stats — min: -4.8632, max: 10.0000, mean: 4.0237, std: 3.0023\n",
      "\n",
      "Step 11629 — Test metrics:\n",
      "  precision@10: 0.010643499\n",
      "  recall@10: 0.010649372\n",
      "  ndcg@10: 0.011100323\n",
      "  map@10: 0.003548313\n",
      "Epoch 61, Step 60, LR: 0.000211, Current Loss: 0.2067, Avg Loss: 0.2023\n",
      "Diff stats — min: -7.0348, max: 10.0000, mean: 3.9920, std: 2.9759\n",
      "\n",
      "Epoch 61, Step 80, LR: 0.000211, Current Loss: 0.2117, Avg Loss: 0.2024\n",
      "Diff stats — min: -4.8176, max: 10.0000, mean: 4.0494, std: 3.0581\n",
      "\n",
      "Epoch 61, Step 100, LR: 0.000211, Current Loss: 0.2063, Avg Loss: 0.2020\n",
      "Diff stats — min: -6.2266, max: 10.0000, mean: 4.0005, std: 2.9718\n",
      "\n",
      "Step 11679 — Test metrics:\n",
      "  precision@10: 0.010617072\n",
      "  recall@10: 0.010623679\n",
      "  ndcg@10: 0.011080587\n",
      "  map@10: 0.003541425\n",
      "Epoch 61, Step 120, LR: 0.000211, Current Loss: 0.1913, Avg Loss: 0.2020\n",
      "Diff stats — min: -7.0148, max: 10.0000, mean: 4.1707, std: 3.0411\n",
      "\n",
      "Epoch 61, Step 140, LR: 0.000207, Current Loss: 0.1962, Avg Loss: 0.2019\n",
      "Diff stats — min: -5.1519, max: 10.0000, mean: 4.0874, std: 3.0109\n",
      "\n",
      "Step 11729 — Test metrics:\n",
      "  precision@10: 0.010636892\n",
      "  recall@10: 0.010642031\n",
      "  ndcg@10: 0.011064161\n",
      "  map@10: 0.003525239\n",
      "Epoch 61, Step 160, LR: 0.000207, Current Loss: 0.1842, Avg Loss: 0.2016\n",
      "Diff stats — min: -5.6693, max: 10.0000, mean: 4.1721, std: 3.0180\n",
      "\n",
      "Epoch 61, Step 180, LR: 0.000207, Current Loss: 0.1975, Avg Loss: 0.2017\n",
      "Diff stats — min: -6.0027, max: 10.0000, mean: 4.1126, std: 2.9917\n",
      "\n",
      "Epoch 61 completed, Train Loss: 0.000049\n",
      "\n",
      "Epoch 62, Step 1, LR: 0.000207, Current Loss: 0.1968, Avg Loss: 0.1968\n",
      "Diff stats — min: -4.8571, max: 10.0000, mean: 4.1128, std: 3.0278\n",
      "\n",
      "Step 11773 — Test metrics:\n",
      "  precision@10: 0.010669926\n",
      "  recall@10: 0.010675065\n",
      "  ndcg@10: 0.011061809\n",
      "  map@10: 0.003512278\n",
      "Epoch 62, Step 20, LR: 0.000207, Current Loss: 0.2032, Avg Loss: 0.2009\n",
      "Diff stats — min: -6.1292, max: 10.0000, mean: 4.0662, std: 3.0241\n",
      "\n",
      "Epoch 62, Step 40, LR: 0.000207, Current Loss: 0.2052, Avg Loss: 0.2020\n",
      "Diff stats — min: -6.5693, max: 10.0000, mean: 4.0981, std: 3.0519\n",
      "\n",
      "Step 11822 — Test metrics:\n",
      "  precision@10: 0.010564218\n",
      "  recall@10: 0.010568622\n",
      "  ndcg@10: 0.011029701\n",
      "  map@10: 0.003525805\n",
      "Epoch 62, Step 60, LR: 0.000207, Current Loss: 0.2038, Avg Loss: 0.2006\n",
      "Diff stats — min: -5.7031, max: 10.0000, mean: 4.1043, std: 3.0208\n",
      "\n",
      "Epoch 62, Step 80, LR: 0.000203, Current Loss: 0.1938, Avg Loss: 0.1997\n",
      "Diff stats — min: -5.2128, max: 10.0000, mean: 4.0803, std: 2.9847\n",
      "\n",
      "Epoch 62, Step 100, LR: 0.000203, Current Loss: 0.2019, Avg Loss: 0.2008\n",
      "Diff stats — min: -5.4100, max: 10.0000, mean: 4.1127, std: 3.0324\n",
      "\n",
      "Step 11872 — Test metrics:\n",
      "  precision@10: 0.010650106\n",
      "  recall@10: 0.010654510\n",
      "  ndcg@10: 0.011083010\n",
      "  map@10: 0.003533470\n",
      "Epoch 62, Step 120, LR: 0.000203, Current Loss: 0.1966, Avg Loss: 0.2005\n",
      "Diff stats — min: -5.2079, max: 10.0000, mean: 4.0811, std: 2.9863\n",
      "\n",
      "Epoch 62, Step 140, LR: 0.000203, Current Loss: 0.2071, Avg Loss: 0.2005\n",
      "Diff stats — min: -5.8119, max: 10.0000, mean: 4.0146, std: 3.0232\n",
      "\n",
      "Step 11922 — Test metrics:\n",
      "  precision@10: 0.010815275\n",
      "  recall@10: 0.010820413\n",
      "  ndcg@10: 0.011248945\n",
      "  map@10: 0.003584994\n",
      "Epoch 62, Step 160, LR: 0.000203, Current Loss: 0.1958, Avg Loss: 0.2006\n",
      "Diff stats — min: -5.4080, max: 10.0000, mean: 4.1050, std: 3.0017\n",
      "\n",
      "Epoch 62, Step 180, LR: 0.000203, Current Loss: 0.2088, Avg Loss: 0.2005\n",
      "Diff stats — min: -5.6508, max: 10.0000, mean: 4.0587, std: 3.0332\n",
      "\n",
      "Epoch 62 completed, Train Loss: 0.000049\n",
      "\n",
      "Epoch 63, Step 1, LR: 0.000203, Current Loss: 0.2029, Avg Loss: 0.2029\n",
      "Diff stats — min: -5.9307, max: 10.0000, mean: 4.1010, std: 3.0094\n",
      "\n",
      "Step 11966 — Test metrics:\n",
      "  precision@10: 0.010610465\n",
      "  recall@10: 0.010616338\n",
      "  ndcg@10: 0.011000999\n",
      "  map@10: 0.003495920\n",
      "Epoch 63, Step 20, LR: 0.000203, Current Loss: 0.1901, Avg Loss: 0.2015\n",
      "Diff stats — min: -5.1765, max: 10.0000, mean: 4.1226, std: 3.0039\n",
      "\n",
      "Epoch 63, Step 40, LR: 0.000199, Current Loss: 0.1906, Avg Loss: 0.2003\n",
      "Diff stats — min: -6.3002, max: 10.0000, mean: 4.0912, std: 2.9945\n",
      "\n",
      "Step 12015 — Test metrics:\n",
      "  precision@10: 0.010742600\n",
      "  recall@10: 0.010748473\n",
      "  ndcg@10: 0.011202681\n",
      "  map@10: 0.003578444\n",
      "Epoch 63, Step 60, LR: 0.000199, Current Loss: 0.2240, Avg Loss: 0.2007\n",
      "Diff stats — min: -6.1019, max: 10.0000, mean: 3.9944, std: 3.0728\n",
      "\n",
      "Epoch 63, Step 80, LR: 0.000199, Current Loss: 0.1890, Avg Loss: 0.2008\n",
      "Diff stats — min: -4.8101, max: 10.0000, mean: 4.0650, std: 2.9472\n",
      "\n",
      "Epoch 63, Step 100, LR: 0.000199, Current Loss: 0.2044, Avg Loss: 0.2011\n",
      "Diff stats — min: -5.2900, max: 10.0000, mean: 4.0038, std: 2.9741\n",
      "\n",
      "Step 12065 — Test metrics:\n",
      "  precision@10: 0.010775634\n",
      "  recall@10: 0.010780039\n",
      "  ndcg@10: 0.011161224\n",
      "  map@10: 0.003551013\n",
      "Epoch 63, Step 120, LR: 0.000199, Current Loss: 0.1873, Avg Loss: 0.2008\n",
      "Diff stats — min: -6.2232, max: 10.0000, mean: 4.1571, std: 2.9803\n",
      "\n",
      "Epoch 63, Step 140, LR: 0.000199, Current Loss: 0.1977, Avg Loss: 0.2009\n",
      "Diff stats — min: -5.5501, max: 10.0000, mean: 4.1074, std: 3.0092\n",
      "\n",
      "Step 12115 — Test metrics:\n",
      "  precision@10: 0.010967230\n",
      "  recall@10: 0.010972369\n",
      "  ndcg@10: 0.011293069\n",
      "  map@10: 0.003572139\n",
      "Epoch 63, Step 160, LR: 0.000199, Current Loss: 0.1960, Avg Loss: 0.2006\n",
      "Diff stats — min: -7.2644, max: 10.0000, mean: 4.0794, std: 3.0075\n",
      "\n",
      "Epoch 63, Step 180, LR: 0.000199, Current Loss: 0.2012, Avg Loss: 0.2006\n",
      "Diff stats — min: -5.9105, max: 10.0000, mean: 4.1519, std: 3.0518\n",
      "\n",
      "Epoch 63 completed, Train Loss: 0.000049\n",
      "\n",
      "Epoch 64, Step 1, LR: 0.000195, Current Loss: 0.1949, Avg Loss: 0.1949\n",
      "Diff stats — min: -6.3381, max: 10.0000, mean: 4.0952, std: 2.9941\n",
      "\n",
      "Step 12159 — Test metrics:\n",
      "  precision@10: 0.010782241\n",
      "  recall@10: 0.010788848\n",
      "  ndcg@10: 0.011277054\n",
      "  map@10: 0.003610602\n",
      "Epoch 64, Step 20, LR: 0.000195, Current Loss: 0.2004, Avg Loss: 0.1984\n",
      "Diff stats — min: -6.8858, max: 10.0000, mean: 4.0319, std: 2.9864\n",
      "\n",
      "Epoch 64, Step 40, LR: 0.000195, Current Loss: 0.1923, Avg Loss: 0.1994\n",
      "Diff stats — min: -4.6832, max: 10.0000, mean: 4.1724, std: 3.0038\n",
      "\n",
      "Step 12208 — Test metrics:\n",
      "  precision@10: 0.010517970\n",
      "  recall@10: 0.010522375\n",
      "  ndcg@10: 0.010973887\n",
      "  map@10: 0.003504822\n",
      "Epoch 64, Step 60, LR: 0.000195, Current Loss: 0.2025, Avg Loss: 0.1991\n",
      "Diff stats — min: -6.9631, max: 10.0000, mean: 4.0016, std: 2.9949\n",
      "\n",
      "Epoch 64, Step 80, LR: 0.000195, Current Loss: 0.1903, Avg Loss: 0.1989\n",
      "Diff stats — min: -5.1861, max: 10.0000, mean: 4.1937, std: 3.0283\n",
      "\n",
      "Epoch 64, Step 100, LR: 0.000195, Current Loss: 0.1921, Avg Loss: 0.1995\n",
      "Diff stats — min: -6.4097, max: 10.0000, mean: 4.1337, std: 3.0326\n",
      "\n",
      "Step 12258 — Test metrics:\n",
      "  precision@10: 0.010775634\n",
      "  recall@10: 0.010780039\n",
      "  ndcg@10: 0.011245761\n",
      "  map@10: 0.003599653\n",
      "Epoch 64, Step 120, LR: 0.000195, Current Loss: 0.2059, Avg Loss: 0.1997\n",
      "Diff stats — min: -5.4928, max: 10.0000, mean: 4.0936, std: 3.0329\n",
      "\n",
      "Epoch 64, Step 140, LR: 0.000195, Current Loss: 0.1873, Avg Loss: 0.2000\n",
      "Diff stats — min: -5.4886, max: 10.0000, mean: 4.1137, std: 2.9905\n",
      "\n",
      "Step 12308 — Test metrics:\n",
      "  precision@10: 0.010755814\n",
      "  recall@10: 0.010761687\n",
      "  ndcg@10: 0.011151040\n",
      "  map@10: 0.003551057\n",
      "Epoch 64, Step 160, LR: 0.000191, Current Loss: 0.2077, Avg Loss: 0.2004\n",
      "Diff stats — min: -5.3441, max: 10.0000, mean: 3.9819, std: 2.9758\n",
      "\n",
      "Epoch 64, Step 180, LR: 0.000191, Current Loss: 0.1976, Avg Loss: 0.2001\n",
      "Diff stats — min: -4.8438, max: 10.0000, mean: 4.0766, std: 3.0096\n",
      "\n",
      "Epoch 64 completed, Train Loss: 0.000049\n",
      "\n",
      "Epoch 65, Step 1, LR: 0.000191, Current Loss: 0.1931, Avg Loss: 0.1931\n",
      "Diff stats — min: -5.7024, max: 10.0000, mean: 4.1052, std: 3.0013\n",
      "\n",
      "Step 12352 — Test metrics:\n",
      "  precision@10: 0.010722780\n",
      "  recall@10: 0.010727919\n",
      "  ndcg@10: 0.011050603\n",
      "  map@10: 0.003503621\n",
      "Epoch 65, Step 20, LR: 0.000191, Current Loss: 0.1973, Avg Loss: 0.1983\n",
      "Diff stats — min: -6.1810, max: 10.0000, mean: 4.1569, std: 3.0565\n",
      "\n",
      "Epoch 65, Step 40, LR: 0.000191, Current Loss: 0.2018, Avg Loss: 0.1989\n",
      "Diff stats — min: -8.1470, max: 10.0000, mean: 4.1231, std: 3.0213\n",
      "\n",
      "Step 12401 — Test metrics:\n",
      "  precision@10: 0.010709567\n",
      "  recall@10: 0.010714705\n",
      "  ndcg@10: 0.011081947\n",
      "  map@10: 0.003509143\n",
      "Epoch 65, Step 60, LR: 0.000191, Current Loss: 0.2059, Avg Loss: 0.1989\n",
      "Diff stats — min: -6.6303, max: 10.0000, mean: 4.0912, std: 3.0647\n",
      "\n",
      "Epoch 65, Step 80, LR: 0.000191, Current Loss: 0.2016, Avg Loss: 0.1997\n",
      "Diff stats — min: -5.1224, max: 10.0000, mean: 4.1399, std: 3.0698\n",
      "\n",
      "Epoch 65, Step 100, LR: 0.000187, Current Loss: 0.2007, Avg Loss: 0.1993\n",
      "Diff stats — min: -8.9593, max: 10.0000, mean: 4.0718, std: 3.0266\n",
      "\n",
      "Step 12451 — Test metrics:\n",
      "  precision@10: 0.010716173\n",
      "  recall@10: 0.010721312\n",
      "  ndcg@10: 0.011015914\n",
      "  map@10: 0.003483319\n",
      "Epoch 65, Step 120, LR: 0.000187, Current Loss: 0.1802, Avg Loss: 0.1994\n",
      "Diff stats — min: -5.8983, max: 10.0000, mean: 4.2078, std: 3.0003\n",
      "\n",
      "Epoch 65, Step 140, LR: 0.000187, Current Loss: 0.2056, Avg Loss: 0.1993\n",
      "Diff stats — min: -7.2677, max: 10.0000, mean: 4.0903, std: 3.0504\n",
      "\n",
      "Step 12501 — Test metrics:\n",
      "  precision@10: 0.010570825\n",
      "  recall@10: 0.010575229\n",
      "  ndcg@10: 0.010892802\n",
      "  map@10: 0.003455760\n",
      "Epoch 65, Step 160, LR: 0.000187, Current Loss: 0.2092, Avg Loss: 0.1997\n",
      "Diff stats — min: -6.7803, max: 10.0000, mean: 4.0544, std: 3.0376\n",
      "\n",
      "Epoch 65, Step 180, LR: 0.000187, Current Loss: 0.2019, Avg Loss: 0.1995\n",
      "Diff stats — min: -5.4278, max: 10.0000, mean: 4.0680, std: 3.0344\n",
      "\n",
      "Epoch 65 completed, Train Loss: 0.000049\n",
      "\n",
      "Epoch 66, Step 1, LR: 0.000187, Current Loss: 0.1878, Avg Loss: 0.1878\n",
      "Diff stats — min: -7.8765, max: 10.0000, mean: 4.2094, std: 2.9949\n",
      "\n",
      "Step 12545 — Test metrics:\n",
      "  precision@10: 0.010696353\n",
      "  recall@10: 0.010700758\n",
      "  ndcg@10: 0.011072792\n",
      "  map@10: 0.003515704\n",
      "Epoch 66, Step 20, LR: 0.000187, Current Loss: 0.2036, Avg Loss: 0.1965\n",
      "Diff stats — min: -4.4702, max: 10.0000, mean: 4.0549, std: 2.9988\n",
      "\n",
      "Epoch 66, Step 40, LR: 0.000187, Current Loss: 0.1856, Avg Loss: 0.1973\n",
      "Diff stats — min: -5.8185, max: 10.0000, mean: 4.1608, std: 3.0022\n",
      "\n",
      "Step 12594 — Test metrics:\n",
      "  precision@10: 0.010914376\n",
      "  recall@10: 0.010918781\n",
      "  ndcg@10: 0.011306959\n",
      "  map@10: 0.003603050\n",
      "Epoch 66, Step 60, LR: 0.000183, Current Loss: 0.1963, Avg Loss: 0.1978\n",
      "Diff stats — min: -6.3621, max: 10.0000, mean: 4.1736, std: 3.0749\n",
      "\n",
      "Epoch 66, Step 80, LR: 0.000183, Current Loss: 0.1949, Avg Loss: 0.1977\n",
      "Diff stats — min: -6.5262, max: 10.0000, mean: 4.1382, std: 3.0147\n",
      "\n",
      "Epoch 66, Step 100, LR: 0.000183, Current Loss: 0.2026, Avg Loss: 0.1979\n",
      "Diff stats — min: -5.8434, max: 10.0000, mean: 4.0971, std: 3.0087\n",
      "\n",
      "Step 12644 — Test metrics:\n",
      "  precision@10: 0.010557611\n",
      "  recall@10: 0.010562016\n",
      "  ndcg@10: 0.010932990\n",
      "  map@10: 0.003459962\n",
      "Epoch 66, Step 120, LR: 0.000183, Current Loss: 0.1972, Avg Loss: 0.1982\n",
      "Diff stats — min: -6.4980, max: 10.0000, mean: 4.1510, std: 3.0541\n",
      "\n",
      "Epoch 66, Step 140, LR: 0.000183, Current Loss: 0.2009, Avg Loss: 0.1983\n",
      "Diff stats — min: -5.2294, max: 10.0000, mean: 4.1136, std: 3.0255\n",
      "\n",
      "Step 12694 — Test metrics:\n",
      "  precision@10: 0.010940803\n",
      "  recall@10: 0.010945208\n",
      "  ndcg@10: 0.011296845\n",
      "  map@10: 0.003581726\n",
      "Epoch 66, Step 160, LR: 0.000183, Current Loss: 0.1956, Avg Loss: 0.1983\n",
      "Diff stats — min: -5.1554, max: 10.0000, mean: 4.1617, std: 3.0204\n",
      "\n",
      "Epoch 66, Step 180, LR: 0.000183, Current Loss: 0.1961, Avg Loss: 0.1980\n",
      "Diff stats — min: -5.4527, max: 10.0000, mean: 4.1632, std: 3.0474\n",
      "\n",
      "Epoch 66 completed, Train Loss: 0.000048\n",
      "\n",
      "Epoch 67, Step 1, LR: 0.000183, Current Loss: 0.1951, Avg Loss: 0.1951\n",
      "Diff stats — min: -6.1155, max: 10.0000, mean: 4.1080, std: 3.0332\n",
      "\n",
      "Step 12738 — Test metrics:\n",
      "  precision@10: 0.010650106\n",
      "  recall@10: 0.010655244\n",
      "  ndcg@10: 0.010983911\n",
      "  map@10: 0.003477876\n",
      "Epoch 67, Step 20, LR: 0.000180, Current Loss: 0.1973, Avg Loss: 0.1954\n",
      "Diff stats — min: -5.8113, max: 10.0000, mean: 4.1990, std: 3.0443\n",
      "\n",
      "Epoch 67, Step 40, LR: 0.000180, Current Loss: 0.1971, Avg Loss: 0.1981\n",
      "Diff stats — min: -5.3511, max: 10.0000, mean: 4.1514, std: 3.0434\n",
      "\n",
      "Step 12787 — Test metrics:\n",
      "  precision@10: 0.010702960\n",
      "  recall@10: 0.010707364\n",
      "  ndcg@10: 0.011072871\n",
      "  map@10: 0.003517209\n",
      "Epoch 67, Step 60, LR: 0.000180, Current Loss: 0.1950, Avg Loss: 0.1978\n",
      "Diff stats — min: -4.9416, max: 10.0000, mean: 4.2087, std: 3.0613\n",
      "\n",
      "Epoch 67, Step 80, LR: 0.000180, Current Loss: 0.1923, Avg Loss: 0.1982\n",
      "Diff stats — min: -5.4591, max: 10.0000, mean: 4.1813, std: 3.0137\n",
      "\n",
      "Epoch 67, Step 100, LR: 0.000180, Current Loss: 0.1932, Avg Loss: 0.1982\n",
      "Diff stats — min: -6.6781, max: 10.0000, mean: 4.1817, std: 3.0521\n",
      "\n",
      "Step 12837 — Test metrics:\n",
      "  precision@10: 0.010802061\n",
      "  recall@10: 0.010807200\n",
      "  ndcg@10: 0.011246287\n",
      "  map@10: 0.003590770\n",
      "Epoch 67, Step 120, LR: 0.000180, Current Loss: 0.2075, Avg Loss: 0.1984\n",
      "Diff stats — min: -6.8949, max: 10.0000, mean: 4.0615, std: 3.0383\n",
      "\n",
      "Epoch 67, Step 140, LR: 0.000180, Current Loss: 0.2058, Avg Loss: 0.1985\n",
      "Diff stats — min: -5.6162, max: 10.0000, mean: 4.1346, std: 3.0960\n",
      "\n",
      "Step 12887 — Test metrics:\n",
      "  precision@10: 0.010551004\n",
      "  recall@10: 0.010555409\n",
      "  ndcg@10: 0.010942816\n",
      "  map@10: 0.003480567\n",
      "Epoch 67, Step 160, LR: 0.000180, Current Loss: 0.2001, Avg Loss: 0.1983\n",
      "Diff stats — min: -5.0216, max: 10.0000, mean: 4.1455, std: 3.0529\n",
      "\n",
      "Epoch 67, Step 180, LR: 0.000176, Current Loss: 0.1968, Avg Loss: 0.1982\n",
      "Diff stats — min: -6.1324, max: 10.0000, mean: 4.1770, std: 3.0506\n",
      "\n",
      "Epoch 67 completed, Train Loss: 0.000048\n",
      "\n",
      "Epoch 68, Step 1, LR: 0.000176, Current Loss: 0.1762, Avg Loss: 0.1762\n",
      "Diff stats — min: -4.5246, max: 10.0000, mean: 4.2210, std: 2.9748\n",
      "\n",
      "Step 12931 — Test metrics:\n",
      "  precision@10: 0.010610465\n",
      "  recall@10: 0.010614870\n",
      "  ndcg@10: 0.011018345\n",
      "  map@10: 0.003508825\n",
      "Epoch 68, Step 20, LR: 0.000176, Current Loss: 0.1851, Avg Loss: 0.1941\n",
      "Diff stats — min: -6.0794, max: 10.0000, mean: 4.2221, std: 3.0098\n",
      "\n",
      "Epoch 68, Step 40, LR: 0.000176, Current Loss: 0.1980, Avg Loss: 0.1949\n",
      "Diff stats — min: -5.8016, max: 10.0000, mean: 4.1365, std: 3.0360\n",
      "\n",
      "Step 12980 — Test metrics:\n",
      "  precision@10: 0.010709567\n",
      "  recall@10: 0.010714705\n",
      "  ndcg@10: 0.011147587\n",
      "  map@10: 0.003549575\n",
      "Epoch 68, Step 60, LR: 0.000176, Current Loss: 0.1994, Avg Loss: 0.1970\n",
      "Diff stats — min: -4.5961, max: 10.0000, mean: 4.2103, std: 3.0691\n",
      "\n",
      "Epoch 68, Step 80, LR: 0.000176, Current Loss: 0.1878, Avg Loss: 0.1962\n",
      "Diff stats — min: -5.9126, max: 10.0000, mean: 4.1932, std: 3.0252\n",
      "\n",
      "Epoch 68, Step 100, LR: 0.000176, Current Loss: 0.2025, Avg Loss: 0.1964\n",
      "Diff stats — min: -6.6942, max: 10.0000, mean: 4.1409, std: 3.0516\n",
      "\n",
      "Step 13030 — Test metrics:\n",
      "  precision@10: 0.010722780\n",
      "  recall@10: 0.010726451\n",
      "  ndcg@10: 0.011182730\n",
      "  map@10: 0.003577789\n",
      "Epoch 68, Step 120, LR: 0.000172, Current Loss: 0.1907, Avg Loss: 0.1969\n",
      "Diff stats — min: -6.3401, max: 10.0000, mean: 4.1272, std: 2.9909\n",
      "\n",
      "Epoch 68, Step 140, LR: 0.000172, Current Loss: 0.1995, Avg Loss: 0.1970\n",
      "Diff stats — min: -6.5043, max: 10.0000, mean: 4.0873, std: 3.0129\n",
      "\n",
      "Step 13080 — Test metrics:\n",
      "  precision@10: 0.010782241\n",
      "  recall@10: 0.010786646\n",
      "  ndcg@10: 0.011155028\n",
      "  map@10: 0.003538862\n",
      "Epoch 68, Step 160, LR: 0.000172, Current Loss: 0.1938, Avg Loss: 0.1968\n",
      "Diff stats — min: -6.4564, max: 10.0000, mean: 4.2284, std: 3.0934\n",
      "\n",
      "Epoch 68, Step 180, LR: 0.000172, Current Loss: 0.2011, Avg Loss: 0.1966\n",
      "Diff stats — min: -5.4503, max: 10.0000, mean: 4.1285, std: 3.0575\n",
      "\n",
      "Epoch 68 completed, Train Loss: 0.000048\n",
      "\n",
      "Epoch 69, Step 1, LR: 0.000172, Current Loss: 0.1881, Avg Loss: 0.1881\n",
      "Diff stats — min: -5.2426, max: 10.0000, mean: 4.2591, std: 3.0358\n",
      "\n",
      "Step 13124 — Test metrics:\n",
      "  precision@10: 0.010636892\n",
      "  recall@10: 0.010644233\n",
      "  ndcg@10: 0.011073001\n",
      "  map@10: 0.003533404\n",
      "Epoch 69, Step 20, LR: 0.000172, Current Loss: 0.2017, Avg Loss: 0.1959\n",
      "Diff stats — min: -6.5528, max: 10.0000, mean: 4.1178, std: 3.0262\n",
      "\n",
      "Epoch 69, Step 40, LR: 0.000172, Current Loss: 0.1923, Avg Loss: 0.1972\n",
      "Diff stats — min: -7.9411, max: 10.0000, mean: 4.2533, std: 3.0506\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/1841242746.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtrain_scheduler_gamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_scheduler_gamma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m model = train_model(model,\n\u001b[0m\u001b[1;32m     24\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mseq_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/1892270750.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, seq_train_data, edge_type, num_epochs, lr, batch_size, device, print_every, test_every, top_k, test_batch_size, scheduler_step_size, scheduler_gamma)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0muser_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mseq_ids_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_times_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_mask_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    feedback_types=feedback_types,\n",
    "    d_model=d_model,\n",
    "    n_head=n_head,\n",
    "    window_size=window_size,\n",
    "    decay=decay,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "edge_type = hyperparameters['train_edge_type']\n",
    "num_epochs = hyperparameters['train_num_epochs']\n",
    "lr = hyperparameters['train_lr']\n",
    "batch_size = hyperparameters['train_batch_size']\n",
    "print_every = hyperparameters['train_print_every']\n",
    "test_every = hyperparameters['train_test_every']\n",
    "top_k = hyperparameters['test_topk']\n",
    "test_batch_size = hyperparameters['test_batch_size']\n",
    "scheduler_step_size = hyperparameters['train_scheduler_step_size']\n",
    "train_scheduler_gamma = hyperparameters['train_scheduler_gamma']\n",
    "\n",
    "model = train_model(model,\n",
    "                    data,\n",
    "                    (seq_ids, event_type, seq_times, seq_mask),\n",
    "                    edge_type=edge_type,\n",
    "                    num_epochs=num_epochs,\n",
    "                    lr=lr,\n",
    "                    batch_size=batch_size,\n",
    "                    print_every=print_every,\n",
    "                    test_every=test_every,\n",
    "                    top_k=top_k,\n",
    "                    test_batch_size=test_batch_size,\n",
    "                    scheduler_step_size=scheduler_step_size,\n",
    "                    scheduler_gamma=train_scheduler_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:27:45.049101Z",
     "iopub.status.busy": "2025-06-25T02:27:45.048573Z",
     "iopub.status.idle": "2025-06-25T02:27:45.116422Z",
     "shell.execute_reply": "2025-06-25T02:27:45.115697Z",
     "shell.execute_reply.started": "2025-06-25T02:27:45.049056Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='gnn_model_mvl.model' target='_blank'>gnn_model_mvl.model</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/gnn_model_mvl.model"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, \"gnn_model_mvl.model\")\n",
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('gnn_model_mvl.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:27:45.689314Z",
     "iopub.status.busy": "2025-06-25T02:27:45.689006Z",
     "iopub.status.idle": "2025-06-25T02:27:46.335779Z",
     "shell.execute_reply": "2025-06-25T02:27:46.335176Z",
     "shell.execute_reply.started": "2025-06-25T02:27:45.689295Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:27:47.229794Z",
     "iopub.status.busy": "2025-06-25T02:27:47.229222Z",
     "iopub.status.idle": "2025-06-25T02:27:47.418115Z",
     "shell.execute_reply": "2025-06-25T02:27:47.417341Z",
     "shell.execute_reply.started": "2025-06-25T02:27:47.229774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "log_model(\n",
    "    experiment=experiment,\n",
    "    model=model,\n",
    "    model_name=\"GNN+THP\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T02:27:48.085317Z",
     "iopub.status.busy": "2025-06-25T02:27:48.085002Z",
     "iopub.status.idle": "2025-06-25T02:27:50.859894Z",
     "shell.execute_reply": "2025-06-25T02:27:50.859129Z",
     "shell.execute_reply.started": "2025-06-25T02:27:48.085296Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : emoSAGE+THP-books\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/annanet/gnn-recommender/5321f7ecb6044c33a138b28b232b1381\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Diff stats (mean) vs step [683] : (-0.051830172538757324, 4.259060382843018)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Diff stats (std) vs step [683]  : (0.6834704875946045, 8.077468872070312)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test map@10 vs step [273]       : (8.525873351454747e-05, 0.003668978277142037)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test ndcg@10 vs step [273]      : (0.0003140293936996998, 0.011515632986891637)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test precision@10 vs step [273] : (0.00033694503171247353, 0.011218287526427062)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test recall@10 vs step [273]    : (0.0003376791167488842, 0.011223426121681937)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Train Loss vs epoch [68]        : (4.806374430542477e-05, 0.00034319379753039236)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Train Loss vs step [13164]      : (0.17221525311470032, 3.8055362701416016)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [1317]                     : (0.18315726518630981, 3.731229305267334)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : emoSAGE+THP-books\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls_id                    : 25457\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_len_of_thp_history    : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pad_id                    : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed                      : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_batch_size           : 8192\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_topk                 : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     thp_decay                 : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     thp_dmodel                : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     thp_dropout               : 0.2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     thp_n_head                : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     thp_window_size           : 101\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_batch_size          : 4096\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_edge_type           : [('item', 'to_feedback_explicit_positive', 'explicit_positive'), ('item', 'to_feedback_implicit_positive', 'implicit_positive')]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_lr                  : 0.001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_num_epochs          : 300\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_print_every         : 20\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_scheduler_gamma     : 0.98\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_scheduler_step_size : 150\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_test_every          : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     types_of_feedback         : ['explicit_positive', 'expliсit_negative', 'implicit_positive', 'implicit_negative']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 2 (29.96 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 file(s), remaining 10.95 MB/29.96 MB\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7705289,
     "sourceId": 12229447,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
