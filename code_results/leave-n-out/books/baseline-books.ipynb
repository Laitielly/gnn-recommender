{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-24T19:59:35.405484Z",
     "iopub.status.busy": "2025-06-24T19:59:35.405213Z",
     "iopub.status.idle": "2025-06-24T19:59:50.455308Z",
     "shell.execute_reply": "2025-06-24T19:59:50.454493Z",
     "shell.execute_reply.started": "2025-06-24T19:59:35.405465Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.1/727.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install torch_geometric rectools\n",
    "!pip -q install comet_ml\n",
    "!pip -q install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:59:50.456332Z",
     "iopub.status.busy": "2025-06-24T19:59:50.456129Z",
     "iopub.status.idle": "2025-06-24T19:59:57.200704Z",
     "shell.execute_reply": "2025-06-24T19:59:57.200169Z",
     "shell.execute_reply.started": "2025-06-24T19:59:50.456308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:59:57.202291Z",
     "iopub.status.busy": "2025-06-24T19:59:57.201897Z",
     "iopub.status.idle": "2025-06-24T19:59:57.209504Z",
     "shell.execute_reply": "2025-06-24T19:59:57.208733Z",
     "shell.execute_reply.started": "2025-06-24T19:59:57.202261Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:59:57.210679Z",
     "iopub.status.busy": "2025-06-24T19:59:57.210437Z",
     "iopub.status.idle": "2025-06-24T20:00:02.106499Z",
     "shell.execute_reply": "2025-06-24T20:00:02.105359Z",
     "shell.execute_reply.started": "2025-06-24T19:59:57.210661Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/annanet/gnn-recommender/e0686063307140c2b54a3db110f14f97\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "  api_key=os.getenv('API_KEY'),\n",
    "  project_name=\"gnn-recommender\",\n",
    "  workspace=\"annanet\",\n",
    "  log_code=True\n",
    ")\n",
    "\n",
    "experiment.set_name('baseline-books')\n",
    "experiment.add_tags(['books', 'leave-n-out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:00:02.112605Z",
     "iopub.status.busy": "2025-06-24T20:00:02.111969Z",
     "iopub.status.idle": "2025-06-24T20:00:02.116928Z",
     "shell.execute_reply": "2025-06-24T20:00:02.116300Z",
     "shell.execute_reply.started": "2025-06-24T20:00:02.112585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'seed': 42,\n",
    "    'types_of_feedback': [\"explicit_positive\", \"expliсit_negative\",\n",
    "                          \"implicit_positive\", \"implicit_negative\"],\n",
    "    'train_edge_type': ('item','to_feedback_explicit_positive','explicit_positive'),\n",
    "    'train_num_epochs': 100,\n",
    "    'train_lr': 8e-5,\n",
    "    'train_batch_size': 32768,\n",
    "    'train_print_every': 10,  \n",
    "    'train_test_every': 50,\n",
    "    'test_topk': 10,\n",
    "    'test_batch_size': 32768\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:00:02.117806Z",
     "iopub.status.busy": "2025-06-24T20:00:02.117620Z",
     "iopub.status.idle": "2025-06-24T20:00:02.154399Z",
     "shell.execute_reply": "2025-06-24T20:00:02.153657Z",
     "shell.execute_reply.started": "2025-06-24T20:00:02.117791Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv', 'test.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('/kaggle/input/data/leave-n-out/books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:00:03.396652Z",
     "iopub.status.busy": "2025-06-24T20:00:03.396344Z",
     "iopub.status.idle": "2025-06-24T20:00:13.958523Z",
     "shell.execute_reply": "2025-06-24T20:00:13.957883Z",
     "shell.execute_reply.started": "2025-06-24T20:00:03.396632Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv, GATConv\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from rectools import Columns\n",
    "from rectools.metrics import MAP, Precision, Recall, NDCG, calc_metrics\n",
    "\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:00:13.960163Z",
     "iopub.status.busy": "2025-06-24T20:00:13.959614Z",
     "iopub.status.idle": "2025-06-24T20:00:13.970126Z",
     "shell.execute_reply": "2025-06-24T20:00:13.969366Z",
     "shell.execute_reply.started": "2025-06-24T20:00:13.960141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = hyperparameters['seed']\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:00:34.412334Z",
     "iopub.status.busy": "2025-06-24T20:00:34.412007Z",
     "iopub.status.idle": "2025-06-24T20:01:06.020341Z",
     "shell.execute_reply": "2025-06-24T20:01:06.019474Z",
     "shell.execute_reply.started": "2025-06-24T20:00:34.412314Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            user_id  book_id  rating  \\\n",
      "0  000883382802f2d95a3dd545bb953882  8525590       3   \n",
      "1  000883382802f2d95a3dd545bb953882  2767052       5   \n",
      "2  000883382802f2d95a3dd545bb953882  3236307       5   \n",
      "3  000883382802f2d95a3dd545bb953882   256683       4   \n",
      "4  000883382802f2d95a3dd545bb953882  6001758       5   \n",
      "\n",
      "                  date_added                       date  \n",
      "0  2011-10-31 18:37:56-07:00  2011-10-31 18:37:56-07:00  \n",
      "1  2011-10-31 18:40:33-07:00  2011-10-31 18:40:33-07:00  \n",
      "2  2011-11-02 08:30:30-07:00  2011-11-02 08:30:30-07:00  \n",
      "3  2011-11-02 08:55:16-07:00  2011-11-02 08:55:16-07:00  \n",
      "4  2011-11-02 08:57:21-07:00  2011-11-02 08:57:21-07:00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/4238775169.py:5: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  train['date'] = pd.to_datetime(train['date_added'])\n"
     ]
    }
   ],
   "source": [
    "rootpath = '/kaggle/input/data/leave-n-out/books/'\n",
    "train = pd.read_csv(\n",
    "    rootpath+'train.csv'\n",
    ")\n",
    "train['date'] = pd.to_datetime(train['date_added'])\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:06.022111Z",
     "iopub.status.busy": "2025-06-24T20:01:06.021628Z",
     "iopub.status.idle": "2025-06-24T20:01:06.114423Z",
     "shell.execute_reply": "2025-06-24T20:01:06.113741Z",
     "shell.execute_reply.started": "2025-06-24T20:01:06.022092Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество explicit позитивного фидбека 359463\n",
      "Количество explicit негативного фидбека 178217\n"
     ]
    }
   ],
   "source": [
    "explicit_positive = train[(train[\"rating\"] == 5)].index\n",
    "explisit_negative = train[(train[\"rating\"] <= 2)].index\n",
    "\n",
    "explicit_combined_feedback = explicit_positive.union(explisit_negative)\n",
    "print('Количество explicit позитивного фидбека', explicit_positive.shape[0])\n",
    "print('Количество explicit негативного фидбека', explisit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:06.115338Z",
     "iopub.status.busy": "2025-06-24T20:01:06.115107Z",
     "iopub.status.idle": "2025-06-24T20:01:06.208119Z",
     "shell.execute_reply": "2025-06-24T20:01:06.207189Z",
     "shell.execute_reply.started": "2025-06-24T20:01:06.115322Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество implicit позитивного фидбека 430342\n",
      "Количество implicit негативного фидбека 258651\n"
     ]
    }
   ],
   "source": [
    "implicit_positive = train[(train[\"rating\"] == 4)].index\n",
    "implicit_negative = train[(train[\"rating\"] == 3)].index\n",
    "\n",
    "implicit_combined_feedback = implicit_positive.union(implicit_negative)\n",
    "print('Количество implicit позитивного фидбека', implicit_positive.shape[0])\n",
    "print('Количество implicit негативного фидбека', implicit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:12.208822Z",
     "iopub.status.busy": "2025-06-24T20:01:12.208305Z",
     "iopub.status.idle": "2025-06-24T20:01:12.363930Z",
     "shell.execute_reply": "2025-06-24T20:01:12.363302Z",
     "shell.execute_reply.started": "2025-06-24T20:01:12.208800Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>8525590</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2011-10-31 18:37:56-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>2767052</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2011-10-31 18:40:33-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>3236307</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2011-11-02 08:30:30-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>256683</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2011-11-02 08:55:16-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>6001758</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2011-11-02 08:57:21-07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id  book_id             target  \\\n",
       "0  000883382802f2d95a3dd545bb953882  8525590  implicit_negative   \n",
       "1  000883382802f2d95a3dd545bb953882  2767052  explicit_positive   \n",
       "2  000883382802f2d95a3dd545bb953882  3236307  explicit_positive   \n",
       "3  000883382802f2d95a3dd545bb953882   256683  implicit_positive   \n",
       "4  000883382802f2d95a3dd545bb953882  6001758  explicit_positive   \n",
       "\n",
       "                        date  \n",
       "0  2011-10-31 18:37:56-07:00  \n",
       "1  2011-10-31 18:40:33-07:00  \n",
       "2  2011-11-02 08:30:30-07:00  \n",
       "3  2011-11-02 08:55:16-07:00  \n",
       "4  2011-11-02 08:57:21-07:00  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:, \"target\"] = \"\"\n",
    "train.loc[explicit_positive, \"target\"] = \"explicit_positive\"\n",
    "train.loc[explisit_negative, \"target\"] = \"expliсit_negative\"\n",
    "train.loc[implicit_positive, \"target\"] = \"implicit_positive\"\n",
    "train.loc[implicit_negative, \"target\"] = \"implicit_negative\"\n",
    "\n",
    "train = train[['user_id','book_id','target','date']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:13.421403Z",
     "iopub.status.busy": "2025-06-24T20:01:13.420782Z",
     "iopub.status.idle": "2025-06-24T20:01:18.824335Z",
     "shell.execute_reply": "2025-06-24T20:01:18.823702Z",
     "shell.execute_reply.started": "2025-06-24T20:01:13.421383Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = train.sort_values(by=[\"user_id\", \"date\"]).reset_index(drop=True)\n",
    "train.columns = ['user_id', 'item_id', 'target', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:18.825648Z",
     "iopub.status.busy": "2025-06-24T20:01:18.825400Z",
     "iopub.status.idle": "2025-06-24T20:01:22.393985Z",
     "shell.execute_reply": "2025-06-24T20:01:22.393044Z",
     "shell.execute_reply.started": "2025-06-24T20:01:18.825623Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            user_id   book_id  rating  \\\n",
      "0  000883382802f2d95a3dd545bb953882   8135807       4   \n",
      "1  000883382802f2d95a3dd545bb953882  18301124       5   \n",
      "2  000883382802f2d95a3dd545bb953882  18220354       4   \n",
      "3  000883382802f2d95a3dd545bb953882  17383918       5   \n",
      "4  000883382802f2d95a3dd545bb953882  13188676       5   \n",
      "\n",
      "                  date_added                       date  \n",
      "0  2013-08-13 09:37:39-07:00  2013-08-13 09:37:39-07:00  \n",
      "1  2013-10-27 22:18:01-07:00  2013-10-27 22:18:01-07:00  \n",
      "2  2013-12-09 22:20:59-08:00  2013-12-09 22:20:59-08:00  \n",
      "3  2013-12-22 20:57:14-08:00  2013-12-22 20:57:14-08:00  \n",
      "4  2013-12-22 20:58:15-08:00  2013-12-22 20:58:15-08:00  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/2717431719.py:4: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  test['date'] = pd.to_datetime(test['date_added'])\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\n",
    "    rootpath+'test.csv'\n",
    ")\n",
    "test['date'] = pd.to_datetime(test['date_added'])\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:22.395401Z",
     "iopub.status.busy": "2025-06-24T20:01:22.395135Z",
     "iopub.status.idle": "2025-06-24T20:01:22.410931Z",
     "shell.execute_reply": "2025-06-24T20:01:22.410194Z",
     "shell.execute_reply.started": "2025-06-24T20:01:22.395385Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>8135807</td>\n",
       "      <td>2013-08-13 09:37:39-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>18301124</td>\n",
       "      <td>2013-10-27 22:18:01-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>18220354</td>\n",
       "      <td>2013-12-09 22:20:59-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>17383918</td>\n",
       "      <td>2013-12-22 20:57:14-08:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000883382802f2d95a3dd545bb953882</td>\n",
       "      <td>13188676</td>\n",
       "      <td>2013-12-22 20:58:15-08:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            user_id   item_id                       date\n",
       "0  000883382802f2d95a3dd545bb953882   8135807  2013-08-13 09:37:39-07:00\n",
       "1  000883382802f2d95a3dd545bb953882  18301124  2013-10-27 22:18:01-07:00\n",
       "2  000883382802f2d95a3dd545bb953882  18220354  2013-12-09 22:20:59-08:00\n",
       "3  000883382802f2d95a3dd545bb953882  17383918  2013-12-22 20:57:14-08:00\n",
       "4  000883382802f2d95a3dd545bb953882  13188676  2013-12-22 20:58:15-08:00"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[['user_id','book_id', 'date']]\n",
    "test.columns = ['user_id', 'item_id', 'date']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP model v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:22.413302Z",
     "iopub.status.busy": "2025-06-24T20:01:22.412967Z",
     "iopub.status.idle": "2025-06-24T20:01:22.487329Z",
     "shell.execute_reply": "2025-06-24T20:01:22.486526Z",
     "shell.execute_reply.started": "2025-06-24T20:01:22.413273Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151126, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[(test.user_id.isin(train.user_id)) & (test.item_id.isin(train.item_id))].copy()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:22.488231Z",
     "iopub.status.busy": "2025-06-24T20:01:22.487990Z",
     "iopub.status.idle": "2025-06-24T20:01:22.933661Z",
     "shell.execute_reply": "2025-06-24T20:01:22.933071Z",
     "shell.execute_reply.started": "2025-06-24T20:01:22.488215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. Преобразование данных - для куарека не особо нужно, но для других - напоминалка\n",
    "# делаем всегда! чтобы не сломать ничего дальше и чтобы все индексы были от 0 до N без пропусков\n",
    "user_encoder = LabelEncoder()\n",
    "video_encoder = LabelEncoder()\n",
    "\n",
    "train.loc[:, 'user_id'] = user_encoder.fit_transform(train['user_id'])\n",
    "train.loc[:, 'item_id'] = video_encoder.fit_transform(train['item_id'])\n",
    "\n",
    "test.loc[:, 'user_id'] = user_encoder.transform(test['user_id'])\n",
    "test.loc[:, 'item_id'] = video_encoder.transform(test['item_id'])\n",
    "\n",
    "train['user_id'] = train['user_id'].astype(int)\n",
    "train['item_id'] = train['item_id'].astype(int)\n",
    "test['user_id'] = test['user_id'].astype(int)\n",
    "test['item_id'] = test['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:22.934750Z",
     "iopub.status.busy": "2025-06-24T20:01:22.934536Z",
     "iopub.status.idle": "2025-06-24T20:01:22.958897Z",
     "shell.execute_reply": "2025-06-24T20:01:22.958081Z",
     "shell.execute_reply.started": "2025-06-24T20:01:22.934734Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных item_id 25456\n",
      "Количество уникальных user_id 18892\n"
     ]
    }
   ],
   "source": [
    "# т.е. сразу знаем количество и в каких пределах изменяется user_id и video_id\n",
    "num_videos = train['item_id'].nunique()\n",
    "num_users = train['user_id'].nunique()\n",
    "\n",
    "print('Количество уникальных item_id', num_videos)\n",
    "print('Количество уникальных user_id', num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:22.959922Z",
     "iopub.status.busy": "2025-06-24T20:01:22.959737Z",
     "iopub.status.idle": "2025-06-24T20:01:22.965012Z",
     "shell.execute_reply": "2025-06-24T20:01:22.964432Z",
     "shell.execute_reply.started": "2025-06-24T20:01:22.959908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_hetero_data(df) -> HeteroData:\n",
    "    \"\"\"\n",
    "    Build a simple hetero-graph with only item->user edges based on interactions in df.\n",
    "    df must contain columns 'item_id' and 'user_id'.\n",
    "    \"\"\"\n",
    "    data = HeteroData()\n",
    "\n",
    "    # Create user and item nodes\n",
    "    users = torch.from_numpy(df['user_id'].unique())\n",
    "    items = torch.from_numpy(df['item_id'].unique())\n",
    "    num_users = int(users.max().item()) + 1\n",
    "    num_items = int(items.max().item()) + 1\n",
    "\n",
    "    data['user'].node_id = torch.arange(num_users)\n",
    "    data['item'].node_id = torch.arange(num_items)\n",
    "\n",
    "    # Build item -> user edge index from interactions\n",
    "    item_ids = torch.LongTensor(df['item_id'].values)\n",
    "    user_ids = torch.LongTensor(df['user_id'].values)\n",
    "    edge_index = torch.stack([item_ids, user_ids], dim=0)\n",
    "\n",
    "    data['item', 'interacts', 'user'].edge_index = edge_index\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:22.966019Z",
     "iopub.status.busy": "2025-06-24T20:01:22.965790Z",
     "iopub.status.idle": "2025-06-24T20:01:22.984289Z",
     "shell.execute_reply": "2025-06-24T20:01:22.983622Z",
     "shell.execute_reply.started": "2025-06-24T20:01:22.966004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, HeteroConv\n",
    "\n",
    "class SimpleItemUserGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Heterogeneous GNN for a bipartite graph with single edge type item->user.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 emb_dim: int = 32,\n",
    "                 hidden_dim: int = 16,\n",
    "                 heads: int = 2,\n",
    "                 dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        # Embeddings\n",
    "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_dim)\n",
    "\n",
    "        # Two-layer HeteroConv with one relation: ('item','interacts','user')\n",
    "        conv1 = {\n",
    "            ('item', 'interacts', 'user'): GATConv(\n",
    "                in_channels=emb_dim,\n",
    "                out_channels=hidden_dim,\n",
    "                heads=heads,\n",
    "                add_self_loops=False\n",
    "            ),\n",
    "        }\n",
    "        conv2 = {\n",
    "            ('item', 'interacts', 'user'): GATConv(\n",
    "                in_channels=hidden_dim * heads,\n",
    "                out_channels=emb_dim,\n",
    "                heads=1,\n",
    "                add_self_loops=False\n",
    "            ),\n",
    "        }\n",
    "        self.conv1 = HeteroConv(conv1, aggr='mean')\n",
    "        self.conv2 = HeteroConv(conv2, aggr='mean')\n",
    "\n",
    "        # LayerNorm & Dropout\n",
    "        self.norm1 = nn.ModuleDict({\n",
    "            'user': nn.LayerNorm(hidden_dim * heads),\n",
    "            'item': nn.LayerNorm(emb_dim)\n",
    "        })\n",
    "        self.norm2 = nn.ModuleDict({\n",
    "            'user': nn.LayerNorm(emb_dim),\n",
    "            'item': nn.LayerNorm(emb_dim)\n",
    "        })\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Initial node features\n",
    "        x = {\n",
    "            'user': self.user_emb(data['user'].node_id),\n",
    "            'item': self.item_emb(data['item'].node_id)\n",
    "        }\n",
    "        # First hetero-conv\n",
    "        h1 = self.conv1(x, data.edge_index_dict)\n",
    "        # Apply activation, norm, dropout\n",
    "        h1_user = F.elu(self.norm1['user'](h1['user']))\n",
    "        h1_user = self.dropout(h1_user)\n",
    "        h1 = {'user': h1_user, 'item': self.item_emb(data['item'].node_id)}\n",
    "\n",
    "        # Second hetero-conv\n",
    "        h2 = self.conv2(h1, data.edge_index_dict)\n",
    "        # Final normalization\n",
    "        h2_user = self.norm2['user'](h2['user'])\n",
    "\n",
    "        return h2_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:22.986265Z",
     "iopub.status.busy": "2025-06-24T20:01:22.986078Z",
     "iopub.status.idle": "2025-06-24T20:01:23.041373Z",
     "shell.execute_reply": "2025-06-24T20:01:23.040756Z",
     "shell.execute_reply.started": "2025-06-24T20:01:22.986252Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ node_id=[18892] },\n",
       "  item={ node_id=[25456] },\n",
       "  (item, interacts, user)={ edge_index=[2, 1226673] }\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = prepare_hetero_data(train)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:23.042175Z",
     "iopub.status.busy": "2025-06-24T20:01:23.041969Z",
     "iopub.status.idle": "2025-06-24T20:01:23.063761Z",
     "shell.execute_reply": "2025-06-24T20:01:23.062985Z",
     "shell.execute_reply.started": "2025-06-24T20:01:23.042160Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25456, 0, 25455)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.item_id.nunique(), train.item_id.min(), train.item_id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:23.065337Z",
     "iopub.status.busy": "2025-06-24T20:01:23.064995Z",
     "iopub.status.idle": "2025-06-24T20:01:23.152487Z",
     "shell.execute_reply": "2025-06-24T20:01:23.151829Z",
     "shell.execute_reply.started": "2025-06-24T20:01:23.065316Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/hetero_conv.py:76: UserWarning: There exist node types ({'item'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_users = len(train['user_id'].unique())\n",
    "num_items = train['item_id'].max() + 1\n",
    "model = SimpleItemUserGNN(num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:24.412273Z",
     "iopub.status.busy": "2025-06-24T20:01:24.411605Z",
     "iopub.status.idle": "2025-06-24T20:01:24.416924Z",
     "shell.execute_reply": "2025-06-24T20:01:24.416134Z",
     "shell.execute_reply.started": "2025-06-24T20:01:24.412251Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleItemUserGNN(\n",
       "  (user_emb): Embedding(18892, 32)\n",
       "  (item_emb): Embedding(25456, 32)\n",
       "  (conv1): HeteroConv(num_relations=1)\n",
       "  (conv2): HeteroConv(num_relations=1)\n",
       "  (norm1): ModuleDict(\n",
       "    (user): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (item): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (norm2): ModuleDict(\n",
       "    (user): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (item): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:25.376083Z",
     "iopub.status.busy": "2025-06-24T20:01:25.375572Z",
     "iopub.status.idle": "2025-06-24T20:01:25.921691Z",
     "shell.execute_reply": "2025-06-24T20:01:25.920902Z",
     "shell.execute_reply.started": "2025-06-24T20:01:25.376048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = test[['user_id', 'item_id']]\n",
    "interactions = test_df.rename(columns={\n",
    "    'user_id': Columns.User,\n",
    "    'item_id': Columns.Item,\n",
    "})\n",
    "\n",
    "viewed_items = train.groupby(\"user_id\")[\"item_id\"].agg(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:26.581666Z",
     "iopub.status.busy": "2025-06-24T20:01:26.580943Z",
     "iopub.status.idle": "2025-06-24T20:01:26.592013Z",
     "shell.execute_reply": "2025-06-24T20:01:26.591182Z",
     "shell.execute_reply.started": "2025-06-24T20:01:26.581642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, train_data,\n",
    "             test_batch_size, top_k,\n",
    "             viewed_items, interactions,\n",
    "             device, test_step):\n",
    "    \"\"\"\n",
    "    Оцениваем модель по всем пользователям:\n",
    "    - строим топ-K рекомендации\n",
    "    - фильтруем уже просмотренные\n",
    "    - считаем recall@K, precision@K, map@K\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    num_users = train_data['user'].node_id.shape[0]\n",
    "    test_top_k = top_k * 150\n",
    "\n",
    "    item_emb = model.item_emb.weight\n",
    "    item_emb_t = item_emb.t().detach()\n",
    "    del item_emb\n",
    "    gc.collect()\n",
    "\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_users, test_batch_size):\n",
    "            end = min(i + test_batch_size, num_users)\n",
    "            batch_users = torch.arange(i, end).to(device)\n",
    "            user_e = model(\n",
    "                data=train_data.to(device)\n",
    "            )\n",
    "            rating = torch.mm(user_e[batch_users].detach(), item_emb_t)\n",
    "            _, topk = torch.topk(rating, k=test_top_k, dim=1)\n",
    "            all_scores.append(topk)\n",
    "\n",
    "            del user_e, rating\n",
    "            gc.collect()\n",
    "    all_scores = torch.cat(all_scores, dim=0).cpu().numpy()\n",
    "\n",
    "    users_list, items, ranks = [], [], []\n",
    "    for u in range(num_users):\n",
    "        seen = viewed_items.get(u, set())\n",
    "        recs = all_scores[u]\n",
    "        mask = ~np.isin(recs, list(seen))\n",
    "        filtered = recs[mask][:top_k]\n",
    "        for rank, it in enumerate(filtered, 1):\n",
    "            users_list.append(u)\n",
    "            items.append(int(it))\n",
    "            ranks.append(rank)\n",
    "    reco_df = pd.DataFrame({\n",
    "        'user_id': users_list,\n",
    "        'item_id': items,\n",
    "        'rank': ranks\n",
    "    })\n",
    "\n",
    "    metrics = {\n",
    "        f'map@{top_k}': MAP(k=top_k),\n",
    "        f'precision@{top_k}': Precision(k=top_k),\n",
    "        f'recall@{top_k}': Recall(k=top_k),\n",
    "        f'ndcg@{top_k}': NDCG(k=top_k)\n",
    "    }\n",
    "    results = calc_metrics(metrics=metrics,\n",
    "                           reco=reco_df,\n",
    "                           interactions=interactions)\n",
    "    print(f\"Step {test_step} — Test metrics:\")\n",
    "    for name, val in results.items():\n",
    "        print(f\"  {name}: {val:.9f}\")\n",
    "        experiment.log_metric(f\"Test {name} vs step\", val, step=test_step)\n",
    "    del all_scores\n",
    "    gc.collect()\n",
    "\n",
    "    model.to(device)\n",
    "    train_data.to(device)\n",
    "    model.train()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:28.497256Z",
     "iopub.status.busy": "2025-06-24T20:01:28.496914Z",
     "iopub.status.idle": "2025-06-24T20:01:28.507398Z",
     "shell.execute_reply": "2025-06-24T20:01:28.506612Z",
     "shell.execute_reply.started": "2025-06-24T20:01:28.497236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "\n",
    "def train_simple_model(model,\n",
    "                       data: HeteroData,\n",
    "                       num_epochs: int = 10,\n",
    "                       lr: float = 1e-3,\n",
    "                       batch_size: int = 1024,\n",
    "                       device: str = None,\n",
    "                       print_every: int = 100,\n",
    "                       test_every: int = 100,\n",
    "                      top_k: int = 10,\n",
    "                      test_batch_size: int = 2048):\n",
    "    \"\"\"\n",
    "    Train a SimpleItemUserGNN on item->user interactions with BPR loss.\n",
    "\n",
    "    Args:\n",
    "        model: SimpleItemUserGNN instance\n",
    "        data: HeteroData containing 'item','interacts','user' edges\n",
    "        num_epochs: number of epochs\n",
    "        lr: learning rate\n",
    "        batch_size: negative sampling batch size\n",
    "        device: 'cpu' or 'cuda'\n",
    "        print_every: print stats every N steps\n",
    "    \"\"\"\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    data = data.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # extract positive edge indices\n",
    "    src, dst = data['item', 'interacts', 'user'].edge_index\n",
    "    num_train = src.size(0)\n",
    "    print(f\"Num of training interactions: {num_train}\")\n",
    "\n",
    "    global_step = 0\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        perm = torch.randperm(num_train, device=device)\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for step, start in enumerate(range(0, num_train, batch_size), 1):\n",
    "            idx = perm[start:start + batch_size]\n",
    "            pos_items = src[idx]\n",
    "            users = dst[idx]\n",
    "            neg_items = torch.randint(\n",
    "                0,\n",
    "                model.item_emb.num_embeddings,\n",
    "                size=pos_items.size(),\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass: get updated embeddings\n",
    "            embeddings = model(data)\n",
    "            user_embs = embeddings[users]\n",
    "            pos_embs = model.item_emb.weight[pos_items]\n",
    "            neg_embs = model.item_emb.weight[neg_items]\n",
    "\n",
    "            # BPR loss\n",
    "            pos_scores = (user_embs * pos_embs).sum(dim=1)\n",
    "            neg_scores = (user_embs * neg_embs).sum(dim=1)\n",
    "            loss = -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-15).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            experiment.log_metric('Train BPR Loss vs step', loss.item(), step=global_step)\n",
    "\n",
    "            total_loss += loss.item() * users.size(0)\n",
    "\n",
    "            if step % print_every == 0 or step == 1:\n",
    "                avg_loss = total_loss / (step * batch_size)\n",
    "                print(f\"Epoch {epoch} Step {step} Loss: {loss.item():.4f}, Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "            if step % test_every == 0 or step == 1:\n",
    "                evaluate(model, data,\n",
    "                         test_batch_size, top_k,\n",
    "                         viewed_items, interactions,\n",
    "                         device, test_step=global_step)\n",
    "\n",
    "            # cleanup\n",
    "            del embeddings, user_embs, pos_embs, neg_embs, pos_scores, neg_scores\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "        epoch_loss = total_loss / num_train\n",
    "        print(f\"Epoch {epoch} completed. Train BPR Loss: {epoch_loss:.4f}\\n\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:30.975355Z",
     "iopub.status.busy": "2025-06-24T20:01:30.974815Z",
     "iopub.status.idle": "2025-06-24T20:01:31.071649Z",
     "shell.execute_reply": "2025-06-24T20:01:31.071074Z",
     "shell.execute_reply.started": "2025-06-24T20:01:30.975335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "experiment.log_parameters(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:32.221917Z",
     "iopub.status.busy": "2025-06-24T20:01:32.221097Z",
     "iopub.status.idle": "2025-06-24T20:01:32.225420Z",
     "shell.execute_reply": "2025-06-24T20:01:32.224828Z",
     "shell.execute_reply.started": "2025-06-24T20:01:32.221890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:01:33.591382Z",
     "iopub.status.busy": "2025-06-24T20:01:33.591105Z",
     "iopub.status.idle": "2025-06-24T20:42:18.413379Z",
     "shell.execute_reply": "2025-06-24T20:42:18.412443Z",
     "shell.execute_reply.started": "2025-06-24T20:01:33.591361Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training interactions: 1226673\n",
      "Epoch 1 Step 1 Loss: 3.3311, Avg Loss: 3.3311\n",
      "Step 0 — Test metrics:\n",
      "  precision@10: 0.000303911\n",
      "  recall@10: 0.000303911\n",
      "  ndcg@10: 0.000307871\n",
      "  map@10: 0.000091409\n",
      "Epoch 1 Step 10 Loss: 3.2369, Avg Loss: 3.3068\n",
      "Epoch 1 Step 20 Loss: 3.2833, Avg Loss: 3.3030\n",
      "Epoch 1 Step 30 Loss: 3.2338, Avg Loss: 3.2921\n",
      "Epoch 1 completed. Train BPR Loss: 3.2873\n",
      "\n",
      "Epoch 2 Step 1 Loss: 3.2594, Avg Loss: 3.2594\n",
      "Step 38 — Test metrics:\n",
      "  precision@10: 0.000303911\n",
      "  recall@10: 0.000303911\n",
      "  ndcg@10: 0.000310474\n",
      "  map@10: 0.000092508\n",
      "Epoch 2 Step 10 Loss: 3.2557, Avg Loss: 3.2535\n",
      "Epoch 2 Step 20 Loss: 3.2712, Avg Loss: 3.2453\n",
      "Epoch 2 Step 30 Loss: 3.2154, Avg Loss: 3.2424\n",
      "Epoch 2 completed. Train BPR Loss: 3.2359\n",
      "\n",
      "Epoch 3 Step 1 Loss: 3.2036, Avg Loss: 3.2036\n",
      "Step 76 — Test metrics:\n",
      "  precision@10: 0.000303911\n",
      "  recall@10: 0.000303911\n",
      "  ndcg@10: 0.000321248\n",
      "  map@10: 0.000099096\n",
      "Epoch 3 Step 10 Loss: 3.2180, Avg Loss: 3.2106\n",
      "Epoch 3 Step 20 Loss: 3.2033, Avg Loss: 3.2032\n",
      "Epoch 3 Step 30 Loss: 3.1329, Avg Loss: 3.1966\n",
      "Epoch 3 completed. Train BPR Loss: 3.1942\n",
      "\n",
      "Epoch 4 Step 1 Loss: 3.1574, Avg Loss: 3.1574\n",
      "Step 114 — Test metrics:\n",
      "  precision@10: 0.000317125\n",
      "  recall@10: 0.000317125\n",
      "  ndcg@10: 0.000332427\n",
      "  map@10: 0.000101917\n",
      "Epoch 4 Step 10 Loss: 3.1534, Avg Loss: 3.1460\n",
      "Epoch 4 Step 20 Loss: 3.1467, Avg Loss: 3.1502\n",
      "Epoch 4 Step 30 Loss: 3.1008, Avg Loss: 3.1426\n",
      "Epoch 4 completed. Train BPR Loss: 3.1403\n",
      "\n",
      "Epoch 5 Step 1 Loss: 3.1237, Avg Loss: 3.1237\n",
      "Step 152 — Test metrics:\n",
      "  precision@10: 0.000317125\n",
      "  recall@10: 0.000317125\n",
      "  ndcg@10: 0.000341424\n",
      "  map@10: 0.000106678\n",
      "Epoch 5 Step 10 Loss: 3.1030, Avg Loss: 3.1139\n",
      "Epoch 5 Step 20 Loss: 3.1042, Avg Loss: 3.1070\n",
      "Epoch 5 Step 30 Loss: 3.1048, Avg Loss: 3.1067\n",
      "Epoch 5 completed. Train BPR Loss: 3.0992\n",
      "\n",
      "Epoch 6 Step 1 Loss: 3.0459, Avg Loss: 3.0459\n",
      "Step 190 — Test metrics:\n",
      "  precision@10: 0.000303911\n",
      "  recall@10: 0.000303911\n",
      "  ndcg@10: 0.000338141\n",
      "  map@10: 0.000108642\n",
      "Epoch 6 Step 10 Loss: 3.0937, Avg Loss: 3.0581\n",
      "Epoch 6 Step 20 Loss: 3.0910, Avg Loss: 3.0664\n",
      "Epoch 6 Step 30 Loss: 3.0774, Avg Loss: 3.0607\n",
      "Epoch 6 completed. Train BPR Loss: 3.0593\n",
      "\n",
      "Epoch 7 Step 1 Loss: 3.0179, Avg Loss: 3.0179\n",
      "Step 228 — Test metrics:\n",
      "  precision@10: 0.000303911\n",
      "  recall@10: 0.000303911\n",
      "  ndcg@10: 0.000338859\n",
      "  map@10: 0.000110427\n",
      "Epoch 7 Step 10 Loss: 3.0296, Avg Loss: 3.0293\n",
      "Epoch 7 Step 20 Loss: 2.9999, Avg Loss: 3.0168\n",
      "Epoch 7 Step 30 Loss: 3.0046, Avg Loss: 3.0161\n",
      "Epoch 7 completed. Train BPR Loss: 3.0108\n",
      "\n",
      "Epoch 8 Step 1 Loss: 2.9762, Avg Loss: 2.9762\n",
      "Step 266 — Test metrics:\n",
      "  precision@10: 0.000310518\n",
      "  recall@10: 0.000310518\n",
      "  ndcg@10: 0.000339623\n",
      "  map@10: 0.000109436\n",
      "Epoch 8 Step 10 Loss: 3.0137, Avg Loss: 2.9978\n",
      "Epoch 8 Step 20 Loss: 2.9663, Avg Loss: 2.9877\n",
      "Epoch 8 Step 30 Loss: 2.9393, Avg Loss: 2.9796\n",
      "Epoch 8 completed. Train BPR Loss: 2.9749\n",
      "\n",
      "Epoch 9 Step 1 Loss: 2.9661, Avg Loss: 2.9661\n",
      "Step 304 — Test metrics:\n",
      "  precision@10: 0.000317125\n",
      "  recall@10: 0.000317125\n",
      "  ndcg@10: 0.000348309\n",
      "  map@10: 0.000112443\n",
      "Epoch 9 Step 10 Loss: 2.9367, Avg Loss: 2.9356\n",
      "Epoch 9 Step 20 Loss: 2.9077, Avg Loss: 2.9345\n",
      "Epoch 9 Step 30 Loss: 2.9347, Avg Loss: 2.9281\n",
      "Epoch 9 completed. Train BPR Loss: 2.9243\n",
      "\n",
      "Epoch 10 Step 1 Loss: 2.8903, Avg Loss: 2.8903\n",
      "Step 342 — Test metrics:\n",
      "  precision@10: 0.000303911\n",
      "  recall@10: 0.000303911\n",
      "  ndcg@10: 0.000344826\n",
      "  map@10: 0.000114460\n",
      "Epoch 10 Step 10 Loss: 2.8877, Avg Loss: 2.8939\n",
      "Epoch 10 Step 20 Loss: 2.8725, Avg Loss: 2.8841\n",
      "Epoch 10 Step 30 Loss: 2.8551, Avg Loss: 2.8819\n",
      "Epoch 10 completed. Train BPR Loss: 2.8787\n",
      "\n",
      "Epoch 11 Step 1 Loss: 2.8126, Avg Loss: 2.8126\n",
      "Step 380 — Test metrics:\n",
      "  precision@10: 0.000336945\n",
      "  recall@10: 0.000336945\n",
      "  ndcg@10: 0.000369807\n",
      "  map@10: 0.000120264\n",
      "Epoch 11 Step 10 Loss: 2.8224, Avg Loss: 2.8387\n",
      "Epoch 11 Step 20 Loss: 2.8120, Avg Loss: 2.8439\n",
      "Epoch 11 Step 30 Loss: 2.8192, Avg Loss: 2.8387\n",
      "Epoch 11 completed. Train BPR Loss: 2.8342\n",
      "\n",
      "Epoch 12 Step 1 Loss: 2.7968, Avg Loss: 2.7968\n",
      "Step 418 — Test metrics:\n",
      "  precision@10: 0.000356765\n",
      "  recall@10: 0.000356765\n",
      "  ndcg@10: 0.000382366\n",
      "  map@10: 0.000122637\n",
      "Epoch 12 Step 10 Loss: 2.8010, Avg Loss: 2.8078\n",
      "Epoch 12 Step 20 Loss: 2.8087, Avg Loss: 2.8005\n",
      "Epoch 12 Step 30 Loss: 2.7989, Avg Loss: 2.7986\n",
      "Epoch 12 completed. Train BPR Loss: 2.7959\n",
      "\n",
      "Epoch 13 Step 1 Loss: 2.7478, Avg Loss: 2.7478\n",
      "Step 456 — Test metrics:\n",
      "  precision@10: 0.000376586\n",
      "  recall@10: 0.000376586\n",
      "  ndcg@10: 0.000400606\n",
      "  map@10: 0.000127503\n",
      "Epoch 13 Step 10 Loss: 2.7468, Avg Loss: 2.7679\n",
      "Epoch 13 Step 20 Loss: 2.7483, Avg Loss: 2.7608\n",
      "Epoch 13 Step 30 Loss: 2.7367, Avg Loss: 2.7529\n",
      "Epoch 13 completed. Train BPR Loss: 2.7482\n",
      "\n",
      "Epoch 14 Step 1 Loss: 2.7420, Avg Loss: 2.7420\n",
      "Step 494 — Test metrics:\n",
      "  precision@10: 0.000396406\n",
      "  recall@10: 0.000396406\n",
      "  ndcg@10: 0.000420961\n",
      "  map@10: 0.000133496\n",
      "Epoch 14 Step 10 Loss: 2.7734, Avg Loss: 2.7207\n",
      "Epoch 14 Step 20 Loss: 2.7074, Avg Loss: 2.7134\n",
      "Epoch 14 Step 30 Loss: 2.6786, Avg Loss: 2.7052\n",
      "Epoch 14 completed. Train BPR Loss: 2.7031\n",
      "\n",
      "Epoch 15 Step 1 Loss: 2.6455, Avg Loss: 2.6455\n",
      "Step 532 — Test metrics:\n",
      "  precision@10: 0.000416226\n",
      "  recall@10: 0.000416226\n",
      "  ndcg@10: 0.000432849\n",
      "  map@10: 0.000133294\n",
      "Epoch 15 Step 10 Loss: 2.6763, Avg Loss: 2.6759\n",
      "Epoch 15 Step 20 Loss: 2.6717, Avg Loss: 2.6703\n",
      "Epoch 15 Step 30 Loss: 2.6797, Avg Loss: 2.6655\n",
      "Epoch 15 completed. Train BPR Loss: 2.6618\n",
      "\n",
      "Epoch 16 Step 1 Loss: 2.6137, Avg Loss: 2.6137\n",
      "Step 570 — Test metrics:\n",
      "  precision@10: 0.000429440\n",
      "  recall@10: 0.000429440\n",
      "  ndcg@10: 0.000440592\n",
      "  map@10: 0.000133588\n",
      "Epoch 16 Step 10 Loss: 2.6810, Avg Loss: 2.6372\n",
      "Epoch 16 Step 20 Loss: 2.6319, Avg Loss: 2.6342\n",
      "Epoch 16 Step 30 Loss: 2.5913, Avg Loss: 2.6257\n",
      "Epoch 16 completed. Train BPR Loss: 2.6204\n",
      "\n",
      "Epoch 17 Step 1 Loss: 2.6095, Avg Loss: 2.6095\n",
      "Step 608 — Test metrics:\n",
      "  precision@10: 0.000403013\n",
      "  recall@10: 0.000403013\n",
      "  ndcg@10: 0.000414860\n",
      "  map@10: 0.000125051\n",
      "Epoch 17 Step 10 Loss: 2.5700, Avg Loss: 2.5939\n",
      "Epoch 17 Step 20 Loss: 2.6101, Avg Loss: 2.5924\n",
      "Epoch 17 Step 30 Loss: 2.5512, Avg Loss: 2.5839\n",
      "Epoch 17 completed. Train BPR Loss: 2.5788\n",
      "\n",
      "Epoch 18 Step 1 Loss: 2.5458, Avg Loss: 2.5458\n",
      "Step 646 — Test metrics:\n",
      "  precision@10: 0.000396406\n",
      "  recall@10: 0.000396406\n",
      "  ndcg@10: 0.000415092\n",
      "  map@10: 0.000127440\n",
      "Epoch 18 Step 10 Loss: 2.5543, Avg Loss: 2.5505\n",
      "Epoch 18 Step 20 Loss: 2.5441, Avg Loss: 2.5445\n",
      "Epoch 18 Step 30 Loss: 2.5149, Avg Loss: 2.5374\n",
      "Epoch 18 completed. Train BPR Loss: 2.5343\n",
      "\n",
      "Epoch 19 Step 1 Loss: 2.5190, Avg Loss: 2.5190\n",
      "Step 684 — Test metrics:\n",
      "  precision@10: 0.000376586\n",
      "  recall@10: 0.000376586\n",
      "  ndcg@10: 0.000401393\n",
      "  map@10: 0.000124084\n",
      "Epoch 19 Step 10 Loss: 2.5222, Avg Loss: 2.5150\n",
      "Epoch 19 Step 20 Loss: 2.4786, Avg Loss: 2.5002\n",
      "Epoch 19 Step 30 Loss: 2.4812, Avg Loss: 2.4960\n",
      "Epoch 19 completed. Train BPR Loss: 2.4916\n",
      "\n",
      "Epoch 20 Step 1 Loss: 2.4450, Avg Loss: 2.4450\n",
      "Step 722 — Test metrics:\n",
      "  precision@10: 0.000409619\n",
      "  recall@10: 0.000410354\n",
      "  ndcg@10: 0.000417814\n",
      "  map@10: 0.000124598\n",
      "Epoch 20 Step 10 Loss: 2.4633, Avg Loss: 2.4712\n",
      "Epoch 20 Step 20 Loss: 2.4880, Avg Loss: 2.4688\n",
      "Epoch 20 Step 30 Loss: 2.4462, Avg Loss: 2.4600\n",
      "Epoch 20 completed. Train BPR Loss: 2.4554\n",
      "\n",
      "Epoch 21 Step 1 Loss: 2.4451, Avg Loss: 2.4451\n",
      "Step 760 — Test metrics:\n",
      "  precision@10: 0.000429440\n",
      "  recall@10: 0.000430174\n",
      "  ndcg@10: 0.000443496\n",
      "  map@10: 0.000134248\n",
      "Epoch 21 Step 10 Loss: 2.3981, Avg Loss: 2.4289\n",
      "Epoch 21 Step 20 Loss: 2.4140, Avg Loss: 2.4263\n",
      "Epoch 21 Step 30 Loss: 2.3984, Avg Loss: 2.4165\n",
      "Epoch 21 completed. Train BPR Loss: 2.4118\n",
      "\n",
      "Epoch 22 Step 1 Loss: 2.3985, Avg Loss: 2.3985\n",
      "Step 798 — Test metrics:\n",
      "  precision@10: 0.000422833\n",
      "  recall@10: 0.000423567\n",
      "  ndcg@10: 0.000440898\n",
      "  map@10: 0.000134157\n",
      "Epoch 22 Step 10 Loss: 2.4246, Avg Loss: 2.3953\n",
      "Epoch 22 Step 20 Loss: 2.3568, Avg Loss: 2.3871\n",
      "Epoch 22 Step 30 Loss: 2.3554, Avg Loss: 2.3831\n",
      "Epoch 22 completed. Train BPR Loss: 2.3750\n",
      "\n",
      "Epoch 23 Step 1 Loss: 2.3568, Avg Loss: 2.3568\n",
      "Step 836 — Test metrics:\n",
      "  precision@10: 0.000429440\n",
      "  recall@10: 0.000430174\n",
      "  ndcg@10: 0.000445179\n",
      "  map@10: 0.000134036\n",
      "Epoch 23 Step 10 Loss: 2.3428, Avg Loss: 2.3410\n",
      "Epoch 23 Step 20 Loss: 2.3723, Avg Loss: 2.3413\n",
      "Epoch 23 Step 30 Loss: 2.3314, Avg Loss: 2.3383\n",
      "Epoch 23 completed. Train BPR Loss: 2.3346\n",
      "\n",
      "Epoch 24 Step 1 Loss: 2.2965, Avg Loss: 2.2965\n",
      "Step 874 — Test metrics:\n",
      "  precision@10: 0.000429440\n",
      "  recall@10: 0.000430174\n",
      "  ndcg@10: 0.000447527\n",
      "  map@10: 0.000135360\n",
      "Epoch 24 Step 10 Loss: 2.2861, Avg Loss: 2.3117\n",
      "Epoch 24 Step 20 Loss: 2.2921, Avg Loss: 2.3064\n",
      "Epoch 24 Step 30 Loss: 2.2648, Avg Loss: 2.3005\n",
      "Epoch 24 completed. Train BPR Loss: 2.2995\n",
      "\n",
      "Epoch 25 Step 1 Loss: 2.2706, Avg Loss: 2.2706\n",
      "Step 912 — Test metrics:\n",
      "  precision@10: 0.000429440\n",
      "  recall@10: 0.000430174\n",
      "  ndcg@10: 0.000439834\n",
      "  map@10: 0.000130625\n",
      "Epoch 25 Step 10 Loss: 2.2808, Avg Loss: 2.2796\n",
      "Epoch 25 Step 20 Loss: 2.2816, Avg Loss: 2.2714\n",
      "Epoch 25 Step 30 Loss: 2.2479, Avg Loss: 2.2666\n",
      "Epoch 25 completed. Train BPR Loss: 2.2621\n",
      "\n",
      "Epoch 26 Step 1 Loss: 2.2156, Avg Loss: 2.2156\n",
      "Step 950 — Test metrics:\n",
      "  precision@10: 0.000416226\n",
      "  recall@10: 0.000416960\n",
      "  ndcg@10: 0.000427706\n",
      "  map@10: 0.000127109\n",
      "Epoch 26 Step 10 Loss: 2.2389, Avg Loss: 2.2243\n",
      "Epoch 26 Step 20 Loss: 2.2226, Avg Loss: 2.2287\n",
      "Epoch 26 Step 30 Loss: 2.2005, Avg Loss: 2.2247\n",
      "Epoch 26 completed. Train BPR Loss: 2.2189\n",
      "\n",
      "Epoch 27 Step 1 Loss: 2.1748, Avg Loss: 2.1748\n",
      "Step 988 — Test metrics:\n",
      "  precision@10: 0.000429440\n",
      "  recall@10: 0.000430174\n",
      "  ndcg@10: 0.000429139\n",
      "  map@10: 0.000124252\n",
      "Epoch 27 Step 10 Loss: 2.2316, Avg Loss: 2.1933\n",
      "Epoch 27 Step 20 Loss: 2.1911, Avg Loss: 2.1955\n",
      "Epoch 27 Step 30 Loss: 2.2250, Avg Loss: 2.1933\n",
      "Epoch 27 completed. Train BPR Loss: 2.1880\n",
      "\n",
      "Epoch 28 Step 1 Loss: 2.1691, Avg Loss: 2.1691\n",
      "Step 1026 — Test metrics:\n",
      "  precision@10: 0.000429440\n",
      "  recall@10: 0.000430174\n",
      "  ndcg@10: 0.000441084\n",
      "  map@10: 0.000131160\n",
      "Epoch 28 Step 10 Loss: 2.1886, Avg Loss: 2.1721\n",
      "Epoch 28 Step 20 Loss: 2.1398, Avg Loss: 2.1643\n",
      "Epoch 28 Step 30 Loss: 2.1539, Avg Loss: 2.1605\n",
      "Epoch 28 completed. Train BPR Loss: 2.1547\n",
      "\n",
      "Epoch 29 Step 1 Loss: 2.1623, Avg Loss: 2.1623\n",
      "Step 1064 — Test metrics:\n",
      "  precision@10: 0.000442653\n",
      "  recall@10: 0.000443387\n",
      "  ndcg@10: 0.000442471\n",
      "  map@10: 0.000128575\n",
      "Epoch 29 Step 10 Loss: 2.1367, Avg Loss: 2.1225\n",
      "Epoch 29 Step 20 Loss: 2.1006, Avg Loss: 2.1210\n",
      "Epoch 29 Step 30 Loss: 2.0983, Avg Loss: 2.1167\n",
      "Epoch 29 completed. Train BPR Loss: 2.1119\n",
      "\n",
      "Epoch 30 Step 1 Loss: 2.0909, Avg Loss: 2.0909\n",
      "Step 1102 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000451042\n",
      "  map@10: 0.000128517\n",
      "Epoch 30 Step 10 Loss: 2.0738, Avg Loss: 2.0920\n",
      "Epoch 30 Step 20 Loss: 2.0776, Avg Loss: 2.0861\n",
      "Epoch 30 Step 30 Loss: 2.1000, Avg Loss: 2.0838\n",
      "Epoch 30 completed. Train BPR Loss: 2.0803\n",
      "\n",
      "Epoch 31 Step 1 Loss: 2.0252, Avg Loss: 2.0252\n",
      "Step 1140 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000450855\n",
      "  map@10: 0.000126682\n",
      "Epoch 31 Step 10 Loss: 2.0538, Avg Loss: 2.0486\n",
      "Epoch 31 Step 20 Loss: 2.0256, Avg Loss: 2.0464\n",
      "Epoch 31 Step 30 Loss: 2.0268, Avg Loss: 2.0394\n",
      "Epoch 31 completed. Train BPR Loss: 2.0411\n",
      "\n",
      "Epoch 32 Step 1 Loss: 2.0258, Avg Loss: 2.0258\n",
      "Step 1178 — Test metrics:\n",
      "  precision@10: 0.000488901\n",
      "  recall@10: 0.000489635\n",
      "  ndcg@10: 0.000460637\n",
      "  map@10: 0.000127254\n",
      "Epoch 32 Step 10 Loss: 1.9968, Avg Loss: 2.0246\n",
      "Epoch 32 Step 20 Loss: 2.0118, Avg Loss: 2.0166\n",
      "Epoch 32 Step 30 Loss: 1.9972, Avg Loss: 2.0109\n",
      "Epoch 32 completed. Train BPR Loss: 2.0084\n",
      "\n",
      "Epoch 33 Step 1 Loss: 1.9893, Avg Loss: 1.9893\n",
      "Step 1216 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000445310\n",
      "  map@10: 0.000123992\n",
      "Epoch 33 Step 10 Loss: 1.9935, Avg Loss: 1.9940\n",
      "Epoch 33 Step 20 Loss: 1.9910, Avg Loss: 1.9886\n",
      "Epoch 33 Step 30 Loss: 1.9689, Avg Loss: 1.9797\n",
      "Epoch 33 completed. Train BPR Loss: 1.9768\n",
      "\n",
      "Epoch 34 Step 1 Loss: 1.9893, Avg Loss: 1.9893\n",
      "Step 1254 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000439454\n",
      "  map@10: 0.000122514\n",
      "Epoch 34 Step 10 Loss: 1.9616, Avg Loss: 1.9599\n",
      "Epoch 34 Step 20 Loss: 1.9414, Avg Loss: 1.9513\n",
      "Epoch 34 Step 30 Loss: 1.9314, Avg Loss: 1.9470\n",
      "Epoch 34 completed. Train BPR Loss: 1.9431\n",
      "\n",
      "Epoch 35 Step 1 Loss: 1.9222, Avg Loss: 1.9222\n",
      "Step 1292 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000445316\n",
      "  map@10: 0.000126145\n",
      "Epoch 35 Step 10 Loss: 1.9283, Avg Loss: 1.9200\n",
      "Epoch 35 Step 20 Loss: 1.9319, Avg Loss: 1.9195\n",
      "Epoch 35 Step 30 Loss: 1.8808, Avg Loss: 1.9159\n",
      "Epoch 35 completed. Train BPR Loss: 1.9127\n",
      "\n",
      "Epoch 36 Step 1 Loss: 1.9128, Avg Loss: 1.9128\n",
      "Step 1330 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000439190\n",
      "  map@10: 0.000120712\n",
      "Epoch 36 Step 10 Loss: 1.8758, Avg Loss: 1.8940\n",
      "Epoch 36 Step 20 Loss: 1.8858, Avg Loss: 1.8930\n",
      "Epoch 36 Step 30 Loss: 1.8780, Avg Loss: 1.8868\n",
      "Epoch 36 completed. Train BPR Loss: 1.8847\n",
      "\n",
      "Epoch 37 Step 1 Loss: 1.8829, Avg Loss: 1.8829\n",
      "Step 1368 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000436158\n",
      "  map@10: 0.000118935\n",
      "Epoch 37 Step 10 Loss: 1.8656, Avg Loss: 1.8691\n",
      "Epoch 37 Step 20 Loss: 1.8590, Avg Loss: 1.8577\n",
      "Epoch 37 Step 30 Loss: 1.8216, Avg Loss: 1.8569\n",
      "Epoch 37 completed. Train BPR Loss: 1.8536\n",
      "\n",
      "Epoch 38 Step 1 Loss: 1.8270, Avg Loss: 1.8270\n",
      "Step 1406 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000435667\n",
      "  map@10: 0.000118694\n",
      "Epoch 38 Step 10 Loss: 1.8273, Avg Loss: 1.8363\n",
      "Epoch 38 Step 20 Loss: 1.8022, Avg Loss: 1.8301\n",
      "Epoch 38 Step 30 Loss: 1.8101, Avg Loss: 1.8272\n",
      "Epoch 38 completed. Train BPR Loss: 1.8240\n",
      "\n",
      "Epoch 39 Step 1 Loss: 1.8001, Avg Loss: 1.8001\n",
      "Step 1444 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000430176\n",
      "  map@10: 0.000115343\n",
      "Epoch 39 Step 10 Loss: 1.7936, Avg Loss: 1.7987\n",
      "Epoch 39 Step 20 Loss: 1.7762, Avg Loss: 1.7991\n",
      "Epoch 39 Step 30 Loss: 1.7855, Avg Loss: 1.7958\n",
      "Epoch 39 completed. Train BPR Loss: 1.7932\n",
      "\n",
      "Epoch 40 Step 1 Loss: 1.7720, Avg Loss: 1.7720\n",
      "Step 1482 — Test metrics:\n",
      "  precision@10: 0.000455867\n",
      "  recall@10: 0.000456601\n",
      "  ndcg@10: 0.000423049\n",
      "  map@10: 0.000114962\n",
      "Epoch 40 Step 10 Loss: 1.7908, Avg Loss: 1.7785\n",
      "Epoch 40 Step 20 Loss: 1.7719, Avg Loss: 1.7729\n",
      "Epoch 40 Step 30 Loss: 1.7251, Avg Loss: 1.7677\n",
      "Epoch 40 completed. Train BPR Loss: 1.7643\n",
      "\n",
      "Epoch 41 Step 1 Loss: 1.7601, Avg Loss: 1.7601\n",
      "Step 1520 — Test metrics:\n",
      "  precision@10: 0.000442653\n",
      "  recall@10: 0.000443387\n",
      "  ndcg@10: 0.000413715\n",
      "  map@10: 0.000113111\n",
      "Epoch 41 Step 10 Loss: 1.7360, Avg Loss: 1.7356\n",
      "Epoch 41 Step 20 Loss: 1.7177, Avg Loss: 1.7390\n",
      "Epoch 41 Step 30 Loss: 1.7266, Avg Loss: 1.7357\n",
      "Epoch 41 completed. Train BPR Loss: 1.7343\n",
      "\n",
      "Epoch 42 Step 1 Loss: 1.7357, Avg Loss: 1.7357\n",
      "Step 1558 — Test metrics:\n",
      "  precision@10: 0.000429440\n",
      "  recall@10: 0.000430174\n",
      "  ndcg@10: 0.000400120\n",
      "  map@10: 0.000108791\n",
      "Epoch 42 Step 10 Loss: 1.7188, Avg Loss: 1.7193\n",
      "Epoch 42 Step 20 Loss: 1.7111, Avg Loss: 1.7174\n",
      "Epoch 42 Step 30 Loss: 1.6879, Avg Loss: 1.7120\n",
      "Epoch 42 completed. Train BPR Loss: 1.7079\n",
      "\n",
      "Epoch 43 Step 1 Loss: 1.7028, Avg Loss: 1.7028\n",
      "Step 1596 — Test metrics:\n",
      "  precision@10: 0.000436047\n",
      "  recall@10: 0.000436781\n",
      "  ndcg@10: 0.000404376\n",
      "  map@10: 0.000109973\n",
      "Epoch 43 Step 10 Loss: 1.6528, Avg Loss: 1.6904\n",
      "Epoch 43 Step 20 Loss: 1.7043, Avg Loss: 1.6899\n",
      "Epoch 43 Step 30 Loss: 1.6951, Avg Loss: 1.6871\n",
      "Epoch 43 completed. Train BPR Loss: 1.6841\n",
      "\n",
      "Epoch 44 Step 1 Loss: 1.6558, Avg Loss: 1.6558\n",
      "Step 1634 — Test metrics:\n",
      "  precision@10: 0.000429440\n",
      "  recall@10: 0.000430174\n",
      "  ndcg@10: 0.000392062\n",
      "  map@10: 0.000104373\n",
      "Epoch 44 Step 10 Loss: 1.6525, Avg Loss: 1.6644\n",
      "Epoch 44 Step 20 Loss: 1.6406, Avg Loss: 1.6598\n",
      "Epoch 44 Step 30 Loss: 1.6603, Avg Loss: 1.6538\n",
      "Epoch 44 completed. Train BPR Loss: 1.6515\n",
      "\n",
      "Epoch 45 Step 1 Loss: 1.6412, Avg Loss: 1.6412\n",
      "Step 1672 — Test metrics:\n",
      "  precision@10: 0.000442653\n",
      "  recall@10: 0.000443387\n",
      "  ndcg@10: 0.000394139\n",
      "  map@10: 0.000101982\n",
      "Epoch 45 Step 10 Loss: 1.6541, Avg Loss: 1.6332\n",
      "Epoch 45 Step 20 Loss: 1.6202, Avg Loss: 1.6336\n",
      "Epoch 45 Step 30 Loss: 1.6398, Avg Loss: 1.6328\n",
      "Epoch 45 completed. Train BPR Loss: 1.6291\n",
      "\n",
      "Epoch 46 Step 1 Loss: 1.6228, Avg Loss: 1.6228\n",
      "Step 1710 — Test metrics:\n",
      "  precision@10: 0.000449260\n",
      "  recall@10: 0.000449994\n",
      "  ndcg@10: 0.000396710\n",
      "  map@10: 0.000101688\n",
      "Epoch 46 Step 10 Loss: 1.6248, Avg Loss: 1.6147\n",
      "Epoch 46 Step 20 Loss: 1.5959, Avg Loss: 1.6098\n",
      "Epoch 46 Step 30 Loss: 1.5929, Avg Loss: 1.6064\n",
      "Epoch 46 completed. Train BPR Loss: 1.6054\n",
      "\n",
      "Epoch 47 Step 1 Loss: 1.5753, Avg Loss: 1.5753\n",
      "Step 1748 — Test metrics:\n",
      "  precision@10: 0.000442653\n",
      "  recall@10: 0.000443387\n",
      "  ndcg@10: 0.000393099\n",
      "  map@10: 0.000101303\n",
      "Epoch 47 Step 10 Loss: 1.5889, Avg Loss: 1.5847\n",
      "Epoch 47 Step 20 Loss: 1.5690, Avg Loss: 1.5788\n",
      "Epoch 47 Step 30 Loss: 1.5728, Avg Loss: 1.5757\n",
      "Epoch 47 completed. Train BPR Loss: 1.5755\n",
      "\n",
      "Epoch 48 Step 1 Loss: 1.5561, Avg Loss: 1.5561\n",
      "Step 1786 — Test metrics:\n",
      "  precision@10: 0.000416226\n",
      "  recall@10: 0.000416960\n",
      "  ndcg@10: 0.000374727\n",
      "  map@10: 0.000097745\n",
      "Epoch 48 Step 10 Loss: 1.5435, Avg Loss: 1.5584\n",
      "Epoch 48 Step 20 Loss: 1.5666, Avg Loss: 1.5567\n",
      "Epoch 48 Step 30 Loss: 1.5526, Avg Loss: 1.5544\n",
      "Epoch 48 completed. Train BPR Loss: 1.5526\n",
      "\n",
      "Epoch 49 Step 1 Loss: 1.5409, Avg Loss: 1.5409\n",
      "Step 1824 — Test metrics:\n",
      "  precision@10: 0.000403013\n",
      "  recall@10: 0.000403747\n",
      "  ndcg@10: 0.000367453\n",
      "  map@10: 0.000097001\n",
      "Epoch 49 Step 10 Loss: 1.5412, Avg Loss: 1.5438\n",
      "Epoch 49 Step 20 Loss: 1.5358, Avg Loss: 1.5368\n",
      "Epoch 49 Step 30 Loss: 1.5148, Avg Loss: 1.5326\n",
      "Epoch 49 completed. Train BPR Loss: 1.5299\n",
      "\n",
      "Epoch 50 Step 1 Loss: 1.5221, Avg Loss: 1.5221\n",
      "Step 1862 — Test metrics:\n",
      "  precision@10: 0.000403013\n",
      "  recall@10: 0.000403747\n",
      "  ndcg@10: 0.000366498\n",
      "  map@10: 0.000096468\n",
      "Epoch 50 Step 10 Loss: 1.5299, Avg Loss: 1.5065\n",
      "Epoch 50 Step 20 Loss: 1.4950, Avg Loss: 1.5064\n",
      "Epoch 50 Step 30 Loss: 1.5075, Avg Loss: 1.5016\n",
      "Epoch 50 completed. Train BPR Loss: 1.4996\n",
      "\n",
      "Epoch 51 Step 1 Loss: 1.4847, Avg Loss: 1.4847\n",
      "Step 1900 — Test metrics:\n",
      "  precision@10: 0.000409619\n",
      "  recall@10: 0.000410354\n",
      "  ndcg@10: 0.000369247\n",
      "  map@10: 0.000096358\n",
      "Epoch 51 Step 10 Loss: 1.4959, Avg Loss: 1.4925\n",
      "Epoch 51 Step 20 Loss: 1.4822, Avg Loss: 1.4855\n",
      "Epoch 51 Step 30 Loss: 1.4671, Avg Loss: 1.4824\n",
      "Epoch 51 completed. Train BPR Loss: 1.4799\n",
      "\n",
      "Epoch 52 Step 1 Loss: 1.4598, Avg Loss: 1.4598\n",
      "Step 1938 — Test metrics:\n",
      "  precision@10: 0.000396406\n",
      "  recall@10: 0.000397140\n",
      "  ndcg@10: 0.000359587\n",
      "  map@10: 0.000094277\n",
      "Epoch 52 Step 10 Loss: 1.4707, Avg Loss: 1.4612\n",
      "Epoch 52 Step 20 Loss: 1.4199, Avg Loss: 1.4585\n",
      "Epoch 52 Step 30 Loss: 1.4712, Avg Loss: 1.4580\n",
      "Epoch 52 completed. Train BPR Loss: 1.4565\n",
      "\n",
      "Epoch 53 Step 1 Loss: 1.4500, Avg Loss: 1.4500\n",
      "Step 1976 — Test metrics:\n",
      "  precision@10: 0.000416226\n",
      "  recall@10: 0.000416960\n",
      "  ndcg@10: 0.000372555\n",
      "  map@10: 0.000096432\n",
      "Epoch 53 Step 10 Loss: 1.4412, Avg Loss: 1.4456\n",
      "Epoch 53 Step 20 Loss: 1.4302, Avg Loss: 1.4428\n",
      "Epoch 53 Step 30 Loss: 1.4413, Avg Loss: 1.4388\n",
      "Epoch 53 completed. Train BPR Loss: 1.4366\n",
      "\n",
      "Epoch 54 Step 1 Loss: 1.4231, Avg Loss: 1.4231\n",
      "Step 2014 — Test metrics:\n",
      "  precision@10: 0.000409619\n",
      "  recall@10: 0.000410354\n",
      "  ndcg@10: 0.000369659\n",
      "  map@10: 0.000096421\n",
      "Epoch 54 Step 10 Loss: 1.4280, Avg Loss: 1.4204\n",
      "Epoch 54 Step 20 Loss: 1.4237, Avg Loss: 1.4190\n",
      "Epoch 54 Step 30 Loss: 1.3814, Avg Loss: 1.4128\n",
      "Epoch 54 completed. Train BPR Loss: 1.4113\n",
      "\n",
      "Epoch 55 Step 1 Loss: 1.4192, Avg Loss: 1.4192\n",
      "Step 2052 — Test metrics:\n",
      "  precision@10: 0.000436047\n",
      "  recall@10: 0.000436781\n",
      "  ndcg@10: 0.000387733\n",
      "  map@10: 0.000099656\n",
      "Epoch 55 Step 10 Loss: 1.3968, Avg Loss: 1.4032\n",
      "Epoch 55 Step 20 Loss: 1.3866, Avg Loss: 1.4002\n",
      "Epoch 55 Step 30 Loss: 1.3832, Avg Loss: 1.3956\n",
      "Epoch 55 completed. Train BPR Loss: 1.3912\n",
      "\n",
      "Epoch 56 Step 1 Loss: 1.3533, Avg Loss: 1.3533\n",
      "Step 2090 — Test metrics:\n",
      "  precision@10: 0.000429440\n",
      "  recall@10: 0.000430174\n",
      "  ndcg@10: 0.000383455\n",
      "  map@10: 0.000098912\n",
      "Epoch 56 Step 10 Loss: 1.3850, Avg Loss: 1.3731\n",
      "Epoch 56 Step 20 Loss: 1.3807, Avg Loss: 1.3739\n",
      "Epoch 56 Step 30 Loss: 1.3523, Avg Loss: 1.3722\n",
      "Epoch 56 completed. Train BPR Loss: 1.3692\n",
      "\n",
      "Epoch 57 Step 1 Loss: 1.3609, Avg Loss: 1.3609\n",
      "Step 2128 — Test metrics:\n",
      "  precision@10: 0.000442653\n",
      "  recall@10: 0.000443387\n",
      "  ndcg@10: 0.000395490\n",
      "  map@10: 0.000102207\n",
      "Epoch 57 Step 10 Loss: 1.3838, Avg Loss: 1.3581\n",
      "Epoch 57 Step 20 Loss: 1.3521, Avg Loss: 1.3569\n",
      "Epoch 57 Step 30 Loss: 1.3222, Avg Loss: 1.3533\n",
      "Epoch 57 completed. Train BPR Loss: 1.3517\n",
      "\n",
      "Epoch 58 Step 1 Loss: 1.3433, Avg Loss: 1.3433\n",
      "Step 2166 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000412928\n",
      "  map@10: 0.000105152\n",
      "Epoch 58 Step 10 Loss: 1.3376, Avg Loss: 1.3386\n",
      "Epoch 58 Step 20 Loss: 1.3074, Avg Loss: 1.3315\n",
      "Epoch 58 Step 30 Loss: 1.2979, Avg Loss: 1.3283\n",
      "Epoch 58 completed. Train BPR Loss: 1.3265\n",
      "\n",
      "Epoch 59 Step 1 Loss: 1.3190, Avg Loss: 1.3190\n",
      "Step 2204 — Test metrics:\n",
      "  precision@10: 0.000455867\n",
      "  recall@10: 0.000456601\n",
      "  ndcg@10: 0.000404334\n",
      "  map@10: 0.000103752\n",
      "Epoch 59 Step 10 Loss: 1.3295, Avg Loss: 1.3166\n",
      "Epoch 59 Step 20 Loss: 1.3175, Avg Loss: 1.3141\n",
      "Epoch 59 Step 30 Loss: 1.2990, Avg Loss: 1.3101\n",
      "Epoch 59 completed. Train BPR Loss: 1.3083\n",
      "\n",
      "Epoch 60 Step 1 Loss: 1.2797, Avg Loss: 1.2797\n",
      "Step 2242 — Test metrics:\n",
      "  precision@10: 0.000462474\n",
      "  recall@10: 0.000463208\n",
      "  ndcg@10: 0.000409969\n",
      "  map@10: 0.000105110\n",
      "Epoch 60 Step 10 Loss: 1.3093, Avg Loss: 1.2994\n",
      "Epoch 60 Step 20 Loss: 1.2848, Avg Loss: 1.2942\n",
      "Epoch 60 Step 30 Loss: 1.2803, Avg Loss: 1.2911\n",
      "Epoch 60 completed. Train BPR Loss: 1.2885\n",
      "\n",
      "Epoch 61 Step 1 Loss: 1.2984, Avg Loss: 1.2984\n",
      "Step 2280 — Test metrics:\n",
      "  precision@10: 0.000469080\n",
      "  recall@10: 0.000469814\n",
      "  ndcg@10: 0.000416504\n",
      "  map@10: 0.000106908\n",
      "Epoch 61 Step 10 Loss: 1.2824, Avg Loss: 1.2830\n",
      "Epoch 61 Step 20 Loss: 1.2768, Avg Loss: 1.2770\n",
      "Epoch 61 Step 30 Loss: 1.2907, Avg Loss: 1.2738\n",
      "Epoch 61 completed. Train BPR Loss: 1.2713\n",
      "\n",
      "Epoch 62 Step 1 Loss: 1.2464, Avg Loss: 1.2464\n",
      "Step 2318 — Test metrics:\n",
      "  precision@10: 0.000475687\n",
      "  recall@10: 0.000476421\n",
      "  ndcg@10: 0.000420277\n",
      "  map@10: 0.000107338\n",
      "Epoch 62 Step 10 Loss: 1.2682, Avg Loss: 1.2571\n",
      "Epoch 62 Step 20 Loss: 1.2381, Avg Loss: 1.2570\n",
      "Epoch 62 Step 30 Loss: 1.2406, Avg Loss: 1.2523\n",
      "Epoch 62 completed. Train BPR Loss: 1.2505\n",
      "\n",
      "Epoch 63 Step 1 Loss: 1.2375, Avg Loss: 1.2375\n",
      "Step 2356 — Test metrics:\n",
      "  precision@10: 0.000475687\n",
      "  recall@10: 0.000476421\n",
      "  ndcg@10: 0.000421231\n",
      "  map@10: 0.000107771\n",
      "Epoch 63 Step 10 Loss: 1.2455, Avg Loss: 1.2377\n",
      "Epoch 63 Step 20 Loss: 1.2430, Avg Loss: 1.2373\n",
      "Epoch 63 Step 30 Loss: 1.2309, Avg Loss: 1.2363\n",
      "Epoch 63 completed. Train BPR Loss: 1.2348\n",
      "\n",
      "Epoch 64 Step 1 Loss: 1.2360, Avg Loss: 1.2360\n",
      "Step 2394 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000425831\n",
      "  map@10: 0.000108602\n",
      "Epoch 64 Step 10 Loss: 1.2288, Avg Loss: 1.2237\n",
      "Epoch 64 Step 20 Loss: 1.1942, Avg Loss: 1.2202\n",
      "Epoch 64 Step 30 Loss: 1.2169, Avg Loss: 1.2170\n",
      "Epoch 64 completed. Train BPR Loss: 1.2160\n",
      "\n",
      "Epoch 65 Step 1 Loss: 1.2098, Avg Loss: 1.2098\n",
      "Step 2432 — Test metrics:\n",
      "  precision@10: 0.000488901\n",
      "  recall@10: 0.000489635\n",
      "  ndcg@10: 0.000430838\n",
      "  map@10: 0.000109632\n",
      "Epoch 65 Step 10 Loss: 1.2095, Avg Loss: 1.2030\n",
      "Epoch 65 Step 20 Loss: 1.2096, Avg Loss: 1.2037\n",
      "Epoch 65 Step 30 Loss: 1.2117, Avg Loss: 1.1997\n",
      "Epoch 65 completed. Train BPR Loss: 1.1979\n",
      "\n",
      "Epoch 66 Step 1 Loss: 1.1753, Avg Loss: 1.1753\n",
      "Step 2470 — Test metrics:\n",
      "  precision@10: 0.000488901\n",
      "  recall@10: 0.000489635\n",
      "  ndcg@10: 0.000433502\n",
      "  map@10: 0.000110909\n",
      "Epoch 66 Step 10 Loss: 1.2074, Avg Loss: 1.1826\n",
      "Epoch 66 Step 20 Loss: 1.1879, Avg Loss: 1.1825\n",
      "Epoch 66 Step 30 Loss: 1.1607, Avg Loss: 1.1803\n",
      "Epoch 66 completed. Train BPR Loss: 1.1790\n",
      "\n",
      "Epoch 67 Step 1 Loss: 1.1727, Avg Loss: 1.1727\n",
      "Step 2508 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000428245\n",
      "  map@10: 0.000109640\n",
      "Epoch 67 Step 10 Loss: 1.1791, Avg Loss: 1.1727\n",
      "Epoch 67 Step 20 Loss: 1.1670, Avg Loss: 1.1712\n",
      "Epoch 67 Step 30 Loss: 1.1549, Avg Loss: 1.1670\n",
      "Epoch 67 completed. Train BPR Loss: 1.1645\n",
      "\n",
      "Epoch 68 Step 1 Loss: 1.1555, Avg Loss: 1.1555\n",
      "Step 2546 — Test metrics:\n",
      "  precision@10: 0.000475687\n",
      "  recall@10: 0.000476421\n",
      "  ndcg@10: 0.000425025\n",
      "  map@10: 0.000109556\n",
      "Epoch 68 Step 10 Loss: 1.1413, Avg Loss: 1.1488\n",
      "Epoch 68 Step 20 Loss: 1.1460, Avg Loss: 1.1499\n",
      "Epoch 68 Step 30 Loss: 1.1356, Avg Loss: 1.1462\n",
      "Epoch 68 completed. Train BPR Loss: 1.1441\n",
      "\n",
      "Epoch 69 Step 1 Loss: 1.1393, Avg Loss: 1.1393\n",
      "Step 2584 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000428896\n",
      "  map@10: 0.000110059\n",
      "Epoch 69 Step 10 Loss: 1.1251, Avg Loss: 1.1346\n",
      "Epoch 69 Step 20 Loss: 1.1258, Avg Loss: 1.1361\n",
      "Epoch 69 Step 30 Loss: 1.1231, Avg Loss: 1.1323\n",
      "Epoch 69 completed. Train BPR Loss: 1.1302\n",
      "\n",
      "Epoch 70 Step 1 Loss: 1.1107, Avg Loss: 1.1107\n",
      "Step 2622 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000429169\n",
      "  map@10: 0.000110122\n",
      "Epoch 70 Step 10 Loss: 1.1397, Avg Loss: 1.1199\n",
      "Epoch 70 Step 20 Loss: 1.1163, Avg Loss: 1.1172\n",
      "Epoch 70 Step 30 Loss: 1.1034, Avg Loss: 1.1145\n",
      "Epoch 70 completed. Train BPR Loss: 1.1135\n",
      "\n",
      "Epoch 71 Step 1 Loss: 1.0843, Avg Loss: 1.0843\n",
      "Step 2660 — Test metrics:\n",
      "  precision@10: 0.000488901\n",
      "  recall@10: 0.000489635\n",
      "  ndcg@10: 0.000432752\n",
      "  map@10: 0.000110453\n",
      "Epoch 71 Step 10 Loss: 1.1006, Avg Loss: 1.0978\n",
      "Epoch 71 Step 20 Loss: 1.1074, Avg Loss: 1.0976\n",
      "Epoch 71 Step 30 Loss: 1.1003, Avg Loss: 1.0982\n",
      "Epoch 71 completed. Train BPR Loss: 1.0968\n",
      "\n",
      "Epoch 72 Step 1 Loss: 1.0899, Avg Loss: 1.0899\n",
      "Step 2698 — Test metrics:\n",
      "  precision@10: 0.000488901\n",
      "  recall@10: 0.000489635\n",
      "  ndcg@10: 0.000433942\n",
      "  map@10: 0.000111050\n",
      "Epoch 72 Step 10 Loss: 1.0930, Avg Loss: 1.0906\n",
      "Epoch 72 Step 20 Loss: 1.0942, Avg Loss: 1.0896\n",
      "Epoch 72 Step 30 Loss: 1.0614, Avg Loss: 1.0868\n",
      "Epoch 72 completed. Train BPR Loss: 1.0857\n",
      "\n",
      "Epoch 73 Step 1 Loss: 1.0929, Avg Loss: 1.0929\n",
      "Step 2736 — Test metrics:\n",
      "  precision@10: 0.000502114\n",
      "  recall@10: 0.000502848\n",
      "  ndcg@10: 0.000441551\n",
      "  map@10: 0.000111976\n",
      "Epoch 73 Step 10 Loss: 1.0557, Avg Loss: 1.0701\n",
      "Epoch 73 Step 20 Loss: 1.0700, Avg Loss: 1.0709\n",
      "Epoch 73 Step 30 Loss: 1.0672, Avg Loss: 1.0693\n",
      "Epoch 73 completed. Train BPR Loss: 1.0676\n",
      "\n",
      "Epoch 74 Step 1 Loss: 1.0627, Avg Loss: 1.0627\n",
      "Step 2774 — Test metrics:\n",
      "  precision@10: 0.000502114\n",
      "  recall@10: 0.000502848\n",
      "  ndcg@10: 0.000441785\n",
      "  map@10: 0.000112057\n",
      "Epoch 74 Step 10 Loss: 1.0422, Avg Loss: 1.0598\n",
      "Epoch 74 Step 20 Loss: 1.0582, Avg Loss: 1.0582\n",
      "Epoch 74 Step 30 Loss: 1.0599, Avg Loss: 1.0567\n",
      "Epoch 74 completed. Train BPR Loss: 1.0548\n",
      "\n",
      "Epoch 75 Step 1 Loss: 1.0400, Avg Loss: 1.0400\n",
      "Step 2812 — Test metrics:\n",
      "  precision@10: 0.000508721\n",
      "  recall@10: 0.000509455\n",
      "  ndcg@10: 0.000445522\n",
      "  map@10: 0.000112498\n",
      "Epoch 75 Step 10 Loss: 1.0463, Avg Loss: 1.0427\n",
      "Epoch 75 Step 20 Loss: 1.0360, Avg Loss: 1.0430\n",
      "Epoch 75 Step 30 Loss: 1.0284, Avg Loss: 1.0406\n",
      "Epoch 75 completed. Train BPR Loss: 1.0387\n",
      "\n",
      "Epoch 76 Step 1 Loss: 1.0250, Avg Loss: 1.0250\n",
      "Step 2850 — Test metrics:\n",
      "  precision@10: 0.000488901\n",
      "  recall@10: 0.000489635\n",
      "  ndcg@10: 0.000434449\n",
      "  map@10: 0.000111339\n",
      "Epoch 76 Step 10 Loss: 1.0415, Avg Loss: 1.0308\n",
      "Epoch 76 Step 20 Loss: 1.0308, Avg Loss: 1.0281\n",
      "Epoch 76 Step 30 Loss: 1.0261, Avg Loss: 1.0277\n",
      "Epoch 76 completed. Train BPR Loss: 1.0256\n",
      "\n",
      "Epoch 77 Step 1 Loss: 1.0181, Avg Loss: 1.0181\n",
      "Step 2888 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000431185\n",
      "  map@10: 0.000111098\n",
      "Epoch 77 Step 10 Loss: 1.0171, Avg Loss: 1.0208\n",
      "Epoch 77 Step 20 Loss: 1.0145, Avg Loss: 1.0184\n",
      "Epoch 77 Step 30 Loss: 1.0111, Avg Loss: 1.0149\n",
      "Epoch 77 completed. Train BPR Loss: 1.0125\n",
      "\n",
      "Epoch 78 Step 1 Loss: 0.9991, Avg Loss: 0.9991\n",
      "Step 2926 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000429618\n",
      "  map@10: 0.000110329\n",
      "Epoch 78 Step 10 Loss: 0.9965, Avg Loss: 0.9984\n",
      "Epoch 78 Step 20 Loss: 0.9802, Avg Loss: 0.9975\n",
      "Epoch 78 Step 30 Loss: 0.9914, Avg Loss: 0.9957\n",
      "Epoch 78 completed. Train BPR Loss: 0.9953\n",
      "\n",
      "Epoch 79 Step 1 Loss: 1.0025, Avg Loss: 1.0025\n",
      "Step 2964 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000435159\n",
      "  map@10: 0.000113706\n",
      "Epoch 79 Step 10 Loss: 0.9865, Avg Loss: 0.9894\n",
      "Epoch 79 Step 20 Loss: 0.9636, Avg Loss: 0.9879\n",
      "Epoch 79 Step 30 Loss: 0.9672, Avg Loss: 0.9855\n",
      "Epoch 79 completed. Train BPR Loss: 0.9838\n",
      "\n",
      "Epoch 80 Step 1 Loss: 0.9757, Avg Loss: 0.9757\n",
      "Step 3002 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000434503\n",
      "  map@10: 0.000113394\n",
      "Epoch 80 Step 10 Loss: 0.9879, Avg Loss: 0.9780\n",
      "Epoch 80 Step 20 Loss: 0.9802, Avg Loss: 0.9764\n",
      "Epoch 80 Step 30 Loss: 0.9776, Avg Loss: 0.9733\n",
      "Epoch 80 completed. Train BPR Loss: 0.9717\n",
      "\n",
      "Epoch 81 Step 1 Loss: 0.9611, Avg Loss: 0.9611\n",
      "Step 3040 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000435511\n",
      "  map@10: 0.000113945\n",
      "Epoch 81 Step 10 Loss: 0.9755, Avg Loss: 0.9610\n",
      "Epoch 81 Step 20 Loss: 0.9706, Avg Loss: 0.9615\n",
      "Epoch 81 Step 30 Loss: 0.9507, Avg Loss: 0.9592\n",
      "Epoch 81 completed. Train BPR Loss: 0.9587\n",
      "\n",
      "Epoch 82 Step 1 Loss: 0.9558, Avg Loss: 0.9558\n",
      "Step 3078 — Test metrics:\n",
      "  precision@10: 0.000495507\n",
      "  recall@10: 0.000496241\n",
      "  ndcg@10: 0.000444284\n",
      "  map@10: 0.000115416\n",
      "Epoch 82 Step 10 Loss: 0.9685, Avg Loss: 0.9500\n",
      "Epoch 82 Step 20 Loss: 0.9574, Avg Loss: 0.9496\n",
      "Epoch 82 Step 30 Loss: 0.9513, Avg Loss: 0.9482\n",
      "Epoch 82 completed. Train BPR Loss: 0.9463\n",
      "\n",
      "Epoch 83 Step 1 Loss: 0.9392, Avg Loss: 0.9392\n",
      "Step 3116 — Test metrics:\n",
      "  precision@10: 0.000502114\n",
      "  recall@10: 0.000502848\n",
      "  ndcg@10: 0.000448734\n",
      "  map@10: 0.000116189\n",
      "Epoch 83 Step 10 Loss: 0.9315, Avg Loss: 0.9337\n",
      "Epoch 83 Step 20 Loss: 0.9356, Avg Loss: 0.9342\n",
      "Epoch 83 Step 30 Loss: 0.9226, Avg Loss: 0.9323\n",
      "Epoch 83 completed. Train BPR Loss: 0.9327\n",
      "\n",
      "Epoch 84 Step 1 Loss: 0.9325, Avg Loss: 0.9325\n",
      "Step 3154 — Test metrics:\n",
      "  precision@10: 0.000488901\n",
      "  recall@10: 0.000489635\n",
      "  ndcg@10: 0.000441213\n",
      "  map@10: 0.000115353\n",
      "Epoch 84 Step 10 Loss: 0.9099, Avg Loss: 0.9243\n",
      "Epoch 84 Step 20 Loss: 0.9189, Avg Loss: 0.9225\n",
      "Epoch 84 Step 30 Loss: 0.9205, Avg Loss: 0.9226\n",
      "Epoch 84 completed. Train BPR Loss: 0.9219\n",
      "\n",
      "Epoch 85 Step 1 Loss: 0.9065, Avg Loss: 0.9065\n",
      "Step 3192 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000438319\n",
      "  map@10: 0.000115290\n",
      "Epoch 85 Step 10 Loss: 0.9165, Avg Loss: 0.9131\n",
      "Epoch 85 Step 20 Loss: 0.9161, Avg Loss: 0.9122\n",
      "Epoch 85 Step 30 Loss: 0.9041, Avg Loss: 0.9106\n",
      "Epoch 85 completed. Train BPR Loss: 0.9107\n",
      "\n",
      "Epoch 86 Step 1 Loss: 0.8948, Avg Loss: 0.8948\n",
      "Step 3230 — Test metrics:\n",
      "  precision@10: 0.000488901\n",
      "  recall@10: 0.000489635\n",
      "  ndcg@10: 0.000440511\n",
      "  map@10: 0.000114756\n",
      "Epoch 86 Step 10 Loss: 0.9113, Avg Loss: 0.8996\n",
      "Epoch 86 Step 20 Loss: 0.8994, Avg Loss: 0.8998\n",
      "Epoch 86 Step 30 Loss: 0.9003, Avg Loss: 0.8992\n",
      "Epoch 86 completed. Train BPR Loss: 0.8987\n",
      "\n",
      "Epoch 87 Step 1 Loss: 0.8940, Avg Loss: 0.8940\n",
      "Step 3268 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000435769\n",
      "  map@10: 0.000113754\n",
      "Epoch 87 Step 10 Loss: 0.8904, Avg Loss: 0.8909\n",
      "Epoch 87 Step 20 Loss: 0.8889, Avg Loss: 0.8910\n",
      "Epoch 87 Step 30 Loss: 0.8929, Avg Loss: 0.8899\n",
      "Epoch 87 completed. Train BPR Loss: 0.8884\n",
      "\n",
      "Epoch 88 Step 1 Loss: 0.8908, Avg Loss: 0.8908\n",
      "Step 3306 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000437933\n",
      "  map@10: 0.000114973\n",
      "Epoch 88 Step 10 Loss: 0.8760, Avg Loss: 0.8820\n",
      "Epoch 88 Step 20 Loss: 0.8875, Avg Loss: 0.8795\n",
      "Epoch 88 Step 30 Loss: 0.8828, Avg Loss: 0.8786\n",
      "Epoch 88 completed. Train BPR Loss: 0.8768\n",
      "\n",
      "Epoch 89 Step 1 Loss: 0.8696, Avg Loss: 0.8696\n",
      "Step 3344 — Test metrics:\n",
      "  precision@10: 0.000482294\n",
      "  recall@10: 0.000483028\n",
      "  ndcg@10: 0.000437008\n",
      "  map@10: 0.000114541\n",
      "Epoch 89 Step 10 Loss: 0.8666, Avg Loss: 0.8671\n",
      "Epoch 89 Step 20 Loss: 0.8687, Avg Loss: 0.8662\n",
      "Epoch 89 Step 30 Loss: 0.8485, Avg Loss: 0.8663\n",
      "Epoch 89 completed. Train BPR Loss: 0.8659\n",
      "\n",
      "Epoch 90 Step 1 Loss: 0.8657, Avg Loss: 0.8657\n",
      "Step 3382 — Test metrics:\n",
      "  precision@10: 0.000502114\n",
      "  recall@10: 0.000502848\n",
      "  ndcg@10: 0.000450668\n",
      "  map@10: 0.000117249\n",
      "Epoch 90 Step 10 Loss: 0.8545, Avg Loss: 0.8602\n",
      "Epoch 90 Step 20 Loss: 0.8496, Avg Loss: 0.8563\n",
      "Epoch 90 Step 30 Loss: 0.8672, Avg Loss: 0.8560\n",
      "Epoch 90 completed. Train BPR Loss: 0.8555\n",
      "\n",
      "Epoch 91 Step 1 Loss: 0.8532, Avg Loss: 0.8532\n",
      "Step 3420 — Test metrics:\n",
      "  precision@10: 0.000515328\n",
      "  recall@10: 0.000516062\n",
      "  ndcg@10: 0.000457969\n",
      "  map@10: 0.000117946\n",
      "Epoch 91 Step 10 Loss: 0.8465, Avg Loss: 0.8474\n",
      "Epoch 91 Step 20 Loss: 0.8439, Avg Loss: 0.8481\n",
      "Epoch 91 Step 30 Loss: 0.8454, Avg Loss: 0.8456\n",
      "Epoch 91 completed. Train BPR Loss: 0.8446\n",
      "\n",
      "Epoch 92 Step 1 Loss: 0.8453, Avg Loss: 0.8453\n",
      "Step 3458 — Test metrics:\n",
      "  precision@10: 0.000515328\n",
      "  recall@10: 0.000516062\n",
      "  ndcg@10: 0.000458797\n",
      "  map@10: 0.000118350\n",
      "Epoch 92 Step 10 Loss: 0.8436, Avg Loss: 0.8385\n",
      "Epoch 92 Step 20 Loss: 0.8257, Avg Loss: 0.8374\n",
      "Epoch 92 Step 30 Loss: 0.8408, Avg Loss: 0.8368\n",
      "Epoch 92 completed. Train BPR Loss: 0.8350\n",
      "\n",
      "Epoch 93 Step 1 Loss: 0.8448, Avg Loss: 0.8448\n",
      "Step 3496 — Test metrics:\n",
      "  precision@10: 0.000515328\n",
      "  recall@10: 0.000516062\n",
      "  ndcg@10: 0.000455705\n",
      "  map@10: 0.000116573\n",
      "Epoch 93 Step 10 Loss: 0.8325, Avg Loss: 0.8282\n",
      "Epoch 93 Step 20 Loss: 0.8354, Avg Loss: 0.8279\n",
      "Epoch 93 Step 30 Loss: 0.8266, Avg Loss: 0.8269\n",
      "Epoch 93 completed. Train BPR Loss: 0.8267\n",
      "\n",
      "Epoch 94 Step 1 Loss: 0.8160, Avg Loss: 0.8160\n",
      "Step 3534 — Test metrics:\n",
      "  precision@10: 0.000528541\n",
      "  recall@10: 0.000529275\n",
      "  ndcg@10: 0.000462044\n",
      "  map@10: 0.000116704\n",
      "Epoch 94 Step 10 Loss: 0.8235, Avg Loss: 0.8207\n",
      "Epoch 94 Step 20 Loss: 0.8265, Avg Loss: 0.8189\n",
      "Epoch 94 Step 30 Loss: 0.8179, Avg Loss: 0.8180\n",
      "Epoch 94 completed. Train BPR Loss: 0.8166\n",
      "\n",
      "Epoch 95 Step 1 Loss: 0.8151, Avg Loss: 0.8151\n",
      "Step 3572 — Test metrics:\n",
      "  precision@10: 0.000528541\n",
      "  recall@10: 0.000529275\n",
      "  ndcg@10: 0.000460976\n",
      "  map@10: 0.000116161\n",
      "Epoch 95 Step 10 Loss: 0.8073, Avg Loss: 0.8095\n",
      "Epoch 95 Step 20 Loss: 0.7993, Avg Loss: 0.8074\n",
      "Epoch 95 Step 30 Loss: 0.7985, Avg Loss: 0.8060\n",
      "Epoch 95 completed. Train BPR Loss: 0.8058\n",
      "\n",
      "Epoch 96 Step 1 Loss: 0.8057, Avg Loss: 0.8057\n",
      "Step 3610 — Test metrics:\n",
      "  precision@10: 0.000521934\n",
      "  recall@10: 0.000522669\n",
      "  ndcg@10: 0.000457164\n",
      "  map@10: 0.000115721\n",
      "Epoch 96 Step 10 Loss: 0.7876, Avg Loss: 0.7986\n",
      "Epoch 96 Step 20 Loss: 0.8062, Avg Loss: 0.7978\n",
      "Epoch 96 Step 30 Loss: 0.7855, Avg Loss: 0.7970\n",
      "Epoch 96 completed. Train BPR Loss: 0.7967\n",
      "\n",
      "Epoch 97 Step 1 Loss: 0.7988, Avg Loss: 0.7988\n",
      "Step 3648 — Test metrics:\n",
      "  precision@10: 0.000535148\n",
      "  recall@10: 0.000535882\n",
      "  ndcg@10: 0.000463683\n",
      "  map@10: 0.000116080\n",
      "Epoch 97 Step 10 Loss: 0.7865, Avg Loss: 0.7870\n",
      "Epoch 97 Step 20 Loss: 0.7823, Avg Loss: 0.7890\n",
      "Epoch 97 Step 30 Loss: 0.7838, Avg Loss: 0.7884\n",
      "Epoch 97 completed. Train BPR Loss: 0.7884\n",
      "\n",
      "Epoch 98 Step 1 Loss: 0.7760, Avg Loss: 0.7760\n",
      "Step 3686 — Test metrics:\n",
      "  precision@10: 0.000535148\n",
      "  recall@10: 0.000535882\n",
      "  ndcg@10: 0.000464609\n",
      "  map@10: 0.000116554\n",
      "Epoch 98 Step 10 Loss: 0.7773, Avg Loss: 0.7825\n",
      "Epoch 98 Step 20 Loss: 0.7825, Avg Loss: 0.7810\n",
      "Epoch 98 Step 30 Loss: 0.7848, Avg Loss: 0.7800\n",
      "Epoch 98 completed. Train BPR Loss: 0.7792\n",
      "\n",
      "Epoch 99 Step 1 Loss: 0.7622, Avg Loss: 0.7622\n",
      "Step 3724 — Test metrics:\n",
      "  precision@10: 0.000535148\n",
      "  recall@10: 0.000535882\n",
      "  ndcg@10: 0.000463332\n",
      "  map@10: 0.000115883\n",
      "Epoch 99 Step 10 Loss: 0.7764, Avg Loss: 0.7716\n",
      "Epoch 99 Step 20 Loss: 0.7689, Avg Loss: 0.7723\n",
      "Epoch 99 Step 30 Loss: 0.7745, Avg Loss: 0.7715\n",
      "Epoch 99 completed. Train BPR Loss: 0.7708\n",
      "\n",
      "Epoch 100 Step 1 Loss: 0.7639, Avg Loss: 0.7639\n",
      "Step 3762 — Test metrics:\n",
      "  precision@10: 0.000541755\n",
      "  recall@10: 0.000542489\n",
      "  ndcg@10: 0.000468153\n",
      "  map@10: 0.000116976\n",
      "Epoch 100 Step 10 Loss: 0.7637, Avg Loss: 0.7658\n",
      "Epoch 100 Step 20 Loss: 0.7624, Avg Loss: 0.7648\n",
      "Epoch 100 Step 30 Loss: 0.7585, Avg Loss: 0.7632\n",
      "Epoch 100 completed. Train BPR Loss: 0.7630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "edge_type = hyperparameters['train_edge_type']\n",
    "num_epochs = hyperparameters['train_num_epochs']\n",
    "lr = hyperparameters['train_lr']\n",
    "batch_size = hyperparameters['train_batch_size']\n",
    "print_every = hyperparameters['train_print_every']\n",
    "test_every = hyperparameters['train_test_every']\n",
    "top_k = hyperparameters['test_topk']\n",
    "test_batch_size = hyperparameters['test_batch_size']\n",
    "model = train_simple_model(model,\n",
    "                    data,\n",
    "                    num_epochs=num_epochs,\n",
    "                    lr=lr,\n",
    "                    batch_size=batch_size,\n",
    "                    device=device,\n",
    "                    print_every=print_every,\n",
    "                    test_every=test_every,\n",
    "                    top_k=top_k,\n",
    "                    test_batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:42:18.415272Z",
     "iopub.status.busy": "2025-06-24T20:42:18.414945Z",
     "iopub.status.idle": "2025-06-24T20:42:18.436575Z",
     "shell.execute_reply": "2025-06-24T20:42:18.435838Z",
     "shell.execute_reply.started": "2025-06-24T20:42:18.415253Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='gnn_model_mvl.model' target='_blank'>gnn_model_mvl.model</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/gnn_model_mvl.model"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, \"gnn_model_mvl.model\")\n",
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('gnn_model_mvl.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:42:18.437925Z",
     "iopub.status.busy": "2025-06-24T20:42:18.437632Z",
     "iopub.status.idle": "2025-06-24T20:42:18.950386Z",
     "shell.execute_reply": "2025-06-24T20:42:18.949480Z",
     "shell.execute_reply.started": "2025-06-24T20:42:18.437901Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:42:18.952695Z",
     "iopub.status.busy": "2025-06-24T20:42:18.952094Z",
     "iopub.status.idle": "2025-06-24T20:42:19.089727Z",
     "shell.execute_reply": "2025-06-24T20:42:19.088861Z",
     "shell.execute_reply.started": "2025-06-24T20:42:18.952668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "log_model(\n",
    "    experiment=experiment,\n",
    "    model=model,\n",
    "    model_name=\"GNN\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:42:19.090834Z",
     "iopub.status.busy": "2025-06-24T20:42:19.090616Z",
     "iopub.status.idle": "2025-06-24T20:42:20.889790Z",
     "shell.execute_reply": "2025-06-24T20:42:20.889013Z",
     "shell.execute_reply.started": "2025-06-24T20:42:19.090817Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : baseline-books\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/annanet/gnn-recommender/e0686063307140c2b54a3db110f14f97\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test map@10 vs step [100]       : (9.140931742675928e-05, 0.00013536003724957214)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test ndcg@10 vs step [100]      : (0.0003078713334703717, 0.0004681525439074918)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test precision@10 vs step [100] : (0.00030391120507399573, 0.0005417547568710359)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test recall@10 vs step [100]    : (0.00030391120507399573, 0.0005424888419074466)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Train BPR Loss vs step [3800]   : (0.7419406175613403, 3.3396990299224854)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [380]                      : (0.7520266771316528, 3.3311269283294678)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : baseline-books\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed              : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_batch_size   : 32768\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_topk         : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_batch_size  : 32768\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_edge_type   : ('item', 'to_feedback_explicit_positive', 'explicit_positive')\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_lr          : 8e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_num_epochs  : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_print_every : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_test_every  : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     types_of_feedback : ['explicit_positive', 'expliсit_negative', 'implicit_positive', 'implicit_negative']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 2 (5.43 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7705289,
     "sourceId": 12229447,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
