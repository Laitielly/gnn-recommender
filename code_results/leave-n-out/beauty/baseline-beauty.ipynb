{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-24T17:59:43.249677Z",
     "iopub.status.busy": "2025-06-24T17:59:43.249416Z",
     "iopub.status.idle": "2025-06-24T17:59:57.655180Z",
     "shell.execute_reply": "2025-06-24T17:59:57.654326Z",
     "shell.execute_reply.started": "2025-06-24T17:59:43.249656Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.1/727.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install torch_geometric rectools\n",
    "!pip -q install comet_ml\n",
    "!pip -q install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T17:59:57.656831Z",
     "iopub.status.busy": "2025-06-24T17:59:57.656599Z",
     "iopub.status.idle": "2025-06-24T18:00:02.806655Z",
     "shell.execute_reply": "2025-06-24T18:00:02.805937Z",
     "shell.execute_reply.started": "2025-06-24T17:59:57.656808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:02.807807Z",
     "iopub.status.busy": "2025-06-24T18:00:02.807502Z",
     "iopub.status.idle": "2025-06-24T18:00:02.814185Z",
     "shell.execute_reply": "2025-06-24T18:00:02.813607Z",
     "shell.execute_reply.started": "2025-06-24T18:00:02.807788Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:02.815971Z",
     "iopub.status.busy": "2025-06-24T18:00:02.815747Z",
     "iopub.status.idle": "2025-06-24T18:00:07.367658Z",
     "shell.execute_reply": "2025-06-24T18:00:07.366936Z",
     "shell.execute_reply.started": "2025-06-24T18:00:02.815955Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/annanet/gnn-recommender/7989efbe77bc41bc94656aab3b575aa5\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "  api_key=os.getenv('API_KEY'),\n",
    "  project_name=\"gnn-recommender\",\n",
    "  workspace=\"annanet\",\n",
    "  log_code=True\n",
    ")\n",
    "\n",
    "experiment.set_name('baseline-beauty')\n",
    "experiment.add_tags(['beauty', 'leave-n-out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:07.368758Z",
     "iopub.status.busy": "2025-06-24T18:00:07.368505Z",
     "iopub.status.idle": "2025-06-24T18:00:07.373046Z",
     "shell.execute_reply": "2025-06-24T18:00:07.372375Z",
     "shell.execute_reply.started": "2025-06-24T18:00:07.368734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'seed': 42,\n",
    "    'types_of_feedback': [\"explicit_positive\", \"expliсit_negative\",\n",
    "                          \"implicit_positive\", \"implicit_negative\"],\n",
    "    'train_edge_type': ('item','to_feedback_explicit_positive','explicit_positive'),\n",
    "    'train_num_epochs': 100,\n",
    "    'train_lr': 8e-5,\n",
    "    'train_batch_size': 16384, \n",
    "    'train_print_every': 10,  \n",
    "    'train_test_every': 25,\n",
    "    'test_topk': 10,\n",
    "    'test_batch_size': 8192\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:07.373864Z",
     "iopub.status.busy": "2025-06-24T18:00:07.373685Z",
     "iopub.status.idle": "2025-06-24T18:00:07.410017Z",
     "shell.execute_reply": "2025-06-24T18:00:07.409306Z",
     "shell.execute_reply.started": "2025-06-24T18:00:07.373849Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv', 'test.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('/kaggle/input/data/leave-n-out/beauty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:07.410771Z",
     "iopub.status.busy": "2025-06-24T18:00:07.410614Z",
     "iopub.status.idle": "2025-06-24T18:00:17.041666Z",
     "shell.execute_reply": "2025-06-24T18:00:17.040940Z",
     "shell.execute_reply.started": "2025-06-24T18:00:07.410758Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv, GATConv\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from rectools import Columns\n",
    "from rectools.metrics import MAP, Precision, Recall, NDCG, calc_metrics\n",
    "\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:17.043035Z",
     "iopub.status.busy": "2025-06-24T18:00:17.042574Z",
     "iopub.status.idle": "2025-06-24T18:00:17.052697Z",
     "shell.execute_reply": "2025-06-24T18:00:17.052200Z",
     "shell.execute_reply.started": "2025-06-24T18:00:17.043003Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = hyperparameters['seed']\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:17.053583Z",
     "iopub.status.busy": "2025-06-24T18:00:17.053384Z",
     "iopub.status.idle": "2025-06-24T18:00:18.587698Z",
     "shell.execute_reply": "2025-06-24T18:00:18.586928Z",
     "shell.execute_reply.started": "2025-06-24T18:00:17.053568Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 user_id     item_id  rating  \\\n",
      "0  A00414041RD0BXM6WK0GX  B007IY97U0     3.0   \n",
      "1  A00414041RD0BXM6WK0GX  B00870XLDS     2.0   \n",
      "2  A00414041RD0BXM6WK0GX  B008MIRO88     1.0   \n",
      "3  A00414041RD0BXM6WK0GX  B00BQYYMN0     3.0   \n",
      "4  A00414041RD0BXM6WK0GX  B00GRTQBTM     5.0   \n",
      "\n",
      "                                         review_text   unix_time       date  \n",
      "0  Good quality wig, but the blonde is much more ...  2014-07-14 2014-07-14  \n",
      "1  Very thin and not as long as the photos :( Aft...  2014-07-14 2014-07-14  \n",
      "2  Very thin and not as long as the photos :( Aft...  2014-07-14 2014-07-14  \n",
      "3  This is a great quality wig, however it is a m...  2014-07-14 2014-07-14  \n",
      "4  This is my absolute favorite wig! I have purch...  2014-07-14 2014-07-14  \n"
     ]
    }
   ],
   "source": [
    "rootpath = '/kaggle/input/data/leave-n-out/beauty/'\n",
    "train = pd.read_csv(\n",
    "    rootpath+'train.csv'\n",
    ")\n",
    "train['date'] = pd.to_datetime(train['unix_time'])\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:18.590376Z",
     "iopub.status.busy": "2025-06-24T18:00:18.590125Z",
     "iopub.status.idle": "2025-06-24T18:00:18.616976Z",
     "shell.execute_reply": "2025-06-24T18:00:18.616404Z",
     "shell.execute_reply.started": "2025-06-24T18:00:18.590359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество explicit позитивного фидбека 90800\n",
      "Количество explicit негативного фидбека 17504\n"
     ]
    }
   ],
   "source": [
    "explicit_positive = train[(train[\"rating\"] == 5)].index\n",
    "explisit_negative = train[(train[\"rating\"] <= 2)].index\n",
    "\n",
    "explicit_combined_feedback = explicit_positive.union(explisit_negative)\n",
    "print('Количество explicit позитивного фидбека', explicit_positive.shape[0])\n",
    "print('Количество explicit негативного фидбека', explisit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:18.618201Z",
     "iopub.status.busy": "2025-06-24T18:00:18.617820Z",
     "iopub.status.idle": "2025-06-24T18:00:18.631820Z",
     "shell.execute_reply": "2025-06-24T18:00:18.631081Z",
     "shell.execute_reply.started": "2025-06-24T18:00:18.618176Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество implicit позитивного фидбека 30668\n",
      "Количество implicit негативного фидбека 17110\n"
     ]
    }
   ],
   "source": [
    "implicit_positive = train[(train[\"rating\"] == 4)].index\n",
    "implicit_negative = train[(train[\"rating\"] == 3)].index\n",
    "\n",
    "implicit_combined_feedback = implicit_positive.union(implicit_negative)\n",
    "print('Количество implicit позитивного фидбека', implicit_positive.shape[0])\n",
    "print('Количество implicit негативного фидбека', implicit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:18.632967Z",
     "iopub.status.busy": "2025-06-24T18:00:18.632686Z",
     "iopub.status.idle": "2025-06-24T18:00:18.677341Z",
     "shell.execute_reply": "2025-06-24T18:00:18.676589Z",
     "shell.execute_reply.started": "2025-06-24T18:00:18.632945Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B007IY97U0</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B00870XLDS</td>\n",
       "      <td>expliсit_negative</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B008MIRO88</td>\n",
       "      <td>expliсit_negative</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B00BQYYMN0</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B00GRTQBTM</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id     item_id             target       date\n",
       "0  A00414041RD0BXM6WK0GX  B007IY97U0  implicit_negative 2014-07-14\n",
       "1  A00414041RD0BXM6WK0GX  B00870XLDS  expliсit_negative 2014-07-14\n",
       "2  A00414041RD0BXM6WK0GX  B008MIRO88  expliсit_negative 2014-07-14\n",
       "3  A00414041RD0BXM6WK0GX  B00BQYYMN0  implicit_negative 2014-07-14\n",
       "4  A00414041RD0BXM6WK0GX  B00GRTQBTM  explicit_positive 2014-07-14"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:, \"target\"] = \"\"\n",
    "train.loc[explicit_positive, \"target\"] = \"explicit_positive\"\n",
    "train.loc[explisit_negative, \"target\"] = \"expliсit_negative\"\n",
    "train.loc[implicit_positive, \"target\"] = \"implicit_positive\"\n",
    "train.loc[implicit_negative, \"target\"] = \"implicit_negative\"\n",
    "\n",
    "train = train[['user_id','item_id','target','date']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:18.678306Z",
     "iopub.status.busy": "2025-06-24T18:00:18.678066Z",
     "iopub.status.idle": "2025-06-24T18:00:18.716214Z",
     "shell.execute_reply": "2025-06-24T18:00:18.715668Z",
     "shell.execute_reply.started": "2025-06-24T18:00:18.678289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = train.sort_values(by=[\"user_id\", \"date\"]).reset_index(drop=True)\n",
    "train.columns = ['user_id', 'item_id', 'target', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:18.717097Z",
     "iopub.status.busy": "2025-06-24T18:00:18.716870Z",
     "iopub.status.idle": "2025-06-24T18:00:19.351511Z",
     "shell.execute_reply": "2025-06-24T18:00:19.350811Z",
     "shell.execute_reply.started": "2025-06-24T18:00:18.717081Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 user_id     item_id  rating  \\\n",
      "0  A02155413BVL8D0G7X6DN  B0089JVEPO     5.0   \n",
      "1  A02155413BVL8D0G7X6DN  B001G2LWDK     5.0   \n",
      "2  A02155413BVL8D0G7X6DN  B005Z41P28     5.0   \n",
      "3  A02155413BVL8D0G7X6DN  B0055MYJ0U     5.0   \n",
      "4  A02155413BVL8D0G7X6DN  B00117CH5M     3.0   \n",
      "\n",
      "                                         review_text   unix_time       date  \n",
      "0  leaves my skin clean and smooth. it is creamy ...  2012-10-25 2012-10-25  \n",
      "1  Works great, smells good, there is a result. I...  2012-12-06 2012-12-06  \n",
      "2  it works for my hair. smells like almond. made...  2013-01-17 2013-01-17  \n",
      "3  got this in the mail from China today! holds m...  2013-04-22 2013-04-22  \n",
      "4  if you like strong smell of honeysuckles and h...  2013-05-01 2013-05-01  \n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\n",
    "    rootpath+'test.csv'\n",
    ")\n",
    "test['date'] = pd.to_datetime(test['unix_time'])\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:19.352585Z",
     "iopub.status.busy": "2025-06-24T18:00:19.352287Z",
     "iopub.status.idle": "2025-06-24T18:00:19.363632Z",
     "shell.execute_reply": "2025-06-24T18:00:19.363092Z",
     "shell.execute_reply.started": "2025-06-24T18:00:19.352556Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A02155413BVL8D0G7X6DN</td>\n",
       "      <td>B0089JVEPO</td>\n",
       "      <td>2012-10-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A02155413BVL8D0G7X6DN</td>\n",
       "      <td>B001G2LWDK</td>\n",
       "      <td>2012-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A02155413BVL8D0G7X6DN</td>\n",
       "      <td>B005Z41P28</td>\n",
       "      <td>2013-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A02155413BVL8D0G7X6DN</td>\n",
       "      <td>B0055MYJ0U</td>\n",
       "      <td>2013-04-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A02155413BVL8D0G7X6DN</td>\n",
       "      <td>B00117CH5M</td>\n",
       "      <td>2013-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id     item_id       date\n",
       "0  A02155413BVL8D0G7X6DN  B0089JVEPO 2012-10-25\n",
       "1  A02155413BVL8D0G7X6DN  B001G2LWDK 2012-12-06\n",
       "2  A02155413BVL8D0G7X6DN  B005Z41P28 2013-01-17\n",
       "3  A02155413BVL8D0G7X6DN  B0055MYJ0U 2013-04-22\n",
       "4  A02155413BVL8D0G7X6DN  B00117CH5M 2013-05-01"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[['user_id','item_id', 'date']]\n",
    "test.columns = ['user_id', 'item_id', 'date']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP model v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:19.364494Z",
     "iopub.status.busy": "2025-06-24T18:00:19.364327Z",
     "iopub.status.idle": "2025-06-24T18:00:19.397619Z",
     "shell.execute_reply": "2025-06-24T18:00:19.396924Z",
     "shell.execute_reply.started": "2025-06-24T18:00:19.364480Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42378, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[(test.user_id.isin(train.user_id)) & (test.item_id.isin(train.item_id))].copy()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:19.398674Z",
     "iopub.status.busy": "2025-06-24T18:00:19.398348Z",
     "iopub.status.idle": "2025-06-24T18:00:19.554175Z",
     "shell.execute_reply": "2025-06-24T18:00:19.553447Z",
     "shell.execute_reply.started": "2025-06-24T18:00:19.398649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. Преобразование данных - для куарека не особо нужно, но для других - напоминалка\n",
    "# делаем всегда! чтобы не сломать ничего дальше и чтобы все индексы были от 0 до N без пропусков\n",
    "user_encoder = LabelEncoder()\n",
    "video_encoder = LabelEncoder()\n",
    "\n",
    "train.loc[:, 'user_id'] = user_encoder.fit_transform(train['user_id'])\n",
    "train.loc[:, 'item_id'] = video_encoder.fit_transform(train['item_id'])\n",
    "\n",
    "test.loc[:, 'user_id'] = user_encoder.transform(test['user_id'])\n",
    "test.loc[:, 'item_id'] = video_encoder.transform(test['item_id'])\n",
    "\n",
    "train['user_id'] = train['user_id'].astype(int)\n",
    "train['item_id'] = train['item_id'].astype(int)\n",
    "test['user_id'] = test['user_id'].astype(int)\n",
    "test['item_id'] = test['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:00:19.555078Z",
     "iopub.status.busy": "2025-06-24T18:00:19.554814Z",
     "iopub.status.idle": "2025-06-24T18:00:19.564210Z",
     "shell.execute_reply": "2025-06-24T18:00:19.563608Z",
     "shell.execute_reply.started": "2025-06-24T18:00:19.555052Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных item_id 12095\n",
      "Количество уникальных user_id 22363\n"
     ]
    }
   ],
   "source": [
    "# т.е. сразу знаем количество и в каких пределах изменяется user_id и video_id\n",
    "num_videos = train['item_id'].nunique()\n",
    "num_users = train['user_id'].nunique()\n",
    "\n",
    "print('Количество уникальных item_id', num_videos)\n",
    "print('Количество уникальных user_id', num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:04:01.131800Z",
     "iopub.status.busy": "2025-06-24T18:04:01.131241Z",
     "iopub.status.idle": "2025-06-24T18:04:01.139225Z",
     "shell.execute_reply": "2025-06-24T18:04:01.138294Z",
     "shell.execute_reply.started": "2025-06-24T18:04:01.131774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_hetero_data(df) -> HeteroData:\n",
    "    \"\"\"\n",
    "    Build a simple hetero-graph with only item->user edges based on interactions in df.\n",
    "    df must contain columns 'item_id' and 'user_id'.\n",
    "    \"\"\"\n",
    "    data = HeteroData()\n",
    "\n",
    "    # Create user and item nodes\n",
    "    users = torch.from_numpy(df['user_id'].unique())\n",
    "    items = torch.from_numpy(df['item_id'].unique())\n",
    "    num_users = int(users.max().item()) + 1\n",
    "    num_items = int(items.max().item()) + 1\n",
    "\n",
    "    data['user'].node_id = torch.arange(num_users)\n",
    "    data['item'].node_id = torch.arange(num_items)\n",
    "\n",
    "    # Build item -> user edge index from interactions\n",
    "    item_ids = torch.LongTensor(df['item_id'].values)\n",
    "    user_ids = torch.LongTensor(df['user_id'].values)\n",
    "    edge_index = torch.stack([item_ids, user_ids], dim=0)\n",
    "\n",
    "    data['item', 'interacts', 'user'].edge_index = edge_index\n",
    "    # data['user', 'interacts_rev', 'item'].edge_index = edge_index.flip(0)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:04:56.096409Z",
     "iopub.status.busy": "2025-06-24T18:04:56.095835Z",
     "iopub.status.idle": "2025-06-24T18:04:56.105245Z",
     "shell.execute_reply": "2025-06-24T18:04:56.104428Z",
     "shell.execute_reply.started": "2025-06-24T18:04:56.096386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, HeteroConv\n",
    "\n",
    "class SimpleItemUserGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Heterogeneous GNN for a bipartite graph with single edge type item->user.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 emb_dim: int = 32,\n",
    "                 hidden_dim: int = 16,\n",
    "                 heads: int = 2,\n",
    "                 dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        # Embeddings\n",
    "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_dim)\n",
    "\n",
    "        # Two-layer HeteroConv with one relation: ('item','interacts','user')\n",
    "        conv1 = {\n",
    "            ('item', 'interacts', 'user'): GATConv(\n",
    "                in_channels=emb_dim,\n",
    "                out_channels=hidden_dim,\n",
    "                heads=heads,\n",
    "                add_self_loops=False\n",
    "            ),\n",
    "            # ('user', 'interacts_rev', 'item'): GATConv(\n",
    "            #     in_channels=emb_dim,\n",
    "            #     out_channels=hidden_dim,\n",
    "            #     heads=heads,\n",
    "            #     add_self_loops=False\n",
    "            # ),\n",
    "        }\n",
    "        conv2 = {\n",
    "            ('item', 'interacts', 'user'): GATConv(\n",
    "                in_channels=hidden_dim * heads,\n",
    "                out_channels=emb_dim,\n",
    "                heads=1,\n",
    "                add_self_loops=False\n",
    "            ),\n",
    "            # ('user', 'interacts_rev', 'item'): GATConv(\n",
    "            #     in_channels=hidden_dim * heads,\n",
    "            #     out_channels=emb_dim,\n",
    "            #     heads=1,\n",
    "            #     add_self_loops=False\n",
    "            # ),\n",
    "        }\n",
    "        self.conv1 = HeteroConv(conv1, aggr='mean')\n",
    "        self.conv2 = HeteroConv(conv2, aggr='mean')\n",
    "\n",
    "        # LayerNorm & Dropout\n",
    "        self.norm1 = nn.ModuleDict({\n",
    "            'user': nn.LayerNorm(hidden_dim * heads),\n",
    "            'item': nn.LayerNorm(emb_dim)\n",
    "        })\n",
    "        self.norm2 = nn.ModuleDict({\n",
    "            'user': nn.LayerNorm(emb_dim),\n",
    "            'item': nn.LayerNorm(emb_dim)\n",
    "        })\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Initial node features\n",
    "        x = {\n",
    "            'user': self.user_emb(data['user'].node_id),\n",
    "            'item': self.item_emb(data['item'].node_id)\n",
    "        }\n",
    "        # First hetero-conv\n",
    "        h1 = self.conv1(x, data.edge_index_dict)\n",
    "        # Apply activation, norm, dropout\n",
    "        h1_user = F.elu(self.norm1['user'](h1['user']))\n",
    "        h1_user = self.dropout(h1_user)\n",
    "        h1 = {'user': h1_user, 'item': self.item_emb(data['item'].node_id)}\n",
    "\n",
    "        # Second hetero-conv\n",
    "        h2 = self.conv2(h1, data.edge_index_dict)\n",
    "        # Final normalization\n",
    "        h2_user = self.norm2['user'](h2['user'])\n",
    "\n",
    "        return h2_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:04:56.745346Z",
     "iopub.status.busy": "2025-06-24T18:04:56.744724Z",
     "iopub.status.idle": "2025-06-24T18:04:56.756845Z",
     "shell.execute_reply": "2025-06-24T18:04:56.756092Z",
     "shell.execute_reply.started": "2025-06-24T18:04:56.745321Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ node_id=[22363] },\n",
       "  item={ node_id=[12095] },\n",
       "  (item, interacts, user)={ edge_index=[2, 156082] }\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = prepare_hetero_data(train)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:04:58.325110Z",
     "iopub.status.busy": "2025-06-24T18:04:58.324835Z",
     "iopub.status.idle": "2025-06-24T18:04:58.333300Z",
     "shell.execute_reply": "2025-06-24T18:04:58.332525Z",
     "shell.execute_reply.started": "2025-06-24T18:04:58.325091Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12095, 0, 12094)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.item_id.nunique(), train.item_id.min(), train.item_id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:04:59.104430Z",
     "iopub.status.busy": "2025-06-24T18:04:59.104152Z",
     "iopub.status.idle": "2025-06-24T18:04:59.122719Z",
     "shell.execute_reply": "2025-06-24T18:04:59.122162Z",
     "shell.execute_reply.started": "2025-06-24T18:04:59.104409Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/hetero_conv.py:76: UserWarning: There exist node types ({'item'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_users = len(train['user_id'].unique())\n",
    "num_items = train['item_id'].max() + 1\n",
    "model = SimpleItemUserGNN(num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:05:00.469672Z",
     "iopub.status.busy": "2025-06-24T18:05:00.469145Z",
     "iopub.status.idle": "2025-06-24T18:05:00.474276Z",
     "shell.execute_reply": "2025-06-24T18:05:00.473671Z",
     "shell.execute_reply.started": "2025-06-24T18:05:00.469650Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleItemUserGNN(\n",
       "  (user_emb): Embedding(22363, 32)\n",
       "  (item_emb): Embedding(12095, 32)\n",
       "  (conv1): HeteroConv(num_relations=1)\n",
       "  (conv2): HeteroConv(num_relations=1)\n",
       "  (norm1): ModuleDict(\n",
       "    (user): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (item): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (norm2): ModuleDict(\n",
       "    (user): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (item): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:05:01.716418Z",
     "iopub.status.busy": "2025-06-24T18:05:01.715745Z",
     "iopub.status.idle": "2025-06-24T18:05:02.026032Z",
     "shell.execute_reply": "2025-06-24T18:05:02.025440Z",
     "shell.execute_reply.started": "2025-06-24T18:05:01.716395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = test[['user_id', 'item_id']]\n",
    "interactions = test_df.rename(columns={\n",
    "    'user_id': Columns.User,\n",
    "    'item_id': Columns.Item,\n",
    "})\n",
    "\n",
    "viewed_items = train.groupby(\"user_id\")[\"item_id\"].agg(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:05:03.486797Z",
     "iopub.status.busy": "2025-06-24T18:05:03.486328Z",
     "iopub.status.idle": "2025-06-24T18:05:03.497152Z",
     "shell.execute_reply": "2025-06-24T18:05:03.496368Z",
     "shell.execute_reply.started": "2025-06-24T18:05:03.486774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, train_data,\n",
    "             test_batch_size, top_k,\n",
    "             viewed_items, interactions,\n",
    "             device, test_step):\n",
    "    \"\"\"\n",
    "    Оцениваем модель по всем пользователям:\n",
    "    - строим топ-K рекомендации\n",
    "    - фильтруем уже просмотренные\n",
    "    - считаем recall@K, precision@K, map@K\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    num_users = train_data['user'].node_id.shape[0]\n",
    "    test_top_k = top_k * 150\n",
    "\n",
    "    item_emb = model.item_emb.weight\n",
    "    item_emb_t = item_emb.t().detach()\n",
    "    del item_emb\n",
    "    gc.collect()\n",
    "\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_users, test_batch_size):\n",
    "            end = min(i + test_batch_size, num_users)\n",
    "            batch_users = torch.arange(i, end).to(device)\n",
    "            user_e = model(\n",
    "                data=train_data.to(device)\n",
    "            )\n",
    "            rating = torch.mm(user_e[batch_users].detach(), item_emb_t)\n",
    "            _, topk = torch.topk(rating, k=test_top_k, dim=1)\n",
    "            all_scores.append(topk)\n",
    "\n",
    "            del user_e, rating\n",
    "            gc.collect()\n",
    "    all_scores = torch.cat(all_scores, dim=0).cpu().numpy()\n",
    "\n",
    "    users_list, items, ranks = [], [], []\n",
    "    for u in range(num_users):\n",
    "        seen = viewed_items.get(u, set())\n",
    "        recs = all_scores[u]\n",
    "        mask = ~np.isin(recs, list(seen))\n",
    "        filtered = recs[mask][:top_k]\n",
    "        for rank, it in enumerate(filtered, 1):\n",
    "            users_list.append(u)\n",
    "            items.append(int(it))\n",
    "            ranks.append(rank)\n",
    "    reco_df = pd.DataFrame({\n",
    "        'user_id': users_list,\n",
    "        'item_id': items,\n",
    "        'rank': ranks\n",
    "    })\n",
    "\n",
    "    metrics = {\n",
    "        f'map@{top_k}': MAP(k=top_k),\n",
    "        f'precision@{top_k}': Precision(k=top_k),\n",
    "        f'recall@{top_k}': Recall(k=top_k),\n",
    "        f'ndcg@{top_k}': NDCG(k=top_k)\n",
    "    }\n",
    "    results = calc_metrics(metrics=metrics,\n",
    "                           reco=reco_df,\n",
    "                           interactions=interactions)\n",
    "    print(f\"Step {test_step} — Test metrics:\")\n",
    "    for name, val in results.items():\n",
    "        print(f\"  {name}: {val:.9f}\")\n",
    "        experiment.log_metric(f\"Test {name} vs step\", val, step=test_step)\n",
    "    del all_scores\n",
    "    gc.collect()\n",
    "\n",
    "    model.to(device)\n",
    "    train_data.to(device)\n",
    "    model.train()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:05:04.790438Z",
     "iopub.status.busy": "2025-06-24T18:05:04.789728Z",
     "iopub.status.idle": "2025-06-24T18:05:04.802747Z",
     "shell.execute_reply": "2025-06-24T18:05:04.802137Z",
     "shell.execute_reply.started": "2025-06-24T18:05:04.790404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "\n",
    "def train_simple_model(model,\n",
    "                       data: HeteroData,\n",
    "                       num_epochs: int = 10,\n",
    "                       lr: float = 1e-3,\n",
    "                       batch_size: int = 1024,\n",
    "                       device: str = None,\n",
    "                       print_every: int = 100,\n",
    "                       test_every: int = 100,\n",
    "                      top_k: int = 10,\n",
    "                      test_batch_size: int = 2048):\n",
    "    \"\"\"\n",
    "    Train a SimpleItemUserGNN on item->user interactions with BPR loss.\n",
    "\n",
    "    Args:\n",
    "        model: SimpleItemUserGNN instance\n",
    "        data: HeteroData containing 'item','interacts','user' edges\n",
    "        num_epochs: number of epochs\n",
    "        lr: learning rate\n",
    "        batch_size: negative sampling batch size\n",
    "        device: 'cpu' or 'cuda'\n",
    "        print_every: print stats every N steps\n",
    "    \"\"\"\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    data = data.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # extract positive edge indices\n",
    "    src, dst = data['item', 'interacts', 'user'].edge_index\n",
    "    num_train = src.size(0)\n",
    "    print(f\"Num of training interactions: {num_train}\")\n",
    "\n",
    "    global_step = 0\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        perm = torch.randperm(num_train, device=device)\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for step, start in enumerate(range(0, num_train, batch_size), 1):\n",
    "            idx = perm[start:start + batch_size]\n",
    "            pos_items = src[idx]\n",
    "            users = dst[idx]\n",
    "            neg_items = torch.randint(\n",
    "                0,\n",
    "                model.item_emb.num_embeddings,\n",
    "                size=pos_items.size(),\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass: get updated embeddings\n",
    "            embeddings = model(data)\n",
    "            user_embs = embeddings[users]\n",
    "            pos_embs = model.item_emb.weight[pos_items]\n",
    "            neg_embs = model.item_emb.weight[neg_items]\n",
    "\n",
    "            # BPR loss\n",
    "            pos_scores = (user_embs * pos_embs).sum(dim=1)\n",
    "            neg_scores = (user_embs * neg_embs).sum(dim=1)\n",
    "            loss = -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-15).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            experiment.log_metric('Train BPR Loss vs step', loss.item(), step=global_step)\n",
    "\n",
    "            total_loss += loss.item() * users.size(0)\n",
    "\n",
    "            if step % print_every == 0 or step == 1:\n",
    "                avg_loss = total_loss / (step * batch_size)\n",
    "                print(f\"Epoch {epoch} Step {step} Loss: {loss.item():.4f}, Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "            if step % test_every == 0 or step == 1:\n",
    "                evaluate(model, data,\n",
    "                         test_batch_size, top_k,\n",
    "                         viewed_items, interactions,\n",
    "                         device, test_step=global_step)\n",
    "\n",
    "            # cleanup\n",
    "            del embeddings, user_embs, pos_embs, neg_embs, pos_scores, neg_scores\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "        epoch_loss = total_loss / num_train\n",
    "        print(f\"Epoch {epoch} completed. Train BPR Loss: {epoch_loss:.4f}\\n\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:05:06.194256Z",
     "iopub.status.busy": "2025-06-24T18:05:06.193989Z",
     "iopub.status.idle": "2025-06-24T18:05:06.290762Z",
     "shell.execute_reply": "2025-06-24T18:05:06.290236Z",
     "shell.execute_reply.started": "2025-06-24T18:05:06.194236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "experiment.log_parameters(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:05:06.509858Z",
     "iopub.status.busy": "2025-06-24T18:05:06.509631Z",
     "iopub.status.idle": "2025-06-24T18:05:06.513507Z",
     "shell.execute_reply": "2025-06-24T18:05:06.512843Z",
     "shell.execute_reply.started": "2025-06-24T18:05:06.509840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:05:07.025445Z",
     "iopub.status.busy": "2025-06-24T18:05:07.025187Z",
     "iopub.status.idle": "2025-06-24T18:14:01.218769Z",
     "shell.execute_reply": "2025-06-24T18:14:01.218167Z",
     "shell.execute_reply.started": "2025-06-24T18:05:07.025425Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training interactions: 156082\n",
      "Epoch 1 Step 1 Loss: 3.3044, Avg Loss: 3.3044\n",
      "Step 0 — Test metrics:\n",
      "  precision@10: 0.000801509\n",
      "  recall@10: 0.000801509\n",
      "  ndcg@10: 0.000872591\n",
      "  map@10: 0.000273942\n",
      "Epoch 1 Step 10 Loss: 3.3230, Avg Loss: 3.1279\n",
      "Epoch 1 completed. Train BPR Loss: 3.2833\n",
      "\n",
      "Epoch 2 Step 1 Loss: 3.2855, Avg Loss: 3.2855\n",
      "Step 10 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000889109\n",
      "  map@10: 0.000272277\n",
      "Epoch 2 Step 10 Loss: 3.2272, Avg Loss: 3.0963\n",
      "Epoch 2 completed. Train BPR Loss: 3.2502\n",
      "\n",
      "Epoch 3 Step 1 Loss: 3.2744, Avg Loss: 3.2744\n",
      "Step 20 — Test metrics:\n",
      "  precision@10: 0.000872230\n",
      "  recall@10: 0.000872230\n",
      "  ndcg@10: 0.000904285\n",
      "  map@10: 0.000274728\n",
      "Epoch 3 Step 10 Loss: 3.2938, Avg Loss: 3.0678\n",
      "Epoch 3 completed. Train BPR Loss: 3.2203\n",
      "\n",
      "Epoch 4 Step 1 Loss: 3.1721, Avg Loss: 3.1721\n",
      "Step 30 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000875080\n",
      "  map@10: 0.000264251\n",
      "Epoch 4 Step 10 Loss: 3.2581, Avg Loss: 3.0704\n",
      "Epoch 4 completed. Train BPR Loss: 3.2230\n",
      "\n",
      "Epoch 5 Step 1 Loss: 3.2149, Avg Loss: 3.2149\n",
      "Step 40 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000875370\n",
      "  map@10: 0.000264083\n",
      "Epoch 5 Step 10 Loss: 3.1983, Avg Loss: 3.0708\n",
      "Epoch 5 completed. Train BPR Loss: 3.2234\n",
      "\n",
      "Epoch 6 Step 1 Loss: 3.2214, Avg Loss: 3.2214\n",
      "Step 50 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000874773\n",
      "  map@10: 0.000263652\n",
      "Epoch 6 Step 10 Loss: 3.2347, Avg Loss: 3.0554\n",
      "Epoch 6 completed. Train BPR Loss: 3.2073\n",
      "\n",
      "Epoch 7 Step 1 Loss: 3.2199, Avg Loss: 3.2199\n",
      "Step 60 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000871572\n",
      "  map@10: 0.000262053\n",
      "Epoch 7 Step 10 Loss: 3.2268, Avg Loss: 3.0428\n",
      "Epoch 7 completed. Train BPR Loss: 3.1941\n",
      "\n",
      "Epoch 8 Step 1 Loss: 3.1566, Avg Loss: 3.1566\n",
      "Step 70 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000857446\n",
      "  map@10: 0.000254588\n",
      "Epoch 8 Step 10 Loss: 3.1983, Avg Loss: 3.0295\n",
      "Epoch 8 completed. Train BPR Loss: 3.1801\n",
      "\n",
      "Epoch 9 Step 1 Loss: 3.1779, Avg Loss: 3.1779\n",
      "Step 80 — Test metrics:\n",
      "  precision@10: 0.000872230\n",
      "  recall@10: 0.000872230\n",
      "  ndcg@10: 0.000872750\n",
      "  map@10: 0.000257104\n",
      "Epoch 9 Step 10 Loss: 3.1823, Avg Loss: 3.0105\n",
      "Epoch 9 completed. Train BPR Loss: 3.1602\n",
      "\n",
      "Epoch 10 Step 1 Loss: 3.1492, Avg Loss: 3.1492\n",
      "Step 90 — Test metrics:\n",
      "  precision@10: 0.000872230\n",
      "  recall@10: 0.000872230\n",
      "  ndcg@10: 0.000871521\n",
      "  map@10: 0.000256440\n",
      "Epoch 10 Step 10 Loss: 3.2073, Avg Loss: 2.9811\n",
      "Epoch 10 completed. Train BPR Loss: 3.1293\n",
      "\n",
      "Epoch 11 Step 1 Loss: 3.2202, Avg Loss: 3.2202\n",
      "Step 100 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000859300\n",
      "  map@10: 0.000255429\n",
      "Epoch 11 Step 10 Loss: 2.9960, Avg Loss: 2.9818\n",
      "Epoch 11 completed. Train BPR Loss: 3.1300\n",
      "\n",
      "Epoch 12 Step 1 Loss: 3.0851, Avg Loss: 3.0851\n",
      "Step 110 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000863021\n",
      "  map@10: 0.000257310\n",
      "Epoch 12 Step 10 Loss: 3.1614, Avg Loss: 2.9730\n",
      "Epoch 12 completed. Train BPR Loss: 3.1208\n",
      "\n",
      "Epoch 13 Step 1 Loss: 3.1361, Avg Loss: 3.1361\n",
      "Step 120 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000865805\n",
      "  map@10: 0.000258816\n",
      "Epoch 13 Step 10 Loss: 3.0302, Avg Loss: 2.9704\n",
      "Epoch 13 completed. Train BPR Loss: 3.1180\n",
      "\n",
      "Epoch 14 Step 1 Loss: 3.1220, Avg Loss: 3.1220\n",
      "Step 130 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000859195\n",
      "  map@10: 0.000254915\n",
      "Epoch 14 Step 10 Loss: 3.1197, Avg Loss: 2.9501\n",
      "Epoch 14 completed. Train BPR Loss: 3.0967\n",
      "\n",
      "Epoch 15 Step 1 Loss: 3.0660, Avg Loss: 3.0660\n",
      "Step 140 — Test metrics:\n",
      "  precision@10: 0.000777935\n",
      "  recall@10: 0.000777935\n",
      "  ndcg@10: 0.000821026\n",
      "  map@10: 0.000251772\n",
      "Epoch 15 Step 10 Loss: 3.0351, Avg Loss: 2.9193\n",
      "Epoch 15 completed. Train BPR Loss: 3.0644\n",
      "\n",
      "Epoch 16 Step 1 Loss: 3.1018, Avg Loss: 3.1018\n",
      "Step 150 — Test metrics:\n",
      "  precision@10: 0.000801509\n",
      "  recall@10: 0.000801509\n",
      "  ndcg@10: 0.000833910\n",
      "  map@10: 0.000253147\n",
      "Epoch 16 Step 10 Loss: 2.9983, Avg Loss: 2.9107\n",
      "Epoch 16 completed. Train BPR Loss: 3.0553\n",
      "\n",
      "Epoch 17 Step 1 Loss: 2.9918, Avg Loss: 2.9918\n",
      "Step 160 — Test metrics:\n",
      "  precision@10: 0.000801509\n",
      "  recall@10: 0.000801509\n",
      "  ndcg@10: 0.000817058\n",
      "  map@10: 0.000243755\n",
      "Epoch 17 Step 10 Loss: 3.0211, Avg Loss: 2.9192\n",
      "Epoch 17 completed. Train BPR Loss: 3.0643\n",
      "\n",
      "Epoch 18 Step 1 Loss: 3.0656, Avg Loss: 3.0656\n",
      "Step 170 — Test metrics:\n",
      "  precision@10: 0.000825083\n",
      "  recall@10: 0.000825083\n",
      "  ndcg@10: 0.000842798\n",
      "  map@10: 0.000251968\n",
      "Epoch 18 Step 10 Loss: 3.0754, Avg Loss: 2.9082\n",
      "Epoch 18 completed. Train BPR Loss: 3.0527\n",
      "\n",
      "Epoch 19 Step 1 Loss: 3.0120, Avg Loss: 3.0120\n",
      "Step 180 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000851277\n",
      "  map@10: 0.000250799\n",
      "Epoch 19 Step 10 Loss: 3.0407, Avg Loss: 2.8851\n",
      "Epoch 19 completed. Train BPR Loss: 3.0286\n",
      "\n",
      "Epoch 20 Step 1 Loss: 3.0987, Avg Loss: 3.0987\n",
      "Step 190 — Test metrics:\n",
      "  precision@10: 0.000825083\n",
      "  recall@10: 0.000825083\n",
      "  ndcg@10: 0.000837890\n",
      "  map@10: 0.000249255\n",
      "Epoch 20 Step 10 Loss: 3.0116, Avg Loss: 2.8927\n",
      "Epoch 20 completed. Train BPR Loss: 3.0365\n",
      "\n",
      "Epoch 21 Step 1 Loss: 3.0037, Avg Loss: 3.0037\n",
      "Step 200 — Test metrics:\n",
      "  precision@10: 0.000825083\n",
      "  recall@10: 0.000825083\n",
      "  ndcg@10: 0.000837890\n",
      "  map@10: 0.000249255\n",
      "Epoch 21 Step 10 Loss: 3.1042, Avg Loss: 2.8681\n",
      "Epoch 21 completed. Train BPR Loss: 3.0106\n",
      "\n",
      "Epoch 22 Step 1 Loss: 3.0209, Avg Loss: 3.0209\n",
      "Step 210 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000852068\n",
      "  map@10: 0.000250995\n",
      "Epoch 22 Step 10 Loss: 3.0727, Avg Loss: 2.8714\n",
      "Epoch 22 completed. Train BPR Loss: 3.0141\n",
      "\n",
      "Epoch 23 Step 1 Loss: 2.9849, Avg Loss: 2.9849\n",
      "Step 220 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000851284\n",
      "  map@10: 0.000250659\n",
      "Epoch 23 Step 10 Loss: 2.9819, Avg Loss: 2.8429\n",
      "Epoch 23 completed. Train BPR Loss: 2.9842\n",
      "\n",
      "Epoch 24 Step 1 Loss: 2.9650, Avg Loss: 2.9650\n",
      "Step 230 — Test metrics:\n",
      "  precision@10: 0.000872230\n",
      "  recall@10: 0.000872230\n",
      "  ndcg@10: 0.000859683\n",
      "  map@10: 0.000249807\n",
      "Epoch 24 Step 10 Loss: 2.9622, Avg Loss: 2.8404\n",
      "Epoch 24 completed. Train BPR Loss: 2.9816\n",
      "\n",
      "Epoch 25 Step 1 Loss: 2.9428, Avg Loss: 2.9428\n",
      "Step 240 — Test metrics:\n",
      "  precision@10: 0.000872230\n",
      "  recall@10: 0.000872230\n",
      "  ndcg@10: 0.000855403\n",
      "  map@10: 0.000247450\n",
      "Epoch 25 Step 10 Loss: 2.9489, Avg Loss: 2.8318\n",
      "Epoch 25 completed. Train BPR Loss: 2.9725\n",
      "\n",
      "Epoch 26 Step 1 Loss: 3.0159, Avg Loss: 3.0159\n",
      "Step 250 — Test metrics:\n",
      "  precision@10: 0.000872230\n",
      "  recall@10: 0.000872230\n",
      "  ndcg@10: 0.000849960\n",
      "  map@10: 0.000244803\n",
      "Epoch 26 Step 10 Loss: 2.8767, Avg Loss: 2.8209\n",
      "Epoch 26 completed. Train BPR Loss: 2.9611\n",
      "\n",
      "Epoch 27 Step 1 Loss: 2.9387, Avg Loss: 2.9387\n",
      "Step 260 — Test metrics:\n",
      "  precision@10: 0.000895804\n",
      "  recall@10: 0.000895804\n",
      "  ndcg@10: 0.000847229\n",
      "  map@10: 0.000236411\n",
      "Epoch 27 Step 10 Loss: 2.9153, Avg Loss: 2.8203\n",
      "Epoch 27 completed. Train BPR Loss: 2.9605\n",
      "\n",
      "Epoch 28 Step 1 Loss: 2.9483, Avg Loss: 2.9483\n",
      "Step 270 — Test metrics:\n",
      "  precision@10: 0.000895804\n",
      "  recall@10: 0.000895804\n",
      "  ndcg@10: 0.000842744\n",
      "  map@10: 0.000234185\n",
      "Epoch 28 Step 10 Loss: 3.0011, Avg Loss: 2.8055\n",
      "Epoch 28 completed. Train BPR Loss: 2.9449\n",
      "\n",
      "Epoch 29 Step 1 Loss: 2.9407, Avg Loss: 2.9407\n",
      "Step 280 — Test metrics:\n",
      "  precision@10: 0.000872230\n",
      "  recall@10: 0.000872230\n",
      "  ndcg@10: 0.000827180\n",
      "  map@10: 0.000231528\n",
      "Epoch 29 Step 10 Loss: 2.9091, Avg Loss: 2.7846\n",
      "Epoch 29 completed. Train BPR Loss: 2.9230\n",
      "\n",
      "Epoch 30 Step 1 Loss: 2.9336, Avg Loss: 2.9336\n",
      "Step 290 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000807958\n",
      "  map@10: 0.000227085\n",
      "Epoch 30 Step 10 Loss: 2.9179, Avg Loss: 2.7804\n",
      "Epoch 30 completed. Train BPR Loss: 2.9186\n",
      "\n",
      "Epoch 31 Step 1 Loss: 2.9331, Avg Loss: 2.9331\n",
      "Step 300 — Test metrics:\n",
      "  precision@10: 0.000872230\n",
      "  recall@10: 0.000872230\n",
      "  ndcg@10: 0.000823704\n",
      "  map@10: 0.000229770\n",
      "Epoch 31 Step 10 Loss: 2.8750, Avg Loss: 2.7567\n",
      "Epoch 31 completed. Train BPR Loss: 2.8937\n",
      "\n",
      "Epoch 32 Step 1 Loss: 2.8815, Avg Loss: 2.8815\n",
      "Step 310 — Test metrics:\n",
      "  precision@10: 0.000872230\n",
      "  recall@10: 0.000872230\n",
      "  ndcg@10: 0.000816070\n",
      "  map@10: 0.000225382\n",
      "Epoch 32 Step 10 Loss: 2.9181, Avg Loss: 2.7538\n",
      "Epoch 32 completed. Train BPR Loss: 2.8907\n",
      "\n",
      "Epoch 33 Step 1 Loss: 2.9017, Avg Loss: 2.9017\n",
      "Step 320 — Test metrics:\n",
      "  precision@10: 0.000872230\n",
      "  recall@10: 0.000872230\n",
      "  ndcg@10: 0.000816376\n",
      "  map@10: 0.000225541\n",
      "Epoch 33 Step 10 Loss: 2.8705, Avg Loss: 2.7544\n",
      "Epoch 33 completed. Train BPR Loss: 2.8913\n",
      "\n",
      "Epoch 34 Step 1 Loss: 2.8591, Avg Loss: 2.8591\n",
      "Step 330 — Test metrics:\n",
      "  precision@10: 0.000825083\n",
      "  recall@10: 0.000825083\n",
      "  ndcg@10: 0.000786339\n",
      "  map@10: 0.000220724\n",
      "Epoch 34 Step 10 Loss: 2.8709, Avg Loss: 2.7289\n",
      "Epoch 34 completed. Train BPR Loss: 2.8646\n",
      "\n",
      "Epoch 35 Step 1 Loss: 2.8442, Avg Loss: 2.8442\n",
      "Step 340 — Test metrics:\n",
      "  precision@10: 0.000825083\n",
      "  recall@10: 0.000825083\n",
      "  ndcg@10: 0.000784749\n",
      "  map@10: 0.000219938\n",
      "Epoch 35 Step 10 Loss: 2.8956, Avg Loss: 2.7233\n",
      "Epoch 35 completed. Train BPR Loss: 2.8586\n",
      "\n",
      "Epoch 36 Step 1 Loss: 2.8740, Avg Loss: 2.8740\n",
      "Step 350 — Test metrics:\n",
      "  precision@10: 0.000801509\n",
      "  recall@10: 0.000801509\n",
      "  ndcg@10: 0.000770817\n",
      "  map@10: 0.000217749\n",
      "Epoch 36 Step 10 Loss: 2.8597, Avg Loss: 2.7157\n",
      "Epoch 36 completed. Train BPR Loss: 2.8507\n",
      "\n",
      "Epoch 37 Step 1 Loss: 2.8205, Avg Loss: 2.8205\n",
      "Step 360 — Test metrics:\n",
      "  precision@10: 0.000801509\n",
      "  recall@10: 0.000801509\n",
      "  ndcg@10: 0.000771729\n",
      "  map@10: 0.000218170\n",
      "Epoch 37 Step 10 Loss: 2.7849, Avg Loss: 2.6836\n",
      "Epoch 37 completed. Train BPR Loss: 2.8170\n",
      "\n",
      "Epoch 38 Step 1 Loss: 2.8399, Avg Loss: 2.8399\n",
      "Step 370 — Test metrics:\n",
      "  precision@10: 0.000825083\n",
      "  recall@10: 0.000825083\n",
      "  ndcg@10: 0.000789750\n",
      "  map@10: 0.000222033\n",
      "Epoch 38 Step 10 Loss: 2.7951, Avg Loss: 2.6805\n",
      "Epoch 38 completed. Train BPR Loss: 2.8137\n",
      "\n",
      "Epoch 39 Step 1 Loss: 2.7845, Avg Loss: 2.7845\n",
      "Step 380 — Test metrics:\n",
      "  precision@10: 0.000825083\n",
      "  recall@10: 0.000825083\n",
      "  ndcg@10: 0.000788563\n",
      "  map@10: 0.000221472\n",
      "Epoch 39 Step 10 Loss: 2.8822, Avg Loss: 2.6725\n",
      "Epoch 39 completed. Train BPR Loss: 2.8053\n",
      "\n",
      "Epoch 40 Step 1 Loss: 2.8262, Avg Loss: 2.8262\n",
      "Step 390 — Test metrics:\n",
      "  precision@10: 0.000825083\n",
      "  recall@10: 0.000825083\n",
      "  ndcg@10: 0.000794278\n",
      "  map@10: 0.000224353\n",
      "Epoch 40 Step 10 Loss: 2.7778, Avg Loss: 2.6688\n",
      "Epoch 40 completed. Train BPR Loss: 2.8014\n",
      "\n",
      "Epoch 41 Step 1 Loss: 2.8387, Avg Loss: 2.8387\n",
      "Step 400 — Test metrics:\n",
      "  precision@10: 0.000825083\n",
      "  recall@10: 0.000825083\n",
      "  ndcg@10: 0.000792909\n",
      "  map@10: 0.000223764\n",
      "Epoch 41 Step 10 Loss: 2.7290, Avg Loss: 2.6726\n",
      "Epoch 41 completed. Train BPR Loss: 2.8054\n",
      "\n",
      "Epoch 42 Step 1 Loss: 2.8243, Avg Loss: 2.8243\n",
      "Step 410 — Test metrics:\n",
      "  precision@10: 0.000825083\n",
      "  recall@10: 0.000825083\n",
      "  ndcg@10: 0.000795418\n",
      "  map@10: 0.000225111\n",
      "Epoch 42 Step 10 Loss: 2.6833, Avg Loss: 2.6489\n",
      "Epoch 42 completed. Train BPR Loss: 2.7805\n",
      "\n",
      "Epoch 43 Step 1 Loss: 2.7663, Avg Loss: 2.7663\n",
      "Step 420 — Test metrics:\n",
      "  precision@10: 0.000825083\n",
      "  recall@10: 0.000825083\n",
      "  ndcg@10: 0.000800031\n",
      "  map@10: 0.000227403\n",
      "Epoch 43 Step 10 Loss: 2.8143, Avg Loss: 2.6461\n",
      "Epoch 43 completed. Train BPR Loss: 2.7777\n",
      "\n",
      "Epoch 44 Step 1 Loss: 2.7964, Avg Loss: 2.7964\n",
      "Step 430 — Test metrics:\n",
      "  precision@10: 0.000825083\n",
      "  recall@10: 0.000825083\n",
      "  ndcg@10: 0.000797912\n",
      "  map@10: 0.000226486\n",
      "Epoch 44 Step 10 Loss: 2.7589, Avg Loss: 2.6304\n",
      "Epoch 44 completed. Train BPR Loss: 2.7612\n",
      "\n",
      "Epoch 45 Step 1 Loss: 2.7640, Avg Loss: 2.7640\n",
      "Step 440 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000815847\n",
      "  map@10: 0.000230387\n",
      "Epoch 45 Step 10 Loss: 2.7225, Avg Loss: 2.6158\n",
      "Epoch 45 completed. Train BPR Loss: 2.7458\n",
      "\n",
      "Epoch 46 Step 1 Loss: 2.6993, Avg Loss: 2.6993\n",
      "Step 450 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000816107\n",
      "  map@10: 0.000230527\n",
      "Epoch 46 Step 10 Loss: 2.7635, Avg Loss: 2.5978\n",
      "Epoch 46 completed. Train BPR Loss: 2.7269\n",
      "\n",
      "Epoch 47 Step 1 Loss: 2.7412, Avg Loss: 2.7412\n",
      "Step 460 — Test metrics:\n",
      "  precision@10: 0.000872230\n",
      "  recall@10: 0.000872230\n",
      "  ndcg@10: 0.000827141\n",
      "  map@10: 0.000230976\n",
      "Epoch 47 Step 10 Loss: 2.7848, Avg Loss: 2.6008\n",
      "Epoch 47 completed. Train BPR Loss: 2.7300\n",
      "\n",
      "Epoch 48 Step 1 Loss: 2.7434, Avg Loss: 2.7434\n",
      "Step 470 — Test metrics:\n",
      "  precision@10: 0.000872230\n",
      "  recall@10: 0.000872230\n",
      "  ndcg@10: 0.000827579\n",
      "  map@10: 0.000231210\n",
      "Epoch 48 Step 10 Loss: 2.7017, Avg Loss: 2.5859\n",
      "Epoch 48 completed. Train BPR Loss: 2.7145\n",
      "\n",
      "Epoch 49 Step 1 Loss: 2.7741, Avg Loss: 2.7741\n",
      "Step 480 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000813686\n",
      "  map@10: 0.000229367\n",
      "Epoch 49 Step 10 Loss: 2.6854, Avg Loss: 2.5699\n",
      "Epoch 49 completed. Train BPR Loss: 2.6976\n",
      "\n",
      "Epoch 50 Step 1 Loss: 2.7429, Avg Loss: 2.7429\n",
      "Step 490 — Test metrics:\n",
      "  precision@10: 0.000825083\n",
      "  recall@10: 0.000825083\n",
      "  ndcg@10: 0.000806102\n",
      "  map@10: 0.000231201\n",
      "Epoch 50 Step 10 Loss: 2.6411, Avg Loss: 2.5816\n",
      "Epoch 50 completed. Train BPR Loss: 2.7099\n",
      "\n",
      "Epoch 51 Step 1 Loss: 2.7346, Avg Loss: 2.7346\n",
      "Step 500 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000828514\n",
      "  map@10: 0.000237749\n",
      "Epoch 51 Step 10 Loss: 2.6927, Avg Loss: 2.5727\n",
      "Epoch 51 completed. Train BPR Loss: 2.7006\n",
      "\n",
      "Epoch 52 Step 1 Loss: 2.6063, Avg Loss: 2.6063\n",
      "Step 510 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000827893\n",
      "  map@10: 0.000237487\n",
      "Epoch 52 Step 10 Loss: 2.6687, Avg Loss: 2.5476\n",
      "Epoch 52 completed. Train BPR Loss: 2.6742\n",
      "\n",
      "Epoch 53 Step 1 Loss: 2.7270, Avg Loss: 2.7270\n",
      "Step 520 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000827319\n",
      "  map@10: 0.000237029\n",
      "Epoch 53 Step 10 Loss: 2.7143, Avg Loss: 2.5444\n",
      "Epoch 53 completed. Train BPR Loss: 2.6708\n",
      "\n",
      "Epoch 54 Step 1 Loss: 2.6379, Avg Loss: 2.6379\n",
      "Step 530 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000825108\n",
      "  map@10: 0.000235981\n",
      "Epoch 54 Step 10 Loss: 2.6477, Avg Loss: 2.5120\n",
      "Epoch 54 completed. Train BPR Loss: 2.6368\n",
      "\n",
      "Epoch 55 Step 1 Loss: 2.6365, Avg Loss: 2.6365\n",
      "Step 540 — Test metrics:\n",
      "  precision@10: 0.000825083\n",
      "  recall@10: 0.000825083\n",
      "  ndcg@10: 0.000809587\n",
      "  map@10: 0.000233427\n",
      "Epoch 55 Step 10 Loss: 2.6745, Avg Loss: 2.5116\n",
      "Epoch 55 completed. Train BPR Loss: 2.6364\n",
      "\n",
      "Epoch 56 Step 1 Loss: 2.6472, Avg Loss: 2.6472\n",
      "Step 550 — Test metrics:\n",
      "  precision@10: 0.000801509\n",
      "  recall@10: 0.000801509\n",
      "  ndcg@10: 0.000788896\n",
      "  map@10: 0.000225401\n",
      "Epoch 56 Step 10 Loss: 2.5892, Avg Loss: 2.5139\n",
      "Epoch 56 completed. Train BPR Loss: 2.6389\n",
      "\n",
      "Epoch 57 Step 1 Loss: 2.6386, Avg Loss: 2.6386\n",
      "Step 560 — Test metrics:\n",
      "  precision@10: 0.000801509\n",
      "  recall@10: 0.000801509\n",
      "  ndcg@10: 0.000788276\n",
      "  map@10: 0.000225139\n",
      "Epoch 57 Step 10 Loss: 2.5608, Avg Loss: 2.4896\n",
      "Epoch 57 completed. Train BPR Loss: 2.6133\n",
      "\n",
      "Epoch 58 Step 1 Loss: 2.6706, Avg Loss: 2.6706\n",
      "Step 570 — Test metrics:\n",
      "  precision@10: 0.000825083\n",
      "  recall@10: 0.000825083\n",
      "  ndcg@10: 0.000800842\n",
      "  map@10: 0.000226252\n",
      "Epoch 58 Step 10 Loss: 2.6988, Avg Loss: 2.4852\n",
      "Epoch 58 completed. Train BPR Loss: 2.6087\n",
      "\n",
      "Epoch 59 Step 1 Loss: 2.5948, Avg Loss: 2.5948\n",
      "Step 580 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000814871\n",
      "  map@10: 0.000228086\n",
      "Epoch 59 Step 10 Loss: 2.6817, Avg Loss: 2.4596\n",
      "Epoch 59 completed. Train BPR Loss: 2.5818\n",
      "\n",
      "Epoch 60 Step 1 Loss: 2.5561, Avg Loss: 2.5561\n",
      "Step 590 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000814651\n",
      "  map@10: 0.000227889\n",
      "Epoch 60 Step 10 Loss: 2.6055, Avg Loss: 2.4597\n",
      "Epoch 60 completed. Train BPR Loss: 2.5819\n",
      "\n",
      "Epoch 61 Step 1 Loss: 2.6216, Avg Loss: 2.6216\n",
      "Step 600 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000816121\n",
      "  map@10: 0.000228778\n",
      "Epoch 61 Step 10 Loss: 2.5710, Avg Loss: 2.4518\n",
      "Epoch 61 completed. Train BPR Loss: 2.5737\n",
      "\n",
      "Epoch 62 Step 1 Loss: 2.5848, Avg Loss: 2.5848\n",
      "Step 610 — Test metrics:\n",
      "  precision@10: 0.000872230\n",
      "  recall@10: 0.000872230\n",
      "  ndcg@10: 0.000832200\n",
      "  map@10: 0.000231463\n",
      "Epoch 62 Step 10 Loss: 2.5198, Avg Loss: 2.4478\n",
      "Epoch 62 completed. Train BPR Loss: 2.5695\n",
      "\n",
      "Epoch 63 Step 1 Loss: 2.5977, Avg Loss: 2.5977\n",
      "Step 620 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000820799\n",
      "  map@10: 0.000231070\n",
      "Epoch 63 Step 10 Loss: 2.5530, Avg Loss: 2.4384\n",
      "Epoch 63 completed. Train BPR Loss: 2.5596\n",
      "\n",
      "Epoch 64 Step 1 Loss: 2.5546, Avg Loss: 2.5546\n",
      "Step 630 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000824107\n",
      "  map@10: 0.000232707\n",
      "Epoch 64 Step 10 Loss: 2.5024, Avg Loss: 2.4229\n",
      "Epoch 64 completed. Train BPR Loss: 2.5434\n",
      "\n",
      "Epoch 65 Step 1 Loss: 2.5155, Avg Loss: 2.5155\n",
      "Step 640 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000824107\n",
      "  map@10: 0.000232707\n",
      "Epoch 65 Step 10 Loss: 2.4626, Avg Loss: 2.4120\n",
      "Epoch 65 completed. Train BPR Loss: 2.5319\n",
      "\n",
      "Epoch 66 Step 1 Loss: 2.5084, Avg Loss: 2.5084\n",
      "Step 650 — Test metrics:\n",
      "  precision@10: 0.000848656\n",
      "  recall@10: 0.000848656\n",
      "  ndcg@10: 0.000824856\n",
      "  map@10: 0.000233034\n",
      "Epoch 66 Step 10 Loss: 2.4978, Avg Loss: 2.4048\n",
      "Epoch 66 completed. Train BPR Loss: 2.5243\n",
      "\n",
      "Epoch 67 Step 1 Loss: 2.5335, Avg Loss: 2.5335\n",
      "Step 660 — Test metrics:\n",
      "  precision@10: 0.000872230\n",
      "  recall@10: 0.000872230\n",
      "  ndcg@10: 0.000847268\n",
      "  map@10: 0.000239583\n",
      "Epoch 67 Step 10 Loss: 2.4998, Avg Loss: 2.4049\n",
      "Epoch 67 completed. Train BPR Loss: 2.5244\n",
      "\n",
      "Epoch 68 Step 1 Loss: 2.5015, Avg Loss: 2.5015\n",
      "Step 670 — Test metrics:\n",
      "  precision@10: 0.000872230\n",
      "  recall@10: 0.000872230\n",
      "  ndcg@10: 0.000849607\n",
      "  map@10: 0.000240696\n",
      "Epoch 68 Step 10 Loss: 2.5638, Avg Loss: 2.3876\n",
      "Epoch 68 completed. Train BPR Loss: 2.5062\n",
      "\n",
      "Epoch 69 Step 1 Loss: 2.4516, Avg Loss: 2.4516\n",
      "Step 680 — Test metrics:\n",
      "  precision@10: 0.000895804\n",
      "  recall@10: 0.000895804\n",
      "  ndcg@10: 0.000849844\n",
      "  map@10: 0.000233427\n",
      "Epoch 69 Step 10 Loss: 2.4191, Avg Loss: 2.3856\n",
      "Epoch 69 completed. Train BPR Loss: 2.5042\n",
      "\n",
      "Epoch 70 Step 1 Loss: 2.5223, Avg Loss: 2.5223\n",
      "Step 690 — Test metrics:\n",
      "  precision@10: 0.000919378\n",
      "  recall@10: 0.000919378\n",
      "  ndcg@10: 0.000862424\n",
      "  map@10: 0.000233839\n",
      "Epoch 70 Step 10 Loss: 2.4354, Avg Loss: 2.3661\n",
      "Epoch 70 completed. Train BPR Loss: 2.4837\n",
      "\n",
      "Epoch 71 Step 1 Loss: 2.5063, Avg Loss: 2.5063\n",
      "Step 700 — Test metrics:\n",
      "  precision@10: 0.000919378\n",
      "  recall@10: 0.000919378\n",
      "  ndcg@10: 0.000861869\n",
      "  map@10: 0.000232997\n",
      "Epoch 71 Step 10 Loss: 2.4232, Avg Loss: 2.3490\n",
      "Epoch 71 completed. Train BPR Loss: 2.4657\n",
      "\n",
      "Epoch 72 Step 1 Loss: 2.4887, Avg Loss: 2.4887\n",
      "Step 710 — Test metrics:\n",
      "  precision@10: 0.000942951\n",
      "  recall@10: 0.000942951\n",
      "  ndcg@10: 0.000885097\n",
      "  map@10: 0.000239452\n",
      "Epoch 72 Step 10 Loss: 2.3932, Avg Loss: 2.3426\n",
      "Epoch 72 completed. Train BPR Loss: 2.4591\n",
      "\n",
      "Epoch 73 Step 1 Loss: 2.4379, Avg Loss: 2.4379\n",
      "Step 720 — Test metrics:\n",
      "  precision@10: 0.000942951\n",
      "  recall@10: 0.000942951\n",
      "  ndcg@10: 0.000883646\n",
      "  map@10: 0.000238600\n",
      "Epoch 73 Step 10 Loss: 2.4535, Avg Loss: 2.3321\n",
      "Epoch 73 completed. Train BPR Loss: 2.4480\n",
      "\n",
      "Epoch 74 Step 1 Loss: 2.5149, Avg Loss: 2.5149\n",
      "Step 730 — Test metrics:\n",
      "  precision@10: 0.000966525\n",
      "  recall@10: 0.000966525\n",
      "  ndcg@10: 0.000898646\n",
      "  map@10: 0.000240761\n",
      "Epoch 74 Step 10 Loss: 2.3697, Avg Loss: 2.3240\n",
      "Epoch 74 completed. Train BPR Loss: 2.4395\n",
      "\n",
      "Epoch 75 Step 1 Loss: 2.4484, Avg Loss: 2.4484\n",
      "Step 740 — Test metrics:\n",
      "  precision@10: 0.000942951\n",
      "  recall@10: 0.000942951\n",
      "  ndcg@10: 0.000885493\n",
      "  map@10: 0.000239816\n",
      "Epoch 75 Step 10 Loss: 2.4308, Avg Loss: 2.3185\n",
      "Epoch 75 completed. Train BPR Loss: 2.4337\n",
      "\n",
      "Epoch 76 Step 1 Loss: 2.4587, Avg Loss: 2.4587\n",
      "Step 750 — Test metrics:\n",
      "  precision@10: 0.000919378\n",
      "  recall@10: 0.000919378\n",
      "  ndcg@10: 0.000868025\n",
      "  map@10: 0.000236271\n",
      "Epoch 76 Step 10 Loss: 2.4282, Avg Loss: 2.3101\n",
      "Epoch 76 completed. Train BPR Loss: 2.4250\n",
      "\n",
      "Epoch 77 Step 1 Loss: 2.3925, Avg Loss: 2.3925\n",
      "Step 760 — Test metrics:\n",
      "  precision@10: 0.000919378\n",
      "  recall@10: 0.000919378\n",
      "  ndcg@10: 0.000882291\n",
      "  map@10: 0.000243989\n",
      "Epoch 77 Step 10 Loss: 2.4707, Avg Loss: 2.2979\n",
      "Epoch 77 completed. Train BPR Loss: 2.4121\n",
      "\n",
      "Epoch 78 Step 1 Loss: 2.4264, Avg Loss: 2.4264\n",
      "Step 770 — Test metrics:\n",
      "  precision@10: 0.000942951\n",
      "  recall@10: 0.000942951\n",
      "  ndcg@10: 0.000901506\n",
      "  map@10: 0.000248572\n",
      "Epoch 78 Step 10 Loss: 2.3840, Avg Loss: 2.2903\n",
      "Epoch 78 completed. Train BPR Loss: 2.4041\n",
      "\n",
      "Epoch 79 Step 1 Loss: 2.3771, Avg Loss: 2.3771\n",
      "Step 780 — Test metrics:\n",
      "  precision@10: 0.001013673\n",
      "  recall@10: 0.001013673\n",
      "  ndcg@10: 0.000944847\n",
      "  map@10: 0.000254728\n",
      "Epoch 79 Step 10 Loss: 2.3823, Avg Loss: 2.2789\n",
      "Epoch 79 completed. Train BPR Loss: 2.3922\n",
      "\n",
      "Epoch 80 Step 1 Loss: 2.4469, Avg Loss: 2.4469\n",
      "Step 790 — Test metrics:\n",
      "  precision@10: 0.001037247\n",
      "  recall@10: 0.001037247\n",
      "  ndcg@10: 0.000959538\n",
      "  map@10: 0.000256926\n",
      "Epoch 80 Step 10 Loss: 2.3282, Avg Loss: 2.2805\n",
      "Epoch 80 completed. Train BPR Loss: 2.3938\n",
      "\n",
      "Epoch 81 Step 1 Loss: 2.3688, Avg Loss: 2.3688\n",
      "Step 800 — Test metrics:\n",
      "  precision@10: 0.001037247\n",
      "  recall@10: 0.001037247\n",
      "  ndcg@10: 0.000960159\n",
      "  map@10: 0.000257188\n",
      "Epoch 81 Step 10 Loss: 2.3862, Avg Loss: 2.2595\n",
      "Epoch 81 completed. Train BPR Loss: 2.3718\n",
      "\n",
      "Epoch 82 Step 1 Loss: 2.3801, Avg Loss: 2.3801\n",
      "Step 810 — Test metrics:\n",
      "  precision@10: 0.001037247\n",
      "  recall@10: 0.001037247\n",
      "  ndcg@10: 0.000963360\n",
      "  map@10: 0.000258788\n",
      "Epoch 82 Step 10 Loss: 2.3562, Avg Loss: 2.2581\n",
      "Epoch 82 completed. Train BPR Loss: 2.3703\n",
      "\n",
      "Epoch 83 Step 1 Loss: 2.3188, Avg Loss: 2.3188\n",
      "Step 820 — Test metrics:\n",
      "  precision@10: 0.001037247\n",
      "  recall@10: 0.001037247\n",
      "  ndcg@10: 0.000958361\n",
      "  map@10: 0.000255701\n",
      "Epoch 83 Step 10 Loss: 2.3685, Avg Loss: 2.2277\n",
      "Epoch 83 completed. Train BPR Loss: 2.3384\n",
      "\n",
      "Epoch 84 Step 1 Loss: 2.3163, Avg Loss: 2.3163\n",
      "Step 830 — Test metrics:\n",
      "  precision@10: 0.001037247\n",
      "  recall@10: 0.001037247\n",
      "  ndcg@10: 0.000954069\n",
      "  map@10: 0.000252960\n",
      "Epoch 84 Step 10 Loss: 2.3346, Avg Loss: 2.2290\n",
      "Epoch 84 completed. Train BPR Loss: 2.3397\n",
      "\n",
      "Epoch 85 Step 1 Loss: 2.3040, Avg Loss: 2.3040\n",
      "Step 840 — Test metrics:\n",
      "  precision@10: 0.001037247\n",
      "  recall@10: 0.001037247\n",
      "  ndcg@10: 0.000954690\n",
      "  map@10: 0.000253222\n",
      "Epoch 85 Step 10 Loss: 2.3555, Avg Loss: 2.2131\n",
      "Epoch 85 completed. Train BPR Loss: 2.3231\n",
      "\n",
      "Epoch 86 Step 1 Loss: 2.3358, Avg Loss: 2.3358\n",
      "Step 850 — Test metrics:\n",
      "  precision@10: 0.001037247\n",
      "  recall@10: 0.001037247\n",
      "  ndcg@10: 0.000959143\n",
      "  map@10: 0.000255317\n",
      "Epoch 86 Step 10 Loss: 2.3219, Avg Loss: 2.2162\n",
      "Epoch 86 completed. Train BPR Loss: 2.3263\n",
      "\n",
      "Epoch 87 Step 1 Loss: 2.3506, Avg Loss: 2.3506\n",
      "Step 860 — Test metrics:\n",
      "  precision@10: 0.001037247\n",
      "  recall@10: 0.001037247\n",
      "  ndcg@10: 0.000964238\n",
      "  map@10: 0.000257937\n",
      "Epoch 87 Step 10 Loss: 2.3959, Avg Loss: 2.2105\n",
      "Epoch 87 completed. Train BPR Loss: 2.3203\n",
      "\n",
      "Epoch 88 Step 1 Loss: 2.3180, Avg Loss: 2.3180\n",
      "Step 870 — Test metrics:\n",
      "  precision@10: 0.001084394\n",
      "  recall@10: 0.001084394\n",
      "  ndcg@10: 0.000994896\n",
      "  map@10: 0.000263016\n",
      "Epoch 88 Step 10 Loss: 2.3179, Avg Loss: 2.2015\n",
      "Epoch 88 completed. Train BPR Loss: 2.3110\n",
      "\n",
      "Epoch 89 Step 1 Loss: 2.2979, Avg Loss: 2.2979\n",
      "Step 880 — Test metrics:\n",
      "  precision@10: 0.001107968\n",
      "  recall@10: 0.001107968\n",
      "  ndcg@10: 0.001008058\n",
      "  map@10: 0.000264429\n",
      "Epoch 89 Step 10 Loss: 2.3051, Avg Loss: 2.1864\n",
      "Epoch 89 completed. Train BPR Loss: 2.2951\n",
      "\n",
      "Epoch 90 Step 1 Loss: 2.3053, Avg Loss: 2.3053\n",
      "Step 890 — Test metrics:\n",
      "  precision@10: 0.001060820\n",
      "  recall@10: 0.001060820\n",
      "  ndcg@10: 0.000974707\n",
      "  map@10: 0.000258208\n",
      "Epoch 90 Step 10 Loss: 2.2411, Avg Loss: 2.1701\n",
      "Epoch 90 completed. Train BPR Loss: 2.2779\n",
      "\n",
      "Epoch 91 Step 1 Loss: 2.3230, Avg Loss: 2.3230\n",
      "Step 900 — Test metrics:\n",
      "  precision@10: 0.001037247\n",
      "  recall@10: 0.001037247\n",
      "  ndcg@10: 0.000964760\n",
      "  map@10: 0.000258376\n",
      "Epoch 91 Step 10 Loss: 2.2910, Avg Loss: 2.1602\n",
      "Epoch 91 completed. Train BPR Loss: 2.2676\n",
      "\n",
      "Epoch 92 Step 1 Loss: 2.2599, Avg Loss: 2.2599\n",
      "Step 910 — Test metrics:\n",
      "  precision@10: 0.001037247\n",
      "  recall@10: 0.001037247\n",
      "  ndcg@10: 0.000961226\n",
      "  map@10: 0.000256543\n",
      "Epoch 92 Step 10 Loss: 2.2584, Avg Loss: 2.1645\n",
      "Epoch 92 completed. Train BPR Loss: 2.2721\n",
      "\n",
      "Epoch 93 Step 1 Loss: 2.2973, Avg Loss: 2.2973\n",
      "Step 920 — Test metrics:\n",
      "  precision@10: 0.000990099\n",
      "  recall@10: 0.000990099\n",
      "  ndcg@10: 0.000933747\n",
      "  map@10: 0.000253035\n",
      "Epoch 93 Step 10 Loss: 2.2795, Avg Loss: 2.1647\n",
      "Epoch 93 completed. Train BPR Loss: 2.2723\n",
      "\n",
      "Epoch 94 Step 1 Loss: 2.2608, Avg Loss: 2.2608\n",
      "Step 930 — Test metrics:\n",
      "  precision@10: 0.000990099\n",
      "  recall@10: 0.000990099\n",
      "  ndcg@10: 0.000930725\n",
      "  map@10: 0.000251529\n",
      "Epoch 94 Step 10 Loss: 2.2419, Avg Loss: 2.1428\n",
      "Epoch 94 completed. Train BPR Loss: 2.2493\n",
      "\n",
      "Epoch 95 Step 1 Loss: 2.2333, Avg Loss: 2.2333\n",
      "Step 940 — Test metrics:\n",
      "  precision@10: 0.000966525\n",
      "  recall@10: 0.000966525\n",
      "  ndcg@10: 0.000914800\n",
      "  map@10: 0.000248750\n",
      "Epoch 95 Step 10 Loss: 2.2555, Avg Loss: 2.1358\n",
      "Epoch 95 completed. Train BPR Loss: 2.2419\n",
      "\n",
      "Epoch 96 Step 1 Loss: 2.2553, Avg Loss: 2.2553\n",
      "Step 950 — Test metrics:\n",
      "  precision@10: 0.000990099\n",
      "  recall@10: 0.000990099\n",
      "  ndcg@10: 0.000956709\n",
      "  map@10: 0.000267347\n",
      "Epoch 96 Step 10 Loss: 2.1554, Avg Loss: 2.1253\n",
      "Epoch 96 completed. Train BPR Loss: 2.2309\n",
      "\n",
      "Epoch 97 Step 1 Loss: 2.2026, Avg Loss: 2.2026\n",
      "Step 960 — Test metrics:\n",
      "  precision@10: 0.000990099\n",
      "  recall@10: 0.000990099\n",
      "  ndcg@10: 0.000955056\n",
      "  map@10: 0.000266431\n",
      "Epoch 97 Step 10 Loss: 2.2608, Avg Loss: 2.1232\n",
      "Epoch 97 completed. Train BPR Loss: 2.2287\n",
      "\n",
      "Epoch 98 Step 1 Loss: 2.2673, Avg Loss: 2.2673\n",
      "Step 970 — Test metrics:\n",
      "  precision@10: 0.000990099\n",
      "  recall@10: 0.000990099\n",
      "  ndcg@10: 0.000957466\n",
      "  map@10: 0.000267834\n",
      "Epoch 98 Step 10 Loss: 2.1622, Avg Loss: 2.1099\n",
      "Epoch 98 completed. Train BPR Loss: 2.2147\n",
      "\n",
      "Epoch 99 Step 1 Loss: 2.2192, Avg Loss: 2.2192\n",
      "Step 980 — Test metrics:\n",
      "  precision@10: 0.000990099\n",
      "  recall@10: 0.000990099\n",
      "  ndcg@10: 0.000957466\n",
      "  map@10: 0.000267834\n",
      "Epoch 99 Step 10 Loss: 2.2054, Avg Loss: 2.1049\n",
      "Epoch 99 completed. Train BPR Loss: 2.2096\n",
      "\n",
      "Epoch 100 Step 1 Loss: 2.1922, Avg Loss: 2.1922\n",
      "Step 990 — Test metrics:\n",
      "  precision@10: 0.000990099\n",
      "  recall@10: 0.000990099\n",
      "  ndcg@10: 0.000939244\n",
      "  map@10: 0.000256468\n",
      "Epoch 100 Step 10 Loss: 2.2056, Avg Loss: 2.0872\n",
      "Epoch 100 completed. Train BPR Loss: 2.1909\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "edge_type = hyperparameters['train_edge_type']\n",
    "num_epochs = hyperparameters['train_num_epochs']\n",
    "lr = hyperparameters['train_lr']\n",
    "batch_size = hyperparameters['train_batch_size']\n",
    "print_every = hyperparameters['train_print_every']\n",
    "test_every = hyperparameters['train_test_every']\n",
    "top_k = hyperparameters['test_topk']\n",
    "test_batch_size = hyperparameters['test_batch_size']\n",
    "model = train_simple_model(model,\n",
    "                    data,\n",
    "                    num_epochs=num_epochs,\n",
    "                    lr=lr,\n",
    "                    batch_size=batch_size,\n",
    "                    device=device,\n",
    "                    print_every=print_every,\n",
    "                    test_every=test_every,\n",
    "                    top_k=top_k,\n",
    "                    test_batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:14:01.220258Z",
     "iopub.status.busy": "2025-06-24T18:14:01.220042Z",
     "iopub.status.idle": "2025-06-24T18:14:01.236094Z",
     "shell.execute_reply": "2025-06-24T18:14:01.235432Z",
     "shell.execute_reply.started": "2025-06-24T18:14:01.220242Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='gnn_model_mvl.model' target='_blank'>gnn_model_mvl.model</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/gnn_model_mvl.model"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, \"gnn_model_mvl.model\")\n",
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('gnn_model_mvl.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:14:01.237158Z",
     "iopub.status.busy": "2025-06-24T18:14:01.236833Z",
     "iopub.status.idle": "2025-06-24T18:14:01.441360Z",
     "shell.execute_reply": "2025-06-24T18:14:01.440555Z",
     "shell.execute_reply.started": "2025-06-24T18:14:01.237141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:14:01.442839Z",
     "iopub.status.busy": "2025-06-24T18:14:01.442624Z",
     "iopub.status.idle": "2025-06-24T18:14:01.669817Z",
     "shell.execute_reply": "2025-06-24T18:14:01.669252Z",
     "shell.execute_reply.started": "2025-06-24T18:14:01.442822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "log_model(\n",
    "    experiment=experiment,\n",
    "    model=model,\n",
    "    model_name=\"GNN\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:14:01.670689Z",
     "iopub.status.busy": "2025-06-24T18:14:01.670479Z",
     "iopub.status.idle": "2025-06-24T18:14:03.341323Z",
     "shell.execute_reply": "2025-06-24T18:14:03.340778Z",
     "shell.execute_reply.started": "2025-06-24T18:14:01.670673Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : baseline-beauty\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/annanet/gnn-recommender/7989efbe77bc41bc94656aab3b575aa5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test map@10 vs step [100]       : (0.00021774881569789633, 0.0002747281530874176)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test ndcg@10 vs step [100]      : (0.0007708170150711486, 0.0010080580744078137)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test precision@10 vs step [100] : (0.0007779349363507779, 0.001107967939651108)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test recall@10 vs step [100]    : (0.0007779349363507779, 0.001107967939651108)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Train BPR Loss vs step [1000]   : (2.144906997680664, 3.370083808898926)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [100]                      : (2.1922457218170166, 3.3044185638427734)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : baseline-beauty\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed              : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_batch_size   : 8192\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_topk         : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_batch_size  : 16384\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_edge_type   : ('item', 'to_feedback_explicit_positive', 'explicit_positive')\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_lr          : 8e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_num_epochs  : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_print_every : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_test_every  : 25\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     types_of_feedback : ['explicit_positive', 'expliсit_negative', 'implicit_positive', 'implicit_negative']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 2 (4.22 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7705289,
     "sourceId": 12229447,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
