{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-24T21:31:35.512074Z",
     "iopub.status.busy": "2025-06-24T21:31:35.511642Z",
     "iopub.status.idle": "2025-06-24T21:31:50.757269Z",
     "shell.execute_reply": "2025-06-24T21:31:50.756470Z",
     "shell.execute_reply.started": "2025-06-24T21:31:35.512058Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.1/727.1 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install torch_geometric rectools\n",
    "!pip -q install comet_ml\n",
    "!pip -q install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:31:50.759366Z",
     "iopub.status.busy": "2025-06-24T21:31:50.759127Z",
     "iopub.status.idle": "2025-06-24T21:31:55.939053Z",
     "shell.execute_reply": "2025-06-24T21:31:55.938522Z",
     "shell.execute_reply.started": "2025-06-24T21:31:50.759344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:31:55.940038Z",
     "iopub.status.busy": "2025-06-24T21:31:55.939729Z",
     "iopub.status.idle": "2025-06-24T21:31:55.946811Z",
     "shell.execute_reply": "2025-06-24T21:31:55.946242Z",
     "shell.execute_reply.started": "2025-06-24T21:31:55.940020Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:31:55.948227Z",
     "iopub.status.busy": "2025-06-24T21:31:55.947624Z",
     "iopub.status.idle": "2025-06-24T21:32:02.382092Z",
     "shell.execute_reply": "2025-06-24T21:32:02.381547Z",
     "shell.execute_reply.started": "2025-06-24T21:31:55.948202Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/annanet/gnn-recommender/dacb52cfe2484bdf829c364c91939b69\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "  api_key=os.getenv('API_KEY'),\n",
    "  project_name=\"gnn-recommender\",\n",
    "  workspace=\"annanet\",\n",
    "  log_code=True\n",
    ")\n",
    "\n",
    "experiment.set_name('emosage-thp-beauty')\n",
    "experiment.add_tags(['beauty', 'leave-n-out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.comet.com/annanet/gnn-recommender/dacb52cfe2484bdf829c364c91939b69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:02.383207Z",
     "iopub.status.busy": "2025-06-24T21:32:02.382930Z",
     "iopub.status.idle": "2025-06-24T21:32:02.388196Z",
     "shell.execute_reply": "2025-06-24T21:32:02.387584Z",
     "shell.execute_reply.started": "2025-06-24T21:32:02.383184Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'seed': 42,\n",
    "    'types_of_feedback': [\"explicit_positive\", \"expliсit_negative\",\n",
    "                          \"implicit_positive\", \"implicit_negative\"],\n",
    "    'max_len_of_thp_history': 100,\n",
    "    'pad_id': 0,         \n",
    "    'cls_id': None,  # filled in at the stage of creating a story for thp\n",
    "    'thp_dmodel': 64,  # размер эмбеддингов\n",
    "    'thp_n_head': 4,  # число attention-голов\n",
    "    'thp_window_size': 101,  # окно THP\n",
    "    'thp_decay': 1.0,  # скорость экспоненциального затухания\n",
    "    'thp_dropout': 0.2,  # dropout\n",
    "    'train_edge_type': [('item','to_feedback_explicit_positive','explicit_positive'), \n",
    "                        ('item','to_feedback_implicit_positive','implicit_positive')],\n",
    "    'train_num_epochs': 200,\n",
    "    'train_lr': 1e-3,\n",
    "    'train_batch_size': 4096,\n",
    "    'train_print_every': 20,  # раз в сколько шагов печатаем статистику\n",
    "    'train_test_every': 50,\n",
    "    'test_topk': 10,\n",
    "    'test_batch_size': 8192,\n",
    "    'train_scheduler_step_size': 150,\n",
    "    'train_scheduler_gamma': 0.98\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:02.391558Z",
     "iopub.status.busy": "2025-06-24T21:32:02.391296Z",
     "iopub.status.idle": "2025-06-24T21:32:02.438225Z",
     "shell.execute_reply": "2025-06-24T21:32:02.437420Z",
     "shell.execute_reply.started": "2025-06-24T21:32:02.391533Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv', 'test.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/kaggle/input/data/leave-n-out/beauty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:02.440543Z",
     "iopub.status.busy": "2025-06-24T21:32:02.440059Z",
     "iopub.status.idle": "2025-06-24T21:32:12.827485Z",
     "shell.execute_reply": "2025-06-24T21:32:12.826883Z",
     "shell.execute_reply.started": "2025-06-24T21:32:02.440522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from rectools import Columns\n",
    "from rectools.metrics import MAP, Precision, Recall, NDCG, calc_metrics\n",
    "\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:12.828473Z",
     "iopub.status.busy": "2025-06-24T21:32:12.828079Z",
     "iopub.status.idle": "2025-06-24T21:32:12.837688Z",
     "shell.execute_reply": "2025-06-24T21:32:12.836977Z",
     "shell.execute_reply.started": "2025-06-24T21:32:12.828456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = hyperparameters['seed']\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:12.838641Z",
     "iopub.status.busy": "2025-06-24T21:32:12.838412Z",
     "iopub.status.idle": "2025-06-24T21:32:14.450540Z",
     "shell.execute_reply": "2025-06-24T21:32:14.449743Z",
     "shell.execute_reply.started": "2025-06-24T21:32:12.838625Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 user_id     item_id  rating  \\\n",
      "0  A00414041RD0BXM6WK0GX  B007IY97U0     3.0   \n",
      "1  A00414041RD0BXM6WK0GX  B00870XLDS     2.0   \n",
      "2  A00414041RD0BXM6WK0GX  B008MIRO88     1.0   \n",
      "3  A00414041RD0BXM6WK0GX  B00BQYYMN0     3.0   \n",
      "4  A00414041RD0BXM6WK0GX  B00GRTQBTM     5.0   \n",
      "\n",
      "                                         review_text   unix_time       date  \n",
      "0  Good quality wig, but the blonde is much more ...  2014-07-14 2014-07-14  \n",
      "1  Very thin and not as long as the photos :( Aft...  2014-07-14 2014-07-14  \n",
      "2  Very thin and not as long as the photos :( Aft...  2014-07-14 2014-07-14  \n",
      "3  This is a great quality wig, however it is a m...  2014-07-14 2014-07-14  \n",
      "4  This is my absolute favorite wig! I have purch...  2014-07-14 2014-07-14  \n"
     ]
    }
   ],
   "source": [
    "rootpath = '/kaggle/input/data/leave-n-out/beauty/'\n",
    "train = pd.read_csv(\n",
    "    rootpath+'train.csv'\n",
    ")\n",
    "train['date'] = pd.to_datetime(train['unix_time'])\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:14.451542Z",
     "iopub.status.busy": "2025-06-24T21:32:14.451251Z",
     "iopub.status.idle": "2025-06-24T21:32:14.484124Z",
     "shell.execute_reply": "2025-06-24T21:32:14.483351Z",
     "shell.execute_reply.started": "2025-06-24T21:32:14.451525Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество explicit позитивного фидбека 90800\n",
      "Количество explicit негативного фидбека 17504\n"
     ]
    }
   ],
   "source": [
    "explicit_positive = train[(train[\"rating\"] == 5)].index\n",
    "explisit_negative = train[(train[\"rating\"] <= 2)].index\n",
    "\n",
    "explicit_combined_feedback = explicit_positive.union(explisit_negative)\n",
    "print('Количество explicit позитивного фидбека', explicit_positive.shape[0])\n",
    "print('Количество explicit негативного фидбека', explisit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:14.485083Z",
     "iopub.status.busy": "2025-06-24T21:32:14.484878Z",
     "iopub.status.idle": "2025-06-24T21:32:14.500028Z",
     "shell.execute_reply": "2025-06-24T21:32:14.499425Z",
     "shell.execute_reply.started": "2025-06-24T21:32:14.485068Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество implicit позитивного фидбека 30668\n",
      "Количество implicit негативного фидбека 17110\n"
     ]
    }
   ],
   "source": [
    "implicit_positive = train[(train[\"rating\"] == 4)].index\n",
    "implicit_negative = train[(train[\"rating\"] == 3)].index\n",
    "\n",
    "implicit_combined_feedback = implicit_positive.union(implicit_negative)\n",
    "print('Количество implicit позитивного фидбека', implicit_positive.shape[0])\n",
    "print('Количество implicit негативного фидбека', implicit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:14.501880Z",
     "iopub.status.busy": "2025-06-24T21:32:14.501675Z",
     "iopub.status.idle": "2025-06-24T21:32:14.548428Z",
     "shell.execute_reply": "2025-06-24T21:32:14.547695Z",
     "shell.execute_reply.started": "2025-06-24T21:32:14.501866Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B007IY97U0</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B00870XLDS</td>\n",
       "      <td>expliсit_negative</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B008MIRO88</td>\n",
       "      <td>expliсit_negative</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B00BQYYMN0</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B00GRTQBTM</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id     item_id             target       date\n",
       "0  A00414041RD0BXM6WK0GX  B007IY97U0  implicit_negative 2014-07-14\n",
       "1  A00414041RD0BXM6WK0GX  B00870XLDS  expliсit_negative 2014-07-14\n",
       "2  A00414041RD0BXM6WK0GX  B008MIRO88  expliсit_negative 2014-07-14\n",
       "3  A00414041RD0BXM6WK0GX  B00BQYYMN0  implicit_negative 2014-07-14\n",
       "4  A00414041RD0BXM6WK0GX  B00GRTQBTM  explicit_positive 2014-07-14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:, \"target\"] = \"\"\n",
    "train.loc[explicit_positive, \"target\"] = \"explicit_positive\"\n",
    "train.loc[explisit_negative, \"target\"] = \"expliсit_negative\"\n",
    "train.loc[implicit_positive, \"target\"] = \"implicit_positive\"\n",
    "train.loc[implicit_negative, \"target\"] = \"implicit_negative\"\n",
    "\n",
    "train = train[['user_id','item_id','target','date']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:14.549406Z",
     "iopub.status.busy": "2025-06-24T21:32:14.549122Z",
     "iopub.status.idle": "2025-06-24T21:32:14.587009Z",
     "shell.execute_reply": "2025-06-24T21:32:14.586418Z",
     "shell.execute_reply.started": "2025-06-24T21:32:14.549350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = train.sort_values(by=[\"user_id\", \"date\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:14.587822Z",
     "iopub.status.busy": "2025-06-24T21:32:14.587611Z",
     "iopub.status.idle": "2025-06-24T21:32:14.597300Z",
     "shell.execute_reply": "2025-06-24T21:32:14.596710Z",
     "shell.execute_reply.started": "2025-06-24T21:32:14.587806Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B007IY97U0</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B00870XLDS</td>\n",
       "      <td>expliсit_negative</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B008MIRO88</td>\n",
       "      <td>expliсit_negative</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B00BQYYMN0</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B00GRTQBTM</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2014-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156077</th>\n",
       "      <td>AZZZLM1E5JJ8C</td>\n",
       "      <td>B00027DMSI</td>\n",
       "      <td>expliсit_negative</td>\n",
       "      <td>2012-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156078</th>\n",
       "      <td>AZZZLM1E5JJ8C</td>\n",
       "      <td>B000QE5GU4</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2013-08-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156079</th>\n",
       "      <td>AZZZLM1E5JJ8C</td>\n",
       "      <td>B004CQ710U</td>\n",
       "      <td>expliсit_negative</td>\n",
       "      <td>2013-08-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156080</th>\n",
       "      <td>AZZZLM1E5JJ8C</td>\n",
       "      <td>B005RFI1YK</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2013-08-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156081</th>\n",
       "      <td>AZZZLM1E5JJ8C</td>\n",
       "      <td>B005XP4YNQ</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2013-08-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156082 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      user_id     item_id             target       date\n",
       "0       A00414041RD0BXM6WK0GX  B007IY97U0  implicit_negative 2014-07-14\n",
       "1       A00414041RD0BXM6WK0GX  B00870XLDS  expliсit_negative 2014-07-14\n",
       "2       A00414041RD0BXM6WK0GX  B008MIRO88  expliсit_negative 2014-07-14\n",
       "3       A00414041RD0BXM6WK0GX  B00BQYYMN0  implicit_negative 2014-07-14\n",
       "4       A00414041RD0BXM6WK0GX  B00GRTQBTM  explicit_positive 2014-07-14\n",
       "...                       ...         ...                ...        ...\n",
       "156077          AZZZLM1E5JJ8C  B00027DMSI  expliсit_negative 2012-11-10\n",
       "156078          AZZZLM1E5JJ8C  B000QE5GU4  explicit_positive 2013-08-17\n",
       "156079          AZZZLM1E5JJ8C  B004CQ710U  expliсit_negative 2013-08-17\n",
       "156080          AZZZLM1E5JJ8C  B005RFI1YK  explicit_positive 2013-08-17\n",
       "156081          AZZZLM1E5JJ8C  B005XP4YNQ  implicit_negative 2013-08-17\n",
       "\n",
       "[156082 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:14.598532Z",
     "iopub.status.busy": "2025-06-24T21:32:14.598274Z",
     "iopub.status.idle": "2025-06-24T21:32:14.612687Z",
     "shell.execute_reply": "2025-06-24T21:32:14.612048Z",
     "shell.execute_reply.started": "2025-06-24T21:32:14.598514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.columns = ['user_id', 'item_id', 'target', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:22.466625Z",
     "iopub.status.busy": "2025-06-24T21:32:22.466323Z",
     "iopub.status.idle": "2025-06-24T21:32:22.964455Z",
     "shell.execute_reply": "2025-06-24T21:32:22.963788Z",
     "shell.execute_reply.started": "2025-06-24T21:32:22.466605Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 user_id     item_id  rating  \\\n",
      "0  A02155413BVL8D0G7X6DN  B0089JVEPO     5.0   \n",
      "1  A02155413BVL8D0G7X6DN  B001G2LWDK     5.0   \n",
      "2  A02155413BVL8D0G7X6DN  B005Z41P28     5.0   \n",
      "3  A02155413BVL8D0G7X6DN  B0055MYJ0U     5.0   \n",
      "4  A02155413BVL8D0G7X6DN  B00117CH5M     3.0   \n",
      "\n",
      "                                         review_text   unix_time       date  \n",
      "0  leaves my skin clean and smooth. it is creamy ...  2012-10-25 2012-10-25  \n",
      "1  Works great, smells good, there is a result. I...  2012-12-06 2012-12-06  \n",
      "2  it works for my hair. smells like almond. made...  2013-01-17 2013-01-17  \n",
      "3  got this in the mail from China today! holds m...  2013-04-22 2013-04-22  \n",
      "4  if you like strong smell of honeysuckles and h...  2013-05-01 2013-05-01  \n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\n",
    "    rootpath+'test.csv'\n",
    ")\n",
    "test['date'] = pd.to_datetime(test['unix_time'])\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:26.910771Z",
     "iopub.status.busy": "2025-06-24T21:32:26.910084Z",
     "iopub.status.idle": "2025-06-24T21:32:26.923101Z",
     "shell.execute_reply": "2025-06-24T21:32:26.922450Z",
     "shell.execute_reply.started": "2025-06-24T21:32:26.910749Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A02155413BVL8D0G7X6DN</td>\n",
       "      <td>B0089JVEPO</td>\n",
       "      <td>2012-10-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A02155413BVL8D0G7X6DN</td>\n",
       "      <td>B001G2LWDK</td>\n",
       "      <td>2012-12-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A02155413BVL8D0G7X6DN</td>\n",
       "      <td>B005Z41P28</td>\n",
       "      <td>2013-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A02155413BVL8D0G7X6DN</td>\n",
       "      <td>B0055MYJ0U</td>\n",
       "      <td>2013-04-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A02155413BVL8D0G7X6DN</td>\n",
       "      <td>B00117CH5M</td>\n",
       "      <td>2013-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id     item_id       date\n",
       "0  A02155413BVL8D0G7X6DN  B0089JVEPO 2012-10-25\n",
       "1  A02155413BVL8D0G7X6DN  B001G2LWDK 2012-12-06\n",
       "2  A02155413BVL8D0G7X6DN  B005Z41P28 2013-01-17\n",
       "3  A02155413BVL8D0G7X6DN  B0055MYJ0U 2013-04-22\n",
       "4  A02155413BVL8D0G7X6DN  B00117CH5M 2013-05-01"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[['user_id','item_id', 'date']]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:28.339576Z",
     "iopub.status.busy": "2025-06-24T21:32:28.339290Z",
     "iopub.status.idle": "2025-06-24T21:32:28.343413Z",
     "shell.execute_reply": "2025-06-24T21:32:28.342626Z",
     "shell.execute_reply.started": "2025-06-24T21:32:28.339558Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test.columns = ['user_id', 'item_id', 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP model v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:30.556569Z",
     "iopub.status.busy": "2025-06-24T21:32:30.556277Z",
     "iopub.status.idle": "2025-06-24T21:32:30.583659Z",
     "shell.execute_reply": "2025-06-24T21:32:30.582833Z",
     "shell.execute_reply.started": "2025-06-24T21:32:30.556550Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.loc[:, \"event\"] = 0\n",
    "train.loc[(train[\"target\"] == \"explicit_positive\") | (train[\"target\"] == \"implicit_positive\"), \"event\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:31.798814Z",
     "iopub.status.busy": "2025-06-24T21:32:31.798255Z",
     "iopub.status.idle": "2025-06-24T21:32:31.824001Z",
     "shell.execute_reply": "2025-06-24T21:32:31.823161Z",
     "shell.execute_reply.started": "2025-06-24T21:32:31.798790Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42378, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[(test.user_id.isin(train.user_id)) & (test.item_id.isin(train.item_id))].copy()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:34.027591Z",
     "iopub.status.busy": "2025-06-24T21:32:34.027280Z",
     "iopub.status.idle": "2025-06-24T21:32:34.171520Z",
     "shell.execute_reply": "2025-06-24T21:32:34.170934Z",
     "shell.execute_reply.started": "2025-06-24T21:32:34.027570Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. Преобразование данных - для куарека не особо нужно, но для других - напоминалка\n",
    "# делаем всегда! чтобы не сломать ничего дальше и чтобы все индексы были от 0 до N без пропусков\n",
    "user_encoder = LabelEncoder()\n",
    "video_encoder = LabelEncoder()\n",
    "\n",
    "train.loc[:, 'user_id'] = user_encoder.fit_transform(train['user_id'])\n",
    "train.loc[:, 'item_id'] = video_encoder.fit_transform(train['item_id'])\n",
    "\n",
    "test.loc[:, 'user_id'] = user_encoder.transform(test['user_id'])\n",
    "test.loc[:, 'item_id'] = video_encoder.transform(test['item_id'])\n",
    "\n",
    "train['user_id'] = train['user_id'].astype(int)\n",
    "train['item_id'] = train['item_id'].astype(int)\n",
    "test['user_id'] = test['user_id'].astype(int)\n",
    "test['item_id'] = test['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:34.701357Z",
     "iopub.status.busy": "2025-06-24T21:32:34.701050Z",
     "iopub.status.idle": "2025-06-24T21:32:34.711943Z",
     "shell.execute_reply": "2025-06-24T21:32:34.711321Z",
     "shell.execute_reply.started": "2025-06-24T21:32:34.701337Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных item_id 12095\n",
      "Количество уникальных user_id 22363\n"
     ]
    }
   ],
   "source": [
    "# т.е. сразу знаем количество и в каких пределах изменяется user_id и video_id\n",
    "num_videos = train['item_id'].nunique()\n",
    "num_users = train['user_id'].nunique()\n",
    "\n",
    "print('Количество уникальных item_id', num_videos)\n",
    "print('Количество уникальных user_id', num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:36.720940Z",
     "iopub.status.busy": "2025-06-24T21:32:36.720644Z",
     "iopub.status.idle": "2025-06-24T21:32:36.727070Z",
     "shell.execute_reply": "2025-06-24T21:32:36.726292Z",
     "shell.execute_reply.started": "2025-06-24T21:32:36.720919Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# так как используем pad, то нумерацию item_id начинаем с 1 до max + 1, чтобы для pad забить 0\n",
    "train.loc[:, 'item_id'] += 1\n",
    "test.loc[:, 'item_id'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:49.276521Z",
     "iopub.status.busy": "2025-06-24T21:32:49.276212Z",
     "iopub.status.idle": "2025-06-24T21:32:49.284068Z",
     "shell.execute_reply": "2025-06-24T21:32:49.283222Z",
     "shell.execute_reply.started": "2025-06-24T21:32:49.276500Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "\n",
    "def prepare_hetero_data(df: pd.DataFrame) -> HeteroData:\n",
    "    \"\"\"\n",
    "    Build a heterogeneous graph dataset from interaction records.\n",
    "\n",
    "    This function constructs a PyTorch Geometric HeteroData object with three types of nodes:\n",
    "      - 'user': representing each unique user in the dataset\n",
    "      - 'item': representing each unique item (formerly movie)\n",
    "      - one node set per feedback type (target), representing feedback interaction events\n",
    "\n",
    "    Edges are created as follows:\n",
    "      1) item -> feedback: connecting items to feedback events of type ft\n",
    "      2) feedback -> item: reverse link from feedback events back to items (for message passing)\n",
    "      3) feedback -> user: linking each feedback event of type ft to its corresponding user (one-to-one)\n",
    "      4) user -> user: a complete graph among all users under the relation 'interacts'\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame must contain the following columns:\n",
    "          - 'user_id' : integer identifiers for users (0-indexed or otherwise)\n",
    "          - 'item_id' : integer identifiers for items (e.g. movies), values must be in [0, max(item_id)]\n",
    "          - 'target' : categorical or numeric label indicating feedback type (e.g. click, purchase)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    data : torch_geometric.data.HeteroData\n",
    "        A heterogeneous graph with node types 'user', 'item', and one per feedback label, and edge_index\n",
    "        tensors appropriately set for message passing in a GNN.\n",
    "    \"\"\"\n",
    "    # Determine the number of users and items\n",
    "    num_users = df['user_id'].nunique()\n",
    "    num_items = int(df['item_id'].max()) + 1\n",
    "    feedback_types = df['target'].unique().tolist()\n",
    "\n",
    "    # Initialize HeteroData\n",
    "    data = HeteroData()\n",
    "    data['user'].node_id = torch.arange(num_users)\n",
    "    data['item'].node_id = torch.arange(num_items)\n",
    "    for ft in feedback_types:\n",
    "        data[ft].node_id = torch.arange(num_users)\n",
    "\n",
    "    # Build edges: item <-> feedback <-> user\n",
    "    for ft in feedback_types:\n",
    "        mask = df['target'] == ft\n",
    "        items = torch.LongTensor(df.loc[mask, 'item_id'].values)\n",
    "        users_idx = torch.LongTensor(df.loc[mask, 'user_id'].values)\n",
    "\n",
    "        # item -> feedback\n",
    "        data['item', f'to_feedback_{ft}', ft].edge_index = torch.stack([items, users_idx], dim=0)\n",
    "        # feedback -> item\n",
    "        data[ft, f'feedback_to_item_{ft}', 'item'].edge_index = torch.stack([users_idx, items], dim=0)\n",
    "        # feedback -> user (1:1 mapping)\n",
    "        idx = torch.arange(num_users)\n",
    "        data[ft, f'to_user_{ft}', 'user'].edge_index = torch.stack([idx, idx], dim=0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:49.647891Z",
     "iopub.status.busy": "2025-06-24T21:32:49.647611Z",
     "iopub.status.idle": "2025-06-24T21:32:49.730706Z",
     "shell.execute_reply": "2025-06-24T21:32:49.729918Z",
     "shell.execute_reply.started": "2025-06-24T21:32:49.647873Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ node_id=[22363] },\n",
       "  item={ node_id=[12096] },\n",
       "  implicit_negative={ node_id=[22363] },\n",
       "  expliсit_negative={ node_id=[22363] },\n",
       "  explicit_positive={ node_id=[22363] },\n",
       "  implicit_positive={ node_id=[22363] },\n",
       "  (item, to_feedback_implicit_negative, implicit_negative)={ edge_index=[2, 17110] },\n",
       "  (implicit_negative, feedback_to_item_implicit_negative, item)={ edge_index=[2, 17110] },\n",
       "  (implicit_negative, to_user_implicit_negative, user)={ edge_index=[2, 22363] },\n",
       "  (item, to_feedback_expliсit_negative, expliсit_negative)={ edge_index=[2, 17504] },\n",
       "  (expliсit_negative, feedback_to_item_expliсit_negative, item)={ edge_index=[2, 17504] },\n",
       "  (expliсit_negative, to_user_expliсit_negative, user)={ edge_index=[2, 22363] },\n",
       "  (item, to_feedback_explicit_positive, explicit_positive)={ edge_index=[2, 90800] },\n",
       "  (explicit_positive, feedback_to_item_explicit_positive, item)={ edge_index=[2, 90800] },\n",
       "  (explicit_positive, to_user_explicit_positive, user)={ edge_index=[2, 22363] },\n",
       "  (item, to_feedback_implicit_positive, implicit_positive)={ edge_index=[2, 30668] },\n",
       "  (implicit_positive, feedback_to_item_implicit_positive, item)={ edge_index=[2, 30668] },\n",
       "  (implicit_positive, to_user_implicit_positive, user)={ edge_index=[2, 22363] }\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = prepare_hetero_data(train)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:51.703962Z",
     "iopub.status.busy": "2025-06-24T21:32:51.703259Z",
     "iopub.status.idle": "2025-06-24T21:32:51.715935Z",
     "shell.execute_reply": "2025-06-24T21:32:51.715290Z",
     "shell.execute_reply.started": "2025-06-24T21:32:51.703939Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     1,     2,  ..., 12093, 12094, 12095])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['item'].node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:55.205205Z",
     "iopub.status.busy": "2025-06-24T21:32:55.204623Z",
     "iopub.status.idle": "2025-06-24T21:32:55.213104Z",
     "shell.execute_reply": "2025-06-24T21:32:55.212438Z",
     "shell.execute_reply.started": "2025-06-24T21:32:55.205183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_thp_data(df: pd.DataFrame, max_len: int, pad: int, cls_id: int):\n",
    "    \"\"\"\n",
    "    Build sequences of item ids, event types and timestamps per user for THP training.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame with columns ['user_id','item_id','event','date']\n",
    "    max_len : int, maximum sequence length (pad or truncate to this length)\n",
    "    pad : int, padding token value (left-padding)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    seq_ids   : LongTensor [num_users, max_len]\n",
    "    event_type: LongTensor [num_users, max_len]\n",
    "    seq_times : FloatTensor [num_users, max_len]\n",
    "    seq_mask  : BoolTensor [num_users, max_len]\n",
    "    \"\"\"\n",
    "    users = df['user_id'].unique()\n",
    "    num_users = len(users)\n",
    "\n",
    "    # +1 for the [CLS] token\n",
    "    new_max_len = max_len + 1\n",
    "    \n",
    "    seq_ids    = torch.full((num_users, new_max_len), pad, dtype=torch.long)\n",
    "    event_type = torch.full((num_users, new_max_len), pad, dtype=torch.long)\n",
    "    seq_times  = torch.zeros((num_users, new_max_len), dtype=torch.float)\n",
    "    seq_mask   = torch.zeros((num_users, new_max_len), dtype=torch.bool)\n",
    "\n",
    "    # map event labels to ints\n",
    "    label2idx = {label: idx for idx, label in enumerate(df['event'].unique())}\n",
    "\n",
    "    # устанавливаем CLS-токен в позицию 0\n",
    "    seq_ids[:, 0]  = cls_id\n",
    "    event_type[:,0] = cls_id   \n",
    "    seq_mask[:, 0] = True\n",
    "\n",
    "    for i, u in enumerate(users):\n",
    "        user_df = df[df['user_id'] == u].sort_values('date')\n",
    "        items = user_df['item_id'].values\n",
    "        types = user_df['event'].map(label2idx).values\n",
    "        times = pd.to_datetime(user_df['date']).values.astype('datetime64[ns]').astype(np.int64) / 1e9\n",
    "        \n",
    "        seq = len(items)\n",
    "        if seq == 0:\n",
    "            continue\n",
    "\n",
    "        # вставляем реальные события **cдвинутые на 1** вправо из-за CLS,\n",
    "        # чтобы первые new_max_len-lengt...new_max_len-1 оказались данными\n",
    "        length = min(seq, max_len)\n",
    "        start = max(0, new_max_len - length)\n",
    "        seq_ids[i, start:]    = torch.tensor(items[-length:],    dtype=torch.long)\n",
    "        event_type[i, start:] = torch.tensor(types[-length:],    dtype=torch.long)\n",
    "        seq_times[i, start:]  = torch.tensor(times[-length:],    dtype=torch.float)\n",
    "        seq_mask[i, start:]   = True\n",
    "\n",
    "    return seq_ids, event_type, seq_times, seq_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:32:57.048018Z",
     "iopub.status.busy": "2025-06-24T21:32:57.047343Z",
     "iopub.status.idle": "2025-06-24T21:33:27.670065Z",
     "shell.execute_reply": "2025-06-24T21:33:27.669401Z",
     "shell.execute_reply.started": "2025-06-24T21:32:57.047997Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12096,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,  9450,  9840, 10077, 11156, 11753,\n",
       "         11864]),\n",
       " tensor([12096,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     1,\n",
       "             1]),\n",
       " tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4053e+09,\n",
       "         1.4053e+09, 1.4053e+09, 1.4053e+09, 1.4053e+09, 1.4053e+09]),\n",
       " tensor([ True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False,  True,  True,  True,  True,  True,\n",
       "          True]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_ID = hyperparameters['pad_id'] \n",
    "CLS_ID = data['item'].node_id.shape[0]  \n",
    "hyperparameters['cls_id'] = CLS_ID\n",
    "max_len = hyperparameters['max_len_of_thp_history']\n",
    "\n",
    "seq_ids, event_type, seq_times, seq_mask = prepare_thp_data(train, \n",
    "                                                            max_len=max_len, \n",
    "                                                            pad=PAD_ID,\n",
    "                                                            cls_id=CLS_ID)\n",
    "seq_ids[0], event_type[0], seq_times[0], seq_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:33:27.671587Z",
     "iopub.status.busy": "2025-06-24T21:33:27.671340Z",
     "iopub.status.idle": "2025-06-24T21:33:27.914842Z",
     "shell.execute_reply": "2025-06-24T21:33:27.914149Z",
     "shell.execute_reply.started": "2025-06-24T21:33:27.671571Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class THPEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head Transformer Hawkes-inspired encoder with local window.\n",
    "    Integrates exponential decay kernel within last `window_size` events.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, n_head: int, window_size: int = 50, \n",
    "                 decay: float = 1.0, dropout: float = 0.1, max_len: int = 101):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_len = max_len\n",
    "        # Learnable positional embeddings\n",
    "        self.pos_emb = nn.Embedding(max_len, d_model)\n",
    "        # Temporal (time) embedding: simple linear projection from scalar to d_model\n",
    "        self.time_emb = nn.Linear(1, d_model)\n",
    "        \n",
    "        self.heads = nn.ModuleList([\n",
    "            _THPHead(d_model, decay, window_size, dropout) for _ in range(n_head)\n",
    "        ])\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "                nn.LayerNorm(d_model),\n",
    "                nn.Linear(d_model, d_model * 4),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(d_model * 4, d_model),\n",
    "                nn.Dropout(dropout)\n",
    "            )\n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, emb: torch.Tensor, times: torch.Tensor, mask: torch.BoolTensor = None):\n",
    "        # emb: [B, L, D], times: [B, L], mask: [B, L]\n",
    "        B, L, D = emb.shape\n",
    "        \n",
    "        positions = torch.arange(L, device=emb.device).unsqueeze(0).expand(B, -1)  # [B, L]\n",
    "        pe = self.pos_emb(positions)  # [B, L, D]\n",
    "        te = self.time_emb(times.unsqueeze(-1))  # [B, L, D]\n",
    "        x = emb + pe + te\n",
    "        \n",
    "        attn_out = torch.stack([head(x, times, mask) for head in self.heads], dim=0).sum(0)\n",
    "        \n",
    "        # Residual connection + normalization\n",
    "        x = x + attn_out\n",
    "        x = x + self.ffn(x)\n",
    "        \n",
    "        return self.final_norm(x)  # [B, L, D]\n",
    "\n",
    "class _THPHead(nn.Module):\n",
    "    def __init__(self, d_model: int, decay: float, window_size: int, dropout: float,\n",
    "                pos_lambda: float = None):\n",
    "        super().__init__()\n",
    "        self.linear_v = nn.Linear(d_model, d_model, bias=False)\n",
    "        nn.init.xavier_uniform_(self.linear_v.weight)\n",
    "        self.temperature = d_model ** 0.5\n",
    "        self.decay = decay\n",
    "        self.window_size = window_size\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.input_norm = nn.LayerNorm(d_model)\n",
    "        self.pos_lambda = pos_lambda or (1.0 / window_size)\n",
    "\n",
    "    def forward(self, emb: torch.Tensor, times: torch.Tensor, mask: torch.BoolTensor = None):\n",
    "        B, L, D = emb.size()\n",
    "        emb_norm = self.input_norm(emb)\n",
    "        q = emb_norm / self.temperature           # [B, L, D]\n",
    "        k = emb_norm                              # [B, L, D]\n",
    "        v = F.elu(self.linear_v(emb_norm))        # [B, L, D]\n",
    "\n",
    "        if not torch.isfinite(q).all():\n",
    "            print(\"NaN/Inf в q:\", torch.isnan(q).sum().item(), torch.isinf(q).sum().item())\n",
    "        if not torch.isfinite(k).all():\n",
    "            print(\"NaN/Inf в k:\", torch.isnan(k).sum().item(), torch.isinf(k).sum().item())\n",
    "        if not torch.isfinite(v).all():\n",
    "            print(\"NaN/Inf в v:\", torch.isnan(v).sum().item(), torch.isinf(v).sum().item())\n",
    "\n",
    "        # 3) Build pad mask only\n",
    "        if mask is not None:\n",
    "            pad_mask = ~mask.unsqueeze(1).expand(-1, L, -1)  # [B, L, L]\n",
    "        else:\n",
    "            pad_mask = torch.zeros((B, L, L), dtype=torch.bool, device=emb.device)\n",
    "\n",
    "        # Always allow self-attention for pad_mask diagonal\n",
    "        idx = torch.arange(L, device=emb.device)\n",
    "        pad_mask[:, idx, idx] = False\n",
    "\n",
    "        scores = torch.bmm(q, k.transpose(1, 2))  # [B, L, L]\n",
    "\n",
    "        # Apply temporal decay kernel\n",
    "        delta = (times.unsqueeze(-1) - times.unsqueeze(-2)).clamp(min=0)\n",
    "        scores = scores * torch.exp(-self.decay * delta)\n",
    "\n",
    "        # Apply smooth positional decay\n",
    "        dist = (idx.unsqueeze(0) - idx.unsqueeze(1)).abs().float()  # [L, L]\n",
    "        pos_decay = torch.exp(-self.pos_lambda * dist).unsqueeze(0)    # [1, L, L]\n",
    "        scores = scores * pos_decay\n",
    "\n",
    "        scores = torch.clamp(scores, min=-1e3, max=1e3)\n",
    "        scores = scores.masked_fill(pad_mask, float('-inf'))\n",
    "\n",
    "        # Debug range\n",
    "        finite = scores[~pad_mask]\n",
    "        # if finite.numel() > 0:\n",
    "        #     print(f\"Диапазон scores до softmax: min={finite.min().item():.3e}, max={finite.max().item():.3e}\")\n",
    "\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        if not torch.isfinite(attn).all():\n",
    "            print(\"NaN/Inf в attn после softmax:\", torch.isnan(attn).sum().item(), torch.isinf(attn).sum().item())\n",
    "        \n",
    "        attn = torch.nan_to_num(attn, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.bmm(attn, v)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:33:27.915764Z",
     "iopub.status.busy": "2025-06-24T21:33:27.915568Z",
     "iopub.status.idle": "2025-06-24T21:33:27.933498Z",
     "shell.execute_reply": "2025-06-24T21:33:27.932838Z",
     "shell.execute_reply.started": "2025-06-24T21:33:27.915749Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HeteroGNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 feedback_types: list,\n",
    "                 emb_dim: int = 32,\n",
    "                 hidden_dim: int = 16,\n",
    "                 dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.feedback_types = feedback_types\n",
    "        # Embeddings\n",
    "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
    "        # 0 - padding, все остальное - item_id\n",
    "        self.item_emb = nn.Embedding(num_items + 1, emb_dim, padding_idx=0)  \n",
    "        self.fb_emb = nn.ModuleDict({ft: nn.Embedding(num_users, emb_dim)\n",
    "                                     for ft in feedback_types})\n",
    "        # LayerNorms\n",
    "        types = ['user', 'item'] + feedback_types\n",
    "        self.norm1 = nn.ModuleDict({t: nn.LayerNorm(hidden_dim) for t in types})\n",
    "        self.norm2 = nn.ModuleDict({t: nn.LayerNorm(emb_dim) for t in types})\n",
    "        # Convolutions\n",
    "        conv1, conv2 = {}, {}\n",
    "        for ft in feedback_types:\n",
    "            conv1[('item', f'to_feedback_{ft}', ft)] = SAGEConv(emb_dim, hidden_dim)\n",
    "            conv1[(ft, f'feedback_to_item_{ft}', 'item')] = SAGEConv(emb_dim, hidden_dim)\n",
    "            conv1[(ft, f'to_user_{ft}', 'user')] = SAGEConv(emb_dim, hidden_dim)\n",
    "            conv2[('item', f'to_feedback_{ft}', ft)] = SAGEConv(hidden_dim, emb_dim)\n",
    "            conv2[(ft, f'feedback_to_item_{ft}', 'item')] = SAGEConv(hidden_dim, emb_dim)\n",
    "            conv2[(ft, f'to_user_{ft}', 'user')] = SAGEConv(hidden_dim, emb_dim)\n",
    "        # user-user\n",
    "        conv1[('user', 'interacts', 'user')] = SAGEConv(emb_dim, hidden_dim)\n",
    "        conv2[('user', 'interacts', 'user')] = SAGEConv(hidden_dim, emb_dim)\n",
    "        self.conv1 = HeteroConv(conv1, aggr='mean')\n",
    "        self.conv2 = HeteroConv(conv2, aggr='mean')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Node features\n",
    "        x = {\n",
    "            'user': self.user_emb(data['user'].node_id),\n",
    "            'item': self.item_emb(data['item'].node_id)\n",
    "        }\n",
    "        for ft in self.feedback_types:\n",
    "            x[ft] = self.fb_emb[ft](data[ft].node_id)\n",
    "            \n",
    "        h1 = self.conv1(x, data.edge_index_dict)\n",
    "        h1 = {t: self.dropout(F.leaky_relu(self.norm1[t](h1[t]))) for t in h1}\n",
    "        \n",
    "        h2 = self.conv2(h1, data.edge_index_dict)\n",
    "        out = {t: self.norm2[t](h2[t]) for t in h2}\n",
    "        return out['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:33:27.935293Z",
     "iopub.status.busy": "2025-06-24T21:33:27.935082Z",
     "iopub.status.idle": "2025-06-24T21:33:27.950195Z",
     "shell.execute_reply": "2025-06-24T21:33:27.949506Z",
     "shell.execute_reply.started": "2025-06-24T21:33:27.935279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 feedback_types: list,\n",
    "                 d_model: int = 32,\n",
    "                 n_head: int = 4,\n",
    "                 window_size: int = 50,\n",
    "                 decay: float = 1.0,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        # Static graph encoder\n",
    "        self.gnn = HeteroGNN(num_users, num_items, feedback_types,\n",
    "                             emb_dim=d_model, hidden_dim=d_model//2,\n",
    "                             dropout=dropout)\n",
    "        # Inlined THP sequence encoder\n",
    "        self.thp = THPEncoder(d_model=d_model,\n",
    "                              n_head=n_head,\n",
    "                              window_size=window_size,\n",
    "                              decay=decay,\n",
    "                              dropout=dropout)\n",
    "\n",
    "    def forward(self, data, seq_ids, seq_times, seq_mask, batch_users):\n",
    "        # Static graph embeddings\n",
    "        user_embs = self.gnn(data)          # [num_users, d_model]\n",
    "        # Sequence encoding\n",
    "        seq_item_emb = self.gnn.item_emb(seq_ids)  # [B, L, d_model]\n",
    "        attn_out = self.thp(seq_item_emb, seq_times, seq_mask)\n",
    "        seq_rep = attn_out[:, -1, :]        # [B, d_model]\n",
    "        # Get static user embeddings\n",
    "        gnn_rep = user_embs[batch_users]   # [B, d_model]\n",
    "        # Updated user embedding\n",
    "        updated_user_emb = seq_rep + gnn_rep\n",
    "        return updated_user_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:33:27.951187Z",
     "iopub.status.busy": "2025-06-24T21:33:27.950936Z",
     "iopub.status.idle": "2025-06-24T21:33:28.097164Z",
     "shell.execute_reply": "2025-06-24T21:33:28.096628Z",
     "shell.execute_reply.started": "2025-06-24T21:33:27.951147Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_users = data['user'].node_id.shape[0]      \n",
    "num_items = data['item'].node_id.shape[0]      \n",
    "feedback_types = train['target'].unique().tolist()\n",
    "data.user_idx = data['user'].node_id\n",
    "d_model = hyperparameters['thp_dmodel']             \n",
    "n_head = hyperparameters['thp_n_head']          \n",
    "window_size = hyperparameters['thp_window_size']     \n",
    "decay = hyperparameters['thp_decay']         \n",
    "dropout = hyperparameters['thp_dropout']           \n",
    "\n",
    "model = Model(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    feedback_types=feedback_types,\n",
    "    d_model=d_model,\n",
    "    n_head=n_head,\n",
    "    window_size=window_size,\n",
    "    decay=decay,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:33:28.098138Z",
     "iopub.status.busy": "2025-06-24T21:33:28.097893Z",
     "iopub.status.idle": "2025-06-24T21:33:28.102927Z",
     "shell.execute_reply": "2025-06-24T21:33:28.102298Z",
     "shell.execute_reply.started": "2025-06-24T21:33:28.098116Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12096"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:33:28.103828Z",
     "iopub.status.busy": "2025-06-24T21:33:28.103546Z",
     "iopub.status.idle": "2025-06-24T21:33:28.860157Z",
     "shell.execute_reply": "2025-06-24T21:33:28.859561Z",
     "shell.execute_reply.started": "2025-06-24T21:33:28.103802Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THPEncoder output shape: torch.Size([32, 101, 64])\n"
     ]
    }
   ],
   "source": [
    "B = 32\n",
    "seq_ids_batch   = seq_ids[:B]     # [B, L]\n",
    "seq_times_batch = seq_times[:B]   # [B, L]\n",
    "seq_mask_batch  = seq_mask[:B]    # [B, L]\n",
    "\n",
    "item_emb = model.gnn.item_emb \n",
    "d_model = item_emb.embedding_dim\n",
    "\n",
    "# Получаем seq_item_emb: [B, L, D]\n",
    "seq_item_emb = item_emb(seq_ids_batch)\n",
    "\n",
    "thp_encoder = THPEncoder(\n",
    "    d_model=d_model,\n",
    "    n_head=4,\n",
    "    window_size=50,\n",
    "    decay=1.0,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "thp_encoder.to(device)\n",
    "seq_item_emb   = seq_item_emb.to(device)\n",
    "seq_times_batch= seq_times_batch.to(device)\n",
    "seq_mask_batch = seq_mask_batch.to(device)\n",
    "\n",
    "out = thp_encoder(\n",
    "    emb=seq_item_emb,\n",
    "    times=seq_times_batch,\n",
    "    mask=seq_mask_batch\n",
    ")\n",
    "\n",
    "print(\"THPEncoder output shape:\", out.shape)  # ожидаем [B, L, D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:33:28.861144Z",
     "iopub.status.busy": "2025-06-24T21:33:28.860940Z",
     "iopub.status.idle": "2025-06-24T21:33:28.978969Z",
     "shell.execute_reply": "2025-06-24T21:33:28.978322Z",
     "shell.execute_reply.started": "2025-06-24T21:33:28.861121Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated user embeddings: torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "B = 32\n",
    "batch_seq_ids   = seq_ids[:B].to(device)    # [B, L]\n",
    "batch_seq_times = seq_times[:B].to(device)  # [B, L]\n",
    "batch_seq_mask  = seq_mask[:B].to(device)   # [B, L]\n",
    "\n",
    "# data.user_idx = data['user'].node_id[:B]\n",
    "batch_users = data.user_idx[:B].to(device)\n",
    "model.to(device)\n",
    "data.to(device)\n",
    "\n",
    "updated_user_emb = model(\n",
    "    data=data,\n",
    "    seq_ids=batch_seq_ids,\n",
    "    seq_times=batch_seq_times,\n",
    "    seq_mask=batch_seq_mask,\n",
    "    batch_users=batch_users\n",
    ")  # [B, d_model]\n",
    "\n",
    "print(\"Updated user embeddings:\", updated_user_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:33:28.979935Z",
     "iopub.status.busy": "2025-06-24T21:33:28.979687Z",
     "iopub.status.idle": "2025-06-24T21:33:28.987745Z",
     "shell.execute_reply": "2025-06-24T21:33:28.987163Z",
     "shell.execute_reply.started": "2025-06-24T21:33:28.979913Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12095, 1, 12095)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.item_id.nunique(), train.item_id.min(), train.item_id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:33:28.990128Z",
     "iopub.status.busy": "2025-06-24T21:33:28.989664Z",
     "iopub.status.idle": "2025-06-24T21:33:29.010344Z",
     "shell.execute_reply": "2025-06-24T21:33:29.009557Z",
     "shell.execute_reply.started": "2025-06-24T21:33:28.990110Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (gnn): HeteroGNN(\n",
       "    (user_emb): Embedding(22363, 64)\n",
       "    (item_emb): Embedding(12097, 64, padding_idx=0)\n",
       "    (fb_emb): ModuleDict(\n",
       "      (implicit_negative): Embedding(22363, 64)\n",
       "      (expliсit_negative): Embedding(22363, 64)\n",
       "      (explicit_positive): Embedding(22363, 64)\n",
       "      (implicit_positive): Embedding(22363, 64)\n",
       "    )\n",
       "    (norm1): ModuleDict(\n",
       "      (user): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (item): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_negative): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (expliсit_negative): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (explicit_positive): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_positive): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (norm2): ModuleDict(\n",
       "      (user): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (item): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_negative): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (expliсit_negative): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (explicit_positive): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_positive): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (conv1): HeteroConv(num_relations=13)\n",
       "    (conv2): HeteroConv(num_relations=13)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (thp): THPEncoder(\n",
       "    (pos_emb): Embedding(101, 64)\n",
       "    (time_emb): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (heads): ModuleList(\n",
       "      (0-3): 4 x _THPHead(\n",
       "        (linear_v): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (input_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ffn): Sequential(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=64, out_features=256, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (4): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (final_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:33:29.011336Z",
     "iopub.status.busy": "2025-06-24T21:33:29.011053Z",
     "iopub.status.idle": "2025-06-24T21:33:29.350813Z",
     "shell.execute_reply": "2025-06-24T21:33:29.350142Z",
     "shell.execute_reply.started": "2025-06-24T21:33:29.011316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = test[['user_id', 'item_id']]\n",
    "interactions = test_df.rename(columns={\n",
    "    'user_id': Columns.User,\n",
    "    'item_id': Columns.Item,\n",
    "})\n",
    "\n",
    "viewed_items = train.groupby(\"user_id\")[\"item_id\"].agg(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:33:29.351786Z",
     "iopub.status.busy": "2025-06-24T21:33:29.351508Z",
     "iopub.status.idle": "2025-06-24T21:33:29.356987Z",
     "shell.execute_reply": "2025-06-24T21:33:29.356350Z",
     "shell.execute_reply.started": "2025-06-24T21:33:29.351766Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLS_ID == model.gnn.item_emb.weight.shape[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:37:28.388673Z",
     "iopub.status.busy": "2025-06-24T21:37:28.388362Z",
     "iopub.status.idle": "2025-06-24T21:37:28.398906Z",
     "shell.execute_reply": "2025-06-24T21:37:28.398211Z",
     "shell.execute_reply.started": "2025-06-24T21:37:28.388654Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, train_data, seq_train_data,\n",
    "             test_batch_size, top_k,\n",
    "             viewed_items, interactions,\n",
    "             device, test_step):\n",
    "    \"\"\"\n",
    "    Оцениваем модель по всем пользователям:\n",
    "    - строим топ-K рекомендации\n",
    "    - фильтруем уже просмотренные\n",
    "    - считаем recall@K, precision@K, map@K\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    seq_ids, event_type, seq_times, seq_mask = seq_train_data\n",
    "    num_users = seq_ids.size(0)\n",
    "    test_top_k = top_k * 150\n",
    "\n",
    "    item_emb = model.gnn.item_emb.weight\n",
    "    num_items = item_emb.shape[0]\n",
    "    item_emb_t = item_emb.t().detach()\n",
    "    del item_emb\n",
    "    gc.collect()\n",
    "\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_users, test_batch_size):\n",
    "            end = min(i + test_batch_size, num_users)\n",
    "            batch_users = torch.arange(i, end).to(device)\n",
    "            s_ids   = seq_ids[i:end].to(device)\n",
    "            s_times = seq_times[i:end].to(device)\n",
    "            s_mask  = seq_mask[i:end].to(device)\n",
    "            user_e = model(\n",
    "                data=train_data.to(device),\n",
    "                seq_ids=s_ids,\n",
    "                seq_times=s_times,\n",
    "                seq_mask=s_mask,\n",
    "                batch_users=batch_users\n",
    "            )\n",
    "            rating = torch.mm(user_e.detach(), item_emb_t)\n",
    "            _, topk = torch.topk(rating, k=test_top_k, dim=1)\n",
    "            all_scores.append(topk)\n",
    "\n",
    "            del user_e, rating\n",
    "            gc.collect()\n",
    "    all_scores = torch.cat(all_scores, dim=0).cpu().numpy()\n",
    "\n",
    "    users_list, items, ranks = [], [], []\n",
    "    for u in range(num_users):\n",
    "        seen = viewed_items.get(u, set())\n",
    "        recs = all_scores[u]\n",
    "        mask = (\n",
    "            (~np.isin(recs, list(seen)))   \n",
    "            & (recs != 0)                  \n",
    "            & (recs != num_items - 1)     \n",
    "            )\n",
    "        filtered = recs[mask][:top_k]\n",
    "        for rank, it in enumerate(filtered, 1):\n",
    "            users_list.append(u)\n",
    "            items.append(int(it))\n",
    "            ranks.append(rank)\n",
    "    reco_df = pd.DataFrame({\n",
    "        'user_id': users_list,\n",
    "        'item_id': items,\n",
    "        'rank': ranks\n",
    "    })\n",
    "\n",
    "    metrics = {\n",
    "        f'map@{top_k}': MAP(k=top_k),\n",
    "        f'precision@{top_k}': Precision(k=top_k),\n",
    "        f'recall@{top_k}': Recall(k=top_k),\n",
    "        f'ndcg@{top_k}': NDCG(k=top_k)\n",
    "    }\n",
    "    results = calc_metrics(metrics=metrics,\n",
    "                           reco=reco_df,\n",
    "                           interactions=interactions)\n",
    "    print(f\"Step {test_step} — Test metrics:\")\n",
    "    for name, val in results.items():\n",
    "        print(f\"  {name}: {val:.9f}\")\n",
    "        experiment.log_metric(f\"Test {name} vs step\", val, step=test_step)\n",
    "    del all_scores\n",
    "    gc.collect()\n",
    "\n",
    "    model.to(device)\n",
    "    train_data.to(device)\n",
    "    model.train()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T23:15:45.795854Z",
     "iopub.status.busy": "2025-06-24T23:15:45.795117Z",
     "iopub.status.idle": "2025-06-24T23:15:45.811072Z",
     "shell.execute_reply": "2025-06-24T23:15:45.810278Z",
     "shell.execute_reply.started": "2025-06-24T23:15:45.795822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model: HeteroGNN,\n",
    "                train_data: HeteroData,\n",
    "                seq_train_data: tuple,\n",
    "                edge_type: tuple,\n",
    "                num_epochs: int = 10,\n",
    "                lr: float = 1e-3,\n",
    "                batch_size: int = 1024,\n",
    "                device: str = None,\n",
    "                print_every: int = 100,\n",
    "                test_every: int = 500,\n",
    "                top_k: int = 10,\n",
    "                test_batch_size=2048,\n",
    "                scheduler_step_size: int = 1,\n",
    "                scheduler_gamma: float = 0.9) -> Model:\n",
    "    seq_ids, event_type, seq_times, seq_mask = seq_train_data\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    train_data = train_data.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma)\n",
    "\n",
    "    if isinstance(edge_type, list):\n",
    "        src_list, dst_list = [], []\n",
    "        for et in edge_type:\n",
    "            s, d = train_data[et].edge_index\n",
    "            src_list.append(s)\n",
    "            dst_list.append(d)\n",
    "        src = torch.cat(src_list, dim=0)\n",
    "        dst = torch.cat(dst_list, dim=0)\n",
    "    else:\n",
    "        src, dst = train_data[edge_type].edge_index\n",
    "    \n",
    "    num_train = src.size(0)\n",
    "    test_top_k = top_k * 150\n",
    "    total_steps = 5971\n",
    "    \n",
    "    print(f\"Num of training examples: {num_train}\")\n",
    "    for epoch in range(201, 1001):\n",
    "        model.train()\n",
    "        perm = torch.randperm(num_train, device=device)\n",
    "        total_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        running_steps = 0\n",
    "        step = 0\n",
    "\n",
    "        for i in range(0, num_train, batch_size):\n",
    "            idx = perm[i:i + batch_size]\n",
    "            users = dst[idx]\n",
    "            cpu_users = users.to('cpu')\n",
    "\n",
    "            seq_ids_batch = seq_ids[cpu_users].to(device)\n",
    "            seq_times_batch = seq_times[cpu_users].to(device)\n",
    "            seq_mask_batch = seq_mask[cpu_users].to(device)\n",
    "            \n",
    "            pos_items = src[idx]\n",
    "            neg_items = torch.randint(1, model.gnn.item_emb.num_embeddings - 1,\n",
    "                                      size=pos_items.size(), device=device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            user_embs = model(data=train_data, \n",
    "                              seq_ids=seq_ids_batch,\n",
    "                              seq_times=seq_times_batch,\n",
    "                              seq_mask=seq_mask_batch,\n",
    "                              batch_users=users)\n",
    "            \n",
    "            pos_emb = model.gnn.item_emb(pos_items)\n",
    "            neg_emb = model.gnn.item_emb(neg_items)\n",
    "            pos_score = (user_embs * pos_emb).sum(dim=1)\n",
    "            neg_score = (user_embs * neg_emb).sum(dim=1)\n",
    "            diff = pos_score - neg_score\n",
    "            diff = torch.clamp(diff, -10.0, 10.0)\n",
    "            loss = -torch.log(torch.sigmoid(diff) + 1e-15).mean()\n",
    "            \n",
    "            nan_mask = torch.isnan(diff)            \n",
    "            if nan_mask.any():\n",
    "                idxs = torch.nonzero(nan_mask).squeeze()\n",
    "                print(f\"!!! FOUND {nan_mask.sum().item()} NaN(s) in diff at positions: {idxs.tolist()}\")\n",
    "\n",
    "            # with torch.autograd.detect_anomaly():\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            running_loss += loss.item()\n",
    "            running_steps += 1\n",
    "            step += 1\n",
    "\n",
    "            experiment.log_metric('Train Loss vs step', loss.item(), step=total_steps)\n",
    "            \n",
    "            if step % print_every == 0 or step == 1:\n",
    "                avg_loss = running_loss / running_steps\n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                d = diff.detach().cpu()\n",
    "                print(f\"Epoch {epoch}, Step {step}, LR: {current_lr:.6f}, Current Loss: {loss.item():.4f}, Avg Loss: {avg_loss:.4f}\")\n",
    "                print(f\"Diff stats — min: {d.min():.4f}, max: {d.max():.4f}, mean: {d.mean():.4f}, std: {d.std():.4f}\")\n",
    "                print()\n",
    "\n",
    "                experiment.log_metric('Diff stats (mean) vs step', d.mean(), step=total_steps)\n",
    "                experiment.log_metric('Diff stats (std) vs step', d.std(), step=total_steps)\n",
    "\n",
    "            del user_embs, pos_emb, neg_emb, pos_score, neg_score,\\\n",
    "            seq_ids_batch, seq_times_batch, seq_mask_batch\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            scheduler.step()\n",
    "            \n",
    "            if step % test_every == 0 or step == 1:\n",
    "                evaluate(model, train_data, seq_train_data,\n",
    "                         test_batch_size, top_k,\n",
    "                         viewed_items, interactions,\n",
    "                         device, test_step=total_steps)\n",
    "            total_steps += 1\n",
    "        epoch_loss = total_loss / num_train\n",
    "        experiment.log_metric(f'Train Loss vs epoch', epoch_loss, epoch=epoch)\n",
    "        print(f\"Epoch {epoch} completed, Train Loss: {epoch_loss:.6f}\")\n",
    "        print()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:37:47.281833Z",
     "iopub.status.busy": "2025-06-24T21:37:47.281218Z",
     "iopub.status.idle": "2025-06-24T21:37:47.599154Z",
     "shell.execute_reply": "2025-06-24T21:37:47.598568Z",
     "shell.execute_reply.started": "2025-06-24T21:37:47.281812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "experiment.log_parameters(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:37:47.772401Z",
     "iopub.status.busy": "2025-06-24T21:37:47.771812Z",
     "iopub.status.idle": "2025-06-24T21:37:47.775805Z",
     "shell.execute_reply": "2025-06-24T21:37:47.775087Z",
     "shell.execute_reply.started": "2025-06-24T21:37:47.772367Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-24T21:37:50.158886Z",
     "iopub.status.busy": "2025-06-24T21:37:50.158595Z",
     "iopub.status.idle": "2025-06-24T23:12:23.137575Z",
     "shell.execute_reply": "2025-06-24T23:12:23.136854Z",
     "shell.execute_reply.started": "2025-06-24T21:37:50.158865Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training examples: 121468\n",
      "Epoch 1, Step 1, LR: 0.001000, Current Loss: 3.8860, Avg Loss: 3.8860\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: -0.1272, std: 8.2312\n",
      "\n",
      "Step 0 — Test metrics:\n",
      "  precision@10: 0.001343706\n",
      "  recall@10: 0.001343706\n",
      "  ndcg@10: 0.001328338\n",
      "  map@10: 0.000382382\n",
      "Epoch 1, Step 20, LR: 0.001000, Current Loss: 3.0869, Avg Loss: 3.5106\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 0.1304, std: 7.0613\n",
      "\n",
      "Epoch 1 completed, Train Loss: 0.000802\n",
      "\n",
      "Epoch 2, Step 1, LR: 0.001000, Current Loss: 2.3224, Avg Loss: 2.3224\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 0.4636, std: 5.8637\n",
      "\n",
      "Step 30 — Test metrics:\n",
      "  precision@10: 0.000730787\n",
      "  recall@10: 0.000736681\n",
      "  ndcg@10: 0.000715219\n",
      "  map@10: 0.000205316\n",
      "Epoch 2, Step 20, LR: 0.001000, Current Loss: 1.4343, Avg Loss: 1.8116\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 0.4945, std: 3.7833\n",
      "\n",
      "Epoch 2 completed, Train Loss: 0.000405\n",
      "\n",
      "Epoch 3, Step 1, LR: 0.001000, Current Loss: 1.2215, Avg Loss: 1.2215\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 0.4611, std: 3.1266\n",
      "\n",
      "Step 60 — Test metrics:\n",
      "  precision@10: 0.001013673\n",
      "  recall@10: 0.001013673\n",
      "  ndcg@10: 0.000939261\n",
      "  map@10: 0.000257123\n",
      "Epoch 3, Step 20, LR: 0.001000, Current Loss: 0.9675, Avg Loss: 1.0358\n",
      "Diff stats — min: -7.9840, max: 9.6336, mean: 0.5069, std: 2.4409\n",
      "\n",
      "Epoch 3 completed, Train Loss: 0.000243\n",
      "\n",
      "Epoch 4, Step 1, LR: 0.001000, Current Loss: 0.8524, Avg Loss: 0.8524\n",
      "Diff stats — min: -8.1977, max: 9.7249, mean: 0.6116, std: 2.2276\n",
      "\n",
      "Step 90 — Test metrics:\n",
      "  precision@10: 0.001060820\n",
      "  recall@10: 0.001060820\n",
      "  ndcg@10: 0.001177384\n",
      "  map@10: 0.000379192\n",
      "Epoch 4, Step 20, LR: 0.001000, Current Loss: 0.7423, Avg Loss: 0.7937\n",
      "Diff stats — min: -5.9313, max: 8.4169, mean: 0.6923, std: 1.9590\n",
      "\n",
      "Epoch 4 completed, Train Loss: 0.000191\n",
      "\n",
      "Epoch 5, Step 1, LR: 0.001000, Current Loss: 0.7164, Avg Loss: 0.7164\n",
      "Diff stats — min: -5.8064, max: 8.8918, mean: 0.6912, std: 1.8698\n",
      "\n",
      "Step 120 — Test metrics:\n",
      "  precision@10: 0.001107968\n",
      "  recall@10: 0.001113861\n",
      "  ndcg@10: 0.001097164\n",
      "  map@10: 0.000320183\n",
      "Epoch 5, Step 20, LR: 0.001000, Current Loss: 0.6768, Avg Loss: 0.6843\n",
      "Diff stats — min: -5.8554, max: 7.4071, mean: 0.6768, std: 1.7109\n",
      "\n",
      "Epoch 5 completed, Train Loss: 0.000166\n",
      "\n",
      "Epoch 6, Step 1, LR: 0.000980, Current Loss: 0.6286, Avg Loss: 0.6286\n",
      "Diff stats — min: -5.5423, max: 7.0107, mean: 0.7785, std: 1.6649\n",
      "\n",
      "Step 150 — Test metrics:\n",
      "  precision@10: 0.001155116\n",
      "  recall@10: 0.001155116\n",
      "  ndcg@10: 0.001146948\n",
      "  map@10: 0.000334523\n",
      "Epoch 6, Step 20, LR: 0.000980, Current Loss: 0.6012, Avg Loss: 0.6149\n",
      "Diff stats — min: -5.8564, max: 8.5153, mean: 0.8554, std: 1.6763\n",
      "\n",
      "Epoch 6 completed, Train Loss: 0.000150\n",
      "\n",
      "Epoch 7, Step 1, LR: 0.000980, Current Loss: 0.5874, Avg Loss: 0.5874\n",
      "Diff stats — min: -5.9532, max: 6.6223, mean: 0.8402, std: 1.5935\n",
      "\n",
      "Step 180 — Test metrics:\n",
      "  precision@10: 0.001155116\n",
      "  recall@10: 0.001155116\n",
      "  ndcg@10: 0.001095078\n",
      "  map@10: 0.000307544\n",
      "Epoch 7, Step 20, LR: 0.000980, Current Loss: 0.5638, Avg Loss: 0.5659\n",
      "Diff stats — min: -4.2875, max: 7.4234, mean: 0.8834, std: 1.5644\n",
      "\n",
      "Epoch 7 completed, Train Loss: 0.000138\n",
      "\n",
      "Epoch 8, Step 1, LR: 0.000980, Current Loss: 0.5178, Avg Loss: 0.5178\n",
      "Diff stats — min: -5.2273, max: 7.6560, mean: 1.0066, std: 1.5509\n",
      "\n",
      "Step 210 — Test metrics:\n",
      "  precision@10: 0.000966525\n",
      "  recall@10: 0.000972419\n",
      "  ndcg@10: 0.000949831\n",
      "  map@10: 0.000271679\n",
      "Epoch 8, Step 20, LR: 0.000980, Current Loss: 0.4964, Avg Loss: 0.5161\n",
      "Diff stats — min: -4.9013, max: 7.6541, mean: 1.0737, std: 1.5601\n",
      "\n",
      "Epoch 8 completed, Train Loss: 0.000126\n",
      "\n",
      "Epoch 9, Step 1, LR: 0.000980, Current Loss: 0.4972, Avg Loss: 0.4972\n",
      "Diff stats — min: -5.2225, max: 7.9932, mean: 1.0822, std: 1.5650\n",
      "\n",
      "Step 240 — Test metrics:\n",
      "  precision@10: 0.001084394\n",
      "  recall@10: 0.001090288\n",
      "  ndcg@10: 0.001085740\n",
      "  map@10: 0.000321371\n",
      "Epoch 9, Step 20, LR: 0.000980, Current Loss: 0.4741, Avg Loss: 0.4868\n",
      "Diff stats — min: -4.1138, max: 7.9825, mean: 1.1594, std: 1.5672\n",
      "\n",
      "Epoch 9 completed, Train Loss: 0.000119\n",
      "\n",
      "Epoch 10, Step 1, LR: 0.000980, Current Loss: 0.4555, Avg Loss: 0.4555\n",
      "Diff stats — min: -3.8017, max: 8.1275, mean: 1.2265, std: 1.5802\n",
      "\n",
      "Step 270 — Test metrics:\n",
      "  precision@10: 0.001155116\n",
      "  recall@10: 0.001161009\n",
      "  ndcg@10: 0.001104373\n",
      "  map@10: 0.000310033\n",
      "Epoch 10, Step 20, LR: 0.000980, Current Loss: 0.4569, Avg Loss: 0.4539\n",
      "Diff stats — min: -6.3963, max: 7.3961, mean: 1.2691, std: 1.6431\n",
      "\n",
      "Epoch 10 completed, Train Loss: 0.000111\n",
      "\n",
      "Epoch 11, Step 1, LR: 0.000960, Current Loss: 0.4427, Avg Loss: 0.4427\n",
      "Diff stats — min: -4.0598, max: 10.0000, mean: 1.3087, std: 1.6449\n",
      "\n",
      "Step 300 — Test metrics:\n",
      "  precision@10: 0.001013673\n",
      "  recall@10: 0.001019566\n",
      "  ndcg@10: 0.001075497\n",
      "  map@10: 0.000336918\n",
      "Epoch 11, Step 20, LR: 0.000960, Current Loss: 0.4245, Avg Loss: 0.4326\n",
      "Diff stats — min: -5.7861, max: 9.1688, mean: 1.4370, std: 1.7193\n",
      "\n",
      "Epoch 11 completed, Train Loss: 0.000106\n",
      "\n",
      "Epoch 12, Step 1, LR: 0.000960, Current Loss: 0.4099, Avg Loss: 0.4099\n",
      "Diff stats — min: -4.2013, max: 7.9796, mean: 1.4836, std: 1.7081\n",
      "\n",
      "Step 330 — Test metrics:\n",
      "  precision@10: 0.001107968\n",
      "  recall@10: 0.001113861\n",
      "  ndcg@10: 0.001158854\n",
      "  map@10: 0.000357788\n",
      "Epoch 12, Step 20, LR: 0.000960, Current Loss: 0.4047, Avg Loss: 0.4102\n",
      "Diff stats — min: -5.5980, max: 9.0997, mean: 1.5504, std: 1.7570\n",
      "\n",
      "Epoch 12 completed, Train Loss: 0.000101\n",
      "\n",
      "Epoch 13, Step 1, LR: 0.000960, Current Loss: 0.3932, Avg Loss: 0.3932\n",
      "Diff stats — min: -5.9339, max: 10.0000, mean: 1.5958, std: 1.7723\n",
      "\n",
      "Step 360 — Test metrics:\n",
      "  precision@10: 0.001202263\n",
      "  recall@10: 0.001208157\n",
      "  ndcg@10: 0.001285582\n",
      "  map@10: 0.000402663\n",
      "Epoch 13, Step 20, LR: 0.000960, Current Loss: 0.3923, Avg Loss: 0.3942\n",
      "Diff stats — min: -4.2098, max: 9.2317, mean: 1.6012, std: 1.7695\n",
      "\n",
      "Epoch 13 completed, Train Loss: 0.000096\n",
      "\n",
      "Epoch 14, Step 1, LR: 0.000960, Current Loss: 0.3883, Avg Loss: 0.3883\n",
      "Diff stats — min: -4.9894, max: 10.0000, mean: 1.6810, std: 1.8343\n",
      "\n",
      "Step 390 — Test metrics:\n",
      "  precision@10: 0.001084394\n",
      "  recall@10: 0.001090288\n",
      "  ndcg@10: 0.001174676\n",
      "  map@10: 0.000372129\n",
      "Epoch 14, Step 20, LR: 0.000960, Current Loss: 0.3750, Avg Loss: 0.3801\n",
      "Diff stats — min: -4.9532, max: 9.2985, mean: 1.7672, std: 1.8827\n",
      "\n",
      "Epoch 14 completed, Train Loss: 0.000093\n",
      "\n",
      "Epoch 15, Step 1, LR: 0.000960, Current Loss: 0.3687, Avg Loss: 0.3687\n",
      "Diff stats — min: -5.3224, max: 9.7952, mean: 1.7678, std: 1.8636\n",
      "\n",
      "Step 420 — Test metrics:\n",
      "  precision@10: 0.001202263\n",
      "  recall@10: 0.001208157\n",
      "  ndcg@10: 0.001206059\n",
      "  map@10: 0.000356666\n",
      "Epoch 15, Step 20, LR: 0.000960, Current Loss: 0.3640, Avg Loss: 0.3576\n",
      "Diff stats — min: -5.4034, max: 10.0000, mean: 1.8474, std: 1.9265\n",
      "\n",
      "Epoch 15 completed, Train Loss: 0.000089\n",
      "\n",
      "Epoch 16, Step 1, LR: 0.000941, Current Loss: 0.3613, Avg Loss: 0.3613\n",
      "Diff stats — min: -5.4775, max: 10.0000, mean: 1.8969, std: 1.9502\n",
      "\n",
      "Step 450 — Test metrics:\n",
      "  precision@10: 0.001131542\n",
      "  recall@10: 0.001137435\n",
      "  ndcg@10: 0.001122905\n",
      "  map@10: 0.000324832\n",
      "Epoch 16, Step 20, LR: 0.000941, Current Loss: 0.3468, Avg Loss: 0.3554\n",
      "Diff stats — min: -4.4979, max: 10.0000, mean: 1.9953, std: 1.9970\n",
      "\n",
      "Epoch 16 completed, Train Loss: 0.000087\n",
      "\n",
      "Epoch 17, Step 1, LR: 0.000941, Current Loss: 0.3451, Avg Loss: 0.3451\n",
      "Diff stats — min: -5.3261, max: 9.7353, mean: 2.0120, std: 1.9873\n",
      "\n",
      "Step 480 — Test metrics:\n",
      "  precision@10: 0.001296558\n",
      "  recall@10: 0.001296558\n",
      "  ndcg@10: 0.001257543\n",
      "  map@10: 0.000357639\n",
      "Epoch 17, Step 20, LR: 0.000941, Current Loss: 0.3269, Avg Loss: 0.3417\n",
      "Diff stats — min: -4.2988, max: 10.0000, mean: 2.0987, std: 1.9979\n",
      "\n",
      "Epoch 17 completed, Train Loss: 0.000085\n",
      "\n",
      "Epoch 18, Step 1, LR: 0.000941, Current Loss: 0.3356, Avg Loss: 0.3356\n",
      "Diff stats — min: -4.6966, max: 10.0000, mean: 2.0912, std: 2.0366\n",
      "\n",
      "Step 510 — Test metrics:\n",
      "  precision@10: 0.001202263\n",
      "  recall@10: 0.001202263\n",
      "  ndcg@10: 0.001246905\n",
      "  map@10: 0.000374486\n",
      "Epoch 18, Step 20, LR: 0.000941, Current Loss: 0.3267, Avg Loss: 0.3328\n",
      "Diff stats — min: -5.1957, max: 10.0000, mean: 2.1506, std: 2.0444\n",
      "\n",
      "Epoch 18 completed, Train Loss: 0.000082\n",
      "\n",
      "Epoch 19, Step 1, LR: 0.000941, Current Loss: 0.3307, Avg Loss: 0.3307\n",
      "Diff stats — min: -5.4253, max: 10.0000, mean: 2.1630, std: 2.0823\n",
      "\n",
      "Step 540 — Test metrics:\n",
      "  precision@10: 0.001084394\n",
      "  recall@10: 0.001084394\n",
      "  ndcg@10: 0.001121662\n",
      "  map@10: 0.000336329\n",
      "Epoch 19, Step 20, LR: 0.000941, Current Loss: 0.3163, Avg Loss: 0.3282\n",
      "Diff stats — min: -4.5186, max: 10.0000, mean: 2.2714, std: 2.1264\n",
      "\n",
      "Epoch 19 completed, Train Loss: 0.000081\n",
      "\n",
      "Epoch 20, Step 1, LR: 0.000941, Current Loss: 0.3139, Avg Loss: 0.3139\n",
      "Diff stats — min: -4.5176, max: 10.0000, mean: 2.3160, std: 2.1659\n",
      "\n",
      "Step 570 — Test metrics:\n",
      "  precision@10: 0.001225837\n",
      "  recall@10: 0.001225837\n",
      "  ndcg@10: 0.001211309\n",
      "  map@10: 0.000352409\n",
      "Epoch 20, Step 20, LR: 0.000941, Current Loss: 0.3172, Avg Loss: 0.3205\n",
      "Diff stats — min: -5.3154, max: 10.0000, mean: 2.3035, std: 2.1612\n",
      "\n",
      "Epoch 20 completed, Train Loss: 0.000079\n",
      "\n",
      "Epoch 21, Step 1, LR: 0.000922, Current Loss: 0.3267, Avg Loss: 0.3267\n",
      "Diff stats — min: -4.8982, max: 10.0000, mean: 2.2541, std: 2.1519\n",
      "\n",
      "Step 600 — Test metrics:\n",
      "  precision@10: 0.001131542\n",
      "  recall@10: 0.001137435\n",
      "  ndcg@10: 0.001122228\n",
      "  map@10: 0.000327383\n",
      "Epoch 21, Step 20, LR: 0.000922, Current Loss: 0.3158, Avg Loss: 0.3118\n",
      "Diff stats — min: -4.8088, max: 10.0000, mean: 2.3512, std: 2.2083\n",
      "\n",
      "Epoch 21 completed, Train Loss: 0.000077\n",
      "\n",
      "Epoch 22, Step 1, LR: 0.000922, Current Loss: 0.3047, Avg Loss: 0.3047\n",
      "Diff stats — min: -5.1703, max: 10.0000, mean: 2.3933, std: 2.1771\n",
      "\n",
      "Step 630 — Test metrics:\n",
      "  precision@10: 0.001107968\n",
      "  recall@10: 0.001113861\n",
      "  ndcg@10: 0.001140577\n",
      "  map@10: 0.000341988\n",
      "Epoch 22, Step 20, LR: 0.000922, Current Loss: 0.2971, Avg Loss: 0.3043\n",
      "Diff stats — min: -4.6067, max: 10.0000, mean: 2.4222, std: 2.1744\n",
      "\n",
      "Epoch 22 completed, Train Loss: 0.000075\n",
      "\n",
      "Epoch 23, Step 1, LR: 0.000922, Current Loss: 0.2979, Avg Loss: 0.2979\n",
      "Diff stats — min: -7.0967, max: 10.0000, mean: 2.5009, std: 2.2461\n",
      "\n",
      "Step 660 — Test metrics:\n",
      "  precision@10: 0.001037247\n",
      "  recall@10: 0.001043140\n",
      "  ndcg@10: 0.001048249\n",
      "  map@10: 0.000309836\n",
      "Epoch 23, Step 20, LR: 0.000922, Current Loss: 0.2885, Avg Loss: 0.3006\n",
      "Diff stats — min: -5.3812, max: 10.0000, mean: 2.5222, std: 2.2200\n",
      "\n",
      "Epoch 23 completed, Train Loss: 0.000074\n",
      "\n",
      "Epoch 24, Step 1, LR: 0.000922, Current Loss: 0.2936, Avg Loss: 0.2936\n",
      "Diff stats — min: -4.7509, max: 10.0000, mean: 2.5708, std: 2.3108\n",
      "\n",
      "Step 690 — Test metrics:\n",
      "  precision@10: 0.001084394\n",
      "  recall@10: 0.001090288\n",
      "  ndcg@10: 0.001117467\n",
      "  map@10: 0.000333850\n",
      "Epoch 24, Step 20, LR: 0.000922, Current Loss: 0.3088, Avg Loss: 0.2951\n",
      "Diff stats — min: -6.4437, max: 10.0000, mean: 2.5484, std: 2.3372\n",
      "\n",
      "Epoch 24 completed, Train Loss: 0.000073\n",
      "\n",
      "Epoch 25, Step 1, LR: 0.000922, Current Loss: 0.2752, Avg Loss: 0.2752\n",
      "Diff stats — min: -5.7790, max: 10.0000, mean: 2.6983, std: 2.3239\n",
      "\n",
      "Step 720 — Test metrics:\n",
      "  precision@10: 0.001343706\n",
      "  recall@10: 0.001343706\n",
      "  ndcg@10: 0.001330824\n",
      "  map@10: 0.000388752\n",
      "Epoch 25, Step 20, LR: 0.000922, Current Loss: 0.3019, Avg Loss: 0.2872\n",
      "Diff stats — min: -5.0763, max: 10.0000, mean: 2.6099, std: 2.3983\n",
      "\n",
      "Epoch 25 completed, Train Loss: 0.000071\n",
      "\n",
      "Epoch 26, Step 1, LR: 0.000904, Current Loss: 0.2754, Avg Loss: 0.2754\n",
      "Diff stats — min: -6.1618, max: 10.0000, mean: 2.7133, std: 2.3398\n",
      "\n",
      "Step 750 — Test metrics:\n",
      "  precision@10: 0.001320132\n",
      "  recall@10: 0.001326025\n",
      "  ndcg@10: 0.001399141\n",
      "  map@10: 0.000432551\n",
      "Epoch 26, Step 20, LR: 0.000904, Current Loss: 0.2760, Avg Loss: 0.2839\n",
      "Diff stats — min: -5.4619, max: 10.0000, mean: 2.7274, std: 2.3335\n",
      "\n",
      "Epoch 26 completed, Train Loss: 0.000070\n",
      "\n",
      "Epoch 27, Step 1, LR: 0.000904, Current Loss: 0.2784, Avg Loss: 0.2784\n",
      "Diff stats — min: -5.4187, max: 10.0000, mean: 2.7836, std: 2.4096\n",
      "\n",
      "Step 780 — Test metrics:\n",
      "  precision@10: 0.001390853\n",
      "  recall@10: 0.001390853\n",
      "  ndcg@10: 0.001390231\n",
      "  map@10: 0.000406227\n",
      "Epoch 27, Step 20, LR: 0.000904, Current Loss: 0.2883, Avg Loss: 0.2814\n",
      "Diff stats — min: -5.5957, max: 10.0000, mean: 2.7191, std: 2.3900\n",
      "\n",
      "Epoch 27 completed, Train Loss: 0.000069\n",
      "\n",
      "Epoch 28, Step 1, LR: 0.000904, Current Loss: 0.2744, Avg Loss: 0.2744\n",
      "Diff stats — min: -5.4144, max: 10.0000, mean: 2.8369, std: 2.4197\n",
      "\n",
      "Step 810 — Test metrics:\n",
      "  precision@10: 0.001225837\n",
      "  recall@10: 0.001225837\n",
      "  ndcg@10: 0.001159936\n",
      "  map@10: 0.000320763\n",
      "Epoch 28, Step 20, LR: 0.000904, Current Loss: 0.2807, Avg Loss: 0.2739\n",
      "Diff stats — min: -6.5221, max: 10.0000, mean: 2.8347, std: 2.4582\n",
      "\n",
      "Epoch 28 completed, Train Loss: 0.000068\n",
      "\n",
      "Epoch 29, Step 1, LR: 0.000904, Current Loss: 0.2676, Avg Loss: 0.2676\n",
      "Diff stats — min: -4.9075, max: 10.0000, mean: 2.8499, std: 2.4223\n",
      "\n",
      "Step 840 — Test metrics:\n",
      "  precision@10: 0.001202263\n",
      "  recall@10: 0.001202263\n",
      "  ndcg@10: 0.001095082\n",
      "  map@10: 0.000289237\n",
      "Epoch 29, Step 20, LR: 0.000904, Current Loss: 0.2773, Avg Loss: 0.2715\n",
      "Diff stats — min: -5.3268, max: 10.0000, mean: 2.8714, std: 2.4725\n",
      "\n",
      "Epoch 29 completed, Train Loss: 0.000067\n",
      "\n",
      "Epoch 30, Step 1, LR: 0.000904, Current Loss: 0.2674, Avg Loss: 0.2674\n",
      "Diff stats — min: -5.3495, max: 10.0000, mean: 2.9211, std: 2.4673\n",
      "\n",
      "Step 870 — Test metrics:\n",
      "  precision@10: 0.001343706\n",
      "  recall@10: 0.001343706\n",
      "  ndcg@10: 0.001353173\n",
      "  map@10: 0.000397424\n",
      "Epoch 30, Step 20, LR: 0.000904, Current Loss: 0.2653, Avg Loss: 0.2646\n",
      "Diff stats — min: -6.1645, max: 10.0000, mean: 2.9481, std: 2.4901\n",
      "\n",
      "Epoch 30 completed, Train Loss: 0.000065\n",
      "\n",
      "Epoch 31, Step 1, LR: 0.000886, Current Loss: 0.2811, Avg Loss: 0.2811\n",
      "Diff stats — min: -5.8986, max: 10.0000, mean: 2.9540, std: 2.5386\n",
      "\n",
      "Step 900 — Test metrics:\n",
      "  precision@10: 0.001438001\n",
      "  recall@10: 0.001438001\n",
      "  ndcg@10: 0.001348102\n",
      "  map@10: 0.000367882\n",
      "Epoch 31, Step 20, LR: 0.000886, Current Loss: 0.2539, Avg Loss: 0.2635\n",
      "Diff stats — min: -8.2423, max: 10.0000, mean: 3.0169, std: 2.4972\n",
      "\n",
      "Epoch 31 completed, Train Loss: 0.000065\n",
      "\n",
      "Epoch 32, Step 1, LR: 0.000886, Current Loss: 0.2526, Avg Loss: 0.2526\n",
      "Diff stats — min: -5.1834, max: 10.0000, mean: 3.0301, std: 2.4800\n",
      "\n",
      "Step 930 — Test metrics:\n",
      "  precision@10: 0.001438001\n",
      "  recall@10: 0.001438001\n",
      "  ndcg@10: 0.001381098\n",
      "  map@10: 0.000382990\n",
      "Epoch 32, Step 20, LR: 0.000886, Current Loss: 0.2465, Avg Loss: 0.2556\n",
      "Diff stats — min: -5.8990, max: 10.0000, mean: 3.0942, std: 2.5128\n",
      "\n",
      "Epoch 32 completed, Train Loss: 0.000063\n",
      "\n",
      "Epoch 33, Step 1, LR: 0.000886, Current Loss: 0.2411, Avg Loss: 0.2411\n",
      "Diff stats — min: -6.5352, max: 10.0000, mean: 3.1251, std: 2.4770\n",
      "\n",
      "Step 960 — Test metrics:\n",
      "  precision@10: 0.001579444\n",
      "  recall@10: 0.001579444\n",
      "  ndcg@10: 0.001651194\n",
      "  map@10: 0.000501083\n",
      "Epoch 33, Step 20, LR: 0.000886, Current Loss: 0.2453, Avg Loss: 0.2530\n",
      "Diff stats — min: -5.2176, max: 10.0000, mean: 3.1750, std: 2.5545\n",
      "\n",
      "Epoch 33 completed, Train Loss: 0.000062\n",
      "\n",
      "Epoch 34, Step 1, LR: 0.000886, Current Loss: 0.2377, Avg Loss: 0.2377\n",
      "Diff stats — min: -7.8087, max: 10.0000, mean: 3.1312, std: 2.4623\n",
      "\n",
      "Step 990 — Test metrics:\n",
      "  precision@10: 0.001555870\n",
      "  recall@10: 0.001555870\n",
      "  ndcg@10: 0.001522312\n",
      "  map@10: 0.000436003\n",
      "Epoch 34, Step 20, LR: 0.000886, Current Loss: 0.2508, Avg Loss: 0.2510\n",
      "Diff stats — min: -5.4325, max: 10.0000, mean: 3.1564, std: 2.5850\n",
      "\n",
      "Epoch 34 completed, Train Loss: 0.000062\n",
      "\n",
      "Epoch 35, Step 1, LR: 0.000886, Current Loss: 0.2593, Avg Loss: 0.2593\n",
      "Diff stats — min: -7.2122, max: 10.0000, mean: 3.1430, std: 2.6130\n",
      "\n",
      "Step 1020 — Test metrics:\n",
      "  precision@10: 0.001673739\n",
      "  recall@10: 0.001679632\n",
      "  ndcg@10: 0.001611833\n",
      "  map@10: 0.000454375\n",
      "Epoch 35, Step 20, LR: 0.000886, Current Loss: 0.2310, Avg Loss: 0.2458\n",
      "Diff stats — min: -5.9055, max: 10.0000, mean: 3.2352, std: 2.5298\n",
      "\n",
      "Epoch 35 completed, Train Loss: 0.000061\n",
      "\n",
      "Epoch 36, Step 1, LR: 0.000868, Current Loss: 0.2286, Avg Loss: 0.2286\n",
      "Diff stats — min: -5.4799, max: 10.0000, mean: 3.2507, std: 2.5426\n",
      "\n",
      "Step 1050 — Test metrics:\n",
      "  precision@10: 0.001626591\n",
      "  recall@10: 0.001626591\n",
      "  ndcg@10: 0.001538752\n",
      "  map@10: 0.000424571\n",
      "Epoch 36, Step 20, LR: 0.000868, Current Loss: 0.2381, Avg Loss: 0.2390\n",
      "Diff stats — min: -5.5660, max: 10.0000, mean: 3.3068, std: 2.6302\n",
      "\n",
      "Epoch 36 completed, Train Loss: 0.000060\n",
      "\n",
      "Epoch 37, Step 1, LR: 0.000868, Current Loss: 0.2408, Avg Loss: 0.2408\n",
      "Diff stats — min: -7.4374, max: 10.0000, mean: 3.3382, std: 2.6523\n",
      "\n",
      "Step 1080 — Test metrics:\n",
      "  precision@10: 0.001720886\n",
      "  recall@10: 0.001720886\n",
      "  ndcg@10: 0.001656667\n",
      "  map@10: 0.000465283\n",
      "Epoch 37, Step 20, LR: 0.000868, Current Loss: 0.2383, Avg Loss: 0.2401\n",
      "Diff stats — min: -6.8582, max: 10.0000, mean: 3.3673, std: 2.6567\n",
      "\n",
      "Epoch 37 completed, Train Loss: 0.000060\n",
      "\n",
      "Epoch 38, Step 1, LR: 0.000868, Current Loss: 0.2375, Avg Loss: 0.2375\n",
      "Diff stats — min: -5.4146, max: 10.0000, mean: 3.3404, std: 2.6304\n",
      "\n",
      "Step 1110 — Test metrics:\n",
      "  precision@10: 0.001862329\n",
      "  recall@10: 0.001868223\n",
      "  ndcg@10: 0.001724556\n",
      "  map@10: 0.000469249\n",
      "Epoch 38, Step 20, LR: 0.000868, Current Loss: 0.2366, Avg Loss: 0.2360\n",
      "Diff stats — min: -8.0155, max: 10.0000, mean: 3.3171, std: 2.6222\n",
      "\n",
      "Epoch 38 completed, Train Loss: 0.000058\n",
      "\n",
      "Epoch 39, Step 1, LR: 0.000868, Current Loss: 0.2535, Avg Loss: 0.2535\n",
      "Diff stats — min: -6.2779, max: 10.0000, mean: 3.3503, std: 2.7178\n",
      "\n",
      "Step 1140 — Test metrics:\n",
      "  precision@10: 0.002050919\n",
      "  recall@10: 0.002050919\n",
      "  ndcg@10: 0.002114740\n",
      "  map@10: 0.000646810\n",
      "Epoch 39, Step 20, LR: 0.000868, Current Loss: 0.2296, Avg Loss: 0.2372\n",
      "Diff stats — min: -4.7461, max: 10.0000, mean: 3.3605, std: 2.6274\n",
      "\n",
      "Epoch 39 completed, Train Loss: 0.000058\n",
      "\n",
      "Epoch 40, Step 1, LR: 0.000868, Current Loss: 0.2269, Avg Loss: 0.2269\n",
      "Diff stats — min: -5.8464, max: 10.0000, mean: 3.4031, std: 2.6439\n",
      "\n",
      "Step 1170 — Test metrics:\n",
      "  precision@10: 0.002168788\n",
      "  recall@10: 0.002168788\n",
      "  ndcg@10: 0.002038724\n",
      "  map@10: 0.000563573\n",
      "Epoch 40, Step 20, LR: 0.000868, Current Loss: 0.2376, Avg Loss: 0.2309\n",
      "Diff stats — min: -7.5738, max: 10.0000, mean: 3.3732, std: 2.6737\n",
      "\n",
      "Epoch 40 completed, Train Loss: 0.000057\n",
      "\n",
      "Epoch 41, Step 1, LR: 0.000851, Current Loss: 0.2229, Avg Loss: 0.2229\n",
      "Diff stats — min: -6.7187, max: 10.0000, mean: 3.4320, std: 2.6484\n",
      "\n",
      "Step 1200 — Test metrics:\n",
      "  precision@10: 0.002239510\n",
      "  recall@10: 0.002239510\n",
      "  ndcg@10: 0.002199984\n",
      "  map@10: 0.000645800\n",
      "Epoch 41, Step 20, LR: 0.000851, Current Loss: 0.2315, Avg Loss: 0.2257\n",
      "Diff stats — min: -8.0948, max: 10.0000, mean: 3.4980, std: 2.7216\n",
      "\n",
      "Epoch 41 completed, Train Loss: 0.000056\n",
      "\n",
      "Epoch 42, Step 1, LR: 0.000851, Current Loss: 0.2157, Avg Loss: 0.2157\n",
      "Diff stats — min: -4.9873, max: 10.0000, mean: 3.5460, std: 2.6791\n",
      "\n",
      "Step 1230 — Test metrics:\n",
      "  precision@10: 0.002168788\n",
      "  recall@10: 0.002168788\n",
      "  ndcg@10: 0.002090806\n",
      "  map@10: 0.000587764\n",
      "Epoch 42, Step 20, LR: 0.000851, Current Loss: 0.2236, Avg Loss: 0.2266\n",
      "Diff stats — min: -5.2956, max: 10.0000, mean: 3.5941, std: 2.7278\n",
      "\n",
      "Epoch 42 completed, Train Loss: 0.000056\n",
      "\n",
      "Epoch 43, Step 1, LR: 0.000851, Current Loss: 0.1988, Avg Loss: 0.1988\n",
      "Diff stats — min: -5.2208, max: 10.0000, mean: 3.6806, std: 2.6542\n",
      "\n",
      "Step 1260 — Test metrics:\n",
      "  precision@10: 0.002145215\n",
      "  recall@10: 0.002145215\n",
      "  ndcg@10: 0.002175146\n",
      "  map@10: 0.000643751\n",
      "Epoch 43, Step 20, LR: 0.000851, Current Loss: 0.2315, Avg Loss: 0.2219\n",
      "Diff stats — min: -6.5497, max: 10.0000, mean: 3.5589, std: 2.7479\n",
      "\n",
      "Epoch 43 completed, Train Loss: 0.000055\n",
      "\n",
      "Epoch 44, Step 1, LR: 0.000851, Current Loss: 0.2164, Avg Loss: 0.2164\n",
      "Diff stats — min: -5.4842, max: 10.0000, mean: 3.5727, std: 2.6913\n",
      "\n",
      "Step 1290 — Test metrics:\n",
      "  precision@10: 0.002475248\n",
      "  recall@10: 0.002475248\n",
      "  ndcg@10: 0.002418880\n",
      "  map@10: 0.000693921\n",
      "Epoch 44, Step 20, LR: 0.000851, Current Loss: 0.2169, Avg Loss: 0.2154\n",
      "Diff stats — min: -7.2336, max: 10.0000, mean: 3.5477, std: 2.6632\n",
      "\n",
      "Epoch 44 completed, Train Loss: 0.000054\n",
      "\n",
      "Epoch 45, Step 1, LR: 0.000851, Current Loss: 0.2159, Avg Loss: 0.2159\n",
      "Diff stats — min: -6.1868, max: 10.0000, mean: 3.6235, std: 2.7214\n",
      "\n",
      "Step 1320 — Test metrics:\n",
      "  precision@10: 0.002451674\n",
      "  recall@10: 0.002451674\n",
      "  ndcg@10: 0.002359407\n",
      "  map@10: 0.000670085\n",
      "Epoch 45, Step 20, LR: 0.000851, Current Loss: 0.2100, Avg Loss: 0.2178\n",
      "Diff stats — min: -6.6630, max: 10.0000, mean: 3.6783, std: 2.7165\n",
      "\n",
      "Epoch 45 completed, Train Loss: 0.000054\n",
      "\n",
      "Epoch 46, Step 1, LR: 0.000834, Current Loss: 0.2155, Avg Loss: 0.2155\n",
      "Diff stats — min: -6.4836, max: 10.0000, mean: 3.6281, std: 2.7460\n",
      "\n",
      "Step 1350 — Test metrics:\n",
      "  precision@10: 0.002758133\n",
      "  recall@10: 0.002758133\n",
      "  ndcg@10: 0.002598793\n",
      "  map@10: 0.000723463\n",
      "Epoch 46, Step 20, LR: 0.000834, Current Loss: 0.2146, Avg Loss: 0.2141\n",
      "Diff stats — min: -4.6692, max: 10.0000, mean: 3.6372, std: 2.7473\n",
      "\n",
      "Epoch 46 completed, Train Loss: 0.000053\n",
      "\n",
      "Epoch 47, Step 1, LR: 0.000834, Current Loss: 0.2135, Avg Loss: 0.2135\n",
      "Diff stats — min: -7.7758, max: 10.0000, mean: 3.7187, std: 2.7941\n",
      "\n",
      "Step 1380 — Test metrics:\n",
      "  precision@10: 0.002852428\n",
      "  recall@10: 0.002858322\n",
      "  ndcg@10: 0.002796762\n",
      "  map@10: 0.000832950\n",
      "Epoch 47, Step 20, LR: 0.000834, Current Loss: 0.2195, Avg Loss: 0.2118\n",
      "Diff stats — min: -5.9390, max: 10.0000, mean: 3.7108, std: 2.7869\n",
      "\n",
      "Epoch 47 completed, Train Loss: 0.000052\n",
      "\n",
      "Epoch 48, Step 1, LR: 0.000834, Current Loss: 0.2133, Avg Loss: 0.2133\n",
      "Diff stats — min: -6.6505, max: 10.0000, mean: 3.7218, std: 2.7734\n",
      "\n",
      "Step 1410 — Test metrics:\n",
      "  precision@10: 0.002899576\n",
      "  recall@10: 0.002905469\n",
      "  ndcg@10: 0.002799890\n",
      "  map@10: 0.000793997\n",
      "Epoch 48, Step 20, LR: 0.000834, Current Loss: 0.2072, Avg Loss: 0.2084\n",
      "Diff stats — min: -6.1341, max: 10.0000, mean: 3.7035, std: 2.7393\n",
      "\n",
      "Epoch 48 completed, Train Loss: 0.000051\n",
      "\n",
      "Epoch 49, Step 1, LR: 0.000834, Current Loss: 0.2018, Avg Loss: 0.2018\n",
      "Diff stats — min: -5.3308, max: 10.0000, mean: 3.8090, std: 2.7711\n",
      "\n",
      "Step 1440 — Test metrics:\n",
      "  precision@10: 0.003041018\n",
      "  recall@10: 0.003046912\n",
      "  ndcg@10: 0.002862726\n",
      "  map@10: 0.000786766\n",
      "Epoch 49, Step 20, LR: 0.000834, Current Loss: 0.2102, Avg Loss: 0.2080\n",
      "Diff stats — min: -6.7713, max: 10.0000, mean: 3.8666, std: 2.8275\n",
      "\n",
      "Epoch 49 completed, Train Loss: 0.000051\n",
      "\n",
      "Epoch 50, Step 1, LR: 0.000834, Current Loss: 0.1940, Avg Loss: 0.1940\n",
      "Diff stats — min: -5.5777, max: 10.0000, mean: 3.9036, std: 2.8254\n",
      "\n",
      "Step 1470 — Test metrics:\n",
      "  precision@10: 0.003182461\n",
      "  recall@10: 0.003188355\n",
      "  ndcg@10: 0.003001586\n",
      "  map@10: 0.000833284\n",
      "Epoch 50, Step 20, LR: 0.000834, Current Loss: 0.2101, Avg Loss: 0.2004\n",
      "Diff stats — min: -5.0397, max: 10.0000, mean: 3.8922, std: 2.8741\n",
      "\n",
      "Epoch 50 completed, Train Loss: 0.000050\n",
      "\n",
      "Epoch 51, Step 1, LR: 0.000817, Current Loss: 0.1989, Avg Loss: 0.1989\n",
      "Diff stats — min: -6.7544, max: 10.0000, mean: 3.8228, std: 2.8049\n",
      "\n",
      "Step 1500 — Test metrics:\n",
      "  precision@10: 0.003206035\n",
      "  recall@10: 0.003211928\n",
      "  ndcg@10: 0.003156812\n",
      "  map@10: 0.000920879\n",
      "Epoch 51, Step 20, LR: 0.000817, Current Loss: 0.2081, Avg Loss: 0.2019\n",
      "Diff stats — min: -7.4867, max: 10.0000, mean: 3.8663, std: 2.8469\n",
      "\n",
      "Epoch 51 completed, Train Loss: 0.000051\n",
      "\n",
      "Epoch 52, Step 1, LR: 0.000817, Current Loss: 0.1891, Avg Loss: 0.1891\n",
      "Diff stats — min: -7.1792, max: 10.0000, mean: 3.8836, std: 2.7974\n",
      "\n",
      "Step 1530 — Test metrics:\n",
      "  precision@10: 0.003276756\n",
      "  recall@10: 0.003282650\n",
      "  ndcg@10: 0.003198178\n",
      "  map@10: 0.000918452\n",
      "Epoch 52, Step 20, LR: 0.000817, Current Loss: 0.1947, Avg Loss: 0.1959\n",
      "Diff stats — min: -6.9186, max: 10.0000, mean: 3.9529, std: 2.8125\n",
      "\n",
      "Epoch 52 completed, Train Loss: 0.000049\n",
      "\n",
      "Epoch 53, Step 1, LR: 0.000817, Current Loss: 0.1953, Avg Loss: 0.1953\n",
      "Diff stats — min: -5.8445, max: 10.0000, mean: 3.9867, std: 2.8512\n",
      "\n",
      "Step 1560 — Test metrics:\n",
      "  precision@10: 0.003465347\n",
      "  recall@10: 0.003471240\n",
      "  ndcg@10: 0.003337450\n",
      "  map@10: 0.000949734\n",
      "Epoch 53, Step 20, LR: 0.000817, Current Loss: 0.2163, Avg Loss: 0.1952\n",
      "Diff stats — min: -7.0075, max: 10.0000, mean: 3.9158, std: 2.9055\n",
      "\n",
      "Epoch 53 completed, Train Loss: 0.000049\n",
      "\n",
      "Epoch 54, Step 1, LR: 0.000817, Current Loss: 0.1894, Avg Loss: 0.1894\n",
      "Diff stats — min: -7.5751, max: 10.0000, mean: 4.0593, std: 2.8648\n",
      "\n",
      "Step 1590 — Test metrics:\n",
      "  precision@10: 0.003630363\n",
      "  recall@10: 0.003630363\n",
      "  ndcg@10: 0.003549190\n",
      "  map@10: 0.001060109\n",
      "Epoch 54, Step 20, LR: 0.000817, Current Loss: 0.2037, Avg Loss: 0.1940\n",
      "Diff stats — min: -6.2048, max: 10.0000, mean: 3.9893, std: 2.8748\n",
      "\n",
      "Epoch 54 completed, Train Loss: 0.000048\n",
      "\n",
      "Epoch 55, Step 1, LR: 0.000817, Current Loss: 0.1864, Avg Loss: 0.1864\n",
      "Diff stats — min: -5.8525, max: 10.0000, mean: 4.0137, std: 2.8484\n",
      "\n",
      "Step 1620 — Test metrics:\n",
      "  precision@10: 0.003653937\n",
      "  recall@10: 0.003653937\n",
      "  ndcg@10: 0.003636888\n",
      "  map@10: 0.001093468\n",
      "Epoch 55, Step 20, LR: 0.000817, Current Loss: 0.1934, Avg Loss: 0.1900\n",
      "Diff stats — min: -5.4599, max: 10.0000, mean: 4.0160, std: 2.8652\n",
      "\n",
      "Epoch 55 completed, Train Loss: 0.000047\n",
      "\n",
      "Epoch 56, Step 1, LR: 0.000801, Current Loss: 0.1914, Avg Loss: 0.1914\n",
      "Diff stats — min: -7.7200, max: 10.0000, mean: 4.0780, std: 2.8855\n",
      "\n",
      "Step 1650 — Test metrics:\n",
      "  precision@10: 0.003960396\n",
      "  recall@10: 0.003963015\n",
      "  ndcg@10: 0.004061275\n",
      "  map@10: 0.001275231\n",
      "Epoch 56, Step 20, LR: 0.000801, Current Loss: 0.1927, Avg Loss: 0.1913\n",
      "Diff stats — min: -5.4443, max: 10.0000, mean: 4.0957, std: 2.8812\n",
      "\n",
      "Epoch 56 completed, Train Loss: 0.000047\n",
      "\n",
      "Epoch 57, Step 1, LR: 0.000801, Current Loss: 0.1872, Avg Loss: 0.1872\n",
      "Diff stats — min: -6.1549, max: 10.0000, mean: 4.1375, std: 2.8959\n",
      "\n",
      "Step 1680 — Test metrics:\n",
      "  precision@10: 0.003866101\n",
      "  recall@10: 0.003868720\n",
      "  ndcg@10: 0.003787702\n",
      "  map@10: 0.001113338\n",
      "Epoch 57, Step 20, LR: 0.000801, Current Loss: 0.1959, Avg Loss: 0.1869\n",
      "Diff stats — min: -9.9307, max: 10.0000, mean: 4.0802, std: 2.9193\n",
      "\n",
      "Epoch 57 completed, Train Loss: 0.000046\n",
      "\n",
      "Epoch 58, Step 1, LR: 0.000801, Current Loss: 0.1981, Avg Loss: 0.1981\n",
      "Diff stats — min: -7.1591, max: 10.0000, mean: 4.0791, std: 2.9151\n",
      "\n",
      "Step 1710 — Test metrics:\n",
      "  precision@10: 0.003889675\n",
      "  recall@10: 0.003889675\n",
      "  ndcg@10: 0.003861700\n",
      "  map@10: 0.001142150\n",
      "Epoch 58, Step 20, LR: 0.000801, Current Loss: 0.1871, Avg Loss: 0.1872\n",
      "Diff stats — min: -6.6939, max: 10.0000, mean: 4.1107, std: 2.8844\n",
      "\n",
      "Epoch 58 completed, Train Loss: 0.000046\n",
      "\n",
      "Epoch 59, Step 1, LR: 0.000801, Current Loss: 0.1813, Avg Loss: 0.1813\n",
      "Diff stats — min: -9.8096, max: 10.0000, mean: 4.1996, std: 2.9035\n",
      "\n",
      "Step 1740 — Test metrics:\n",
      "  precision@10: 0.004384724\n",
      "  recall@10: 0.004394827\n",
      "  ndcg@10: 0.004598520\n",
      "  map@10: 0.001472679\n",
      "Epoch 59, Step 20, LR: 0.000801, Current Loss: 0.1791, Avg Loss: 0.1844\n",
      "Diff stats — min: -8.4826, max: 10.0000, mean: 4.2103, std: 2.9028\n",
      "\n",
      "Epoch 59 completed, Train Loss: 0.000046\n",
      "\n",
      "Epoch 60, Step 1, LR: 0.000801, Current Loss: 0.1781, Avg Loss: 0.1781\n",
      "Diff stats — min: -6.8418, max: 10.0000, mean: 4.2212, std: 2.9042\n",
      "\n",
      "Step 1770 — Test metrics:\n",
      "  precision@10: 0.004054691\n",
      "  recall@10: 0.004054691\n",
      "  ndcg@10: 0.004262952\n",
      "  map@10: 0.001352443\n",
      "Epoch 60, Step 20, LR: 0.000801, Current Loss: 0.1821, Avg Loss: 0.1792\n",
      "Diff stats — min: -5.5590, max: 10.0000, mean: 4.2174, std: 2.9615\n",
      "\n",
      "Epoch 60 completed, Train Loss: 0.000045\n",
      "\n",
      "Epoch 61, Step 1, LR: 0.000785, Current Loss: 0.1744, Avg Loss: 0.1744\n",
      "Diff stats — min: -4.9225, max: 10.0000, mean: 4.2941, std: 2.9376\n",
      "\n",
      "Step 1800 — Test metrics:\n",
      "  precision@10: 0.004219708\n",
      "  recall@10: 0.004219708\n",
      "  ndcg@10: 0.004375881\n",
      "  map@10: 0.001378617\n",
      "Epoch 61, Step 20, LR: 0.000785, Current Loss: 0.1694, Avg Loss: 0.1841\n",
      "Diff stats — min: -5.3965, max: 10.0000, mean: 4.2555, std: 2.8864\n",
      "\n",
      "Epoch 61 completed, Train Loss: 0.000045\n",
      "\n",
      "Epoch 62, Step 1, LR: 0.000785, Current Loss: 0.1808, Avg Loss: 0.1808\n",
      "Diff stats — min: -6.6835, max: 10.0000, mean: 4.2686, std: 2.9378\n",
      "\n",
      "Step 1830 — Test metrics:\n",
      "  precision@10: 0.004266855\n",
      "  recall@10: 0.004276958\n",
      "  ndcg@10: 0.004363938\n",
      "  map@10: 0.001346877\n",
      "Epoch 62, Step 20, LR: 0.000785, Current Loss: 0.1720, Avg Loss: 0.1747\n",
      "Diff stats — min: -4.9486, max: 10.0000, mean: 4.2915, std: 2.9094\n",
      "\n",
      "Epoch 62 completed, Train Loss: 0.000043\n",
      "\n",
      "Epoch 63, Step 1, LR: 0.000785, Current Loss: 0.1816, Avg Loss: 0.1816\n",
      "Diff stats — min: -4.9771, max: 10.0000, mean: 4.3040, std: 3.0196\n",
      "\n",
      "Step 1860 — Test metrics:\n",
      "  precision@10: 0.004761905\n",
      "  recall@10: 0.004780521\n",
      "  ndcg@10: 0.004719125\n",
      "  map@10: 0.001417898\n",
      "Epoch 63, Step 20, LR: 0.000785, Current Loss: 0.1796, Avg Loss: 0.1745\n",
      "Diff stats — min: -6.3634, max: 10.0000, mean: 4.3080, std: 2.9639\n",
      "\n",
      "Epoch 63 completed, Train Loss: 0.000043\n",
      "\n",
      "Epoch 64, Step 1, LR: 0.000785, Current Loss: 0.1700, Avg Loss: 0.1700\n",
      "Diff stats — min: -7.0313, max: 10.0000, mean: 4.3371, std: 2.9091\n",
      "\n",
      "Step 1890 — Test metrics:\n",
      "  precision@10: 0.004667610\n",
      "  recall@10: 0.004677713\n",
      "  ndcg@10: 0.004675168\n",
      "  map@10: 0.001414580\n",
      "Epoch 64, Step 20, LR: 0.000785, Current Loss: 0.1881, Avg Loss: 0.1739\n",
      "Diff stats — min: -5.9970, max: 10.0000, mean: 4.2913, std: 2.9806\n",
      "\n",
      "Epoch 64 completed, Train Loss: 0.000043\n",
      "\n",
      "Epoch 65, Step 1, LR: 0.000785, Current Loss: 0.1621, Avg Loss: 0.1621\n",
      "Diff stats — min: -6.6733, max: 10.0000, mean: 4.4324, std: 2.9288\n",
      "\n",
      "Step 1920 — Test metrics:\n",
      "  precision@10: 0.004667610\n",
      "  recall@10: 0.004670229\n",
      "  ndcg@10: 0.004880383\n",
      "  map@10: 0.001526693\n",
      "Epoch 65, Step 20, LR: 0.000785, Current Loss: 0.1811, Avg Loss: 0.1735\n",
      "Diff stats — min: -6.6094, max: 10.0000, mean: 4.4358, std: 3.0417\n",
      "\n",
      "Epoch 65 completed, Train Loss: 0.000043\n",
      "\n",
      "Epoch 66, Step 1, LR: 0.000769, Current Loss: 0.1635, Avg Loss: 0.1635\n",
      "Diff stats — min: -5.5272, max: 10.0000, mean: 4.4833, std: 2.9555\n",
      "\n",
      "Step 1950 — Test metrics:\n",
      "  precision@10: 0.004950495\n",
      "  recall@10: 0.004953114\n",
      "  ndcg@10: 0.005022075\n",
      "  map@10: 0.001533260\n",
      "Epoch 66, Step 20, LR: 0.000769, Current Loss: 0.1673, Avg Loss: 0.1693\n",
      "Diff stats — min: -5.5228, max: 10.0000, mean: 4.4740, std: 3.0074\n",
      "\n",
      "Epoch 66 completed, Train Loss: 0.000042\n",
      "\n",
      "Epoch 67, Step 1, LR: 0.000769, Current Loss: 0.1690, Avg Loss: 0.1690\n",
      "Diff stats — min: -7.3444, max: 10.0000, mean: 4.4821, std: 2.9804\n",
      "\n",
      "Step 1980 — Test metrics:\n",
      "  precision@10: 0.004832626\n",
      "  recall@10: 0.004835245\n",
      "  ndcg@10: 0.004886340\n",
      "  map@10: 0.001511661\n",
      "Epoch 67, Step 20, LR: 0.000769, Current Loss: 0.1697, Avg Loss: 0.1705\n",
      "Diff stats — min: -6.9995, max: 10.0000, mean: 4.4631, std: 2.9914\n",
      "\n",
      "Epoch 67 completed, Train Loss: 0.000042\n",
      "\n",
      "Epoch 68, Step 1, LR: 0.000769, Current Loss: 0.1579, Avg Loss: 0.1579\n",
      "Diff stats — min: -7.0207, max: 10.0000, mean: 4.5720, std: 3.0076\n",
      "\n",
      "Step 2010 — Test metrics:\n",
      "  precision@10: 0.005162659\n",
      "  recall@10: 0.005172762\n",
      "  ndcg@10: 0.005339433\n",
      "  map@10: 0.001696995\n",
      "Epoch 68, Step 20, LR: 0.000769, Current Loss: 0.1685, Avg Loss: 0.1674\n",
      "Diff stats — min: -7.0151, max: 10.0000, mean: 4.5071, std: 3.0079\n",
      "\n",
      "Epoch 68 completed, Train Loss: 0.000041\n",
      "\n",
      "Epoch 69, Step 1, LR: 0.000769, Current Loss: 0.1681, Avg Loss: 0.1681\n",
      "Diff stats — min: -7.7171, max: 10.0000, mean: 4.5052, std: 2.9874\n",
      "\n",
      "Step 2040 — Test metrics:\n",
      "  precision@10: 0.005186233\n",
      "  recall@10: 0.005202229\n",
      "  ndcg@10: 0.005342679\n",
      "  map@10: 0.001664712\n",
      "Epoch 69, Step 20, LR: 0.000769, Current Loss: 0.1780, Avg Loss: 0.1668\n",
      "Diff stats — min: -5.9836, max: 10.0000, mean: 4.5237, std: 3.0492\n",
      "\n",
      "Epoch 69 completed, Train Loss: 0.000041\n",
      "\n",
      "Epoch 70, Step 1, LR: 0.000769, Current Loss: 0.1662, Avg Loss: 0.1662\n",
      "Diff stats — min: -5.6540, max: 10.0000, mean: 4.5136, std: 3.0080\n",
      "\n",
      "Step 2070 — Test metrics:\n",
      "  precision@10: 0.005469118\n",
      "  recall@10: 0.005469118\n",
      "  ndcg@10: 0.005460780\n",
      "  map@10: 0.001678519\n",
      "Epoch 70, Step 20, LR: 0.000769, Current Loss: 0.1608, Avg Loss: 0.1627\n",
      "Diff stats — min: -5.1342, max: 10.0000, mean: 4.5458, std: 3.0125\n",
      "\n",
      "Epoch 70 completed, Train Loss: 0.000041\n",
      "\n",
      "Epoch 71, Step 1, LR: 0.000754, Current Loss: 0.1626, Avg Loss: 0.1626\n",
      "Diff stats — min: -5.5034, max: 10.0000, mean: 4.5842, std: 3.0142\n",
      "\n",
      "Step 2100 — Test metrics:\n",
      "  precision@10: 0.005256954\n",
      "  recall@10: 0.005269677\n",
      "  ndcg@10: 0.005315899\n",
      "  map@10: 0.001637158\n",
      "Epoch 71, Step 20, LR: 0.000754, Current Loss: 0.1625, Avg Loss: 0.1648\n",
      "Diff stats — min: -6.4386, max: 10.0000, mean: 4.6179, std: 3.0163\n",
      "\n",
      "Epoch 71 completed, Train Loss: 0.000040\n",
      "\n",
      "Epoch 72, Step 1, LR: 0.000754, Current Loss: 0.1580, Avg Loss: 0.1580\n",
      "Diff stats — min: -7.7184, max: 10.0000, mean: 4.6570, std: 3.0187\n",
      "\n",
      "Step 2130 — Test metrics:\n",
      "  precision@10: 0.005869873\n",
      "  recall@10: 0.005885214\n",
      "  ndcg@10: 0.005922917\n",
      "  map@10: 0.001830255\n",
      "Epoch 72, Step 20, LR: 0.000754, Current Loss: 0.1514, Avg Loss: 0.1595\n",
      "Diff stats — min: -5.3056, max: 10.0000, mean: 4.6981, std: 2.9928\n",
      "\n",
      "Epoch 72 completed, Train Loss: 0.000040\n",
      "\n",
      "Epoch 73, Step 1, LR: 0.000754, Current Loss: 0.1540, Avg Loss: 0.1540\n",
      "Diff stats — min: -5.2415, max: 10.0000, mean: 4.6632, std: 3.0073\n",
      "\n",
      "Step 2160 — Test metrics:\n",
      "  precision@10: 0.005421971\n",
      "  recall@10: 0.005434693\n",
      "  ndcg@10: 0.005644681\n",
      "  map@10: 0.001781885\n",
      "Epoch 73, Step 20, LR: 0.000754, Current Loss: 0.1564, Avg Loss: 0.1596\n",
      "Diff stats — min: -6.7934, max: 10.0000, mean: 4.7191, std: 3.0314\n",
      "\n",
      "Epoch 73 completed, Train Loss: 0.000039\n",
      "\n",
      "Epoch 74, Step 1, LR: 0.000754, Current Loss: 0.1564, Avg Loss: 0.1564\n",
      "Diff stats — min: -5.2267, max: 10.0000, mean: 4.6879, std: 3.0068\n",
      "\n",
      "Step 2190 — Test metrics:\n",
      "  precision@10: 0.005822725\n",
      "  recall@10: 0.005833857\n",
      "  ndcg@10: 0.005847018\n",
      "  map@10: 0.001803554\n",
      "Epoch 74, Step 20, LR: 0.000754, Current Loss: 0.1557, Avg Loss: 0.1597\n",
      "Diff stats — min: -8.0516, max: 10.0000, mean: 4.7412, std: 3.0350\n",
      "\n",
      "Epoch 74 completed, Train Loss: 0.000039\n",
      "\n",
      "Epoch 75, Step 1, LR: 0.000754, Current Loss: 0.1523, Avg Loss: 0.1523\n",
      "Diff stats — min: -5.9732, max: 10.0000, mean: 4.7467, std: 3.0202\n",
      "\n",
      "Step 2220 — Test metrics:\n",
      "  precision@10: 0.005704856\n",
      "  recall@10: 0.005715988\n",
      "  ndcg@10: 0.005857737\n",
      "  map@10: 0.001827817\n",
      "Epoch 75, Step 20, LR: 0.000754, Current Loss: 0.1606, Avg Loss: 0.1572\n",
      "Diff stats — min: -7.2050, max: 10.0000, mean: 4.6541, std: 3.0228\n",
      "\n",
      "Epoch 75 completed, Train Loss: 0.000039\n",
      "\n",
      "Epoch 76, Step 1, LR: 0.000739, Current Loss: 0.1614, Avg Loss: 0.1614\n",
      "Diff stats — min: -6.0525, max: 10.0000, mean: 4.7199, std: 3.0590\n",
      "\n",
      "Step 2250 — Test metrics:\n",
      "  precision@10: 0.005681282\n",
      "  recall@10: 0.005699243\n",
      "  ndcg@10: 0.005824074\n",
      "  map@10: 0.001843136\n",
      "Epoch 76, Step 20, LR: 0.000739, Current Loss: 0.1433, Avg Loss: 0.1570\n",
      "Diff stats — min: -4.3679, max: 10.0000, mean: 4.7040, std: 2.9672\n",
      "\n",
      "Epoch 76 completed, Train Loss: 0.000038\n",
      "\n",
      "Epoch 77, Step 1, LR: 0.000739, Current Loss: 0.1546, Avg Loss: 0.1546\n",
      "Diff stats — min: -5.7726, max: 10.0000, mean: 4.7856, std: 3.0656\n",
      "\n",
      "Step 2280 — Test metrics:\n",
      "  precision@10: 0.005799151\n",
      "  recall@10: 0.005817112\n",
      "  ndcg@10: 0.006028897\n",
      "  map@10: 0.001925315\n",
      "Epoch 77, Step 20, LR: 0.000739, Current Loss: 0.1636, Avg Loss: 0.1538\n",
      "Diff stats — min: -4.7131, max: 10.0000, mean: 4.7227, std: 3.0684\n",
      "\n",
      "Epoch 77 completed, Train Loss: 0.000038\n",
      "\n",
      "Epoch 78, Step 1, LR: 0.000739, Current Loss: 0.1616, Avg Loss: 0.1616\n",
      "Diff stats — min: -5.5667, max: 10.0000, mean: 4.8007, std: 3.0924\n",
      "\n",
      "Step 2310 — Test metrics:\n",
      "  precision@10: 0.006176332\n",
      "  recall@10: 0.006189054\n",
      "  ndcg@10: 0.006375673\n",
      "  map@10: 0.002051041\n",
      "Epoch 78, Step 20, LR: 0.000739, Current Loss: 0.1546, Avg Loss: 0.1532\n",
      "Diff stats — min: -6.8018, max: 10.0000, mean: 4.7599, std: 3.0614\n",
      "\n",
      "Epoch 78 completed, Train Loss: 0.000038\n",
      "\n",
      "Epoch 79, Step 1, LR: 0.000739, Current Loss: 0.1389, Avg Loss: 0.1389\n",
      "Diff stats — min: -6.4882, max: 10.0000, mean: 4.8747, std: 3.0114\n",
      "\n",
      "Step 2340 — Test metrics:\n",
      "  precision@10: 0.006364922\n",
      "  recall@10: 0.006382883\n",
      "  ndcg@10: 0.006683688\n",
      "  map@10: 0.002149168\n",
      "Epoch 79, Step 20, LR: 0.000739, Current Loss: 0.1454, Avg Loss: 0.1508\n",
      "Diff stats — min: -6.8563, max: 10.0000, mean: 4.8013, std: 3.0322\n",
      "\n",
      "Epoch 79 completed, Train Loss: 0.000037\n",
      "\n",
      "Epoch 80, Step 1, LR: 0.000739, Current Loss: 0.1370, Avg Loss: 0.1370\n",
      "Diff stats — min: -6.0000, max: 10.0000, mean: 4.8959, std: 3.0160\n",
      "\n",
      "Step 2370 — Test metrics:\n",
      "  precision@10: 0.006506365\n",
      "  recall@10: 0.006530219\n",
      "  ndcg@10: 0.006779208\n",
      "  map@10: 0.002174859\n",
      "Epoch 80, Step 20, LR: 0.000739, Current Loss: 0.1541, Avg Loss: 0.1483\n",
      "Diff stats — min: -6.5763, max: 10.0000, mean: 4.8679, std: 3.1158\n",
      "\n",
      "Epoch 80 completed, Train Loss: 0.000037\n",
      "\n",
      "Epoch 81, Step 1, LR: 0.000724, Current Loss: 0.1560, Avg Loss: 0.1560\n",
      "Diff stats — min: -6.3859, max: 10.0000, mean: 4.9031, std: 3.0945\n",
      "\n",
      "Step 2400 — Test metrics:\n",
      "  precision@10: 0.006600660\n",
      "  recall@10: 0.006624514\n",
      "  ndcg@10: 0.006997714\n",
      "  map@10: 0.002294828\n",
      "Epoch 81, Step 20, LR: 0.000724, Current Loss: 0.1382, Avg Loss: 0.1476\n",
      "Diff stats — min: -6.6823, max: 10.0000, mean: 4.9473, std: 3.0522\n",
      "\n",
      "Epoch 81 completed, Train Loss: 0.000037\n",
      "\n",
      "Epoch 82, Step 1, LR: 0.000724, Current Loss: 0.1357, Avg Loss: 0.1357\n",
      "Diff stats — min: -7.0580, max: 10.0000, mean: 5.0382, std: 3.0604\n",
      "\n",
      "Step 2430 — Test metrics:\n",
      "  precision@10: 0.006388496\n",
      "  recall@10: 0.006411696\n",
      "  ndcg@10: 0.006493895\n",
      "  map@10: 0.002015587\n",
      "Epoch 82, Step 20, LR: 0.000724, Current Loss: 0.1486, Avg Loss: 0.1456\n",
      "Diff stats — min: -6.2097, max: 10.0000, mean: 4.9194, std: 3.1000\n",
      "\n",
      "Epoch 82 completed, Train Loss: 0.000036\n",
      "\n",
      "Epoch 83, Step 1, LR: 0.000724, Current Loss: 0.1538, Avg Loss: 0.1538\n",
      "Diff stats — min: -7.8984, max: 10.0000, mean: 4.8758, std: 3.1129\n",
      "\n",
      "Step 2460 — Test metrics:\n",
      "  precision@10: 0.006553512\n",
      "  recall@10: 0.006574093\n",
      "  ndcg@10: 0.006623596\n",
      "  map@10: 0.002049872\n",
      "Epoch 83, Step 20, LR: 0.000724, Current Loss: 0.1306, Avg Loss: 0.1445\n",
      "Diff stats — min: -6.6059, max: 10.0000, mean: 4.9853, std: 3.0292\n",
      "\n",
      "Epoch 83 completed, Train Loss: 0.000036\n",
      "\n",
      "Epoch 84, Step 1, LR: 0.000724, Current Loss: 0.1294, Avg Loss: 0.1294\n",
      "Diff stats — min: -5.0836, max: 10.0000, mean: 5.0395, std: 3.0826\n",
      "\n",
      "Step 2490 — Test metrics:\n",
      "  precision@10: 0.006647808\n",
      "  recall@10: 0.006676901\n",
      "  ndcg@10: 0.006729768\n",
      "  map@10: 0.002091795\n",
      "Epoch 84, Step 20, LR: 0.000724, Current Loss: 0.1342, Avg Loss: 0.1417\n",
      "Diff stats — min: -5.6170, max: 10.0000, mean: 5.0983, std: 3.0734\n",
      "\n",
      "Epoch 84 completed, Train Loss: 0.000035\n",
      "\n",
      "Epoch 85, Step 1, LR: 0.000724, Current Loss: 0.1408, Avg Loss: 0.1408\n",
      "Diff stats — min: -7.3612, max: 10.0000, mean: 4.9800, std: 3.0793\n",
      "\n",
      "Step 2520 — Test metrics:\n",
      "  precision@10: 0.006789250\n",
      "  recall@10: 0.006809831\n",
      "  ndcg@10: 0.007052098\n",
      "  map@10: 0.002269919\n",
      "Epoch 85, Step 20, LR: 0.000724, Current Loss: 0.1505, Avg Loss: 0.1412\n",
      "Diff stats — min: -6.6413, max: 10.0000, mean: 5.0395, std: 3.1332\n",
      "\n",
      "Epoch 85 completed, Train Loss: 0.000035\n",
      "\n",
      "Epoch 86, Step 1, LR: 0.000709, Current Loss: 0.1385, Avg Loss: 0.1385\n",
      "Diff stats — min: -7.4680, max: 10.0000, mean: 5.0207, std: 3.0651\n",
      "\n",
      "Step 2550 — Test metrics:\n",
      "  precision@10: 0.006859972\n",
      "  recall@10: 0.006883171\n",
      "  ndcg@10: 0.006895403\n",
      "  map@10: 0.002148120\n",
      "Epoch 86, Step 20, LR: 0.000709, Current Loss: 0.1338, Avg Loss: 0.1444\n",
      "Diff stats — min: -4.8562, max: 10.0000, mean: 5.0729, std: 3.0699\n",
      "\n",
      "Epoch 86 completed, Train Loss: 0.000036\n",
      "\n",
      "Epoch 87, Step 1, LR: 0.000709, Current Loss: 0.1382, Avg Loss: 0.1382\n",
      "Diff stats — min: -7.6858, max: 10.0000, mean: 5.0926, std: 3.0969\n",
      "\n",
      "Step 2580 — Test metrics:\n",
      "  precision@10: 0.006718529\n",
      "  recall@10: 0.006741729\n",
      "  ndcg@10: 0.006840078\n",
      "  map@10: 0.002163317\n",
      "Epoch 87, Step 20, LR: 0.000709, Current Loss: 0.1446, Avg Loss: 0.1384\n",
      "Diff stats — min: -7.5111, max: 10.0000, mean: 5.0290, std: 3.0999\n",
      "\n",
      "Epoch 87 completed, Train Loss: 0.000034\n",
      "\n",
      "Epoch 88, Step 1, LR: 0.000709, Current Loss: 0.1392, Avg Loss: 0.1392\n",
      "Diff stats — min: -5.6504, max: 10.0000, mean: 5.0775, std: 3.0883\n",
      "\n",
      "Step 2610 — Test metrics:\n",
      "  precision@10: 0.006812824\n",
      "  recall@10: 0.006833404\n",
      "  ndcg@10: 0.006993054\n",
      "  map@10: 0.002218488\n",
      "Epoch 88, Step 20, LR: 0.000709, Current Loss: 0.1224, Avg Loss: 0.1383\n",
      "Diff stats — min: -5.7758, max: 10.0000, mean: 5.1771, std: 3.0327\n",
      "\n",
      "Epoch 88 completed, Train Loss: 0.000034\n",
      "\n",
      "Epoch 89, Step 1, LR: 0.000709, Current Loss: 0.1363, Avg Loss: 0.1363\n",
      "Diff stats — min: -7.6517, max: 10.0000, mean: 5.1735, std: 3.1363\n",
      "\n",
      "Step 2640 — Test metrics:\n",
      "  precision@10: 0.007024988\n",
      "  recall@10: 0.007050807\n",
      "  ndcg@10: 0.007246965\n",
      "  map@10: 0.002331348\n",
      "Epoch 89, Step 20, LR: 0.000709, Current Loss: 0.1456, Avg Loss: 0.1367\n",
      "Diff stats — min: -6.9633, max: 10.0000, mean: 5.1221, std: 3.1429\n",
      "\n",
      "Epoch 89 completed, Train Loss: 0.000034\n",
      "\n",
      "Epoch 90, Step 1, LR: 0.000709, Current Loss: 0.1363, Avg Loss: 0.1363\n",
      "Diff stats — min: -8.8322, max: 10.0000, mean: 5.1409, std: 3.0840\n",
      "\n",
      "Step 2670 — Test metrics:\n",
      "  precision@10: 0.007024988\n",
      "  recall@10: 0.007048188\n",
      "  ndcg@10: 0.007061226\n",
      "  map@10: 0.002200264\n",
      "Epoch 90, Step 20, LR: 0.000709, Current Loss: 0.1357, Avg Loss: 0.1344\n",
      "Diff stats — min: -6.2895, max: 10.0000, mean: 5.1689, std: 3.1163\n",
      "\n",
      "Epoch 90 completed, Train Loss: 0.000033\n",
      "\n",
      "Epoch 91, Step 1, LR: 0.000695, Current Loss: 0.1520, Avg Loss: 0.1520\n",
      "Diff stats — min: -6.6440, max: 10.0000, mean: 5.0659, std: 3.1315\n",
      "\n",
      "Step 2700 — Test metrics:\n",
      "  precision@10: 0.007284300\n",
      "  recall@10: 0.007310119\n",
      "  ndcg@10: 0.007562842\n",
      "  map@10: 0.002445409\n",
      "Epoch 91, Step 20, LR: 0.000695, Current Loss: 0.1353, Avg Loss: 0.1341\n",
      "Diff stats — min: -7.8975, max: 10.0000, mean: 5.1564, std: 3.1203\n",
      "\n",
      "Epoch 91 completed, Train Loss: 0.000033\n",
      "\n",
      "Epoch 92, Step 1, LR: 0.000695, Current Loss: 0.1264, Avg Loss: 0.1264\n",
      "Diff stats — min: -7.4571, max: 10.0000, mean: 5.2696, std: 3.1128\n",
      "\n",
      "Step 2730 — Test metrics:\n",
      "  precision@10: 0.007237152\n",
      "  recall@10: 0.007265591\n",
      "  ndcg@10: 0.007382561\n",
      "  map@10: 0.002336418\n",
      "Epoch 92, Step 20, LR: 0.000695, Current Loss: 0.1335, Avg Loss: 0.1342\n",
      "Diff stats — min: -7.4492, max: 10.0000, mean: 5.2155, std: 3.1335\n",
      "\n",
      "Epoch 92 completed, Train Loss: 0.000033\n",
      "\n",
      "Epoch 93, Step 1, LR: 0.000695, Current Loss: 0.1338, Avg Loss: 0.1338\n",
      "Diff stats — min: -7.3426, max: 10.0000, mean: 5.1941, std: 3.0963\n",
      "\n",
      "Step 2760 — Test metrics:\n",
      "  precision@10: 0.007355021\n",
      "  recall@10: 0.007384114\n",
      "  ndcg@10: 0.007725962\n",
      "  map@10: 0.002527276\n",
      "Epoch 93, Step 20, LR: 0.000695, Current Loss: 0.1296, Avg Loss: 0.1298\n",
      "Diff stats — min: -5.4343, max: 10.0000, mean: 5.2582, std: 3.1114\n",
      "\n",
      "Epoch 93 completed, Train Loss: 0.000033\n",
      "\n",
      "Epoch 94, Step 1, LR: 0.000695, Current Loss: 0.1352, Avg Loss: 0.1352\n",
      "Diff stats — min: -7.6582, max: 10.0000, mean: 5.2809, std: 3.1387\n",
      "\n",
      "Step 2790 — Test metrics:\n",
      "  precision@10: 0.007142857\n",
      "  recall@10: 0.007166057\n",
      "  ndcg@10: 0.007665459\n",
      "  map@10: 0.002540428\n",
      "Epoch 94, Step 20, LR: 0.000695, Current Loss: 0.1328, Avg Loss: 0.1329\n",
      "Diff stats — min: -8.7360, max: 10.0000, mean: 5.1802, std: 3.0889\n",
      "\n",
      "Epoch 94 completed, Train Loss: 0.000033\n",
      "\n",
      "Epoch 95, Step 1, LR: 0.000695, Current Loss: 0.1402, Avg Loss: 0.1402\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 5.2449, std: 3.1929\n",
      "\n",
      "Step 2820 — Test metrics:\n",
      "  precision@10: 0.007307874\n",
      "  recall@10: 0.007325835\n",
      "  ndcg@10: 0.007569909\n",
      "  map@10: 0.002451235\n",
      "Epoch 95, Step 20, LR: 0.000695, Current Loss: 0.1263, Avg Loss: 0.1311\n",
      "Diff stats — min: -6.5097, max: 10.0000, mean: 5.3722, std: 3.1230\n",
      "\n",
      "Epoch 95 completed, Train Loss: 0.000033\n",
      "\n",
      "Epoch 96, Step 1, LR: 0.000681, Current Loss: 0.1297, Avg Loss: 0.1297\n",
      "Diff stats — min: -7.6650, max: 10.0000, mean: 5.3235, std: 3.1147\n",
      "\n",
      "Step 2850 — Test metrics:\n",
      "  precision@10: 0.007331447\n",
      "  recall@10: 0.007360540\n",
      "  ndcg@10: 0.007728941\n",
      "  map@10: 0.002558308\n",
      "Epoch 96, Step 20, LR: 0.000681, Current Loss: 0.1317, Avg Loss: 0.1302\n",
      "Diff stats — min: -6.1849, max: 10.0000, mean: 5.3701, std: 3.1761\n",
      "\n",
      "Epoch 96 completed, Train Loss: 0.000032\n",
      "\n",
      "Epoch 97, Step 1, LR: 0.000681, Current Loss: 0.1315, Avg Loss: 0.1315\n",
      "Diff stats — min: -7.1465, max: 10.0000, mean: 5.3301, std: 3.1190\n",
      "\n",
      "Step 2880 — Test metrics:\n",
      "  precision@10: 0.007944366\n",
      "  recall@10: 0.007976078\n",
      "  ndcg@10: 0.008255835\n",
      "  map@10: 0.002738405\n",
      "Epoch 97, Step 20, LR: 0.000681, Current Loss: 0.1327, Avg Loss: 0.1299\n",
      "Diff stats — min: -7.0537, max: 10.0000, mean: 5.3290, std: 3.1393\n",
      "\n",
      "Epoch 97 completed, Train Loss: 0.000032\n",
      "\n",
      "Epoch 98, Step 1, LR: 0.000681, Current Loss: 0.1373, Avg Loss: 0.1373\n",
      "Diff stats — min: -7.5568, max: 10.0000, mean: 5.3038, std: 3.1536\n",
      "\n",
      "Step 2910 — Test metrics:\n",
      "  precision@10: 0.007425743\n",
      "  recall@10: 0.007448942\n",
      "  ndcg@10: 0.007646248\n",
      "  map@10: 0.002459798\n",
      "Epoch 98, Step 20, LR: 0.000681, Current Loss: 0.1316, Avg Loss: 0.1297\n",
      "Diff stats — min: -5.9450, max: 10.0000, mean: 5.3741, std: 3.1543\n",
      "\n",
      "Epoch 98 completed, Train Loss: 0.000032\n",
      "\n",
      "Epoch 99, Step 1, LR: 0.000681, Current Loss: 0.1239, Avg Loss: 0.1239\n",
      "Diff stats — min: -5.3192, max: 10.0000, mean: 5.3942, std: 3.1059\n",
      "\n",
      "Step 2940 — Test metrics:\n",
      "  precision@10: 0.007449316\n",
      "  recall@10: 0.007475135\n",
      "  ndcg@10: 0.007739477\n",
      "  map@10: 0.002564422\n",
      "Epoch 99, Step 20, LR: 0.000681, Current Loss: 0.1281, Avg Loss: 0.1265\n",
      "Diff stats — min: -6.3458, max: 10.0000, mean: 5.3740, std: 3.1277\n",
      "\n",
      "Epoch 99 completed, Train Loss: 0.000031\n",
      "\n",
      "Epoch 100, Step 1, LR: 0.000681, Current Loss: 0.1125, Avg Loss: 0.1125\n",
      "Diff stats — min: -6.8982, max: 10.0000, mean: 5.4296, std: 3.1071\n",
      "\n",
      "Step 2970 — Test metrics:\n",
      "  precision@10: 0.007802923\n",
      "  recall@10: 0.007834636\n",
      "  ndcg@10: 0.008065567\n",
      "  map@10: 0.002690691\n",
      "Epoch 100, Step 20, LR: 0.000681, Current Loss: 0.1268, Avg Loss: 0.1252\n",
      "Diff stats — min: -5.8463, max: 10.0000, mean: 5.4079, std: 3.1272\n",
      "\n",
      "Epoch 100 completed, Train Loss: 0.000031\n",
      "\n",
      "Epoch 101, Step 1, LR: 0.000668, Current Loss: 0.1070, Avg Loss: 0.1070\n",
      "Diff stats — min: -5.8528, max: 10.0000, mean: 5.5069, std: 3.0774\n",
      "\n",
      "Step 3000 — Test metrics:\n",
      "  precision@10: 0.008085809\n",
      "  recall@10: 0.008109008\n",
      "  ndcg@10: 0.008148023\n",
      "  map@10: 0.002634405\n",
      "Epoch 101, Step 20, LR: 0.000668, Current Loss: 0.1282, Avg Loss: 0.1229\n",
      "Diff stats — min: -6.5212, max: 10.0000, mean: 5.4215, std: 3.1717\n",
      "\n",
      "Epoch 101 completed, Train Loss: 0.000031\n",
      "\n",
      "Epoch 102, Step 1, LR: 0.000668, Current Loss: 0.1263, Avg Loss: 0.1263\n",
      "Diff stats — min: -5.7094, max: 10.0000, mean: 5.4301, std: 3.1543\n",
      "\n",
      "Step 3030 — Test metrics:\n",
      "  precision@10: 0.008156530\n",
      "  recall@10: 0.008182349\n",
      "  ndcg@10: 0.008377142\n",
      "  map@10: 0.002777745\n",
      "Epoch 102, Step 20, LR: 0.000668, Current Loss: 0.1223, Avg Loss: 0.1226\n",
      "Diff stats — min: -4.9597, max: 10.0000, mean: 5.4516, std: 3.1009\n",
      "\n",
      "Epoch 102 completed, Train Loss: 0.000030\n",
      "\n",
      "Epoch 103, Step 1, LR: 0.000668, Current Loss: 0.1166, Avg Loss: 0.1166\n",
      "Diff stats — min: -5.7007, max: 10.0000, mean: 5.4486, std: 3.1110\n",
      "\n",
      "Step 3060 — Test metrics:\n",
      "  precision@10: 0.008321546\n",
      "  recall@10: 0.008347365\n",
      "  ndcg@10: 0.008557000\n",
      "  map@10: 0.002786458\n",
      "Epoch 103, Step 20, LR: 0.000668, Current Loss: 0.1217, Avg Loss: 0.1207\n",
      "Diff stats — min: -5.5110, max: 10.0000, mean: 5.4843, std: 3.1412\n",
      "\n",
      "Epoch 103 completed, Train Loss: 0.000030\n",
      "\n",
      "Epoch 104, Step 1, LR: 0.000668, Current Loss: 0.1199, Avg Loss: 0.1199\n",
      "Diff stats — min: -7.4345, max: 10.0000, mean: 5.5052, std: 3.1153\n",
      "\n",
      "Step 3090 — Test metrics:\n",
      "  precision@10: 0.007920792\n",
      "  recall@10: 0.007946611\n",
      "  ndcg@10: 0.008350131\n",
      "  map@10: 0.002819287\n",
      "Epoch 104, Step 20, LR: 0.000668, Current Loss: 0.1100, Avg Loss: 0.1224\n",
      "Diff stats — min: -4.8970, max: 10.0000, mean: 5.6048, std: 3.1306\n",
      "\n",
      "Epoch 104 completed, Train Loss: 0.000030\n",
      "\n",
      "Epoch 105, Step 1, LR: 0.000668, Current Loss: 0.1300, Avg Loss: 0.1300\n",
      "Diff stats — min: -6.9735, max: 10.0000, mean: 5.4165, std: 3.1678\n",
      "\n",
      "Step 3120 — Test metrics:\n",
      "  precision@10: 0.007991513\n",
      "  recall@10: 0.008019952\n",
      "  ndcg@10: 0.008280251\n",
      "  map@10: 0.002742988\n",
      "Epoch 105, Step 20, LR: 0.000668, Current Loss: 0.1164, Avg Loss: 0.1208\n",
      "Diff stats — min: -6.2618, max: 10.0000, mean: 5.5681, std: 3.1331\n",
      "\n",
      "Epoch 105 completed, Train Loss: 0.000030\n",
      "\n",
      "Epoch 106, Step 1, LR: 0.000654, Current Loss: 0.1146, Avg Loss: 0.1146\n",
      "Diff stats — min: -5.0758, max: 10.0000, mean: 5.5265, std: 3.1445\n",
      "\n",
      "Step 3150 — Test metrics:\n",
      "  precision@10: 0.008180104\n",
      "  recall@10: 0.008205923\n",
      "  ndcg@10: 0.008485253\n",
      "  map@10: 0.002805559\n",
      "Epoch 106, Step 20, LR: 0.000654, Current Loss: 0.1220, Avg Loss: 0.1193\n",
      "Diff stats — min: -7.6135, max: 10.0000, mean: 5.5460, std: 3.1539\n",
      "\n",
      "Epoch 106 completed, Train Loss: 0.000030\n",
      "\n",
      "Epoch 107, Step 1, LR: 0.000654, Current Loss: 0.1236, Avg Loss: 0.1236\n",
      "Diff stats — min: -7.0779, max: 10.0000, mean: 5.5536, std: 3.1743\n",
      "\n",
      "Step 3180 — Test metrics:\n",
      "  precision@10: 0.008156530\n",
      "  recall@10: 0.008182349\n",
      "  ndcg@10: 0.008353726\n",
      "  map@10: 0.002740543\n",
      "Epoch 107, Step 20, LR: 0.000654, Current Loss: 0.1248, Avg Loss: 0.1206\n",
      "Diff stats — min: -9.0891, max: 10.0000, mean: 5.5791, std: 3.1904\n",
      "\n",
      "Epoch 107 completed, Train Loss: 0.000030\n",
      "\n",
      "Epoch 108, Step 1, LR: 0.000654, Current Loss: 0.1272, Avg Loss: 0.1272\n",
      "Diff stats — min: -8.4752, max: 10.0000, mean: 5.5148, std: 3.1578\n",
      "\n",
      "Step 3210 — Test metrics:\n",
      "  precision@10: 0.008180104\n",
      "  recall@10: 0.008203303\n",
      "  ndcg@10: 0.008387988\n",
      "  map@10: 0.002729947\n",
      "Epoch 108, Step 20, LR: 0.000654, Current Loss: 0.1121, Avg Loss: 0.1170\n",
      "Diff stats — min: -6.5918, max: 10.0000, mean: 5.6129, std: 3.1016\n",
      "\n",
      "Epoch 108 completed, Train Loss: 0.000029\n",
      "\n",
      "Epoch 109, Step 1, LR: 0.000654, Current Loss: 0.1193, Avg Loss: 0.1193\n",
      "Diff stats — min: -4.8905, max: 10.0000, mean: 5.5203, std: 3.1257\n",
      "\n",
      "Step 3240 — Test metrics:\n",
      "  precision@10: 0.008486563\n",
      "  recall@10: 0.008509763\n",
      "  ndcg@10: 0.008538594\n",
      "  map@10: 0.002740912\n",
      "Epoch 109, Step 20, LR: 0.000654, Current Loss: 0.1239, Avg Loss: 0.1174\n",
      "Diff stats — min: -6.0399, max: 10.0000, mean: 5.5379, std: 3.1512\n",
      "\n",
      "Epoch 109 completed, Train Loss: 0.000029\n",
      "\n",
      "Epoch 110, Step 1, LR: 0.000654, Current Loss: 0.1186, Avg Loss: 0.1186\n",
      "Diff stats — min: -8.4323, max: 10.0000, mean: 5.6220, std: 3.1674\n",
      "\n",
      "Step 3270 — Test metrics:\n",
      "  precision@10: 0.008368694\n",
      "  recall@10: 0.008391894\n",
      "  ndcg@10: 0.008770622\n",
      "  map@10: 0.002891244\n",
      "Epoch 110, Step 20, LR: 0.000654, Current Loss: 0.1226, Avg Loss: 0.1148\n",
      "Diff stats — min: -6.7361, max: 10.0000, mean: 5.5906, std: 3.1707\n",
      "\n",
      "Epoch 110 completed, Train Loss: 0.000029\n",
      "\n",
      "Epoch 111, Step 1, LR: 0.000641, Current Loss: 0.1230, Avg Loss: 0.1230\n",
      "Diff stats — min: -6.1678, max: 10.0000, mean: 5.5708, std: 3.1722\n",
      "\n",
      "Step 3300 — Test metrics:\n",
      "  precision@10: 0.008297973\n",
      "  recall@10: 0.008323792\n",
      "  ndcg@10: 0.008770133\n",
      "  map@10: 0.002926472\n",
      "Epoch 111, Step 20, LR: 0.000641, Current Loss: 0.1159, Avg Loss: 0.1171\n",
      "Diff stats — min: -5.9439, max: 10.0000, mean: 5.6049, std: 3.1627\n",
      "\n",
      "Epoch 111 completed, Train Loss: 0.000029\n",
      "\n",
      "Epoch 112, Step 1, LR: 0.000641, Current Loss: 0.1088, Avg Loss: 0.1088\n",
      "Diff stats — min: -6.0758, max: 10.0000, mean: 5.6508, std: 3.1153\n",
      "\n",
      "Step 3330 — Test metrics:\n",
      "  precision@10: 0.008345120\n",
      "  recall@10: 0.008370939\n",
      "  ndcg@10: 0.008802632\n",
      "  map@10: 0.002926720\n",
      "Epoch 112, Step 20, LR: 0.000641, Current Loss: 0.1191, Avg Loss: 0.1138\n",
      "Diff stats — min: -7.2301, max: 10.0000, mean: 5.6427, std: 3.1822\n",
      "\n",
      "Epoch 112 completed, Train Loss: 0.000028\n",
      "\n",
      "Epoch 113, Step 1, LR: 0.000641, Current Loss: 0.1115, Avg Loss: 0.1115\n",
      "Diff stats — min: -5.7329, max: 10.0000, mean: 5.6386, std: 3.1220\n",
      "\n",
      "Step 3360 — Test metrics:\n",
      "  precision@10: 0.008604432\n",
      "  recall@10: 0.008635489\n",
      "  ndcg@10: 0.008964914\n",
      "  map@10: 0.002964026\n",
      "Epoch 113, Step 20, LR: 0.000641, Current Loss: 0.1211, Avg Loss: 0.1135\n",
      "Diff stats — min: -7.5757, max: 10.0000, mean: 5.6506, std: 3.1967\n",
      "\n",
      "Epoch 113 completed, Train Loss: 0.000028\n",
      "\n",
      "Epoch 114, Step 1, LR: 0.000641, Current Loss: 0.1026, Avg Loss: 0.1026\n",
      "Diff stats — min: -5.8755, max: 10.0000, mean: 5.7860, std: 3.1141\n",
      "\n",
      "Step 3390 — Test metrics:\n",
      "  precision@10: 0.008557284\n",
      "  recall@10: 0.008585723\n",
      "  ndcg@10: 0.008958058\n",
      "  map@10: 0.002983094\n",
      "Epoch 114, Step 20, LR: 0.000641, Current Loss: 0.1142, Avg Loss: 0.1148\n",
      "Diff stats — min: -6.3628, max: 10.0000, mean: 5.6774, std: 3.1484\n",
      "\n",
      "Epoch 114 completed, Train Loss: 0.000028\n",
      "\n",
      "Epoch 115, Step 1, LR: 0.000641, Current Loss: 0.1048, Avg Loss: 0.1048\n",
      "Diff stats — min: -7.6894, max: 10.0000, mean: 5.7441, std: 3.1165\n",
      "\n",
      "Step 3420 — Test metrics:\n",
      "  precision@10: 0.008793022\n",
      "  recall@10: 0.008826699\n",
      "  ndcg@10: 0.009057076\n",
      "  map@10: 0.002990260\n",
      "Epoch 115, Step 20, LR: 0.000641, Current Loss: 0.1064, Avg Loss: 0.1123\n",
      "Diff stats — min: -6.2941, max: 10.0000, mean: 5.7817, std: 3.1533\n",
      "\n",
      "Epoch 115 completed, Train Loss: 0.000028\n",
      "\n",
      "Epoch 116, Step 1, LR: 0.000628, Current Loss: 0.1153, Avg Loss: 0.1153\n",
      "Diff stats — min: -6.8176, max: 10.0000, mean: 5.6791, std: 3.1782\n",
      "\n",
      "Step 3450 — Test metrics:\n",
      "  precision@10: 0.009052334\n",
      "  recall@10: 0.009080772\n",
      "  ndcg@10: 0.009216768\n",
      "  map@10: 0.003013061\n",
      "Epoch 116, Step 20, LR: 0.000628, Current Loss: 0.1091, Avg Loss: 0.1136\n",
      "Diff stats — min: -4.6554, max: 10.0000, mean: 5.7692, std: 3.1496\n",
      "\n",
      "Epoch 116 completed, Train Loss: 0.000028\n",
      "\n",
      "Epoch 117, Step 1, LR: 0.000628, Current Loss: 0.1062, Avg Loss: 0.1062\n",
      "Diff stats — min: -7.6201, max: 10.0000, mean: 5.7327, std: 3.1059\n",
      "\n",
      "Step 3480 — Test metrics:\n",
      "  precision@10: 0.008604432\n",
      "  recall@10: 0.008640354\n",
      "  ndcg@10: 0.009081242\n",
      "  map@10: 0.003089744\n",
      "Epoch 117, Step 20, LR: 0.000628, Current Loss: 0.1161, Avg Loss: 0.1102\n",
      "Diff stats — min: -5.9784, max: 10.0000, mean: 5.6751, std: 3.1427\n",
      "\n",
      "Epoch 117 completed, Train Loss: 0.000027\n",
      "\n",
      "Epoch 118, Step 1, LR: 0.000628, Current Loss: 0.1011, Avg Loss: 0.1011\n",
      "Diff stats — min: -7.9044, max: 10.0000, mean: 5.8290, std: 3.1186\n",
      "\n",
      "Step 3510 — Test metrics:\n",
      "  precision@10: 0.008863744\n",
      "  recall@10: 0.008892182\n",
      "  ndcg@10: 0.009445390\n",
      "  map@10: 0.003213860\n",
      "Epoch 118, Step 20, LR: 0.000628, Current Loss: 0.1093, Avg Loss: 0.1103\n",
      "Diff stats — min: -7.8022, max: 10.0000, mean: 5.7919, std: 3.1612\n",
      "\n",
      "Epoch 118 completed, Train Loss: 0.000027\n",
      "\n",
      "Epoch 119, Step 1, LR: 0.000628, Current Loss: 0.1151, Avg Loss: 0.1151\n",
      "Diff stats — min: -7.5132, max: 10.0000, mean: 5.7925, std: 3.1765\n",
      "\n",
      "Step 3540 — Test metrics:\n",
      "  precision@10: 0.009052334\n",
      "  recall@10: 0.009080772\n",
      "  ndcg@10: 0.009630562\n",
      "  map@10: 0.003295039\n",
      "Epoch 119, Step 20, LR: 0.000628, Current Loss: 0.1093, Avg Loss: 0.1070\n",
      "Diff stats — min: -5.7740, max: 10.0000, mean: 5.7495, std: 3.1618\n",
      "\n",
      "Epoch 119 completed, Train Loss: 0.000027\n",
      "\n",
      "Epoch 120, Step 1, LR: 0.000628, Current Loss: 0.0941, Avg Loss: 0.0941\n",
      "Diff stats — min: -7.4406, max: 10.0000, mean: 5.8227, std: 3.1026\n",
      "\n",
      "Step 3570 — Test metrics:\n",
      "  precision@10: 0.009193777\n",
      "  recall@10: 0.009222215\n",
      "  ndcg@10: 0.009787293\n",
      "  map@10: 0.003333550\n",
      "Epoch 120, Step 20, LR: 0.000628, Current Loss: 0.1040, Avg Loss: 0.1080\n",
      "Diff stats — min: -6.8196, max: 10.0000, mean: 5.9397, std: 3.1541\n",
      "\n",
      "Epoch 120 completed, Train Loss: 0.000027\n",
      "\n",
      "Epoch 121, Step 1, LR: 0.000616, Current Loss: 0.1125, Avg Loss: 0.1125\n",
      "Diff stats — min: -6.9948, max: 10.0000, mean: 5.7774, std: 3.1614\n",
      "\n",
      "Step 3600 — Test metrics:\n",
      "  precision@10: 0.009123055\n",
      "  recall@10: 0.009154113\n",
      "  ndcg@10: 0.009465059\n",
      "  map@10: 0.003168713\n",
      "Epoch 121, Step 20, LR: 0.000616, Current Loss: 0.1116, Avg Loss: 0.1076\n",
      "Diff stats — min: -6.5621, max: 10.0000, mean: 5.8274, std: 3.1815\n",
      "\n",
      "Epoch 121 completed, Train Loss: 0.000027\n",
      "\n",
      "Epoch 122, Step 1, LR: 0.000616, Current Loss: 0.0948, Avg Loss: 0.0948\n",
      "Diff stats — min: -4.5032, max: 10.0000, mean: 5.8466, std: 3.1041\n",
      "\n",
      "Step 3630 — Test metrics:\n",
      "  precision@10: 0.008981612\n",
      "  recall@10: 0.009010051\n",
      "  ndcg@10: 0.009484744\n",
      "  map@10: 0.003262683\n",
      "Epoch 122, Step 20, LR: 0.000616, Current Loss: 0.1010, Avg Loss: 0.1062\n",
      "Diff stats — min: -6.0517, max: 10.0000, mean: 5.8863, std: 3.1242\n",
      "\n",
      "Epoch 122 completed, Train Loss: 0.000026\n",
      "\n",
      "Epoch 123, Step 1, LR: 0.000616, Current Loss: 0.1026, Avg Loss: 0.1026\n",
      "Diff stats — min: -5.2395, max: 10.0000, mean: 5.9030, std: 3.1455\n",
      "\n",
      "Step 3660 — Test metrics:\n",
      "  precision@10: 0.008934465\n",
      "  recall@10: 0.008960284\n",
      "  ndcg@10: 0.009294556\n",
      "  map@10: 0.003146988\n",
      "Epoch 123, Step 20, LR: 0.000616, Current Loss: 0.1152, Avg Loss: 0.1054\n",
      "Diff stats — min: -6.1624, max: 10.0000, mean: 5.8988, std: 3.1971\n",
      "\n",
      "Epoch 123 completed, Train Loss: 0.000026\n",
      "\n",
      "Epoch 124, Step 1, LR: 0.000616, Current Loss: 0.1148, Avg Loss: 0.1148\n",
      "Diff stats — min: -6.8164, max: 10.0000, mean: 5.9185, std: 3.2082\n",
      "\n",
      "Step 3690 — Test metrics:\n",
      "  precision@10: 0.009193777\n",
      "  recall@10: 0.009228108\n",
      "  ndcg@10: 0.009527652\n",
      "  map@10: 0.003180500\n",
      "Epoch 124, Step 20, LR: 0.000616, Current Loss: 0.1146, Avg Loss: 0.1067\n",
      "Diff stats — min: -7.8170, max: 10.0000, mean: 5.8877, std: 3.1807\n",
      "\n",
      "Epoch 124 completed, Train Loss: 0.000026\n",
      "\n",
      "Epoch 125, Step 1, LR: 0.000616, Current Loss: 0.1067, Avg Loss: 0.1067\n",
      "Diff stats — min: -6.6621, max: 10.0000, mean: 5.9434, std: 3.1663\n",
      "\n",
      "Step 3720 — Test metrics:\n",
      "  precision@10: 0.009028760\n",
      "  recall@10: 0.009059818\n",
      "  ndcg@10: 0.009487486\n",
      "  map@10: 0.003196147\n",
      "Epoch 125, Step 20, LR: 0.000616, Current Loss: 0.1004, Avg Loss: 0.1023\n",
      "Diff stats — min: -6.4235, max: 10.0000, mean: 6.0115, std: 3.1516\n",
      "\n",
      "Epoch 125 completed, Train Loss: 0.000026\n",
      "\n",
      "Epoch 126, Step 1, LR: 0.000603, Current Loss: 0.0942, Avg Loss: 0.0942\n",
      "Diff stats — min: -6.9629, max: 10.0000, mean: 5.9822, std: 3.1198\n",
      "\n",
      "Step 3750 — Test metrics:\n",
      "  precision@10: 0.009075908\n",
      "  recall@10: 0.009106965\n",
      "  ndcg@10: 0.009318571\n",
      "  map@10: 0.003104359\n",
      "Epoch 126, Step 20, LR: 0.000603, Current Loss: 0.1062, Avg Loss: 0.1017\n",
      "Diff stats — min: -6.7525, max: 10.0000, mean: 5.9986, std: 3.1778\n",
      "\n",
      "Epoch 126 completed, Train Loss: 0.000025\n",
      "\n",
      "Epoch 127, Step 1, LR: 0.000603, Current Loss: 0.0978, Avg Loss: 0.0978\n",
      "Diff stats — min: -5.7265, max: 10.0000, mean: 5.9819, std: 3.1409\n",
      "\n",
      "Step 3780 — Test metrics:\n",
      "  precision@10: 0.008981612\n",
      "  recall@10: 0.009018563\n",
      "  ndcg@10: 0.009640592\n",
      "  map@10: 0.003326125\n",
      "Epoch 127, Step 20, LR: 0.000603, Current Loss: 0.1112, Avg Loss: 0.1042\n",
      "Diff stats — min: -8.4834, max: 10.0000, mean: 5.9355, std: 3.1926\n",
      "\n",
      "Epoch 127 completed, Train Loss: 0.000026\n",
      "\n",
      "Epoch 128, Step 1, LR: 0.000603, Current Loss: 0.0925, Avg Loss: 0.0925\n",
      "Diff stats — min: -5.0956, max: 10.0000, mean: 6.0619, std: 3.1307\n",
      "\n",
      "Step 3810 — Test metrics:\n",
      "  precision@10: 0.009264498\n",
      "  recall@10: 0.009292936\n",
      "  ndcg@10: 0.009691099\n",
      "  map@10: 0.003287926\n",
      "Epoch 128, Step 20, LR: 0.000603, Current Loss: 0.1071, Avg Loss: 0.1017\n",
      "Diff stats — min: -6.9813, max: 10.0000, mean: 5.9224, std: 3.1778\n",
      "\n",
      "Epoch 128 completed, Train Loss: 0.000025\n",
      "\n",
      "Epoch 129, Step 1, LR: 0.000603, Current Loss: 0.0951, Avg Loss: 0.0951\n",
      "Diff stats — min: -5.7161, max: 10.0000, mean: 6.0756, std: 3.1351\n",
      "\n",
      "Step 3840 — Test metrics:\n",
      "  precision@10: 0.009335219\n",
      "  recall@10: 0.009363657\n",
      "  ndcg@10: 0.009902137\n",
      "  map@10: 0.003390023\n",
      "Epoch 129, Step 20, LR: 0.000603, Current Loss: 0.1028, Avg Loss: 0.1010\n",
      "Diff stats — min: -7.3077, max: 10.0000, mean: 6.0861, std: 3.1659\n",
      "\n",
      "Epoch 129 completed, Train Loss: 0.000025\n",
      "\n",
      "Epoch 130, Step 1, LR: 0.000603, Current Loss: 0.1036, Avg Loss: 0.1036\n",
      "Diff stats — min: -7.6086, max: 10.0000, mean: 6.0179, std: 3.1852\n",
      "\n",
      "Step 3870 — Test metrics:\n",
      "  precision@10: 0.009335219\n",
      "  recall@10: 0.009366277\n",
      "  ndcg@10: 0.009794904\n",
      "  map@10: 0.003314910\n",
      "Epoch 130, Step 20, LR: 0.000603, Current Loss: 0.0989, Avg Loss: 0.1028\n",
      "Diff stats — min: -6.9846, max: 10.0000, mean: 5.9724, std: 3.1621\n",
      "\n",
      "Epoch 130 completed, Train Loss: 0.000025\n",
      "\n",
      "Epoch 131, Step 1, LR: 0.000591, Current Loss: 0.0915, Avg Loss: 0.0915\n",
      "Diff stats — min: -5.8800, max: 10.0000, mean: 6.0201, std: 3.0814\n",
      "\n",
      "Step 3900 — Test metrics:\n",
      "  precision@10: 0.009382367\n",
      "  recall@10: 0.009426802\n",
      "  ndcg@10: 0.009954422\n",
      "  map@10: 0.003391637\n",
      "Epoch 131, Step 20, LR: 0.000591, Current Loss: 0.1014, Avg Loss: 0.1006\n",
      "Diff stats — min: -6.1409, max: 10.0000, mean: 6.0423, std: 3.1747\n",
      "\n",
      "Epoch 131 completed, Train Loss: 0.000025\n",
      "\n",
      "Epoch 132, Step 1, LR: 0.000591, Current Loss: 0.1033, Avg Loss: 0.1033\n",
      "Diff stats — min: -5.3201, max: 10.0000, mean: 6.0323, std: 3.1890\n",
      "\n",
      "Step 3930 — Test metrics:\n",
      "  precision@10: 0.009547383\n",
      "  recall@10: 0.009581060\n",
      "  ndcg@10: 0.010089236\n",
      "  map@10: 0.003436157\n",
      "Epoch 132, Step 20, LR: 0.000591, Current Loss: 0.1065, Avg Loss: 0.1023\n",
      "Diff stats — min: -5.2565, max: 10.0000, mean: 5.9296, std: 3.1840\n",
      "\n",
      "Epoch 132 completed, Train Loss: 0.000025\n",
      "\n",
      "Epoch 133, Step 1, LR: 0.000591, Current Loss: 0.1035, Avg Loss: 0.1035\n",
      "Diff stats — min: -5.3040, max: 10.0000, mean: 6.0529, std: 3.1527\n",
      "\n",
      "Step 3960 — Test metrics:\n",
      "  precision@10: 0.009500236\n",
      "  recall@10: 0.009533913\n",
      "  ndcg@10: 0.009897323\n",
      "  map@10: 0.003343437\n",
      "Epoch 133, Step 20, LR: 0.000591, Current Loss: 0.0938, Avg Loss: 0.0993\n",
      "Diff stats — min: -6.2693, max: 10.0000, mean: 6.0661, std: 3.1166\n",
      "\n",
      "Epoch 133 completed, Train Loss: 0.000025\n",
      "\n",
      "Epoch 134, Step 1, LR: 0.000591, Current Loss: 0.1044, Avg Loss: 0.1044\n",
      "Diff stats — min: -6.7303, max: 10.0000, mean: 5.9915, std: 3.1765\n",
      "\n",
      "Step 3990 — Test metrics:\n",
      "  precision@10: 0.009924564\n",
      "  recall@10: 0.009970028\n",
      "  ndcg@10: 0.010447179\n",
      "  map@10: 0.003583144\n",
      "Epoch 134, Step 20, LR: 0.000591, Current Loss: 0.0987, Avg Loss: 0.0982\n",
      "Diff stats — min: -4.9619, max: 10.0000, mean: 6.0991, std: 3.1429\n",
      "\n",
      "Epoch 134 completed, Train Loss: 0.000024\n",
      "\n",
      "Epoch 135, Step 1, LR: 0.000591, Current Loss: 0.0980, Avg Loss: 0.0980\n",
      "Diff stats — min: -5.5959, max: 10.0000, mean: 6.1444, std: 3.1421\n",
      "\n",
      "Step 4020 — Test metrics:\n",
      "  precision@10: 0.009806695\n",
      "  recall@10: 0.009846265\n",
      "  ndcg@10: 0.010076402\n",
      "  map@10: 0.003404018\n",
      "Epoch 135, Step 20, LR: 0.000591, Current Loss: 0.1098, Avg Loss: 0.0969\n",
      "Diff stats — min: -7.8230, max: 10.0000, mean: 5.9968, std: 3.2106\n",
      "\n",
      "Epoch 135 completed, Train Loss: 0.000024\n",
      "\n",
      "Epoch 136, Step 1, LR: 0.000580, Current Loss: 0.1027, Avg Loss: 0.1027\n",
      "Diff stats — min: -9.1653, max: 10.0000, mean: 6.1225, std: 3.2013\n",
      "\n",
      "Step 4050 — Test metrics:\n",
      "  precision@10: 0.009500236\n",
      "  recall@10: 0.009531293\n",
      "  ndcg@10: 0.009806110\n",
      "  map@10: 0.003311381\n",
      "Epoch 136, Step 20, LR: 0.000580, Current Loss: 0.1024, Avg Loss: 0.0988\n",
      "Diff stats — min: -7.1363, max: 10.0000, mean: 6.1096, std: 3.1776\n",
      "\n",
      "Epoch 136 completed, Train Loss: 0.000024\n",
      "\n",
      "Epoch 137, Step 1, LR: 0.000580, Current Loss: 0.1047, Avg Loss: 0.1047\n",
      "Diff stats — min: -6.7782, max: 10.0000, mean: 6.0695, std: 3.1818\n",
      "\n",
      "Step 4080 — Test metrics:\n",
      "  precision@10: 0.009665252\n",
      "  recall@10: 0.009693690\n",
      "  ndcg@10: 0.009961513\n",
      "  map@10: 0.003391003\n",
      "Epoch 137, Step 20, LR: 0.000580, Current Loss: 0.0935, Avg Loss: 0.0963\n",
      "Diff stats — min: -6.4381, max: 10.0000, mean: 6.1320, std: 3.1416\n",
      "\n",
      "Epoch 137 completed, Train Loss: 0.000024\n",
      "\n",
      "Epoch 138, Step 1, LR: 0.000580, Current Loss: 0.1067, Avg Loss: 0.1067\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 6.0723, std: 3.1648\n",
      "\n",
      "Step 4110 — Test metrics:\n",
      "  precision@10: 0.009594531\n",
      "  recall@10: 0.009625588\n",
      "  ndcg@10: 0.009815892\n",
      "  map@10: 0.003313463\n",
      "Epoch 138, Step 20, LR: 0.000580, Current Loss: 0.1003, Avg Loss: 0.0968\n",
      "Diff stats — min: -6.4096, max: 10.0000, mean: 6.1371, std: 3.1874\n",
      "\n",
      "Epoch 138 completed, Train Loss: 0.000024\n",
      "\n",
      "Epoch 139, Step 1, LR: 0.000580, Current Loss: 0.1012, Avg Loss: 0.1012\n",
      "Diff stats — min: -7.5740, max: 10.0000, mean: 6.1724, std: 3.1578\n",
      "\n",
      "Step 4140 — Test metrics:\n",
      "  precision@10: 0.009971711\n",
      "  recall@10: 0.010021385\n",
      "  ndcg@10: 0.010370237\n",
      "  map@10: 0.003546742\n",
      "Epoch 139, Step 20, LR: 0.000580, Current Loss: 0.0959, Avg Loss: 0.0980\n",
      "Diff stats — min: -6.4044, max: 10.0000, mean: 6.1663, std: 3.1628\n",
      "\n",
      "Epoch 139 completed, Train Loss: 0.000024\n",
      "\n",
      "Epoch 140, Step 1, LR: 0.000580, Current Loss: 0.1000, Avg Loss: 0.1000\n",
      "Diff stats — min: -7.7695, max: 10.0000, mean: 6.1844, std: 3.1482\n",
      "\n",
      "Step 4170 — Test metrics:\n",
      "  precision@10: 0.010042433\n",
      "  recall@10: 0.010079384\n",
      "  ndcg@10: 0.010118382\n",
      "  map@10: 0.003345289\n",
      "Epoch 140, Step 20, LR: 0.000580, Current Loss: 0.0987, Avg Loss: 0.0943\n",
      "Diff stats — min: -5.7802, max: 10.0000, mean: 6.2106, std: 3.1770\n",
      "\n",
      "Epoch 140 completed, Train Loss: 0.000023\n",
      "\n",
      "Epoch 141, Step 1, LR: 0.000568, Current Loss: 0.0909, Avg Loss: 0.0909\n",
      "Diff stats — min: -5.6970, max: 10.0000, mean: 6.2063, std: 3.0989\n",
      "\n",
      "Step 4200 — Test metrics:\n",
      "  precision@10: 0.010136728\n",
      "  recall@10: 0.010186401\n",
      "  ndcg@10: 0.010249724\n",
      "  map@10: 0.003423685\n",
      "Epoch 141, Step 20, LR: 0.000568, Current Loss: 0.0927, Avg Loss: 0.0942\n",
      "Diff stats — min: -6.0962, max: 10.0000, mean: 6.1781, std: 3.1625\n",
      "\n",
      "Epoch 141 completed, Train Loss: 0.000023\n",
      "\n",
      "Epoch 142, Step 1, LR: 0.000568, Current Loss: 0.0916, Avg Loss: 0.0916\n",
      "Diff stats — min: -5.9645, max: 10.0000, mean: 6.1962, std: 3.1374\n",
      "\n",
      "Step 4230 — Test metrics:\n",
      "  precision@10: 0.010113154\n",
      "  recall@10: 0.010146831\n",
      "  ndcg@10: 0.010473499\n",
      "  map@10: 0.003580514\n",
      "Epoch 142, Step 20, LR: 0.000568, Current Loss: 0.0952, Avg Loss: 0.0950\n",
      "Diff stats — min: -6.2132, max: 10.0000, mean: 6.1628, std: 3.1608\n",
      "\n",
      "Epoch 142 completed, Train Loss: 0.000023\n",
      "\n",
      "Epoch 143, Step 1, LR: 0.000568, Current Loss: 0.0937, Avg Loss: 0.0937\n",
      "Diff stats — min: -5.7308, max: 10.0000, mean: 6.1985, std: 3.1241\n",
      "\n",
      "Step 4260 — Test metrics:\n",
      "  precision@10: 0.010254597\n",
      "  recall@10: 0.010306890\n",
      "  ndcg@10: 0.010374750\n",
      "  map@10: 0.003478334\n",
      "Epoch 143, Step 20, LR: 0.000568, Current Loss: 0.0912, Avg Loss: 0.0917\n",
      "Diff stats — min: -5.8546, max: 10.0000, mean: 6.3316, std: 3.1338\n",
      "\n",
      "Epoch 143 completed, Train Loss: 0.000023\n",
      "\n",
      "Epoch 144, Step 1, LR: 0.000568, Current Loss: 0.0947, Avg Loss: 0.0947\n",
      "Diff stats — min: -6.4437, max: 10.0000, mean: 6.2538, std: 3.1783\n",
      "\n",
      "Step 4290 — Test metrics:\n",
      "  precision@10: 0.009971711\n",
      "  recall@10: 0.010017175\n",
      "  ndcg@10: 0.010360322\n",
      "  map@10: 0.003483881\n",
      "Epoch 144, Step 20, LR: 0.000568, Current Loss: 0.1002, Avg Loss: 0.0919\n",
      "Diff stats — min: -4.9718, max: 10.0000, mean: 6.2019, std: 3.1867\n",
      "\n",
      "Epoch 144 completed, Train Loss: 0.000023\n",
      "\n",
      "Epoch 145, Step 1, LR: 0.000568, Current Loss: 0.0960, Avg Loss: 0.0960\n",
      "Diff stats — min: -6.1721, max: 10.0000, mean: 6.2091, std: 3.1368\n",
      "\n",
      "Step 4320 — Test metrics:\n",
      "  precision@10: 0.010042433\n",
      "  recall@10: 0.010089487\n",
      "  ndcg@10: 0.010394519\n",
      "  map@10: 0.003546173\n",
      "Epoch 145, Step 20, LR: 0.000568, Current Loss: 0.0956, Avg Loss: 0.0914\n",
      "Diff stats — min: -4.7760, max: 10.0000, mean: 6.2229, std: 3.1794\n",
      "\n",
      "Epoch 145 completed, Train Loss: 0.000023\n",
      "\n",
      "Epoch 146, Step 1, LR: 0.000557, Current Loss: 0.0846, Avg Loss: 0.0846\n",
      "Diff stats — min: -5.7817, max: 10.0000, mean: 6.2535, std: 3.0980\n",
      "\n",
      "Step 4350 — Test metrics:\n",
      "  precision@10: 0.010113154\n",
      "  recall@10: 0.010152724\n",
      "  ndcg@10: 0.010511081\n",
      "  map@10: 0.003579786\n",
      "Epoch 146, Step 20, LR: 0.000557, Current Loss: 0.1006, Avg Loss: 0.0919\n",
      "Diff stats — min: -7.1338, max: 10.0000, mean: 6.2451, std: 3.1724\n",
      "\n",
      "Epoch 146 completed, Train Loss: 0.000023\n",
      "\n",
      "Epoch 147, Step 1, LR: 0.000557, Current Loss: 0.0835, Avg Loss: 0.0835\n",
      "Diff stats — min: -5.4032, max: 10.0000, mean: 6.3445, std: 3.1060\n",
      "\n",
      "Step 4380 — Test metrics:\n",
      "  precision@10: 0.010278171\n",
      "  recall@10: 0.010322605\n",
      "  ndcg@10: 0.010519249\n",
      "  map@10: 0.003558478\n",
      "Epoch 147, Step 20, LR: 0.000557, Current Loss: 0.0900, Avg Loss: 0.0917\n",
      "Diff stats — min: -5.8352, max: 10.0000, mean: 6.3032, std: 3.1412\n",
      "\n",
      "Epoch 147 completed, Train Loss: 0.000023\n",
      "\n",
      "Epoch 148, Step 1, LR: 0.000557, Current Loss: 0.0952, Avg Loss: 0.0952\n",
      "Diff stats — min: -5.8445, max: 10.0000, mean: 6.3458, std: 3.1594\n",
      "\n",
      "Step 4410 — Test metrics:\n",
      "  precision@10: 0.010348892\n",
      "  recall@10: 0.010390053\n",
      "  ndcg@10: 0.010795874\n",
      "  map@10: 0.003710336\n",
      "Epoch 148, Step 20, LR: 0.000557, Current Loss: 0.0939, Avg Loss: 0.0899\n",
      "Diff stats — min: -5.6320, max: 10.0000, mean: 6.2642, std: 3.1511\n",
      "\n",
      "Epoch 148 completed, Train Loss: 0.000022\n",
      "\n",
      "Epoch 149, Step 1, LR: 0.000557, Current Loss: 0.0886, Avg Loss: 0.0886\n",
      "Diff stats — min: -6.2913, max: 10.0000, mean: 6.3195, std: 3.1513\n",
      "\n",
      "Step 4440 — Test metrics:\n",
      "  precision@10: 0.010207449\n",
      "  recall@10: 0.010247020\n",
      "  ndcg@10: 0.010647220\n",
      "  map@10: 0.003672638\n",
      "Epoch 149, Step 20, LR: 0.000557, Current Loss: 0.0915, Avg Loss: 0.0921\n",
      "Diff stats — min: -6.8670, max: 10.0000, mean: 6.3798, std: 3.1511\n",
      "\n",
      "Epoch 149 completed, Train Loss: 0.000023\n",
      "\n",
      "Epoch 150, Step 1, LR: 0.000557, Current Loss: 0.0955, Avg Loss: 0.0955\n",
      "Diff stats — min: -7.8236, max: 10.0000, mean: 6.3503, std: 3.1580\n",
      "\n",
      "Step 4470 — Test metrics:\n",
      "  precision@10: 0.010136728\n",
      "  recall@10: 0.010180508\n",
      "  ndcg@10: 0.010520397\n",
      "  map@10: 0.003597850\n",
      "Epoch 150, Step 20, LR: 0.000557, Current Loss: 0.1012, Avg Loss: 0.0912\n",
      "Diff stats — min: -6.5036, max: 10.0000, mean: 6.2451, std: 3.1866\n",
      "\n",
      "Epoch 150 completed, Train Loss: 0.000022\n",
      "\n",
      "Epoch 151, Step 1, LR: 0.000545, Current Loss: 0.0877, Avg Loss: 0.0877\n",
      "Diff stats — min: -5.4025, max: 10.0000, mean: 6.3591, std: 3.1365\n",
      "\n",
      "Step 4500 — Test metrics:\n",
      "  precision@10: 0.009971711\n",
      "  recall@10: 0.010006043\n",
      "  ndcg@10: 0.010438684\n",
      "  map@10: 0.003588900\n",
      "Epoch 151, Step 20, LR: 0.000545, Current Loss: 0.0864, Avg Loss: 0.0893\n",
      "Diff stats — min: -6.5092, max: 10.0000, mean: 6.2861, std: 3.0963\n",
      "\n",
      "Epoch 151 completed, Train Loss: 0.000022\n",
      "\n",
      "Epoch 152, Step 1, LR: 0.000545, Current Loss: 0.0883, Avg Loss: 0.0883\n",
      "Diff stats — min: -6.4523, max: 10.0000, mean: 6.3340, std: 3.1295\n",
      "\n",
      "Step 4530 — Test metrics:\n",
      "  precision@10: 0.010113154\n",
      "  recall@10: 0.010157589\n",
      "  ndcg@10: 0.010323874\n",
      "  map@10: 0.003469933\n",
      "Epoch 152, Step 20, LR: 0.000545, Current Loss: 0.0946, Avg Loss: 0.0885\n",
      "Diff stats — min: -4.7205, max: 10.0000, mean: 6.3332, std: 3.1913\n",
      "\n",
      "Epoch 152 completed, Train Loss: 0.000022\n",
      "\n",
      "Epoch 153, Step 1, LR: 0.000545, Current Loss: 0.0829, Avg Loss: 0.0829\n",
      "Diff stats — min: -5.1407, max: 10.0000, mean: 6.3450, std: 3.1271\n",
      "\n",
      "Step 4560 — Test metrics:\n",
      "  precision@10: 0.010419613\n",
      "  recall@10: 0.010456564\n",
      "  ndcg@10: 0.010744811\n",
      "  map@10: 0.003668596\n",
      "Epoch 153, Step 20, LR: 0.000545, Current Loss: 0.0785, Avg Loss: 0.0870\n",
      "Diff stats — min: -5.0470, max: 10.0000, mean: 6.3270, std: 3.0826\n",
      "\n",
      "Epoch 153 completed, Train Loss: 0.000021\n",
      "\n",
      "Epoch 154, Step 1, LR: 0.000545, Current Loss: 0.0864, Avg Loss: 0.0864\n",
      "Diff stats — min: -5.7625, max: 10.0000, mean: 6.3693, std: 3.1393\n",
      "\n",
      "Step 4590 — Test metrics:\n",
      "  precision@10: 0.010348892\n",
      "  recall@10: 0.010387433\n",
      "  ndcg@10: 0.010583418\n",
      "  map@10: 0.003569685\n",
      "Epoch 154, Step 20, LR: 0.000545, Current Loss: 0.0798, Avg Loss: 0.0858\n",
      "Diff stats — min: -6.8376, max: 10.0000, mean: 6.3902, std: 3.1122\n",
      "\n",
      "Epoch 154 completed, Train Loss: 0.000021\n",
      "\n",
      "Epoch 155, Step 1, LR: 0.000545, Current Loss: 0.0759, Avg Loss: 0.0759\n",
      "Diff stats — min: -5.8803, max: 10.0000, mean: 6.4439, std: 3.0795\n",
      "\n",
      "Step 4620 — Test metrics:\n",
      "  precision@10: 0.010749646\n",
      "  recall@10: 0.010790807\n",
      "  ndcg@10: 0.011094037\n",
      "  map@10: 0.003824290\n",
      "Epoch 155, Step 20, LR: 0.000545, Current Loss: 0.0865, Avg Loss: 0.0858\n",
      "Diff stats — min: -7.3581, max: 10.0000, mean: 6.3587, std: 3.1387\n",
      "\n",
      "Epoch 155 completed, Train Loss: 0.000022\n",
      "\n",
      "Epoch 156, Step 1, LR: 0.000535, Current Loss: 0.0791, Avg Loss: 0.0791\n",
      "Diff stats — min: -9.8397, max: 10.0000, mean: 6.4617, std: 3.0757\n",
      "\n",
      "Step 4650 — Test metrics:\n",
      "  precision@10: 0.010490335\n",
      "  recall@10: 0.010534115\n",
      "  ndcg@10: 0.010818145\n",
      "  map@10: 0.003700524\n",
      "Epoch 156, Step 20, LR: 0.000535, Current Loss: 0.0883, Avg Loss: 0.0845\n",
      "Diff stats — min: -7.2769, max: 10.0000, mean: 6.3422, std: 3.1315\n",
      "\n",
      "Epoch 156 completed, Train Loss: 0.000021\n",
      "\n",
      "Epoch 157, Step 1, LR: 0.000535, Current Loss: 0.0916, Avg Loss: 0.0916\n",
      "Diff stats — min: -5.9561, max: 10.0000, mean: 6.4360, std: 3.1478\n",
      "\n",
      "Step 4680 — Test metrics:\n",
      "  precision@10: 0.010325318\n",
      "  recall@10: 0.010363860\n",
      "  ndcg@10: 0.010553115\n",
      "  map@10: 0.003568432\n",
      "Epoch 157, Step 20, LR: 0.000535, Current Loss: 0.0807, Avg Loss: 0.0860\n",
      "Diff stats — min: -6.6293, max: 10.0000, mean: 6.5004, std: 3.0875\n",
      "\n",
      "Epoch 157 completed, Train Loss: 0.000021\n",
      "\n",
      "Epoch 158, Step 1, LR: 0.000535, Current Loss: 0.0941, Avg Loss: 0.0941\n",
      "Diff stats — min: -5.4068, max: 10.0000, mean: 6.3935, std: 3.1708\n",
      "\n",
      "Step 4710 — Test metrics:\n",
      "  precision@10: 0.011008958\n",
      "  recall@10: 0.011061251\n",
      "  ndcg@10: 0.011429387\n",
      "  map@10: 0.003940959\n",
      "Epoch 158, Step 20, LR: 0.000535, Current Loss: 0.0787, Avg Loss: 0.0852\n",
      "Diff stats — min: -5.3728, max: 10.0000, mean: 6.4714, std: 3.1237\n",
      "\n",
      "Epoch 158 completed, Train Loss: 0.000021\n",
      "\n",
      "Epoch 159, Step 1, LR: 0.000535, Current Loss: 0.0925, Avg Loss: 0.0925\n",
      "Diff stats — min: -5.8598, max: 10.0000, mean: 6.4436, std: 3.2055\n",
      "\n",
      "Step 4740 — Test metrics:\n",
      "  precision@10: 0.010867515\n",
      "  recall@10: 0.010913915\n",
      "  ndcg@10: 0.011427292\n",
      "  map@10: 0.003955218\n",
      "Epoch 159, Step 20, LR: 0.000535, Current Loss: 0.0912, Avg Loss: 0.0856\n",
      "Diff stats — min: -6.8338, max: 10.0000, mean: 6.4409, std: 3.1488\n",
      "\n",
      "Epoch 159 completed, Train Loss: 0.000021\n",
      "\n",
      "Epoch 160, Step 1, LR: 0.000535, Current Loss: 0.0894, Avg Loss: 0.0894\n",
      "Diff stats — min: -7.4258, max: 10.0000, mean: 6.3862, std: 3.1766\n",
      "\n",
      "Step 4770 — Test metrics:\n",
      "  precision@10: 0.011056106\n",
      "  recall@10: 0.011102505\n",
      "  ndcg@10: 0.011472010\n",
      "  map@10: 0.003964957\n",
      "Epoch 160, Step 20, LR: 0.000535, Current Loss: 0.0782, Avg Loss: 0.0838\n",
      "Diff stats — min: -5.5431, max: 10.0000, mean: 6.5208, std: 3.0959\n",
      "\n",
      "Epoch 160 completed, Train Loss: 0.000021\n",
      "\n",
      "Epoch 161, Step 1, LR: 0.000524, Current Loss: 0.0830, Avg Loss: 0.0830\n",
      "Diff stats — min: -6.0224, max: 10.0000, mean: 6.4525, std: 3.1142\n",
      "\n",
      "Step 4800 — Test metrics:\n",
      "  precision@10: 0.011244696\n",
      "  recall@10: 0.011278373\n",
      "  ndcg@10: 0.011733248\n",
      "  map@10: 0.004052848\n",
      "Epoch 161, Step 20, LR: 0.000524, Current Loss: 0.0842, Avg Loss: 0.0828\n",
      "Diff stats — min: -5.7058, max: 10.0000, mean: 6.4793, std: 3.1211\n",
      "\n",
      "Epoch 161 completed, Train Loss: 0.000021\n",
      "\n",
      "Epoch 162, Step 1, LR: 0.000524, Current Loss: 0.0776, Avg Loss: 0.0776\n",
      "Diff stats — min: -4.2840, max: 10.0000, mean: 6.5461, std: 3.1124\n",
      "\n",
      "Step 4830 — Test metrics:\n",
      "  precision@10: 0.010961810\n",
      "  recall@10: 0.011000726\n",
      "  ndcg@10: 0.011306090\n",
      "  map@10: 0.003851873\n",
      "Epoch 162, Step 20, LR: 0.000524, Current Loss: 0.0666, Avg Loss: 0.0804\n",
      "Diff stats — min: -5.4746, max: 10.0000, mean: 6.4837, std: 3.0509\n",
      "\n",
      "Epoch 162 completed, Train Loss: 0.000020\n",
      "\n",
      "Epoch 163, Step 1, LR: 0.000524, Current Loss: 0.0776, Avg Loss: 0.0776\n",
      "Diff stats — min: -7.4022, max: 10.0000, mean: 6.6013, std: 3.1079\n",
      "\n",
      "Step 4860 — Test metrics:\n",
      "  precision@10: 0.011126827\n",
      "  recall@10: 0.011178465\n",
      "  ndcg@10: 0.011600879\n",
      "  map@10: 0.003978145\n",
      "Epoch 163, Step 20, LR: 0.000524, Current Loss: 0.0770, Avg Loss: 0.0811\n",
      "Diff stats — min: -6.4347, max: 10.0000, mean: 6.5737, std: 3.1063\n",
      "\n",
      "Epoch 163 completed, Train Loss: 0.000020\n",
      "\n",
      "Epoch 164, Step 1, LR: 0.000524, Current Loss: 0.0977, Avg Loss: 0.0977\n",
      "Diff stats — min: -8.8146, max: 10.0000, mean: 6.4378, std: 3.1835\n",
      "\n",
      "Step 4890 — Test metrics:\n",
      "  precision@10: 0.011386139\n",
      "  recall@10: 0.011435157\n",
      "  ndcg@10: 0.011976498\n",
      "  map@10: 0.004179158\n",
      "Epoch 164, Step 20, LR: 0.000524, Current Loss: 0.0817, Avg Loss: 0.0833\n",
      "Diff stats — min: -7.3891, max: 10.0000, mean: 6.5837, std: 3.1063\n",
      "\n",
      "Epoch 164 completed, Train Loss: 0.000021\n",
      "\n",
      "Epoch 165, Step 1, LR: 0.000524, Current Loss: 0.0835, Avg Loss: 0.0835\n",
      "Diff stats — min: -5.5425, max: 10.0000, mean: 6.5541, std: 3.1468\n",
      "\n",
      "Step 4920 — Test metrics:\n",
      "  precision@10: 0.011032532\n",
      "  recall@10: 0.011071447\n",
      "  ndcg@10: 0.011585336\n",
      "  map@10: 0.004041390\n",
      "Epoch 165, Step 20, LR: 0.000524, Current Loss: 0.0870, Avg Loss: 0.0842\n",
      "Diff stats — min: -6.5656, max: 10.0000, mean: 6.4777, std: 3.1616\n",
      "\n",
      "Epoch 165 completed, Train Loss: 0.000021\n",
      "\n",
      "Epoch 166, Step 1, LR: 0.000513, Current Loss: 0.0850, Avg Loss: 0.0850\n",
      "Diff stats — min: -5.6770, max: 10.0000, mean: 6.5905, std: 3.1381\n",
      "\n",
      "Step 4950 — Test metrics:\n",
      "  precision@10: 0.011103253\n",
      "  recall@10: 0.011154891\n",
      "  ndcg@10: 0.011534048\n",
      "  map@10: 0.004004268\n",
      "Epoch 166, Step 20, LR: 0.000513, Current Loss: 0.0796, Avg Loss: 0.0818\n",
      "Diff stats — min: -7.2109, max: 10.0000, mean: 6.5473, std: 3.1307\n",
      "\n",
      "Epoch 166 completed, Train Loss: 0.000020\n",
      "\n",
      "Epoch 167, Step 1, LR: 0.000513, Current Loss: 0.0843, Avg Loss: 0.0843\n",
      "Diff stats — min: -7.7074, max: 10.0000, mean: 6.5744, std: 3.1284\n",
      "\n",
      "Step 4980 — Test metrics:\n",
      "  precision@10: 0.011197548\n",
      "  recall@10: 0.011239083\n",
      "  ndcg@10: 0.011531795\n",
      "  map@10: 0.003982654\n",
      "Epoch 167, Step 20, LR: 0.000513, Current Loss: 0.0857, Avg Loss: 0.0820\n",
      "Diff stats — min: -5.9773, max: 10.0000, mean: 6.5553, std: 3.1367\n",
      "\n",
      "Epoch 167 completed, Train Loss: 0.000021\n",
      "\n",
      "Epoch 168, Step 1, LR: 0.000513, Current Loss: 0.0892, Avg Loss: 0.0892\n",
      "Diff stats — min: -7.1403, max: 10.0000, mean: 6.5921, std: 3.1569\n",
      "\n",
      "Step 5010 — Test metrics:\n",
      "  precision@10: 0.011173975\n",
      "  recall@10: 0.011215509\n",
      "  ndcg@10: 0.011381097\n",
      "  map@10: 0.003886291\n",
      "Epoch 168, Step 20, LR: 0.000513, Current Loss: 0.0849, Avg Loss: 0.0834\n",
      "Diff stats — min: -6.8223, max: 10.0000, mean: 6.5498, std: 3.1281\n",
      "\n",
      "Epoch 168 completed, Train Loss: 0.000021\n",
      "\n",
      "Epoch 169, Step 1, LR: 0.000513, Current Loss: 0.0820, Avg Loss: 0.0820\n",
      "Diff stats — min: -4.8359, max: 10.0000, mean: 6.5413, std: 3.1341\n",
      "\n",
      "Step 5040 — Test metrics:\n",
      "  precision@10: 0.010820368\n",
      "  recall@10: 0.010874625\n",
      "  ndcg@10: 0.011065486\n",
      "  map@10: 0.003794057\n",
      "Epoch 169, Step 20, LR: 0.000513, Current Loss: 0.0816, Avg Loss: 0.0805\n",
      "Diff stats — min: -8.0969, max: 10.0000, mean: 6.7043, std: 3.0888\n",
      "\n",
      "Epoch 169 completed, Train Loss: 0.000020\n",
      "\n",
      "Epoch 170, Step 1, LR: 0.000513, Current Loss: 0.0835, Avg Loss: 0.0835\n",
      "Diff stats — min: -7.5595, max: 10.0000, mean: 6.6293, std: 3.1059\n",
      "\n",
      "Step 5070 — Test metrics:\n",
      "  precision@10: 0.010914663\n",
      "  recall@10: 0.010968920\n",
      "  ndcg@10: 0.011116769\n",
      "  map@10: 0.003782372\n",
      "Epoch 170, Step 20, LR: 0.000513, Current Loss: 0.0870, Avg Loss: 0.0828\n",
      "Diff stats — min: -5.5564, max: 10.0000, mean: 6.5312, std: 3.1299\n",
      "\n",
      "Epoch 170 completed, Train Loss: 0.000020\n",
      "\n",
      "Epoch 171, Step 1, LR: 0.000503, Current Loss: 0.0789, Avg Loss: 0.0789\n",
      "Diff stats — min: -8.2683, max: 10.0000, mean: 6.6024, std: 3.0955\n",
      "\n",
      "Step 5100 — Test metrics:\n",
      "  precision@10: 0.011197548\n",
      "  recall@10: 0.011249186\n",
      "  ndcg@10: 0.011320443\n",
      "  map@10: 0.003875464\n",
      "Epoch 171, Step 20, LR: 0.000503, Current Loss: 0.0927, Avg Loss: 0.0804\n",
      "Diff stats — min: -7.1663, max: 10.0000, mean: 6.4413, std: 3.2088\n",
      "\n",
      "Epoch 171 completed, Train Loss: 0.000020\n",
      "\n",
      "Epoch 172, Step 1, LR: 0.000503, Current Loss: 0.0874, Avg Loss: 0.0874\n",
      "Diff stats — min: -6.3036, max: 10.0000, mean: 6.5241, std: 3.1586\n",
      "\n",
      "Step 5130 — Test metrics:\n",
      "  precision@10: 0.010985384\n",
      "  recall@10: 0.011042916\n",
      "  ndcg@10: 0.011479694\n",
      "  map@10: 0.003997618\n",
      "Epoch 172, Step 20, LR: 0.000503, Current Loss: 0.0789, Avg Loss: 0.0783\n",
      "Diff stats — min: -7.4325, max: 10.0000, mean: 6.5245, std: 3.1178\n",
      "\n",
      "Epoch 172 completed, Train Loss: 0.000019\n",
      "\n",
      "Epoch 173, Step 1, LR: 0.000503, Current Loss: 0.0839, Avg Loss: 0.0839\n",
      "Diff stats — min: -6.0796, max: 10.0000, mean: 6.6189, std: 3.1378\n",
      "\n",
      "Step 5160 — Test metrics:\n",
      "  precision@10: 0.011008958\n",
      "  recall@10: 0.011060596\n",
      "  ndcg@10: 0.011248831\n",
      "  map@10: 0.003850662\n",
      "Epoch 173, Step 20, LR: 0.000503, Current Loss: 0.0762, Avg Loss: 0.0789\n",
      "Diff stats — min: -6.1944, max: 10.0000, mean: 6.6359, std: 3.1073\n",
      "\n",
      "Epoch 173 completed, Train Loss: 0.000020\n",
      "\n",
      "Epoch 174, Step 1, LR: 0.000503, Current Loss: 0.0828, Avg Loss: 0.0828\n",
      "Diff stats — min: -5.0237, max: 10.0000, mean: 6.6650, std: 3.1411\n",
      "\n",
      "Step 5190 — Test metrics:\n",
      "  precision@10: 0.011315417\n",
      "  recall@10: 0.011372949\n",
      "  ndcg@10: 0.011614442\n",
      "  map@10: 0.004030965\n",
      "Epoch 174, Step 20, LR: 0.000503, Current Loss: 0.0726, Avg Loss: 0.0767\n",
      "Diff stats — min: -7.7081, max: 10.0000, mean: 6.5878, std: 3.0965\n",
      "\n",
      "Epoch 174 completed, Train Loss: 0.000019\n",
      "\n",
      "Epoch 175, Step 1, LR: 0.000503, Current Loss: 0.0749, Avg Loss: 0.0749\n",
      "Diff stats — min: -5.4884, max: 10.0000, mean: 6.5721, std: 3.0925\n",
      "\n",
      "Step 5220 — Test metrics:\n",
      "  precision@10: 0.011244696\n",
      "  recall@10: 0.011296334\n",
      "  ndcg@10: 0.011445578\n",
      "  map@10: 0.003906850\n",
      "Epoch 175, Step 20, LR: 0.000503, Current Loss: 0.0658, Avg Loss: 0.0765\n",
      "Diff stats — min: -5.9482, max: 10.0000, mean: 6.7036, std: 3.0438\n",
      "\n",
      "Epoch 175 completed, Train Loss: 0.000019\n",
      "\n",
      "Epoch 176, Step 1, LR: 0.000493, Current Loss: 0.0789, Avg Loss: 0.0789\n",
      "Diff stats — min: -8.8000, max: 10.0000, mean: 6.6830, std: 3.0977\n",
      "\n",
      "Step 5250 — Test metrics:\n",
      "  precision@10: 0.011598303\n",
      "  recall@10: 0.011661727\n",
      "  ndcg@10: 0.011912161\n",
      "  map@10: 0.004082984\n",
      "Epoch 176, Step 20, LR: 0.000493, Current Loss: 0.0795, Avg Loss: 0.0769\n",
      "Diff stats — min: -6.1665, max: 10.0000, mean: 6.7017, std: 3.1272\n",
      "\n",
      "Epoch 176 completed, Train Loss: 0.000019\n",
      "\n",
      "Epoch 177, Step 1, LR: 0.000493, Current Loss: 0.0811, Avg Loss: 0.0811\n",
      "Diff stats — min: -6.9228, max: 10.0000, mean: 6.7133, std: 3.1108\n",
      "\n",
      "Step 5280 — Test metrics:\n",
      "  precision@10: 0.011645450\n",
      "  recall@10: 0.011702982\n",
      "  ndcg@10: 0.011992932\n",
      "  map@10: 0.004171879\n",
      "Epoch 177, Step 20, LR: 0.000493, Current Loss: 0.0758, Avg Loss: 0.0796\n",
      "Diff stats — min: -7.6553, max: 10.0000, mean: 6.6657, std: 3.1132\n",
      "\n",
      "Epoch 177 completed, Train Loss: 0.000020\n",
      "\n",
      "Epoch 178, Step 1, LR: 0.000493, Current Loss: 0.0761, Avg Loss: 0.0761\n",
      "Diff stats — min: -5.2589, max: 10.0000, mean: 6.7430, std: 3.0769\n",
      "\n",
      "Step 5310 — Test metrics:\n",
      "  precision@10: 0.011338991\n",
      "  recall@10: 0.011399796\n",
      "  ndcg@10: 0.011999242\n",
      "  map@10: 0.004280497\n",
      "Epoch 178, Step 20, LR: 0.000493, Current Loss: 0.0847, Avg Loss: 0.0801\n",
      "Diff stats — min: -8.3500, max: 10.0000, mean: 6.6467, std: 3.1482\n",
      "\n",
      "Epoch 178 completed, Train Loss: 0.000020\n",
      "\n",
      "Epoch 179, Step 1, LR: 0.000493, Current Loss: 0.0785, Avg Loss: 0.0785\n",
      "Diff stats — min: -6.1373, max: 10.0000, mean: 6.6505, std: 3.1217\n",
      "\n",
      "Step 5340 — Test metrics:\n",
      "  precision@10: 0.011079679\n",
      "  recall@10: 0.011134591\n",
      "  ndcg@10: 0.011583928\n",
      "  map@10: 0.004055917\n",
      "Epoch 179, Step 20, LR: 0.000493, Current Loss: 0.0823, Avg Loss: 0.0774\n",
      "Diff stats — min: -6.7018, max: 10.0000, mean: 6.6769, std: 3.1270\n",
      "\n",
      "Epoch 179 completed, Train Loss: 0.000019\n",
      "\n",
      "Epoch 180, Step 1, LR: 0.000493, Current Loss: 0.0773, Avg Loss: 0.0773\n",
      "Diff stats — min: -6.9003, max: 10.0000, mean: 6.7281, std: 3.1032\n",
      "\n",
      "Step 5370 — Test metrics:\n",
      "  precision@10: 0.011386139\n",
      "  recall@10: 0.011433567\n",
      "  ndcg@10: 0.012061838\n",
      "  map@10: 0.004276193\n",
      "Epoch 180, Step 20, LR: 0.000493, Current Loss: 0.0814, Avg Loss: 0.0798\n",
      "Diff stats — min: -7.6135, max: 10.0000, mean: 6.6462, std: 3.1270\n",
      "\n",
      "Epoch 180 completed, Train Loss: 0.000020\n",
      "\n",
      "Epoch 181, Step 1, LR: 0.000483, Current Loss: 0.0665, Avg Loss: 0.0665\n",
      "Diff stats — min: -5.9109, max: 10.0000, mean: 6.7093, std: 3.0427\n",
      "\n",
      "Step 5400 — Test metrics:\n",
      "  precision@10: 0.011126827\n",
      "  recall@10: 0.011177529\n",
      "  ndcg@10: 0.011575714\n",
      "  map@10: 0.004043975\n",
      "Epoch 181, Step 20, LR: 0.000483, Current Loss: 0.0863, Avg Loss: 0.0764\n",
      "Diff stats — min: -6.9013, max: 10.0000, mean: 6.5599, std: 3.1554\n",
      "\n",
      "Epoch 181 completed, Train Loss: 0.000019\n",
      "\n",
      "Epoch 182, Step 1, LR: 0.000483, Current Loss: 0.0734, Avg Loss: 0.0734\n",
      "Diff stats — min: -5.5875, max: 10.0000, mean: 6.7459, std: 3.1159\n",
      "\n",
      "Step 5430 — Test metrics:\n",
      "  precision@10: 0.011551155\n",
      "  recall@10: 0.011604477\n",
      "  ndcg@10: 0.012328541\n",
      "  map@10: 0.004399786\n",
      "Epoch 182, Step 20, LR: 0.000483, Current Loss: 0.0800, Avg Loss: 0.0759\n",
      "Diff stats — min: -5.8996, max: 10.0000, mean: 6.7068, std: 3.1272\n",
      "\n",
      "Epoch 182 completed, Train Loss: 0.000019\n",
      "\n",
      "Epoch 183, Step 1, LR: 0.000483, Current Loss: 0.0731, Avg Loss: 0.0731\n",
      "Diff stats — min: -6.7722, max: 10.0000, mean: 6.7284, std: 3.0870\n",
      "\n",
      "Step 5460 — Test metrics:\n",
      "  precision@10: 0.011480434\n",
      "  recall@10: 0.011527862\n",
      "  ndcg@10: 0.012047791\n",
      "  map@10: 0.004241796\n",
      "Epoch 183, Step 20, LR: 0.000483, Current Loss: 0.0695, Avg Loss: 0.0752\n",
      "Diff stats — min: -5.4804, max: 10.0000, mean: 6.6629, std: 3.0545\n",
      "\n",
      "Epoch 183 completed, Train Loss: 0.000019\n",
      "\n",
      "Epoch 184, Step 1, LR: 0.000483, Current Loss: 0.0932, Avg Loss: 0.0932\n",
      "Diff stats — min: -6.7552, max: 10.0000, mean: 6.6549, std: 3.1845\n",
      "\n",
      "Step 5490 — Test metrics:\n",
      "  precision@10: 0.011574729\n",
      "  recall@10: 0.011632260\n",
      "  ndcg@10: 0.011992085\n",
      "  map@10: 0.004191663\n",
      "Epoch 184, Step 20, LR: 0.000483, Current Loss: 0.0873, Avg Loss: 0.0760\n",
      "Diff stats — min: -8.3482, max: 10.0000, mean: 6.7121, std: 3.1716\n",
      "\n",
      "Epoch 184 completed, Train Loss: 0.000019\n",
      "\n",
      "Epoch 185, Step 1, LR: 0.000483, Current Loss: 0.0756, Avg Loss: 0.0756\n",
      "Diff stats — min: -7.1075, max: 10.0000, mean: 6.6990, std: 3.0909\n",
      "\n",
      "Step 5520 — Test metrics:\n",
      "  precision@10: 0.011103253\n",
      "  recall@10: 0.011142169\n",
      "  ndcg@10: 0.011815511\n",
      "  map@10: 0.004176144\n",
      "Epoch 185, Step 20, LR: 0.000483, Current Loss: 0.0741, Avg Loss: 0.0751\n",
      "Diff stats — min: -5.5407, max: 10.0000, mean: 6.7379, std: 3.0986\n",
      "\n",
      "Epoch 185 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 186, Step 1, LR: 0.000474, Current Loss: 0.0790, Avg Loss: 0.0790\n",
      "Diff stats — min: -5.0805, max: 10.0000, mean: 6.7465, std: 3.1113\n",
      "\n",
      "Step 5550 — Test metrics:\n",
      "  precision@10: 0.011409712\n",
      "  recall@10: 0.011456112\n",
      "  ndcg@10: 0.011911263\n",
      "  map@10: 0.004189947\n",
      "Epoch 186, Step 20, LR: 0.000474, Current Loss: 0.0655, Avg Loss: 0.0741\n",
      "Diff stats — min: -5.6173, max: 10.0000, mean: 6.7589, std: 3.0610\n",
      "\n",
      "Epoch 186 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 187, Step 1, LR: 0.000474, Current Loss: 0.0698, Avg Loss: 0.0698\n",
      "Diff stats — min: -6.5321, max: 10.0000, mean: 6.7886, std: 3.0667\n",
      "\n",
      "Step 5580 — Test metrics:\n",
      "  precision@10: 0.011032532\n",
      "  recall@10: 0.011071447\n",
      "  ndcg@10: 0.011523939\n",
      "  map@10: 0.004026839\n",
      "Epoch 187, Step 20, LR: 0.000474, Current Loss: 0.0690, Avg Loss: 0.0730\n",
      "Diff stats — min: -5.9092, max: 10.0000, mean: 6.8032, std: 3.0575\n",
      "\n",
      "Epoch 187 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 188, Step 1, LR: 0.000474, Current Loss: 0.0767, Avg Loss: 0.0767\n",
      "Diff stats — min: -6.2268, max: 10.0000, mean: 6.7612, std: 3.1304\n",
      "\n",
      "Step 5610 — Test metrics:\n",
      "  precision@10: 0.011409712\n",
      "  recall@10: 0.011458731\n",
      "  ndcg@10: 0.011988946\n",
      "  map@10: 0.004255895\n",
      "Epoch 188, Step 20, LR: 0.000474, Current Loss: 0.0729, Avg Loss: 0.0749\n",
      "Diff stats — min: -5.6942, max: 10.0000, mean: 6.7902, std: 3.0694\n",
      "\n",
      "Epoch 188 completed, Train Loss: 0.000019\n",
      "\n",
      "Epoch 189, Step 1, LR: 0.000474, Current Loss: 0.0852, Avg Loss: 0.0852\n",
      "Diff stats — min: -6.0196, max: 10.0000, mean: 6.7249, std: 3.1452\n",
      "\n",
      "Step 5640 — Test metrics:\n",
      "  precision@10: 0.011197548\n",
      "  recall@10: 0.011239738\n",
      "  ndcg@10: 0.011818624\n",
      "  map@10: 0.004173396\n",
      "Epoch 189, Step 20, LR: 0.000474, Current Loss: 0.0649, Avg Loss: 0.0736\n",
      "Diff stats — min: -7.4271, max: 10.0000, mean: 6.8725, std: 3.0154\n",
      "\n",
      "Epoch 189 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 190, Step 1, LR: 0.000474, Current Loss: 0.0743, Avg Loss: 0.0743\n",
      "Diff stats — min: -4.9083, max: 10.0000, mean: 6.7341, std: 3.0800\n",
      "\n",
      "Step 5670 — Test metrics:\n",
      "  precision@10: 0.011645450\n",
      "  recall@10: 0.011702982\n",
      "  ndcg@10: 0.012353640\n",
      "  map@10: 0.004366397\n",
      "Epoch 190, Step 20, LR: 0.000474, Current Loss: 0.0701, Avg Loss: 0.0735\n",
      "Diff stats — min: -5.4045, max: 10.0000, mean: 6.8157, std: 3.0652\n",
      "\n",
      "Epoch 190 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 191, Step 1, LR: 0.000464, Current Loss: 0.0618, Avg Loss: 0.0618\n",
      "Diff stats — min: -5.9134, max: 10.0000, mean: 6.8854, std: 3.0204\n",
      "\n",
      "Step 5700 — Test metrics:\n",
      "  precision@10: 0.011433286\n",
      "  recall@10: 0.011490817\n",
      "  ndcg@10: 0.012261144\n",
      "  map@10: 0.004349483\n",
      "Epoch 191, Step 20, LR: 0.000464, Current Loss: 0.0646, Avg Loss: 0.0736\n",
      "Diff stats — min: -6.1079, max: 10.0000, mean: 6.8927, std: 3.0036\n",
      "\n",
      "Epoch 191 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 192, Step 1, LR: 0.000464, Current Loss: 0.0866, Avg Loss: 0.0866\n",
      "Diff stats — min: -8.6827, max: 10.0000, mean: 6.7189, std: 3.1475\n",
      "\n",
      "Step 5730 — Test metrics:\n",
      "  precision@10: 0.011763319\n",
      "  recall@10: 0.011818231\n",
      "  ndcg@10: 0.012313941\n",
      "  map@10: 0.004277573\n",
      "Epoch 192, Step 20, LR: 0.000464, Current Loss: 0.0697, Avg Loss: 0.0741\n",
      "Diff stats — min: -6.5119, max: 10.0000, mean: 6.9008, std: 3.0582\n",
      "\n",
      "Epoch 192 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 193, Step 1, LR: 0.000464, Current Loss: 0.0688, Avg Loss: 0.0688\n",
      "Diff stats — min: -7.7985, max: 10.0000, mean: 6.8425, std: 3.0468\n",
      "\n",
      "Step 5760 — Test metrics:\n",
      "  precision@10: 0.011763319\n",
      "  recall@10: 0.011820850\n",
      "  ndcg@10: 0.012450606\n",
      "  map@10: 0.004420966\n",
      "Epoch 193, Step 20, LR: 0.000464, Current Loss: 0.0798, Avg Loss: 0.0750\n",
      "Diff stats — min: -7.4951, max: 10.0000, mean: 6.7982, std: 3.1051\n",
      "\n",
      "Epoch 193 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 194, Step 1, LR: 0.000464, Current Loss: 0.0689, Avg Loss: 0.0689\n",
      "Diff stats — min: -5.9244, max: 10.0000, mean: 6.8374, std: 3.0168\n",
      "\n",
      "Step 5790 — Test metrics:\n",
      "  precision@10: 0.011338991\n",
      "  recall@10: 0.011388010\n",
      "  ndcg@10: 0.011948986\n",
      "  map@10: 0.004171334\n",
      "Epoch 194, Step 20, LR: 0.000464, Current Loss: 0.0746, Avg Loss: 0.0726\n",
      "Diff stats — min: -5.7023, max: 10.0000, mean: 6.7965, std: 3.1093\n",
      "\n",
      "Epoch 194 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 195, Step 1, LR: 0.000464, Current Loss: 0.0706, Avg Loss: 0.0706\n",
      "Diff stats — min: -7.3498, max: 10.0000, mean: 6.9074, std: 3.0567\n",
      "\n",
      "Step 5820 — Test metrics:\n",
      "  precision@10: 0.011716172\n",
      "  recall@10: 0.011765190\n",
      "  ndcg@10: 0.012208003\n",
      "  map@10: 0.004240521\n",
      "Epoch 195, Step 20, LR: 0.000464, Current Loss: 0.0704, Avg Loss: 0.0720\n",
      "Diff stats — min: -8.2127, max: 10.0000, mean: 6.8756, std: 3.0788\n",
      "\n",
      "Epoch 195 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 196, Step 1, LR: 0.000455, Current Loss: 0.0768, Avg Loss: 0.0768\n",
      "Diff stats — min: -4.6915, max: 10.0000, mean: 6.8112, std: 3.1176\n",
      "\n",
      "Step 5850 — Test metrics:\n",
      "  precision@10: 0.012022631\n",
      "  recall@10: 0.012077543\n",
      "  ndcg@10: 0.012617171\n",
      "  map@10: 0.004457853\n",
      "Epoch 196, Step 20, LR: 0.000455, Current Loss: 0.0811, Avg Loss: 0.0723\n",
      "Diff stats — min: -8.8635, max: 10.0000, mean: 6.8277, std: 3.1407\n",
      "\n",
      "Epoch 196 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 197, Step 1, LR: 0.000455, Current Loss: 0.0746, Avg Loss: 0.0746\n",
      "Diff stats — min: -6.8252, max: 10.0000, mean: 6.8377, std: 3.1112\n",
      "\n",
      "Step 5880 — Test metrics:\n",
      "  precision@10: 0.011834041\n",
      "  recall@10: 0.011891572\n",
      "  ndcg@10: 0.012438874\n",
      "  map@10: 0.004413369\n",
      "Epoch 197, Step 20, LR: 0.000455, Current Loss: 0.0785, Avg Loss: 0.0716\n",
      "Diff stats — min: -5.9510, max: 10.0000, mean: 6.8280, std: 3.1041\n",
      "\n",
      "Epoch 197 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 198, Step 1, LR: 0.000455, Current Loss: 0.0662, Avg Loss: 0.0662\n",
      "Diff stats — min: -5.8467, max: 10.0000, mean: 6.9327, std: 3.0234\n",
      "\n",
      "Step 5910 — Test metrics:\n",
      "  precision@10: 0.012234795\n",
      "  recall@10: 0.012294945\n",
      "  ndcg@10: 0.012975422\n",
      "  map@10: 0.004615660\n",
      "Epoch 198, Step 20, LR: 0.000455, Current Loss: 0.0726, Avg Loss: 0.0715\n",
      "Diff stats — min: -6.9648, max: 10.0000, mean: 6.9257, std: 3.0700\n",
      "\n",
      "Epoch 198 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 199, Step 1, LR: 0.000455, Current Loss: 0.0841, Avg Loss: 0.0841\n",
      "Diff stats — min: -6.2917, max: 10.0000, mean: 6.7838, std: 3.1432\n",
      "\n",
      "Step 5940 — Test metrics:\n",
      "  precision@10: 0.011669024\n",
      "  recall@10: 0.011720662\n",
      "  ndcg@10: 0.012340028\n",
      "  map@10: 0.004346663\n",
      "Epoch 199, Step 20, LR: 0.000455, Current Loss: 0.0727, Avg Loss: 0.0726\n",
      "Diff stats — min: -7.7088, max: 10.0000, mean: 6.9443, std: 3.0482\n",
      "\n",
      "Epoch 199 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 200, Step 1, LR: 0.000455, Current Loss: 0.0738, Avg Loss: 0.0738\n",
      "Diff stats — min: -6.3578, max: 10.0000, mean: 6.9205, std: 3.0561\n",
      "\n",
      "Step 5970 — Test metrics:\n",
      "  precision@10: 0.012022631\n",
      "  recall@10: 0.012070059\n",
      "  ndcg@10: 0.012653639\n",
      "  map@10: 0.004442486\n",
      "Epoch 200, Step 20, LR: 0.000455, Current Loss: 0.0727, Avg Loss: 0.0726\n",
      "Diff stats — min: -7.6530, max: 10.0000, mean: 6.9301, std: 3.0610\n",
      "\n",
      "Epoch 200 completed, Train Loss: 0.000018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    feedback_types=feedback_types,\n",
    "    d_model=d_model,\n",
    "    n_head=n_head,\n",
    "    window_size=window_size,\n",
    "    decay=decay,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "edge_type = hyperparameters['train_edge_type']\n",
    "num_epochs = hyperparameters['train_num_epochs']\n",
    "lr = hyperparameters['train_lr']\n",
    "batch_size = hyperparameters['train_batch_size']\n",
    "print_every = hyperparameters['train_print_every']\n",
    "test_every = hyperparameters['train_test_every']\n",
    "top_k = hyperparameters['test_topk']\n",
    "test_batch_size = hyperparameters['test_batch_size']\n",
    "scheduler_step_size = hyperparameters['train_scheduler_step_size']\n",
    "train_scheduler_gamma = hyperparameters['train_scheduler_gamma']\n",
    "\n",
    "model = train_model(model,\n",
    "                    data,\n",
    "                    (seq_ids, event_type, seq_times, seq_mask),\n",
    "                    edge_type=edge_type,\n",
    "                    num_epochs=num_epochs,\n",
    "                    lr=lr,\n",
    "                    batch_size=batch_size,\n",
    "                    print_every=print_every,\n",
    "                    test_every=test_every,\n",
    "                    top_k=top_k,\n",
    "                    test_batch_size=test_batch_size,\n",
    "                    scheduler_step_size=scheduler_step_size,\n",
    "                    scheduler_gamma=train_scheduler_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-25T01:50:48.436Z",
     "iopub.execute_input": "2025-06-24T23:15:49.651959Z",
     "iopub.status.busy": "2025-06-24T23:15:49.651680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training examples: 121468\n",
      "Epoch 201, Step 1, LR: 0.001000, Current Loss: 0.0662, Avg Loss: 0.0662\n",
      "Diff stats — min: -5.0348, max: 10.0000, mean: 6.9157, std: 3.0586\n",
      "\n",
      "Step 5971 — Test metrics:\n",
      "  precision@10: 0.011692598\n",
      "  recall@10: 0.011744236\n",
      "  ndcg@10: 0.012454147\n",
      "  map@10: 0.004414655\n",
      "Epoch 201, Step 20, LR: 0.001000, Current Loss: 0.0764, Avg Loss: 0.0716\n",
      "Diff stats — min: -9.0807, max: 10.0000, mean: 6.8470, std: 3.1010\n",
      "\n",
      "Epoch 201 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 202, Step 1, LR: 0.001000, Current Loss: 0.0614, Avg Loss: 0.0614\n",
      "Diff stats — min: -6.7937, max: 10.0000, mean: 6.9491, std: 3.0069\n",
      "\n",
      "Step 6001 — Test metrics:\n",
      "  precision@10: 0.011857614\n",
      "  recall@10: 0.011912900\n",
      "  ndcg@10: 0.012691956\n",
      "  map@10: 0.004524252\n",
      "Epoch 202, Step 20, LR: 0.001000, Current Loss: 0.0659, Avg Loss: 0.0719\n",
      "Diff stats — min: -6.0834, max: 10.0000, mean: 6.9209, std: 3.0576\n",
      "\n",
      "Epoch 202 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 203, Step 1, LR: 0.001000, Current Loss: 0.0695, Avg Loss: 0.0695\n",
      "Diff stats — min: -8.3657, max: 10.0000, mean: 6.8950, std: 3.0802\n",
      "\n",
      "Step 6031 — Test metrics:\n",
      "  precision@10: 0.011315417\n",
      "  recall@10: 0.011365465\n",
      "  ndcg@10: 0.012215954\n",
      "  map@10: 0.004389680\n",
      "Epoch 203, Step 20, LR: 0.001000, Current Loss: 0.0720, Avg Loss: 0.0714\n",
      "Diff stats — min: -5.2862, max: 10.0000, mean: 6.8205, std: 3.0681\n",
      "\n",
      "Epoch 203 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 204, Step 1, LR: 0.001000, Current Loss: 0.0759, Avg Loss: 0.0759\n",
      "Diff stats — min: -6.2241, max: 10.0000, mean: 6.8615, std: 3.0966\n",
      "\n",
      "Step 6061 — Test metrics:\n",
      "  precision@10: 0.011669024\n",
      "  recall@10: 0.011716452\n",
      "  ndcg@10: 0.012160299\n",
      "  map@10: 0.004272916\n",
      "Epoch 204, Step 20, LR: 0.001000, Current Loss: 0.0748, Avg Loss: 0.0713\n",
      "Diff stats — min: -5.8542, max: 10.0000, mean: 7.0146, std: 3.0940\n",
      "\n",
      "Epoch 204 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 205, Step 1, LR: 0.001000, Current Loss: 0.0661, Avg Loss: 0.0661\n",
      "Diff stats — min: -6.3726, max: 10.0000, mean: 6.9328, std: 3.0251\n",
      "\n",
      "Step 6091 — Test metrics:\n",
      "  precision@10: 0.012140500\n",
      "  recall@10: 0.012187928\n",
      "  ndcg@10: 0.012682910\n",
      "  map@10: 0.004494470\n",
      "Epoch 205, Step 20, LR: 0.001000, Current Loss: 0.0724, Avg Loss: 0.0718\n",
      "Diff stats — min: -7.4590, max: 10.0000, mean: 6.9400, std: 3.0753\n",
      "\n",
      "Epoch 205 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 206, Step 1, LR: 0.000980, Current Loss: 0.0675, Avg Loss: 0.0675\n",
      "Diff stats — min: -5.6238, max: 10.0000, mean: 6.9341, std: 3.0448\n",
      "\n",
      "Step 6121 — Test metrics:\n",
      "  precision@10: 0.011951909\n",
      "  recall@10: 0.012005231\n",
      "  ndcg@10: 0.012784924\n",
      "  map@10: 0.004593013\n",
      "Epoch 206, Step 20, LR: 0.000980, Current Loss: 0.0909, Avg Loss: 0.0720\n",
      "Diff stats — min: -8.5652, max: 10.0000, mean: 6.8710, std: 3.1756\n",
      "\n",
      "Epoch 206 completed, Train Loss: 0.000018\n",
      "\n",
      "Epoch 207, Step 1, LR: 0.000980, Current Loss: 0.0719, Avg Loss: 0.0719\n",
      "Diff stats — min: -8.4876, max: 10.0000, mean: 7.0300, std: 3.0691\n",
      "\n",
      "Step 6151 — Test metrics:\n",
      "  precision@10: 0.011904762\n",
      "  recall@10: 0.011964912\n",
      "  ndcg@10: 0.012758345\n",
      "  map@10: 0.004608504\n",
      "Epoch 207, Step 20, LR: 0.000980, Current Loss: 0.0733, Avg Loss: 0.0698\n",
      "Diff stats — min: -6.8271, max: 10.0000, mean: 6.9726, std: 3.0834\n",
      "\n",
      "Epoch 207 completed, Train Loss: 0.000017\n",
      "\n",
      "Epoch 208, Step 1, LR: 0.000980, Current Loss: 0.0647, Avg Loss: 0.0647\n",
      "Diff stats — min: -6.9376, max: 10.0000, mean: 7.0098, std: 3.0453\n",
      "\n",
      "Step 6181 — Test metrics:\n",
      "  precision@10: 0.011173975\n",
      "  recall@10: 0.011237399\n",
      "  ndcg@10: 0.012125251\n",
      "  map@10: 0.004417605\n",
      "Epoch 208, Step 20, LR: 0.000980, Current Loss: 0.0735, Avg Loss: 0.0706\n",
      "Diff stats — min: -8.4259, max: 10.0000, mean: 6.9698, std: 3.0895\n",
      "\n",
      "Epoch 208 completed, Train Loss: 0.000017\n",
      "\n",
      "Epoch 209, Step 1, LR: 0.000980, Current Loss: 0.0668, Avg Loss: 0.0668\n",
      "Diff stats — min: -5.6333, max: 10.0000, mean: 7.0048, std: 3.0666\n",
      "\n",
      "Step 6211 — Test metrics:\n",
      "  precision@10: 0.011881188\n",
      "  recall@10: 0.011947232\n",
      "  ndcg@10: 0.012896767\n",
      "  map@10: 0.004735201\n",
      "Epoch 209, Step 20, LR: 0.000980, Current Loss: 0.0755, Avg Loss: 0.0698\n",
      "Diff stats — min: -5.5785, max: 10.0000, mean: 6.9660, std: 3.0856\n",
      "\n",
      "Epoch 209 completed, Train Loss: 0.000017\n",
      "\n",
      "Epoch 210, Step 1, LR: 0.000980, Current Loss: 0.0626, Avg Loss: 0.0626\n",
      "Diff stats — min: -4.6392, max: 10.0000, mean: 7.0887, std: 2.9925\n",
      "\n",
      "Step 6241 — Test metrics:\n",
      "  precision@10: 0.011904762\n",
      "  recall@10: 0.011956400\n",
      "  ndcg@10: 0.013033286\n",
      "  map@10: 0.004804373\n",
      "Epoch 210, Step 20, LR: 0.000980, Current Loss: 0.0690, Avg Loss: 0.0677\n",
      "Diff stats — min: -6.4954, max: 10.0000, mean: 6.9739, std: 3.0512\n",
      "\n",
      "Epoch 210 completed, Train Loss: 0.000017\n",
      "\n",
      "Epoch 211, Step 1, LR: 0.000960, Current Loss: 0.0695, Avg Loss: 0.0695\n",
      "Diff stats — min: -6.3921, max: 10.0000, mean: 6.9790, std: 3.0624\n",
      "\n",
      "Step 6271 — Test metrics:\n",
      "  precision@10: 0.012140500\n",
      "  recall@10: 0.012195412\n",
      "  ndcg@10: 0.013255741\n",
      "  map@10: 0.004868785\n",
      "Epoch 211, Step 20, LR: 0.000960, Current Loss: 0.0647, Avg Loss: 0.0699\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 7.0118, std: 3.0537\n",
      "\n",
      "Epoch 211 completed, Train Loss: 0.000017\n",
      "\n",
      "Epoch 212, Step 1, LR: 0.000960, Current Loss: 0.0598, Avg Loss: 0.0598\n",
      "Diff stats — min: -8.6027, max: 10.0000, mean: 7.0786, std: 3.0152\n",
      "\n",
      "Step 6301 — Test metrics:\n",
      "  precision@10: 0.012446959\n",
      "  recall@10: 0.012493358\n",
      "  ndcg@10: 0.013619836\n",
      "  map@10: 0.005027411\n",
      "Epoch 212, Step 20, LR: 0.000960, Current Loss: 0.0730, Avg Loss: 0.0672\n",
      "Diff stats — min: -5.2258, max: 10.0000, mean: 6.9610, std: 3.1084\n",
      "\n",
      "Epoch 212 completed, Train Loss: 0.000017\n",
      "\n",
      "Epoch 213, Step 1, LR: 0.000960, Current Loss: 0.0635, Avg Loss: 0.0635\n",
      "Diff stats — min: -7.0567, max: 10.0000, mean: 7.0999, std: 3.0182\n",
      "\n",
      "Step 6331 — Test metrics:\n",
      "  precision@10: 0.012517680\n",
      "  recall@10: 0.012577831\n",
      "  ndcg@10: 0.013761757\n",
      "  map@10: 0.005070949\n",
      "Epoch 213, Step 20, LR: 0.000960, Current Loss: 0.0730, Avg Loss: 0.0665\n",
      "Diff stats — min: -8.7884, max: 10.0000, mean: 7.0445, std: 3.0676\n",
      "\n",
      "Epoch 213 completed, Train Loss: 0.000017\n",
      "\n",
      "Epoch 214, Step 1, LR: 0.000960, Current Loss: 0.0663, Avg Loss: 0.0663\n",
      "Diff stats — min: -9.7991, max: 10.0000, mean: 7.0768, std: 3.0074\n",
      "\n",
      "Step 6361 — Test metrics:\n",
      "  precision@10: 0.012046205\n",
      "  recall@10: 0.012101117\n",
      "  ndcg@10: 0.013251725\n",
      "  map@10: 0.004849270\n",
      "Epoch 214, Step 20, LR: 0.000960, Current Loss: 0.0681, Avg Loss: 0.0663\n",
      "Diff stats — min: -7.0859, max: 10.0000, mean: 7.0874, std: 3.0337\n",
      "\n",
      "Epoch 214 completed, Train Loss: 0.000016\n",
      "\n",
      "Epoch 215, Step 1, LR: 0.000960, Current Loss: 0.0726, Avg Loss: 0.0726\n",
      "Diff stats — min: -7.4840, max: 10.0000, mean: 7.0285, std: 3.0818\n",
      "\n",
      "Step 6391 — Test metrics:\n",
      "  precision@10: 0.012541254\n",
      "  recall@10: 0.012590273\n",
      "  ndcg@10: 0.013615577\n",
      "  map@10: 0.004977427\n",
      "Epoch 215, Step 20, LR: 0.000960, Current Loss: 0.0668, Avg Loss: 0.0662\n",
      "Diff stats — min: -5.5763, max: 10.0000, mean: 7.1235, std: 3.0465\n",
      "\n",
      "Epoch 215 completed, Train Loss: 0.000016\n",
      "\n",
      "Epoch 216, Step 1, LR: 0.000941, Current Loss: 0.0581, Avg Loss: 0.0581\n",
      "Diff stats — min: -5.4136, max: 10.0000, mean: 7.0742, std: 3.0019\n",
      "\n",
      "Step 6421 — Test metrics:\n",
      "  precision@10: 0.012116926\n",
      "  recall@10: 0.012153222\n",
      "  ndcg@10: 0.013113881\n",
      "  map@10: 0.004748353\n",
      "Epoch 216, Step 20, LR: 0.000941, Current Loss: 0.0575, Avg Loss: 0.0646\n",
      "Diff stats — min: -6.0322, max: 10.0000, mean: 7.1360, std: 2.9653\n",
      "\n",
      "Epoch 216 completed, Train Loss: 0.000016\n",
      "\n",
      "Epoch 217, Step 1, LR: 0.000941, Current Loss: 0.0738, Avg Loss: 0.0738\n",
      "Diff stats — min: -6.9910, max: 10.0000, mean: 7.0833, std: 3.0675\n",
      "\n",
      "Step 6451 — Test metrics:\n",
      "  precision@10: 0.012706271\n",
      "  recall@10: 0.012753699\n",
      "  ndcg@10: 0.013387154\n",
      "  map@10: 0.004830044\n",
      "Epoch 217, Step 20, LR: 0.000941, Current Loss: 0.0662, Avg Loss: 0.0655\n",
      "Diff stats — min: -7.7040, max: 10.0000, mean: 7.0979, std: 3.0428\n",
      "\n",
      "Epoch 217 completed, Train Loss: 0.000016\n",
      "\n",
      "Epoch 218, Step 1, LR: 0.000941, Current Loss: 0.0606, Avg Loss: 0.0606\n",
      "Diff stats — min: -7.1359, max: 10.0000, mean: 7.1637, std: 3.0009\n",
      "\n",
      "Step 6481 — Test metrics:\n",
      "  precision@10: 0.012470533\n",
      "  recall@10: 0.012516932\n",
      "  ndcg@10: 0.013616175\n",
      "  map@10: 0.005045195\n",
      "Epoch 218, Step 20, LR: 0.000941, Current Loss: 0.0596, Avg Loss: 0.0659\n",
      "Diff stats — min: -4.7966, max: 10.0000, mean: 7.1036, std: 3.0111\n",
      "\n",
      "Epoch 218 completed, Train Loss: 0.000016\n",
      "\n",
      "Epoch 219, Step 1, LR: 0.000941, Current Loss: 0.0644, Avg Loss: 0.0644\n",
      "Diff stats — min: -4.7042, max: 10.0000, mean: 7.1358, std: 3.0306\n",
      "\n",
      "Step 6511 — Test metrics:\n",
      "  precision@10: 0.012682697\n",
      "  recall@10: 0.012736954\n",
      "  ndcg@10: 0.013791867\n",
      "  map@10: 0.005117645\n",
      "Epoch 219, Step 20, LR: 0.000941, Current Loss: 0.0632, Avg Loss: 0.0646\n",
      "Diff stats — min: -7.0755, max: 10.0000, mean: 7.1211, std: 3.0613\n",
      "\n",
      "Epoch 219 completed, Train Loss: 0.000016\n",
      "\n",
      "Epoch 220, Step 1, LR: 0.000941, Current Loss: 0.0631, Avg Loss: 0.0631\n",
      "Diff stats — min: -6.3233, max: 10.0000, mean: 7.2228, std: 2.9738\n",
      "\n",
      "Step 6541 — Test metrics:\n",
      "  precision@10: 0.011951909\n",
      "  recall@10: 0.011995689\n",
      "  ndcg@10: 0.013221703\n",
      "  map@10: 0.004861990\n",
      "Epoch 220, Step 20, LR: 0.000941, Current Loss: 0.0651, Avg Loss: 0.0631\n",
      "Diff stats — min: -7.8307, max: 10.0000, mean: 7.1937, std: 3.0232\n",
      "\n",
      "Epoch 220 completed, Train Loss: 0.000016\n",
      "\n",
      "Epoch 221, Step 1, LR: 0.000922, Current Loss: 0.0711, Avg Loss: 0.0711\n",
      "Diff stats — min: -6.3656, max: 10.0000, mean: 7.1125, std: 3.0755\n",
      "\n",
      "Step 6571 — Test metrics:\n",
      "  precision@10: 0.012399811\n",
      "  recall@10: 0.012454723\n",
      "  ndcg@10: 0.013432800\n",
      "  map@10: 0.004941817\n",
      "Epoch 221, Step 20, LR: 0.000922, Current Loss: 0.0729, Avg Loss: 0.0641\n",
      "Diff stats — min: -7.6129, max: 10.0000, mean: 7.1794, std: 3.0373\n",
      "\n",
      "Epoch 221 completed, Train Loss: 0.000016\n",
      "\n",
      "Epoch 222, Step 1, LR: 0.000922, Current Loss: 0.0582, Avg Loss: 0.0582\n",
      "Diff stats — min: -6.0044, max: 10.0000, mean: 7.2069, std: 2.9718\n",
      "\n",
      "Step 6601 — Test metrics:\n",
      "  precision@10: 0.012234795\n",
      "  recall@10: 0.012289707\n",
      "  ndcg@10: 0.013337754\n",
      "  map@10: 0.004909252\n",
      "Epoch 222, Step 20, LR: 0.000922, Current Loss: 0.0609, Avg Loss: 0.0651\n",
      "Diff stats — min: -5.1410, max: 10.0000, mean: 7.1497, std: 2.9988\n",
      "\n",
      "Epoch 222 completed, Train Loss: 0.000016\n",
      "\n",
      "Epoch 223, Step 1, LR: 0.000922, Current Loss: 0.0644, Avg Loss: 0.0644\n",
      "Diff stats — min: -7.3744, max: 10.0000, mean: 7.1769, std: 3.0439\n",
      "\n",
      "Step 6631 — Test metrics:\n",
      "  precision@10: 0.012588402\n",
      "  recall@10: 0.012633211\n",
      "  ndcg@10: 0.013547539\n",
      "  map@10: 0.005027163\n",
      "Epoch 223, Step 20, LR: 0.000922, Current Loss: 0.0673, Avg Loss: 0.0630\n",
      "Diff stats — min: -7.2712, max: 10.0000, mean: 7.1666, std: 3.0552\n",
      "\n",
      "Epoch 223 completed, Train Loss: 0.000015\n",
      "\n",
      "Epoch 224, Step 1, LR: 0.000922, Current Loss: 0.0671, Avg Loss: 0.0671\n",
      "Diff stats — min: -6.4523, max: 10.0000, mean: 7.1815, std: 3.0281\n",
      "\n",
      "Step 6661 — Test metrics:\n",
      "  precision@10: 0.012611975\n",
      "  recall@10: 0.012650891\n",
      "  ndcg@10: 0.013750100\n",
      "  map@10: 0.005065841\n",
      "Epoch 224, Step 20, LR: 0.000922, Current Loss: 0.0654, Avg Loss: 0.0617\n",
      "Diff stats — min: -7.9708, max: 10.0000, mean: 7.2058, std: 3.0292\n",
      "\n",
      "Epoch 224 completed, Train Loss: 0.000015\n",
      "\n",
      "Epoch 225, Step 1, LR: 0.000922, Current Loss: 0.0668, Avg Loss: 0.0668\n",
      "Diff stats — min: -6.6776, max: 10.0000, mean: 7.1985, std: 3.0465\n",
      "\n",
      "Step 6691 — Test metrics:\n",
      "  precision@10: 0.012918435\n",
      "  recall@10: 0.012959969\n",
      "  ndcg@10: 0.013821917\n",
      "  map@10: 0.005051469\n",
      "Epoch 225, Step 20, LR: 0.000922, Current Loss: 0.0659, Avg Loss: 0.0615\n",
      "Diff stats — min: -6.4442, max: 10.0000, mean: 7.2341, std: 3.0174\n",
      "\n",
      "Epoch 225 completed, Train Loss: 0.000015\n",
      "\n",
      "Epoch 226, Step 1, LR: 0.000904, Current Loss: 0.0596, Avg Loss: 0.0596\n",
      "Diff stats — min: -6.3235, max: 10.0000, mean: 7.2375, std: 2.9869\n",
      "\n",
      "Step 6721 — Test metrics:\n",
      "  precision@10: 0.013059877\n",
      "  recall@10: 0.013101412\n",
      "  ndcg@10: 0.014107442\n",
      "  map@10: 0.005257387\n",
      "Epoch 226, Step 20, LR: 0.000904, Current Loss: 0.0598, Avg Loss: 0.0600\n",
      "Diff stats — min: -6.5557, max: 10.0000, mean: 7.3168, std: 2.9703\n",
      "\n",
      "Epoch 226 completed, Train Loss: 0.000014\n",
      "\n",
      "Epoch 227, Step 1, LR: 0.000904, Current Loss: 0.0690, Avg Loss: 0.0690\n",
      "Diff stats — min: -6.7760, max: 10.0000, mean: 7.2188, std: 3.0698\n",
      "\n",
      "Step 6751 — Test metrics:\n",
      "  precision@10: 0.012894861\n",
      "  recall@10: 0.012936396\n",
      "  ndcg@10: 0.014005088\n",
      "  map@10: 0.005181967\n",
      "Epoch 227, Step 20, LR: 0.000904, Current Loss: 0.0661, Avg Loss: 0.0623\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 7.2167, std: 3.0301\n",
      "\n",
      "Epoch 227 completed, Train Loss: 0.000015\n",
      "\n",
      "Epoch 228, Step 1, LR: 0.000904, Current Loss: 0.0665, Avg Loss: 0.0665\n",
      "Diff stats — min: -5.8318, max: 10.0000, mean: 7.2610, std: 3.0321\n",
      "\n",
      "Step 6781 — Test metrics:\n",
      "  precision@10: 0.012800566\n",
      "  recall@10: 0.012851268\n",
      "  ndcg@10: 0.013952238\n",
      "  map@10: 0.005153695\n",
      "Epoch 228, Step 20, LR: 0.000904, Current Loss: 0.0634, Avg Loss: 0.0605\n",
      "Diff stats — min: -6.3122, max: 10.0000, mean: 7.2602, std: 3.0049\n",
      "\n",
      "Epoch 228 completed, Train Loss: 0.000015\n",
      "\n",
      "Epoch 229, Step 1, LR: 0.000904, Current Loss: 0.0590, Avg Loss: 0.0590\n",
      "Diff stats — min: -3.6568, max: 10.0000, mean: 7.2592, std: 3.0119\n",
      "\n",
      "Step 6811 — Test metrics:\n",
      "  precision@10: 0.013059877\n",
      "  recall@10: 0.013102067\n",
      "  ndcg@10: 0.014104450\n",
      "  map@10: 0.005193505\n",
      "Epoch 229, Step 20, LR: 0.000904, Current Loss: 0.0514, Avg Loss: 0.0600\n",
      "Diff stats — min: -5.3576, max: 10.0000, mean: 7.3701, std: 2.9211\n",
      "\n",
      "Epoch 229 completed, Train Loss: 0.000015\n",
      "\n",
      "Epoch 230, Step 1, LR: 0.000904, Current Loss: 0.0617, Avg Loss: 0.0617\n",
      "Diff stats — min: -6.4197, max: 10.0000, mean: 7.2846, std: 3.0083\n",
      "\n",
      "Step 6841 — Test metrics:\n",
      "  precision@10: 0.013224894\n",
      "  recall@10: 0.013269703\n",
      "  ndcg@10: 0.014311402\n",
      "  map@10: 0.005278716\n",
      "Epoch 230, Step 20, LR: 0.000904, Current Loss: 0.0606, Avg Loss: 0.0592\n",
      "Diff stats — min: -6.3472, max: 10.0000, mean: 7.2607, std: 2.9969\n",
      "\n",
      "Epoch 230 completed, Train Loss: 0.000015\n",
      "\n",
      "Epoch 231, Step 1, LR: 0.000886, Current Loss: 0.0513, Avg Loss: 0.0513\n",
      "Diff stats — min: -5.4748, max: 10.0000, mean: 7.3655, std: 2.9392\n",
      "\n",
      "Step 6871 — Test metrics:\n",
      "  precision@10: 0.013107025\n",
      "  recall@10: 0.013151179\n",
      "  ndcg@10: 0.014509053\n",
      "  map@10: 0.005436704\n",
      "Epoch 231, Step 20, LR: 0.000886, Current Loss: 0.0683, Avg Loss: 0.0578\n",
      "Diff stats — min: -9.0829, max: 10.0000, mean: 7.2652, std: 3.0460\n",
      "\n",
      "Epoch 231 completed, Train Loss: 0.000014\n",
      "\n",
      "Epoch 232, Step 1, LR: 0.000886, Current Loss: 0.0671, Avg Loss: 0.0671\n",
      "Diff stats — min: -6.7956, max: 10.0000, mean: 7.3572, std: 2.9978\n",
      "\n",
      "Step 6901 — Test metrics:\n",
      "  precision@10: 0.013154173\n",
      "  recall@10: 0.013201601\n",
      "  ndcg@10: 0.014203974\n",
      "  map@10: 0.005241362\n",
      "Epoch 232, Step 20, LR: 0.000886, Current Loss: 0.0568, Avg Loss: 0.0594\n",
      "Diff stats — min: -7.4936, max: 10.0000, mean: 7.3400, std: 2.9346\n",
      "\n",
      "Epoch 232 completed, Train Loss: 0.000015\n",
      "\n",
      "Epoch 233, Step 1, LR: 0.000886, Current Loss: 0.0709, Avg Loss: 0.0709\n",
      "Diff stats — min: -7.5115, max: 10.0000, mean: 7.2066, std: 3.0793\n",
      "\n",
      "Step 6931 — Test metrics:\n",
      "  precision@10: 0.013602074\n",
      "  recall@10: 0.013656986\n",
      "  ndcg@10: 0.014512728\n",
      "  map@10: 0.005309412\n",
      "Epoch 233, Step 20, LR: 0.000886, Current Loss: 0.0555, Avg Loss: 0.0583\n",
      "Diff stats — min: -5.1575, max: 10.0000, mean: 7.4043, std: 2.9306\n",
      "\n",
      "Epoch 233 completed, Train Loss: 0.000014\n",
      "\n",
      "Epoch 234, Step 1, LR: 0.000886, Current Loss: 0.0628, Avg Loss: 0.0628\n",
      "Diff stats — min: -7.6713, max: 10.0000, mean: 7.3388, std: 2.9937\n",
      "\n",
      "Step 6961 — Test metrics:\n",
      "  precision@10: 0.013295615\n",
      "  recall@10: 0.013348937\n",
      "  ndcg@10: 0.014140441\n",
      "  map@10: 0.005190995\n",
      "Epoch 234, Step 20, LR: 0.000886, Current Loss: 0.0539, Avg Loss: 0.0577\n",
      "Diff stats — min: -5.8526, max: 10.0000, mean: 7.4176, std: 2.9021\n",
      "\n",
      "Epoch 234 completed, Train Loss: 0.000014\n",
      "\n",
      "Epoch 235, Step 1, LR: 0.000886, Current Loss: 0.0574, Avg Loss: 0.0574\n",
      "Diff stats — min: -6.6781, max: 10.0000, mean: 7.3137, std: 2.9760\n",
      "\n",
      "Step 6991 — Test metrics:\n",
      "  precision@10: 0.014144272\n",
      "  recall@10: 0.014207696\n",
      "  ndcg@10: 0.014931493\n",
      "  map@10: 0.005518766\n",
      "Epoch 235, Step 20, LR: 0.000886, Current Loss: 0.0577, Avg Loss: 0.0591\n",
      "Diff stats — min: -6.8798, max: 10.0000, mean: 7.3608, std: 2.9752\n",
      "\n",
      "Epoch 235 completed, Train Loss: 0.000014\n",
      "\n",
      "Epoch 236, Step 1, LR: 0.000868, Current Loss: 0.0534, Avg Loss: 0.0534\n",
      "Diff stats — min: -5.1664, max: 10.0000, mean: 7.3993, std: 2.9103\n",
      "\n",
      "Step 7021 — Test metrics:\n",
      "  precision@10: 0.013554927\n",
      "  recall@10: 0.013599081\n",
      "  ndcg@10: 0.014404182\n",
      "  map@10: 0.005237130\n",
      "Epoch 236, Step 20, LR: 0.000868, Current Loss: 0.0579, Avg Loss: 0.0586\n",
      "Diff stats — min: -6.1961, max: 10.0000, mean: 7.3048, std: 2.9908\n",
      "\n",
      "Epoch 236 completed, Train Loss: 0.000014\n",
      "\n",
      "Epoch 237, Step 1, LR: 0.000868, Current Loss: 0.0546, Avg Loss: 0.0546\n",
      "Diff stats — min: -6.4936, max: 10.0000, mean: 7.3702, std: 2.9459\n",
      "\n",
      "Step 7051 — Test metrics:\n",
      "  precision@10: 0.013767091\n",
      "  recall@10: 0.013814519\n",
      "  ndcg@10: 0.014545531\n",
      "  map@10: 0.005316471\n",
      "Epoch 237, Step 20, LR: 0.000868, Current Loss: 0.0539, Avg Loss: 0.0574\n",
      "Diff stats — min: -7.7899, max: 10.0000, mean: 7.3634, std: 2.9238\n",
      "\n",
      "Epoch 237 completed, Train Loss: 0.000014\n",
      "\n",
      "Epoch 238, Step 1, LR: 0.000868, Current Loss: 0.0509, Avg Loss: 0.0509\n",
      "Diff stats — min: -6.0162, max: 10.0000, mean: 7.4572, std: 2.8723\n",
      "\n",
      "Step 7081 — Test metrics:\n",
      "  precision@10: 0.013507779\n",
      "  recall@10: 0.013552588\n",
      "  ndcg@10: 0.014506308\n",
      "  map@10: 0.005372067\n",
      "Epoch 238, Step 20, LR: 0.000868, Current Loss: 0.0611, Avg Loss: 0.0567\n",
      "Diff stats — min: -6.1464, max: 10.0000, mean: 7.3866, std: 2.9778\n",
      "\n",
      "Epoch 238 completed, Train Loss: 0.000014\n",
      "\n",
      "Epoch 239, Step 1, LR: 0.000868, Current Loss: 0.0521, Avg Loss: 0.0521\n",
      "Diff stats — min: -8.0030, max: 10.0000, mean: 7.3636, std: 2.9339\n",
      "\n",
      "Step 7111 — Test metrics:\n",
      "  precision@10: 0.013767091\n",
      "  recall@10: 0.013832480\n",
      "  ndcg@10: 0.014584369\n",
      "  map@10: 0.005344803\n",
      "Epoch 239, Step 20, LR: 0.000868, Current Loss: 0.0643, Avg Loss: 0.0559\n",
      "Diff stats — min: -6.4906, max: 10.0000, mean: 7.3571, std: 3.0204\n",
      "\n",
      "Epoch 239 completed, Train Loss: 0.000014\n",
      "\n",
      "Epoch 240, Step 1, LR: 0.000868, Current Loss: 0.0694, Avg Loss: 0.0694\n",
      "Diff stats — min: -7.3013, max: 10.0000, mean: 7.3633, std: 3.0155\n",
      "\n",
      "Step 7141 — Test metrics:\n",
      "  precision@10: 0.014120698\n",
      "  recall@10: 0.014164852\n",
      "  ndcg@10: 0.014919625\n",
      "  map@10: 0.005478271\n",
      "Epoch 240, Step 20, LR: 0.000868, Current Loss: 0.0600, Avg Loss: 0.0566\n",
      "Diff stats — min: -5.6561, max: 10.0000, mean: 7.4822, std: 2.9606\n",
      "\n",
      "Epoch 240 completed, Train Loss: 0.000014\n",
      "\n",
      "Epoch 241, Step 1, LR: 0.000851, Current Loss: 0.0578, Avg Loss: 0.0578\n",
      "Diff stats — min: -9.7022, max: 10.0000, mean: 7.5046, std: 2.9334\n",
      "\n",
      "Step 7171 — Test metrics:\n",
      "  precision@10: 0.014026403\n",
      "  recall@10: 0.014070557\n",
      "  ndcg@10: 0.015017849\n",
      "  map@10: 0.005516263\n",
      "Epoch 241, Step 20, LR: 0.000851, Current Loss: 0.0584, Avg Loss: 0.0555\n",
      "Diff stats — min: -5.6449, max: 10.0000, mean: 7.4222, std: 2.9679\n",
      "\n",
      "Epoch 241 completed, Train Loss: 0.000014\n",
      "\n",
      "Epoch 242, Step 1, LR: 0.000851, Current Loss: 0.0523, Avg Loss: 0.0523\n",
      "Diff stats — min: -6.1913, max: 10.0000, mean: 7.4287, std: 2.9222\n",
      "\n",
      "Step 7201 — Test metrics:\n",
      "  precision@10: 0.013578501\n",
      "  recall@10: 0.013630139\n",
      "  ndcg@10: 0.014451037\n",
      "  map@10: 0.005238376\n",
      "Epoch 242, Step 20, LR: 0.000851, Current Loss: 0.0523, Avg Loss: 0.0553\n",
      "Diff stats — min: -7.6430, max: 10.0000, mean: 7.4527, std: 2.9634\n",
      "\n",
      "Epoch 242 completed, Train Loss: 0.000014\n",
      "\n",
      "Epoch 243, Step 1, LR: 0.000851, Current Loss: 0.0542, Avg Loss: 0.0542\n",
      "Diff stats — min: -6.3112, max: 10.0000, mean: 7.5388, std: 2.8927\n",
      "\n",
      "Step 7231 — Test metrics:\n",
      "  precision@10: 0.014049976\n",
      "  recall@10: 0.014109472\n",
      "  ndcg@10: 0.014937089\n",
      "  map@10: 0.005471105\n",
      "Epoch 243, Step 20, LR: 0.000851, Current Loss: 0.0572, Avg Loss: 0.0538\n",
      "Diff stats — min: -8.0734, max: 10.0000, mean: 7.4520, std: 2.9488\n",
      "\n",
      "Epoch 243 completed, Train Loss: 0.000013\n",
      "\n",
      "Epoch 244, Step 1, LR: 0.000851, Current Loss: 0.0620, Avg Loss: 0.0620\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 7.4125, std: 2.9922\n",
      "\n",
      "Step 7261 — Test metrics:\n",
      "  precision@10: 0.014073550\n",
      "  recall@10: 0.014125188\n",
      "  ndcg@10: 0.015116490\n",
      "  map@10: 0.005630240\n",
      "Epoch 244, Step 20, LR: 0.000851, Current Loss: 0.0543, Avg Loss: 0.0551\n",
      "Diff stats — min: -6.9881, max: 10.0000, mean: 7.4140, std: 2.9506\n",
      "\n",
      "Epoch 244 completed, Train Loss: 0.000014\n",
      "\n",
      "Epoch 245, Step 1, LR: 0.000851, Current Loss: 0.0557, Avg Loss: 0.0557\n",
      "Diff stats — min: -6.7571, max: 10.0000, mean: 7.4955, std: 2.9233\n",
      "\n",
      "Step 7291 — Test metrics:\n",
      "  precision@10: 0.013861386\n",
      "  recall@10: 0.013913024\n",
      "  ndcg@10: 0.015043040\n",
      "  map@10: 0.005650665\n",
      "Epoch 245, Step 20, LR: 0.000851, Current Loss: 0.0561, Avg Loss: 0.0536\n",
      "Diff stats — min: -8.4351, max: 10.0000, mean: 7.4615, std: 2.9176\n",
      "\n",
      "Epoch 245 completed, Train Loss: 0.000013\n",
      "\n",
      "Epoch 246, Step 1, LR: 0.000834, Current Loss: 0.0512, Avg Loss: 0.0512\n",
      "Diff stats — min: -6.4089, max: 10.0000, mean: 7.4895, std: 2.9371\n",
      "\n",
      "Step 7321 — Test metrics:\n",
      "  precision@10: 0.013908534\n",
      "  recall@10: 0.013971304\n",
      "  ndcg@10: 0.015044701\n",
      "  map@10: 0.005712125\n",
      "Epoch 246, Step 20, LR: 0.000834, Current Loss: 0.0616, Avg Loss: 0.0525\n",
      "Diff stats — min: -7.0615, max: 10.0000, mean: 7.4569, std: 2.9627\n",
      "\n",
      "Epoch 246 completed, Train Loss: 0.000013\n",
      "\n",
      "Epoch 247, Step 1, LR: 0.000834, Current Loss: 0.0585, Avg Loss: 0.0585\n",
      "Diff stats — min: -8.0137, max: 10.0000, mean: 7.5038, std: 2.9389\n",
      "\n",
      "Step 7351 — Test metrics:\n",
      "  precision@10: 0.013767091\n",
      "  recall@10: 0.013813864\n",
      "  ndcg@10: 0.015071382\n",
      "  map@10: 0.005717079\n",
      "Epoch 247, Step 20, LR: 0.000834, Current Loss: 0.0534, Avg Loss: 0.0531\n",
      "Diff stats — min: -6.9649, max: 10.0000, mean: 7.5675, std: 2.9140\n",
      "\n",
      "Epoch 247 completed, Train Loss: 0.000013\n",
      "\n",
      "Epoch 248, Step 1, LR: 0.000834, Current Loss: 0.0470, Avg Loss: 0.0470\n",
      "Diff stats — min: -6.0298, max: 10.0000, mean: 7.5569, std: 2.8735\n",
      "\n",
      "Step 7381 — Test metrics:\n",
      "  precision@10: 0.014191419\n",
      "  recall@10: 0.014244086\n",
      "  ndcg@10: 0.015250966\n",
      "  map@10: 0.005792612\n",
      "Epoch 248, Step 20, LR: 0.000834, Current Loss: 0.0456, Avg Loss: 0.0529\n",
      "Diff stats — min: -4.7783, max: 10.0000, mean: 7.5470, std: 2.8756\n",
      "\n",
      "Epoch 248 completed, Train Loss: 0.000013\n",
      "\n",
      "Epoch 249, Step 1, LR: 0.000834, Current Loss: 0.0439, Avg Loss: 0.0439\n",
      "Diff stats — min: -7.5953, max: 10.0000, mean: 7.6283, std: 2.8220\n",
      "\n",
      "Step 7411 — Test metrics:\n",
      "  precision@10: 0.013389910\n",
      "  recall@10: 0.013437339\n",
      "  ndcg@10: 0.014968382\n",
      "  map@10: 0.005724582\n",
      "Epoch 249, Step 20, LR: 0.000834, Current Loss: 0.0553, Avg Loss: 0.0542\n",
      "Diff stats — min: -6.3397, max: 10.0000, mean: 7.4958, std: 2.9431\n",
      "\n",
      "Epoch 249 completed, Train Loss: 0.000013\n",
      "\n",
      "Epoch 250, Step 1, LR: 0.000834, Current Loss: 0.0535, Avg Loss: 0.0535\n",
      "Diff stats — min: -6.5944, max: 10.0000, mean: 7.5282, std: 2.9146\n",
      "\n",
      "Step 7441 — Test metrics:\n",
      "  precision@10: 0.013767091\n",
      "  recall@10: 0.013811245\n",
      "  ndcg@10: 0.015223503\n",
      "  map@10: 0.005736289\n",
      "Epoch 250, Step 20, LR: 0.000834, Current Loss: 0.0546, Avg Loss: 0.0525\n",
      "Diff stats — min: -5.8196, max: 10.0000, mean: 7.5146, std: 2.9437\n",
      "\n",
      "Epoch 250 completed, Train Loss: 0.000013\n",
      "\n",
      "Epoch 251, Step 1, LR: 0.000817, Current Loss: 0.0490, Avg Loss: 0.0490\n",
      "Diff stats — min: -5.2306, max: 10.0000, mean: 7.5959, std: 2.8820\n",
      "\n",
      "Step 7471 — Test metrics:\n",
      "  precision@10: 0.013083451\n",
      "  recall@10: 0.013127605\n",
      "  ndcg@10: 0.014627612\n",
      "  map@10: 0.005651780\n",
      "Epoch 251, Step 20, LR: 0.000817, Current Loss: 0.0516, Avg Loss: 0.0535\n",
      "Diff stats — min: -5.1025, max: 10.0000, mean: 7.4334, std: 2.9153\n",
      "\n",
      "Epoch 251 completed, Train Loss: 0.000013\n",
      "\n",
      "Epoch 252, Step 1, LR: 0.000817, Current Loss: 0.0541, Avg Loss: 0.0541\n",
      "Diff stats — min: -5.6503, max: 10.0000, mean: 7.5234, std: 2.9153\n",
      "\n",
      "Step 7501 — Test metrics:\n",
      "  precision@10: 0.013932107\n",
      "  recall@10: 0.013978881\n",
      "  ndcg@10: 0.015214052\n",
      "  map@10: 0.005768311\n",
      "Epoch 252, Step 20, LR: 0.000817, Current Loss: 0.0544, Avg Loss: 0.0513\n",
      "Diff stats — min: -6.8777, max: 10.0000, mean: 7.5774, std: 2.9004\n",
      "\n",
      "Epoch 252 completed, Train Loss: 0.000013\n",
      "\n",
      "Epoch 253, Step 1, LR: 0.000817, Current Loss: 0.0501, Avg Loss: 0.0501\n",
      "Diff stats — min: -9.2009, max: 10.0000, mean: 7.5771, std: 2.8690\n",
      "\n",
      "Step 7531 — Test metrics:\n",
      "  precision@10: 0.013366337\n",
      "  recall@10: 0.013410491\n",
      "  ndcg@10: 0.014703031\n",
      "  map@10: 0.005534146\n",
      "Epoch 253, Step 20, LR: 0.000817, Current Loss: 0.0456, Avg Loss: 0.0513\n",
      "Diff stats — min: -4.7075, max: 10.0000, mean: 7.5940, std: 2.8269\n",
      "\n",
      "Epoch 253 completed, Train Loss: 0.000013\n",
      "\n",
      "Epoch 254, Step 1, LR: 0.000817, Current Loss: 0.0476, Avg Loss: 0.0476\n",
      "Diff stats — min: -6.2957, max: 10.0000, mean: 7.6426, std: 2.8545\n",
      "\n",
      "Step 7561 — Test metrics:\n",
      "  precision@10: 0.013649222\n",
      "  recall@10: 0.013690757\n",
      "  ndcg@10: 0.014925666\n",
      "  map@10: 0.005630876\n",
      "Epoch 254, Step 20, LR: 0.000817, Current Loss: 0.0521, Avg Loss: 0.0504\n",
      "Diff stats — min: -6.1999, max: 10.0000, mean: 7.5581, std: 2.8867\n",
      "\n",
      "Epoch 254 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 255, Step 1, LR: 0.000817, Current Loss: 0.0443, Avg Loss: 0.0443\n",
      "Diff stats — min: -5.3674, max: 10.0000, mean: 7.6506, std: 2.8346\n",
      "\n",
      "Step 7591 — Test metrics:\n",
      "  precision@10: 0.014167845\n",
      "  recall@10: 0.014211999\n",
      "  ndcg@10: 0.015304292\n",
      "  map@10: 0.005787405\n",
      "Epoch 255, Step 20, LR: 0.000817, Current Loss: 0.0421, Avg Loss: 0.0495\n",
      "Diff stats — min: -6.2572, max: 10.0000, mean: 7.6077, std: 2.8323\n",
      "\n",
      "Epoch 255 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 256, Step 1, LR: 0.000801, Current Loss: 0.0461, Avg Loss: 0.0461\n",
      "Diff stats — min: -6.7079, max: 10.0000, mean: 7.6830, std: 2.8266\n",
      "\n",
      "Step 7621 — Test metrics:\n",
      "  precision@10: 0.014002829\n",
      "  recall@10: 0.014059705\n",
      "  ndcg@10: 0.014964920\n",
      "  map@10: 0.005614131\n",
      "Epoch 256, Step 20, LR: 0.000801, Current Loss: 0.0505, Avg Loss: 0.0515\n",
      "Diff stats — min: -6.4829, max: 10.0000, mean: 7.6799, std: 2.8679\n",
      "\n",
      "Epoch 256 completed, Train Loss: 0.000013\n",
      "\n",
      "Epoch 257, Step 1, LR: 0.000801, Current Loss: 0.0485, Avg Loss: 0.0485\n",
      "Diff stats — min: -8.5248, max: 10.0000, mean: 7.6092, std: 2.8465\n",
      "\n",
      "Step 7651 — Test metrics:\n",
      "  precision@10: 0.013649222\n",
      "  recall@10: 0.013698615\n",
      "  ndcg@10: 0.014884738\n",
      "  map@10: 0.005675488\n",
      "Epoch 257, Step 20, LR: 0.000801, Current Loss: 0.0460, Avg Loss: 0.0491\n",
      "Diff stats — min: -5.2908, max: 10.0000, mean: 7.6319, std: 2.8456\n",
      "\n",
      "Epoch 257 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 258, Step 1, LR: 0.000801, Current Loss: 0.0492, Avg Loss: 0.0492\n",
      "Diff stats — min: -4.7408, max: 10.0000, mean: 7.5932, std: 2.8819\n",
      "\n",
      "Step 7681 — Test metrics:\n",
      "  precision@10: 0.013861386\n",
      "  recall@10: 0.013924156\n",
      "  ndcg@10: 0.014787595\n",
      "  map@10: 0.005580289\n",
      "Epoch 258, Step 20, LR: 0.000801, Current Loss: 0.0620, Avg Loss: 0.0518\n",
      "Diff stats — min: -7.3673, max: 10.0000, mean: 7.6065, std: 2.9354\n",
      "\n",
      "Epoch 258 completed, Train Loss: 0.000013\n",
      "\n",
      "Epoch 259, Step 1, LR: 0.000801, Current Loss: 0.0513, Avg Loss: 0.0513\n",
      "Diff stats — min: -5.6723, max: 10.0000, mean: 7.6549, std: 2.8639\n",
      "\n",
      "Step 7711 — Test metrics:\n",
      "  precision@10: 0.014167845\n",
      "  recall@10: 0.014220512\n",
      "  ndcg@10: 0.015183195\n",
      "  map@10: 0.005661918\n",
      "Epoch 259, Step 20, LR: 0.000801, Current Loss: 0.0652, Avg Loss: 0.0509\n",
      "Diff stats — min: -7.0296, max: 10.0000, mean: 7.5854, std: 2.9651\n",
      "\n",
      "Epoch 259 completed, Train Loss: 0.000013\n",
      "\n",
      "Epoch 260, Step 1, LR: 0.000801, Current Loss: 0.0533, Avg Loss: 0.0533\n",
      "Diff stats — min: -6.9297, max: 10.0000, mean: 7.6329, std: 2.9054\n",
      "\n",
      "Step 7741 — Test metrics:\n",
      "  precision@10: 0.013625648\n",
      "  recall@10: 0.013673076\n",
      "  ndcg@10: 0.014814901\n",
      "  map@10: 0.005557785\n",
      "Epoch 260, Step 20, LR: 0.000801, Current Loss: 0.0419, Avg Loss: 0.0505\n",
      "Diff stats — min: -5.8015, max: 10.0000, mean: 7.7328, std: 2.7819\n",
      "\n",
      "Epoch 260 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 261, Step 1, LR: 0.000785, Current Loss: 0.0465, Avg Loss: 0.0465\n",
      "Diff stats — min: -6.7008, max: 10.0000, mean: 7.6968, std: 2.8108\n",
      "\n",
      "Step 7771 — Test metrics:\n",
      "  precision@10: 0.013790665\n",
      "  recall@10: 0.013834819\n",
      "  ndcg@10: 0.014911425\n",
      "  map@10: 0.005555263\n",
      "Epoch 261, Step 20, LR: 0.000785, Current Loss: 0.0518, Avg Loss: 0.0472\n",
      "Diff stats — min: -5.0083, max: 10.0000, mean: 7.6406, std: 2.8957\n",
      "\n",
      "Epoch 261 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 262, Step 1, LR: 0.000785, Current Loss: 0.0507, Avg Loss: 0.0507\n",
      "Diff stats — min: -5.4561, max: 10.0000, mean: 7.6205, std: 2.8762\n",
      "\n",
      "Step 7801 — Test metrics:\n",
      "  precision@10: 0.014049976\n",
      "  recall@10: 0.014101988\n",
      "  ndcg@10: 0.014954683\n",
      "  map@10: 0.005566666\n",
      "Epoch 262, Step 20, LR: 0.000785, Current Loss: 0.0471, Avg Loss: 0.0488\n",
      "Diff stats — min: -6.6130, max: 10.0000, mean: 7.6800, std: 2.8322\n",
      "\n",
      "Epoch 262 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 263, Step 1, LR: 0.000785, Current Loss: 0.0456, Avg Loss: 0.0456\n",
      "Diff stats — min: -5.0085, max: 10.0000, mean: 7.7185, std: 2.8390\n",
      "\n",
      "Step 7831 — Test metrics:\n",
      "  precision@10: 0.013460632\n",
      "  recall@10: 0.013507405\n",
      "  ndcg@10: 0.014659465\n",
      "  map@10: 0.005526191\n",
      "Epoch 263, Step 20, LR: 0.000785, Current Loss: 0.0490, Avg Loss: 0.0479\n",
      "Diff stats — min: -7.2423, max: 10.0000, mean: 7.6422, std: 2.8403\n",
      "\n",
      "Epoch 263 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 264, Step 1, LR: 0.000785, Current Loss: 0.0457, Avg Loss: 0.0457\n",
      "Diff stats — min: -7.3620, max: 10.0000, mean: 7.6217, std: 2.8956\n",
      "\n",
      "Step 7861 — Test metrics:\n",
      "  precision@10: 0.013861386\n",
      "  recall@10: 0.013910779\n",
      "  ndcg@10: 0.014961047\n",
      "  map@10: 0.005597674\n",
      "Epoch 264, Step 20, LR: 0.000785, Current Loss: 0.0479, Avg Loss: 0.0497\n",
      "Diff stats — min: -5.4076, max: 10.0000, mean: 7.7273, std: 2.8463\n",
      "\n",
      "Epoch 264 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 265, Step 1, LR: 0.000785, Current Loss: 0.0490, Avg Loss: 0.0490\n",
      "Diff stats — min: -7.0402, max: 10.0000, mean: 7.6404, std: 2.8678\n",
      "\n",
      "Step 7891 — Test metrics:\n",
      "  precision@10: 0.013625648\n",
      "  recall@10: 0.013672422\n",
      "  ndcg@10: 0.014738966\n",
      "  map@10: 0.005536540\n",
      "Epoch 265, Step 20, LR: 0.000785, Current Loss: 0.0548, Avg Loss: 0.0493\n",
      "Diff stats — min: -7.2186, max: 10.0000, mean: 7.6743, std: 2.8927\n",
      "\n",
      "Epoch 265 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 266, Step 1, LR: 0.000769, Current Loss: 0.0492, Avg Loss: 0.0492\n",
      "Diff stats — min: -9.0011, max: 10.0000, mean: 7.7365, std: 2.8471\n",
      "\n",
      "Step 7921 — Test metrics:\n",
      "  precision@10: 0.013979255\n",
      "  recall@10: 0.014020790\n",
      "  ndcg@10: 0.014779969\n",
      "  map@10: 0.005485471\n",
      "Epoch 266, Step 20, LR: 0.000769, Current Loss: 0.0505, Avg Loss: 0.0474\n",
      "Diff stats — min: -6.4171, max: 10.0000, mean: 7.6209, std: 2.8982\n",
      "\n",
      "Epoch 266 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 267, Step 1, LR: 0.000769, Current Loss: 0.0485, Avg Loss: 0.0485\n",
      "Diff stats — min: -5.1615, max: 10.0000, mean: 7.7028, std: 2.8695\n",
      "\n",
      "Step 7951 — Test metrics:\n",
      "  precision@10: 0.014262140\n",
      "  recall@10: 0.014314153\n",
      "  ndcg@10: 0.015467497\n",
      "  map@10: 0.005812072\n",
      "Epoch 267, Step 20, LR: 0.000769, Current Loss: 0.0549, Avg Loss: 0.0486\n",
      "Diff stats — min: -7.4267, max: 10.0000, mean: 7.6895, std: 2.8927\n",
      "\n",
      "Epoch 267 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 268, Step 1, LR: 0.000769, Current Loss: 0.0447, Avg Loss: 0.0447\n",
      "Diff stats — min: -8.0471, max: 10.0000, mean: 7.7540, std: 2.7990\n",
      "\n",
      "Step 7981 — Test metrics:\n",
      "  precision@10: 0.013649222\n",
      "  recall@10: 0.013690757\n",
      "  ndcg@10: 0.014662797\n",
      "  map@10: 0.005433171\n",
      "Epoch 268, Step 20, LR: 0.000769, Current Loss: 0.0408, Avg Loss: 0.0468\n",
      "Diff stats — min: -5.5215, max: 10.0000, mean: 7.7149, std: 2.7958\n",
      "\n",
      "Epoch 268 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 269, Step 1, LR: 0.000769, Current Loss: 0.0434, Avg Loss: 0.0434\n",
      "Diff stats — min: -4.7295, max: 10.0000, mean: 7.7708, std: 2.7892\n",
      "\n",
      "Step 8011 — Test metrics:\n",
      "  precision@10: 0.014049976\n",
      "  recall@10: 0.014096750\n",
      "  ndcg@10: 0.015386414\n",
      "  map@10: 0.005778418\n",
      "Epoch 269, Step 20, LR: 0.000769, Current Loss: 0.0433, Avg Loss: 0.0474\n",
      "Diff stats — min: -4.7375, max: 10.0000, mean: 7.7704, std: 2.7963\n",
      "\n",
      "Epoch 269 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 270, Step 1, LR: 0.000769, Current Loss: 0.0463, Avg Loss: 0.0463\n",
      "Diff stats — min: -8.0298, max: 10.0000, mean: 7.7560, std: 2.8318\n",
      "\n",
      "Step 8041 — Test metrics:\n",
      "  precision@10: 0.014309288\n",
      "  recall@10: 0.014364574\n",
      "  ndcg@10: 0.015310112\n",
      "  map@10: 0.005656902\n",
      "Epoch 270, Step 20, LR: 0.000769, Current Loss: 0.0470, Avg Loss: 0.0459\n",
      "Diff stats — min: -7.1176, max: 10.0000, mean: 7.7886, std: 2.8195\n",
      "\n",
      "Epoch 270 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 271, Step 1, LR: 0.000754, Current Loss: 0.0409, Avg Loss: 0.0409\n",
      "Diff stats — min: -4.4295, max: 10.0000, mean: 7.6776, std: 2.8255\n",
      "\n",
      "Step 8071 — Test metrics:\n",
      "  precision@10: 0.013437058\n",
      "  recall@10: 0.013486451\n",
      "  ndcg@10: 0.014577992\n",
      "  map@10: 0.005451703\n",
      "Epoch 271, Step 20, LR: 0.000754, Current Loss: 0.0511, Avg Loss: 0.0463\n",
      "Diff stats — min: -7.4800, max: 10.0000, mean: 7.6806, std: 2.8658\n",
      "\n",
      "Epoch 271 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 272, Step 1, LR: 0.000754, Current Loss: 0.0467, Avg Loss: 0.0467\n",
      "Diff stats — min: -7.2427, max: 10.0000, mean: 7.7937, std: 2.7958\n",
      "\n",
      "Step 8101 — Test metrics:\n",
      "  precision@10: 0.014238567\n",
      "  recall@10: 0.014287959\n",
      "  ndcg@10: 0.015002627\n",
      "  map@10: 0.005545974\n",
      "Epoch 272, Step 20, LR: 0.000754, Current Loss: 0.0391, Avg Loss: 0.0469\n",
      "Diff stats — min: -5.0295, max: 10.0000, mean: 7.8172, std: 2.7846\n",
      "\n",
      "Epoch 272 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 273, Step 1, LR: 0.000754, Current Loss: 0.0555, Avg Loss: 0.0555\n",
      "Diff stats — min: -7.6653, max: 10.0000, mean: 7.7248, std: 2.8965\n",
      "\n",
      "Step 8131 — Test metrics:\n",
      "  precision@10: 0.014026403\n",
      "  recall@10: 0.014075795\n",
      "  ndcg@10: 0.014909747\n",
      "  map@10: 0.005574720\n",
      "Epoch 273, Step 20, LR: 0.000754, Current Loss: 0.0443, Avg Loss: 0.0481\n",
      "Diff stats — min: -5.5182, max: 10.0000, mean: 7.7868, std: 2.7914\n",
      "\n",
      "Epoch 273 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 274, Step 1, LR: 0.000754, Current Loss: 0.0468, Avg Loss: 0.0468\n",
      "Diff stats — min: -8.3175, max: 10.0000, mean: 7.7334, std: 2.8743\n",
      "\n",
      "Step 8161 — Test metrics:\n",
      "  precision@10: 0.013837812\n",
      "  recall@10: 0.013884586\n",
      "  ndcg@10: 0.015165875\n",
      "  map@10: 0.005758271\n",
      "Epoch 274, Step 20, LR: 0.000754, Current Loss: 0.0509, Avg Loss: 0.0456\n",
      "Diff stats — min: -5.5138, max: 10.0000, mean: 7.7607, std: 2.8533\n",
      "\n",
      "Epoch 274 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 275, Step 1, LR: 0.000754, Current Loss: 0.0371, Avg Loss: 0.0371\n",
      "Diff stats — min: -8.2752, max: 10.0000, mean: 7.8297, std: 2.7678\n",
      "\n",
      "Step 8191 — Test metrics:\n",
      "  precision@10: 0.014497878\n",
      "  recall@10: 0.014542032\n",
      "  ndcg@10: 0.015353525\n",
      "  map@10: 0.005690372\n",
      "Epoch 275, Step 20, LR: 0.000754, Current Loss: 0.0426, Avg Loss: 0.0452\n",
      "Diff stats — min: -6.3837, max: 10.0000, mean: 7.8098, std: 2.7798\n",
      "\n",
      "Epoch 275 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 276, Step 1, LR: 0.000739, Current Loss: 0.0416, Avg Loss: 0.0416\n",
      "Diff stats — min: -4.2556, max: 10.0000, mean: 7.8340, std: 2.7901\n",
      "\n",
      "Step 8221 — Test metrics:\n",
      "  precision@10: 0.014262140\n",
      "  recall@10: 0.014314807\n",
      "  ndcg@10: 0.015326229\n",
      "  map@10: 0.005742896\n",
      "Epoch 276, Step 20, LR: 0.000739, Current Loss: 0.0373, Avg Loss: 0.0454\n",
      "Diff stats — min: -3.9428, max: 10.0000, mean: 7.8605, std: 2.7410\n",
      "\n",
      "Epoch 276 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 277, Step 1, LR: 0.000739, Current Loss: 0.0420, Avg Loss: 0.0420\n",
      "Diff stats — min: -5.1837, max: 10.0000, mean: 7.8251, std: 2.7602\n",
      "\n",
      "Step 8251 — Test metrics:\n",
      "  precision@10: 0.014073550\n",
      "  recall@10: 0.014117704\n",
      "  ndcg@10: 0.015029031\n",
      "  map@10: 0.005590536\n",
      "Epoch 277, Step 20, LR: 0.000739, Current Loss: 0.0496, Avg Loss: 0.0457\n",
      "Diff stats — min: -7.5885, max: 10.0000, mean: 7.8087, std: 2.8305\n",
      "\n",
      "Epoch 277 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 278, Step 1, LR: 0.000739, Current Loss: 0.0516, Avg Loss: 0.0516\n",
      "Diff stats — min: -6.4526, max: 10.0000, mean: 7.8026, std: 2.8555\n",
      "\n",
      "Step 8281 — Test metrics:\n",
      "  precision@10: 0.013861386\n",
      "  recall@10: 0.013905540\n",
      "  ndcg@10: 0.014781277\n",
      "  map@10: 0.005447949\n",
      "Epoch 278, Step 20, LR: 0.000739, Current Loss: 0.0432, Avg Loss: 0.0449\n",
      "Diff stats — min: -4.5244, max: 10.0000, mean: 7.7916, std: 2.8324\n",
      "\n",
      "Epoch 278 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 279, Step 1, LR: 0.000739, Current Loss: 0.0458, Avg Loss: 0.0458\n",
      "Diff stats — min: -6.2332, max: 10.0000, mean: 7.7798, std: 2.8397\n",
      "\n",
      "Step 8311 — Test metrics:\n",
      "  precision@10: 0.013861386\n",
      "  recall@10: 0.013908814\n",
      "  ndcg@10: 0.015055252\n",
      "  map@10: 0.005670646\n",
      "Epoch 279, Step 20, LR: 0.000739, Current Loss: 0.0486, Avg Loss: 0.0463\n",
      "Diff stats — min: -5.2325, max: 10.0000, mean: 7.8065, std: 2.8098\n",
      "\n",
      "Epoch 279 completed, Train Loss: 0.000012\n",
      "\n",
      "Epoch 280, Step 1, LR: 0.000739, Current Loss: 0.0513, Avg Loss: 0.0513\n",
      "Diff stats — min: -7.3415, max: 10.0000, mean: 7.8851, std: 2.8436\n",
      "\n",
      "Step 8341 — Test metrics:\n",
      "  precision@10: 0.014191419\n",
      "  recall@10: 0.014238847\n",
      "  ndcg@10: 0.015265409\n",
      "  map@10: 0.005731586\n",
      "Epoch 280, Step 20, LR: 0.000739, Current Loss: 0.0359, Avg Loss: 0.0450\n",
      "Diff stats — min: -8.4626, max: 10.0000, mean: 7.8694, std: 2.7170\n",
      "\n",
      "Epoch 280 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 281, Step 1, LR: 0.000724, Current Loss: 0.0370, Avg Loss: 0.0370\n",
      "Diff stats — min: -4.7682, max: 10.0000, mean: 7.8795, std: 2.7365\n",
      "\n",
      "Step 8371 — Test metrics:\n",
      "  precision@10: 0.014120698\n",
      "  recall@10: 0.014167471\n",
      "  ndcg@10: 0.015089459\n",
      "  map@10: 0.005678868\n",
      "Epoch 281, Step 20, LR: 0.000724, Current Loss: 0.0463, Avg Loss: 0.0451\n",
      "Diff stats — min: -8.0516, max: 10.0000, mean: 7.7884, std: 2.8074\n",
      "\n",
      "Epoch 281 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 282, Step 1, LR: 0.000724, Current Loss: 0.0393, Avg Loss: 0.0393\n",
      "Diff stats — min: -4.3572, max: 10.0000, mean: 7.8160, std: 2.7579\n",
      "\n",
      "Step 8401 — Test metrics:\n",
      "  precision@10: 0.014639321\n",
      "  recall@10: 0.014696852\n",
      "  ndcg@10: 0.015787129\n",
      "  map@10: 0.005943071\n",
      "Epoch 282, Step 20, LR: 0.000724, Current Loss: 0.0421, Avg Loss: 0.0442\n",
      "Diff stats — min: -6.2840, max: 10.0000, mean: 7.9285, std: 2.7360\n",
      "\n",
      "Epoch 282 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 283, Step 1, LR: 0.000724, Current Loss: 0.0464, Avg Loss: 0.0464\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 7.7998, std: 2.8083\n",
      "\n",
      "Step 8431 — Test metrics:\n",
      "  precision@10: 0.014780764\n",
      "  recall@10: 0.014840914\n",
      "  ndcg@10: 0.015843190\n",
      "  map@10: 0.005972590\n",
      "Epoch 283, Step 20, LR: 0.000724, Current Loss: 0.0441, Avg Loss: 0.0441\n",
      "Diff stats — min: -7.4806, max: 10.0000, mean: 7.8135, std: 2.8127\n",
      "\n",
      "Epoch 283 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 284, Step 1, LR: 0.000724, Current Loss: 0.0476, Avg Loss: 0.0476\n",
      "Diff stats — min: -5.9408, max: 10.0000, mean: 7.8246, std: 2.8216\n",
      "\n",
      "Step 8461 — Test metrics:\n",
      "  precision@10: 0.014332862\n",
      "  recall@10: 0.014393012\n",
      "  ndcg@10: 0.015472470\n",
      "  map@10: 0.005845545\n",
      "Epoch 284, Step 20, LR: 0.000724, Current Loss: 0.0423, Avg Loss: 0.0438\n",
      "Diff stats — min: -5.5209, max: 10.0000, mean: 7.8497, std: 2.8026\n",
      "\n",
      "Epoch 284 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 285, Step 1, LR: 0.000724, Current Loss: 0.0421, Avg Loss: 0.0421\n",
      "Diff stats — min: -4.7584, max: 10.0000, mean: 7.8721, std: 2.8020\n",
      "\n",
      "Step 8491 — Test metrics:\n",
      "  precision@10: 0.013861386\n",
      "  recall@10: 0.013906195\n",
      "  ndcg@10: 0.014884212\n",
      "  map@10: 0.005546183\n",
      "Epoch 285, Step 20, LR: 0.000724, Current Loss: 0.0374, Avg Loss: 0.0450\n",
      "Diff stats — min: -5.6928, max: 10.0000, mean: 7.8851, std: 2.7328\n",
      "\n",
      "Epoch 285 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 286, Step 1, LR: 0.000709, Current Loss: 0.0427, Avg Loss: 0.0427\n",
      "Diff stats — min: -5.6623, max: 10.0000, mean: 7.8255, std: 2.8204\n",
      "\n",
      "Step 8521 — Test metrics:\n",
      "  precision@10: 0.014002829\n",
      "  recall@10: 0.014056151\n",
      "  ndcg@10: 0.015132240\n",
      "  map@10: 0.005648703\n",
      "Epoch 286, Step 20, LR: 0.000709, Current Loss: 0.0439, Avg Loss: 0.0449\n",
      "Diff stats — min: -5.0318, max: 10.0000, mean: 7.8576, std: 2.7983\n",
      "\n",
      "Epoch 286 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 287, Step 1, LR: 0.000709, Current Loss: 0.0470, Avg Loss: 0.0470\n",
      "Diff stats — min: -4.3739, max: 10.0000, mean: 7.8042, std: 2.8469\n",
      "\n",
      "Step 8551 — Test metrics:\n",
      "  precision@10: 0.014214993\n",
      "  recall@10: 0.014265040\n",
      "  ndcg@10: 0.015458392\n",
      "  map@10: 0.005866210\n",
      "Epoch 287, Step 20, LR: 0.000709, Current Loss: 0.0487, Avg Loss: 0.0428\n",
      "Diff stats — min: -6.6234, max: 10.0000, mean: 7.7823, std: 2.8639\n",
      "\n",
      "Epoch 287 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 288, Step 1, LR: 0.000709, Current Loss: 0.0388, Avg Loss: 0.0388\n",
      "Diff stats — min: -4.9222, max: 10.0000, mean: 7.8678, std: 2.7613\n",
      "\n",
      "Step 8581 — Test metrics:\n",
      "  precision@10: 0.013578501\n",
      "  recall@10: 0.013623310\n",
      "  ndcg@10: 0.014922914\n",
      "  map@10: 0.005726554\n",
      "Epoch 288, Step 20, LR: 0.000709, Current Loss: 0.0460, Avg Loss: 0.0443\n",
      "Diff stats — min: -6.3432, max: 10.0000, mean: 7.8765, std: 2.7966\n",
      "\n",
      "Epoch 288 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 289, Step 1, LR: 0.000709, Current Loss: 0.0425, Avg Loss: 0.0425\n",
      "Diff stats — min: -6.5914, max: 10.0000, mean: 7.9124, std: 2.7779\n",
      "\n",
      "Step 8611 — Test metrics:\n",
      "  precision@10: 0.014120698\n",
      "  recall@10: 0.014164852\n",
      "  ndcg@10: 0.015487618\n",
      "  map@10: 0.005940508\n",
      "Epoch 289, Step 20, LR: 0.000709, Current Loss: 0.0394, Avg Loss: 0.0440\n",
      "Diff stats — min: -5.3277, max: 10.0000, mean: 7.8669, std: 2.7762\n",
      "\n",
      "Epoch 289 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 290, Step 1, LR: 0.000709, Current Loss: 0.0415, Avg Loss: 0.0415\n",
      "Diff stats — min: -6.7972, max: 10.0000, mean: 7.8783, std: 2.7609\n",
      "\n",
      "Step 8641 — Test metrics:\n",
      "  precision@10: 0.014049976\n",
      "  recall@10: 0.014091511\n",
      "  ndcg@10: 0.015369033\n",
      "  map@10: 0.005874453\n",
      "Epoch 290, Step 20, LR: 0.000709, Current Loss: 0.0526, Avg Loss: 0.0425\n",
      "Diff stats — min: -6.4859, max: 10.0000, mean: 7.7955, std: 2.8690\n",
      "\n",
      "Epoch 290 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 291, Step 1, LR: 0.000695, Current Loss: 0.0427, Avg Loss: 0.0427\n",
      "Diff stats — min: -5.5939, max: 10.0000, mean: 7.8443, std: 2.7998\n",
      "\n",
      "Step 8671 — Test metrics:\n",
      "  precision@10: 0.014427157\n",
      "  recall@10: 0.014471311\n",
      "  ndcg@10: 0.015846969\n",
      "  map@10: 0.006057356\n",
      "Epoch 291, Step 20, LR: 0.000695, Current Loss: 0.0371, Avg Loss: 0.0419\n",
      "Diff stats — min: -5.1069, max: 10.0000, mean: 7.8638, std: 2.7365\n",
      "\n",
      "Epoch 291 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 292, Step 1, LR: 0.000695, Current Loss: 0.0461, Avg Loss: 0.0461\n",
      "Diff stats — min: -6.5174, max: 10.0000, mean: 7.8414, std: 2.8190\n",
      "\n",
      "Step 8701 — Test metrics:\n",
      "  precision@10: 0.013955681\n",
      "  recall@10: 0.014007693\n",
      "  ndcg@10: 0.015366668\n",
      "  map@10: 0.005835411\n",
      "Epoch 292, Step 20, LR: 0.000695, Current Loss: 0.0424, Avg Loss: 0.0426\n",
      "Diff stats — min: -6.5704, max: 10.0000, mean: 7.9195, std: 2.7618\n",
      "\n",
      "Epoch 292 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 293, Step 1, LR: 0.000695, Current Loss: 0.0424, Avg Loss: 0.0424\n",
      "Diff stats — min: -6.4117, max: 10.0000, mean: 7.9199, std: 2.7442\n",
      "\n",
      "Step 8731 — Test metrics:\n",
      "  precision@10: 0.014427157\n",
      "  recall@10: 0.014482443\n",
      "  ndcg@10: 0.016032858\n",
      "  map@10: 0.006191206\n",
      "Epoch 293, Step 20, LR: 0.000695, Current Loss: 0.0375, Avg Loss: 0.0412\n",
      "Diff stats — min: -6.9968, max: 10.0000, mean: 7.9564, std: 2.7348\n",
      "\n",
      "Epoch 293 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 294, Step 1, LR: 0.000695, Current Loss: 0.0411, Avg Loss: 0.0411\n",
      "Diff stats — min: -5.3740, max: 10.0000, mean: 7.9547, std: 2.7763\n",
      "\n",
      "Step 8761 — Test metrics:\n",
      "  precision@10: 0.014403583\n",
      "  recall@10: 0.014461489\n",
      "  ndcg@10: 0.015798138\n",
      "  map@10: 0.006046302\n",
      "Epoch 294, Step 20, LR: 0.000695, Current Loss: 0.0474, Avg Loss: 0.0418\n",
      "Diff stats — min: -6.1982, max: 10.0000, mean: 7.9072, std: 2.7978\n",
      "\n",
      "Epoch 294 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 295, Step 1, LR: 0.000695, Current Loss: 0.0392, Avg Loss: 0.0392\n",
      "Diff stats — min: -6.6857, max: 10.0000, mean: 7.9333, std: 2.7392\n",
      "\n",
      "Step 8791 — Test metrics:\n",
      "  precision@10: 0.013908534\n",
      "  recall@10: 0.013963820\n",
      "  ndcg@10: 0.015601127\n",
      "  map@10: 0.006044535\n",
      "Epoch 295, Step 20, LR: 0.000695, Current Loss: 0.0350, Avg Loss: 0.0411\n",
      "Diff stats — min: -5.0305, max: 10.0000, mean: 8.0206, std: 2.6882\n",
      "\n",
      "Epoch 295 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 296, Step 1, LR: 0.000681, Current Loss: 0.0404, Avg Loss: 0.0404\n",
      "Diff stats — min: -4.8764, max: 10.0000, mean: 7.8896, std: 2.7798\n",
      "\n",
      "Step 8821 — Test metrics:\n",
      "  precision@10: 0.014214993\n",
      "  recall@10: 0.014267005\n",
      "  ndcg@10: 0.015722677\n",
      "  map@10: 0.005983364\n",
      "Epoch 296, Step 20, LR: 0.000681, Current Loss: 0.0418, Avg Loss: 0.0402\n",
      "Diff stats — min: -6.0251, max: 10.0000, mean: 7.9063, std: 2.7644\n",
      "\n",
      "Epoch 296 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 297, Step 1, LR: 0.000681, Current Loss: 0.0482, Avg Loss: 0.0482\n",
      "Diff stats — min: -7.8568, max: 10.0000, mean: 7.8610, std: 2.8484\n",
      "\n",
      "Step 8851 — Test metrics:\n",
      "  precision@10: 0.014285714\n",
      "  recall@10: 0.014343620\n",
      "  ndcg@10: 0.015574063\n",
      "  map@10: 0.005908302\n",
      "Epoch 297, Step 20, LR: 0.000681, Current Loss: 0.0468, Avg Loss: 0.0425\n",
      "Diff stats — min: -4.7133, max: 10.0000, mean: 7.8963, std: 2.8222\n",
      "\n",
      "Epoch 297 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 298, Step 1, LR: 0.000681, Current Loss: 0.0458, Avg Loss: 0.0458\n",
      "Diff stats — min: -7.1177, max: 10.0000, mean: 7.9172, std: 2.7891\n",
      "\n",
      "Step 8881 — Test metrics:\n",
      "  precision@10: 0.014309288\n",
      "  recall@10: 0.014358681\n",
      "  ndcg@10: 0.015764382\n",
      "  map@10: 0.005991285\n",
      "Epoch 298, Step 20, LR: 0.000681, Current Loss: 0.0410, Avg Loss: 0.0439\n",
      "Diff stats — min: -8.5341, max: 10.0000, mean: 7.8894, std: 2.7892\n",
      "\n",
      "Epoch 298 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 299, Step 1, LR: 0.000681, Current Loss: 0.0433, Avg Loss: 0.0433\n",
      "Diff stats — min: -5.3299, max: 10.0000, mean: 7.9350, std: 2.7729\n",
      "\n",
      "Step 8911 — Test metrics:\n",
      "  precision@10: 0.013979255\n",
      "  recall@10: 0.014037161\n",
      "  ndcg@10: 0.015306000\n",
      "  map@10: 0.005808166\n",
      "Epoch 299, Step 20, LR: 0.000681, Current Loss: 0.0377, Avg Loss: 0.0430\n",
      "Diff stats — min: -5.9533, max: 10.0000, mean: 7.9890, std: 2.7160\n",
      "\n",
      "Epoch 299 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 300, Step 1, LR: 0.000681, Current Loss: 0.0398, Avg Loss: 0.0398\n",
      "Diff stats — min: -7.8308, max: 10.0000, mean: 7.9999, std: 2.7158\n",
      "\n",
      "Step 8941 — Test metrics:\n",
      "  precision@10: 0.013884960\n",
      "  recall@10: 0.013940246\n",
      "  ndcg@10: 0.015202789\n",
      "  map@10: 0.005773111\n",
      "Epoch 300, Step 20, LR: 0.000681, Current Loss: 0.0323, Avg Loss: 0.0421\n",
      "Diff stats — min: -4.5527, max: 10.0000, mean: 7.9926, std: 2.7021\n",
      "\n",
      "Epoch 300 completed, Train Loss: 0.000011\n",
      "\n",
      "Epoch 301, Step 1, LR: 0.000668, Current Loss: 0.0379, Avg Loss: 0.0379\n",
      "Diff stats — min: -5.8688, max: 10.0000, mean: 8.1116, std: 2.6773\n",
      "\n",
      "Step 8971 — Test metrics:\n",
      "  precision@10: 0.014780764\n",
      "  recall@10: 0.014836050\n",
      "  ndcg@10: 0.016090124\n",
      "  map@10: 0.006076564\n",
      "Epoch 301, Step 20, LR: 0.000668, Current Loss: 0.0414, Avg Loss: 0.0414\n",
      "Diff stats — min: -7.9648, max: 10.0000, mean: 7.9813, std: 2.7312\n",
      "\n",
      "Epoch 301 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 302, Step 1, LR: 0.000668, Current Loss: 0.0383, Avg Loss: 0.0383\n",
      "Diff stats — min: -5.5924, max: 10.0000, mean: 7.9684, std: 2.7225\n",
      "\n",
      "Step 9001 — Test metrics:\n",
      "  precision@10: 0.013908534\n",
      "  recall@10: 0.013963820\n",
      "  ndcg@10: 0.015481419\n",
      "  map@10: 0.005917584\n",
      "Epoch 302, Step 20, LR: 0.000668, Current Loss: 0.0455, Avg Loss: 0.0415\n",
      "Diff stats — min: -6.3905, max: 10.0000, mean: 7.9357, std: 2.7827\n",
      "\n",
      "Epoch 302 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 303, Step 1, LR: 0.000668, Current Loss: 0.0444, Avg Loss: 0.0444\n",
      "Diff stats — min: -5.7643, max: 10.0000, mean: 7.9697, std: 2.7476\n",
      "\n",
      "Step 9031 — Test metrics:\n",
      "  precision@10: 0.014332862\n",
      "  recall@10: 0.014388148\n",
      "  ndcg@10: 0.015847438\n",
      "  map@10: 0.006046650\n",
      "Epoch 303, Step 20, LR: 0.000668, Current Loss: 0.0401, Avg Loss: 0.0402\n",
      "Diff stats — min: -5.7739, max: 10.0000, mean: 7.9306, std: 2.7211\n",
      "\n",
      "Epoch 303 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 304, Step 1, LR: 0.000668, Current Loss: 0.0401, Avg Loss: 0.0401\n",
      "Diff stats — min: -5.1276, max: 10.0000, mean: 7.9617, std: 2.7358\n",
      "\n",
      "Step 9061 — Test metrics:\n",
      "  precision@10: 0.015157944\n",
      "  recall@10: 0.015218469\n",
      "  ndcg@10: 0.016324034\n",
      "  map@10: 0.006216421\n",
      "Epoch 304, Step 20, LR: 0.000668, Current Loss: 0.0418, Avg Loss: 0.0413\n",
      "Diff stats — min: -6.4362, max: 10.0000, mean: 7.9961, std: 2.7274\n",
      "\n",
      "Epoch 304 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 305, Step 1, LR: 0.000668, Current Loss: 0.0401, Avg Loss: 0.0401\n",
      "Diff stats — min: -5.3413, max: 10.0000, mean: 7.9913, std: 2.7542\n",
      "\n",
      "Step 9091 — Test metrics:\n",
      "  precision@10: 0.014992928\n",
      "  recall@10: 0.015056727\n",
      "  ndcg@10: 0.016349940\n",
      "  map@10: 0.006269368\n",
      "Epoch 305, Step 20, LR: 0.000668, Current Loss: 0.0378, Avg Loss: 0.0395\n",
      "Diff stats — min: -5.9812, max: 10.0000, mean: 7.9700, std: 2.7187\n",
      "\n",
      "Epoch 305 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 306, Step 1, LR: 0.000654, Current Loss: 0.0401, Avg Loss: 0.0401\n",
      "Diff stats — min: -6.4927, max: 10.0000, mean: 8.0348, std: 2.7000\n",
      "\n",
      "Step 9121 — Test metrics:\n",
      "  precision@10: 0.014827911\n",
      "  recall@10: 0.014894330\n",
      "  ndcg@10: 0.015892328\n",
      "  map@10: 0.006036772\n",
      "Epoch 306, Step 20, LR: 0.000654, Current Loss: 0.0403, Avg Loss: 0.0407\n",
      "Diff stats — min: -5.6410, max: 10.0000, mean: 8.0322, std: 2.7088\n",
      "\n",
      "Epoch 306 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 307, Step 1, LR: 0.000654, Current Loss: 0.0328, Avg Loss: 0.0328\n",
      "Diff stats — min: -4.0007, max: 10.0000, mean: 8.0117, std: 2.6712\n",
      "\n",
      "Step 9151 — Test metrics:\n",
      "  precision@10: 0.014686469\n",
      "  recall@10: 0.014739135\n",
      "  ndcg@10: 0.016016229\n",
      "  map@10: 0.006082729\n",
      "Epoch 307, Step 20, LR: 0.000654, Current Loss: 0.0384, Avg Loss: 0.0405\n",
      "Diff stats — min: -5.3689, max: 10.0000, mean: 7.9889, std: 2.7281\n",
      "\n",
      "Epoch 307 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 308, Step 1, LR: 0.000654, Current Loss: 0.0332, Avg Loss: 0.0332\n",
      "Diff stats — min: -6.3046, max: 10.0000, mean: 8.0794, std: 2.6625\n",
      "\n",
      "Step 9181 — Test metrics:\n",
      "  precision@10: 0.014662895\n",
      "  recall@10: 0.014729313\n",
      "  ndcg@10: 0.015755853\n",
      "  map@10: 0.005959536\n",
      "Epoch 308, Step 20, LR: 0.000654, Current Loss: 0.0406, Avg Loss: 0.0393\n",
      "Diff stats — min: -7.4715, max: 10.0000, mean: 8.0017, std: 2.7225\n",
      "\n",
      "Epoch 308 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 309, Step 1, LR: 0.000654, Current Loss: 0.0475, Avg Loss: 0.0475\n",
      "Diff stats — min: -7.5485, max: 10.0000, mean: 7.9668, std: 2.7986\n",
      "\n",
      "Step 9211 — Test metrics:\n",
      "  precision@10: 0.014474305\n",
      "  recall@10: 0.014524352\n",
      "  ndcg@10: 0.015664271\n",
      "  map@10: 0.005970941\n",
      "Epoch 309, Step 20, LR: 0.000654, Current Loss: 0.0476, Avg Loss: 0.0408\n",
      "Diff stats — min: -6.8802, max: 10.0000, mean: 7.9221, std: 2.8095\n",
      "\n",
      "Epoch 309 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 310, Step 1, LR: 0.000654, Current Loss: 0.0498, Avg Loss: 0.0498\n",
      "Diff stats — min: -7.1741, max: 10.0000, mean: 7.9568, std: 2.8094\n",
      "\n",
      "Step 9241 — Test metrics:\n",
      "  precision@10: 0.014615747\n",
      "  recall@10: 0.014668414\n",
      "  ndcg@10: 0.015750209\n",
      "  map@10: 0.005923008\n",
      "Epoch 310, Step 20, LR: 0.000654, Current Loss: 0.0410, Avg Loss: 0.0404\n",
      "Diff stats — min: -6.7174, max: 10.0000, mean: 7.9711, std: 2.7764\n",
      "\n",
      "Epoch 310 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 311, Step 1, LR: 0.000641, Current Loss: 0.0412, Avg Loss: 0.0412\n",
      "Diff stats — min: -6.6113, max: 10.0000, mean: 8.0421, std: 2.6976\n",
      "\n",
      "Step 9271 — Test metrics:\n",
      "  precision@10: 0.014875059\n",
      "  recall@10: 0.014922487\n",
      "  ndcg@10: 0.016009355\n",
      "  map@10: 0.006069197\n",
      "Epoch 311, Step 20, LR: 0.000641, Current Loss: 0.0367, Avg Loss: 0.0397\n",
      "Diff stats — min: -6.9305, max: 10.0000, mean: 8.0428, std: 2.6828\n",
      "\n",
      "Epoch 311 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 312, Step 1, LR: 0.000641, Current Loss: 0.0414, Avg Loss: 0.0414\n",
      "Diff stats — min: -5.4514, max: 10.0000, mean: 8.0278, std: 2.7383\n",
      "\n",
      "Step 9301 — Test metrics:\n",
      "  precision@10: 0.014992928\n",
      "  recall@10: 0.015045595\n",
      "  ndcg@10: 0.016186257\n",
      "  map@10: 0.006118252\n",
      "Epoch 312, Step 20, LR: 0.000641, Current Loss: 0.0413, Avg Loss: 0.0425\n",
      "Diff stats — min: -5.6919, max: 10.0000, mean: 8.0151, std: 2.7367\n",
      "\n",
      "Epoch 312 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 313, Step 1, LR: 0.000641, Current Loss: 0.0413, Avg Loss: 0.0413\n",
      "Diff stats — min: -5.2616, max: 10.0000, mean: 7.9546, std: 2.7490\n",
      "\n",
      "Step 9331 — Test metrics:\n",
      "  precision@10: 0.014497878\n",
      "  recall@10: 0.014550545\n",
      "  ndcg@10: 0.015669716\n",
      "  map@10: 0.005936712\n",
      "Epoch 313, Step 20, LR: 0.000641, Current Loss: 0.0401, Avg Loss: 0.0392\n",
      "Diff stats — min: -5.3218, max: 10.0000, mean: 8.0025, std: 2.7259\n",
      "\n",
      "Epoch 313 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 314, Step 1, LR: 0.000641, Current Loss: 0.0377, Avg Loss: 0.0377\n",
      "Diff stats — min: -8.4014, max: 10.0000, mean: 8.1018, std: 2.6643\n",
      "\n",
      "Step 9361 — Test metrics:\n",
      "  precision@10: 0.014662895\n",
      "  recall@10: 0.014720800\n",
      "  ndcg@10: 0.015972044\n",
      "  map@10: 0.006130747\n",
      "Epoch 314, Step 20, LR: 0.000641, Current Loss: 0.0399, Avg Loss: 0.0385\n",
      "Diff stats — min: -4.9285, max: 10.0000, mean: 8.0378, std: 2.7264\n",
      "\n",
      "Epoch 314 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 315, Step 1, LR: 0.000641, Current Loss: 0.0367, Avg Loss: 0.0367\n",
      "Diff stats — min: -8.2775, max: 10.0000, mean: 8.0373, std: 2.7093\n",
      "\n",
      "Step 9391 — Test metrics:\n",
      "  precision@10: 0.014992928\n",
      "  recall@10: 0.015058317\n",
      "  ndcg@10: 0.016204496\n",
      "  map@10: 0.006172320\n",
      "Epoch 315, Step 20, LR: 0.000641, Current Loss: 0.0492, Avg Loss: 0.0395\n",
      "Diff stats — min: -8.3986, max: 10.0000, mean: 7.9214, std: 2.8212\n",
      "\n",
      "Epoch 315 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 316, Step 1, LR: 0.000628, Current Loss: 0.0405, Avg Loss: 0.0405\n",
      "Diff stats — min: -4.2438, max: 10.0000, mean: 7.9904, std: 2.7430\n",
      "\n",
      "Step 9421 — Test metrics:\n",
      "  precision@10: 0.015087223\n",
      "  recall@10: 0.015155232\n",
      "  ndcg@10: 0.016243002\n",
      "  map@10: 0.006229524\n",
      "Epoch 316, Step 20, LR: 0.000628, Current Loss: 0.0400, Avg Loss: 0.0392\n",
      "Diff stats — min: -5.9687, max: 10.0000, mean: 8.0593, std: 2.6821\n",
      "\n",
      "Epoch 316 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 317, Step 1, LR: 0.000628, Current Loss: 0.0447, Avg Loss: 0.0447\n",
      "Diff stats — min: -5.2716, max: 10.0000, mean: 8.0226, std: 2.7739\n",
      "\n",
      "Step 9451 — Test metrics:\n",
      "  precision@10: 0.014992928\n",
      "  recall@10: 0.015069449\n",
      "  ndcg@10: 0.016320157\n",
      "  map@10: 0.006354974\n",
      "Epoch 317, Step 20, LR: 0.000628, Current Loss: 0.0315, Avg Loss: 0.0383\n",
      "Diff stats — min: -5.8710, max: 10.0000, mean: 8.0833, std: 2.6219\n",
      "\n",
      "Epoch 317 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 318, Step 1, LR: 0.000628, Current Loss: 0.0344, Avg Loss: 0.0344\n",
      "Diff stats — min: -6.4266, max: 10.0000, mean: 8.0511, std: 2.6714\n",
      "\n",
      "Step 9481 — Test metrics:\n",
      "  precision@10: 0.014568600\n",
      "  recall@10: 0.014636608\n",
      "  ndcg@10: 0.016174569\n",
      "  map@10: 0.006329656\n",
      "Epoch 318, Step 20, LR: 0.000628, Current Loss: 0.0406, Avg Loss: 0.0377\n",
      "Diff stats — min: -5.4174, max: 10.0000, mean: 8.0755, std: 2.6981\n",
      "\n",
      "Epoch 318 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 319, Step 1, LR: 0.000628, Current Loss: 0.0370, Avg Loss: 0.0370\n",
      "Diff stats — min: -5.8347, max: 10.0000, mean: 8.1045, std: 2.6527\n",
      "\n",
      "Step 9511 — Test metrics:\n",
      "  precision@10: 0.015134371\n",
      "  recall@10: 0.015198169\n",
      "  ndcg@10: 0.016648369\n",
      "  map@10: 0.006503595\n",
      "Epoch 319, Step 20, LR: 0.000628, Current Loss: 0.0428, Avg Loss: 0.0375\n",
      "Diff stats — min: -9.1553, max: 10.0000, mean: 8.0448, std: 2.7471\n",
      "\n",
      "Epoch 319 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 320, Step 1, LR: 0.000628, Current Loss: 0.0385, Avg Loss: 0.0385\n",
      "Diff stats — min: -6.0829, max: 10.0000, mean: 8.0948, std: 2.7006\n",
      "\n",
      "Step 9541 — Test metrics:\n",
      "  precision@10: 0.015322961\n",
      "  recall@10: 0.015383486\n",
      "  ndcg@10: 0.016713488\n",
      "  map@10: 0.006455294\n",
      "Epoch 320, Step 20, LR: 0.000628, Current Loss: 0.0313, Avg Loss: 0.0386\n",
      "Diff stats — min: -6.3354, max: 10.0000, mean: 8.1495, std: 2.6174\n",
      "\n",
      "Epoch 320 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 321, Step 1, LR: 0.000616, Current Loss: 0.0359, Avg Loss: 0.0359\n",
      "Diff stats — min: -6.1246, max: 10.0000, mean: 8.0863, std: 2.6615\n",
      "\n",
      "Step 9571 — Test metrics:\n",
      "  precision@10: 0.015322961\n",
      "  recall@10: 0.015386760\n",
      "  ndcg@10: 0.016524936\n",
      "  map@10: 0.006295090\n",
      "Epoch 321, Step 20, LR: 0.000616, Current Loss: 0.0432, Avg Loss: 0.0386\n",
      "Diff stats — min: -5.2698, max: 10.0000, mean: 8.0652, std: 2.7298\n",
      "\n",
      "Epoch 321 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 322, Step 1, LR: 0.000616, Current Loss: 0.0401, Avg Loss: 0.0401\n",
      "Diff stats — min: -4.9612, max: 10.0000, mean: 8.1275, std: 2.6728\n",
      "\n",
      "Step 9601 — Test metrics:\n",
      "  precision@10: 0.015205092\n",
      "  recall@10: 0.015266272\n",
      "  ndcg@10: 0.016407639\n",
      "  map@10: 0.006271550\n",
      "Epoch 322, Step 20, LR: 0.000616, Current Loss: 0.0472, Avg Loss: 0.0378\n",
      "Diff stats — min: -7.2349, max: 10.0000, mean: 8.0805, std: 2.7646\n",
      "\n",
      "Epoch 322 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 323, Step 1, LR: 0.000616, Current Loss: 0.0279, Avg Loss: 0.0279\n",
      "Diff stats — min: -4.5758, max: 10.0000, mean: 8.1311, std: 2.5887\n",
      "\n",
      "Step 9631 — Test metrics:\n",
      "  precision@10: 0.015676568\n",
      "  recall@10: 0.015737747\n",
      "  ndcg@10: 0.016816109\n",
      "  map@10: 0.006465904\n",
      "Epoch 323, Step 20, LR: 0.000616, Current Loss: 0.0353, Avg Loss: 0.0362\n",
      "Diff stats — min: -7.5827, max: 10.0000, mean: 8.0861, std: 2.6543\n",
      "\n",
      "Epoch 323 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 324, Step 1, LR: 0.000616, Current Loss: 0.0339, Avg Loss: 0.0339\n",
      "Diff stats — min: -3.7304, max: 10.0000, mean: 8.0970, std: 2.6712\n",
      "\n",
      "Step 9661 — Test metrics:\n",
      "  precision@10: 0.015511551\n",
      "  recall@10: 0.015575350\n",
      "  ndcg@10: 0.016593794\n",
      "  map@10: 0.006297564\n",
      "Epoch 324, Step 20, LR: 0.000616, Current Loss: 0.0331, Avg Loss: 0.0365\n",
      "Diff stats — min: -4.9425, max: 10.0000, mean: 8.0545, std: 2.6775\n",
      "\n",
      "Epoch 324 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 325, Step 1, LR: 0.000616, Current Loss: 0.0423, Avg Loss: 0.0423\n",
      "Diff stats — min: -5.3490, max: 10.0000, mean: 8.1320, std: 2.6997\n",
      "\n",
      "Step 9691 — Test metrics:\n",
      "  precision@10: 0.015652994\n",
      "  recall@10: 0.015716793\n",
      "  ndcg@10: 0.016681636\n",
      "  map@10: 0.006321131\n",
      "Epoch 325, Step 20, LR: 0.000616, Current Loss: 0.0352, Avg Loss: 0.0382\n",
      "Diff stats — min: -5.6352, max: 10.0000, mean: 8.1159, std: 2.6576\n",
      "\n",
      "Epoch 325 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 326, Step 1, LR: 0.000603, Current Loss: 0.0344, Avg Loss: 0.0344\n",
      "Diff stats — min: -4.5046, max: 10.0000, mean: 8.1566, std: 2.6226\n",
      "\n",
      "Step 9721 — Test metrics:\n",
      "  precision@10: 0.015040075\n",
      "  recall@10: 0.015103874\n",
      "  ndcg@10: 0.016061167\n",
      "  map@10: 0.006084646\n",
      "Epoch 326, Step 20, LR: 0.000603, Current Loss: 0.0337, Avg Loss: 0.0385\n",
      "Diff stats — min: -6.4961, max: 10.0000, mean: 8.0878, std: 2.6813\n",
      "\n",
      "Epoch 326 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 327, Step 1, LR: 0.000603, Current Loss: 0.0426, Avg Loss: 0.0426\n",
      "Diff stats — min: -6.4914, max: 10.0000, mean: 8.0354, std: 2.7601\n",
      "\n",
      "Step 9751 — Test metrics:\n",
      "  precision@10: 0.015723715\n",
      "  recall@10: 0.015793408\n",
      "  ndcg@10: 0.016758543\n",
      "  map@10: 0.006343676\n",
      "Epoch 327, Step 20, LR: 0.000603, Current Loss: 0.0482, Avg Loss: 0.0386\n",
      "Diff stats — min: -6.0178, max: 10.0000, mean: 8.0107, std: 2.7864\n",
      "\n",
      "Epoch 327 completed, Train Loss: 0.000010\n",
      "\n",
      "Epoch 328, Step 1, LR: 0.000603, Current Loss: 0.0353, Avg Loss: 0.0353\n",
      "Diff stats — min: -4.5000, max: 10.0000, mean: 8.0617, std: 2.6865\n",
      "\n",
      "Step 9781 — Test metrics:\n",
      "  precision@10: 0.015134371\n",
      "  recall@10: 0.015200789\n",
      "  ndcg@10: 0.016383332\n",
      "  map@10: 0.006304020\n",
      "Epoch 328, Step 20, LR: 0.000603, Current Loss: 0.0351, Avg Loss: 0.0370\n",
      "Diff stats — min: -6.6896, max: 10.0000, mean: 8.1103, std: 2.6740\n",
      "\n",
      "Epoch 328 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 329, Step 1, LR: 0.000603, Current Loss: 0.0467, Avg Loss: 0.0467\n",
      "Diff stats — min: -5.5276, max: 10.0000, mean: 8.0188, std: 2.7785\n",
      "\n",
      "Step 9811 — Test metrics:\n",
      "  precision@10: 0.015346535\n",
      "  recall@10: 0.015416227\n",
      "  ndcg@10: 0.016286699\n",
      "  map@10: 0.006142793\n",
      "Epoch 329, Step 20, LR: 0.000603, Current Loss: 0.0383, Avg Loss: 0.0385\n",
      "Diff stats — min: -6.2199, max: 10.0000, mean: 8.1119, std: 2.6587\n",
      "\n",
      "Epoch 329 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 330, Step 1, LR: 0.000603, Current Loss: 0.0355, Avg Loss: 0.0355\n",
      "Diff stats — min: -6.0405, max: 10.0000, mean: 8.1210, std: 2.6893\n",
      "\n",
      "Step 9841 — Test metrics:\n",
      "  precision@10: 0.015346535\n",
      "  recall@10: 0.015416227\n",
      "  ndcg@10: 0.016337280\n",
      "  map@10: 0.006200254\n",
      "Epoch 330, Step 20, LR: 0.000603, Current Loss: 0.0290, Avg Loss: 0.0368\n",
      "Diff stats — min: -8.0279, max: 10.0000, mean: 8.1151, std: 2.5938\n",
      "\n",
      "Epoch 330 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 331, Step 1, LR: 0.000591, Current Loss: 0.0367, Avg Loss: 0.0367\n",
      "Diff stats — min: -4.5651, max: 10.0000, mean: 8.1238, std: 2.6711\n",
      "\n",
      "Step 9871 — Test metrics:\n",
      "  precision@10: 0.015558699\n",
      "  recall@10: 0.015622498\n",
      "  ndcg@10: 0.016742883\n",
      "  map@10: 0.006356377\n",
      "Epoch 331, Step 20, LR: 0.000591, Current Loss: 0.0314, Avg Loss: 0.0353\n",
      "Diff stats — min: -5.3613, max: 10.0000, mean: 8.1148, std: 2.6415\n",
      "\n",
      "Epoch 331 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 332, Step 1, LR: 0.000591, Current Loss: 0.0328, Avg Loss: 0.0328\n",
      "Diff stats — min: -6.9002, max: 10.0000, mean: 8.1043, std: 2.6287\n",
      "\n",
      "Step 9901 — Test metrics:\n",
      "  precision@10: 0.015157944\n",
      "  recall@10: 0.015225017\n",
      "  ndcg@10: 0.016348188\n",
      "  map@10: 0.006203109\n",
      "Epoch 332, Step 20, LR: 0.000591, Current Loss: 0.0339, Avg Loss: 0.0363\n",
      "Diff stats — min: -8.0899, max: 10.0000, mean: 8.1224, std: 2.6439\n",
      "\n",
      "Epoch 332 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 333, Step 1, LR: 0.000591, Current Loss: 0.0318, Avg Loss: 0.0318\n",
      "Diff stats — min: -5.1688, max: 10.0000, mean: 8.1562, std: 2.6368\n",
      "\n",
      "Step 9931 — Test metrics:\n",
      "  precision@10: 0.015346535\n",
      "  recall@10: 0.015401821\n",
      "  ndcg@10: 0.016490614\n",
      "  map@10: 0.006320216\n",
      "Epoch 333, Step 20, LR: 0.000591, Current Loss: 0.0472, Avg Loss: 0.0371\n",
      "Diff stats — min: -7.9674, max: 10.0000, mean: 8.0809, std: 2.7727\n",
      "\n",
      "Epoch 333 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 334, Step 1, LR: 0.000591, Current Loss: 0.0358, Avg Loss: 0.0358\n",
      "Diff stats — min: -6.1657, max: 10.0000, mean: 8.1533, std: 2.6448\n",
      "\n",
      "Step 9961 — Test metrics:\n",
      "  precision@10: 0.015252240\n",
      "  recall@10: 0.015301632\n",
      "  ndcg@10: 0.016455213\n",
      "  map@10: 0.006312200\n",
      "Epoch 334, Step 20, LR: 0.000591, Current Loss: 0.0387, Avg Loss: 0.0362\n",
      "Diff stats — min: -9.7399, max: 10.0000, mean: 8.1140, std: 2.6707\n",
      "\n",
      "Epoch 334 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 335, Step 1, LR: 0.000591, Current Loss: 0.0477, Avg Loss: 0.0477\n",
      "Diff stats — min: -7.8727, max: 10.0000, mean: 8.0379, std: 2.7409\n",
      "\n",
      "Step 9991 — Test metrics:\n",
      "  precision@10: 0.014686469\n",
      "  recall@10: 0.014739135\n",
      "  ndcg@10: 0.015883731\n",
      "  map@10: 0.006067811\n",
      "Epoch 335, Step 20, LR: 0.000591, Current Loss: 0.0459, Avg Loss: 0.0380\n",
      "Diff stats — min: -6.7614, max: 10.0000, mean: 8.1348, std: 2.7281\n",
      "\n",
      "Epoch 335 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 336, Step 1, LR: 0.000580, Current Loss: 0.0328, Avg Loss: 0.0328\n",
      "Diff stats — min: -4.8566, max: 10.0000, mean: 8.1985, std: 2.5940\n",
      "\n",
      "Step 10021 — Test metrics:\n",
      "  precision@10: 0.015487977\n",
      "  recall@10: 0.015539989\n",
      "  ndcg@10: 0.016437098\n",
      "  map@10: 0.006248091\n",
      "Epoch 336, Step 20, LR: 0.000580, Current Loss: 0.0396, Avg Loss: 0.0369\n",
      "Diff stats — min: -6.9019, max: 10.0000, mean: 8.1807, std: 2.6560\n",
      "\n",
      "Epoch 336 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 337, Step 1, LR: 0.000580, Current Loss: 0.0373, Avg Loss: 0.0373\n",
      "Diff stats — min: -6.4136, max: 10.0000, mean: 8.1130, std: 2.6937\n",
      "\n",
      "Step 10051 — Test metrics:\n",
      "  precision@10: 0.015299387\n",
      "  recall@10: 0.015354018\n",
      "  ndcg@10: 0.016606794\n",
      "  map@10: 0.006438476\n",
      "Epoch 337, Step 20, LR: 0.000580, Current Loss: 0.0410, Avg Loss: 0.0366\n",
      "Diff stats — min: -6.8403, max: 10.0000, mean: 8.1538, std: 2.6622\n",
      "\n",
      "Epoch 337 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 338, Step 1, LR: 0.000580, Current Loss: 0.0300, Avg Loss: 0.0300\n",
      "Diff stats — min: -5.3954, max: 10.0000, mean: 8.2283, std: 2.5824\n",
      "\n",
      "Step 10081 — Test metrics:\n",
      "  precision@10: 0.015134371\n",
      "  recall@10: 0.015197515\n",
      "  ndcg@10: 0.016272428\n",
      "  map@10: 0.006288939\n",
      "Epoch 338, Step 20, LR: 0.000580, Current Loss: 0.0335, Avg Loss: 0.0352\n",
      "Diff stats — min: -6.0295, max: 10.0000, mean: 8.1053, std: 2.6475\n",
      "\n",
      "Epoch 338 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 339, Step 1, LR: 0.000580, Current Loss: 0.0380, Avg Loss: 0.0380\n",
      "Diff stats — min: -5.7470, max: 10.0000, mean: 8.1195, std: 2.6824\n",
      "\n",
      "Step 10111 — Test metrics:\n",
      "  precision@10: 0.015370108\n",
      "  recall@10: 0.015433253\n",
      "  ndcg@10: 0.016430333\n",
      "  map@10: 0.006280308\n",
      "Epoch 339, Step 20, LR: 0.000580, Current Loss: 0.0362, Avg Loss: 0.0368\n",
      "Diff stats — min: -3.8357, max: 10.0000, mean: 8.1880, std: 2.6402\n",
      "\n",
      "Epoch 339 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 340, Step 1, LR: 0.000580, Current Loss: 0.0403, Avg Loss: 0.0403\n",
      "Diff stats — min: -6.4325, max: 10.0000, mean: 8.1541, std: 2.6978\n",
      "\n",
      "Step 10141 — Test metrics:\n",
      "  precision@10: 0.015417256\n",
      "  recall@10: 0.015474507\n",
      "  ndcg@10: 0.016645697\n",
      "  map@10: 0.006458693\n",
      "Epoch 340, Step 20, LR: 0.000580, Current Loss: 0.0384, Avg Loss: 0.0357\n",
      "Diff stats — min: -6.6054, max: 10.0000, mean: 8.2055, std: 2.6284\n",
      "\n",
      "Epoch 340 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 341, Step 1, LR: 0.000568, Current Loss: 0.0308, Avg Loss: 0.0308\n",
      "Diff stats — min: -5.3462, max: 10.0000, mean: 8.1672, std: 2.6134\n",
      "\n",
      "Step 10171 — Test metrics:\n",
      "  precision@10: 0.015818010\n",
      "  recall@10: 0.015884429\n",
      "  ndcg@10: 0.017016676\n",
      "  map@10: 0.006479134\n",
      "Epoch 341, Step 20, LR: 0.000568, Current Loss: 0.0368, Avg Loss: 0.0359\n",
      "Diff stats — min: -6.5033, max: 10.0000, mean: 8.1409, std: 2.6473\n",
      "\n",
      "Epoch 341 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 342, Step 1, LR: 0.000568, Current Loss: 0.0304, Avg Loss: 0.0304\n",
      "Diff stats — min: -4.3420, max: 10.0000, mean: 8.1837, std: 2.6039\n",
      "\n",
      "Step 10201 — Test metrics:\n",
      "  precision@10: 0.015346535\n",
      "  recall@10: 0.015404440\n",
      "  ndcg@10: 0.016545384\n",
      "  map@10: 0.006372275\n",
      "Epoch 342, Step 20, LR: 0.000568, Current Loss: 0.0377, Avg Loss: 0.0360\n",
      "Diff stats — min: -5.8482, max: 10.0000, mean: 8.1825, std: 2.6452\n",
      "\n",
      "Epoch 342 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 343, Step 1, LR: 0.000568, Current Loss: 0.0305, Avg Loss: 0.0305\n",
      "Diff stats — min: -4.3129, max: 10.0000, mean: 8.2889, std: 2.5563\n",
      "\n",
      "Step 10231 — Test metrics:\n",
      "  precision@10: 0.015535125\n",
      "  recall@10: 0.015594995\n",
      "  ndcg@10: 0.016752948\n",
      "  map@10: 0.006379909\n",
      "Epoch 343, Step 20, LR: 0.000568, Current Loss: 0.0459, Avg Loss: 0.0360\n",
      "Diff stats — min: -4.5335, max: 10.0000, mean: 8.1073, std: 2.7332\n",
      "\n",
      "Epoch 343 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 344, Step 1, LR: 0.000568, Current Loss: 0.0388, Avg Loss: 0.0388\n",
      "Diff stats — min: -7.1226, max: 10.0000, mean: 8.1920, std: 2.6192\n",
      "\n",
      "Step 10261 — Test metrics:\n",
      "  precision@10: 0.015770863\n",
      "  recall@10: 0.015844110\n",
      "  ndcg@10: 0.017008577\n",
      "  map@10: 0.006614638\n",
      "Epoch 344, Step 20, LR: 0.000568, Current Loss: 0.0332, Avg Loss: 0.0357\n",
      "Diff stats — min: -5.6283, max: 10.0000, mean: 8.2210, std: 2.6010\n",
      "\n",
      "Epoch 344 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 345, Step 1, LR: 0.000568, Current Loss: 0.0311, Avg Loss: 0.0311\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 8.2417, std: 2.5946\n",
      "\n",
      "Step 10291 — Test metrics:\n",
      "  precision@10: 0.015959453\n",
      "  recall@10: 0.016022597\n",
      "  ndcg@10: 0.017248177\n",
      "  map@10: 0.006624469\n",
      "Epoch 345, Step 20, LR: 0.000568, Current Loss: 0.0373, Avg Loss: 0.0349\n",
      "Diff stats — min: -5.6394, max: 10.0000, mean: 8.1544, std: 2.6636\n",
      "\n",
      "Epoch 345 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 346, Step 1, LR: 0.000557, Current Loss: 0.0396, Avg Loss: 0.0396\n",
      "Diff stats — min: -5.6912, max: 10.0000, mean: 8.1471, std: 2.6832\n",
      "\n",
      "Step 10321 — Test metrics:\n",
      "  precision@10: 0.016124470\n",
      "  recall@10: 0.016179101\n",
      "  ndcg@10: 0.017283022\n",
      "  map@10: 0.006688279\n",
      "Epoch 346, Step 20, LR: 0.000557, Current Loss: 0.0344, Avg Loss: 0.0360\n",
      "Diff stats — min: -6.0255, max: 10.0000, mean: 8.2089, std: 2.6279\n",
      "\n",
      "Epoch 346 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 347, Step 1, LR: 0.000557, Current Loss: 0.0337, Avg Loss: 0.0337\n",
      "Diff stats — min: -5.6503, max: 10.0000, mean: 8.2096, std: 2.6171\n",
      "\n",
      "Step 10351 — Test metrics:\n",
      "  precision@10: 0.015582273\n",
      "  recall@10: 0.015650936\n",
      "  ndcg@10: 0.016761992\n",
      "  map@10: 0.006449369\n",
      "Epoch 347, Step 20, LR: 0.000557, Current Loss: 0.0385, Avg Loss: 0.0355\n",
      "Diff stats — min: -5.5087, max: 10.0000, mean: 8.1853, std: 2.6712\n",
      "\n",
      "Epoch 347 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 348, Step 1, LR: 0.000557, Current Loss: 0.0395, Avg Loss: 0.0395\n",
      "Diff stats — min: -5.0507, max: 10.0000, mean: 8.1542, std: 2.6781\n",
      "\n",
      "Step 10381 — Test metrics:\n",
      "  precision@10: 0.015558699\n",
      "  recall@10: 0.015624088\n",
      "  ndcg@10: 0.016615855\n",
      "  map@10: 0.006389963\n",
      "Epoch 348, Step 20, LR: 0.000557, Current Loss: 0.0297, Avg Loss: 0.0352\n",
      "Diff stats — min: -6.4473, max: 10.0000, mean: 8.2346, std: 2.5746\n",
      "\n",
      "Epoch 348 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 349, Step 1, LR: 0.000557, Current Loss: 0.0324, Avg Loss: 0.0324\n",
      "Diff stats — min: -5.2573, max: 10.0000, mean: 8.1967, std: 2.6210\n",
      "\n",
      "Step 10411 — Test metrics:\n",
      "  precision@10: 0.015535125\n",
      "  recall@10: 0.015587792\n",
      "  ndcg@10: 0.016670957\n",
      "  map@10: 0.006485424\n",
      "Epoch 349, Step 20, LR: 0.000557, Current Loss: 0.0317, Avg Loss: 0.0337\n",
      "Diff stats — min: -5.0574, max: 10.0000, mean: 8.2333, std: 2.5784\n",
      "\n",
      "Epoch 349 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 350, Step 1, LR: 0.000557, Current Loss: 0.0313, Avg Loss: 0.0313\n",
      "Diff stats — min: -9.6613, max: 10.0000, mean: 8.2604, std: 2.5713\n",
      "\n",
      "Step 10441 — Test metrics:\n",
      "  precision@10: 0.015417256\n",
      "  recall@10: 0.015466649\n",
      "  ndcg@10: 0.016630698\n",
      "  map@10: 0.006426769\n",
      "Epoch 350, Step 20, LR: 0.000557, Current Loss: 0.0337, Avg Loss: 0.0343\n",
      "Diff stats — min: -4.4769, max: 10.0000, mean: 8.2426, std: 2.6044\n",
      "\n",
      "Epoch 350 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 351, Step 1, LR: 0.000545, Current Loss: 0.0352, Avg Loss: 0.0352\n",
      "Diff stats — min: -7.8490, max: 10.0000, mean: 8.2064, std: 2.6288\n",
      "\n",
      "Step 10471 — Test metrics:\n",
      "  precision@10: 0.015558699\n",
      "  recall@10: 0.015615575\n",
      "  ndcg@10: 0.016334342\n",
      "  map@10: 0.006097841\n",
      "Epoch 351, Step 20, LR: 0.000545, Current Loss: 0.0325, Avg Loss: 0.0341\n",
      "Diff stats — min: -5.0182, max: 10.0000, mean: 8.2244, std: 2.6148\n",
      "\n",
      "Epoch 351 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 352, Step 1, LR: 0.000545, Current Loss: 0.0328, Avg Loss: 0.0328\n",
      "Diff stats — min: -5.2040, max: 10.0000, mean: 8.1921, std: 2.6122\n",
      "\n",
      "Step 10501 — Test metrics:\n",
      "  precision@10: 0.015346535\n",
      "  recall@10: 0.015396582\n",
      "  ndcg@10: 0.016414794\n",
      "  map@10: 0.006291575\n",
      "Epoch 352, Step 20, LR: 0.000545, Current Loss: 0.0334, Avg Loss: 0.0341\n",
      "Diff stats — min: -4.4280, max: 10.0000, mean: 8.2618, std: 2.5921\n",
      "\n",
      "Epoch 352 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 353, Step 1, LR: 0.000545, Current Loss: 0.0308, Avg Loss: 0.0308\n",
      "Diff stats — min: -6.8110, max: 10.0000, mean: 8.2255, std: 2.6037\n",
      "\n",
      "Step 10531 — Test metrics:\n",
      "  precision@10: 0.015157944\n",
      "  recall@10: 0.015207992\n",
      "  ndcg@10: 0.016043300\n",
      "  map@10: 0.006080581\n",
      "Epoch 353, Step 20, LR: 0.000545, Current Loss: 0.0333, Avg Loss: 0.0356\n",
      "Diff stats — min: -8.2528, max: 10.0000, mean: 8.2024, std: 2.6095\n",
      "\n",
      "Epoch 353 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 354, Step 1, LR: 0.000545, Current Loss: 0.0419, Avg Loss: 0.0419\n",
      "Diff stats — min: -7.6086, max: 10.0000, mean: 8.2364, std: 2.6538\n",
      "\n",
      "Step 10561 — Test metrics:\n",
      "  precision@10: 0.015464404\n",
      "  recall@10: 0.015514451\n",
      "  ndcg@10: 0.016501595\n",
      "  map@10: 0.006306290\n",
      "Epoch 354, Step 20, LR: 0.000545, Current Loss: 0.0345, Avg Loss: 0.0340\n",
      "Diff stats — min: -5.7560, max: 10.0000, mean: 8.2127, std: 2.6290\n",
      "\n",
      "Epoch 354 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 355, Step 1, LR: 0.000545, Current Loss: 0.0346, Avg Loss: 0.0346\n",
      "Diff stats — min: -8.5804, max: 10.0000, mean: 8.2287, std: 2.6247\n",
      "\n",
      "Step 10591 — Test metrics:\n",
      "  precision@10: 0.016148043\n",
      "  recall@10: 0.016227839\n",
      "  ndcg@10: 0.016902941\n",
      "  map@10: 0.006387592\n",
      "Epoch 355, Step 20, LR: 0.000545, Current Loss: 0.0306, Avg Loss: 0.0338\n",
      "Diff stats — min: -3.9689, max: 10.0000, mean: 8.2031, std: 2.6258\n",
      "\n",
      "Epoch 355 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 356, Step 1, LR: 0.000535, Current Loss: 0.0348, Avg Loss: 0.0348\n",
      "Diff stats — min: -5.5210, max: 10.0000, mean: 8.2983, std: 2.5806\n",
      "\n",
      "Step 10621 — Test metrics:\n",
      "  precision@10: 0.015959453\n",
      "  recall@10: 0.016031765\n",
      "  ndcg@10: 0.017189385\n",
      "  map@10: 0.006667926\n",
      "Epoch 356, Step 20, LR: 0.000535, Current Loss: 0.0311, Avg Loss: 0.0347\n",
      "Diff stats — min: -7.1250, max: 10.0000, mean: 8.2048, std: 2.6128\n",
      "\n",
      "Epoch 356 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 357, Step 1, LR: 0.000535, Current Loss: 0.0415, Avg Loss: 0.0415\n",
      "Diff stats — min: -8.7322, max: 10.0000, mean: 8.2067, std: 2.6751\n",
      "\n",
      "Step 10651 — Test metrics:\n",
      "  precision@10: 0.015252240\n",
      "  recall@10: 0.015304906\n",
      "  ndcg@10: 0.016534465\n",
      "  map@10: 0.006332861\n",
      "Epoch 357, Step 20, LR: 0.000535, Current Loss: 0.0345, Avg Loss: 0.0348\n",
      "Diff stats — min: -5.2628, max: 10.0000, mean: 8.2453, std: 2.6176\n",
      "\n",
      "Epoch 357 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 358, Step 1, LR: 0.000535, Current Loss: 0.0357, Avg Loss: 0.0357\n",
      "Diff stats — min: -7.9609, max: 10.0000, mean: 8.2608, std: 2.6062\n",
      "\n",
      "Step 10681 — Test metrics:\n",
      "  precision@10: 0.015535125\n",
      "  recall@10: 0.015606408\n",
      "  ndcg@10: 0.016551120\n",
      "  map@10: 0.006283967\n",
      "Epoch 358, Step 20, LR: 0.000535, Current Loss: 0.0295, Avg Loss: 0.0340\n",
      "Diff stats — min: -8.6784, max: 10.0000, mean: 8.3233, std: 2.5121\n",
      "\n",
      "Epoch 358 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 359, Step 1, LR: 0.000535, Current Loss: 0.0368, Avg Loss: 0.0368\n",
      "Diff stats — min: -6.2691, max: 10.0000, mean: 8.2118, std: 2.6435\n",
      "\n",
      "Step 10711 — Test metrics:\n",
      "  precision@10: 0.015605846\n",
      "  recall@10: 0.015669645\n",
      "  ndcg@10: 0.016521340\n",
      "  map@10: 0.006246679\n",
      "Epoch 359, Step 20, LR: 0.000535, Current Loss: 0.0317, Avg Loss: 0.0328\n",
      "Diff stats — min: -4.3606, max: 10.0000, mean: 8.1851, std: 2.6531\n",
      "\n",
      "Epoch 359 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 360, Step 1, LR: 0.000535, Current Loss: 0.0374, Avg Loss: 0.0374\n",
      "Diff stats — min: -4.6770, max: 10.0000, mean: 8.2308, std: 2.6298\n",
      "\n",
      "Step 10741 — Test metrics:\n",
      "  precision@10: 0.015770863\n",
      "  recall@10: 0.015834007\n",
      "  ndcg@10: 0.016748637\n",
      "  map@10: 0.006373986\n",
      "Epoch 360, Step 20, LR: 0.000535, Current Loss: 0.0311, Avg Loss: 0.0353\n",
      "Diff stats — min: -5.3366, max: 10.0000, mean: 8.2875, std: 2.5731\n",
      "\n",
      "Epoch 360 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 361, Step 1, LR: 0.000524, Current Loss: 0.0374, Avg Loss: 0.0374\n",
      "Diff stats — min: -8.4039, max: 10.0000, mean: 8.2626, std: 2.6169\n",
      "\n",
      "Step 10771 — Test metrics:\n",
      "  precision@10: 0.016077322\n",
      "  recall@10: 0.016135227\n",
      "  ndcg@10: 0.017038087\n",
      "  map@10: 0.006491662\n",
      "Epoch 361, Step 20, LR: 0.000524, Current Loss: 0.0326, Avg Loss: 0.0340\n",
      "Diff stats — min: -4.5952, max: 10.0000, mean: 8.2783, std: 2.5750\n",
      "\n",
      "Epoch 361 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 362, Step 1, LR: 0.000524, Current Loss: 0.0318, Avg Loss: 0.0318\n",
      "Diff stats — min: -5.5988, max: 10.0000, mean: 8.2355, std: 2.6113\n",
      "\n",
      "Step 10801 — Test metrics:\n",
      "  precision@10: 0.015228666\n",
      "  recall@10: 0.015291810\n",
      "  ndcg@10: 0.016365587\n",
      "  map@10: 0.006292626\n",
      "Epoch 362, Step 20, LR: 0.000524, Current Loss: 0.0315, Avg Loss: 0.0336\n",
      "Diff stats — min: -5.1969, max: 10.0000, mean: 8.3265, std: 2.5644\n",
      "\n",
      "Epoch 362 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 363, Step 1, LR: 0.000524, Current Loss: 0.0312, Avg Loss: 0.0312\n",
      "Diff stats — min: -4.8121, max: 10.0000, mean: 8.3577, std: 2.5152\n",
      "\n",
      "Step 10831 — Test metrics:\n",
      "  precision@10: 0.015700141\n",
      "  recall@10: 0.015760666\n",
      "  ndcg@10: 0.016830101\n",
      "  map@10: 0.006511008\n",
      "Epoch 363, Step 20, LR: 0.000524, Current Loss: 0.0342, Avg Loss: 0.0331\n",
      "Diff stats — min: -7.5193, max: 10.0000, mean: 8.3560, std: 2.5446\n",
      "\n",
      "Epoch 363 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 364, Step 1, LR: 0.000524, Current Loss: 0.0415, Avg Loss: 0.0415\n",
      "Diff stats — min: -5.0264, max: 10.0000, mean: 8.1799, std: 2.7001\n",
      "\n",
      "Step 10861 — Test metrics:\n",
      "  precision@10: 0.015464404\n",
      "  recall@10: 0.015522964\n",
      "  ndcg@10: 0.016629552\n",
      "  map@10: 0.006420078\n",
      "Epoch 364, Step 20, LR: 0.000524, Current Loss: 0.0348, Avg Loss: 0.0342\n",
      "Diff stats — min: -5.2672, max: 10.0000, mean: 8.2008, std: 2.6316\n",
      "\n",
      "Epoch 364 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 365, Step 1, LR: 0.000524, Current Loss: 0.0408, Avg Loss: 0.0408\n",
      "Diff stats — min: -5.8296, max: 10.0000, mean: 8.2613, std: 2.6267\n",
      "\n",
      "Step 10891 — Test metrics:\n",
      "  precision@10: 0.015582273\n",
      "  recall@10: 0.015643452\n",
      "  ndcg@10: 0.016664875\n",
      "  map@10: 0.006431556\n",
      "Epoch 365, Step 20, LR: 0.000524, Current Loss: 0.0406, Avg Loss: 0.0358\n",
      "Diff stats — min: -5.7951, max: 10.0000, mean: 8.2241, std: 2.6576\n",
      "\n",
      "Epoch 365 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 366, Step 1, LR: 0.000513, Current Loss: 0.0304, Avg Loss: 0.0304\n",
      "Diff stats — min: -5.5861, max: 10.0000, mean: 8.2734, std: 2.6025\n",
      "\n",
      "Step 10921 — Test metrics:\n",
      "  precision@10: 0.015558699\n",
      "  recall@10: 0.015615949\n",
      "  ndcg@10: 0.016608027\n",
      "  map@10: 0.006372172\n",
      "Epoch 366, Step 20, LR: 0.000513, Current Loss: 0.0412, Avg Loss: 0.0336\n",
      "Diff stats — min: -5.2443, max: 10.0000, mean: 8.2123, std: 2.6630\n",
      "\n",
      "Epoch 366 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 367, Step 1, LR: 0.000513, Current Loss: 0.0328, Avg Loss: 0.0328\n",
      "Diff stats — min: -4.1871, max: 10.0000, mean: 8.2994, std: 2.5692\n",
      "\n",
      "Step 10951 — Test metrics:\n",
      "  precision@10: 0.015700141\n",
      "  recall@10: 0.015767214\n",
      "  ndcg@10: 0.016682112\n",
      "  map@10: 0.006391546\n",
      "Epoch 367, Step 20, LR: 0.000513, Current Loss: 0.0322, Avg Loss: 0.0330\n",
      "Diff stats — min: -5.0693, max: 10.0000, mean: 8.3915, std: 2.5321\n",
      "\n",
      "Epoch 367 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 368, Step 1, LR: 0.000513, Current Loss: 0.0348, Avg Loss: 0.0348\n",
      "Diff stats — min: -5.5841, max: 10.0000, mean: 8.2259, std: 2.6417\n",
      "\n",
      "Step 10981 — Test metrics:\n",
      "  precision@10: 0.015511551\n",
      "  recall@10: 0.015560944\n",
      "  ndcg@10: 0.016557314\n",
      "  map@10: 0.006377849\n",
      "Epoch 368, Step 20, LR: 0.000513, Current Loss: 0.0296, Avg Loss: 0.0326\n",
      "Diff stats — min: -4.6687, max: 10.0000, mean: 8.2769, std: 2.5514\n",
      "\n",
      "Epoch 368 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 369, Step 1, LR: 0.000513, Current Loss: 0.0355, Avg Loss: 0.0355\n",
      "Diff stats — min: -7.7192, max: 10.0000, mean: 8.2528, std: 2.6247\n",
      "\n",
      "Step 11011 — Test metrics:\n",
      "  precision@10: 0.015794437\n",
      "  recall@10: 0.015849723\n",
      "  ndcg@10: 0.016682450\n",
      "  map@10: 0.006319386\n",
      "Epoch 369, Step 20, LR: 0.000513, Current Loss: 0.0359, Avg Loss: 0.0336\n",
      "Diff stats — min: -5.3807, max: 10.0000, mean: 8.2708, std: 2.6109\n",
      "\n",
      "Epoch 369 completed, Train Loss: 0.000009\n",
      "\n",
      "Epoch 370, Step 1, LR: 0.000513, Current Loss: 0.0370, Avg Loss: 0.0370\n",
      "Diff stats — min: -5.9059, max: 10.0000, mean: 8.3253, std: 2.5767\n",
      "\n",
      "Step 11041 — Test metrics:\n",
      "  precision@10: 0.016077322\n",
      "  recall@10: 0.016126715\n",
      "  ndcg@10: 0.017153413\n",
      "  map@10: 0.006685288\n",
      "Epoch 370, Step 20, LR: 0.000513, Current Loss: 0.0293, Avg Loss: 0.0338\n",
      "Diff stats — min: -5.0695, max: 10.0000, mean: 8.3495, std: 2.5197\n",
      "\n",
      "Epoch 370 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 371, Step 1, LR: 0.000503, Current Loss: 0.0333, Avg Loss: 0.0333\n",
      "Diff stats — min: -4.5917, max: 10.0000, mean: 8.2457, std: 2.6028\n",
      "\n",
      "Step 11071 — Test metrics:\n",
      "  precision@10: 0.015110797\n",
      "  recall@10: 0.015171322\n",
      "  ndcg@10: 0.016339615\n",
      "  map@10: 0.006323846\n",
      "Epoch 371, Step 20, LR: 0.000503, Current Loss: 0.0299, Avg Loss: 0.0315\n",
      "Diff stats — min: -4.6321, max: 10.0000, mean: 8.3366, std: 2.5316\n",
      "\n",
      "Epoch 371 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 372, Step 1, LR: 0.000503, Current Loss: 0.0343, Avg Loss: 0.0343\n",
      "Diff stats — min: -7.5184, max: 10.0000, mean: 8.2888, std: 2.5755\n",
      "\n",
      "Step 11101 — Test metrics:\n",
      "  precision@10: 0.015747289\n",
      "  recall@10: 0.015807814\n",
      "  ndcg@10: 0.016624115\n",
      "  map@10: 0.006332717\n",
      "Epoch 372, Step 20, LR: 0.000503, Current Loss: 0.0309, Avg Loss: 0.0331\n",
      "Diff stats — min: -5.3161, max: 10.0000, mean: 8.2958, std: 2.5692\n",
      "\n",
      "Epoch 372 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 373, Step 1, LR: 0.000503, Current Loss: 0.0354, Avg Loss: 0.0354\n",
      "Diff stats — min: -6.4648, max: 10.0000, mean: 8.2855, std: 2.6190\n",
      "\n",
      "Step 11131 — Test metrics:\n",
      "  precision@10: 0.015511551\n",
      "  recall@10: 0.015569457\n",
      "  ndcg@10: 0.016576543\n",
      "  map@10: 0.006316081\n",
      "Epoch 373, Step 20, LR: 0.000503, Current Loss: 0.0338, Avg Loss: 0.0326\n",
      "Diff stats — min: -6.3818, max: 10.0000, mean: 8.3148, std: 2.5899\n",
      "\n",
      "Epoch 373 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 374, Step 1, LR: 0.000503, Current Loss: 0.0338, Avg Loss: 0.0338\n",
      "Diff stats — min: -7.7677, max: 10.0000, mean: 8.2827, std: 2.5956\n",
      "\n",
      "Step 11161 — Test metrics:\n",
      "  precision@10: 0.015841584\n",
      "  recall@10: 0.015904728\n",
      "  ndcg@10: 0.016961050\n",
      "  map@10: 0.006601412\n",
      "Epoch 374, Step 20, LR: 0.000503, Current Loss: 0.0370, Avg Loss: 0.0344\n",
      "Diff stats — min: -6.4093, max: 10.0000, mean: 8.2194, std: 2.6414\n",
      "\n",
      "Epoch 374 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 375, Step 1, LR: 0.000503, Current Loss: 0.0285, Avg Loss: 0.0285\n",
      "Diff stats — min: -7.0857, max: 10.0000, mean: 8.3237, std: 2.5243\n",
      "\n",
      "Step 11191 — Test metrics:\n",
      "  precision@10: 0.015393682\n",
      "  recall@10: 0.015459446\n",
      "  ndcg@10: 0.016570761\n",
      "  map@10: 0.006344187\n",
      "Epoch 375, Step 20, LR: 0.000503, Current Loss: 0.0337, Avg Loss: 0.0309\n",
      "Diff stats — min: -9.0539, max: 10.0000, mean: 8.3184, std: 2.5515\n",
      "\n",
      "Epoch 375 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 376, Step 1, LR: 0.000493, Current Loss: 0.0268, Avg Loss: 0.0268\n",
      "Diff stats — min: -4.3937, max: 10.0000, mean: 8.3774, std: 2.4955\n",
      "\n",
      "Step 11221 — Test metrics:\n",
      "  precision@10: 0.015535125\n",
      "  recall@10: 0.015595650\n",
      "  ndcg@10: 0.016673634\n",
      "  map@10: 0.006379395\n",
      "Epoch 376, Step 20, LR: 0.000493, Current Loss: 0.0374, Avg Loss: 0.0332\n",
      "Diff stats — min: -7.6659, max: 10.0000, mean: 8.2149, std: 2.6563\n",
      "\n",
      "Epoch 376 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 377, Step 1, LR: 0.000493, Current Loss: 0.0289, Avg Loss: 0.0289\n",
      "Diff stats — min: -6.8473, max: 10.0000, mean: 8.3745, std: 2.4908\n",
      "\n",
      "Step 11251 — Test metrics:\n",
      "  precision@10: 0.015794437\n",
      "  recall@10: 0.015857581\n",
      "  ndcg@10: 0.017069092\n",
      "  map@10: 0.006616598\n",
      "Epoch 377, Step 20, LR: 0.000493, Current Loss: 0.0309, Avg Loss: 0.0334\n",
      "Diff stats — min: -3.6815, max: 10.0000, mean: 8.3062, std: 2.5592\n",
      "\n",
      "Epoch 377 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 378, Step 1, LR: 0.000493, Current Loss: 0.0303, Avg Loss: 0.0303\n",
      "Diff stats — min: -5.6940, max: 10.0000, mean: 8.3433, std: 2.5406\n",
      "\n",
      "Step 11281 — Test metrics:\n",
      "  precision@10: 0.015440830\n",
      "  recall@10: 0.015501355\n",
      "  ndcg@10: 0.016535819\n",
      "  map@10: 0.006360085\n",
      "Epoch 378, Step 20, LR: 0.000493, Current Loss: 0.0310, Avg Loss: 0.0325\n",
      "Diff stats — min: -6.0474, max: 10.0000, mean: 8.2867, std: 2.5678\n",
      "\n",
      "Epoch 378 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 379, Step 1, LR: 0.000493, Current Loss: 0.0289, Avg Loss: 0.0289\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 8.2719, std: 2.5687\n",
      "\n",
      "Step 11311 — Test metrics:\n",
      "  precision@10: 0.015370108\n",
      "  recall@10: 0.015428014\n",
      "  ndcg@10: 0.016692511\n",
      "  map@10: 0.006493810\n",
      "Epoch 379, Step 20, LR: 0.000493, Current Loss: 0.0370, Avg Loss: 0.0321\n",
      "Diff stats — min: -6.9566, max: 10.0000, mean: 8.2211, std: 2.6328\n",
      "\n",
      "Epoch 379 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 380, Step 1, LR: 0.000493, Current Loss: 0.0363, Avg Loss: 0.0363\n",
      "Diff stats — min: -6.5255, max: 10.0000, mean: 8.3179, std: 2.5587\n",
      "\n",
      "Step 11341 — Test metrics:\n",
      "  precision@10: 0.015629420\n",
      "  recall@10: 0.015682087\n",
      "  ndcg@10: 0.016581640\n",
      "  map@10: 0.006282037\n",
      "Epoch 380, Step 20, LR: 0.000493, Current Loss: 0.0352, Avg Loss: 0.0331\n",
      "Diff stats — min: -5.0364, max: 10.0000, mean: 8.2444, std: 2.6465\n",
      "\n",
      "Epoch 380 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 381, Step 1, LR: 0.000483, Current Loss: 0.0324, Avg Loss: 0.0324\n",
      "Diff stats — min: -4.6580, max: 10.0000, mean: 8.2751, std: 2.5822\n",
      "\n",
      "Step 11371 — Test metrics:\n",
      "  precision@10: 0.015487977\n",
      "  recall@10: 0.015545883\n",
      "  ndcg@10: 0.016629616\n",
      "  map@10: 0.006358108\n",
      "Epoch 381, Step 20, LR: 0.000483, Current Loss: 0.0391, Avg Loss: 0.0333\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 8.3124, std: 2.6023\n",
      "\n",
      "Epoch 381 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 382, Step 1, LR: 0.000483, Current Loss: 0.0272, Avg Loss: 0.0272\n",
      "Diff stats — min: -5.2333, max: 10.0000, mean: 8.3154, std: 2.5303\n",
      "\n",
      "Step 11401 — Test metrics:\n",
      "  precision@10: 0.015487977\n",
      "  recall@10: 0.015545883\n",
      "  ndcg@10: 0.016345408\n",
      "  map@10: 0.006239205\n",
      "Epoch 382, Step 20, LR: 0.000483, Current Loss: 0.0320, Avg Loss: 0.0330\n",
      "Diff stats — min: -5.1213, max: 10.0000, mean: 8.3268, std: 2.5615\n",
      "\n",
      "Epoch 382 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 383, Step 1, LR: 0.000483, Current Loss: 0.0324, Avg Loss: 0.0324\n",
      "Diff stats — min: -5.4173, max: 10.0000, mean: 8.3028, std: 2.5983\n",
      "\n",
      "Step 11431 — Test metrics:\n",
      "  precision@10: 0.016242339\n",
      "  recall@10: 0.016315586\n",
      "  ndcg@10: 0.017225844\n",
      "  map@10: 0.006675872\n",
      "Epoch 383, Step 20, LR: 0.000483, Current Loss: 0.0348, Avg Loss: 0.0336\n",
      "Diff stats — min: -5.9688, max: 10.0000, mean: 8.3399, std: 2.5953\n",
      "\n",
      "Epoch 383 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 384, Step 1, LR: 0.000483, Current Loss: 0.0296, Avg Loss: 0.0296\n",
      "Diff stats — min: -8.0301, max: 10.0000, mean: 8.3699, std: 2.5074\n",
      "\n",
      "Step 11461 — Test metrics:\n",
      "  precision@10: 0.016124470\n",
      "  recall@10: 0.016182375\n",
      "  ndcg@10: 0.017145719\n",
      "  map@10: 0.006597178\n",
      "Epoch 384, Step 20, LR: 0.000483, Current Loss: 0.0304, Avg Loss: 0.0328\n",
      "Diff stats — min: -5.6219, max: 10.0000, mean: 8.2804, std: 2.5698\n",
      "\n",
      "Epoch 384 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 385, Step 1, LR: 0.000483, Current Loss: 0.0288, Avg Loss: 0.0288\n",
      "Diff stats — min: -5.8237, max: 10.0000, mean: 8.3709, std: 2.5053\n",
      "\n",
      "Step 11491 — Test metrics:\n",
      "  precision@10: 0.016265912\n",
      "  recall@10: 0.016331676\n",
      "  ndcg@10: 0.017489271\n",
      "  map@10: 0.006813736\n",
      "Epoch 385, Step 20, LR: 0.000483, Current Loss: 0.0279, Avg Loss: 0.0311\n",
      "Diff stats — min: -3.7139, max: 10.0000, mean: 8.3358, std: 2.5406\n",
      "\n",
      "Epoch 385 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 386, Step 1, LR: 0.000474, Current Loss: 0.0274, Avg Loss: 0.0274\n",
      "Diff stats — min: -5.2932, max: 10.0000, mean: 8.3310, std: 2.5077\n",
      "\n",
      "Step 11521 — Test metrics:\n",
      "  precision@10: 0.015841584\n",
      "  recall@10: 0.015896870\n",
      "  ndcg@10: 0.017007954\n",
      "  map@10: 0.006641722\n",
      "Epoch 386, Step 20, LR: 0.000474, Current Loss: 0.0283, Avg Loss: 0.0324\n",
      "Diff stats — min: -4.4863, max: 10.0000, mean: 8.3625, std: 2.5118\n",
      "\n",
      "Epoch 386 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 387, Step 1, LR: 0.000474, Current Loss: 0.0342, Avg Loss: 0.0342\n",
      "Diff stats — min: -6.2286, max: 10.0000, mean: 8.3134, std: 2.5848\n",
      "\n",
      "Step 11551 — Test metrics:\n",
      "  precision@10: 0.015511551\n",
      "  recall@10: 0.015576940\n",
      "  ndcg@10: 0.016664729\n",
      "  map@10: 0.006483473\n",
      "Epoch 387, Step 20, LR: 0.000474, Current Loss: 0.0349, Avg Loss: 0.0312\n",
      "Diff stats — min: -6.8647, max: 10.0000, mean: 8.2838, std: 2.6018\n",
      "\n",
      "Epoch 387 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 388, Step 1, LR: 0.000474, Current Loss: 0.0255, Avg Loss: 0.0255\n",
      "Diff stats — min: -3.0828, max: 10.0000, mean: 8.3346, std: 2.5294\n",
      "\n",
      "Step 11581 — Test metrics:\n",
      "  precision@10: 0.016006601\n",
      "  recall@10: 0.016082467\n",
      "  ndcg@10: 0.017071004\n",
      "  map@10: 0.006592408\n",
      "Epoch 388, Step 20, LR: 0.000474, Current Loss: 0.0293, Avg Loss: 0.0317\n",
      "Diff stats — min: -5.0450, max: 10.0000, mean: 8.3722, std: 2.5200\n",
      "\n",
      "Epoch 388 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 389, Step 1, LR: 0.000474, Current Loss: 0.0257, Avg Loss: 0.0257\n",
      "Diff stats — min: -4.6743, max: 10.0000, mean: 8.3101, std: 2.5401\n",
      "\n",
      "Step 11611 — Test metrics:\n",
      "  precision@10: 0.015747289\n",
      "  recall@10: 0.015817917\n",
      "  ndcg@10: 0.017125406\n",
      "  map@10: 0.006645423\n",
      "Epoch 389, Step 20, LR: 0.000474, Current Loss: 0.0263, Avg Loss: 0.0315\n",
      "Diff stats — min: -5.5129, max: 10.0000, mean: 8.4014, std: 2.4838\n",
      "\n",
      "Epoch 389 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 390, Step 1, LR: 0.000474, Current Loss: 0.0416, Avg Loss: 0.0416\n",
      "Diff stats — min: -7.4511, max: 10.0000, mean: 8.2845, std: 2.6311\n",
      "\n",
      "Step 11641 — Test metrics:\n",
      "  precision@10: 0.015794437\n",
      "  recall@10: 0.015862445\n",
      "  ndcg@10: 0.016913635\n",
      "  map@10: 0.006473917\n",
      "Epoch 390, Step 20, LR: 0.000474, Current Loss: 0.0310, Avg Loss: 0.0317\n",
      "Diff stats — min: -4.7230, max: 10.0000, mean: 8.3370, std: 2.5572\n",
      "\n",
      "Epoch 390 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 391, Step 1, LR: 0.000464, Current Loss: 0.0345, Avg Loss: 0.0345\n",
      "Diff stats — min: -9.4145, max: 10.0000, mean: 8.3262, std: 2.5755\n",
      "\n",
      "Step 11671 — Test metrics:\n",
      "  precision@10: 0.015983027\n",
      "  recall@10: 0.016056274\n",
      "  ndcg@10: 0.016938725\n",
      "  map@10: 0.006499495\n",
      "Epoch 391, Step 20, LR: 0.000464, Current Loss: 0.0310, Avg Loss: 0.0319\n",
      "Diff stats — min: -6.1025, max: 10.0000, mean: 8.4088, std: 2.5299\n",
      "\n",
      "Epoch 391 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 392, Step 1, LR: 0.000464, Current Loss: 0.0355, Avg Loss: 0.0355\n",
      "Diff stats — min: -8.7844, max: 10.0000, mean: 8.3608, std: 2.5482\n",
      "\n",
      "Step 11701 — Test metrics:\n",
      "  precision@10: 0.015582273\n",
      "  recall@10: 0.015652900\n",
      "  ndcg@10: 0.016658855\n",
      "  map@10: 0.006399740\n",
      "Epoch 392, Step 20, LR: 0.000464, Current Loss: 0.0415, Avg Loss: 0.0316\n",
      "Diff stats — min: -4.7696, max: 10.0000, mean: 8.3362, std: 2.6183\n",
      "\n",
      "Epoch 392 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 393, Step 1, LR: 0.000464, Current Loss: 0.0318, Avg Loss: 0.0318\n",
      "Diff stats — min: -6.1848, max: 10.0000, mean: 8.3628, std: 2.5278\n",
      "\n",
      "Step 11731 — Test metrics:\n",
      "  precision@10: 0.016124470\n",
      "  recall@10: 0.016186585\n",
      "  ndcg@10: 0.017239527\n",
      "  map@10: 0.006655890\n",
      "Epoch 393, Step 20, LR: 0.000464, Current Loss: 0.0294, Avg Loss: 0.0301\n",
      "Diff stats — min: -6.2324, max: 10.0000, mean: 8.3718, std: 2.5292\n",
      "\n",
      "Epoch 393 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 394, Step 1, LR: 0.000464, Current Loss: 0.0355, Avg Loss: 0.0355\n",
      "Diff stats — min: -4.7800, max: 10.0000, mean: 8.3446, std: 2.5960\n",
      "\n",
      "Step 11761 — Test metrics:\n",
      "  precision@10: 0.016100896\n",
      "  recall@10: 0.016174798\n",
      "  ndcg@10: 0.016936089\n",
      "  map@10: 0.006470584\n",
      "Epoch 394, Step 20, LR: 0.000464, Current Loss: 0.0408, Avg Loss: 0.0323\n",
      "Diff stats — min: -7.1524, max: 10.0000, mean: 8.3448, std: 2.6093\n",
      "\n",
      "Epoch 394 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 395, Step 1, LR: 0.000464, Current Loss: 0.0320, Avg Loss: 0.0320\n",
      "Diff stats — min: -5.5066, max: 10.0000, mean: 8.3376, std: 2.5572\n",
      "\n",
      "Step 11791 — Test metrics:\n",
      "  precision@10: 0.015818010\n",
      "  recall@10: 0.015886019\n",
      "  ndcg@10: 0.016825509\n",
      "  map@10: 0.006451095\n",
      "Epoch 395, Step 20, LR: 0.000464, Current Loss: 0.0244, Avg Loss: 0.0307\n",
      "Diff stats — min: -4.5168, max: 10.0000, mean: 8.3471, std: 2.4701\n",
      "\n",
      "Epoch 395 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 396, Step 1, LR: 0.000455, Current Loss: 0.0367, Avg Loss: 0.0367\n",
      "Diff stats — min: -5.9319, max: 10.0000, mean: 8.2746, std: 2.6302\n",
      "\n",
      "Step 11821 — Test metrics:\n",
      "  precision@10: 0.016195191\n",
      "  recall@10: 0.016273677\n",
      "  ndcg@10: 0.017218665\n",
      "  map@10: 0.006588860\n",
      "Epoch 396, Step 20, LR: 0.000455, Current Loss: 0.0263, Avg Loss: 0.0315\n",
      "Diff stats — min: -7.2106, max: 10.0000, mean: 8.3873, std: 2.5066\n",
      "\n",
      "Epoch 396 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 397, Step 1, LR: 0.000455, Current Loss: 0.0357, Avg Loss: 0.0357\n",
      "Diff stats — min: -5.6885, max: 10.0000, mean: 8.3417, std: 2.5678\n",
      "\n",
      "Step 11851 — Test metrics:\n",
      "  precision@10: 0.016053748\n",
      "  recall@10: 0.016126341\n",
      "  ndcg@10: 0.017224898\n",
      "  map@10: 0.006658756\n",
      "Epoch 397, Step 20, LR: 0.000455, Current Loss: 0.0273, Avg Loss: 0.0318\n",
      "Diff stats — min: -4.9737, max: 10.0000, mean: 8.3731, std: 2.5171\n",
      "\n",
      "Epoch 397 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 398, Step 1, LR: 0.000455, Current Loss: 0.0326, Avg Loss: 0.0326\n",
      "Diff stats — min: -4.6640, max: 10.0000, mean: 8.3709, std: 2.5230\n",
      "\n",
      "Step 11881 — Test metrics:\n",
      "  precision@10: 0.015747289\n",
      "  recall@10: 0.015814643\n",
      "  ndcg@10: 0.017013893\n",
      "  map@10: 0.006535249\n",
      "Epoch 398, Step 20, LR: 0.000455, Current Loss: 0.0323, Avg Loss: 0.0320\n",
      "Diff stats — min: -5.8654, max: 10.0000, mean: 8.4100, std: 2.5493\n",
      "\n",
      "Epoch 398 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 399, Step 1, LR: 0.000455, Current Loss: 0.0334, Avg Loss: 0.0334\n",
      "Diff stats — min: -5.7242, max: 10.0000, mean: 8.3161, std: 2.5861\n",
      "\n",
      "Step 11911 — Test metrics:\n",
      "  precision@10: 0.016077322\n",
      "  recall@10: 0.016147950\n",
      "  ndcg@10: 0.017235613\n",
      "  map@10: 0.006673395\n",
      "Epoch 399, Step 20, LR: 0.000455, Current Loss: 0.0274, Avg Loss: 0.0307\n",
      "Diff stats — min: -5.7981, max: 10.0000, mean: 8.3931, std: 2.4928\n",
      "\n",
      "Epoch 399 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 400, Step 1, LR: 0.000455, Current Loss: 0.0322, Avg Loss: 0.0322\n",
      "Diff stats — min: -6.1970, max: 10.0000, mean: 8.4286, std: 2.5233\n",
      "\n",
      "Step 11941 — Test metrics:\n",
      "  precision@10: 0.016265912\n",
      "  recall@10: 0.016336540\n",
      "  ndcg@10: 0.017515772\n",
      "  map@10: 0.006769678\n",
      "Epoch 400, Step 20, LR: 0.000455, Current Loss: 0.0321, Avg Loss: 0.0310\n",
      "Diff stats — min: -5.6768, max: 10.0000, mean: 8.3599, std: 2.5813\n",
      "\n",
      "Epoch 400 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 401, Step 1, LR: 0.000446, Current Loss: 0.0230, Avg Loss: 0.0230\n",
      "Diff stats — min: -3.2523, max: 10.0000, mean: 8.3543, std: 2.4860\n",
      "\n",
      "Step 11971 — Test metrics:\n",
      "  precision@10: 0.016077322\n",
      "  recall@10: 0.016150569\n",
      "  ndcg@10: 0.017386337\n",
      "  map@10: 0.006707876\n",
      "Epoch 401, Step 20, LR: 0.000446, Current Loss: 0.0331, Avg Loss: 0.0303\n",
      "Diff stats — min: -6.3719, max: 10.0000, mean: 8.4633, std: 2.5014\n",
      "\n",
      "Epoch 401 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 402, Step 1, LR: 0.000446, Current Loss: 0.0312, Avg Loss: 0.0312\n",
      "Diff stats — min: -5.4397, max: 10.0000, mean: 8.3794, std: 2.5356\n",
      "\n",
      "Step 12001 — Test metrics:\n",
      "  precision@10: 0.016218765\n",
      "  recall@10: 0.016300525\n",
      "  ndcg@10: 0.017262976\n",
      "  map@10: 0.006595067\n",
      "Epoch 402, Step 20, LR: 0.000446, Current Loss: 0.0420, Avg Loss: 0.0322\n",
      "Diff stats — min: -5.9029, max: 10.0000, mean: 8.3018, std: 2.6554\n",
      "\n",
      "Epoch 402 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 403, Step 1, LR: 0.000446, Current Loss: 0.0362, Avg Loss: 0.0362\n",
      "Diff stats — min: -4.7714, max: 10.0000, mean: 8.3639, std: 2.5643\n",
      "\n",
      "Step 12031 — Test metrics:\n",
      "  precision@10: 0.016100896\n",
      "  recall@10: 0.016168249\n",
      "  ndcg@10: 0.017336824\n",
      "  map@10: 0.006711164\n",
      "Epoch 403, Step 20, LR: 0.000446, Current Loss: 0.0312, Avg Loss: 0.0300\n",
      "Diff stats — min: -7.2438, max: 10.0000, mean: 8.3788, std: 2.5150\n",
      "\n",
      "Epoch 403 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 404, Step 1, LR: 0.000446, Current Loss: 0.0295, Avg Loss: 0.0295\n",
      "Diff stats — min: -4.9869, max: 10.0000, mean: 8.4192, std: 2.5296\n",
      "\n",
      "Step 12061 — Test metrics:\n",
      "  precision@10: 0.016053748\n",
      "  recall@10: 0.016115863\n",
      "  ndcg@10: 0.017316038\n",
      "  map@10: 0.006668988\n",
      "Epoch 404, Step 20, LR: 0.000446, Current Loss: 0.0266, Avg Loss: 0.0305\n",
      "Diff stats — min: -6.3181, max: 10.0000, mean: 8.4021, std: 2.5151\n",
      "\n",
      "Epoch 404 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 405, Step 1, LR: 0.000446, Current Loss: 0.0316, Avg Loss: 0.0316\n",
      "Diff stats — min: -3.8147, max: 10.0000, mean: 8.3851, std: 2.5402\n",
      "\n",
      "Step 12091 — Test metrics:\n",
      "  precision@10: 0.015959453\n",
      "  recall@10: 0.016024187\n",
      "  ndcg@10: 0.017248145\n",
      "  map@10: 0.006659987\n",
      "Epoch 405, Step 20, LR: 0.000446, Current Loss: 0.0267, Avg Loss: 0.0302\n",
      "Diff stats — min: -5.5898, max: 10.0000, mean: 8.4487, std: 2.4714\n",
      "\n",
      "Epoch 405 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 406, Step 1, LR: 0.000437, Current Loss: 0.0289, Avg Loss: 0.0289\n",
      "Diff stats — min: -3.9169, max: 10.0000, mean: 8.3942, std: 2.5225\n",
      "\n",
      "Step 12121 — Test metrics:\n",
      "  precision@10: 0.015770863\n",
      "  recall@10: 0.015846729\n",
      "  ndcg@10: 0.016962462\n",
      "  map@10: 0.006539972\n",
      "Epoch 406, Step 20, LR: 0.000437, Current Loss: 0.0260, Avg Loss: 0.0302\n",
      "Diff stats — min: -6.0785, max: 10.0000, mean: 8.4226, std: 2.4568\n",
      "\n",
      "Epoch 406 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 407, Step 1, LR: 0.000437, Current Loss: 0.0364, Avg Loss: 0.0364\n",
      "Diff stats — min: -5.3811, max: 10.0000, mean: 8.3916, std: 2.5521\n",
      "\n",
      "Step 12151 — Test metrics:\n",
      "  precision@10: 0.016148043\n",
      "  recall@10: 0.016212778\n",
      "  ndcg@10: 0.017290252\n",
      "  map@10: 0.006665479\n",
      "Epoch 407, Step 20, LR: 0.000437, Current Loss: 0.0313, Avg Loss: 0.0309\n",
      "Diff stats — min: -8.0367, max: 10.0000, mean: 8.3760, std: 2.5193\n",
      "\n",
      "Epoch 407 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 408, Step 1, LR: 0.000437, Current Loss: 0.0314, Avg Loss: 0.0314\n",
      "Diff stats — min: -4.1631, max: 10.0000, mean: 8.3749, std: 2.5374\n",
      "\n",
      "Step 12181 — Test metrics:\n",
      "  precision@10: 0.015723715\n",
      "  recall@10: 0.015794343\n",
      "  ndcg@10: 0.016969252\n",
      "  map@10: 0.006470060\n",
      "Epoch 408, Step 20, LR: 0.000437, Current Loss: 0.0298, Avg Loss: 0.0317\n",
      "Diff stats — min: -4.1723, max: 10.0000, mean: 8.4000, std: 2.5120\n",
      "\n",
      "Epoch 408 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 409, Step 1, LR: 0.000437, Current Loss: 0.0343, Avg Loss: 0.0343\n",
      "Diff stats — min: -6.7369, max: 10.0000, mean: 8.3261, std: 2.6247\n",
      "\n",
      "Step 12211 — Test metrics:\n",
      "  precision@10: 0.015912306\n",
      "  recall@10: 0.015966937\n",
      "  ndcg@10: 0.017013700\n",
      "  map@10: 0.006483923\n",
      "Epoch 409, Step 20, LR: 0.000437, Current Loss: 0.0293, Avg Loss: 0.0304\n",
      "Diff stats — min: -6.4149, max: 10.0000, mean: 8.4297, std: 2.4965\n",
      "\n",
      "Epoch 409 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 410, Step 1, LR: 0.000437, Current Loss: 0.0263, Avg Loss: 0.0263\n",
      "Diff stats — min: -4.6495, max: 10.0000, mean: 8.4321, std: 2.4721\n",
      "\n",
      "Step 12241 — Test metrics:\n",
      "  precision@10: 0.015935879\n",
      "  recall@10: 0.016006507\n",
      "  ndcg@10: 0.017238233\n",
      "  map@10: 0.006677012\n",
      "Epoch 410, Step 20, LR: 0.000437, Current Loss: 0.0283, Avg Loss: 0.0318\n",
      "Diff stats — min: -4.3664, max: 10.0000, mean: 8.4074, std: 2.4866\n",
      "\n",
      "Epoch 410 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 411, Step 1, LR: 0.000428, Current Loss: 0.0250, Avg Loss: 0.0250\n",
      "Diff stats — min: -5.9603, max: 10.0000, mean: 8.4629, std: 2.4180\n",
      "\n",
      "Step 12271 — Test metrics:\n",
      "  precision@10: 0.015888732\n",
      "  recall@10: 0.015955150\n",
      "  ndcg@10: 0.017026641\n",
      "  map@10: 0.006535372\n",
      "Epoch 411, Step 20, LR: 0.000428, Current Loss: 0.0301, Avg Loss: 0.0306\n",
      "Diff stats — min: -6.4501, max: 10.0000, mean: 8.4272, std: 2.5062\n",
      "\n",
      "Epoch 411 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 412, Step 1, LR: 0.000428, Current Loss: 0.0302, Avg Loss: 0.0302\n",
      "Diff stats — min: -4.3313, max: 10.0000, mean: 8.4127, std: 2.5120\n",
      "\n",
      "Step 12301 — Test metrics:\n",
      "  precision@10: 0.015888732\n",
      "  recall@10: 0.015964598\n",
      "  ndcg@10: 0.016986175\n",
      "  map@10: 0.006462204\n",
      "Epoch 412, Step 20, LR: 0.000428, Current Loss: 0.0257, Avg Loss: 0.0311\n",
      "Diff stats — min: -4.8110, max: 10.0000, mean: 8.4261, std: 2.4759\n",
      "\n",
      "Epoch 412 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 413, Step 1, LR: 0.000428, Current Loss: 0.0257, Avg Loss: 0.0257\n",
      "Diff stats — min: -3.9391, max: 10.0000, mean: 8.5066, std: 2.4261\n",
      "\n",
      "Step 12331 — Test metrics:\n",
      "  precision@10: 0.016030174\n",
      "  recall@10: 0.016111934\n",
      "  ndcg@10: 0.017075906\n",
      "  map@10: 0.006541054\n",
      "Epoch 413, Step 20, LR: 0.000428, Current Loss: 0.0287, Avg Loss: 0.0298\n",
      "Diff stats — min: -5.3072, max: 10.0000, mean: 8.3957, std: 2.4892\n",
      "\n",
      "Epoch 413 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 414, Step 1, LR: 0.000428, Current Loss: 0.0333, Avg Loss: 0.0333\n",
      "Diff stats — min: -5.3835, max: 10.0000, mean: 8.4084, std: 2.5500\n",
      "\n",
      "Step 12361 — Test metrics:\n",
      "  precision@10: 0.016195191\n",
      "  recall@10: 0.016282844\n",
      "  ndcg@10: 0.017125489\n",
      "  map@10: 0.006539230\n",
      "Epoch 414, Step 20, LR: 0.000428, Current Loss: 0.0326, Avg Loss: 0.0290\n",
      "Diff stats — min: -7.3120, max: 10.0000, mean: 8.3832, std: 2.5560\n",
      "\n",
      "Epoch 414 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 415, Step 1, LR: 0.000428, Current Loss: 0.0338, Avg Loss: 0.0338\n",
      "Diff stats — min: -6.8797, max: 10.0000, mean: 8.3972, std: 2.5686\n",
      "\n",
      "Step 12391 — Test metrics:\n",
      "  precision@10: 0.016313060\n",
      "  recall@10: 0.016400713\n",
      "  ndcg@10: 0.017451326\n",
      "  map@10: 0.006685475\n",
      "Epoch 415, Step 20, LR: 0.000428, Current Loss: 0.0285, Avg Loss: 0.0301\n",
      "Diff stats — min: -3.4860, max: 10.0000, mean: 8.4288, std: 2.4853\n",
      "\n",
      "Epoch 415 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 416, Step 1, LR: 0.000419, Current Loss: 0.0367, Avg Loss: 0.0367\n",
      "Diff stats — min: -6.8032, max: 10.0000, mean: 8.3468, std: 2.5861\n",
      "\n",
      "Step 12421 — Test metrics:\n",
      "  precision@10: 0.016548798\n",
      "  recall@10: 0.016630558\n",
      "  ndcg@10: 0.017550923\n",
      "  map@10: 0.006752543\n",
      "Epoch 416, Step 20, LR: 0.000419, Current Loss: 0.0299, Avg Loss: 0.0306\n",
      "Diff stats — min: -5.3609, max: 10.0000, mean: 8.4099, std: 2.5174\n",
      "\n",
      "Epoch 416 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 417, Step 1, LR: 0.000419, Current Loss: 0.0309, Avg Loss: 0.0309\n",
      "Diff stats — min: -8.7000, max: 10.0000, mean: 8.4013, std: 2.5023\n",
      "\n",
      "Step 12451 — Test metrics:\n",
      "  precision@10: 0.016148043\n",
      "  recall@10: 0.016216426\n",
      "  ndcg@10: 0.017352482\n",
      "  map@10: 0.006716350\n",
      "Epoch 417, Step 20, LR: 0.000419, Current Loss: 0.0257, Avg Loss: 0.0294\n",
      "Diff stats — min: -5.4916, max: 10.0000, mean: 8.4259, std: 2.4661\n",
      "\n",
      "Epoch 417 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 418, Step 1, LR: 0.000419, Current Loss: 0.0286, Avg Loss: 0.0286\n",
      "Diff stats — min: -7.8232, max: 10.0000, mean: 8.4146, std: 2.4919\n",
      "\n",
      "Step 12481 — Test metrics:\n",
      "  precision@10: 0.016737388\n",
      "  recall@10: 0.016809045\n",
      "  ndcg@10: 0.017738182\n",
      "  map@10: 0.006819296\n",
      "Epoch 418, Step 20, LR: 0.000419, Current Loss: 0.0234, Avg Loss: 0.0293\n",
      "Diff stats — min: -7.8405, max: 10.0000, mean: 8.4910, std: 2.4212\n",
      "\n",
      "Epoch 418 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 419, Step 1, LR: 0.000419, Current Loss: 0.0249, Avg Loss: 0.0249\n",
      "Diff stats — min: -3.2249, max: 10.0000, mean: 8.4374, std: 2.4690\n",
      "\n",
      "Step 12511 — Test metrics:\n",
      "  precision@10: 0.016100896\n",
      "  recall@10: 0.016169933\n",
      "  ndcg@10: 0.017393227\n",
      "  map@10: 0.006759663\n",
      "Epoch 419, Step 20, LR: 0.000419, Current Loss: 0.0307, Avg Loss: 0.0284\n",
      "Diff stats — min: -5.7127, max: 10.0000, mean: 8.4458, std: 2.4889\n",
      "\n",
      "Epoch 419 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 420, Step 1, LR: 0.000419, Current Loss: 0.0325, Avg Loss: 0.0325\n",
      "Diff stats — min: -4.1576, max: 10.0000, mean: 8.4172, std: 2.5675\n",
      "\n",
      "Step 12541 — Test metrics:\n",
      "  precision@10: 0.016407355\n",
      "  recall@10: 0.016486496\n",
      "  ndcg@10: 0.017479824\n",
      "  map@10: 0.006754398\n",
      "Epoch 420, Step 20, LR: 0.000419, Current Loss: 0.0309, Avg Loss: 0.0299\n",
      "Diff stats — min: -7.0918, max: 10.0000, mean: 8.4202, std: 2.5188\n",
      "\n",
      "Epoch 420 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 421, Step 1, LR: 0.000411, Current Loss: 0.0316, Avg Loss: 0.0316\n",
      "Diff stats — min: -4.6500, max: 10.0000, mean: 8.4227, std: 2.5159\n",
      "\n",
      "Step 12571 — Test metrics:\n",
      "  precision@10: 0.016360207\n",
      "  recall@10: 0.016444587\n",
      "  ndcg@10: 0.017375499\n",
      "  map@10: 0.006662981\n",
      "Epoch 421, Step 20, LR: 0.000411, Current Loss: 0.0293, Avg Loss: 0.0305\n",
      "Diff stats — min: -5.0417, max: 10.0000, mean: 8.4650, std: 2.4911\n",
      "\n",
      "Epoch 421 completed, Train Loss: 0.000008\n",
      "\n",
      "Epoch 422, Step 1, LR: 0.000411, Current Loss: 0.0297, Avg Loss: 0.0297\n",
      "Diff stats — min: -6.0151, max: 10.0000, mean: 8.5316, std: 2.4250\n",
      "\n",
      "Step 12601 — Test metrics:\n",
      "  precision@10: 0.016336634\n",
      "  recall@10: 0.016418394\n",
      "  ndcg@10: 0.017303480\n",
      "  map@10: 0.006665644\n",
      "Epoch 422, Step 20, LR: 0.000411, Current Loss: 0.0266, Avg Loss: 0.0292\n",
      "Diff stats — min: -5.5132, max: 10.0000, mean: 8.4073, std: 2.4774\n",
      "\n",
      "Epoch 422 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 423, Step 1, LR: 0.000411, Current Loss: 0.0390, Avg Loss: 0.0390\n",
      "Diff stats — min: -6.5477, max: 10.0000, mean: 8.4376, std: 2.5631\n",
      "\n",
      "Step 12631 — Test metrics:\n",
      "  precision@10: 0.016336634\n",
      "  recall@10: 0.016415774\n",
      "  ndcg@10: 0.017610805\n",
      "  map@10: 0.006859831\n",
      "Epoch 423, Step 20, LR: 0.000411, Current Loss: 0.0297, Avg Loss: 0.0309\n",
      "Diff stats — min: -5.6276, max: 10.0000, mean: 8.4298, std: 2.5024\n",
      "\n",
      "Epoch 423 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 424, Step 1, LR: 0.000411, Current Loss: 0.0310, Avg Loss: 0.0310\n",
      "Diff stats — min: -7.5890, max: 10.0000, mean: 8.4876, std: 2.4590\n",
      "\n",
      "Step 12661 — Test metrics:\n",
      "  precision@10: 0.015888732\n",
      "  recall@10: 0.015964598\n",
      "  ndcg@10: 0.017391218\n",
      "  map@10: 0.006824162\n",
      "Epoch 424, Step 20, LR: 0.000411, Current Loss: 0.0325, Avg Loss: 0.0299\n",
      "Diff stats — min: -5.5556, max: 10.0000, mean: 8.4437, std: 2.5072\n",
      "\n",
      "Epoch 424 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 425, Step 1, LR: 0.000411, Current Loss: 0.0377, Avg Loss: 0.0377\n",
      "Diff stats — min: -6.6569, max: 10.0000, mean: 8.4167, std: 2.5720\n",
      "\n",
      "Step 12691 — Test metrics:\n",
      "  precision@10: 0.016077322\n",
      "  recall@10: 0.016150569\n",
      "  ndcg@10: 0.017277899\n",
      "  map@10: 0.006735575\n",
      "Epoch 425, Step 20, LR: 0.000411, Current Loss: 0.0318, Avg Loss: 0.0290\n",
      "Diff stats — min: -6.0381, max: 10.0000, mean: 8.4410, std: 2.4955\n",
      "\n",
      "Epoch 425 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 426, Step 1, LR: 0.000403, Current Loss: 0.0306, Avg Loss: 0.0306\n",
      "Diff stats — min: -6.2443, max: 10.0000, mean: 8.4521, std: 2.4880\n",
      "\n",
      "Step 12721 — Test metrics:\n",
      "  precision@10: 0.016430929\n",
      "  recall@10: 0.016506795\n",
      "  ndcg@10: 0.017560916\n",
      "  map@10: 0.006757610\n",
      "Epoch 426, Step 20, LR: 0.000403, Current Loss: 0.0259, Avg Loss: 0.0282\n",
      "Diff stats — min: -5.1400, max: 10.0000, mean: 8.4467, std: 2.4427\n",
      "\n",
      "Epoch 426 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 427, Step 1, LR: 0.000403, Current Loss: 0.0269, Avg Loss: 0.0269\n",
      "Diff stats — min: -4.3314, max: 10.0000, mean: 8.4650, std: 2.4536\n",
      "\n",
      "Step 12751 — Test metrics:\n",
      "  precision@10: 0.016030174\n",
      "  recall@10: 0.016114554\n",
      "  ndcg@10: 0.017295198\n",
      "  map@10: 0.006764736\n",
      "Epoch 427, Step 20, LR: 0.000403, Current Loss: 0.0277, Avg Loss: 0.0291\n",
      "Diff stats — min: -6.0778, max: 10.0000, mean: 8.4452, std: 2.4844\n",
      "\n",
      "Epoch 427 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 428, Step 1, LR: 0.000403, Current Loss: 0.0324, Avg Loss: 0.0324\n",
      "Diff stats — min: -6.5902, max: 10.0000, mean: 8.4568, std: 2.5165\n",
      "\n",
      "Step 12781 — Test metrics:\n",
      "  precision@10: 0.015865158\n",
      "  recall@10: 0.015941024\n",
      "  ndcg@10: 0.017068368\n",
      "  map@10: 0.006653762\n",
      "Epoch 428, Step 20, LR: 0.000403, Current Loss: 0.0249, Avg Loss: 0.0292\n",
      "Diff stats — min: -6.0887, max: 10.0000, mean: 8.4934, std: 2.4087\n",
      "\n",
      "Epoch 428 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 429, Step 1, LR: 0.000403, Current Loss: 0.0266, Avg Loss: 0.0266\n",
      "Diff stats — min: -6.1602, max: 10.0000, mean: 8.5301, std: 2.4202\n",
      "\n",
      "Step 12811 — Test metrics:\n",
      "  precision@10: 0.016030174\n",
      "  recall@10: 0.016106041\n",
      "  ndcg@10: 0.017261359\n",
      "  map@10: 0.006709028\n",
      "Epoch 429, Step 20, LR: 0.000403, Current Loss: 0.0287, Avg Loss: 0.0292\n",
      "Diff stats — min: -5.1651, max: 10.0000, mean: 8.4987, std: 2.4464\n",
      "\n",
      "Epoch 429 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 430, Step 1, LR: 0.000403, Current Loss: 0.0284, Avg Loss: 0.0284\n",
      "Diff stats — min: -8.3244, max: 10.0000, mean: 8.4716, std: 2.4686\n",
      "\n",
      "Step 12841 — Test metrics:\n",
      "  precision@10: 0.015582273\n",
      "  recall@10: 0.015648036\n",
      "  ndcg@10: 0.016674554\n",
      "  map@10: 0.006384796\n",
      "Epoch 430, Step 20, LR: 0.000403, Current Loss: 0.0359, Avg Loss: 0.0296\n",
      "Diff stats — min: -6.4722, max: 10.0000, mean: 8.3630, std: 2.5965\n",
      "\n",
      "Epoch 430 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 431, Step 1, LR: 0.000395, Current Loss: 0.0253, Avg Loss: 0.0253\n",
      "Diff stats — min: -5.1072, max: 10.0000, mean: 8.4207, std: 2.4654\n",
      "\n",
      "Step 12871 — Test metrics:\n",
      "  precision@10: 0.015700141\n",
      "  recall@10: 0.015760666\n",
      "  ndcg@10: 0.016765843\n",
      "  map@10: 0.006447692\n",
      "Epoch 431, Step 20, LR: 0.000395, Current Loss: 0.0218, Avg Loss: 0.0291\n",
      "Diff stats — min: -5.0786, max: 10.0000, mean: 8.5218, std: 2.3993\n",
      "\n",
      "Epoch 431 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 432, Step 1, LR: 0.000395, Current Loss: 0.0223, Avg Loss: 0.0223\n",
      "Diff stats — min: -4.4883, max: 10.0000, mean: 8.5933, std: 2.3764\n",
      "\n",
      "Step 12901 — Test metrics:\n",
      "  precision@10: 0.016006601\n",
      "  recall@10: 0.016079848\n",
      "  ndcg@10: 0.017153174\n",
      "  map@10: 0.006667554\n",
      "Epoch 432, Step 20, LR: 0.000395, Current Loss: 0.0262, Avg Loss: 0.0289\n",
      "Diff stats — min: -5.7114, max: 10.0000, mean: 8.4681, std: 2.4726\n",
      "\n",
      "Epoch 432 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 433, Step 1, LR: 0.000395, Current Loss: 0.0283, Avg Loss: 0.0283\n",
      "Diff stats — min: -6.6537, max: 10.0000, mean: 8.4749, std: 2.4752\n",
      "\n",
      "Step 12931 — Test metrics:\n",
      "  precision@10: 0.015865158\n",
      "  recall@10: 0.015925683\n",
      "  ndcg@10: 0.016953216\n",
      "  map@10: 0.006528706\n",
      "Epoch 433, Step 20, LR: 0.000395, Current Loss: 0.0249, Avg Loss: 0.0272\n",
      "Diff stats — min: -6.3743, max: 10.0000, mean: 8.5208, std: 2.3925\n",
      "\n",
      "Epoch 433 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 434, Step 1, LR: 0.000395, Current Loss: 0.0354, Avg Loss: 0.0354\n",
      "Diff stats — min: -5.5727, max: 10.0000, mean: 8.3995, std: 2.5260\n",
      "\n",
      "Step 12961 — Test metrics:\n",
      "  precision@10: 0.015652994\n",
      "  recall@10: 0.015713519\n",
      "  ndcg@10: 0.016739107\n",
      "  map@10: 0.006434790\n",
      "Epoch 434, Step 20, LR: 0.000395, Current Loss: 0.0321, Avg Loss: 0.0288\n",
      "Diff stats — min: -9.4305, max: 10.0000, mean: 8.4783, std: 2.5078\n",
      "\n",
      "Epoch 434 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 435, Step 1, LR: 0.000395, Current Loss: 0.0305, Avg Loss: 0.0305\n",
      "Diff stats — min: -6.1034, max: 10.0000, mean: 8.4405, std: 2.5049\n",
      "\n",
      "Step 12991 — Test metrics:\n",
      "  precision@10: 0.015700141\n",
      "  recall@10: 0.015760666\n",
      "  ndcg@10: 0.016749285\n",
      "  map@10: 0.006478034\n",
      "Epoch 435, Step 20, LR: 0.000395, Current Loss: 0.0262, Avg Loss: 0.0291\n",
      "Diff stats — min: -4.9147, max: 10.0000, mean: 8.4800, std: 2.4211\n",
      "\n",
      "Epoch 435 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 436, Step 1, LR: 0.000387, Current Loss: 0.0270, Avg Loss: 0.0270\n",
      "Diff stats — min: -4.2493, max: 10.0000, mean: 8.4739, std: 2.4391\n",
      "\n",
      "Step 13021 — Test metrics:\n",
      "  precision@10: 0.015723715\n",
      "  recall@10: 0.015784240\n",
      "  ndcg@10: 0.016850620\n",
      "  map@10: 0.006531410\n",
      "Epoch 436, Step 20, LR: 0.000387, Current Loss: 0.0281, Avg Loss: 0.0288\n",
      "Diff stats — min: -5.2131, max: 10.0000, mean: 8.4670, std: 2.4858\n",
      "\n",
      "Epoch 436 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 437, Step 1, LR: 0.000387, Current Loss: 0.0318, Avg Loss: 0.0318\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 8.4692, std: 2.5174\n",
      "\n",
      "Step 13051 — Test metrics:\n",
      "  precision@10: 0.015959453\n",
      "  recall@10: 0.016019978\n",
      "  ndcg@10: 0.017120570\n",
      "  map@10: 0.006618258\n",
      "Epoch 437, Step 20, LR: 0.000387, Current Loss: 0.0325, Avg Loss: 0.0296\n",
      "Diff stats — min: -6.3926, max: 10.0000, mean: 8.4555, std: 2.5058\n",
      "\n",
      "Epoch 437 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 438, Step 1, LR: 0.000387, Current Loss: 0.0334, Avg Loss: 0.0334\n",
      "Diff stats — min: -5.7606, max: 10.0000, mean: 8.4353, std: 2.5448\n",
      "\n",
      "Step 13081 — Test metrics:\n",
      "  precision@10: 0.015865158\n",
      "  recall@10: 0.015925683\n",
      "  ndcg@10: 0.016975309\n",
      "  map@10: 0.006517682\n",
      "Epoch 438, Step 20, LR: 0.000387, Current Loss: 0.0259, Avg Loss: 0.0295\n",
      "Diff stats — min: -7.5727, max: 10.0000, mean: 8.4564, std: 2.4402\n",
      "\n",
      "Epoch 438 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 439, Step 1, LR: 0.000387, Current Loss: 0.0278, Avg Loss: 0.0278\n",
      "Diff stats — min: -5.3401, max: 10.0000, mean: 8.4887, std: 2.4682\n",
      "\n",
      "Step 13111 — Test metrics:\n",
      "  precision@10: 0.015652994\n",
      "  recall@10: 0.015710899\n",
      "  ndcg@10: 0.016932487\n",
      "  map@10: 0.006575122\n",
      "Epoch 439, Step 20, LR: 0.000387, Current Loss: 0.0315, Avg Loss: 0.0283\n",
      "Diff stats — min: -4.9255, max: 10.0000, mean: 8.4353, std: 2.5301\n",
      "\n",
      "Epoch 439 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 440, Step 1, LR: 0.000387, Current Loss: 0.0250, Avg Loss: 0.0250\n",
      "Diff stats — min: -5.4146, max: 10.0000, mean: 8.5250, std: 2.4092\n",
      "\n",
      "Step 13141 — Test metrics:\n",
      "  precision@10: 0.015582273\n",
      "  recall@10: 0.015642797\n",
      "  ndcg@10: 0.016714853\n",
      "  map@10: 0.006445851\n",
      "Epoch 440, Step 20, LR: 0.000387, Current Loss: 0.0288, Avg Loss: 0.0272\n",
      "Diff stats — min: -5.1630, max: 10.0000, mean: 8.5325, std: 2.4547\n",
      "\n",
      "Epoch 440 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 441, Step 1, LR: 0.000379, Current Loss: 0.0230, Avg Loss: 0.0230\n",
      "Diff stats — min: -4.6203, max: 10.0000, mean: 8.4856, std: 2.4276\n",
      "\n",
      "Step 13171 — Test metrics:\n",
      "  precision@10: 0.016053748\n",
      "  recall@10: 0.016114273\n",
      "  ndcg@10: 0.017267984\n",
      "  map@10: 0.006728497\n",
      "Epoch 441, Step 20, LR: 0.000379, Current Loss: 0.0268, Avg Loss: 0.0272\n",
      "Diff stats — min: -7.0225, max: 10.0000, mean: 8.4879, std: 2.4679\n",
      "\n",
      "Epoch 441 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 442, Step 1, LR: 0.000379, Current Loss: 0.0293, Avg Loss: 0.0293\n",
      "Diff stats — min: -6.2581, max: 10.0000, mean: 8.5284, std: 2.4556\n",
      "\n",
      "Step 13201 — Test metrics:\n",
      "  precision@10: 0.015770863\n",
      "  recall@10: 0.015826149\n",
      "  ndcg@10: 0.017007145\n",
      "  map@10: 0.006618521\n",
      "Epoch 442, Step 20, LR: 0.000379, Current Loss: 0.0234, Avg Loss: 0.0279\n",
      "Diff stats — min: -8.5409, max: 10.0000, mean: 8.4622, std: 2.4301\n",
      "\n",
      "Epoch 442 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 443, Step 1, LR: 0.000379, Current Loss: 0.0262, Avg Loss: 0.0262\n",
      "Diff stats — min: -6.3635, max: 10.0000, mean: 8.5173, std: 2.4071\n",
      "\n",
      "Step 13231 — Test metrics:\n",
      "  precision@10: 0.016100896\n",
      "  recall@10: 0.016161421\n",
      "  ndcg@10: 0.017418671\n",
      "  map@10: 0.006806879\n",
      "Epoch 443, Step 20, LR: 0.000379, Current Loss: 0.0264, Avg Loss: 0.0272\n",
      "Diff stats — min: -6.9360, max: 10.0000, mean: 8.5364, std: 2.4370\n",
      "\n",
      "Epoch 443 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 444, Step 1, LR: 0.000379, Current Loss: 0.0240, Avg Loss: 0.0240\n",
      "Diff stats — min: -5.3676, max: 10.0000, mean: 8.5410, std: 2.4001\n",
      "\n",
      "Step 13261 — Test metrics:\n",
      "  precision@10: 0.016100896\n",
      "  recall@10: 0.016158801\n",
      "  ndcg@10: 0.017421487\n",
      "  map@10: 0.006775624\n",
      "Epoch 444, Step 20, LR: 0.000379, Current Loss: 0.0319, Avg Loss: 0.0268\n",
      "Diff stats — min: -8.4057, max: 10.0000, mean: 8.4378, std: 2.5170\n",
      "\n",
      "Epoch 444 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 445, Step 1, LR: 0.000379, Current Loss: 0.0256, Avg Loss: 0.0256\n",
      "Diff stats — min: -5.4432, max: 10.0000, mean: 8.5049, std: 2.4091\n",
      "\n",
      "Step 13291 — Test metrics:\n",
      "  precision@10: 0.015652994\n",
      "  recall@10: 0.015716138\n",
      "  ndcg@10: 0.016942842\n",
      "  map@10: 0.006588442\n",
      "Epoch 445, Step 20, LR: 0.000379, Current Loss: 0.0300, Avg Loss: 0.0289\n",
      "Diff stats — min: -4.8071, max: 10.0000, mean: 8.4886, std: 2.4847\n",
      "\n",
      "Epoch 445 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 446, Step 1, LR: 0.000372, Current Loss: 0.0258, Avg Loss: 0.0258\n",
      "Diff stats — min: -5.5667, max: 10.0000, mean: 8.5501, std: 2.4006\n",
      "\n",
      "Step 13321 — Test metrics:\n",
      "  precision@10: 0.015723715\n",
      "  recall@10: 0.015784240\n",
      "  ndcg@10: 0.016960008\n",
      "  map@10: 0.006556482\n",
      "Epoch 446, Step 20, LR: 0.000372, Current Loss: 0.0209, Avg Loss: 0.0276\n",
      "Diff stats — min: -4.3737, max: 10.0000, mean: 8.5381, std: 2.3729\n",
      "\n",
      "Epoch 446 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 447, Step 1, LR: 0.000372, Current Loss: 0.0237, Avg Loss: 0.0237\n",
      "Diff stats — min: -6.7367, max: 10.0000, mean: 8.5463, std: 2.4071\n",
      "\n",
      "Step 13351 — Test metrics:\n",
      "  precision@10: 0.016053748\n",
      "  recall@10: 0.016119512\n",
      "  ndcg@10: 0.017354981\n",
      "  map@10: 0.006769745\n",
      "Epoch 447, Step 20, LR: 0.000372, Current Loss: 0.0284, Avg Loss: 0.0273\n",
      "Diff stats — min: -7.1472, max: 10.0000, mean: 8.5045, std: 2.4628\n",
      "\n",
      "Epoch 447 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 448, Step 1, LR: 0.000372, Current Loss: 0.0257, Avg Loss: 0.0257\n",
      "Diff stats — min: -6.0812, max: 10.0000, mean: 8.5055, std: 2.4361\n",
      "\n",
      "Step 13381 — Test metrics:\n",
      "  precision@10: 0.016478076\n",
      "  recall@10: 0.016543840\n",
      "  ndcg@10: 0.017617478\n",
      "  map@10: 0.006834587\n",
      "Epoch 448, Step 20, LR: 0.000372, Current Loss: 0.0262, Avg Loss: 0.0277\n",
      "Diff stats — min: -4.1566, max: 10.0000, mean: 8.5303, std: 2.4213\n",
      "\n",
      "Epoch 448 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 449, Step 1, LR: 0.000372, Current Loss: 0.0304, Avg Loss: 0.0304\n",
      "Diff stats — min: -6.7759, max: 10.0000, mean: 8.4912, std: 2.4689\n",
      "\n",
      "Step 13411 — Test metrics:\n",
      "  precision@10: 0.016407355\n",
      "  recall@10: 0.016475738\n",
      "  ndcg@10: 0.017811793\n",
      "  map@10: 0.007011807\n",
      "Epoch 449, Step 20, LR: 0.000372, Current Loss: 0.0272, Avg Loss: 0.0285\n",
      "Diff stats — min: -4.0828, max: 10.0000, mean: 8.5076, std: 2.4794\n",
      "\n",
      "Epoch 449 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 450, Step 1, LR: 0.000372, Current Loss: 0.0332, Avg Loss: 0.0332\n",
      "Diff stats — min: -6.8115, max: 10.0000, mean: 8.5659, std: 2.4246\n",
      "\n",
      "Step 13441 — Test metrics:\n",
      "  precision@10: 0.016053748\n",
      "  recall@10: 0.016128024\n",
      "  ndcg@10: 0.017575551\n",
      "  map@10: 0.006901021\n",
      "Epoch 450, Step 20, LR: 0.000372, Current Loss: 0.0316, Avg Loss: 0.0287\n",
      "Diff stats — min: -6.7012, max: 10.0000, mean: 8.5423, std: 2.4690\n",
      "\n",
      "Epoch 450 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 451, Step 1, LR: 0.000364, Current Loss: 0.0257, Avg Loss: 0.0257\n",
      "Diff stats — min: -5.4426, max: 10.0000, mean: 8.5413, std: 2.4359\n",
      "\n",
      "Step 13471 — Test metrics:\n",
      "  precision@10: 0.016454503\n",
      "  recall@10: 0.016525130\n",
      "  ndcg@10: 0.017672080\n",
      "  map@10: 0.006840184\n",
      "Epoch 451, Step 20, LR: 0.000364, Current Loss: 0.0269, Avg Loss: 0.0271\n",
      "Diff stats — min: -5.0208, max: 10.0000, mean: 8.5313, std: 2.4645\n",
      "\n",
      "Epoch 451 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 452, Step 1, LR: 0.000364, Current Loss: 0.0264, Avg Loss: 0.0264\n",
      "Diff stats — min: -6.0593, max: 10.0000, mean: 8.4741, std: 2.4743\n",
      "\n",
      "Step 13501 — Test metrics:\n",
      "  precision@10: 0.016619519\n",
      "  recall@10: 0.016703898\n",
      "  ndcg@10: 0.017731692\n",
      "  map@10: 0.006899547\n",
      "Epoch 452, Step 20, LR: 0.000364, Current Loss: 0.0269, Avg Loss: 0.0271\n",
      "Diff stats — min: -6.0274, max: 10.0000, mean: 8.5052, std: 2.4497\n",
      "\n",
      "Epoch 452 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 453, Step 1, LR: 0.000364, Current Loss: 0.0237, Avg Loss: 0.0237\n",
      "Diff stats — min: -3.9741, max: 10.0000, mean: 8.5333, std: 2.4246\n",
      "\n",
      "Step 13531 — Test metrics:\n",
      "  precision@10: 0.016430929\n",
      "  recall@10: 0.016512034\n",
      "  ndcg@10: 0.017614270\n",
      "  map@10: 0.006815378\n",
      "Epoch 453, Step 20, LR: 0.000364, Current Loss: 0.0258, Avg Loss: 0.0282\n",
      "Diff stats — min: -5.7618, max: 10.0000, mean: 8.5417, std: 2.4014\n",
      "\n",
      "Epoch 453 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 454, Step 1, LR: 0.000364, Current Loss: 0.0278, Avg Loss: 0.0278\n",
      "Diff stats — min: -7.0515, max: 10.0000, mean: 8.5088, std: 2.4524\n",
      "\n",
      "Step 13561 — Test metrics:\n",
      "  precision@10: 0.016289486\n",
      "  recall@10: 0.016373210\n",
      "  ndcg@10: 0.017682685\n",
      "  map@10: 0.006916290\n",
      "Epoch 454, Step 20, LR: 0.000364, Current Loss: 0.0250, Avg Loss: 0.0289\n",
      "Diff stats — min: -5.8889, max: 10.0000, mean: 8.4977, std: 2.4341\n",
      "\n",
      "Epoch 454 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 455, Step 1, LR: 0.000364, Current Loss: 0.0281, Avg Loss: 0.0281\n",
      "Diff stats — min: -7.1779, max: 10.0000, mean: 8.5044, std: 2.4354\n",
      "\n",
      "Step 13591 — Test metrics:\n",
      "  precision@10: 0.016313060\n",
      "  recall@10: 0.016399404\n",
      "  ndcg@10: 0.017627536\n",
      "  map@10: 0.006923610\n",
      "Epoch 455, Step 20, LR: 0.000364, Current Loss: 0.0326, Avg Loss: 0.0272\n",
      "Diff stats — min: -7.3441, max: 10.0000, mean: 8.5343, std: 2.4728\n",
      "\n",
      "Epoch 455 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 456, Step 1, LR: 0.000357, Current Loss: 0.0360, Avg Loss: 0.0360\n",
      "Diff stats — min: -5.4220, max: 10.0000, mean: 8.5469, std: 2.4646\n",
      "\n",
      "Step 13621 — Test metrics:\n",
      "  precision@10: 0.016501650\n",
      "  recall@10: 0.016580136\n",
      "  ndcg@10: 0.017681822\n",
      "  map@10: 0.006908143\n",
      "Epoch 456, Step 20, LR: 0.000357, Current Loss: 0.0246, Avg Loss: 0.0283\n",
      "Diff stats — min: -5.7166, max: 10.0000, mean: 8.4944, std: 2.4172\n",
      "\n",
      "Epoch 456 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 457, Step 1, LR: 0.000357, Current Loss: 0.0268, Avg Loss: 0.0268\n",
      "Diff stats — min: -6.9814, max: 10.0000, mean: 8.5297, std: 2.4445\n",
      "\n",
      "Step 13651 — Test metrics:\n",
      "  precision@10: 0.016053748\n",
      "  recall@10: 0.016132234\n",
      "  ndcg@10: 0.017440833\n",
      "  map@10: 0.006871944\n",
      "Epoch 457, Step 20, LR: 0.000357, Current Loss: 0.0318, Avg Loss: 0.0294\n",
      "Diff stats — min: -8.2526, max: 10.0000, mean: 8.5501, std: 2.4646\n",
      "\n",
      "Epoch 457 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 458, Step 1, LR: 0.000357, Current Loss: 0.0293, Avg Loss: 0.0293\n",
      "Diff stats — min: -4.4128, max: 10.0000, mean: 8.4931, std: 2.5097\n",
      "\n",
      "Step 13681 — Test metrics:\n",
      "  precision@10: 0.016077322\n",
      "  recall@10: 0.016155808\n",
      "  ndcg@10: 0.017288094\n",
      "  map@10: 0.006698097\n",
      "Epoch 458, Step 20, LR: 0.000357, Current Loss: 0.0246, Avg Loss: 0.0277\n",
      "Diff stats — min: -5.7072, max: 10.0000, mean: 8.5579, std: 2.3957\n",
      "\n",
      "Epoch 458 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 459, Step 1, LR: 0.000357, Current Loss: 0.0296, Avg Loss: 0.0296\n",
      "Diff stats — min: -6.9731, max: 10.0000, mean: 8.6111, std: 2.3828\n",
      "\n",
      "Step 13711 — Test metrics:\n",
      "  precision@10: 0.016430929\n",
      "  recall@10: 0.016506795\n",
      "  ndcg@10: 0.017722915\n",
      "  map@10: 0.006896844\n",
      "Epoch 459, Step 20, LR: 0.000357, Current Loss: 0.0268, Avg Loss: 0.0268\n",
      "Diff stats — min: -8.2042, max: 10.0000, mean: 8.5672, std: 2.3986\n",
      "\n",
      "Epoch 459 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 460, Step 1, LR: 0.000357, Current Loss: 0.0257, Avg Loss: 0.0257\n",
      "Diff stats — min: -4.3159, max: 10.0000, mean: 8.5237, std: 2.4067\n",
      "\n",
      "Step 13741 — Test metrics:\n",
      "  precision@10: 0.016572372\n",
      "  recall@10: 0.016653477\n",
      "  ndcg@10: 0.017728599\n",
      "  map@10: 0.006833454\n",
      "Epoch 460, Step 20, LR: 0.000357, Current Loss: 0.0275, Avg Loss: 0.0275\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 8.5077, std: 2.4580\n",
      "\n",
      "Epoch 460 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 461, Step 1, LR: 0.000350, Current Loss: 0.0290, Avg Loss: 0.0290\n",
      "Diff stats — min: -9.0455, max: 10.0000, mean: 8.5087, std: 2.4632\n",
      "\n",
      "Step 13771 — Test metrics:\n",
      "  precision@10: 0.016643093\n",
      "  recall@10: 0.016718959\n",
      "  ndcg@10: 0.017744989\n",
      "  map@10: 0.006871790\n",
      "Epoch 461, Step 20, LR: 0.000350, Current Loss: 0.0286, Avg Loss: 0.0268\n",
      "Diff stats — min: -6.2506, max: 10.0000, mean: 8.5171, std: 2.4722\n",
      "\n",
      "Epoch 461 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 462, Step 1, LR: 0.000350, Current Loss: 0.0217, Avg Loss: 0.0217\n",
      "Diff stats — min: -4.6683, max: 10.0000, mean: 8.5541, std: 2.3858\n",
      "\n",
      "Step 13801 — Test metrics:\n",
      "  precision@10: 0.016407355\n",
      "  recall@10: 0.016491734\n",
      "  ndcg@10: 0.017836346\n",
      "  map@10: 0.006973291\n",
      "Epoch 462, Step 20, LR: 0.000350, Current Loss: 0.0315, Avg Loss: 0.0279\n",
      "Diff stats — min: -8.4706, max: 10.0000, mean: 8.5651, std: 2.4340\n",
      "\n",
      "Epoch 462 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 463, Step 1, LR: 0.000350, Current Loss: 0.0370, Avg Loss: 0.0370\n",
      "Diff stats — min: -7.8450, max: 10.0000, mean: 8.4511, std: 2.5308\n",
      "\n",
      "Step 13831 — Test metrics:\n",
      "  precision@10: 0.016572372\n",
      "  recall@10: 0.016656751\n",
      "  ndcg@10: 0.017822441\n",
      "  map@10: 0.006947061\n",
      "Epoch 463, Step 20, LR: 0.000350, Current Loss: 0.0253, Avg Loss: 0.0280\n",
      "Diff stats — min: -5.1697, max: 10.0000, mean: 8.5292, std: 2.3967\n",
      "\n",
      "Epoch 463 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 464, Step 1, LR: 0.000350, Current Loss: 0.0200, Avg Loss: 0.0200\n",
      "Diff stats — min: -5.5788, max: 10.0000, mean: 8.5876, std: 2.3268\n",
      "\n",
      "Step 13861 — Test metrics:\n",
      "  precision@10: 0.016690240\n",
      "  recall@10: 0.016779858\n",
      "  ndcg@10: 0.017933014\n",
      "  map@10: 0.007002271\n",
      "Epoch 464, Step 20, LR: 0.000350, Current Loss: 0.0315, Avg Loss: 0.0268\n",
      "Diff stats — min: -6.4596, max: 10.0000, mean: 8.5461, std: 2.4631\n",
      "\n",
      "Epoch 464 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 465, Step 1, LR: 0.000350, Current Loss: 0.0225, Avg Loss: 0.0225\n",
      "Diff stats — min: -3.7630, max: 10.0000, mean: 8.5671, std: 2.3737\n",
      "\n",
      "Step 13891 — Test metrics:\n",
      "  precision@10: 0.016195191\n",
      "  recall@10: 0.016282189\n",
      "  ndcg@10: 0.017634457\n",
      "  map@10: 0.006934333\n",
      "Epoch 465, Step 20, LR: 0.000350, Current Loss: 0.0282, Avg Loss: 0.0274\n",
      "Diff stats — min: -4.2157, max: 10.0000, mean: 8.5282, std: 2.4728\n",
      "\n",
      "Epoch 465 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 466, Step 1, LR: 0.000343, Current Loss: 0.0266, Avg Loss: 0.0266\n",
      "Diff stats — min: -4.7801, max: 10.0000, mean: 8.5402, std: 2.4382\n",
      "\n",
      "Step 13921 — Test metrics:\n",
      "  precision@10: 0.016572372\n",
      "  recall@10: 0.016654131\n",
      "  ndcg@10: 0.018013020\n",
      "  map@10: 0.007074846\n",
      "Epoch 466, Step 20, LR: 0.000343, Current Loss: 0.0283, Avg Loss: 0.0267\n",
      "Diff stats — min: -5.7553, max: 10.0000, mean: 8.4954, std: 2.4777\n",
      "\n",
      "Epoch 466 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 467, Step 1, LR: 0.000343, Current Loss: 0.0314, Avg Loss: 0.0314\n",
      "Diff stats — min: -7.3248, max: 10.0000, mean: 8.5739, std: 2.4265\n",
      "\n",
      "Step 13951 — Test metrics:\n",
      "  precision@10: 0.016666667\n",
      "  recall@10: 0.016753665\n",
      "  ndcg@10: 0.017943537\n",
      "  map@10: 0.007004013\n",
      "Epoch 467, Step 20, LR: 0.000343, Current Loss: 0.0261, Avg Loss: 0.0282\n",
      "Diff stats — min: -5.5269, max: 10.0000, mean: 8.5057, std: 2.4384\n",
      "\n",
      "Epoch 467 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 468, Step 1, LR: 0.000343, Current Loss: 0.0278, Avg Loss: 0.0278\n",
      "Diff stats — min: -5.0560, max: 10.0000, mean: 8.5218, std: 2.4500\n",
      "\n",
      "Step 13981 — Test metrics:\n",
      "  precision@10: 0.016737388\n",
      "  recall@10: 0.016821767\n",
      "  ndcg@10: 0.018080368\n",
      "  map@10: 0.007042987\n",
      "Epoch 468, Step 20, LR: 0.000343, Current Loss: 0.0350, Avg Loss: 0.0275\n",
      "Diff stats — min: -6.0439, max: 10.0000, mean: 8.4951, std: 2.5098\n",
      "\n",
      "Epoch 468 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 469, Step 1, LR: 0.000343, Current Loss: 0.0265, Avg Loss: 0.0265\n",
      "Diff stats — min: -5.3316, max: 10.0000, mean: 8.4764, std: 2.4518\n",
      "\n",
      "Step 14011 — Test metrics:\n",
      "  precision@10: 0.016454503\n",
      "  recall@10: 0.016538882\n",
      "  ndcg@10: 0.017893701\n",
      "  map@10: 0.007000360\n",
      "Epoch 469, Step 20, LR: 0.000343, Current Loss: 0.0221, Avg Loss: 0.0261\n",
      "Diff stats — min: -4.1747, max: 10.0000, mean: 8.5850, std: 2.3692\n",
      "\n",
      "Epoch 469 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 470, Step 1, LR: 0.000343, Current Loss: 0.0286, Avg Loss: 0.0286\n",
      "Diff stats — min: -5.8579, max: 10.0000, mean: 8.5589, std: 2.4015\n",
      "\n",
      "Step 14041 — Test metrics:\n",
      "  precision@10: 0.016572372\n",
      "  recall@10: 0.016656751\n",
      "  ndcg@10: 0.017966488\n",
      "  map@10: 0.007008744\n",
      "Epoch 470, Step 20, LR: 0.000343, Current Loss: 0.0226, Avg Loss: 0.0279\n",
      "Diff stats — min: -4.3475, max: 10.0000, mean: 8.5579, std: 2.4046\n",
      "\n",
      "Epoch 470 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 471, Step 1, LR: 0.000336, Current Loss: 0.0225, Avg Loss: 0.0225\n",
      "Diff stats — min: -4.2272, max: 10.0000, mean: 8.5471, std: 2.3981\n",
      "\n",
      "Step 14071 — Test metrics:\n",
      "  precision@10: 0.016619519\n",
      "  recall@10: 0.016706518\n",
      "  ndcg@10: 0.018114536\n",
      "  map@10: 0.007074470\n",
      "Epoch 471, Step 20, LR: 0.000336, Current Loss: 0.0230, Avg Loss: 0.0262\n",
      "Diff stats — min: -5.6650, max: 10.0000, mean: 8.5388, std: 2.4029\n",
      "\n",
      "Epoch 471 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 472, Step 1, LR: 0.000336, Current Loss: 0.0288, Avg Loss: 0.0288\n",
      "Diff stats — min: -4.5376, max: 10.0000, mean: 8.5329, std: 2.4427\n",
      "\n",
      "Step 14101 — Test metrics:\n",
      "  precision@10: 0.016666667\n",
      "  recall@10: 0.016751046\n",
      "  ndcg@10: 0.018001733\n",
      "  map@10: 0.007021482\n",
      "Epoch 472, Step 20, LR: 0.000336, Current Loss: 0.0254, Avg Loss: 0.0279\n",
      "Diff stats — min: -8.8465, max: 10.0000, mean: 8.5562, std: 2.4236\n",
      "\n",
      "Epoch 472 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 473, Step 1, LR: 0.000336, Current Loss: 0.0207, Avg Loss: 0.0207\n",
      "Diff stats — min: -6.2390, max: 10.0000, mean: 8.6070, std: 2.3588\n",
      "\n",
      "Step 14131 — Test metrics:\n",
      "  precision@10: 0.016737388\n",
      "  recall@10: 0.016824387\n",
      "  ndcg@10: 0.018244487\n",
      "  map@10: 0.007134597\n",
      "Epoch 473, Step 20, LR: 0.000336, Current Loss: 0.0237, Avg Loss: 0.0251\n",
      "Diff stats — min: -4.1650, max: 10.0000, mean: 8.5727, std: 2.4001\n",
      "\n",
      "Epoch 473 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 474, Step 1, LR: 0.000336, Current Loss: 0.0231, Avg Loss: 0.0231\n",
      "Diff stats — min: -5.4702, max: 10.0000, mean: 8.6037, std: 2.3396\n",
      "\n",
      "Step 14161 — Test metrics:\n",
      "  precision@10: 0.016713814\n",
      "  recall@10: 0.016800813\n",
      "  ndcg@10: 0.018022146\n",
      "  map@10: 0.006965743\n",
      "Epoch 474, Step 20, LR: 0.000336, Current Loss: 0.0284, Avg Loss: 0.0265\n",
      "Diff stats — min: -5.4396, max: 10.0000, mean: 8.5464, std: 2.4347\n",
      "\n",
      "Epoch 474 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 475, Step 1, LR: 0.000336, Current Loss: 0.0292, Avg Loss: 0.0292\n",
      "Diff stats — min: -4.3964, max: 10.0000, mean: 8.5237, std: 2.4872\n",
      "\n",
      "Step 14191 — Test metrics:\n",
      "  precision@10: 0.016313060\n",
      "  recall@10: 0.016397439\n",
      "  ndcg@10: 0.017769245\n",
      "  map@10: 0.006979524\n",
      "Epoch 475, Step 20, LR: 0.000336, Current Loss: 0.0291, Avg Loss: 0.0277\n",
      "Diff stats — min: -6.6120, max: 10.0000, mean: 8.5096, std: 2.4475\n",
      "\n",
      "Epoch 475 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 476, Step 1, LR: 0.000329, Current Loss: 0.0280, Avg Loss: 0.0280\n",
      "Diff stats — min: -7.9748, max: 10.0000, mean: 8.5047, std: 2.4783\n",
      "\n",
      "Step 14221 — Test metrics:\n",
      "  precision@10: 0.016430929\n",
      "  recall@10: 0.016509415\n",
      "  ndcg@10: 0.017772234\n",
      "  map@10: 0.006901180\n",
      "Epoch 476, Step 20, LR: 0.000329, Current Loss: 0.0264, Avg Loss: 0.0277\n",
      "Diff stats — min: -7.5799, max: 10.0000, mean: 8.5871, std: 2.3934\n",
      "\n",
      "Epoch 476 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 477, Step 1, LR: 0.000329, Current Loss: 0.0257, Avg Loss: 0.0257\n",
      "Diff stats — min: -3.5839, max: 10.0000, mean: 8.5392, std: 2.4325\n",
      "\n",
      "Step 14251 — Test metrics:\n",
      "  precision@10: 0.016525224\n",
      "  recall@10: 0.016610258\n",
      "  ndcg@10: 0.017782962\n",
      "  map@10: 0.006884189\n",
      "Epoch 477, Step 20, LR: 0.000329, Current Loss: 0.0270, Avg Loss: 0.0268\n",
      "Diff stats — min: -5.6304, max: 10.0000, mean: 8.5237, std: 2.4207\n",
      "\n",
      "Epoch 477 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 478, Step 1, LR: 0.000329, Current Loss: 0.0248, Avg Loss: 0.0248\n",
      "Diff stats — min: -8.0364, max: 10.0000, mean: 8.5315, std: 2.4080\n",
      "\n",
      "Step 14281 — Test metrics:\n",
      "  precision@10: 0.016713814\n",
      "  recall@10: 0.016798193\n",
      "  ndcg@10: 0.018087516\n",
      "  map@10: 0.007100145\n",
      "Epoch 478, Step 20, LR: 0.000329, Current Loss: 0.0242, Avg Loss: 0.0255\n",
      "Diff stats — min: -5.2579, max: 10.0000, mean: 8.6000, std: 2.3767\n",
      "\n",
      "Epoch 478 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 479, Step 1, LR: 0.000329, Current Loss: 0.0250, Avg Loss: 0.0250\n",
      "Diff stats — min: -7.6123, max: 10.0000, mean: 8.5667, std: 2.4099\n",
      "\n",
      "Step 14311 — Test metrics:\n",
      "  precision@10: 0.016713814\n",
      "  recall@10: 0.016787716\n",
      "  ndcg@10: 0.017982609\n",
      "  map@10: 0.007023822\n",
      "Epoch 479, Step 20, LR: 0.000329, Current Loss: 0.0262, Avg Loss: 0.0266\n",
      "Diff stats — min: -9.6680, max: 10.0000, mean: 8.5602, std: 2.4042\n",
      "\n",
      "Epoch 479 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 480, Step 1, LR: 0.000329, Current Loss: 0.0261, Avg Loss: 0.0261\n",
      "Diff stats — min: -8.6270, max: 10.0000, mean: 8.6063, std: 2.3837\n",
      "\n",
      "Step 14341 — Test metrics:\n",
      "  precision@10: 0.016831683\n",
      "  recall@10: 0.016904930\n",
      "  ndcg@10: 0.017979310\n",
      "  map@10: 0.006924952\n",
      "Epoch 480, Step 20, LR: 0.000329, Current Loss: 0.0255, Avg Loss: 0.0273\n",
      "Diff stats — min: -8.2933, max: 10.0000, mean: 8.6301, std: 2.3553\n",
      "\n",
      "Epoch 480 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 481, Step 1, LR: 0.000323, Current Loss: 0.0252, Avg Loss: 0.0252\n",
      "Diff stats — min: -6.1765, max: 10.0000, mean: 8.6396, std: 2.3609\n",
      "\n",
      "Step 14371 — Test metrics:\n",
      "  precision@10: 0.016501650\n",
      "  recall@10: 0.016584065\n",
      "  ndcg@10: 0.017869950\n",
      "  map@10: 0.006962606\n",
      "Epoch 481, Step 20, LR: 0.000323, Current Loss: 0.0238, Avg Loss: 0.0262\n",
      "Diff stats — min: -5.0055, max: 10.0000, mean: 8.5349, std: 2.4106\n",
      "\n",
      "Epoch 481 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 482, Step 1, LR: 0.000323, Current Loss: 0.0267, Avg Loss: 0.0267\n",
      "Diff stats — min: -6.2798, max: 10.0000, mean: 8.6205, std: 2.3688\n",
      "\n",
      "Step 14401 — Test metrics:\n",
      "  precision@10: 0.017067421\n",
      "  recall@10: 0.017149836\n",
      "  ndcg@10: 0.018296245\n",
      "  map@10: 0.007102032\n",
      "Epoch 482, Step 20, LR: 0.000323, Current Loss: 0.0278, Avg Loss: 0.0264\n",
      "Diff stats — min: -6.5327, max: 10.0000, mean: 8.4507, std: 2.4881\n",
      "\n",
      "Epoch 482 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 483, Step 1, LR: 0.000323, Current Loss: 0.0210, Avg Loss: 0.0210\n",
      "Diff stats — min: -5.8847, max: 10.0000, mean: 8.6603, std: 2.3108\n",
      "\n",
      "Step 14431 — Test metrics:\n",
      "  precision@10: 0.016713814\n",
      "  recall@10: 0.016804087\n",
      "  ndcg@10: 0.017914507\n",
      "  map@10: 0.006942111\n",
      "Epoch 483, Step 20, LR: 0.000323, Current Loss: 0.0271, Avg Loss: 0.0254\n",
      "Diff stats — min: -8.1076, max: 10.0000, mean: 8.5737, std: 2.4099\n",
      "\n",
      "Epoch 483 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 484, Step 1, LR: 0.000323, Current Loss: 0.0272, Avg Loss: 0.0272\n",
      "Diff stats — min: -6.6566, max: 10.0000, mean: 8.6022, std: 2.4022\n",
      "\n",
      "Step 14461 — Test metrics:\n",
      "  precision@10: 0.016949552\n",
      "  recall@10: 0.017039825\n",
      "  ndcg@10: 0.018190705\n",
      "  map@10: 0.007069030\n",
      "Epoch 484, Step 20, LR: 0.000323, Current Loss: 0.0295, Avg Loss: 0.0266\n",
      "Diff stats — min: -6.7447, max: 10.0000, mean: 8.5518, std: 2.4328\n",
      "\n",
      "Epoch 484 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 485, Step 1, LR: 0.000323, Current Loss: 0.0268, Avg Loss: 0.0268\n",
      "Diff stats — min: -3.4117, max: 10.0000, mean: 8.6109, std: 2.3869\n",
      "\n",
      "Step 14491 — Test metrics:\n",
      "  precision@10: 0.016595945\n",
      "  recall@10: 0.016691082\n",
      "  ndcg@10: 0.017947256\n",
      "  map@10: 0.006967664\n",
      "Epoch 485, Step 20, LR: 0.000323, Current Loss: 0.0240, Avg Loss: 0.0263\n",
      "Diff stats — min: -5.3232, max: 10.0000, mean: 8.6463, std: 2.3511\n",
      "\n",
      "Epoch 485 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 486, Step 1, LR: 0.000316, Current Loss: 0.0298, Avg Loss: 0.0298\n",
      "Diff stats — min: -7.5527, max: 10.0000, mean: 8.5193, std: 2.4534\n",
      "\n",
      "Step 14521 — Test metrics:\n",
      "  precision@10: 0.016595945\n",
      "  recall@10: 0.016680979\n",
      "  ndcg@10: 0.017959315\n",
      "  map@10: 0.007009881\n",
      "Epoch 486, Step 20, LR: 0.000316, Current Loss: 0.0267, Avg Loss: 0.0258\n",
      "Diff stats — min: -6.2134, max: 10.0000, mean: 8.5385, std: 2.4252\n",
      "\n",
      "Epoch 486 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 487, Step 1, LR: 0.000316, Current Loss: 0.0262, Avg Loss: 0.0262\n",
      "Diff stats — min: -3.8211, max: 10.0000, mean: 8.5429, std: 2.4538\n",
      "\n",
      "Step 14551 — Test metrics:\n",
      "  precision@10: 0.016619519\n",
      "  recall@10: 0.016707827\n",
      "  ndcg@10: 0.017912167\n",
      "  map@10: 0.006943334\n",
      "Epoch 487, Step 20, LR: 0.000316, Current Loss: 0.0285, Avg Loss: 0.0271\n",
      "Diff stats — min: -6.6871, max: 10.0000, mean: 8.5504, std: 2.4123\n",
      "\n",
      "Epoch 487 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 488, Step 1, LR: 0.000316, Current Loss: 0.0214, Avg Loss: 0.0214\n",
      "Diff stats — min: -5.6258, max: 10.0000, mean: 8.5964, std: 2.3621\n",
      "\n",
      "Step 14581 — Test metrics:\n",
      "  precision@10: 0.016784536\n",
      "  recall@10: 0.016874808\n",
      "  ndcg@10: 0.018093720\n",
      "  map@10: 0.006990279\n",
      "Epoch 488, Step 20, LR: 0.000316, Current Loss: 0.0328, Avg Loss: 0.0262\n",
      "Diff stats — min: -8.5890, max: 10.0000, mean: 8.5420, std: 2.4712\n",
      "\n",
      "Epoch 488 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 489, Step 1, LR: 0.000316, Current Loss: 0.0253, Avg Loss: 0.0253\n",
      "Diff stats — min: -4.1102, max: 10.0000, mean: 8.5674, std: 2.3966\n",
      "\n",
      "Step 14611 — Test metrics:\n",
      "  precision@10: 0.016572372\n",
      "  recall@10: 0.016667509\n",
      "  ndcg@10: 0.017982281\n",
      "  map@10: 0.007004528\n",
      "Epoch 489, Step 20, LR: 0.000316, Current Loss: 0.0256, Avg Loss: 0.0270\n",
      "Diff stats — min: -4.6861, max: 10.0000, mean: 8.5792, std: 2.4134\n",
      "\n",
      "Epoch 489 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 490, Step 1, LR: 0.000316, Current Loss: 0.0194, Avg Loss: 0.0194\n",
      "Diff stats — min: -3.8540, max: 10.0000, mean: 8.5964, std: 2.3521\n",
      "\n",
      "Step 14641 — Test metrics:\n",
      "  precision@10: 0.016619519\n",
      "  recall@10: 0.016717275\n",
      "  ndcg@10: 0.017998572\n",
      "  map@10: 0.007010681\n",
      "Epoch 490, Step 20, LR: 0.000316, Current Loss: 0.0284, Avg Loss: 0.0257\n",
      "Diff stats — min: -6.8417, max: 10.0000, mean: 8.5108, std: 2.4595\n",
      "\n",
      "Epoch 490 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 491, Step 1, LR: 0.000310, Current Loss: 0.0293, Avg Loss: 0.0293\n",
      "Diff stats — min: -6.1917, max: 10.0000, mean: 8.5580, std: 2.4414\n",
      "\n",
      "Step 14671 — Test metrics:\n",
      "  precision@10: 0.016289486\n",
      "  recall@10: 0.016377139\n",
      "  ndcg@10: 0.017637220\n",
      "  map@10: 0.006867293\n",
      "Epoch 491, Step 20, LR: 0.000310, Current Loss: 0.0263, Avg Loss: 0.0262\n",
      "Diff stats — min: -5.2965, max: 10.0000, mean: 8.5751, std: 2.4090\n",
      "\n",
      "Epoch 491 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 492, Step 1, LR: 0.000310, Current Loss: 0.0240, Avg Loss: 0.0240\n",
      "Diff stats — min: -4.9413, max: 10.0000, mean: 8.6302, std: 2.3432\n",
      "\n",
      "Step 14701 — Test metrics:\n",
      "  precision@10: 0.016548798\n",
      "  recall@10: 0.016636451\n",
      "  ndcg@10: 0.017877900\n",
      "  map@10: 0.006950841\n",
      "Epoch 492, Step 20, LR: 0.000310, Current Loss: 0.0225, Avg Loss: 0.0257\n",
      "Diff stats — min: -7.2756, max: 10.0000, mean: 8.7004, std: 2.2837\n",
      "\n",
      "Epoch 492 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 493, Step 1, LR: 0.000310, Current Loss: 0.0261, Avg Loss: 0.0261\n",
      "Diff stats — min: -7.0082, max: 10.0000, mean: 8.5196, std: 2.4227\n",
      "\n",
      "Step 14731 — Test metrics:\n",
      "  precision@10: 0.016902405\n",
      "  recall@10: 0.017001190\n",
      "  ndcg@10: 0.018134475\n",
      "  map@10: 0.007111841\n",
      "Epoch 493, Step 20, LR: 0.000310, Current Loss: 0.0287, Avg Loss: 0.0271\n",
      "Diff stats — min: -6.4101, max: 10.0000, mean: 8.5130, std: 2.4618\n",
      "\n",
      "Epoch 493 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 494, Step 1, LR: 0.000310, Current Loss: 0.0283, Avg Loss: 0.0283\n",
      "Diff stats — min: -5.0136, max: 10.0000, mean: 8.6243, std: 2.3794\n",
      "\n",
      "Step 14761 — Test metrics:\n",
      "  precision@10: 0.016619519\n",
      "  recall@10: 0.016713066\n",
      "  ndcg@10: 0.017889882\n",
      "  map@10: 0.006965796\n",
      "Epoch 494, Step 20, LR: 0.000310, Current Loss: 0.0260, Avg Loss: 0.0269\n",
      "Diff stats — min: -4.8116, max: 10.0000, mean: 8.6061, std: 2.3793\n",
      "\n",
      "Epoch 494 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 495, Step 1, LR: 0.000310, Current Loss: 0.0338, Avg Loss: 0.0338\n",
      "Diff stats — min: -5.9134, max: 10.0000, mean: 8.5354, std: 2.4768\n",
      "\n",
      "Step 14791 — Test metrics:\n",
      "  precision@10: 0.016760962\n",
      "  recall@10: 0.016845341\n",
      "  ndcg@10: 0.017984839\n",
      "  map@10: 0.006955267\n",
      "Epoch 495, Step 20, LR: 0.000310, Current Loss: 0.0230, Avg Loss: 0.0261\n",
      "Diff stats — min: -4.2356, max: 10.0000, mean: 8.5640, std: 2.3826\n",
      "\n",
      "Epoch 495 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 496, Step 1, LR: 0.000304, Current Loss: 0.0253, Avg Loss: 0.0253\n",
      "Diff stats — min: -7.7182, max: 10.0000, mean: 8.5649, std: 2.3992\n",
      "\n",
      "Step 14821 — Test metrics:\n",
      "  precision@10: 0.016572372\n",
      "  recall@10: 0.016654131\n",
      "  ndcg@10: 0.017851051\n",
      "  map@10: 0.006904903\n",
      "Epoch 496, Step 20, LR: 0.000304, Current Loss: 0.0230, Avg Loss: 0.0243\n",
      "Diff stats — min: -4.4213, max: 10.0000, mean: 8.5818, std: 2.3484\n",
      "\n",
      "Epoch 496 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 497, Step 1, LR: 0.000304, Current Loss: 0.0308, Avg Loss: 0.0308\n",
      "Diff stats — min: -7.3245, max: 10.0000, mean: 8.5429, std: 2.4810\n",
      "\n",
      "Step 14851 — Test metrics:\n",
      "  precision@10: 0.016501650\n",
      "  recall@10: 0.016586684\n",
      "  ndcg@10: 0.017712246\n",
      "  map@10: 0.006823310\n",
      "Epoch 497, Step 20, LR: 0.000304, Current Loss: 0.0329, Avg Loss: 0.0256\n",
      "Diff stats — min: -7.7091, max: 10.0000, mean: 8.6095, std: 2.4517\n",
      "\n",
      "Epoch 497 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 498, Step 1, LR: 0.000304, Current Loss: 0.0240, Avg Loss: 0.0240\n",
      "Diff stats — min: -6.7422, max: 10.0000, mean: 8.5725, std: 2.3817\n",
      "\n",
      "Step 14881 — Test metrics:\n",
      "  precision@10: 0.016619519\n",
      "  recall@10: 0.016707172\n",
      "  ndcg@10: 0.017882039\n",
      "  map@10: 0.006948251\n",
      "Epoch 498, Step 20, LR: 0.000304, Current Loss: 0.0294, Avg Loss: 0.0267\n",
      "Diff stats — min: -6.2572, max: 10.0000, mean: 8.5438, std: 2.4186\n",
      "\n",
      "Epoch 498 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 499, Step 1, LR: 0.000304, Current Loss: 0.0187, Avg Loss: 0.0187\n",
      "Diff stats — min: -3.8719, max: 10.0000, mean: 8.5964, std: 2.3146\n",
      "\n",
      "Step 14911 — Test metrics:\n",
      "  precision@10: 0.017090995\n",
      "  recall@10: 0.017178648\n",
      "  ndcg@10: 0.018130407\n",
      "  map@10: 0.007020722\n",
      "Epoch 499, Step 20, LR: 0.000304, Current Loss: 0.0211, Avg Loss: 0.0256\n",
      "Diff stats — min: -4.3259, max: 10.0000, mean: 8.6375, std: 2.3288\n",
      "\n",
      "Epoch 499 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 500, Step 1, LR: 0.000304, Current Loss: 0.0232, Avg Loss: 0.0232\n",
      "Diff stats — min: -7.0977, max: 10.0000, mean: 8.5831, std: 2.3611\n",
      "\n",
      "Step 14941 — Test metrics:\n",
      "  precision@10: 0.016501650\n",
      "  recall@10: 0.016578171\n",
      "  ndcg@10: 0.017722631\n",
      "  map@10: 0.006871149\n",
      "Epoch 500, Step 20, LR: 0.000304, Current Loss: 0.0294, Avg Loss: 0.0270\n",
      "Diff stats — min: -5.6428, max: 10.0000, mean: 8.5707, std: 2.4261\n",
      "\n",
      "Epoch 500 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 501, Step 1, LR: 0.000298, Current Loss: 0.0215, Avg Loss: 0.0215\n",
      "Diff stats — min: -5.8335, max: 10.0000, mean: 8.6193, std: 2.3344\n",
      "\n",
      "Step 14971 — Test metrics:\n",
      "  precision@10: 0.016690240\n",
      "  recall@10: 0.016780513\n",
      "  ndcg@10: 0.017915994\n",
      "  map@10: 0.006951371\n",
      "Epoch 501, Step 20, LR: 0.000298, Current Loss: 0.0279, Avg Loss: 0.0249\n",
      "Diff stats — min: -8.4032, max: 10.0000, mean: 8.5647, std: 2.4263\n",
      "\n",
      "Epoch 501 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 502, Step 1, LR: 0.000298, Current Loss: 0.0313, Avg Loss: 0.0313\n",
      "Diff stats — min: -5.4149, max: 10.0000, mean: 8.5840, std: 2.4244\n",
      "\n",
      "Step 15001 — Test metrics:\n",
      "  precision@10: 0.016831683\n",
      "  recall@10: 0.016913443\n",
      "  ndcg@10: 0.017934958\n",
      "  map@10: 0.006948295\n",
      "Epoch 502, Step 20, LR: 0.000298, Current Loss: 0.0218, Avg Loss: 0.0247\n",
      "Diff stats — min: -4.6831, max: 10.0000, mean: 8.6124, std: 2.3522\n",
      "\n",
      "Epoch 502 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 503, Step 1, LR: 0.000298, Current Loss: 0.0227, Avg Loss: 0.0227\n",
      "Diff stats — min: -6.1642, max: 10.0000, mean: 8.6533, std: 2.3293\n",
      "\n",
      "Step 15031 — Test metrics:\n",
      "  precision@10: 0.016690240\n",
      "  recall@10: 0.016772000\n",
      "  ndcg@10: 0.018105244\n",
      "  map@10: 0.007080467\n",
      "Epoch 503, Step 20, LR: 0.000298, Current Loss: 0.0266, Avg Loss: 0.0260\n",
      "Diff stats — min: -5.3271, max: 10.0000, mean: 8.5824, std: 2.3798\n",
      "\n",
      "Epoch 503 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 504, Step 1, LR: 0.000298, Current Loss: 0.0181, Avg Loss: 0.0181\n",
      "Diff stats — min: -3.3821, max: 10.0000, mean: 8.6316, std: 2.3113\n",
      "\n",
      "Step 15061 — Test metrics:\n",
      "  precision@10: 0.016784536\n",
      "  recall@10: 0.016863676\n",
      "  ndcg@10: 0.018041743\n",
      "  map@10: 0.007003574\n",
      "Epoch 504, Step 20, LR: 0.000298, Current Loss: 0.0276, Avg Loss: 0.0257\n",
      "Diff stats — min: -5.1968, max: 10.0000, mean: 8.5760, std: 2.4139\n",
      "\n",
      "Epoch 504 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 505, Step 1, LR: 0.000298, Current Loss: 0.0257, Avg Loss: 0.0257\n",
      "Diff stats — min: -7.4344, max: 10.0000, mean: 8.5935, std: 2.3978\n",
      "\n",
      "Step 15091 — Test metrics:\n",
      "  precision@10: 0.016784536\n",
      "  recall@10: 0.016872189\n",
      "  ndcg@10: 0.017977115\n",
      "  map@10: 0.006996462\n",
      "Epoch 505, Step 20, LR: 0.000298, Current Loss: 0.0259, Avg Loss: 0.0261\n",
      "Diff stats — min: -5.3963, max: 10.0000, mean: 8.5577, std: 2.4403\n",
      "\n",
      "Epoch 505 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 506, Step 1, LR: 0.000292, Current Loss: 0.0304, Avg Loss: 0.0304\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 8.5841, std: 2.4125\n",
      "\n",
      "Step 15121 — Test metrics:\n",
      "  precision@10: 0.016713814\n",
      "  recall@10: 0.016798193\n",
      "  ndcg@10: 0.018034274\n",
      "  map@10: 0.007011130\n",
      "Epoch 506, Step 20, LR: 0.000292, Current Loss: 0.0264, Avg Loss: 0.0246\n",
      "Diff stats — min: -4.7293, max: 10.0000, mean: 8.5738, std: 2.3979\n",
      "\n",
      "Epoch 506 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 507, Step 1, LR: 0.000292, Current Loss: 0.0200, Avg Loss: 0.0200\n",
      "Diff stats — min: -3.6368, max: 10.0000, mean: 8.6120, std: 2.3491\n",
      "\n",
      "Step 15151 — Test metrics:\n",
      "  precision@10: 0.016313060\n",
      "  recall@10: 0.016394820\n",
      "  ndcg@10: 0.017603198\n",
      "  map@10: 0.006833142\n",
      "Epoch 507, Step 20, LR: 0.000292, Current Loss: 0.0277, Avg Loss: 0.0247\n",
      "Diff stats — min: -4.4751, max: 10.0000, mean: 8.6428, std: 2.3723\n",
      "\n",
      "Epoch 507 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 508, Step 1, LR: 0.000292, Current Loss: 0.0317, Avg Loss: 0.0317\n",
      "Diff stats — min: -8.5055, max: 10.0000, mean: 8.6106, std: 2.4334\n",
      "\n",
      "Step 15181 — Test metrics:\n",
      "  precision@10: 0.016619519\n",
      "  recall@10: 0.016707172\n",
      "  ndcg@10: 0.017844243\n",
      "  map@10: 0.006923886\n",
      "Epoch 508, Step 20, LR: 0.000292, Current Loss: 0.0221, Avg Loss: 0.0266\n",
      "Diff stats — min: -8.1956, max: 10.0000, mean: 8.6281, std: 2.3596\n",
      "\n",
      "Epoch 508 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 509, Step 1, LR: 0.000292, Current Loss: 0.0293, Avg Loss: 0.0293\n",
      "Diff stats — min: -6.4455, max: 10.0000, mean: 8.6299, std: 2.4148\n",
      "\n",
      "Step 15211 — Test metrics:\n",
      "  precision@10: 0.016737388\n",
      "  recall@10: 0.016825041\n",
      "  ndcg@10: 0.017856501\n",
      "  map@10: 0.006923121\n",
      "Epoch 509, Step 20, LR: 0.000292, Current Loss: 0.0226, Avg Loss: 0.0254\n",
      "Diff stats — min: -6.4962, max: 10.0000, mean: 8.6709, std: 2.3356\n",
      "\n",
      "Epoch 509 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 510, Step 1, LR: 0.000292, Current Loss: 0.0276, Avg Loss: 0.0276\n",
      "Diff stats — min: -7.4756, max: 10.0000, mean: 8.6549, std: 2.3250\n",
      "\n",
      "Step 15241 — Test metrics:\n",
      "  precision@10: 0.016690240\n",
      "  recall@10: 0.016780513\n",
      "  ndcg@10: 0.017871025\n",
      "  map@10: 0.006955633\n",
      "Epoch 510, Step 20, LR: 0.000292, Current Loss: 0.0276, Avg Loss: 0.0268\n",
      "Diff stats — min: -8.8310, max: 10.0000, mean: 8.6306, std: 2.3764\n",
      "\n",
      "Epoch 510 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 511, Step 1, LR: 0.000286, Current Loss: 0.0272, Avg Loss: 0.0272\n",
      "Diff stats — min: -5.1742, max: 10.0000, mean: 8.6403, std: 2.3679\n",
      "\n",
      "Step 15271 — Test metrics:\n",
      "  precision@10: 0.016902405\n",
      "  recall@10: 0.016987439\n",
      "  ndcg@10: 0.018097308\n",
      "  map@10: 0.007052460\n",
      "Epoch 511, Step 20, LR: 0.000286, Current Loss: 0.0226, Avg Loss: 0.0266\n",
      "Diff stats — min: -5.2887, max: 10.0000, mean: 8.5660, std: 2.3742\n",
      "\n",
      "Epoch 511 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 512, Step 1, LR: 0.000286, Current Loss: 0.0244, Avg Loss: 0.0244\n",
      "Diff stats — min: -4.4447, max: 10.0000, mean: 8.5974, std: 2.3629\n",
      "\n",
      "Step 15301 — Test metrics:\n",
      "  precision@10: 0.017043847\n",
      "  recall@10: 0.017131501\n",
      "  ndcg@10: 0.018177404\n",
      "  map@10: 0.007060692\n",
      "Epoch 512, Step 20, LR: 0.000286, Current Loss: 0.0289, Avg Loss: 0.0250\n",
      "Diff stats — min: -6.7623, max: 10.0000, mean: 8.5472, std: 2.4378\n",
      "\n",
      "Epoch 512 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 513, Step 1, LR: 0.000286, Current Loss: 0.0190, Avg Loss: 0.0190\n",
      "Diff stats — min: -3.8916, max: 10.0000, mean: 8.6321, std: 2.3367\n",
      "\n",
      "Step 15331 — Test metrics:\n",
      "  precision@10: 0.016902405\n",
      "  recall@10: 0.016990058\n",
      "  ndcg@10: 0.018125592\n",
      "  map@10: 0.007072409\n",
      "Epoch 513, Step 20, LR: 0.000286, Current Loss: 0.0259, Avg Loss: 0.0253\n",
      "Diff stats — min: -4.7017, max: 10.0000, mean: 8.6255, std: 2.3740\n",
      "\n",
      "Epoch 513 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 514, Step 1, LR: 0.000286, Current Loss: 0.0296, Avg Loss: 0.0296\n",
      "Diff stats — min: -6.9103, max: 10.0000, mean: 8.6164, std: 2.4123\n",
      "\n",
      "Step 15361 — Test metrics:\n",
      "  precision@10: 0.016760962\n",
      "  recall@10: 0.016848615\n",
      "  ndcg@10: 0.018011378\n",
      "  map@10: 0.006952452\n",
      "Epoch 514, Step 20, LR: 0.000286, Current Loss: 0.0260, Avg Loss: 0.0255\n",
      "Diff stats — min: -5.6550, max: 10.0000, mean: 8.6321, std: 2.3855\n",
      "\n",
      "Epoch 514 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 515, Step 1, LR: 0.000286, Current Loss: 0.0247, Avg Loss: 0.0247\n",
      "Diff stats — min: -6.6467, max: 10.0000, mean: 8.6271, std: 2.3562\n",
      "\n",
      "Step 15391 — Test metrics:\n",
      "  precision@10: 0.016831683\n",
      "  recall@10: 0.016916717\n",
      "  ndcg@10: 0.018005006\n",
      "  map@10: 0.007011539\n",
      "Epoch 515, Step 20, LR: 0.000286, Current Loss: 0.0234, Avg Loss: 0.0256\n",
      "Diff stats — min: -9.0034, max: 10.0000, mean: 8.6529, std: 2.3349\n",
      "\n",
      "Epoch 515 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 516, Step 1, LR: 0.000280, Current Loss: 0.0265, Avg Loss: 0.0265\n",
      "Diff stats — min: -4.1468, max: 10.0000, mean: 8.5974, std: 2.3898\n",
      "\n",
      "Step 15421 — Test metrics:\n",
      "  precision@10: 0.017090995\n",
      "  recall@10: 0.017178648\n",
      "  ndcg@10: 0.018207029\n",
      "  map@10: 0.007082728\n",
      "Epoch 516, Step 20, LR: 0.000280, Current Loss: 0.0277, Avg Loss: 0.0248\n",
      "Diff stats — min: -4.5206, max: 10.0000, mean: 8.6426, std: 2.3645\n",
      "\n",
      "Epoch 516 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 517, Step 1, LR: 0.000280, Current Loss: 0.0237, Avg Loss: 0.0237\n",
      "Diff stats — min: -5.7528, max: 10.0000, mean: 8.6430, std: 2.3453\n",
      "\n",
      "Step 15451 — Test metrics:\n",
      "  precision@10: 0.016878831\n",
      "  recall@10: 0.016963865\n",
      "  ndcg@10: 0.018002878\n",
      "  map@10: 0.006945994\n",
      "Epoch 517, Step 20, LR: 0.000280, Current Loss: 0.0321, Avg Loss: 0.0255\n",
      "Diff stats — min: -7.3793, max: 10.0000, mean: 8.5980, std: 2.4243\n",
      "\n",
      "Epoch 517 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 518, Step 1, LR: 0.000280, Current Loss: 0.0236, Avg Loss: 0.0236\n",
      "Diff stats — min: -6.2361, max: 10.0000, mean: 8.6489, std: 2.3449\n",
      "\n",
      "Step 15481 — Test metrics:\n",
      "  precision@10: 0.016973126\n",
      "  recall@10: 0.017063399\n",
      "  ndcg@10: 0.018167690\n",
      "  map@10: 0.007048798\n",
      "Epoch 518, Step 20, LR: 0.000280, Current Loss: 0.0186, Avg Loss: 0.0245\n",
      "Diff stats — min: -3.9563, max: 10.0000, mean: 8.6069, std: 2.3103\n",
      "\n",
      "Epoch 518 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 519, Step 1, LR: 0.000280, Current Loss: 0.0290, Avg Loss: 0.0290\n",
      "Diff stats — min: -9.1293, max: 10.0000, mean: 8.6131, std: 2.3978\n",
      "\n",
      "Step 15511 — Test metrics:\n",
      "  precision@10: 0.017397454\n",
      "  recall@10: 0.017487727\n",
      "  ndcg@10: 0.018625999\n",
      "  map@10: 0.007261967\n",
      "Epoch 519, Step 20, LR: 0.000280, Current Loss: 0.0204, Avg Loss: 0.0261\n",
      "Diff stats — min: -4.8410, max: 10.0000, mean: 8.6627, std: 2.2827\n",
      "\n",
      "Epoch 519 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 520, Step 1, LR: 0.000280, Current Loss: 0.0217, Avg Loss: 0.0217\n",
      "Diff stats — min: -4.0033, max: 10.0000, mean: 8.5886, std: 2.3540\n",
      "\n",
      "Step 15541 — Test metrics:\n",
      "  precision@10: 0.017161716\n",
      "  recall@10: 0.017251989\n",
      "  ndcg@10: 0.018259719\n",
      "  map@10: 0.007085094\n",
      "Epoch 520, Step 20, LR: 0.000280, Current Loss: 0.0225, Avg Loss: 0.0242\n",
      "Diff stats — min: -5.9238, max: 10.0000, mean: 8.6374, std: 2.3361\n",
      "\n",
      "Epoch 520 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 521, Step 1, LR: 0.000274, Current Loss: 0.0268, Avg Loss: 0.0268\n",
      "Diff stats — min: -5.3301, max: 10.0000, mean: 8.6274, std: 2.3691\n",
      "\n",
      "Step 15571 — Test metrics:\n",
      "  precision@10: 0.017256011\n",
      "  recall@10: 0.017353768\n",
      "  ndcg@10: 0.018507257\n",
      "  map@10: 0.007247394\n",
      "Epoch 521, Step 20, LR: 0.000274, Current Loss: 0.0238, Avg Loss: 0.0240\n",
      "Diff stats — min: -4.3641, max: 10.0000, mean: 8.6901, std: 2.3228\n",
      "\n",
      "Epoch 521 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 522, Step 1, LR: 0.000274, Current Loss: 0.0345, Avg Loss: 0.0345\n",
      "Diff stats — min: -5.9300, max: 10.0000, mean: 8.5841, std: 2.4761\n",
      "\n",
      "Step 15601 — Test metrics:\n",
      "  precision@10: 0.017161716\n",
      "  recall@10: 0.017240857\n",
      "  ndcg@10: 0.018263718\n",
      "  map@10: 0.007067723\n",
      "Epoch 522, Step 20, LR: 0.000274, Current Loss: 0.0230, Avg Loss: 0.0254\n",
      "Diff stats — min: -4.2797, max: 10.0000, mean: 8.6290, std: 2.3431\n",
      "\n",
      "Epoch 522 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 523, Step 1, LR: 0.000274, Current Loss: 0.0269, Avg Loss: 0.0269\n",
      "Diff stats — min: -4.2869, max: 10.0000, mean: 8.6227, std: 2.3987\n",
      "\n",
      "Step 15631 — Test metrics:\n",
      "  precision@10: 0.017232438\n",
      "  recall@10: 0.017317472\n",
      "  ndcg@10: 0.018349976\n",
      "  map@10: 0.007104114\n",
      "Epoch 523, Step 20, LR: 0.000274, Current Loss: 0.0263, Avg Loss: 0.0250\n",
      "Diff stats — min: -7.7070, max: 10.0000, mean: 8.6437, std: 2.3722\n",
      "\n",
      "Epoch 523 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 524, Step 1, LR: 0.000274, Current Loss: 0.0243, Avg Loss: 0.0243\n",
      "Diff stats — min: -5.7001, max: 10.0000, mean: 8.6077, std: 2.3755\n",
      "\n",
      "Step 15661 — Test metrics:\n",
      "  precision@10: 0.017208864\n",
      "  recall@10: 0.017291278\n",
      "  ndcg@10: 0.018089530\n",
      "  map@10: 0.006922609\n",
      "Epoch 524, Step 20, LR: 0.000274, Current Loss: 0.0289, Avg Loss: 0.0243\n",
      "Diff stats — min: -5.8616, max: 10.0000, mean: 8.6245, std: 2.4037\n",
      "\n",
      "Epoch 524 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 525, Step 1, LR: 0.000274, Current Loss: 0.0231, Avg Loss: 0.0231\n",
      "Diff stats — min: -6.6616, max: 10.0000, mean: 8.6364, std: 2.3446\n",
      "\n",
      "Step 15691 — Test metrics:\n",
      "  precision@10: 0.016760962\n",
      "  recall@10: 0.016843377\n",
      "  ndcg@10: 0.018155367\n",
      "  map@10: 0.007097751\n",
      "Epoch 525, Step 20, LR: 0.000274, Current Loss: 0.0257, Avg Loss: 0.0264\n",
      "Diff stats — min: -5.0358, max: 10.0000, mean: 8.5523, std: 2.4072\n",
      "\n",
      "Epoch 525 completed, Train Loss: 0.000007\n",
      "\n",
      "Epoch 526, Step 1, LR: 0.000269, Current Loss: 0.0217, Avg Loss: 0.0217\n",
      "Diff stats — min: -3.5055, max: 10.0000, mean: 8.6535, std: 2.3359\n",
      "\n",
      "Step 15721 — Test metrics:\n",
      "  precision@10: 0.016760962\n",
      "  recall@10: 0.016840757\n",
      "  ndcg@10: 0.018084341\n",
      "  map@10: 0.007013293\n",
      "Epoch 526, Step 20, LR: 0.000269, Current Loss: 0.0286, Avg Loss: 0.0252\n",
      "Diff stats — min: -7.8951, max: 10.0000, mean: 8.6240, std: 2.3853\n",
      "\n",
      "Epoch 526 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 527, Step 1, LR: 0.000269, Current Loss: 0.0228, Avg Loss: 0.0228\n",
      "Diff stats — min: -6.2712, max: 10.0000, mean: 8.6384, std: 2.3363\n",
      "\n",
      "Step 15751 — Test metrics:\n",
      "  precision@10: 0.016784536\n",
      "  recall@10: 0.016864331\n",
      "  ndcg@10: 0.018072983\n",
      "  map@10: 0.007016990\n",
      "Epoch 527, Step 20, LR: 0.000269, Current Loss: 0.0252, Avg Loss: 0.0252\n",
      "Diff stats — min: -5.0598, max: 10.0000, mean: 8.6935, std: 2.3273\n",
      "\n",
      "Epoch 527 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 528, Step 1, LR: 0.000269, Current Loss: 0.0285, Avg Loss: 0.0285\n",
      "Diff stats — min: -6.7449, max: 10.0000, mean: 8.5911, std: 2.4119\n",
      "\n",
      "Step 15781 — Test metrics:\n",
      "  precision@10: 0.016690240\n",
      "  recall@10: 0.016775274\n",
      "  ndcg@10: 0.018034744\n",
      "  map@10: 0.007031000\n",
      "Epoch 528, Step 20, LR: 0.000269, Current Loss: 0.0260, Avg Loss: 0.0249\n",
      "Diff stats — min: -5.6903, max: 10.0000, mean: 8.6682, std: 2.3373\n",
      "\n",
      "Epoch 528 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 529, Step 1, LR: 0.000269, Current Loss: 0.0240, Avg Loss: 0.0240\n",
      "Diff stats — min: -6.5479, max: 10.0000, mean: 8.6469, std: 2.3720\n",
      "\n",
      "Step 15811 — Test metrics:\n",
      "  precision@10: 0.016430929\n",
      "  recall@10: 0.016513344\n",
      "  ndcg@10: 0.017839061\n",
      "  map@10: 0.006932477\n",
      "Epoch 529, Step 20, LR: 0.000269, Current Loss: 0.0274, Avg Loss: 0.0265\n",
      "Diff stats — min: -7.3812, max: 10.0000, mean: 8.6746, std: 2.3680\n",
      "\n",
      "Epoch 529 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 530, Step 1, LR: 0.000269, Current Loss: 0.0178, Avg Loss: 0.0178\n",
      "Diff stats — min: -2.4849, max: 10.0000, mean: 8.6865, std: 2.2919\n",
      "\n",
      "Step 15841 — Test metrics:\n",
      "  precision@10: 0.016171617\n",
      "  recall@10: 0.016254032\n",
      "  ndcg@10: 0.017532018\n",
      "  map@10: 0.006797630\n",
      "Epoch 530, Step 20, LR: 0.000269, Current Loss: 0.0254, Avg Loss: 0.0241\n",
      "Diff stats — min: -8.4978, max: 10.0000, mean: 8.6691, std: 2.3569\n",
      "\n",
      "Epoch 530 completed, Train Loss: 0.000006\n",
      "\n",
      "Epoch 531, Step 1, LR: 0.000264, Current Loss: 0.0283, Avg Loss: 0.0283\n",
      "Diff stats — min: -5.3092, max: 10.0000, mean: 8.6526, std: 2.3836\n",
      "\n",
      "Step 15871 — Test metrics:\n",
      "  precision@10: 0.016902405\n",
      "  recall@10: 0.016984819\n",
      "  ndcg@10: 0.018200955\n",
      "  map@10: 0.007084831\n",
      "Epoch 531, Step 20, LR: 0.000264, Current Loss: 0.0252, Avg Loss: 0.0255\n",
      "Diff stats — min: -6.4662, max: 10.0000, mean: 8.6434, std: 2.3752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model,\n",
    "                    data,\n",
    "                    (seq_ids, event_type, seq_times, seq_mask),\n",
    "                    edge_type=edge_type,\n",
    "                    num_epochs=num_epochs,\n",
    "                    lr=lr,\n",
    "                    batch_size=batch_size,\n",
    "                    print_every=print_every,\n",
    "                    test_every=test_every,\n",
    "                    top_k=top_k,\n",
    "                    test_batch_size=test_batch_size,\n",
    "                    scheduler_step_size=scheduler_step_size,\n",
    "                    scheduler_gamma=train_scheduler_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:36:30.198395Z",
     "iopub.status.busy": "2025-06-22T17:36:30.197899Z",
     "iopub.status.idle": "2025-06-22T17:36:30.232997Z",
     "shell.execute_reply": "2025-06-22T17:36:30.232268Z",
     "shell.execute_reply.started": "2025-06-22T17:36:30.198372Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='gnn_model_mvl.model' target='_blank'>gnn_model_mvl.model</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/gnn_model_mvl.model"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, \"gnn_model_mvl.model\")\n",
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('gnn_model_mvl.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:36:30.596044Z",
     "iopub.status.busy": "2025-06-22T17:36:30.595398Z",
     "iopub.status.idle": "2025-06-22T17:36:30.873926Z",
     "shell.execute_reply": "2025-06-22T17:36:30.873365Z",
     "shell.execute_reply.started": "2025-06-22T17:36:30.596021Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:36:31.390627Z",
     "iopub.status.busy": "2025-06-22T17:36:31.390366Z",
     "iopub.status.idle": "2025-06-22T17:36:31.492038Z",
     "shell.execute_reply": "2025-06-22T17:36:31.491494Z",
     "shell.execute_reply.started": "2025-06-22T17:36:31.390608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "log_model(\n",
    "    experiment=experiment,\n",
    "    model=model,\n",
    "    model_name=\"GNN+THP\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T17:36:31.787745Z",
     "iopub.status.busy": "2025-06-22T17:36:31.787479Z",
     "iopub.status.idle": "2025-06-22T17:36:33.738416Z",
     "shell.execute_reply": "2025-06-22T17:36:33.737894Z",
     "shell.execute_reply.started": "2025-06-22T17:36:31.787695Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : adding THP - movielens\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/annanet/gnn-recommender/e25265c5f38c4e04a51da951e587bfd4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Diff stats (mean) vs step [215] : (-0.6151944398880005, 2.360701322555542)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Diff stats (std) vs step [215]  : (1.0896390676498413, 8.307546615600586)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test map@10 vs step [214]       : (0.0006757857668453696, 0.003020701934195312)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test ndcg@10 vs step [214]      : (0.002398712119910755, 0.008660432668069255)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test precision@10 vs step [214] : (0.002450331125827815, 0.007748344370860928)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test recall@10 vs step [214]    : (0.002450331125827815, 0.007748344370860928)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Train Loss vs epoch [2]         : (0.0006868301924491638, 0.0015121251939579949)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Train Loss vs step [2130]       : (0.2705432176589966, 4.192562103271484)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [212]                      : (0.29193949699401855, 4.192562103271484)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : adding THP - movielens\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls_id                    : 3701\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_len_of_thp_history    : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pad_id                    : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed                      : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_batch_size           : 2048\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_topk                 : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     thp_decay                 : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     thp_dmodel                : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     thp_dropout               : 0.2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     thp_n_head                : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     thp_window_size           : 101\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_batch_size          : 512\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_edge_type           : [('item', 'to_feedback_explicit_positive', 'explicit_positive'), ('item', 'to_feedback_implicit_positive', 'implicit_positive')]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_lr                  : 0.001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_num_epochs          : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_print_every         : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_scheduler_gamma     : 0.98\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_scheduler_step_size : 150\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_test_every          : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     types_of_feedback         : ['explicit_positive', 'expliсit_negative', 'implicit_positive', 'implicit_negative']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 2 (8.96 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7705289,
     "sourceId": 12229447,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
