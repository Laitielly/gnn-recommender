{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1JMxRqxYhCF",
        "outputId": "b04af033-3782-48c4-9b95-120027e1f3b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting comet_ml\n",
            "  Downloading comet_ml-3.49.11-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml)\n",
            "  Downloading dulwich-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting everett<3.2.0,>=1.0.1 (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n",
            "  Downloading everett-3.1.0-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (4.24.0)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (5.9.5)\n",
            "Collecting python-box<7.0.0 (from comet_ml)\n",
            "  Downloading python_box-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (2.32.3)\n",
            "Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (13.9.4)\n",
            "Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (2.10.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (2.30.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from comet_ml) (3.20.1)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (1.17.2)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (3.1.1)\n",
            "Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n",
            "  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.25.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->comet_ml) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->comet_ml) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->comet_ml) (2025.6.15)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.3.2->comet_ml) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema!=3.1.0,>=2.6.0->comet_ml) (4.14.0)\n",
            "Downloading comet_ml-3.49.11-py3-none-any.whl (727 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.1/727.1 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading dulwich-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n",
            "Downloading python_box-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: everett, python-dotenv, python-box, dulwich, configobj, comet_ml\n",
            "  Attempting uninstall: python-box\n",
            "    Found existing installation: python-box 7.3.2\n",
            "    Uninstalling python-box-7.3.2:\n",
            "      Successfully uninstalled python-box-7.3.2\n",
            "Successfully installed comet_ml-3.49.11 configobj-5.0.9 dulwich-0.23.0 everett-3.1.0 python-box-6.1.0 python-dotenv-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install comet_ml python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "maBNQn9GaBsD",
        "outputId": "9fd8b656-937a-44c4-ece5-766f658fe48e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rectools\n",
            "  Downloading rectools-0.14.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Collecting attrs<24.0.0,>=19.1.0 (from rectools)\n",
            "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: fastrlock<0.9.0,>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from rectools) (0.8.3)\n",
            "Collecting implicit<0.8.0,>=0.7.1 (from rectools)\n",
            "  Downloading implicit-0.7.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting numpy (from torch_geometric)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0.0,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from rectools) (2.2.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from rectools) (2.11.7)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.20.1 in /usr/local/lib/python3.11/dist-packages (from rectools) (2.33.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from rectools) (1.15.3)\n",
            "Requirement already satisfied: typeguard<5.0.0,>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from rectools) (4.4.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from rectools) (4.14.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from implicit<0.8.0,>=0.7.1->rectools) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.5.0->rectools) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.5.0->rectools) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.5.0->rectools) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.2->rectools) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.2->rectools) (0.4.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.6.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.5.0->rectools) (1.17.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rectools-0.14.0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading implicit-0.7.2-cp311-cp311-manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, attrs, torch_geometric, implicit, rectools\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.3.0\n",
            "    Uninstalling attrs-25.3.0:\n",
            "      Successfully uninstalled attrs-25.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed attrs-23.2.0 implicit-0.7.2 numpy-1.26.4 rectools-0.14.0 torch_geometric-2.6.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "52c82f8fae9a4e46a4756924c28e5915",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install torch_geometric rectools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:09.175870Z",
          "iopub.status.busy": "2025-06-24T18:34:09.175582Z",
          "iopub.status.idle": "2025-06-24T18:34:14.600361Z",
          "shell.execute_reply": "2025-06-24T18:34:14.599796Z",
          "shell.execute_reply.started": "2025-06-24T18:34:09.175845Z"
        },
        "id": "Iq6mZl9SSeff",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import comet_ml\n",
        "from comet_ml import Experiment\n",
        "from comet_ml.integration.pytorch import log_model\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "gVcMYJ03TEoU",
        "outputId": "b43ea573-a40d-48ee-fa33-6c043400e6fa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3a5f0b0a-0568-4e20-8169-0f761ddc10fa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3a5f0b0a-0568-4e20-8169-0f761ddc10fa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"annanet\",\"key\":\"4dc3363d23056c66a776bfb47ee72ef8\"}'}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "k91CKDRuT-L2"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRI8T7maUASA",
        "outputId": "0ac0ed2a-c0a2-4100-c208-5896187fecd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/abrosimovkirill/gnn-dataset\n",
            "License(s): apache-2.0\n",
            "Downloading gnn-dataset.zip to /content/data\n",
            " 78% 95.0M/122M [00:00<00:00, 988MB/s]\n",
            "100% 122M/122M [00:00<00:00, 602MB/s] \n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet kaggle\n",
        "!kaggle datasets download -d abrosimovkirill/gnn-dataset -p /content/data\n",
        "!unzip -q /content/data/*.zip -d /content/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:14.606078Z",
          "iopub.status.busy": "2025-06-24T18:34:14.605916Z",
          "iopub.status.idle": "2025-06-24T18:34:14.633150Z",
          "shell.execute_reply": "2025-06-24T18:34:14.632641Z",
          "shell.execute_reply.started": "2025-06-24T18:34:14.606065Z"
        },
        "id": "kWxid0yKSeff",
        "outputId": "1fd1806d-7db0-42f1-fe05-d4d1983cca19",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv(\".env\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:14.636103Z",
          "iopub.status.busy": "2025-06-24T18:34:14.635594Z",
          "iopub.status.idle": "2025-06-24T18:34:20.699353Z",
          "shell.execute_reply": "2025-06-24T18:34:20.698767Z",
          "shell.execute_reply.started": "2025-06-24T18:34:14.636078Z"
        },
        "id": "ox-0MRqdSefg",
        "outputId": "0458bc79-a68b-4ac9-9d39-905dfd53448d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/annanet/gnn-recommender/b3740a03f56c484397e536d859f6df50\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        }
      ],
      "source": [
        "experiment = Experiment(\n",
        "  api_key=os.getenv('API_KEY'),\n",
        "  project_name=\"gnn-recommender\",\n",
        "  workspace=\"annanet\",\n",
        "  log_code=True\n",
        ")\n",
        "\n",
        "experiment.set_name('addthp-beautyv2-addce')\n",
        "experiment.add_tags(['beauty'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:20.700218Z",
          "iopub.status.busy": "2025-06-24T18:34:20.700041Z",
          "iopub.status.idle": "2025-06-24T18:34:20.705016Z",
          "shell.execute_reply": "2025-06-24T18:34:20.704512Z",
          "shell.execute_reply.started": "2025-06-24T18:34:20.700204Z"
        },
        "id": "GIIGBlQOSefg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "hyperparameters = {\n",
        "    'seed': 42,\n",
        "    'types_of_feedback': [\"explicit_positive\", \"expliсit_negative\",\n",
        "                          \"implicit_positive\", \"implicit_negative\"],\n",
        "    'max_len_of_thp_history': 100,\n",
        "    'pad_id': 0,\n",
        "    'cls_id': None,  # filled in at the stage of creating a story for thp\n",
        "    'thp_dmodel': 64,  # размер эмбеддингов\n",
        "    'thp_n_head': 4,  # число attention-голов\n",
        "    'thp_window_size': 101,  # окно THP\n",
        "    'thp_decay': 1.0,  # скорость экспоненциального затухания\n",
        "    'thp_dropout': 0.2,  # dropout\n",
        "    'train_edge_type': [('item','item2explicit_positive','explicit_positive'),\n",
        "                        ('item','item2implicit_positive','implicit_positive')],\n",
        "    'train_num_epochs': 100,\n",
        "    'train_lr': 1e-3,\n",
        "    'train_batch_size': 4096,\n",
        "    'train_print_every': 20,  # раз в сколько шагов печатаем статистику\n",
        "    'train_test_every': 50,\n",
        "    'test_topk': 10,\n",
        "    'test_batch_size': 8192,\n",
        "    'train_scheduler_step_size': 150,\n",
        "    'train_scheduler_gamma': 0.98,\n",
        "    'train_margin': 1.0,\n",
        "    'train_lambda_margin': 0.1,\n",
        "    'train_lambda_ce': 0.7\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:20.706302Z",
          "iopub.status.busy": "2025-06-24T18:34:20.705801Z",
          "iopub.status.idle": "2025-06-24T18:34:20.743622Z",
          "shell.execute_reply": "2025-06-24T18:34:20.743124Z",
          "shell.execute_reply.started": "2025-06-24T18:34:20.706264Z"
        },
        "id": "v3-Bi6aASefg",
        "outputId": "8a622a32-0692-42db-a476-a8b2dc47475c",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['train.csv', 'test.csv']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir('/content/data/data/leave-n-out/beauty')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:20.745124Z",
          "iopub.status.busy": "2025-06-24T18:34:20.744935Z",
          "iopub.status.idle": "2025-06-24T18:34:30.385086Z",
          "shell.execute_reply": "2025-06-24T18:34:30.384299Z",
          "shell.execute_reply.started": "2025-06-24T18:34:20.745108Z"
        },
        "id": "WMxHY4brSefg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import HeteroConv, GATConv\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from rectools import Columns\n",
        "from rectools.metrics import MAP, Precision, Recall, NDCG, calc_metrics\n",
        "\n",
        "import gc\n",
        "\n",
        "from collections import defaultdict\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:30.386242Z",
          "iopub.status.busy": "2025-06-24T18:34:30.385846Z",
          "iopub.status.idle": "2025-06-24T18:34:30.395533Z",
          "shell.execute_reply": "2025-06-24T18:34:30.394762Z",
          "shell.execute_reply.started": "2025-06-24T18:34:30.386224Z"
        },
        "id": "HV8Nwj8nSefg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "SEED = hyperparameters['seed']\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:30.396630Z",
          "iopub.status.busy": "2025-06-24T18:34:30.396352Z",
          "iopub.status.idle": "2025-06-24T18:34:31.561526Z",
          "shell.execute_reply": "2025-06-24T18:34:31.560780Z",
          "shell.execute_reply.started": "2025-06-24T18:34:30.396589Z"
        },
        "id": "9bPtQeODSefg",
        "outputId": "365a8a8d-a333-4563-bfe7-a38d35933a8d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 user_id     item_id  rating  \\\n",
            "0  A00414041RD0BXM6WK0GX  B007IY97U0     3.0   \n",
            "1  A00414041RD0BXM6WK0GX  B00870XLDS     2.0   \n",
            "2  A00414041RD0BXM6WK0GX  B008MIRO88     1.0   \n",
            "3  A00414041RD0BXM6WK0GX  B00BQYYMN0     3.0   \n",
            "4  A00414041RD0BXM6WK0GX  B00GRTQBTM     5.0   \n",
            "\n",
            "                                         review_text   unix_time       date  \n",
            "0  Good quality wig, but the blonde is much more ...  2014-07-14 2014-07-14  \n",
            "1  Very thin and not as long as the photos :( Aft...  2014-07-14 2014-07-14  \n",
            "2  Very thin and not as long as the photos :( Aft...  2014-07-14 2014-07-14  \n",
            "3  This is a great quality wig, however it is a m...  2014-07-14 2014-07-14  \n",
            "4  This is my absolute favorite wig! I have purch...  2014-07-14 2014-07-14  \n"
          ]
        }
      ],
      "source": [
        "rootpath = '/content/data/data/leave-n-out/beauty/'\n",
        "train = pd.read_csv(\n",
        "    rootpath+'train.csv'\n",
        ")\n",
        "train['date'] = pd.to_datetime(train['unix_time'])\n",
        "print(train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:31.562680Z",
          "iopub.status.busy": "2025-06-24T18:34:31.562424Z",
          "iopub.status.idle": "2025-06-24T18:34:31.600066Z",
          "shell.execute_reply": "2025-06-24T18:34:31.599322Z",
          "shell.execute_reply.started": "2025-06-24T18:34:31.562664Z"
        },
        "id": "JUXB1wz9Sefg",
        "outputId": "57421dce-3c63-400a-f32b-54f75773c0c3",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество explicit позитивного фидбека 90800\n",
            "Количество explicit негативного фидбека 17504\n"
          ]
        }
      ],
      "source": [
        "explicit_positive = train[(train[\"rating\"] == 5)].index\n",
        "explisit_negative = train[(train[\"rating\"] <= 2)].index\n",
        "\n",
        "explicit_combined_feedback = explicit_positive.union(explisit_negative)\n",
        "print('Количество explicit позитивного фидбека', explicit_positive.shape[0])\n",
        "print('Количество explicit негативного фидбека', explisit_negative.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:31.601269Z",
          "iopub.status.busy": "2025-06-24T18:34:31.601008Z",
          "iopub.status.idle": "2025-06-24T18:34:31.638609Z",
          "shell.execute_reply": "2025-06-24T18:34:31.637862Z",
          "shell.execute_reply.started": "2025-06-24T18:34:31.601242Z"
        },
        "id": "8QWQgDJYSefh",
        "outputId": "076a10cb-572e-4324-c5fd-3b72570a249b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество implicit позитивного фидбека 30668\n",
            "Количество implicit негативного фидбека 17110\n"
          ]
        }
      ],
      "source": [
        "implicit_positive = train[(train[\"rating\"] == 4)].index\n",
        "implicit_negative = train[(train[\"rating\"] == 3)].index\n",
        "\n",
        "implicit_combined_feedback = implicit_positive.union(implicit_negative)\n",
        "print('Количество implicit позитивного фидбека', implicit_positive.shape[0])\n",
        "print('Количество implicit негативного фидбека', implicit_negative.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:31.639965Z",
          "iopub.status.busy": "2025-06-24T18:34:31.639453Z",
          "iopub.status.idle": "2025-06-24T18:34:31.745613Z",
          "shell.execute_reply": "2025-06-24T18:34:31.744737Z",
          "shell.execute_reply.started": "2025-06-24T18:34:31.639938Z"
        },
        "id": "9pRT8NILSefh",
        "outputId": "5e80c908-0e03-41b0-82d8-c2777309eb83",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e720e4e9-7b05-44ac-9506-8d21abfdacb2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>target</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A00414041RD0BXM6WK0GX</td>\n",
              "      <td>B007IY97U0</td>\n",
              "      <td>implicit_negative</td>\n",
              "      <td>2014-07-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A00414041RD0BXM6WK0GX</td>\n",
              "      <td>B00870XLDS</td>\n",
              "      <td>expliсit_negative</td>\n",
              "      <td>2014-07-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A00414041RD0BXM6WK0GX</td>\n",
              "      <td>B008MIRO88</td>\n",
              "      <td>expliсit_negative</td>\n",
              "      <td>2014-07-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A00414041RD0BXM6WK0GX</td>\n",
              "      <td>B00BQYYMN0</td>\n",
              "      <td>implicit_negative</td>\n",
              "      <td>2014-07-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A00414041RD0BXM6WK0GX</td>\n",
              "      <td>B00GRTQBTM</td>\n",
              "      <td>explicit_positive</td>\n",
              "      <td>2014-07-14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e720e4e9-7b05-44ac-9506-8d21abfdacb2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e720e4e9-7b05-44ac-9506-8d21abfdacb2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e720e4e9-7b05-44ac-9506-8d21abfdacb2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-522388fa-068e-4c9e-8651-3d148c103593\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-522388fa-068e-4c9e-8651-3d148c103593')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-522388fa-068e-4c9e-8651-3d148c103593 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                 user_id     item_id             target       date\n",
              "0  A00414041RD0BXM6WK0GX  B007IY97U0  implicit_negative 2014-07-14\n",
              "1  A00414041RD0BXM6WK0GX  B00870XLDS  expliсit_negative 2014-07-14\n",
              "2  A00414041RD0BXM6WK0GX  B008MIRO88  expliсit_negative 2014-07-14\n",
              "3  A00414041RD0BXM6WK0GX  B00BQYYMN0  implicit_negative 2014-07-14\n",
              "4  A00414041RD0BXM6WK0GX  B00GRTQBTM  explicit_positive 2014-07-14"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.loc[:, \"target\"] = \"\"\n",
        "train.loc[explicit_positive, \"target\"] = \"explicit_positive\"\n",
        "train.loc[explisit_negative, \"target\"] = \"expliсit_negative\"\n",
        "train.loc[implicit_positive, \"target\"] = \"implicit_positive\"\n",
        "train.loc[implicit_negative, \"target\"] = \"implicit_negative\"\n",
        "\n",
        "train = train[['user_id','item_id','target','date']]\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:31.749361Z",
          "iopub.status.busy": "2025-06-24T18:34:31.749103Z",
          "iopub.status.idle": "2025-06-24T18:34:31.916896Z",
          "shell.execute_reply": "2025-06-24T18:34:31.916326Z",
          "shell.execute_reply.started": "2025-06-24T18:34:31.749343Z"
        },
        "id": "e-DWxe6DSefh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train = train.sort_values(by=[\"user_id\", \"date\"]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:31.917825Z",
          "iopub.status.busy": "2025-06-24T18:34:31.917610Z",
          "iopub.status.idle": "2025-06-24T18:34:31.921670Z",
          "shell.execute_reply": "2025-06-24T18:34:31.921120Z",
          "shell.execute_reply.started": "2025-06-24T18:34:31.917809Z"
        },
        "id": "R25_9RW4Sefh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train.columns = ['user_id', 'item_id', 'target', 'date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:31.922584Z",
          "iopub.status.busy": "2025-06-24T18:34:31.922371Z",
          "iopub.status.idle": "2025-06-24T18:34:32.015091Z",
          "shell.execute_reply": "2025-06-24T18:34:32.014469Z",
          "shell.execute_reply.started": "2025-06-24T18:34:31.922570Z"
        },
        "id": "Aksi6MYxSefh",
        "outputId": "11752776-b7c4-45b5-b94f-63a8267bd5d9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 user_id     item_id  rating  \\\n",
            "0  A02155413BVL8D0G7X6DN  B0089JVEPO     5.0   \n",
            "1  A02155413BVL8D0G7X6DN  B001G2LWDK     5.0   \n",
            "2  A02155413BVL8D0G7X6DN  B005Z41P28     5.0   \n",
            "3  A02155413BVL8D0G7X6DN  B0055MYJ0U     5.0   \n",
            "4  A02155413BVL8D0G7X6DN  B00117CH5M     3.0   \n",
            "\n",
            "                                         review_text   unix_time       date  \n",
            "0  leaves my skin clean and smooth. it is creamy ...  2012-10-25 2012-10-25  \n",
            "1  Works great, smells good, there is a result. I...  2012-12-06 2012-12-06  \n",
            "2  it works for my hair. smells like almond. made...  2013-01-17 2013-01-17  \n",
            "3  got this in the mail from China today! holds m...  2013-04-22 2013-04-22  \n",
            "4  if you like strong smell of honeysuckles and h...  2013-05-01 2013-05-01  \n"
          ]
        }
      ],
      "source": [
        "test = pd.read_csv(\n",
        "    rootpath+'test.csv'\n",
        ")\n",
        "test['date'] = pd.to_datetime(test['unix_time'])\n",
        "print(test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:32.016163Z",
          "iopub.status.busy": "2025-06-24T18:34:32.015921Z",
          "iopub.status.idle": "2025-06-24T18:34:32.024310Z",
          "shell.execute_reply": "2025-06-24T18:34:32.023740Z",
          "shell.execute_reply.started": "2025-06-24T18:34:32.016146Z"
        },
        "id": "bUolOGlHSefh",
        "outputId": "c9d73ae2-d8c9-4bea-9e18-742657c32886",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"test\",\n  \"rows\": 42420,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4242,\n        \"samples\": [\n          \"A5E55GXT5AAJS\",\n          \"AXR3CV6A4FMBG\",\n          \"A2UWHCX8CJXDMD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9828,\n        \"samples\": [\n          \"B001H3JQ0E\",\n          \"B004X9BRU6\",\n          \"B0064RT5L8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2005-01-20 00:00:00\",\n        \"max\": \"2014-07-23 00:00:00\",\n        \"num_unique_values\": 1706,\n        \"samples\": [\n          \"2012-04-10 00:00:00\",\n          \"2008-07-05 00:00:00\",\n          \"2011-07-21 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "test"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-911a70e1-a809-474e-bb6d-858432521f2a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A02155413BVL8D0G7X6DN</td>\n",
              "      <td>B0089JVEPO</td>\n",
              "      <td>2012-10-25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A02155413BVL8D0G7X6DN</td>\n",
              "      <td>B001G2LWDK</td>\n",
              "      <td>2012-12-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A02155413BVL8D0G7X6DN</td>\n",
              "      <td>B005Z41P28</td>\n",
              "      <td>2013-01-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A02155413BVL8D0G7X6DN</td>\n",
              "      <td>B0055MYJ0U</td>\n",
              "      <td>2013-04-22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A02155413BVL8D0G7X6DN</td>\n",
              "      <td>B00117CH5M</td>\n",
              "      <td>2013-05-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-911a70e1-a809-474e-bb6d-858432521f2a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-911a70e1-a809-474e-bb6d-858432521f2a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-911a70e1-a809-474e-bb6d-858432521f2a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7e8b3eaf-898c-46f1-aac3-eb572ba40eb4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e8b3eaf-898c-46f1-aac3-eb572ba40eb4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7e8b3eaf-898c-46f1-aac3-eb572ba40eb4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                 user_id     item_id       date\n",
              "0  A02155413BVL8D0G7X6DN  B0089JVEPO 2012-10-25\n",
              "1  A02155413BVL8D0G7X6DN  B001G2LWDK 2012-12-06\n",
              "2  A02155413BVL8D0G7X6DN  B005Z41P28 2013-01-17\n",
              "3  A02155413BVL8D0G7X6DN  B0055MYJ0U 2013-04-22\n",
              "4  A02155413BVL8D0G7X6DN  B00117CH5M 2013-05-01"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = test[['user_id','item_id', 'date']]\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:32.025668Z",
          "iopub.status.busy": "2025-06-24T18:34:32.025185Z",
          "iopub.status.idle": "2025-06-24T18:34:32.035304Z",
          "shell.execute_reply": "2025-06-24T18:34:32.034628Z",
          "shell.execute_reply.started": "2025-06-24T18:34:32.025651Z"
        },
        "id": "OR-6IPtrSefh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test.columns = ['user_id', 'item_id', 'date']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BInnKkdfSefh"
      },
      "source": [
        "# MVP model v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:32.036208Z",
          "iopub.status.busy": "2025-06-24T18:34:32.035992Z",
          "iopub.status.idle": "2025-06-24T18:34:32.185003Z",
          "shell.execute_reply": "2025-06-24T18:34:32.184495Z",
          "shell.execute_reply.started": "2025-06-24T18:34:32.036186Z"
        },
        "id": "ZvcL6rP5Sefi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train.loc[:, \"event\"] = 0\n",
        "train.loc[(train[\"target\"] == \"explicit_positive\") | (train[\"target\"] == \"implicit_positive\"), \"event\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:32.186394Z",
          "iopub.status.busy": "2025-06-24T18:34:32.185723Z",
          "iopub.status.idle": "2025-06-24T18:34:32.205878Z",
          "shell.execute_reply": "2025-06-24T18:34:32.205334Z",
          "shell.execute_reply.started": "2025-06-24T18:34:32.186375Z"
        },
        "id": "bTChsePzSefi",
        "outputId": "6770a8c0-2475-45e4-c5ce-219adf8dbe00",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(42378, 3)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = test[(test.user_id.isin(train.user_id)) & (test.item_id.isin(train.item_id))].copy()\n",
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:32.206896Z",
          "iopub.status.busy": "2025-06-24T18:34:32.206717Z",
          "iopub.status.idle": "2025-06-24T18:34:32.365891Z",
          "shell.execute_reply": "2025-06-24T18:34:32.365312Z",
          "shell.execute_reply.started": "2025-06-24T18:34:32.206882Z"
        },
        "id": "rBddCByiSefi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# 2. Преобразование данных - для куарека не особо нужно, но для других - напоминалка\n",
        "# делаем всегда! чтобы не сломать ничего дальше и чтобы все индексы были от 0 до N без пропусков\n",
        "user_encoder = LabelEncoder()\n",
        "video_encoder = LabelEncoder()\n",
        "\n",
        "train.loc[:, 'user_id'] = user_encoder.fit_transform(train['user_id'])\n",
        "train.loc[:, 'item_id'] = video_encoder.fit_transform(train['item_id'])\n",
        "\n",
        "test.loc[:, 'user_id'] = user_encoder.transform(test['user_id'])\n",
        "test.loc[:, 'item_id'] = video_encoder.transform(test['item_id'])\n",
        "train['user_id'] = train['user_id'].astype(int)\n",
        "train['item_id'] = train['item_id'].astype(int)\n",
        "test['user_id'] = test['user_id'].astype(int)\n",
        "test['item_id'] = test['item_id'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:32.366859Z",
          "iopub.status.busy": "2025-06-24T18:34:32.366593Z",
          "iopub.status.idle": "2025-06-24T18:34:32.374423Z",
          "shell.execute_reply": "2025-06-24T18:34:32.373662Z",
          "shell.execute_reply.started": "2025-06-24T18:34:32.366835Z"
        },
        "id": "nMceWg1pSefi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# так как используем pad, то нумерацию item_id начинаем с 1 до max + 1, чтобы для pad забить 0\n",
        "train.loc[:, 'item_id'] += 1\n",
        "test.loc[:, 'item_id'] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:32.375605Z",
          "iopub.status.busy": "2025-06-24T18:34:32.375322Z",
          "iopub.status.idle": "2025-06-24T18:34:32.400014Z",
          "shell.execute_reply": "2025-06-24T18:34:32.399358Z",
          "shell.execute_reply.started": "2025-06-24T18:34:32.375580Z"
        },
        "id": "LsyZwimjSefi",
        "outputId": "38b68330-50b6-4a23-90a2-d9980645aa82",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество уникальных item_id 12095\n",
            "Количество уникальных user_id 22363\n"
          ]
        }
      ],
      "source": [
        "# т.е. сразу знаем количество и в каких пределах изменяется user_id и item_id\n",
        "num_videos = train['item_id'].nunique()\n",
        "num_users = train['user_id'].nunique()\n",
        "\n",
        "print('Количество уникальных item_id', num_videos)\n",
        "print('Количество уникальных user_id', num_users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:32.401122Z",
          "iopub.status.busy": "2025-06-24T18:34:32.400873Z",
          "iopub.status.idle": "2025-06-24T18:34:32.409900Z",
          "shell.execute_reply": "2025-06-24T18:34:32.409116Z",
          "shell.execute_reply.started": "2025-06-24T18:34:32.401098Z"
        },
        "id": "TYlVz2ukSefj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def prepare_hetero_data(df: pd.DataFrame) -> HeteroData:\n",
        "    \"\"\"\n",
        "    Construct a heterogeneous graph for recommendation from interaction records.\n",
        "\n",
        "    Node types:\n",
        "      - 'user': one node per unique user_id\n",
        "      - 'item': one node per unique item_id\n",
        "      - one node per user per feedback type ('implicit_positive',\n",
        "        'explicit_positive', 'implicit_negative', 'explicit_negative')\n",
        "\n",
        "    Edges:\n",
        "      1) item -> feedback_node: connect each item to the corresponding feedback node.\n",
        "      2) feedback_node -> item: reverse connection, to allow message passing back to items.\n",
        "      3) feedback_node -> user: link each feedback node to the user who generated that feedback.\n",
        "      4) user -> user: a complete graph among all users under the relation 'interacts'.\n",
        "\n",
        "    For edges (1)-(3), each edge stores:\n",
        "      - edge_attr: a vector of length (1 + num_feedback_types),\n",
        "                   where index 0 is Δt = (reference_time - event_timestamp),\n",
        "                   and indices 1.. end are a one-hot encoding of the feedback type.\n",
        "      - edge_time: a separate tensor containing only Δt for convenience.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas.DataFrame\n",
        "        Must contain columns:\n",
        "          - 'user_id': integer user identifier (0-indexed or otherwise)\n",
        "          - 'item_id': integer item identifier\n",
        "          - 'target': feedback type (one of 'implicit_positive',\n",
        "                      'explicit_positive', 'implicit_negative',\n",
        "                      'explicit_negative')\n",
        "          - 'date': timestamp string for the interaction\n",
        "    reference_time : float\n",
        "        A Unix timestamp (in seconds). For each interaction, Δt is computed as\n",
        "        (reference_time - interaction_timestamp).\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    data : torch_geometric.data.HeteroData\n",
        "        A heterogeneous graph with node types 'user', 'item', and each feedback type.\n",
        "        Edge indices, edge_attr, and edge_time are set for relations:\n",
        "          - ('item', 'item2<ft>', ft)\n",
        "          - (ft, '<ft>2item', 'item')\n",
        "          - (ft, '<ft>2user', 'user')\n",
        "        Additionally, ('user', 'interacts', 'user') is a complete graph among users.\n",
        "    \"\"\"\n",
        "    # Determine the number of users and items\n",
        "    num_users = df['user_id'].nunique()\n",
        "    num_items = int(df['item_id'].max()) + 1\n",
        "    feedback_types = df['target'].unique().tolist()\n",
        "    type2idx = {tp: i for i, tp in enumerate(feedback_types)}\n",
        "\n",
        "    # Transform data to seconds\n",
        "    times = pd.to_datetime(df['date']).astype('datetime64[ns]').astype(int) / 1e9\n",
        "    df['timestamp'] = times\n",
        "\n",
        "    # Initialize HeteroData\n",
        "    data = HeteroData()\n",
        "    data['user'].node_id = torch.arange(num_users)\n",
        "    data['item'].node_id = torch.arange(num_items)\n",
        "    for ft in feedback_types:\n",
        "        data[ft].node_id = torch.arange(num_users)\n",
        "\n",
        "    # Build edges: item -> feedback -> user\n",
        "    for ft in feedback_types:\n",
        "        mask = df['target'] == ft\n",
        "        # user -> ft\n",
        "        src_fu = torch.LongTensor(df.loc[mask, 'user_id'].values)    # [E_ft]\n",
        "        dst_fu = torch.LongTensor(df.loc[mask, 'user_id'].values)    # тот же user_id, т.к. ft_node ID = user_id\n",
        "        # ft -> item\n",
        "        src_fi = torch.LongTensor(df.loc[mask, 'user_id'].values)\n",
        "        dst_fi = torch.LongTensor(df.loc[mask, 'item_id'].values)\n",
        "        # item -> ft\n",
        "        src_if = torch.LongTensor(df.loc[mask, 'item_id'].values)\n",
        "        dst_if = torch.LongTensor(df.loc[mask, 'user_id'].values)\n",
        "\n",
        "        # edge_attr\n",
        "        # delta_t = reference_time - timestamp\n",
        "        # delta = reference_time - torch.tensor(df.loc[mask, 'timestamp'].values, dtype=torch.float)  # [E_ft]\n",
        "        # delta = delta.unsqueeze(1)    # [E_ft, 1]\n",
        "        # one-hot of ft\n",
        "        # idx = type2idx[ft]\n",
        "        # one_hot = F.one_hot(torch.full((src_fu.size(0),), idx, dtype=torch.long),\n",
        "        #                     num_classes=len(feedback_types)).float()  # [E_ft, 4]\n",
        "        # combine: [delta | one_hot] → [E_ft, 5]\n",
        "        # edge_attr = torch.cat([delta, one_hot], dim=1)  # [E_ft, 1+4]\n",
        "\n",
        "        data['item', f'item2{ft}', ft].edge_index = torch.stack([src_if, dst_if], dim=0)\n",
        "        # data['item', f'item2{ft}', ft].edge_attr = edge_attr\n",
        "        # data['item', f'item2{ft}', ft].edge_time = delta\n",
        "\n",
        "        data[ft, f'{ft}2item', 'item'].edge_index = torch.stack([src_fi, dst_fi], dim=0)\n",
        "        # data[ft, f'{ft}2item', 'item'].edge_attr = edge_attr\n",
        "        # data[ft, f'{ft}2item', 'item'].edge_time = delta\n",
        "\n",
        "        data[ft, f'{ft}2user', 'user'].edge_index = torch.stack([src_fu, dst_fu], dim=0)\n",
        "        # data[ft, f'{ft}2user', 'user'].edge_attr = edge_attr\n",
        "        # data[ft, f'{ft}2user', 'user'].edge_time = delta\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:32.410839Z",
          "iopub.status.busy": "2025-06-24T18:34:32.410671Z",
          "iopub.status.idle": "2025-06-24T18:34:32.897389Z",
          "shell.execute_reply": "2025-06-24T18:34:32.896543Z",
          "shell.execute_reply.started": "2025-06-24T18:34:32.410826Z"
        },
        "id": "nDJby_nhSefj",
        "outputId": "10d74efc-827b-4cc3-d696-e89964149a59",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  user={ node_id=[22363] },\n",
              "  item={ node_id=[12096] },\n",
              "  implicit_negative={ node_id=[22363] },\n",
              "  expliсit_negative={ node_id=[22363] },\n",
              "  explicit_positive={ node_id=[22363] },\n",
              "  implicit_positive={ node_id=[22363] },\n",
              "  (item, item2implicit_negative, implicit_negative)={ edge_index=[2, 17110] },\n",
              "  (implicit_negative, implicit_negative2item, item)={ edge_index=[2, 17110] },\n",
              "  (implicit_negative, implicit_negative2user, user)={ edge_index=[2, 17110] },\n",
              "  (item, item2expliсit_negative, expliсit_negative)={ edge_index=[2, 17504] },\n",
              "  (expliсit_negative, expliсit_negative2item, item)={ edge_index=[2, 17504] },\n",
              "  (expliсit_negative, expliсit_negative2user, user)={ edge_index=[2, 17504] },\n",
              "  (item, item2explicit_positive, explicit_positive)={ edge_index=[2, 90800] },\n",
              "  (explicit_positive, explicit_positive2item, item)={ edge_index=[2, 90800] },\n",
              "  (explicit_positive, explicit_positive2user, user)={ edge_index=[2, 90800] },\n",
              "  (item, item2implicit_positive, implicit_positive)={ edge_index=[2, 30668] },\n",
              "  (implicit_positive, implicit_positive2item, item)={ edge_index=[2, 30668] },\n",
              "  (implicit_positive, implicit_positive2user, user)={ edge_index=[2, 30668] }\n",
              ")"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = prepare_hetero_data(train)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:32.898531Z",
          "iopub.status.busy": "2025-06-24T18:34:32.898235Z",
          "iopub.status.idle": "2025-06-24T18:34:32.910864Z",
          "shell.execute_reply": "2025-06-24T18:34:32.910219Z",
          "shell.execute_reply.started": "2025-06-24T18:34:32.898505Z"
        },
        "id": "2vx6pIONSefj",
        "outputId": "a7530b4d-aca7-4859-a349-7ed2d11eefe0",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([    0,     1,     2,  ..., 12093, 12094, 12095])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['item'].node_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:32.911970Z",
          "iopub.status.busy": "2025-06-24T18:34:32.911730Z",
          "iopub.status.idle": "2025-06-24T18:34:32.919931Z",
          "shell.execute_reply": "2025-06-24T18:34:32.919398Z",
          "shell.execute_reply.started": "2025-06-24T18:34:32.911950Z"
        },
        "id": "HVoiAYq5Sefj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def prepare_thp_data(df: pd.DataFrame, max_len: int, pad: int, cls_id: int):\n",
        "    \"\"\"\n",
        "    Build sequences of item ids, event types and timestamps per user for THP training.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame with columns ['user_id','item_id','event','date']\n",
        "    max_len : int, maximum sequence length (pad or truncate to this length)\n",
        "    pad : int, padding token value (left-padding)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    seq_ids   : LongTensor [num_users, max_len]\n",
        "    event_type: LongTensor [num_users, max_len]\n",
        "    seq_times : FloatTensor [num_users, max_len]\n",
        "    seq_mask  : BoolTensor [num_users, max_len]\n",
        "    \"\"\"\n",
        "    users = df['user_id'].unique()\n",
        "    num_users = len(users)\n",
        "\n",
        "    # +1 for the [CLS] token\n",
        "    new_max_len = max_len + 1\n",
        "\n",
        "    seq_ids    = torch.full((num_users, new_max_len), pad, dtype=torch.long)\n",
        "    event_type = torch.full((num_users, new_max_len), pad, dtype=torch.long)\n",
        "    seq_times  = torch.zeros((num_users, new_max_len), dtype=torch.float)\n",
        "    seq_mask   = torch.zeros((num_users, new_max_len), dtype=torch.bool)\n",
        "\n",
        "    # map event labels to ints\n",
        "    label2idx = {label: idx for idx, label in enumerate(df['event'].unique())}\n",
        "\n",
        "    # устанавливаем CLS-токен в позицию 0\n",
        "    seq_ids[:, 0]  = cls_id\n",
        "    event_type[:,0] = cls_id\n",
        "    seq_mask[:, 0] = True\n",
        "\n",
        "    for i, u in enumerate(users):\n",
        "        user_df = df[df['user_id'] == u].sort_values('date')\n",
        "        items = user_df['item_id'].values\n",
        "        types = user_df['event'].map(label2idx).values\n",
        "        times = pd.to_datetime(user_df['date']).values.astype('datetime64[ns]').astype(np.int64) / 1e9\n",
        "\n",
        "        seq = len(items)\n",
        "        if seq == 0:\n",
        "            continue\n",
        "\n",
        "        # вставляем реальные события **cдвинутые на 1** вправо из-за CLS,\n",
        "        # чтобы первые new_max_len-lengt...new_max_len-1 оказались данными\n",
        "        length = min(seq, max_len)\n",
        "        start = max(0, new_max_len - length)\n",
        "        seq_ids[i, start:]    = torch.tensor(items[-length:],    dtype=torch.long)\n",
        "        event_type[i, start:] = torch.tensor(types[-length:],    dtype=torch.long)\n",
        "        seq_times[i, start:]  = torch.tensor(times[-length:],    dtype=torch.float)\n",
        "        seq_mask[i, start:]   = True\n",
        "\n",
        "    return seq_ids, event_type, seq_times, seq_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:32.920975Z",
          "iopub.status.busy": "2025-06-24T18:34:32.920741Z",
          "iopub.status.idle": "2025-06-24T18:34:46.984053Z",
          "shell.execute_reply": "2025-06-24T18:34:46.983443Z",
          "shell.execute_reply.started": "2025-06-24T18:34:32.920955Z"
        },
        "id": "2I9Bfs_RSefj",
        "outputId": "09156e69-2513-41a7-c346-ef3eb7de3f17",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([12096,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,  9450,  9840, 10077, 11156, 11753,\n",
              "         11864]),\n",
              " tensor([12096,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     1,\n",
              "             1]),\n",
              " tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4053e+09,\n",
              "         1.4053e+09, 1.4053e+09, 1.4053e+09, 1.4053e+09, 1.4053e+09]),\n",
              " tensor([ True, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False,  True,  True,  True,  True,  True,\n",
              "          True]))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "PAD_ID = hyperparameters['pad_id']\n",
        "CLS_ID = data['item'].node_id.shape[0]\n",
        "hyperparameters['cls_id'] = CLS_ID\n",
        "max_len = hyperparameters['max_len_of_thp_history']\n",
        "\n",
        "seq_ids, event_type, seq_times, seq_mask = prepare_thp_data(train,\n",
        "                                                            max_len=max_len,\n",
        "                                                            pad=PAD_ID,\n",
        "                                                            cls_id=CLS_ID)\n",
        "seq_ids[0], event_type[0], seq_times[0], seq_mask[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:46.984974Z",
          "iopub.status.busy": "2025-06-24T18:34:46.984779Z",
          "iopub.status.idle": "2025-06-24T18:34:46.999614Z",
          "shell.execute_reply": "2025-06-24T18:34:46.998987Z",
          "shell.execute_reply.started": "2025-06-24T18:34:46.984951Z"
        },
        "id": "l8bepYE1Sefj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class THPEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-head Transformer Hawkes-inspired encoder with local window.\n",
        "    Integrates exponential decay kernel within last `window_size` events.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model: int, n_head: int, window_size: int = 50,\n",
        "                 decay: float = 1.0, dropout: float = 0.1, max_len: int = 101):\n",
        "        super().__init__()\n",
        "\n",
        "        self.max_len = max_len\n",
        "        # Learnable positional embeddings\n",
        "        self.pos_emb = nn.Embedding(max_len, d_model)\n",
        "        # Temporal (time) embedding: simple linear projection from scalar to d_model\n",
        "        self.time_emb = nn.Linear(1, d_model)\n",
        "\n",
        "        self.heads = nn.ModuleList([\n",
        "            _THPHead(d_model, decay, window_size, dropout) for _ in range(n_head)\n",
        "        ])\n",
        "\n",
        "        self.ffn = nn.Sequential(\n",
        "                nn.LayerNorm(d_model),\n",
        "                nn.Linear(d_model, d_model * 4),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(d_model * 4, d_model),\n",
        "                nn.Dropout(dropout)\n",
        "            )\n",
        "        self.final_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, emb: torch.Tensor, times: torch.Tensor, mask: torch.BoolTensor = None):\n",
        "        # emb: [B, L, D], times: [B, L], mask: [B, L]\n",
        "        B, L, D = emb.shape\n",
        "\n",
        "        positions = torch.arange(L, device=emb.device).unsqueeze(0).expand(B, -1)  # [B, L]\n",
        "        pe = self.pos_emb(positions)  # [B, L, D]\n",
        "        te = self.time_emb(times.unsqueeze(-1))  # [B, L, D]\n",
        "        x = emb + pe + te\n",
        "\n",
        "        attn_out = torch.stack([head(x, times, mask) for head in self.heads], dim=0).sum(0)\n",
        "\n",
        "        # Residual connection + normalization\n",
        "        x = x + attn_out\n",
        "        x = x + self.ffn(x)\n",
        "\n",
        "        return self.final_norm(x)  # [B, L, D]\n",
        "\n",
        "class _THPHead(nn.Module):\n",
        "    def __init__(self, d_model: int, decay: float, window_size: int, dropout: float,\n",
        "                pos_lambda: float = None):\n",
        "        super().__init__()\n",
        "        self.linear_v = nn.Linear(d_model, d_model, bias=False)\n",
        "        nn.init.xavier_uniform_(self.linear_v.weight)\n",
        "        self.temperature = d_model ** 0.5\n",
        "        self.decay = decay\n",
        "        self.window_size = window_size\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.input_norm = nn.LayerNorm(d_model)\n",
        "        self.pos_lambda = pos_lambda or (1.0 / window_size)\n",
        "\n",
        "    def forward(self, emb: torch.Tensor, times: torch.Tensor, mask: torch.BoolTensor = None):\n",
        "        B, L, D = emb.size()\n",
        "        emb_norm = self.input_norm(emb)\n",
        "        q = emb_norm / self.temperature           # [B, L, D]\n",
        "        k = emb_norm                              # [B, L, D]\n",
        "        v = F.elu(self.linear_v(emb_norm))        # [B, L, D]\n",
        "\n",
        "        if not torch.isfinite(q).all():\n",
        "            print(\"NaN/Inf в q:\", torch.isnan(q).sum().item(), torch.isinf(q).sum().item())\n",
        "        if not torch.isfinite(k).all():\n",
        "            print(\"NaN/Inf в k:\", torch.isnan(k).sum().item(), torch.isinf(k).sum().item())\n",
        "        if not torch.isfinite(v).all():\n",
        "            print(\"NaN/Inf в v:\", torch.isnan(v).sum().item(), torch.isinf(v).sum().item())\n",
        "\n",
        "        # 3) Build pad mask only\n",
        "        if mask is not None:\n",
        "            pad_mask = ~mask.unsqueeze(1).expand(-1, L, -1)  # [B, L, L]\n",
        "        else:\n",
        "            pad_mask = torch.zeros((B, L, L), dtype=torch.bool, device=emb.device)\n",
        "\n",
        "        # Always allow self-attention for pad_mask diagonal\n",
        "        idx = torch.arange(L, device=emb.device)\n",
        "        pad_mask[:, idx, idx] = False\n",
        "\n",
        "        scores = torch.bmm(q, k.transpose(1, 2))  # [B, L, L]\n",
        "\n",
        "        # Apply temporal decay kernel\n",
        "        delta = (times.unsqueeze(-1) - times.unsqueeze(-2)).clamp(min=0)\n",
        "        scores = scores * torch.exp(-self.decay * delta)\n",
        "\n",
        "        # Apply smooth positional decay\n",
        "        dist = (idx.unsqueeze(0) - idx.unsqueeze(1)).abs().float()  # [L, L]\n",
        "        pos_decay = torch.exp(-self.pos_lambda * dist).unsqueeze(0)    # [1, L, L]\n",
        "        scores = scores * pos_decay\n",
        "\n",
        "        scores = torch.clamp(scores, min=-1e3, max=1e3)\n",
        "        scores = scores.masked_fill(pad_mask, float('-inf'))\n",
        "\n",
        "        # Debug range\n",
        "        finite = scores[~pad_mask]\n",
        "        # if finite.numel() > 0:\n",
        "        #     print(f\"Диапазон scores до softmax: min={finite.min().item():.3e}, max={finite.max().item():.3e}\")\n",
        "\n",
        "        attn = F.softmax(scores, dim=-1)\n",
        "\n",
        "        if not torch.isfinite(attn).all():\n",
        "            print(\"NaN/Inf в attn после softmax:\", torch.isnan(attn).sum().item(), torch.isinf(attn).sum().item())\n",
        "\n",
        "        attn = torch.nan_to_num(attn, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        attn = self.dropout(attn)\n",
        "\n",
        "        out = torch.bmm(attn, v)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:47.000538Z",
          "iopub.status.busy": "2025-06-24T18:34:47.000377Z",
          "iopub.status.idle": "2025-06-24T18:34:47.025246Z",
          "shell.execute_reply": "2025-06-24T18:34:47.024696Z",
          "shell.execute_reply.started": "2025-06-24T18:34:47.000526Z"
        },
        "id": "uzxqKLTuSefj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class HeteroGNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_users: int,\n",
        "                 num_items: int,\n",
        "                 feedback_types: list,\n",
        "                 emb_dim: int = 32,\n",
        "                 hidden_dim: int = 16,\n",
        "                 heads: int = 2,\n",
        "                 dropout: float = 0.2):\n",
        "        super().__init__()\n",
        "        self.feedback_types = feedback_types\n",
        "        self.pos_types = ['implicit_positive', 'explicit_positive']\n",
        "        self.neg_types = ['implicit_negative', 'expliсit_negative']\n",
        "\n",
        "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
        "        self.item_emb = nn.Embedding(num_items + 1, emb_dim, padding_idx=0)\n",
        "        self.fb_emb   = nn.ModuleDict({\n",
        "            ft: nn.Embedding(num_users, emb_dim) for ft in feedback_types\n",
        "        })\n",
        "\n",
        "        conv1, conv2 = {}, {}\n",
        "        for ft in feedback_types:\n",
        "            # ft -> user\n",
        "            conv1[(ft, f'{ft}2user', 'user')] = GATConv(emb_dim, hidden_dim,\n",
        "                                                      heads=heads,\n",
        "                                                      add_self_loops=False)\n",
        "            conv2[(ft, f'{ft}2user', 'user')] = GATConv(hidden_dim*heads, emb_dim,\n",
        "                                                      heads=1,\n",
        "                                                      add_self_loops=False)\n",
        "            # ft -> item\n",
        "            conv1[(ft, f'{ft}2item', 'item')] = GATConv(emb_dim, hidden_dim,\n",
        "                                                       heads=heads,\n",
        "                                                       add_self_loops=False)\n",
        "            conv2[(ft, f'{ft}2item', 'item')] = GATConv(hidden_dim*heads, emb_dim,\n",
        "                                                       heads=1,\n",
        "                                                       add_self_loops=False)\n",
        "\n",
        "            # item -> ft\n",
        "            conv1[('item', f'item2{ft}', ft)] = GATConv(emb_dim, hidden_dim,\n",
        "                                                       heads=heads,\n",
        "                                                       add_self_loops=False)\n",
        "            conv2[('item', f'item2{ft}', ft)] = GATConv(hidden_dim*heads, emb_dim,\n",
        "                                                       heads=1,\n",
        "                                                       add_self_loops=False)\n",
        "\n",
        "        self.conv1 = HeteroConv(conv1, aggr='mean')\n",
        "        self.conv2 = HeteroConv(conv2, aggr='mean')\n",
        "\n",
        "        # LayerNorm и Dropout\n",
        "        types = ['user', 'item'] + feedback_types\n",
        "        self.norm1 = nn.ModuleDict({t: nn.LayerNorm(hidden_dim*heads) for t in types})\n",
        "        self.norm2 = nn.ModuleDict({t: nn.LayerNorm(emb_dim) for t in types})\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = {\n",
        "            'user': self.user_emb(data['user'].node_id),\n",
        "            'item': self.item_emb(data['item'].node_id)\n",
        "        }\n",
        "        for ft in self.feedback_types:\n",
        "            x[ft] = self.fb_emb[ft](data[ft].node_id)\n",
        "\n",
        "        h1 = self.conv1(x, data.edge_index_dict)\n",
        "        for t, h in h1.items():\n",
        "            h1[t] = self.dropout(F.leaky_relu(self.norm1[t](h)))\n",
        "        # print(h1.keys())\n",
        "\n",
        "        h2 = self.conv2(h1, data.edge_index_dict)\n",
        "        # print(h2.keys())\n",
        "        out = {}\n",
        "        for t, h in h2.items():\n",
        "            out[t] = self.norm2[t](h)\n",
        "\n",
        "        # print(out.keys())\n",
        "\n",
        "        return out['user']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:47.026161Z",
          "iopub.status.busy": "2025-06-24T18:34:47.025955Z",
          "iopub.status.idle": "2025-06-24T18:34:47.045129Z",
          "shell.execute_reply": "2025-06-24T18:34:47.044634Z",
          "shell.execute_reply.started": "2025-06-24T18:34:47.026139Z"
        },
        "id": "m7_4uoetSefk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_users: int,\n",
        "                 num_items: int,\n",
        "                 feedback_types: list,\n",
        "                 d_model: int = 32,\n",
        "                 n_head: int = 4,\n",
        "                 window_size: int = 50,\n",
        "                 decay: float = 1.0,\n",
        "                 dropout: float = 0.1,\n",
        "                 num_event_types: int = 2):\n",
        "        super().__init__()\n",
        "        # Static graph encoder\n",
        "        self.gnn = HeteroGNN(num_users, num_items, feedback_types,\n",
        "                                   emb_dim=d_model, hidden_dim=d_model//2,\n",
        "                                   heads=2, dropout=dropout)\n",
        "        # Inlined THP sequence encoder\n",
        "        self.thp = THPEncoder(d_model=d_model,\n",
        "                              n_head=n_head,\n",
        "                              window_size=window_size,\n",
        "                              decay=decay,\n",
        "                              dropout=dropout)\n",
        "        # 3) Multi‐task heads:\n",
        "        #   a) ranking: produce updated user embedding\n",
        "        #   b) classification: predict next event type\n",
        "        self.event_classifier = nn.Linear(d_model, num_event_types)\n",
        "\n",
        "    def forward(self, data, seq_ids, seq_times, seq_mask, batch_users):\n",
        "        # Static graph embeddings\n",
        "        user_embs = self.gnn(data)          # [num_users, d_model]\n",
        "        # Sequence encoding\n",
        "        seq_item_emb = self.gnn.item_emb(seq_ids)  # [B, L, d_model]\n",
        "        attn_out = self.thp(seq_item_emb, seq_times, seq_mask)\n",
        "        seq_rep = attn_out[:, -1, :]        # [B, d_model]\n",
        "        # Get static user embeddings\n",
        "        gnn_rep = user_embs[batch_users]   # [B, d_model]\n",
        "        # Updated user embedding\n",
        "        updated_user_emb = seq_rep + gnn_rep\n",
        "        event_logits = self.event_classifier(seq_rep)\n",
        "        return updated_user_emb, event_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:47.046640Z",
          "iopub.status.busy": "2025-06-24T18:34:47.045826Z",
          "iopub.status.idle": "2025-06-24T18:34:47.115874Z",
          "shell.execute_reply": "2025-06-24T18:34:47.115414Z",
          "shell.execute_reply.started": "2025-06-24T18:34:47.046617Z"
        },
        "id": "sbtca2YxSefk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "num_users = data['user'].node_id.shape[0]\n",
        "num_items = data['item'].node_id.shape[0]\n",
        "feedback_types = train['target'].unique().tolist()\n",
        "data.user_idx = data['user'].node_id\n",
        "d_model = hyperparameters['thp_dmodel']\n",
        "n_head = hyperparameters['thp_n_head']\n",
        "window_size = hyperparameters['thp_window_size']\n",
        "decay = hyperparameters['thp_decay']\n",
        "dropout = hyperparameters['thp_dropout']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:47.116686Z",
          "iopub.status.busy": "2025-06-24T18:34:47.116486Z",
          "iopub.status.idle": "2025-06-24T18:34:47.121436Z",
          "shell.execute_reply": "2025-06-24T18:34:47.120859Z",
          "shell.execute_reply.started": "2025-06-24T18:34:47.116671Z"
        },
        "id": "YUiBbLg8Sefk",
        "outputId": "45d13b96-9149-4559-e642-a6a3afe4c408",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  user_idx=[22363],\n",
              "  user={ node_id=[22363] },\n",
              "  item={ node_id=[12096] },\n",
              "  implicit_negative={ node_id=[22363] },\n",
              "  expliсit_negative={ node_id=[22363] },\n",
              "  explicit_positive={ node_id=[22363] },\n",
              "  implicit_positive={ node_id=[22363] },\n",
              "  (item, item2implicit_negative, implicit_negative)={ edge_index=[2, 17110] },\n",
              "  (implicit_negative, implicit_negative2item, item)={ edge_index=[2, 17110] },\n",
              "  (implicit_negative, implicit_negative2user, user)={ edge_index=[2, 17110] },\n",
              "  (item, item2expliсit_negative, expliсit_negative)={ edge_index=[2, 17504] },\n",
              "  (expliсit_negative, expliсit_negative2item, item)={ edge_index=[2, 17504] },\n",
              "  (expliсit_negative, expliсit_negative2user, user)={ edge_index=[2, 17504] },\n",
              "  (item, item2explicit_positive, explicit_positive)={ edge_index=[2, 90800] },\n",
              "  (explicit_positive, explicit_positive2item, item)={ edge_index=[2, 90800] },\n",
              "  (explicit_positive, explicit_positive2user, user)={ edge_index=[2, 90800] },\n",
              "  (item, item2implicit_positive, implicit_positive)={ edge_index=[2, 30668] },\n",
              "  (implicit_positive, implicit_positive2item, item)={ edge_index=[2, 30668] },\n",
              "  (implicit_positive, implicit_positive2user, user)={ edge_index=[2, 30668] }\n",
              ")"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:47.122337Z",
          "iopub.status.busy": "2025-06-24T18:34:47.122079Z",
          "iopub.status.idle": "2025-06-24T18:34:49.152912Z",
          "shell.execute_reply": "2025-06-24T18:34:49.152127Z",
          "shell.execute_reply.started": "2025-06-24T18:34:47.122315Z"
        },
        "id": "KyR9AfpsSefk",
        "outputId": "bec62de3-9317-490b-b936-b6b60659304b",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([22363, 64])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "heterognn = HeteroGNN(num_users, num_items, feedback_types,\n",
        "                            emb_dim=d_model, hidden_dim=d_model//2,\n",
        "                            heads=2, dropout=dropout)\n",
        "output = heterognn(data)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:49.153948Z",
          "iopub.status.busy": "2025-06-24T18:34:49.153727Z",
          "iopub.status.idle": "2025-06-24T18:34:49.194096Z",
          "shell.execute_reply": "2025-06-24T18:34:49.193609Z",
          "shell.execute_reply.started": "2025-06-24T18:34:49.153931Z"
        },
        "id": "A9-QsDPHSefk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model = Model(\n",
        "    num_users=num_users,\n",
        "    num_items=num_items,\n",
        "    feedback_types=feedback_types,\n",
        "    d_model=d_model,\n",
        "    n_head=n_head,\n",
        "    window_size=window_size,\n",
        "    decay=decay,\n",
        "    dropout=dropout,\n",
        "    num_event_types=2\n",
        ")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:49.194939Z",
          "iopub.status.busy": "2025-06-24T18:34:49.194740Z",
          "iopub.status.idle": "2025-06-24T18:34:49.860586Z",
          "shell.execute_reply": "2025-06-24T18:34:49.859958Z",
          "shell.execute_reply.started": "2025-06-24T18:34:49.194924Z"
        },
        "id": "G_-E05AvSefk",
        "outputId": "fdada511-2062-448c-8d3a-7422a0d61d98",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "THPEncoder output shape: torch.Size([32, 101, 64])\n"
          ]
        }
      ],
      "source": [
        "B = 32\n",
        "seq_ids_batch   = seq_ids[:B]     # [B, L]\n",
        "seq_times_batch = seq_times[:B]   # [B, L]\n",
        "seq_mask_batch  = seq_mask[:B]    # [B, L]\n",
        "\n",
        "item_emb = model.gnn.item_emb\n",
        "d_model = item_emb.embedding_dim\n",
        "\n",
        "# Получаем seq_item_emb: [B, L, D]\n",
        "seq_item_emb = item_emb(seq_ids_batch)\n",
        "\n",
        "thp_encoder = THPEncoder(\n",
        "    d_model=d_model,\n",
        "    n_head=4,\n",
        "    window_size=50,\n",
        "    decay=1.0,\n",
        "    dropout=0.1\n",
        ")\n",
        "\n",
        "thp_encoder.to(device)\n",
        "seq_item_emb   = seq_item_emb.to(device)\n",
        "seq_times_batch= seq_times_batch.to(device)\n",
        "seq_mask_batch = seq_mask_batch.to(device)\n",
        "\n",
        "out = thp_encoder(\n",
        "    emb=seq_item_emb,\n",
        "    times=seq_times_batch,\n",
        "    mask=seq_mask_batch\n",
        ")\n",
        "\n",
        "print(\"THPEncoder output shape:\", out.shape)  # ожидаем [B, L, D]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:49.861459Z",
          "iopub.status.busy": "2025-06-24T18:34:49.861268Z",
          "iopub.status.idle": "2025-06-24T18:34:49.988102Z",
          "shell.execute_reply": "2025-06-24T18:34:49.987518Z",
          "shell.execute_reply.started": "2025-06-24T18:34:49.861445Z"
        },
        "id": "TrLEmx_vSefl",
        "outputId": "af3d8485-5b3d-4800-9732-ff767ecc3d55",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated user embeddings: torch.Size([32, 64]) torch.Size([32, 2])\n"
          ]
        }
      ],
      "source": [
        "B = 32\n",
        "batch_seq_ids   = seq_ids[:B].to(device)    # [B, L]\n",
        "batch_seq_times = seq_times[:B].to(device)  # [B, L]\n",
        "batch_seq_mask  = seq_mask[:B].to(device)   # [B, L]\n",
        "\n",
        "# data.user_idx = data['user'].node_id[:B]\n",
        "batch_users = data.user_idx[:B].to(device)\n",
        "model.to(device)\n",
        "data.to(device)\n",
        "\n",
        "updated_user_emb = model(\n",
        "    data=data,\n",
        "    seq_ids=batch_seq_ids,\n",
        "    seq_times=batch_seq_times,\n",
        "    seq_mask=batch_seq_mask,\n",
        "    batch_users=batch_users\n",
        ")  # [B, d_model]\n",
        "\n",
        "print(\"Updated user embeddings:\", updated_user_emb[0].shape, updated_user_emb[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:49.989055Z",
          "iopub.status.busy": "2025-06-24T18:34:49.988803Z",
          "iopub.status.idle": "2025-06-24T18:34:50.007736Z",
          "shell.execute_reply": "2025-06-24T18:34:50.007165Z",
          "shell.execute_reply.started": "2025-06-24T18:34:49.989036Z"
        },
        "id": "j9t__9UDSefl",
        "outputId": "01f1a1e0-01e5-4009-99a2-9cb7ac8da3ae",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12095, 1, 12095)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.item_id.nunique(), train.item_id.min(), train.item_id.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:50.008772Z",
          "iopub.status.busy": "2025-06-24T18:34:50.008496Z",
          "iopub.status.idle": "2025-06-24T18:34:50.013652Z",
          "shell.execute_reply": "2025-06-24T18:34:50.013065Z",
          "shell.execute_reply.started": "2025-06-24T18:34:50.008750Z"
        },
        "id": "1PYvcNOUSefl",
        "outputId": "ad2b722e-d383-4ff0-fa66-053fa4a9b2fc",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Model(\n",
              "  (gnn): HeteroGNN(\n",
              "    (user_emb): Embedding(22363, 64)\n",
              "    (item_emb): Embedding(12097, 64, padding_idx=0)\n",
              "    (fb_emb): ModuleDict(\n",
              "      (implicit_negative): Embedding(22363, 64)\n",
              "      (expliсit_negative): Embedding(22363, 64)\n",
              "      (explicit_positive): Embedding(22363, 64)\n",
              "      (implicit_positive): Embedding(22363, 64)\n",
              "    )\n",
              "    (conv1): HeteroConv(num_relations=12)\n",
              "    (conv2): HeteroConv(num_relations=12)\n",
              "    (norm1): ModuleDict(\n",
              "      (user): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      (item): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      (implicit_negative): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      (expliсit_negative): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      (explicit_positive): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      (implicit_positive): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (norm2): ModuleDict(\n",
              "      (user): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      (item): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      (implicit_negative): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      (expliсit_negative): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      (explicit_positive): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      (implicit_positive): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (thp): THPEncoder(\n",
              "    (pos_emb): Embedding(101, 64)\n",
              "    (time_emb): Linear(in_features=1, out_features=64, bias=True)\n",
              "    (heads): ModuleList(\n",
              "      (0-3): 4 x _THPHead(\n",
              "        (linear_v): Linear(in_features=64, out_features=64, bias=False)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (input_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (ffn): Sequential(\n",
              "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "      (1): Linear(in_features=64, out_features=256, bias=True)\n",
              "      (2): ReLU()\n",
              "      (3): Linear(in_features=256, out_features=64, bias=True)\n",
              "      (4): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (final_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (event_classifier): Linear(in_features=64, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:50.014676Z",
          "iopub.status.busy": "2025-06-24T18:34:50.014451Z",
          "iopub.status.idle": "2025-06-24T18:34:50.351014Z",
          "shell.execute_reply": "2025-06-24T18:34:50.350218Z",
          "shell.execute_reply.started": "2025-06-24T18:34:50.014661Z"
        },
        "id": "P2kl-G0GSefl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_df = test[['user_id', 'item_id']]\n",
        "interactions = test_df.rename(columns={\n",
        "    'user_id': Columns.User,\n",
        "    'item_id': Columns.Item,\n",
        "})\n",
        "\n",
        "viewed_items = train.groupby(\"user_id\")[\"item_id\"].agg(set).to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:50.355618Z",
          "iopub.status.busy": "2025-06-24T18:34:50.355399Z",
          "iopub.status.idle": "2025-06-24T18:34:51.067415Z",
          "shell.execute_reply": "2025-06-24T18:34:51.066531Z",
          "shell.execute_reply.started": "2025-06-24T18:34:50.355602Z"
        },
        "id": "Qooc7gkXSefl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "user2lists = {ft: defaultdict(list) for ft in feedback_types}\n",
        "\n",
        "for ft, sub in train.groupby('target'):\n",
        "    mapping = sub.groupby('user_id')['item_id'].apply(list)\n",
        "    for u, items in mapping.items():\n",
        "        user2lists[ft][u] = items\n",
        "\n",
        "user2explicit_pos = user2lists['explicit_positive']\n",
        "user2implicit_pos = user2lists['implicit_positive']\n",
        "user2explicit_neg = user2lists['expliсit_negative']\n",
        "user2implicit_neg = user2lists['implicit_negative']\n",
        "all_items_set = set(train.item_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg3k35habyUO",
        "outputId": "0c40a2d5-f7eb-465c-92fe-6117e19ce995"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.gnn.item_emb.weight.shape[0] - 1 == CLS_ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:51.068765Z",
          "iopub.status.busy": "2025-06-24T18:34:51.068539Z",
          "iopub.status.idle": "2025-06-24T18:34:51.080315Z",
          "shell.execute_reply": "2025-06-24T18:34:51.079645Z",
          "shell.execute_reply.started": "2025-06-24T18:34:51.068749Z"
        },
        "id": "gUi6_m6sSefl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def evaluate(model, train_data, seq_train_data,\n",
        "             test_batch_size, top_k,\n",
        "             viewed_items, interactions,\n",
        "             device, test_step):\n",
        "    \"\"\"\n",
        "    Оцениваем модель по всем пользователям:\n",
        "    - строим топ-K рекомендации\n",
        "    - фильтруем уже просмотренные\n",
        "    - считаем recall@K, precision@K, map@K\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    seq_ids, event_type, seq_times, seq_mask = seq_train_data\n",
        "    num_users = seq_ids.size(0)\n",
        "    test_top_k = top_k * 150\n",
        "\n",
        "    item_emb = model.gnn.item_emb.weight\n",
        "    num_items = item_emb.shape[0]\n",
        "    item_emb_t = item_emb.t().detach()\n",
        "    del item_emb\n",
        "    gc.collect()\n",
        "\n",
        "    all_scores = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, num_users, test_batch_size):\n",
        "            end = min(i + test_batch_size, num_users)\n",
        "            batch_users = torch.arange(i, end).to(device)\n",
        "            s_ids   = seq_ids[i:end].to(device)\n",
        "            s_times = seq_times[i:end].to(device)\n",
        "            s_mask  = seq_mask[i:end].to(device)\n",
        "            user_e, polar = model(\n",
        "                data=train_data.to(device),\n",
        "                seq_ids=s_ids,\n",
        "                seq_times=s_times,\n",
        "                seq_mask=s_mask,\n",
        "                batch_users=batch_users\n",
        "            )\n",
        "            rating = torch.mm(user_e.detach(), item_emb_t)\n",
        "            _, topk = torch.topk(rating, k=test_top_k, dim=1)\n",
        "            all_scores.append(topk)\n",
        "\n",
        "            del user_e, rating\n",
        "            gc.collect()\n",
        "    all_scores = torch.cat(all_scores, dim=0).cpu().numpy()\n",
        "\n",
        "    users_list, items, ranks = [], [], []\n",
        "    for u in range(num_users):\n",
        "        seen = viewed_items.get(u, set())\n",
        "        recs = all_scores[u]\n",
        "        mask = (\n",
        "            (~np.isin(recs, list(seen)))\n",
        "            & (recs != 0)\n",
        "            & (recs != num_items - 1)\n",
        "            )\n",
        "        filtered = recs[mask][:top_k]\n",
        "        for rank, it in enumerate(filtered, 1):\n",
        "            users_list.append(u)\n",
        "            items.append(int(it))\n",
        "            ranks.append(rank)\n",
        "    reco_df = pd.DataFrame({\n",
        "        'user_id': users_list,\n",
        "        'item_id': items,\n",
        "        'rank': ranks\n",
        "    })\n",
        "\n",
        "    metrics = {\n",
        "        f'map@{top_k}': MAP(k=top_k),\n",
        "        f'precision@{top_k}': Precision(k=top_k),\n",
        "        f'recall@{top_k}': Recall(k=top_k),\n",
        "        f'ndcg@{top_k}': NDCG(k=top_k)\n",
        "    }\n",
        "    results = calc_metrics(metrics=metrics,\n",
        "                           reco=reco_df,\n",
        "                           interactions=interactions)\n",
        "    print(f\"Step {test_step} — Test metrics:\")\n",
        "    for name, val in results.items():\n",
        "        print(f\"  {name}: {val:.9f}\")\n",
        "        experiment.log_metric(f\"Test {name} vs step\", val, step=test_step)\n",
        "    del all_scores\n",
        "    gc.collect()\n",
        "\n",
        "    model.to(device)\n",
        "    train_data.to(device)\n",
        "    model.train()\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:51.081337Z",
          "iopub.status.busy": "2025-06-24T18:34:51.081087Z",
          "iopub.status.idle": "2025-06-24T18:34:51.109149Z",
          "shell.execute_reply": "2025-06-24T18:34:51.108343Z",
          "shell.execute_reply.started": "2025-06-24T18:34:51.081318Z"
        },
        "id": "gRqlodsqSefl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_model(model,\n",
        "                train_data: HeteroData,\n",
        "                seq_train_data: tuple,\n",
        "                edge_type: tuple,\n",
        "                num_epochs: int = 10,\n",
        "                lr: float = 1e-3,\n",
        "                batch_size: int = 1024,\n",
        "                device: str = None,\n",
        "                print_every: int = 100,\n",
        "                test_every: int = 500,\n",
        "                top_k: int = 10,\n",
        "                test_batch_size=2048,\n",
        "                scheduler_step_size: int = 1,\n",
        "                scheduler_gamma: float = 0.9) -> Model:\n",
        "    seq_ids, event_type, seq_times, seq_mask = seq_train_data\n",
        "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    train_data = train_data.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = StepLR(optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma)\n",
        "\n",
        "    if isinstance(edge_type, list):\n",
        "        src_list, dst_list = [], []\n",
        "        for et in edge_type:\n",
        "            # print(et, train_data[et])\n",
        "            s, d = train_data[et].edge_index\n",
        "            src_list.append(s)\n",
        "            dst_list.append(d)\n",
        "        src = torch.cat(src_list, dim=0)\n",
        "        dst = torch.cat(dst_list, dim=0)\n",
        "    else:\n",
        "        src, dst = train_data[edge_type].edge_index\n",
        "\n",
        "    num_train = src.size(0)\n",
        "    test_top_k = top_k * 150\n",
        "    total_steps = 5942\n",
        "\n",
        "    print(f\"Num of training examples: {num_train}\")\n",
        "    for epoch in range(251, 501):\n",
        "        model.train()\n",
        "        perm = torch.randperm(num_train, device=device)\n",
        "        total_loss = 0.0\n",
        "        running_loss = 0.0\n",
        "        running_steps = 0\n",
        "        step = 0\n",
        "\n",
        "        for i in range(0, num_train, batch_size):\n",
        "            idx = perm[i:i + batch_size]\n",
        "            users = dst[idx]\n",
        "            cpu_users = users.to('cpu')\n",
        "\n",
        "            seq_ids_batch = seq_ids[cpu_users, :-1].to(device)\n",
        "            seq_times_batch = seq_times[cpu_users, :-1].to(device)\n",
        "            seq_mask_batch = seq_mask[cpu_users, :-1].to(device)\n",
        "            true_evt  = event_type[cpu_users, -1].to(device)\n",
        "\n",
        "            pos_items = src[idx]\n",
        "            neg_items = torch.randint(1, model.gnn.item_emb.num_embeddings - 1,\n",
        "                                      size=pos_items.size(), device=device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            user_embs, event_logits = model(data=train_data,\n",
        "                              seq_ids=seq_ids_batch,\n",
        "                              seq_times=seq_times_batch,\n",
        "                              seq_mask=seq_mask_batch,\n",
        "                              batch_users=users)\n",
        "\n",
        "            pos_emb = model.gnn.item_emb(pos_items)\n",
        "            neg_emb = model.gnn.item_emb(neg_items)\n",
        "            pos_score = (user_embs * pos_emb).sum(dim=1)\n",
        "            neg_score = (user_embs * neg_emb).sum(dim=1)\n",
        "            diff = pos_score - neg_score\n",
        "            diff = torch.clamp(diff, -10.0, 10.0)\n",
        "            ce_loss = F.cross_entropy(event_logits, true_evt)\n",
        "            bpr_loss = -torch.log(torch.sigmoid(diff) + 1e-15).mean()\n",
        "\n",
        "            loss = bpr_loss + ce_loss\n",
        "\n",
        "            nan_mask = torch.isnan(diff)\n",
        "            if nan_mask.any():\n",
        "                idxs = torch.nonzero(nan_mask).squeeze()\n",
        "                print(f\"!!! FOUND {nan_mask.sum().item()} NaN(s) in diff at positions: {idxs.tolist()}\")\n",
        "\n",
        "            # with torch.autograd.detect_anomaly():\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            running_loss += loss.item()\n",
        "            running_steps += 1\n",
        "            step += 1\n",
        "\n",
        "            experiment.log_metric('Train Loss vs step', loss.item(), step=total_steps)\n",
        "            experiment.log_metric('Train CE Loss vs step', ce_loss.item(), step=total_steps)\n",
        "            experiment.log_metric('Train BPR Loss vs step', bpr_loss.item(), step=total_steps)\n",
        "\n",
        "            if step % print_every == 0 or step == 1:\n",
        "                avg_loss = running_loss / running_steps\n",
        "                current_lr = optimizer.param_groups[0]['lr']\n",
        "                d = diff.detach().cpu()\n",
        "                print(f\"Epoch {epoch}, Step {step}, LR: {current_lr:.6f}, Current Loss: {loss.item():.4f}, Avg Loss: {avg_loss:.4f}\")\n",
        "                print(f\"Diff stats — min: {d.min():.4f}, max: {d.max():.4f}, mean: {d.mean():.4f}, std: {d.std():.4f}\")\n",
        "                print()\n",
        "\n",
        "                experiment.log_metric('Diff stats (mean) vs step', d.mean(), step=total_steps)\n",
        "                experiment.log_metric('Diff stats (std) vs step', d.std(), step=total_steps)\n",
        "\n",
        "            del user_embs, pos_emb, neg_emb, pos_score, neg_score,\\\n",
        "            seq_ids_batch, seq_times_batch, seq_mask_batch\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            if step % test_every == 0 or step == 1:\n",
        "                evaluate(model, train_data, seq_train_data,\n",
        "                         test_batch_size, top_k,\n",
        "                         viewed_items, interactions,\n",
        "                         device, test_step=total_steps)\n",
        "\n",
        "            total_steps += 1\n",
        "        epoch_loss = total_loss / num_train\n",
        "        experiment.log_metric(f'Train Loss vs epoch', epoch_loss, epoch=epoch)\n",
        "        print(f\"Epoch {epoch} completed, Train Loss: {epoch_loss:.6f}\")\n",
        "        print()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:51.110131Z",
          "iopub.status.busy": "2025-06-24T18:34:51.109882Z",
          "iopub.status.idle": "2025-06-24T18:34:51.315385Z",
          "shell.execute_reply": "2025-06-24T18:34:51.314691Z",
          "shell.execute_reply.started": "2025-06-24T18:34:51.110103Z"
        },
        "id": "Uu3fztn5Sefl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "experiment.log_parameters(hyperparameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:51.316441Z",
          "iopub.status.busy": "2025-06-24T18:34:51.316188Z",
          "iopub.status.idle": "2025-06-24T18:34:51.320734Z",
          "shell.execute_reply": "2025-06-24T18:34:51.319902Z",
          "shell.execute_reply.started": "2025-06-24T18:34:51.316422Z"
        },
        "id": "sFMh2aDYSefl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-24T18:34:51.321752Z",
          "iopub.status.busy": "2025-06-24T18:34:51.321498Z"
        },
        "id": "ixoYHqhKSefl",
        "outputId": "fcad8302-fb1c-48ba-b9a6-5100e15047e9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of training examples: 121468\n",
            "Epoch 1, Step 1, LR: 0.001000, Current Loss: 4.3589, Avg Loss: 4.3589\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: -0.0829, std: 8.2042\n",
            "\n",
            "Step 0 — Test metrics:\n",
            "  precision@10: 0.000730787\n",
            "  recall@10: 0.000730787\n",
            "  ndcg@10: 0.000698116\n",
            "  map@10: 0.000197692\n",
            "Epoch 1, Step 20, LR: 0.001000, Current Loss: 3.5961, Avg Loss: 3.9438\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 0.6211, std: 7.5720\n",
            "\n",
            "Epoch 1 completed, Train Loss: 0.000923\n",
            "\n",
            "Epoch 2, Step 1, LR: 0.001000, Current Loss: 3.0165, Avg Loss: 3.0165\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 1.2879, std: 7.0173\n",
            "\n",
            "Step 30 — Test metrics:\n",
            "  precision@10: 0.000942951\n",
            "  recall@10: 0.000942951\n",
            "  ndcg@10: 0.000842557\n",
            "  map@10: 0.000216926\n",
            "Epoch 2, Step 20, LR: 0.001000, Current Loss: 2.1306, Avg Loss: 2.5770\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 1.9188, std: 5.6895\n",
            "\n",
            "Epoch 2 completed, Train Loss: 0.000587\n",
            "\n",
            "Epoch 3, Step 1, LR: 0.001000, Current Loss: 1.8635, Avg Loss: 1.8635\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 1.9951, std: 5.1662\n",
            "\n",
            "Step 60 — Test metrics:\n",
            "  precision@10: 0.000848656\n",
            "  recall@10: 0.000848656\n",
            "  ndcg@10: 0.000750978\n",
            "  map@10: 0.000192080\n",
            "Epoch 3, Step 20, LR: 0.001000, Current Loss: 1.3980, Avg Loss: 1.6163\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 2.4430, std: 4.3152\n",
            "\n",
            "Epoch 3 completed, Train Loss: 0.000379\n",
            "\n",
            "Epoch 4, Step 1, LR: 0.001000, Current Loss: 1.3096, Avg Loss: 1.3096\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 2.4151, std: 4.0714\n",
            "\n",
            "Step 90 — Test metrics:\n",
            "  precision@10: 0.000919378\n",
            "  recall@10: 0.000919378\n",
            "  ndcg@10: 0.000859876\n",
            "  map@10: 0.000237946\n",
            "Epoch 4, Step 20, LR: 0.001000, Current Loss: 1.1905, Avg Loss: 1.2395\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 2.4812, std: 3.7798\n",
            "\n",
            "Epoch 4 completed, Train Loss: 0.000297\n",
            "\n",
            "Epoch 5, Step 1, LR: 0.001000, Current Loss: 1.0950, Avg Loss: 1.0950\n",
            "Diff stats — min: -9.4620, max: 10.0000, mean: 2.6684, std: 3.6361\n",
            "\n",
            "Step 120 — Test metrics:\n",
            "  precision@10: 0.000966525\n",
            "  recall@10: 0.000966525\n",
            "  ndcg@10: 0.000918217\n",
            "  map@10: 0.000255168\n",
            "Epoch 5, Step 20, LR: 0.001000, Current Loss: 1.0456, Avg Loss: 1.0665\n",
            "Diff stats — min: -9.9695, max: 10.0000, mean: 2.5401, std: 3.4290\n",
            "\n",
            "Epoch 5 completed, Train Loss: 0.000259\n",
            "\n",
            "Epoch 6, Step 1, LR: 0.000980, Current Loss: 0.9974, Avg Loss: 0.9974\n",
            "Diff stats — min: -9.2440, max: 10.0000, mean: 2.7571, std: 3.3803\n",
            "\n",
            "Step 150 — Test metrics:\n",
            "  precision@10: 0.000872230\n",
            "  recall@10: 0.000872230\n",
            "  ndcg@10: 0.000917908\n",
            "  map@10: 0.000282736\n",
            "Epoch 6, Step 20, LR: 0.000980, Current Loss: 0.9239, Avg Loss: 0.9683\n",
            "Diff stats — min: -9.2663, max: 10.0000, mean: 2.8076, std: 3.2531\n",
            "\n",
            "Epoch 6 completed, Train Loss: 0.000237\n",
            "\n",
            "Epoch 7, Step 1, LR: 0.000980, Current Loss: 0.8978, Avg Loss: 0.8978\n",
            "Diff stats — min: -7.3975, max: 10.0000, mean: 2.9104, std: 3.2344\n",
            "\n",
            "Step 180 — Test metrics:\n",
            "  precision@10: 0.000895804\n",
            "  recall@10: 0.000895804\n",
            "  ndcg@10: 0.000907084\n",
            "  map@10: 0.000269929\n",
            "Epoch 7, Step 20, LR: 0.000980, Current Loss: 0.8641, Avg Loss: 0.9079\n",
            "Diff stats — min: -7.4276, max: 10.0000, mean: 2.9727, std: 3.1224\n",
            "\n",
            "Epoch 7 completed, Train Loss: 0.000223\n",
            "\n",
            "Epoch 8, Step 1, LR: 0.000980, Current Loss: 0.8812, Avg Loss: 0.8812\n",
            "Diff stats — min: -7.9213, max: 10.0000, mean: 2.9119, std: 3.1277\n",
            "\n",
            "Step 210 — Test metrics:\n",
            "  precision@10: 0.000825083\n",
            "  recall@10: 0.000825083\n",
            "  ndcg@10: 0.000887964\n",
            "  map@10: 0.000277694\n",
            "Epoch 8, Step 20, LR: 0.000980, Current Loss: 0.8673, Avg Loss: 0.8663\n",
            "Diff stats — min: -6.6377, max: 10.0000, mean: 2.9884, std: 3.0854\n",
            "\n",
            "Epoch 8 completed, Train Loss: 0.000213\n",
            "\n",
            "Epoch 9, Step 1, LR: 0.000980, Current Loss: 0.8323, Avg Loss: 0.8323\n",
            "Diff stats — min: -6.7508, max: 10.0000, mean: 2.9419, std: 2.9999\n",
            "\n",
            "Step 240 — Test metrics:\n",
            "  precision@10: 0.000848656\n",
            "  recall@10: 0.000848656\n",
            "  ndcg@10: 0.000884916\n",
            "  map@10: 0.000270631\n",
            "Epoch 9, Step 20, LR: 0.000980, Current Loss: 0.8180, Avg Loss: 0.8378\n",
            "Diff stats — min: -8.9231, max: 10.0000, mean: 3.0357, std: 3.0517\n",
            "\n",
            "Epoch 9 completed, Train Loss: 0.000207\n",
            "\n",
            "Epoch 10, Step 1, LR: 0.000980, Current Loss: 0.8363, Avg Loss: 0.8363\n",
            "Diff stats — min: -6.9324, max: 10.0000, mean: 3.0428, std: 3.0663\n",
            "\n",
            "Step 270 — Test metrics:\n",
            "  precision@10: 0.000801509\n",
            "  recall@10: 0.000801509\n",
            "  ndcg@10: 0.000866833\n",
            "  map@10: 0.000277114\n",
            "Epoch 10, Step 20, LR: 0.000980, Current Loss: 0.8139, Avg Loss: 0.8143\n",
            "Diff stats — min: -7.2411, max: 10.0000, mean: 3.1042, std: 2.9659\n",
            "\n",
            "Epoch 10 completed, Train Loss: 0.000200\n",
            "\n",
            "Epoch 11, Step 1, LR: 0.000960, Current Loss: 0.7968, Avg Loss: 0.7968\n",
            "Diff stats — min: -8.2589, max: 10.0000, mean: 3.1995, std: 2.9167\n",
            "\n",
            "Step 300 — Test metrics:\n",
            "  precision@10: 0.000777935\n",
            "  recall@10: 0.000777935\n",
            "  ndcg@10: 0.000867935\n",
            "  map@10: 0.000278620\n",
            "Epoch 11, Step 20, LR: 0.000960, Current Loss: 0.7704, Avg Loss: 0.7916\n",
            "Diff stats — min: -6.6659, max: 10.0000, mean: 3.1561, std: 2.8926\n",
            "\n",
            "Epoch 11 completed, Train Loss: 0.000195\n",
            "\n",
            "Epoch 12, Step 1, LR: 0.000960, Current Loss: 0.7725, Avg Loss: 0.7725\n",
            "Diff stats — min: -5.6000, max: 10.0000, mean: 3.2633, std: 2.9387\n",
            "\n",
            "Step 330 — Test metrics:\n",
            "  precision@10: 0.000825083\n",
            "  recall@10: 0.000825083\n",
            "  ndcg@10: 0.000928744\n",
            "  map@10: 0.000304579\n",
            "Epoch 12, Step 20, LR: 0.000960, Current Loss: 0.7852, Avg Loss: 0.7819\n",
            "Diff stats — min: -6.5718, max: 10.0000, mean: 3.2044, std: 2.8906\n",
            "\n",
            "Epoch 12 completed, Train Loss: 0.000192\n",
            "\n",
            "Epoch 13, Step 1, LR: 0.000960, Current Loss: 0.7524, Avg Loss: 0.7524\n",
            "Diff stats — min: -5.3194, max: 10.0000, mean: 3.3030, std: 2.9179\n",
            "\n",
            "Step 360 — Test metrics:\n",
            "  precision@10: 0.000848656\n",
            "  recall@10: 0.000848656\n",
            "  ndcg@10: 0.000927473\n",
            "  map@10: 0.000294401\n",
            "Epoch 13, Step 20, LR: 0.000960, Current Loss: 0.7658, Avg Loss: 0.7588\n",
            "Diff stats — min: -6.1248, max: 10.0000, mean: 3.2486, std: 2.9389\n",
            "\n",
            "Epoch 13 completed, Train Loss: 0.000188\n",
            "\n",
            "Epoch 14, Step 1, LR: 0.000960, Current Loss: 0.7748, Avg Loss: 0.7748\n",
            "Diff stats — min: -7.5009, max: 10.0000, mean: 3.2370, std: 2.9216\n",
            "\n",
            "Step 390 — Test metrics:\n",
            "  precision@10: 0.000801509\n",
            "  recall@10: 0.000801509\n",
            "  ndcg@10: 0.000921482\n",
            "  map@10: 0.000303681\n",
            "Epoch 14, Step 20, LR: 0.000960, Current Loss: 0.7421, Avg Loss: 0.7509\n",
            "Diff stats — min: -7.0725, max: 10.0000, mean: 3.3548, std: 2.8940\n",
            "\n",
            "Epoch 14 completed, Train Loss: 0.000186\n",
            "\n",
            "Epoch 15, Step 1, LR: 0.000960, Current Loss: 0.7500, Avg Loss: 0.7500\n",
            "Diff stats — min: -5.8408, max: 10.0000, mean: 3.3571, std: 2.8962\n",
            "\n",
            "Step 420 — Test metrics:\n",
            "  precision@10: 0.000848656\n",
            "  recall@10: 0.000848656\n",
            "  ndcg@10: 0.000973289\n",
            "  map@10: 0.000321866\n",
            "Epoch 15, Step 20, LR: 0.000960, Current Loss: 0.7520, Avg Loss: 0.7418\n",
            "Diff stats — min: -6.1634, max: 10.0000, mean: 3.3894, std: 2.9086\n",
            "\n",
            "Epoch 15 completed, Train Loss: 0.000183\n",
            "\n",
            "Epoch 16, Step 1, LR: 0.000941, Current Loss: 0.7437, Avg Loss: 0.7437\n",
            "Diff stats — min: -7.7453, max: 10.0000, mean: 3.4695, std: 2.9209\n",
            "\n",
            "Step 450 — Test metrics:\n",
            "  precision@10: 0.000777935\n",
            "  recall@10: 0.000777935\n",
            "  ndcg@10: 0.000927714\n",
            "  map@10: 0.000314570\n",
            "Epoch 16, Step 20, LR: 0.000941, Current Loss: 0.7297, Avg Loss: 0.7362\n",
            "Diff stats — min: -6.4944, max: 10.0000, mean: 3.4291, std: 2.8671\n",
            "\n",
            "Epoch 16 completed, Train Loss: 0.000181\n",
            "\n",
            "Epoch 17, Step 1, LR: 0.000941, Current Loss: 0.7177, Avg Loss: 0.7177\n",
            "Diff stats — min: -4.9395, max: 10.0000, mean: 3.4976, std: 2.8612\n",
            "\n",
            "Step 480 — Test metrics:\n",
            "  precision@10: 0.000801509\n",
            "  recall@10: 0.000801509\n",
            "  ndcg@10: 0.000961778\n",
            "  map@10: 0.000327199\n",
            "Epoch 17, Step 20, LR: 0.000941, Current Loss: 0.7392, Avg Loss: 0.7252\n",
            "Diff stats — min: -7.2517, max: 10.0000, mean: 3.4985, std: 2.9410\n",
            "\n",
            "Epoch 17 completed, Train Loss: 0.000179\n",
            "\n",
            "Epoch 18, Step 1, LR: 0.000941, Current Loss: 0.7335, Avg Loss: 0.7335\n",
            "Diff stats — min: -7.9057, max: 10.0000, mean: 3.5250, std: 2.9304\n",
            "\n",
            "Step 510 — Test metrics:\n",
            "  precision@10: 0.000872230\n",
            "  recall@10: 0.000872230\n",
            "  ndcg@10: 0.000987943\n",
            "  map@10: 0.000323344\n",
            "Epoch 18, Step 20, LR: 0.000941, Current Loss: 0.7201, Avg Loss: 0.7205\n",
            "Diff stats — min: -5.7589, max: 10.0000, mean: 3.5524, std: 2.9200\n",
            "\n",
            "Epoch 18 completed, Train Loss: 0.000177\n",
            "\n",
            "Epoch 19, Step 1, LR: 0.000941, Current Loss: 0.7101, Avg Loss: 0.7101\n",
            "Diff stats — min: -6.8236, max: 10.0000, mean: 3.6106, std: 2.8913\n",
            "\n",
            "Step 540 — Test metrics:\n",
            "  precision@10: 0.000801509\n",
            "  recall@10: 0.000801509\n",
            "  ndcg@10: 0.000987616\n",
            "  map@10: 0.000343990\n",
            "Epoch 19, Step 20, LR: 0.000941, Current Loss: 0.7132, Avg Loss: 0.7146\n",
            "Diff stats — min: -5.8541, max: 10.0000, mean: 3.6622, std: 2.8895\n",
            "\n",
            "Epoch 19 completed, Train Loss: 0.000176\n",
            "\n",
            "Epoch 20, Step 1, LR: 0.000941, Current Loss: 0.7201, Avg Loss: 0.7201\n",
            "Diff stats — min: -5.3349, max: 10.0000, mean: 3.6679, std: 2.8715\n",
            "\n",
            "Step 570 — Test metrics:\n",
            "  precision@10: 0.000801509\n",
            "  recall@10: 0.000801509\n",
            "  ndcg@10: 0.000927497\n",
            "  map@10: 0.000308414\n",
            "Epoch 20, Step 20, LR: 0.000941, Current Loss: 0.6954, Avg Loss: 0.7077\n",
            "Diff stats — min: -5.8773, max: 10.0000, mean: 3.6208, std: 2.8801\n",
            "\n",
            "Epoch 20 completed, Train Loss: 0.000174\n",
            "\n",
            "Epoch 21, Step 1, LR: 0.000922, Current Loss: 0.6836, Avg Loss: 0.6836\n",
            "Diff stats — min: -7.5086, max: 10.0000, mean: 3.7561, std: 2.8484\n",
            "\n",
            "Step 600 — Test metrics:\n",
            "  precision@10: 0.000919378\n",
            "  recall@10: 0.000919378\n",
            "  ndcg@10: 0.000944686\n",
            "  map@10: 0.000283044\n",
            "Epoch 21, Step 20, LR: 0.000922, Current Loss: 0.7112, Avg Loss: 0.6977\n",
            "Diff stats — min: -5.8443, max: 10.0000, mean: 3.6615, std: 2.9251\n",
            "\n",
            "Epoch 21 completed, Train Loss: 0.000172\n",
            "\n",
            "Epoch 22, Step 1, LR: 0.000922, Current Loss: 0.6829, Avg Loss: 0.6829\n",
            "Diff stats — min: -7.2231, max: 10.0000, mean: 3.6622, std: 2.8501\n",
            "\n",
            "Step 630 — Test metrics:\n",
            "  precision@10: 0.000895804\n",
            "  recall@10: 0.000895804\n",
            "  ndcg@10: 0.001033970\n",
            "  map@10: 0.000342746\n",
            "Epoch 22, Step 20, LR: 0.000922, Current Loss: 0.6824, Avg Loss: 0.6944\n",
            "Diff stats — min: -7.1774, max: 10.0000, mean: 3.7382, std: 2.9257\n",
            "\n",
            "Epoch 22 completed, Train Loss: 0.000171\n",
            "\n",
            "Epoch 23, Step 1, LR: 0.000922, Current Loss: 0.6850, Avg Loss: 0.6850\n",
            "Diff stats — min: -6.4446, max: 10.0000, mean: 3.8174, std: 2.9386\n",
            "\n",
            "Step 660 — Test metrics:\n",
            "  precision@10: 0.000966525\n",
            "  recall@10: 0.000966525\n",
            "  ndcg@10: 0.001124420\n",
            "  map@10: 0.000376610\n",
            "Epoch 23, Step 20, LR: 0.000922, Current Loss: 0.6900, Avg Loss: 0.6889\n",
            "Diff stats — min: -7.4467, max: 10.0000, mean: 3.8195, std: 2.9453\n",
            "\n",
            "Epoch 23 completed, Train Loss: 0.000170\n",
            "\n",
            "Epoch 24, Step 1, LR: 0.000922, Current Loss: 0.6822, Avg Loss: 0.6822\n",
            "Diff stats — min: -6.7068, max: 10.0000, mean: 3.8392, std: 2.9245\n",
            "\n",
            "Step 690 — Test metrics:\n",
            "  precision@10: 0.000919378\n",
            "  recall@10: 0.000919378\n",
            "  ndcg@10: 0.000994745\n",
            "  map@10: 0.000313138\n",
            "Epoch 24, Step 20, LR: 0.000922, Current Loss: 0.6956, Avg Loss: 0.6838\n",
            "Diff stats — min: -5.3041, max: 10.0000, mean: 3.8509, std: 3.0181\n",
            "\n",
            "Epoch 24 completed, Train Loss: 0.000169\n",
            "\n",
            "Epoch 25, Step 1, LR: 0.000922, Current Loss: 0.6815, Avg Loss: 0.6815\n",
            "Diff stats — min: -5.6326, max: 10.0000, mean: 3.8924, std: 2.9467\n",
            "\n",
            "Step 720 — Test metrics:\n",
            "  precision@10: 0.000966525\n",
            "  recall@10: 0.000966525\n",
            "  ndcg@10: 0.001029770\n",
            "  map@10: 0.000321801\n",
            "Epoch 25, Step 20, LR: 0.000922, Current Loss: 0.6880, Avg Loss: 0.6769\n",
            "Diff stats — min: -8.8952, max: 10.0000, mean: 3.9379, std: 2.9766\n",
            "\n",
            "Epoch 25 completed, Train Loss: 0.000168\n",
            "\n",
            "Epoch 26, Step 1, LR: 0.000904, Current Loss: 0.6716, Avg Loss: 0.6716\n",
            "Diff stats — min: -5.8410, max: 10.0000, mean: 4.0079, std: 2.9257\n",
            "\n",
            "Step 750 — Test metrics:\n",
            "  precision@10: 0.000966525\n",
            "  recall@10: 0.000966525\n",
            "  ndcg@10: 0.001098443\n",
            "  map@10: 0.000360295\n",
            "Epoch 26, Step 20, LR: 0.000904, Current Loss: 0.6835, Avg Loss: 0.6777\n",
            "Diff stats — min: -4.8363, max: 10.0000, mean: 3.9649, std: 2.9494\n",
            "\n",
            "Epoch 26 completed, Train Loss: 0.000167\n",
            "\n",
            "Epoch 27, Step 1, LR: 0.000904, Current Loss: 0.6825, Avg Loss: 0.6825\n",
            "Diff stats — min: -9.8983, max: 10.0000, mean: 3.9843, std: 3.0031\n",
            "\n",
            "Step 780 — Test metrics:\n",
            "  precision@10: 0.000895804\n",
            "  recall@10: 0.000895804\n",
            "  ndcg@10: 0.000998905\n",
            "  map@10: 0.000321071\n",
            "Epoch 27, Step 20, LR: 0.000904, Current Loss: 0.6764, Avg Loss: 0.6780\n",
            "Diff stats — min: -5.5070, max: 10.0000, mean: 4.0221, std: 2.9783\n",
            "\n",
            "Epoch 27 completed, Train Loss: 0.000167\n",
            "\n",
            "Epoch 28, Step 1, LR: 0.000904, Current Loss: 0.6815, Avg Loss: 0.6815\n",
            "Diff stats — min: -7.0613, max: 10.0000, mean: 3.9989, std: 2.9767\n",
            "\n",
            "Step 810 — Test metrics:\n",
            "  precision@10: 0.000942951\n",
            "  recall@10: 0.000942951\n",
            "  ndcg@10: 0.001013915\n",
            "  map@10: 0.000315178\n",
            "Epoch 28, Step 20, LR: 0.000904, Current Loss: 0.6742, Avg Loss: 0.6707\n",
            "Diff stats — min: -6.0331, max: 10.0000, mean: 4.0043, std: 2.9696\n",
            "\n",
            "Epoch 28 completed, Train Loss: 0.000166\n",
            "\n",
            "Epoch 29, Step 1, LR: 0.000904, Current Loss: 0.6730, Avg Loss: 0.6730\n",
            "Diff stats — min: -5.5559, max: 10.0000, mean: 4.1599, std: 2.9922\n",
            "\n",
            "Step 840 — Test metrics:\n",
            "  precision@10: 0.001037247\n",
            "  recall@10: 0.001037247\n",
            "  ndcg@10: 0.001140937\n",
            "  map@10: 0.000365225\n",
            "Epoch 29, Step 20, LR: 0.000904, Current Loss: 0.6491, Avg Loss: 0.6655\n",
            "Diff stats — min: -5.3579, max: 10.0000, mean: 4.1881, std: 2.9317\n",
            "\n",
            "Epoch 29 completed, Train Loss: 0.000164\n",
            "\n",
            "Epoch 30, Step 1, LR: 0.000904, Current Loss: 0.6691, Avg Loss: 0.6691\n",
            "Diff stats — min: -5.8234, max: 10.0000, mean: 4.1780, std: 3.0281\n",
            "\n",
            "Step 870 — Test metrics:\n",
            "  precision@10: 0.000942951\n",
            "  recall@10: 0.000942951\n",
            "  ndcg@10: 0.001101767\n",
            "  map@10: 0.000367985\n",
            "Epoch 30, Step 20, LR: 0.000904, Current Loss: 0.6610, Avg Loss: 0.6637\n",
            "Diff stats — min: -6.6767, max: 10.0000, mean: 4.2213, std: 2.9650\n",
            "\n",
            "Epoch 30 completed, Train Loss: 0.000164\n",
            "\n",
            "Epoch 31, Step 1, LR: 0.000886, Current Loss: 0.6663, Avg Loss: 0.6663\n",
            "Diff stats — min: -6.9754, max: 10.0000, mean: 4.1217, std: 2.9981\n",
            "\n",
            "Step 900 — Test metrics:\n",
            "  precision@10: 0.000919378\n",
            "  recall@10: 0.000919378\n",
            "  ndcg@10: 0.001104217\n",
            "  map@10: 0.000374028\n",
            "Epoch 31, Step 20, LR: 0.000886, Current Loss: 0.6654, Avg Loss: 0.6602\n",
            "Diff stats — min: -7.5627, max: 10.0000, mean: 4.2068, std: 2.9783\n",
            "\n",
            "Epoch 31 completed, Train Loss: 0.000163\n",
            "\n",
            "Epoch 32, Step 1, LR: 0.000886, Current Loss: 0.6474, Avg Loss: 0.6474\n",
            "Diff stats — min: -6.5157, max: 10.0000, mean: 4.1441, std: 2.9876\n",
            "\n",
            "Step 930 — Test metrics:\n",
            "  precision@10: 0.001013673\n",
            "  recall@10: 0.001013673\n",
            "  ndcg@10: 0.001167278\n",
            "  map@10: 0.000384749\n",
            "Epoch 32, Step 20, LR: 0.000886, Current Loss: 0.6586, Avg Loss: 0.6606\n",
            "Diff stats — min: -8.1627, max: 10.0000, mean: 4.2119, std: 3.0297\n",
            "\n",
            "Epoch 32 completed, Train Loss: 0.000163\n",
            "\n",
            "Epoch 33, Step 1, LR: 0.000886, Current Loss: 0.6662, Avg Loss: 0.6662\n",
            "Diff stats — min: -5.4718, max: 10.0000, mean: 4.2247, std: 3.0636\n",
            "\n",
            "Step 960 — Test metrics:\n",
            "  precision@10: 0.001060820\n",
            "  recall@10: 0.001060820\n",
            "  ndcg@10: 0.001253806\n",
            "  map@10: 0.000419866\n",
            "Epoch 33, Step 20, LR: 0.000886, Current Loss: 0.6555, Avg Loss: 0.6540\n",
            "Diff stats — min: -5.9075, max: 10.0000, mean: 4.3252, std: 3.0094\n",
            "\n",
            "Epoch 33 completed, Train Loss: 0.000162\n",
            "\n",
            "Epoch 34, Step 1, LR: 0.000886, Current Loss: 0.6621, Avg Loss: 0.6621\n",
            "Diff stats — min: -6.8191, max: 10.0000, mean: 4.2147, std: 2.9601\n",
            "\n",
            "Step 990 — Test metrics:\n",
            "  precision@10: 0.001037247\n",
            "  recall@10: 0.001037247\n",
            "  ndcg@10: 0.001167755\n",
            "  map@10: 0.000378612\n",
            "Epoch 34, Step 20, LR: 0.000886, Current Loss: 0.6474, Avg Loss: 0.6515\n",
            "Diff stats — min: -5.8104, max: 10.0000, mean: 4.4403, std: 3.0247\n",
            "\n",
            "Epoch 34 completed, Train Loss: 0.000161\n",
            "\n",
            "Epoch 35, Step 1, LR: 0.000886, Current Loss: 0.6413, Avg Loss: 0.6413\n",
            "Diff stats — min: -5.5905, max: 10.0000, mean: 4.4563, std: 3.0327\n",
            "\n",
            "Step 1020 — Test metrics:\n",
            "  precision@10: 0.001013673\n",
            "  recall@10: 0.001013673\n",
            "  ndcg@10: 0.001196314\n",
            "  map@10: 0.000401858\n",
            "Epoch 35, Step 20, LR: 0.000886, Current Loss: 0.6467, Avg Loss: 0.6475\n",
            "Diff stats — min: -5.9500, max: 10.0000, mean: 4.3739, std: 3.0123\n",
            "\n",
            "Epoch 35 completed, Train Loss: 0.000160\n",
            "\n",
            "Epoch 36, Step 1, LR: 0.000868, Current Loss: 0.6486, Avg Loss: 0.6486\n",
            "Diff stats — min: -8.0273, max: 10.0000, mean: 4.4355, std: 3.0380\n",
            "\n",
            "Step 1050 — Test metrics:\n",
            "  precision@10: 0.001178689\n",
            "  recall@10: 0.001178689\n",
            "  ndcg@10: 0.001347781\n",
            "  map@10: 0.000443430\n",
            "Epoch 36, Step 20, LR: 0.000868, Current Loss: 0.6451, Avg Loss: 0.6462\n",
            "Diff stats — min: -5.2140, max: 10.0000, mean: 4.4127, std: 3.0142\n",
            "\n",
            "Epoch 36 completed, Train Loss: 0.000160\n",
            "\n",
            "Epoch 37, Step 1, LR: 0.000868, Current Loss: 0.6588, Avg Loss: 0.6588\n",
            "Diff stats — min: -7.2249, max: 10.0000, mean: 4.4491, std: 3.0435\n",
            "\n",
            "Step 1080 — Test metrics:\n",
            "  precision@10: 0.001202263\n",
            "  recall@10: 0.001202263\n",
            "  ndcg@10: 0.001394175\n",
            "  map@10: 0.000465264\n",
            "Epoch 37, Step 20, LR: 0.000868, Current Loss: 0.6438, Avg Loss: 0.6452\n",
            "Diff stats — min: -6.4867, max: 10.0000, mean: 4.4653, std: 3.0173\n",
            "\n",
            "Epoch 37 completed, Train Loss: 0.000159\n",
            "\n",
            "Epoch 38, Step 1, LR: 0.000868, Current Loss: 0.6333, Avg Loss: 0.6333\n",
            "Diff stats — min: -5.3411, max: 10.0000, mean: 4.5285, std: 3.0463\n",
            "\n",
            "Step 1110 — Test metrics:\n",
            "  precision@10: 0.001131542\n",
            "  recall@10: 0.001131542\n",
            "  ndcg@10: 0.001344187\n",
            "  map@10: 0.000453758\n",
            "Epoch 38, Step 20, LR: 0.000868, Current Loss: 0.6387, Avg Loss: 0.6437\n",
            "Diff stats — min: -5.9433, max: 10.0000, mean: 4.5425, std: 3.0485\n",
            "\n",
            "Epoch 38 completed, Train Loss: 0.000159\n",
            "\n",
            "Epoch 39, Step 1, LR: 0.000868, Current Loss: 0.6424, Avg Loss: 0.6424\n",
            "Diff stats — min: -5.3340, max: 10.0000, mean: 4.5019, std: 3.0493\n",
            "\n",
            "Step 1140 — Test metrics:\n",
            "  precision@10: 0.001155116\n",
            "  recall@10: 0.001155116\n",
            "  ndcg@10: 0.001266442\n",
            "  map@10: 0.000401699\n",
            "Epoch 39, Step 20, LR: 0.000868, Current Loss: 0.6396, Avg Loss: 0.6397\n",
            "Diff stats — min: -7.1211, max: 10.0000, mean: 4.5012, std: 3.0875\n",
            "\n",
            "Epoch 39 completed, Train Loss: 0.000158\n",
            "\n",
            "Epoch 40, Step 1, LR: 0.000868, Current Loss: 0.6273, Avg Loss: 0.6273\n",
            "Diff stats — min: -5.9366, max: 10.0000, mean: 4.4986, std: 3.0350\n",
            "\n",
            "Step 1170 — Test metrics:\n",
            "  precision@10: 0.001249411\n",
            "  recall@10: 0.001249411\n",
            "  ndcg@10: 0.001401728\n",
            "  map@10: 0.000455217\n",
            "Epoch 40, Step 20, LR: 0.000868, Current Loss: 0.6503, Avg Loss: 0.6404\n",
            "Diff stats — min: -6.1964, max: 10.0000, mean: 4.5741, std: 3.0860\n",
            "\n",
            "Epoch 40 completed, Train Loss: 0.000157\n",
            "\n",
            "Epoch 41, Step 1, LR: 0.000851, Current Loss: 0.6275, Avg Loss: 0.6275\n",
            "Diff stats — min: -7.5284, max: 10.0000, mean: 4.6923, std: 3.0797\n",
            "\n",
            "Step 1200 — Test metrics:\n",
            "  precision@10: 0.001202263\n",
            "  recall@10: 0.001202263\n",
            "  ndcg@10: 0.001361349\n",
            "  map@10: 0.000445264\n",
            "Epoch 41, Step 20, LR: 0.000851, Current Loss: 0.6511, Avg Loss: 0.6388\n",
            "Diff stats — min: -6.7537, max: 10.0000, mean: 4.5267, std: 3.0644\n",
            "\n",
            "Epoch 41 completed, Train Loss: 0.000157\n",
            "\n",
            "Epoch 42, Step 1, LR: 0.000851, Current Loss: 0.6495, Avg Loss: 0.6495\n",
            "Diff stats — min: -5.7298, max: 10.0000, mean: 4.5567, std: 3.0413\n",
            "\n",
            "Step 1230 — Test metrics:\n",
            "  precision@10: 0.001320132\n",
            "  recall@10: 0.001320132\n",
            "  ndcg@10: 0.001470839\n",
            "  map@10: 0.000475236\n",
            "Epoch 42, Step 20, LR: 0.000851, Current Loss: 0.6305, Avg Loss: 0.6335\n",
            "Diff stats — min: -6.2180, max: 10.0000, mean: 4.6719, std: 3.0477\n",
            "\n",
            "Epoch 42 completed, Train Loss: 0.000157\n",
            "\n",
            "Epoch 43, Step 1, LR: 0.000851, Current Loss: 0.6557, Avg Loss: 0.6557\n",
            "Diff stats — min: -6.9199, max: 10.0000, mean: 4.6537, std: 3.0815\n",
            "\n",
            "Step 1260 — Test metrics:\n",
            "  precision@10: 0.001296558\n",
            "  recall@10: 0.001296558\n",
            "  ndcg@10: 0.001492585\n",
            "  map@10: 0.000496322\n",
            "Epoch 43, Step 20, LR: 0.000851, Current Loss: 0.6373, Avg Loss: 0.6355\n",
            "Diff stats — min: -5.5313, max: 10.0000, mean: 4.6051, std: 3.0746\n",
            "\n",
            "Epoch 43 completed, Train Loss: 0.000156\n",
            "\n",
            "Epoch 44, Step 1, LR: 0.000851, Current Loss: 0.6355, Avg Loss: 0.6355\n",
            "Diff stats — min: -7.1194, max: 10.0000, mean: 4.7146, std: 3.0903\n",
            "\n",
            "Step 1290 — Test metrics:\n",
            "  precision@10: 0.001249411\n",
            "  recall@10: 0.001249411\n",
            "  ndcg@10: 0.001432423\n",
            "  map@10: 0.000472729\n",
            "Epoch 44, Step 20, LR: 0.000851, Current Loss: 0.6205, Avg Loss: 0.6314\n",
            "Diff stats — min: -5.7226, max: 10.0000, mean: 4.7337, std: 3.0432\n",
            "\n",
            "Epoch 44 completed, Train Loss: 0.000156\n",
            "\n",
            "Epoch 45, Step 1, LR: 0.000851, Current Loss: 0.6368, Avg Loss: 0.6368\n",
            "Diff stats — min: -5.4931, max: 10.0000, mean: 4.7275, std: 3.0950\n",
            "\n",
            "Step 1320 — Test metrics:\n",
            "  precision@10: 0.001461575\n",
            "  recall@10: 0.001461575\n",
            "  ndcg@10: 0.001544632\n",
            "  map@10: 0.000479848\n",
            "Epoch 45, Step 20, LR: 0.000851, Current Loss: 0.6514, Avg Loss: 0.6262\n",
            "Diff stats — min: -6.2838, max: 10.0000, mean: 4.7005, std: 3.1557\n",
            "\n",
            "Epoch 45 completed, Train Loss: 0.000155\n",
            "\n",
            "Epoch 46, Step 1, LR: 0.000834, Current Loss: 0.6465, Avg Loss: 0.6465\n",
            "Diff stats — min: -6.5347, max: 10.0000, mean: 4.6998, std: 3.1219\n",
            "\n",
            "Step 1350 — Test metrics:\n",
            "  precision@10: 0.001390853\n",
            "  recall@10: 0.001390853\n",
            "  ndcg@10: 0.001546860\n",
            "  map@10: 0.000500690\n",
            "Epoch 46, Step 20, LR: 0.000834, Current Loss: 0.6425, Avg Loss: 0.6245\n",
            "Diff stats — min: -5.2346, max: 10.0000, mean: 4.7365, std: 3.0607\n",
            "\n",
            "Epoch 46 completed, Train Loss: 0.000154\n",
            "\n",
            "Epoch 47, Step 1, LR: 0.000834, Current Loss: 0.6269, Avg Loss: 0.6269\n",
            "Diff stats — min: -6.0049, max: 10.0000, mean: 4.8327, std: 3.0922\n",
            "\n",
            "Step 1380 — Test metrics:\n",
            "  precision@10: 0.001532296\n",
            "  recall@10: 0.001532296\n",
            "  ndcg@10: 0.001661098\n",
            "  map@10: 0.000527314\n",
            "Epoch 47, Step 20, LR: 0.000834, Current Loss: 0.6127, Avg Loss: 0.6222\n",
            "Diff stats — min: -6.0118, max: 10.0000, mean: 4.8154, std: 3.0891\n",
            "\n",
            "Epoch 47 completed, Train Loss: 0.000154\n",
            "\n",
            "Epoch 48, Step 1, LR: 0.000834, Current Loss: 0.6359, Avg Loss: 0.6359\n",
            "Diff stats — min: -6.1415, max: 10.0000, mean: 4.8088, std: 3.1319\n",
            "\n",
            "Step 1410 — Test metrics:\n",
            "  precision@10: 0.001532296\n",
            "  recall@10: 0.001532296\n",
            "  ndcg@10: 0.001589771\n",
            "  map@10: 0.000483917\n",
            "Epoch 48, Step 20, LR: 0.000834, Current Loss: 0.6139, Avg Loss: 0.6197\n",
            "Diff stats — min: -5.8182, max: 10.0000, mean: 4.9025, std: 3.0910\n",
            "\n",
            "Epoch 48 completed, Train Loss: 0.000153\n",
            "\n",
            "Epoch 49, Step 1, LR: 0.000834, Current Loss: 0.6251, Avg Loss: 0.6251\n",
            "Diff stats — min: -7.9921, max: 10.0000, mean: 4.8907, std: 3.1487\n",
            "\n",
            "Step 1440 — Test metrics:\n",
            "  precision@10: 0.001343706\n",
            "  recall@10: 0.001343706\n",
            "  ndcg@10: 0.001502570\n",
            "  map@10: 0.000486518\n",
            "Epoch 49, Step 20, LR: 0.000834, Current Loss: 0.6180, Avg Loss: 0.6175\n",
            "Diff stats — min: -7.0264, max: 10.0000, mean: 4.8770, std: 3.1157\n",
            "\n",
            "Epoch 49 completed, Train Loss: 0.000153\n",
            "\n",
            "Epoch 50, Step 1, LR: 0.000834, Current Loss: 0.6372, Avg Loss: 0.6372\n",
            "Diff stats — min: -7.0343, max: 10.0000, mean: 4.9492, std: 3.1541\n",
            "\n",
            "Step 1470 — Test metrics:\n",
            "  precision@10: 0.001414427\n",
            "  recall@10: 0.001414427\n",
            "  ndcg@10: 0.001565073\n",
            "  map@10: 0.000502000\n",
            "Epoch 50, Step 20, LR: 0.000834, Current Loss: 0.6229, Avg Loss: 0.6160\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 4.9426, std: 3.0866\n",
            "\n",
            "Epoch 50 completed, Train Loss: 0.000152\n",
            "\n",
            "Epoch 51, Step 1, LR: 0.000817, Current Loss: 0.5855, Avg Loss: 0.5855\n",
            "Diff stats — min: -6.6327, max: 10.0000, mean: 4.9710, std: 3.1405\n",
            "\n",
            "Step 1500 — Test metrics:\n",
            "  precision@10: 0.001414427\n",
            "  recall@10: 0.001414427\n",
            "  ndcg@10: 0.001545833\n",
            "  map@10: 0.000493637\n",
            "Epoch 51, Step 20, LR: 0.000817, Current Loss: 0.6116, Avg Loss: 0.6183\n",
            "Diff stats — min: -6.0494, max: 10.0000, mean: 5.0136, std: 3.1234\n",
            "\n",
            "Epoch 51 completed, Train Loss: 0.000153\n",
            "\n",
            "Epoch 52, Step 1, LR: 0.000817, Current Loss: 0.6005, Avg Loss: 0.6005\n",
            "Diff stats — min: -5.7876, max: 10.0000, mean: 4.9959, std: 3.1294\n",
            "\n",
            "Step 1530 — Test metrics:\n",
            "  precision@10: 0.001461575\n",
            "  recall@10: 0.001461575\n",
            "  ndcg@10: 0.001630198\n",
            "  map@10: 0.000529493\n",
            "Epoch 52, Step 20, LR: 0.000817, Current Loss: 0.6067, Avg Loss: 0.6149\n",
            "Diff stats — min: -6.5488, max: 10.0000, mean: 4.9736, std: 3.1079\n",
            "\n",
            "Epoch 52 completed, Train Loss: 0.000152\n",
            "\n",
            "Epoch 53, Step 1, LR: 0.000817, Current Loss: 0.6038, Avg Loss: 0.6038\n",
            "Diff stats — min: -5.4643, max: 10.0000, mean: 5.0808, std: 3.0591\n",
            "\n",
            "Step 1560 — Test metrics:\n",
            "  precision@10: 0.001367280\n",
            "  recall@10: 0.001367280\n",
            "  ndcg@10: 0.001512280\n",
            "  map@10: 0.000480522\n",
            "Epoch 53, Step 20, LR: 0.000817, Current Loss: 0.6214, Avg Loss: 0.6108\n",
            "Diff stats — min: -7.0267, max: 10.0000, mean: 5.0126, std: 3.1663\n",
            "\n",
            "Epoch 53 completed, Train Loss: 0.000151\n",
            "\n",
            "Epoch 54, Step 1, LR: 0.000817, Current Loss: 0.6278, Avg Loss: 0.6278\n",
            "Diff stats — min: -5.4462, max: 10.0000, mean: 5.0621, std: 3.1219\n",
            "\n",
            "Step 1590 — Test metrics:\n",
            "  precision@10: 0.001390853\n",
            "  recall@10: 0.001390853\n",
            "  ndcg@10: 0.001628002\n",
            "  map@10: 0.000549325\n",
            "Epoch 54, Step 20, LR: 0.000817, Current Loss: 0.6117, Avg Loss: 0.6123\n",
            "Diff stats — min: -5.8226, max: 10.0000, mean: 5.0831, std: 3.1252\n",
            "\n",
            "Epoch 54 completed, Train Loss: 0.000151\n",
            "\n",
            "Epoch 55, Step 1, LR: 0.000817, Current Loss: 0.6331, Avg Loss: 0.6331\n",
            "Diff stats — min: -5.2411, max: 10.0000, mean: 5.0150, std: 3.1700\n",
            "\n",
            "Step 1620 — Test metrics:\n",
            "  precision@10: 0.001603017\n",
            "  recall@10: 0.001603017\n",
            "  ndcg@10: 0.001789438\n",
            "  map@10: 0.000577773\n",
            "Epoch 55, Step 20, LR: 0.000817, Current Loss: 0.6068, Avg Loss: 0.6110\n",
            "Diff stats — min: -6.5049, max: 10.0000, mean: 5.1158, std: 3.1390\n",
            "\n",
            "Epoch 55 completed, Train Loss: 0.000150\n",
            "\n",
            "Epoch 56, Step 1, LR: 0.000801, Current Loss: 0.6146, Avg Loss: 0.6146\n",
            "Diff stats — min: -5.0645, max: 10.0000, mean: 5.2345, std: 3.1304\n",
            "\n",
            "Step 1650 — Test metrics:\n",
            "  precision@10: 0.001485149\n",
            "  recall@10: 0.001485149\n",
            "  ndcg@10: 0.001597318\n",
            "  map@10: 0.000500765\n",
            "Epoch 56, Step 20, LR: 0.000801, Current Loss: 0.6083, Avg Loss: 0.6101\n",
            "Diff stats — min: -6.2588, max: 10.0000, mean: 5.1968, std: 3.1847\n",
            "\n",
            "Epoch 56 completed, Train Loss: 0.000151\n",
            "\n",
            "Epoch 57, Step 1, LR: 0.000801, Current Loss: 0.6087, Avg Loss: 0.6087\n",
            "Diff stats — min: -8.4745, max: 10.0000, mean: 5.1782, std: 3.1476\n",
            "\n",
            "Step 1680 — Test metrics:\n",
            "  precision@10: 0.001673739\n",
            "  recall@10: 0.001673739\n",
            "  ndcg@10: 0.001814035\n",
            "  map@10: 0.000572852\n",
            "Epoch 57, Step 20, LR: 0.000801, Current Loss: 0.5888, Avg Loss: 0.6040\n",
            "Diff stats — min: -5.2142, max: 10.0000, mean: 5.2078, std: 3.0522\n",
            "\n",
            "Epoch 57 completed, Train Loss: 0.000149\n",
            "\n",
            "Epoch 58, Step 1, LR: 0.000801, Current Loss: 0.6048, Avg Loss: 0.6048\n",
            "Diff stats — min: -5.7872, max: 10.0000, mean: 5.2737, std: 3.1629\n",
            "\n",
            "Step 1710 — Test metrics:\n",
            "  precision@10: 0.001626591\n",
            "  recall@10: 0.001626591\n",
            "  ndcg@10: 0.001767654\n",
            "  map@10: 0.000561187\n",
            "Epoch 58, Step 20, LR: 0.000801, Current Loss: 0.5948, Avg Loss: 0.6047\n",
            "Diff stats — min: -8.1575, max: 10.0000, mean: 5.2193, std: 3.1441\n",
            "\n",
            "Epoch 58 completed, Train Loss: 0.000149\n",
            "\n",
            "Epoch 59, Step 1, LR: 0.000801, Current Loss: 0.5966, Avg Loss: 0.5966\n",
            "Diff stats — min: -6.4366, max: 10.0000, mean: 5.1413, std: 3.1997\n",
            "\n",
            "Step 1740 — Test metrics:\n",
            "  precision@10: 0.001532296\n",
            "  recall@10: 0.001532296\n",
            "  ndcg@10: 0.001726585\n",
            "  map@10: 0.000560214\n",
            "Epoch 59, Step 20, LR: 0.000801, Current Loss: 0.5846, Avg Loss: 0.6022\n",
            "Diff stats — min: -4.7560, max: 10.0000, mean: 5.3135, std: 3.1341\n",
            "\n",
            "Epoch 59 completed, Train Loss: 0.000149\n",
            "\n",
            "Epoch 60, Step 1, LR: 0.000801, Current Loss: 0.6098, Avg Loss: 0.6098\n",
            "Diff stats — min: -6.2029, max: 10.0000, mean: 5.3096, std: 3.1188\n",
            "\n",
            "Step 1770 — Test metrics:\n",
            "  precision@10: 0.001579444\n",
            "  recall@10: 0.001579444\n",
            "  ndcg@10: 0.001756746\n",
            "  map@10: 0.000562824\n",
            "Epoch 60, Step 20, LR: 0.000801, Current Loss: 0.6126, Avg Loss: 0.6022\n",
            "Diff stats — min: -8.2237, max: 10.0000, mean: 5.2184, std: 3.1805\n",
            "\n",
            "Epoch 60 completed, Train Loss: 0.000149\n",
            "\n",
            "Epoch 61, Step 1, LR: 0.000785, Current Loss: 0.5899, Avg Loss: 0.5899\n",
            "Diff stats — min: -5.7100, max: 10.0000, mean: 5.2936, std: 3.1548\n",
            "\n",
            "Step 1800 — Test metrics:\n",
            "  precision@10: 0.001673739\n",
            "  recall@10: 0.001673739\n",
            "  ndcg@10: 0.001848387\n",
            "  map@10: 0.000590037\n",
            "Epoch 61, Step 20, LR: 0.000785, Current Loss: 0.5993, Avg Loss: 0.6047\n",
            "Diff stats — min: -5.7893, max: 10.0000, mean: 5.3509, std: 3.1164\n",
            "\n",
            "Epoch 61 completed, Train Loss: 0.000149\n",
            "\n",
            "Epoch 62, Step 1, LR: 0.000785, Current Loss: 0.6119, Avg Loss: 0.6119\n",
            "Diff stats — min: -5.0934, max: 10.0000, mean: 5.3352, std: 3.1439\n",
            "\n",
            "Step 1830 — Test metrics:\n",
            "  precision@10: 0.001555870\n",
            "  recall@10: 0.001555870\n",
            "  ndcg@10: 0.001841485\n",
            "  map@10: 0.000618372\n",
            "Epoch 62, Step 20, LR: 0.000785, Current Loss: 0.5812, Avg Loss: 0.5991\n",
            "Diff stats — min: -5.0406, max: 10.0000, mean: 5.2869, std: 3.1357\n",
            "\n",
            "Epoch 62 completed, Train Loss: 0.000148\n",
            "\n",
            "Epoch 63, Step 1, LR: 0.000785, Current Loss: 0.6002, Avg Loss: 0.6002\n",
            "Diff stats — min: -7.0474, max: 10.0000, mean: 5.3986, std: 3.1474\n",
            "\n",
            "Step 1860 — Test metrics:\n",
            "  precision@10: 0.001650165\n",
            "  recall@10: 0.001650165\n",
            "  ndcg@10: 0.001894834\n",
            "  map@10: 0.000624013\n",
            "Epoch 63, Step 20, LR: 0.000785, Current Loss: 0.5959, Avg Loss: 0.5972\n",
            "Diff stats — min: -7.9192, max: 10.0000, mean: 5.2763, std: 3.1698\n",
            "\n",
            "Epoch 63 completed, Train Loss: 0.000148\n",
            "\n",
            "Epoch 64, Step 1, LR: 0.000785, Current Loss: 0.6041, Avg Loss: 0.6041\n",
            "Diff stats — min: -5.4914, max: 10.0000, mean: 5.3814, std: 3.1215\n",
            "\n",
            "Step 1890 — Test metrics:\n",
            "  precision@10: 0.001673739\n",
            "  recall@10: 0.001673739\n",
            "  ndcg@10: 0.001885115\n",
            "  map@10: 0.000612497\n",
            "Epoch 64, Step 20, LR: 0.000785, Current Loss: 0.5979, Avg Loss: 0.5967\n",
            "Diff stats — min: -5.2994, max: 10.0000, mean: 5.3895, std: 3.1313\n",
            "\n",
            "Epoch 64 completed, Train Loss: 0.000147\n",
            "\n",
            "Epoch 65, Step 1, LR: 0.000785, Current Loss: 0.6052, Avg Loss: 0.6052\n",
            "Diff stats — min: -8.6930, max: 10.0000, mean: 5.3712, std: 3.1637\n",
            "\n",
            "Step 1920 — Test metrics:\n",
            "  precision@10: 0.001744460\n",
            "  recall@10: 0.001744460\n",
            "  ndcg@10: 0.001927216\n",
            "  map@10: 0.000619775\n",
            "Epoch 65, Step 20, LR: 0.000785, Current Loss: 0.5832, Avg Loss: 0.5962\n",
            "Diff stats — min: -5.3822, max: 10.0000, mean: 5.4006, std: 3.1638\n",
            "\n",
            "Epoch 65 completed, Train Loss: 0.000147\n",
            "\n",
            "Epoch 66, Step 1, LR: 0.000769, Current Loss: 0.5961, Avg Loss: 0.5961\n",
            "Diff stats — min: -9.1320, max: 10.0000, mean: 5.4972, std: 3.1774\n",
            "\n",
            "Step 1950 — Test metrics:\n",
            "  precision@10: 0.001697313\n",
            "  recall@10: 0.001697313\n",
            "  ndcg@10: 0.001882138\n",
            "  map@10: 0.000607568\n",
            "Epoch 66, Step 20, LR: 0.000769, Current Loss: 0.5918, Avg Loss: 0.5939\n",
            "Diff stats — min: -5.5726, max: 10.0000, mean: 5.4351, std: 3.1533\n",
            "\n",
            "Epoch 66 completed, Train Loss: 0.000146\n",
            "\n",
            "Epoch 67, Step 1, LR: 0.000769, Current Loss: 0.5907, Avg Loss: 0.5907\n",
            "Diff stats — min: -5.1862, max: 10.0000, mean: 5.5680, std: 3.1177\n",
            "\n",
            "Step 1980 — Test metrics:\n",
            "  precision@10: 0.001768034\n",
            "  recall@10: 0.001768034\n",
            "  ndcg@10: 0.001974259\n",
            "  map@10: 0.000641731\n",
            "Epoch 67, Step 20, LR: 0.000769, Current Loss: 0.6012, Avg Loss: 0.5906\n",
            "Diff stats — min: -6.7268, max: 10.0000, mean: 5.4858, std: 3.1299\n",
            "\n",
            "Epoch 67 completed, Train Loss: 0.000146\n",
            "\n",
            "Epoch 68, Step 1, LR: 0.000769, Current Loss: 0.5894, Avg Loss: 0.5894\n",
            "Diff stats — min: -6.7726, max: 10.0000, mean: 5.5478, std: 3.1959\n",
            "\n",
            "Step 2010 — Test metrics:\n",
            "  precision@10: 0.001838755\n",
            "  recall@10: 0.001838755\n",
            "  ndcg@10: 0.001970864\n",
            "  map@10: 0.000621833\n",
            "Epoch 68, Step 20, LR: 0.000769, Current Loss: 0.6015, Avg Loss: 0.5938\n",
            "Diff stats — min: -7.1361, max: 10.0000, mean: 5.5514, std: 3.1707\n",
            "\n",
            "Epoch 68 completed, Train Loss: 0.000146\n",
            "\n",
            "Epoch 69, Step 1, LR: 0.000769, Current Loss: 0.6018, Avg Loss: 0.6018\n",
            "Diff stats — min: -5.8938, max: 10.0000, mean: 5.5155, std: 3.1832\n",
            "\n",
            "Step 2040 — Test metrics:\n",
            "  precision@10: 0.001862329\n",
            "  recall@10: 0.001862329\n",
            "  ndcg@10: 0.002002539\n",
            "  map@10: 0.000630131\n",
            "Epoch 69, Step 20, LR: 0.000769, Current Loss: 0.5876, Avg Loss: 0.5884\n",
            "Diff stats — min: -5.6124, max: 10.0000, mean: 5.5811, std: 3.2046\n",
            "\n",
            "Epoch 69 completed, Train Loss: 0.000146\n",
            "\n",
            "Epoch 70, Step 1, LR: 0.000769, Current Loss: 0.5979, Avg Loss: 0.5979\n",
            "Diff stats — min: -7.3938, max: 10.0000, mean: 5.5668, std: 3.1807\n",
            "\n",
            "Step 2070 — Test metrics:\n",
            "  precision@10: 0.001885903\n",
            "  recall@10: 0.001885903\n",
            "  ndcg@10: 0.002032135\n",
            "  map@10: 0.000641852\n",
            "Epoch 70, Step 20, LR: 0.000769, Current Loss: 0.5953, Avg Loss: 0.5927\n",
            "Diff stats — min: -5.9750, max: 10.0000, mean: 5.5773, std: 3.2379\n",
            "\n",
            "Epoch 70 completed, Train Loss: 0.000146\n",
            "\n",
            "Epoch 71, Step 1, LR: 0.000754, Current Loss: 0.6324, Avg Loss: 0.6324\n",
            "Diff stats — min: -6.4286, max: 10.0000, mean: 5.4720, std: 3.2409\n",
            "\n",
            "Step 2100 — Test metrics:\n",
            "  precision@10: 0.001838755\n",
            "  recall@10: 0.001838755\n",
            "  ndcg@10: 0.001993490\n",
            "  map@10: 0.000631347\n",
            "Epoch 71, Step 20, LR: 0.000754, Current Loss: 0.5916, Avg Loss: 0.5882\n",
            "Diff stats — min: -5.5185, max: 10.0000, mean: 5.5928, std: 3.1882\n",
            "\n",
            "Epoch 71 completed, Train Loss: 0.000146\n",
            "\n",
            "Epoch 72, Step 1, LR: 0.000754, Current Loss: 0.5907, Avg Loss: 0.5907\n",
            "Diff stats — min: -4.7289, max: 10.0000, mean: 5.6265, std: 3.1718\n",
            "\n",
            "Step 2130 — Test metrics:\n",
            "  precision@10: 0.002003772\n",
            "  recall@10: 0.002003772\n",
            "  ndcg@10: 0.002086606\n",
            "  map@10: 0.000638765\n",
            "Epoch 72, Step 20, LR: 0.000754, Current Loss: 0.5709, Avg Loss: 0.5875\n",
            "Diff stats — min: -5.4588, max: 10.0000, mean: 5.6473, std: 3.1617\n",
            "\n",
            "Epoch 72 completed, Train Loss: 0.000145\n",
            "\n",
            "Epoch 73, Step 1, LR: 0.000754, Current Loss: 0.5733, Avg Loss: 0.5733\n",
            "Diff stats — min: -6.9114, max: 10.0000, mean: 5.7145, std: 3.1685\n",
            "\n",
            "Step 2160 — Test metrics:\n",
            "  precision@10: 0.001885903\n",
            "  recall@10: 0.001885903\n",
            "  ndcg@10: 0.002030300\n",
            "  map@10: 0.000639140\n",
            "Epoch 73, Step 20, LR: 0.000754, Current Loss: 0.5894, Avg Loss: 0.5902\n",
            "Diff stats — min: -8.0150, max: 10.0000, mean: 5.7245, std: 3.1661\n",
            "\n",
            "Epoch 73 completed, Train Loss: 0.000145\n",
            "\n",
            "Epoch 74, Step 1, LR: 0.000754, Current Loss: 0.5821, Avg Loss: 0.5821\n",
            "Diff stats — min: -4.7419, max: 10.0000, mean: 5.6886, std: 3.1536\n",
            "\n",
            "Step 2190 — Test metrics:\n",
            "  precision@10: 0.002027346\n",
            "  recall@10: 0.002027346\n",
            "  ndcg@10: 0.002160499\n",
            "  map@10: 0.000679608\n",
            "Epoch 74, Step 20, LR: 0.000754, Current Loss: 0.5852, Avg Loss: 0.5849\n",
            "Diff stats — min: -5.6686, max: 10.0000, mean: 5.6728, std: 3.1693\n",
            "\n",
            "Epoch 74 completed, Train Loss: 0.000145\n",
            "\n",
            "Epoch 75, Step 1, LR: 0.000754, Current Loss: 0.5864, Avg Loss: 0.5864\n",
            "Diff stats — min: -8.6444, max: 10.0000, mean: 5.6080, std: 3.1533\n",
            "\n",
            "Step 2220 — Test metrics:\n",
            "  precision@10: 0.001980198\n",
            "  recall@10: 0.001980198\n",
            "  ndcg@10: 0.002170152\n",
            "  map@10: 0.000697129\n",
            "Epoch 75, Step 20, LR: 0.000754, Current Loss: 0.5878, Avg Loss: 0.5847\n",
            "Diff stats — min: -6.4391, max: 10.0000, mean: 5.6441, std: 3.2022\n",
            "\n",
            "Epoch 75 completed, Train Loss: 0.000144\n",
            "\n",
            "Epoch 76, Step 1, LR: 0.000739, Current Loss: 0.5881, Avg Loss: 0.5881\n",
            "Diff stats — min: -7.6067, max: 10.0000, mean: 5.6634, std: 3.2059\n",
            "\n",
            "Step 2250 — Test metrics:\n",
            "  precision@10: 0.001933050\n",
            "  recall@10: 0.001933050\n",
            "  ndcg@10: 0.002122371\n",
            "  map@10: 0.000683602\n",
            "Epoch 76, Step 20, LR: 0.000739, Current Loss: 0.5853, Avg Loss: 0.5852\n",
            "Diff stats — min: -6.6622, max: 10.0000, mean: 5.6607, std: 3.1662\n",
            "\n",
            "Epoch 76 completed, Train Loss: 0.000144\n",
            "\n",
            "Epoch 77, Step 1, LR: 0.000739, Current Loss: 0.5876, Avg Loss: 0.5876\n",
            "Diff stats — min: -6.5994, max: 10.0000, mean: 5.6501, std: 3.1664\n",
            "\n",
            "Step 2280 — Test metrics:\n",
            "  precision@10: 0.002145215\n",
            "  recall@10: 0.002145215\n",
            "  ndcg@10: 0.002299472\n",
            "  map@10: 0.000723547\n",
            "Epoch 77, Step 20, LR: 0.000739, Current Loss: 0.5821, Avg Loss: 0.5827\n",
            "Diff stats — min: -5.1088, max: 10.0000, mean: 5.7434, std: 3.1515\n",
            "\n",
            "Epoch 77 completed, Train Loss: 0.000144\n",
            "\n",
            "Epoch 78, Step 1, LR: 0.000739, Current Loss: 0.5789, Avg Loss: 0.5789\n",
            "Diff stats — min: -7.1481, max: 10.0000, mean: 5.7915, std: 3.1740\n",
            "\n",
            "Step 2310 — Test metrics:\n",
            "  precision@10: 0.002215936\n",
            "  recall@10: 0.002215936\n",
            "  ndcg@10: 0.002358026\n",
            "  map@10: 0.000738280\n",
            "Epoch 78, Step 20, LR: 0.000739, Current Loss: 0.5865, Avg Loss: 0.5803\n",
            "Diff stats — min: -5.5930, max: 10.0000, mean: 5.7550, std: 3.1573\n",
            "\n",
            "Epoch 78 completed, Train Loss: 0.000143\n",
            "\n",
            "Epoch 79, Step 1, LR: 0.000739, Current Loss: 0.5854, Avg Loss: 0.5854\n",
            "Diff stats — min: -5.0754, max: 10.0000, mean: 5.7238, std: 3.1750\n",
            "\n",
            "Step 2340 — Test metrics:\n",
            "  precision@10: 0.002333805\n",
            "  recall@10: 0.002333805\n",
            "  ndcg@10: 0.002462107\n",
            "  map@10: 0.000773482\n",
            "Epoch 79, Step 20, LR: 0.000739, Current Loss: 0.5822, Avg Loss: 0.5815\n",
            "Diff stats — min: -7.0428, max: 10.0000, mean: 5.7263, std: 3.1845\n",
            "\n",
            "Epoch 79 completed, Train Loss: 0.000144\n",
            "\n",
            "Epoch 80, Step 1, LR: 0.000739, Current Loss: 0.5764, Avg Loss: 0.5764\n",
            "Diff stats — min: -6.0163, max: 10.0000, mean: 5.8379, std: 3.1751\n",
            "\n",
            "Step 2370 — Test metrics:\n",
            "  precision@10: 0.002168788\n",
            "  recall@10: 0.002168788\n",
            "  ndcg@10: 0.002349438\n",
            "  map@10: 0.000753575\n",
            "Epoch 80, Step 20, LR: 0.000739, Current Loss: 0.5653, Avg Loss: 0.5793\n",
            "Diff stats — min: -6.4938, max: 10.0000, mean: 5.8166, std: 3.1401\n",
            "\n",
            "Epoch 80 completed, Train Loss: 0.000143\n",
            "\n",
            "Epoch 81, Step 1, LR: 0.000724, Current Loss: 0.5554, Avg Loss: 0.5554\n",
            "Diff stats — min: -5.4151, max: 10.0000, mean: 5.8209, std: 3.1286\n",
            "\n",
            "Step 2400 — Test metrics:\n",
            "  precision@10: 0.002098067\n",
            "  recall@10: 0.002098067\n",
            "  ndcg@10: 0.002272965\n",
            "  map@10: 0.000722041\n",
            "Epoch 81, Step 20, LR: 0.000724, Current Loss: 0.5829, Avg Loss: 0.5782\n",
            "Diff stats — min: -8.1299, max: 10.0000, mean: 5.8852, std: 3.1449\n",
            "\n",
            "Epoch 81 completed, Train Loss: 0.000143\n",
            "\n",
            "Epoch 82, Step 1, LR: 0.000724, Current Loss: 0.6001, Avg Loss: 0.6001\n",
            "Diff stats — min: -7.8680, max: 10.0000, mean: 5.7875, std: 3.2064\n",
            "\n",
            "Step 2430 — Test metrics:\n",
            "  precision@10: 0.002404526\n",
            "  recall@10: 0.002404526\n",
            "  ndcg@10: 0.002598233\n",
            "  map@10: 0.000826308\n",
            "Epoch 82, Step 20, LR: 0.000724, Current Loss: 0.5531, Avg Loss: 0.5742\n",
            "Diff stats — min: -5.6646, max: 10.0000, mean: 5.8734, std: 3.1472\n",
            "\n",
            "Epoch 82 completed, Train Loss: 0.000142\n",
            "\n",
            "Epoch 83, Step 1, LR: 0.000724, Current Loss: 0.5799, Avg Loss: 0.5799\n",
            "Diff stats — min: -5.9661, max: 10.0000, mean: 5.8327, std: 3.1353\n",
            "\n",
            "Step 2460 — Test metrics:\n",
            "  precision@10: 0.002215936\n",
            "  recall@10: 0.002215936\n",
            "  ndcg@10: 0.002371869\n",
            "  map@10: 0.000747383\n",
            "Epoch 83, Step 20, LR: 0.000724, Current Loss: 0.5727, Avg Loss: 0.5751\n",
            "Diff stats — min: -5.8396, max: 10.0000, mean: 5.8251, std: 3.1442\n",
            "\n",
            "Epoch 83 completed, Train Loss: 0.000143\n",
            "\n",
            "Epoch 84, Step 1, LR: 0.000724, Current Loss: 0.5791, Avg Loss: 0.5791\n",
            "Diff stats — min: -5.7277, max: 10.0000, mean: 5.8797, std: 3.1490\n",
            "\n",
            "Step 2490 — Test metrics:\n",
            "  precision@10: 0.002498821\n",
            "  recall@10: 0.002498821\n",
            "  ndcg@10: 0.002689131\n",
            "  map@10: 0.000852108\n",
            "Epoch 84, Step 20, LR: 0.000724, Current Loss: 0.5904, Avg Loss: 0.5753\n",
            "Diff stats — min: -5.4807, max: 10.0000, mean: 5.9595, std: 3.1897\n",
            "\n",
            "Epoch 84 completed, Train Loss: 0.000142\n",
            "\n",
            "Epoch 85, Step 1, LR: 0.000724, Current Loss: 0.5673, Avg Loss: 0.5673\n",
            "Diff stats — min: -6.7102, max: 10.0000, mean: 5.8711, std: 3.1668\n",
            "\n",
            "Step 2520 — Test metrics:\n",
            "  precision@10: 0.002404526\n",
            "  recall@10: 0.002404526\n",
            "  ndcg@10: 0.002573824\n",
            "  map@10: 0.000813717\n",
            "Epoch 85, Step 20, LR: 0.000724, Current Loss: 0.5622, Avg Loss: 0.5757\n",
            "Diff stats — min: -6.7034, max: 10.0000, mean: 6.0036, std: 3.1581\n",
            "\n",
            "Epoch 85 completed, Train Loss: 0.000142\n",
            "\n",
            "Epoch 86, Step 1, LR: 0.000709, Current Loss: 0.5614, Avg Loss: 0.5614\n",
            "Diff stats — min: -5.5926, max: 10.0000, mean: 5.9790, std: 3.1135\n",
            "\n",
            "Step 2550 — Test metrics:\n",
            "  precision@10: 0.002687412\n",
            "  recall@10: 0.002687412\n",
            "  ndcg@10: 0.002801798\n",
            "  map@10: 0.000878292\n",
            "Epoch 86, Step 20, LR: 0.000709, Current Loss: 0.5900, Avg Loss: 0.5729\n",
            "Diff stats — min: -6.7301, max: 10.0000, mean: 5.8747, std: 3.1756\n",
            "\n",
            "Epoch 86 completed, Train Loss: 0.000141\n",
            "\n",
            "Epoch 87, Step 1, LR: 0.000709, Current Loss: 0.5617, Avg Loss: 0.5617\n",
            "Diff stats — min: -8.5992, max: 10.0000, mean: 5.9669, std: 3.1323\n",
            "\n",
            "Step 2580 — Test metrics:\n",
            "  precision@10: 0.002734559\n",
            "  recall@10: 0.002734559\n",
            "  ndcg@10: 0.002840773\n",
            "  map@10: 0.000877450\n",
            "Epoch 87, Step 20, LR: 0.000709, Current Loss: 0.5766, Avg Loss: 0.5738\n",
            "Diff stats — min: -8.3923, max: 10.0000, mean: 6.0102, std: 3.1672\n",
            "\n",
            "Epoch 87 completed, Train Loss: 0.000142\n",
            "\n",
            "Epoch 88, Step 1, LR: 0.000709, Current Loss: 0.5601, Avg Loss: 0.5601\n",
            "Diff stats — min: -6.7139, max: 10.0000, mean: 6.0959, std: 3.0878\n",
            "\n",
            "Step 2610 — Test metrics:\n",
            "  precision@10: 0.002569543\n",
            "  recall@10: 0.002569543\n",
            "  ndcg@10: 0.002727661\n",
            "  map@10: 0.000857665\n",
            "Epoch 88, Step 20, LR: 0.000709, Current Loss: 0.5793, Avg Loss: 0.5697\n",
            "Diff stats — min: -6.0392, max: 10.0000, mean: 6.0810, std: 3.1600\n",
            "\n",
            "Epoch 88 completed, Train Loss: 0.000141\n",
            "\n",
            "Epoch 89, Step 1, LR: 0.000709, Current Loss: 0.5640, Avg Loss: 0.5640\n",
            "Diff stats — min: -5.5822, max: 10.0000, mean: 6.0114, std: 3.1431\n",
            "\n",
            "Step 2640 — Test metrics:\n",
            "  precision@10: 0.002710985\n",
            "  recall@10: 0.002710985\n",
            "  ndcg@10: 0.002857837\n",
            "  map@10: 0.000897310\n",
            "Epoch 89, Step 20, LR: 0.000709, Current Loss: 0.5853, Avg Loss: 0.5737\n",
            "Diff stats — min: -5.8228, max: 10.0000, mean: 5.9924, std: 3.1742\n",
            "\n",
            "Epoch 89 completed, Train Loss: 0.000141\n",
            "\n",
            "Epoch 90, Step 1, LR: 0.000709, Current Loss: 0.5576, Avg Loss: 0.5576\n",
            "Diff stats — min: -5.5167, max: 10.0000, mean: 6.0823, std: 3.2061\n",
            "\n",
            "Step 2670 — Test metrics:\n",
            "  precision@10: 0.002663838\n",
            "  recall@10: 0.002663838\n",
            "  ndcg@10: 0.002773665\n",
            "  map@10: 0.000858703\n",
            "Epoch 90, Step 20, LR: 0.000709, Current Loss: 0.5722, Avg Loss: 0.5692\n",
            "Diff stats — min: -5.2554, max: 10.0000, mean: 6.0535, std: 3.1515\n",
            "\n",
            "Epoch 90 completed, Train Loss: 0.000141\n",
            "\n",
            "Epoch 91, Step 1, LR: 0.000695, Current Loss: 0.5726, Avg Loss: 0.5726\n",
            "Diff stats — min: -6.4618, max: 10.0000, mean: 6.0041, std: 3.1661\n",
            "\n",
            "Step 2700 — Test metrics:\n",
            "  precision@10: 0.002758133\n",
            "  recall@10: 0.002758133\n",
            "  ndcg@10: 0.002892758\n",
            "  map@10: 0.000905542\n",
            "Epoch 91, Step 20, LR: 0.000695, Current Loss: 0.5635, Avg Loss: 0.5700\n",
            "Diff stats — min: -6.1799, max: 10.0000, mean: 6.0860, std: 3.1681\n",
            "\n",
            "Epoch 91 completed, Train Loss: 0.000141\n",
            "\n",
            "Epoch 92, Step 1, LR: 0.000695, Current Loss: 0.5681, Avg Loss: 0.5681\n",
            "Diff stats — min: -5.3187, max: 10.0000, mean: 6.0682, std: 3.1504\n",
            "\n",
            "Step 2730 — Test metrics:\n",
            "  precision@10: 0.003064592\n",
            "  recall@10: 0.003064592\n",
            "  ndcg@10: 0.003068809\n",
            "  map@10: 0.000927039\n",
            "Epoch 92, Step 20, LR: 0.000695, Current Loss: 0.5692, Avg Loss: 0.5708\n",
            "Diff stats — min: -8.9044, max: 10.0000, mean: 6.1501, std: 3.1203\n",
            "\n",
            "Epoch 92 completed, Train Loss: 0.000141\n",
            "\n",
            "Epoch 93, Step 1, LR: 0.000695, Current Loss: 0.5821, Avg Loss: 0.5821\n",
            "Diff stats — min: -4.8459, max: 10.0000, mean: 6.0717, std: 3.1830\n",
            "\n",
            "Step 2760 — Test metrics:\n",
            "  precision@10: 0.002734559\n",
            "  recall@10: 0.002734559\n",
            "  ndcg@10: 0.002808030\n",
            "  map@10: 0.000858685\n",
            "Epoch 93, Step 20, LR: 0.000695, Current Loss: 0.5686, Avg Loss: 0.5688\n",
            "Diff stats — min: -6.1214, max: 10.0000, mean: 6.1338, std: 3.1589\n",
            "\n",
            "Epoch 93 completed, Train Loss: 0.000140\n",
            "\n",
            "Epoch 94, Step 1, LR: 0.000695, Current Loss: 0.5671, Avg Loss: 0.5671\n",
            "Diff stats — min: -7.7843, max: 10.0000, mean: 6.1551, std: 3.1515\n",
            "\n",
            "Step 2790 — Test metrics:\n",
            "  precision@10: 0.003041018\n",
            "  recall@10: 0.003041018\n",
            "  ndcg@10: 0.003053334\n",
            "  map@10: 0.000928227\n",
            "Epoch 94, Step 20, LR: 0.000695, Current Loss: 0.5591, Avg Loss: 0.5656\n",
            "Diff stats — min: -5.7907, max: 10.0000, mean: 6.1950, std: 3.1747\n",
            "\n",
            "Epoch 94 completed, Train Loss: 0.000140\n",
            "\n",
            "Epoch 95, Step 1, LR: 0.000695, Current Loss: 0.5660, Avg Loss: 0.5660\n",
            "Diff stats — min: -8.3421, max: 10.0000, mean: 6.1938, std: 3.1778\n",
            "\n",
            "Step 2820 — Test metrics:\n",
            "  precision@10: 0.003229609\n",
            "  recall@10: 0.003229609\n",
            "  ndcg@10: 0.003160524\n",
            "  map@10: 0.000926599\n",
            "Epoch 95, Step 20, LR: 0.000695, Current Loss: 0.5687, Avg Loss: 0.5627\n",
            "Diff stats — min: -5.8975, max: 10.0000, mean: 6.1623, std: 3.1510\n",
            "\n",
            "Epoch 95 completed, Train Loss: 0.000139\n",
            "\n",
            "Epoch 96, Step 1, LR: 0.000681, Current Loss: 0.5716, Avg Loss: 0.5716\n",
            "Diff stats — min: -7.7663, max: 10.0000, mean: 6.1664, std: 3.1732\n",
            "\n",
            "Step 2850 — Test metrics:\n",
            "  precision@10: 0.003394625\n",
            "  recall@10: 0.003394625\n",
            "  ndcg@10: 0.003348939\n",
            "  map@10: 0.001001989\n",
            "Epoch 96, Step 20, LR: 0.000681, Current Loss: 0.5574, Avg Loss: 0.5702\n",
            "Diff stats — min: -5.4750, max: 10.0000, mean: 6.1687, std: 3.1475\n",
            "\n",
            "Epoch 96 completed, Train Loss: 0.000140\n",
            "\n",
            "Epoch 97, Step 1, LR: 0.000681, Current Loss: 0.5772, Avg Loss: 0.5772\n",
            "Diff stats — min: -5.6170, max: 10.0000, mean: 6.2274, std: 3.1636\n",
            "\n",
            "Step 2880 — Test metrics:\n",
            "  precision@10: 0.003229609\n",
            "  recall@10: 0.003229609\n",
            "  ndcg@10: 0.003146754\n",
            "  map@10: 0.000927834\n",
            "Epoch 97, Step 20, LR: 0.000681, Current Loss: 0.5627, Avg Loss: 0.5674\n",
            "Diff stats — min: -6.2202, max: 10.0000, mean: 6.2319, std: 3.1747\n",
            "\n",
            "Epoch 97 completed, Train Loss: 0.000140\n",
            "\n",
            "Epoch 98, Step 1, LR: 0.000681, Current Loss: 0.5863, Avg Loss: 0.5863\n",
            "Diff stats — min: -4.8574, max: 10.0000, mean: 6.2086, std: 3.1891\n",
            "\n",
            "Step 2910 — Test metrics:\n",
            "  precision@10: 0.003465347\n",
            "  recall@10: 0.003465347\n",
            "  ndcg@10: 0.003377417\n",
            "  map@10: 0.000998752\n",
            "Epoch 98, Step 20, LR: 0.000681, Current Loss: 0.5675, Avg Loss: 0.5645\n",
            "Diff stats — min: -6.5321, max: 10.0000, mean: 6.2587, std: 3.1973\n",
            "\n",
            "Epoch 98 completed, Train Loss: 0.000140\n",
            "\n",
            "Epoch 99, Step 1, LR: 0.000681, Current Loss: 0.5823, Avg Loss: 0.5823\n",
            "Diff stats — min: -5.4300, max: 10.0000, mean: 6.2837, std: 3.1880\n",
            "\n",
            "Step 2940 — Test metrics:\n",
            "  precision@10: 0.003206035\n",
            "  recall@10: 0.003206035\n",
            "  ndcg@10: 0.003267632\n",
            "  map@10: 0.000999079\n",
            "Epoch 99, Step 20, LR: 0.000681, Current Loss: 0.5816, Avg Loss: 0.5653\n",
            "Diff stats — min: -7.2786, max: 10.0000, mean: 6.1460, std: 3.2137\n",
            "\n",
            "Epoch 99 completed, Train Loss: 0.000139\n",
            "\n",
            "Epoch 100, Step 1, LR: 0.000681, Current Loss: 0.5683, Avg Loss: 0.5683\n",
            "Diff stats — min: -5.5621, max: 10.0000, mean: 6.2482, std: 3.1967\n",
            "\n",
            "Step 2970 — Test metrics:\n",
            "  precision@10: 0.003371051\n",
            "  recall@10: 0.003371051\n",
            "  ndcg@10: 0.003388329\n",
            "  map@10: 0.001021680\n",
            "Epoch 100, Step 20, LR: 0.000681, Current Loss: 0.5633, Avg Loss: 0.5620\n",
            "Diff stats — min: -7.1320, max: 10.0000, mean: 6.3010, std: 3.1431\n",
            "\n",
            "Epoch 100 completed, Train Loss: 0.000139\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = Model(\n",
        "    num_users=num_users,\n",
        "    num_items=num_items,\n",
        "    feedback_types=feedback_types,\n",
        "    d_model=d_model,\n",
        "    n_head=n_head,\n",
        "    window_size=window_size,\n",
        "    decay=decay,\n",
        "    dropout=dropout\n",
        ")\n",
        "\n",
        "edge_type = hyperparameters['train_edge_type']\n",
        "num_epochs = hyperparameters['train_num_epochs']\n",
        "lr = hyperparameters['train_lr']\n",
        "batch_size = hyperparameters['train_batch_size']\n",
        "print_every = hyperparameters['train_print_every']\n",
        "test_every = hyperparameters['train_test_every']\n",
        "top_k = hyperparameters['test_topk']\n",
        "test_batch_size = hyperparameters['test_batch_size']\n",
        "scheduler_step_size = hyperparameters['train_scheduler_step_size']\n",
        "train_scheduler_gamma = hyperparameters['train_scheduler_gamma']\n",
        "train_margin = hyperparameters['train_margin']\n",
        "train_lambda_margin = hyperparameters['train_lambda_margin']\n",
        "train_lambda_ce = hyperparameters['train_lambda_ce']\n",
        "\n",
        "model = train_model(model,\n",
        "                    data,\n",
        "                    (seq_ids, event_type, seq_times, seq_mask),\n",
        "                    edge_type=edge_type,\n",
        "                    num_epochs=num_epochs,\n",
        "                    lr=lr,\n",
        "                    batch_size=batch_size,\n",
        "                    print_every=print_every,\n",
        "                    test_every=test_every,\n",
        "                    top_k=top_k,\n",
        "                    test_batch_size=test_batch_size,\n",
        "                    scheduler_step_size=scheduler_step_size,\n",
        "                    scheduler_gamma=train_scheduler_gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1it3iLR_opQa",
        "outputId": "d1b41cbd-c24f-4e39-ff9e-3ac66597444f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of training examples: 121468\n",
            "Epoch 101, Step 1, LR: 0.001000, Current Loss: 0.5880, Avg Loss: 0.5880\n",
            "Diff stats — min: -7.3681, max: 10.0000, mean: 6.1840, std: 3.2096\n",
            "\n",
            "Step 2971 — Test metrics:\n",
            "  precision@10: 0.003253182\n",
            "  recall@10: 0.003253182\n",
            "  ndcg@10: 0.003275990\n",
            "  map@10: 0.000985515\n",
            "Epoch 101, Step 20, LR: 0.001000, Current Loss: 0.5556, Avg Loss: 0.5649\n",
            "Diff stats — min: -4.8773, max: 10.0000, mean: 6.3527, std: 3.1540\n",
            "\n",
            "Epoch 101 completed, Train Loss: 0.000139\n",
            "\n",
            "Epoch 102, Step 1, LR: 0.001000, Current Loss: 0.5533, Avg Loss: 0.5533\n",
            "Diff stats — min: -6.8575, max: 10.0000, mean: 6.2739, std: 3.1476\n",
            "\n",
            "Step 3001 — Test metrics:\n",
            "  precision@10: 0.003512494\n",
            "  recall@10: 0.003512494\n",
            "  ndcg@10: 0.003574537\n",
            "  map@10: 0.001091869\n",
            "Epoch 102, Step 20, LR: 0.001000, Current Loss: 0.5608, Avg Loss: 0.5626\n",
            "Diff stats — min: -7.6029, max: 10.0000, mean: 6.2907, std: 3.1624\n",
            "\n",
            "Epoch 102 completed, Train Loss: 0.000139\n",
            "\n",
            "Epoch 103, Step 1, LR: 0.001000, Current Loss: 0.5652, Avg Loss: 0.5652\n",
            "Diff stats — min: -6.5556, max: 10.0000, mean: 6.3286, std: 3.1797\n",
            "\n",
            "Step 3031 — Test metrics:\n",
            "  precision@10: 0.003418199\n",
            "  recall@10: 0.003418199\n",
            "  ndcg@10: 0.003508288\n",
            "  map@10: 0.001080007\n",
            "Epoch 103, Step 20, LR: 0.001000, Current Loss: 0.5690, Avg Loss: 0.5644\n",
            "Diff stats — min: -5.3862, max: 10.0000, mean: 6.3616, std: 3.1538\n",
            "\n",
            "Epoch 103 completed, Train Loss: 0.000139\n",
            "\n",
            "Epoch 104, Step 1, LR: 0.001000, Current Loss: 0.5664, Avg Loss: 0.5664\n",
            "Diff stats — min: -6.6369, max: 10.0000, mean: 6.3342, std: 3.1717\n",
            "\n",
            "Step 3061 — Test metrics:\n",
            "  precision@10: 0.003842527\n",
            "  recall@10: 0.003842527\n",
            "  ndcg@10: 0.004014817\n",
            "  map@10: 0.001270094\n",
            "Epoch 104, Step 20, LR: 0.001000, Current Loss: 0.5474, Avg Loss: 0.5619\n",
            "Diff stats — min: -6.4204, max: 10.0000, mean: 6.4033, std: 3.1320\n",
            "\n",
            "Epoch 104 completed, Train Loss: 0.000138\n",
            "\n",
            "Epoch 105, Step 1, LR: 0.001000, Current Loss: 0.5757, Avg Loss: 0.5757\n",
            "Diff stats — min: -6.8423, max: 10.0000, mean: 6.3902, std: 3.1692\n",
            "\n",
            "Step 3091 — Test metrics:\n",
            "  precision@10: 0.003677511\n",
            "  recall@10: 0.003677511\n",
            "  ndcg@10: 0.003799430\n",
            "  map@10: 0.001175911\n",
            "Epoch 105, Step 20, LR: 0.001000, Current Loss: 0.5604, Avg Loss: 0.5605\n",
            "Diff stats — min: -8.9985, max: 10.0000, mean: 6.4572, std: 3.2047\n",
            "\n",
            "Epoch 105 completed, Train Loss: 0.000138\n",
            "\n",
            "Epoch 106, Step 1, LR: 0.000980, Current Loss: 0.5626, Avg Loss: 0.5626\n",
            "Diff stats — min: -7.8758, max: 10.0000, mean: 6.4320, std: 3.1754\n",
            "\n",
            "Step 3121 — Test metrics:\n",
            "  precision@10: 0.003771806\n",
            "  recall@10: 0.003771806\n",
            "  ndcg@10: 0.003871801\n",
            "  map@10: 0.001199952\n",
            "Epoch 106, Step 20, LR: 0.000980, Current Loss: 0.5439, Avg Loss: 0.5616\n",
            "Diff stats — min: -5.6263, max: 10.0000, mean: 6.4615, std: 3.1130\n",
            "\n",
            "Epoch 106 completed, Train Loss: 0.000138\n",
            "\n",
            "Epoch 107, Step 1, LR: 0.000980, Current Loss: 0.5794, Avg Loss: 0.5794\n",
            "Diff stats — min: -5.0758, max: 10.0000, mean: 6.4168, std: 3.1538\n",
            "\n",
            "Step 3151 — Test metrics:\n",
            "  precision@10: 0.003748232\n",
            "  recall@10: 0.003748232\n",
            "  ndcg@10: 0.003837557\n",
            "  map@10: 0.001187146\n",
            "Epoch 107, Step 20, LR: 0.000980, Current Loss: 0.5589, Avg Loss: 0.5564\n",
            "Diff stats — min: -5.4088, max: 10.0000, mean: 6.4637, std: 3.1430\n",
            "\n",
            "Epoch 107 completed, Train Loss: 0.000138\n",
            "\n",
            "Epoch 108, Step 1, LR: 0.000980, Current Loss: 0.5546, Avg Loss: 0.5546\n",
            "Diff stats — min: -6.4186, max: 10.0000, mean: 6.5931, std: 3.1170\n",
            "\n",
            "Step 3181 — Test metrics:\n",
            "  precision@10: 0.003913248\n",
            "  recall@10: 0.003913248\n",
            "  ndcg@10: 0.004120337\n",
            "  map@10: 0.001306549\n",
            "Epoch 108, Step 20, LR: 0.000980, Current Loss: 0.5613, Avg Loss: 0.5586\n",
            "Diff stats — min: -6.4174, max: 10.0000, mean: 6.4791, std: 3.1606\n",
            "\n",
            "Epoch 108 completed, Train Loss: 0.000137\n",
            "\n",
            "Epoch 109, Step 1, LR: 0.000980, Current Loss: 0.5668, Avg Loss: 0.5668\n",
            "Diff stats — min: -6.0772, max: 10.0000, mean: 6.5502, std: 3.1146\n",
            "\n",
            "Step 3211 — Test metrics:\n",
            "  precision@10: 0.003748232\n",
            "  recall@10: 0.003748232\n",
            "  ndcg@10: 0.003965882\n",
            "  map@10: 0.001253312\n",
            "Epoch 109, Step 20, LR: 0.000980, Current Loss: 0.5522, Avg Loss: 0.5523\n",
            "Diff stats — min: -4.8528, max: 10.0000, mean: 6.5893, std: 3.0742\n",
            "\n",
            "Epoch 109 completed, Train Loss: 0.000137\n",
            "\n",
            "Epoch 110, Step 1, LR: 0.000980, Current Loss: 0.5522, Avg Loss: 0.5522\n",
            "Diff stats — min: -5.2869, max: 10.0000, mean: 6.5140, std: 3.1422\n",
            "\n",
            "Step 3241 — Test metrics:\n",
            "  precision@10: 0.004384724\n",
            "  recall@10: 0.004384724\n",
            "  ndcg@10: 0.004488380\n",
            "  map@10: 0.001382182\n",
            "Epoch 110, Step 20, LR: 0.000980, Current Loss: 0.5599, Avg Loss: 0.5526\n",
            "Diff stats — min: -6.6672, max: 10.0000, mean: 6.5062, std: 3.1463\n",
            "\n",
            "Epoch 110 completed, Train Loss: 0.000137\n",
            "\n",
            "Epoch 111, Step 1, LR: 0.000960, Current Loss: 0.5513, Avg Loss: 0.5513\n",
            "Diff stats — min: -5.8833, max: 10.0000, mean: 6.5064, std: 3.1464\n",
            "\n",
            "Step 3271 — Test metrics:\n",
            "  precision@10: 0.003960396\n",
            "  recall@10: 0.003960396\n",
            "  ndcg@10: 0.004078065\n",
            "  map@10: 0.001271095\n",
            "Epoch 111, Step 20, LR: 0.000960, Current Loss: 0.5584, Avg Loss: 0.5578\n",
            "Diff stats — min: -8.6950, max: 10.0000, mean: 6.5177, std: 3.1885\n",
            "\n",
            "Epoch 111 completed, Train Loss: 0.000137\n",
            "\n",
            "Epoch 112, Step 1, LR: 0.000960, Current Loss: 0.5536, Avg Loss: 0.5536\n",
            "Diff stats — min: -6.8045, max: 10.0000, mean: 6.6154, std: 3.1238\n",
            "\n",
            "Step 3301 — Test metrics:\n",
            "  precision@10: 0.004172560\n",
            "  recall@10: 0.004172560\n",
            "  ndcg@10: 0.004311679\n",
            "  map@10: 0.001344445\n",
            "Epoch 112, Step 20, LR: 0.000960, Current Loss: 0.5555, Avg Loss: 0.5532\n",
            "Diff stats — min: -6.4855, max: 10.0000, mean: 6.5949, std: 3.1052\n",
            "\n",
            "Epoch 112 completed, Train Loss: 0.000137\n",
            "\n",
            "Epoch 113, Step 1, LR: 0.000960, Current Loss: 0.5438, Avg Loss: 0.5438\n",
            "Diff stats — min: -6.5099, max: 10.0000, mean: 6.5663, std: 3.1224\n",
            "\n",
            "Step 3331 — Test metrics:\n",
            "  precision@10: 0.004667610\n",
            "  recall@10: 0.004667610\n",
            "  ndcg@10: 0.004764802\n",
            "  map@10: 0.001472828\n",
            "Epoch 113, Step 20, LR: 0.000960, Current Loss: 0.5550, Avg Loss: 0.5523\n",
            "Diff stats — min: -6.8784, max: 10.0000, mean: 6.6665, std: 3.1304\n",
            "\n",
            "Epoch 113 completed, Train Loss: 0.000136\n",
            "\n",
            "Epoch 114, Step 1, LR: 0.000960, Current Loss: 0.5438, Avg Loss: 0.5438\n",
            "Diff stats — min: -7.5157, max: 10.0000, mean: 6.6520, std: 3.1409\n",
            "\n",
            "Step 3361 — Test metrics:\n",
            "  precision@10: 0.004502593\n",
            "  recall@10: 0.004502593\n",
            "  ndcg@10: 0.004617265\n",
            "  map@10: 0.001447720\n",
            "Epoch 114, Step 20, LR: 0.000960, Current Loss: 0.5547, Avg Loss: 0.5496\n",
            "Diff stats — min: -5.6121, max: 10.0000, mean: 6.7096, std: 3.1186\n",
            "\n",
            "Epoch 114 completed, Train Loss: 0.000136\n",
            "\n",
            "Epoch 115, Step 1, LR: 0.000960, Current Loss: 0.5471, Avg Loss: 0.5471\n",
            "Diff stats — min: -8.2081, max: 10.0000, mean: 6.7124, std: 3.1489\n",
            "\n",
            "Step 3391 — Test metrics:\n",
            "  precision@10: 0.004761905\n",
            "  recall@10: 0.004761905\n",
            "  ndcg@10: 0.004838274\n",
            "  map@10: 0.001503605\n",
            "Epoch 115, Step 20, LR: 0.000960, Current Loss: 0.5520, Avg Loss: 0.5513\n",
            "Diff stats — min: -5.6982, max: 10.0000, mean: 6.7108, std: 3.1193\n",
            "\n",
            "Epoch 115 completed, Train Loss: 0.000136\n",
            "\n",
            "Epoch 116, Step 1, LR: 0.000941, Current Loss: 0.5370, Avg Loss: 0.5370\n",
            "Diff stats — min: -5.0961, max: 10.0000, mean: 6.7922, std: 3.0669\n",
            "\n",
            "Step 3421 — Test metrics:\n",
            "  precision@10: 0.004691183\n",
            "  recall@10: 0.004691183\n",
            "  ndcg@10: 0.004830264\n",
            "  map@10: 0.001515177\n",
            "Epoch 116, Step 20, LR: 0.000941, Current Loss: 0.5572, Avg Loss: 0.5508\n",
            "Diff stats — min: -6.8099, max: 10.0000, mean: 6.6975, std: 3.1492\n",
            "\n",
            "Epoch 116 completed, Train Loss: 0.000136\n",
            "\n",
            "Epoch 117, Step 1, LR: 0.000941, Current Loss: 0.5491, Avg Loss: 0.5491\n",
            "Diff stats — min: -5.3309, max: 10.0000, mean: 6.6742, std: 3.0972\n",
            "\n",
            "Step 3451 — Test metrics:\n",
            "  precision@10: 0.004761905\n",
            "  recall@10: 0.004761905\n",
            "  ndcg@10: 0.004975219\n",
            "  map@10: 0.001573382\n",
            "Epoch 117, Step 20, LR: 0.000941, Current Loss: 0.5759, Avg Loss: 0.5459\n",
            "Diff stats — min: -5.8176, max: 10.0000, mean: 6.7814, std: 3.1446\n",
            "\n",
            "Epoch 117 completed, Train Loss: 0.000136\n",
            "\n",
            "Epoch 118, Step 1, LR: 0.000941, Current Loss: 0.5352, Avg Loss: 0.5352\n",
            "Diff stats — min: -5.5252, max: 10.0000, mean: 6.7604, std: 3.1197\n",
            "\n",
            "Step 3481 — Test metrics:\n",
            "  precision@10: 0.004785479\n",
            "  recall@10: 0.004785479\n",
            "  ndcg@10: 0.004871347\n",
            "  map@10: 0.001505261\n",
            "Epoch 118, Step 20, LR: 0.000941, Current Loss: 0.5412, Avg Loss: 0.5485\n",
            "Diff stats — min: -5.6918, max: 10.0000, mean: 6.7105, std: 3.1361\n",
            "\n",
            "Epoch 118 completed, Train Loss: 0.000136\n",
            "\n",
            "Epoch 119, Step 1, LR: 0.000941, Current Loss: 0.5443, Avg Loss: 0.5443\n",
            "Diff stats — min: -7.4694, max: 10.0000, mean: 6.7373, std: 3.0553\n",
            "\n",
            "Step 3511 — Test metrics:\n",
            "  precision@10: 0.004832626\n",
            "  recall@10: 0.004832626\n",
            "  ndcg@10: 0.004865487\n",
            "  map@10: 0.001486206\n",
            "Epoch 119, Step 20, LR: 0.000941, Current Loss: 0.5521, Avg Loss: 0.5470\n",
            "Diff stats — min: -6.3658, max: 10.0000, mean: 6.8734, std: 3.1000\n",
            "\n",
            "Epoch 119 completed, Train Loss: 0.000135\n",
            "\n",
            "Epoch 120, Step 1, LR: 0.000941, Current Loss: 0.5452, Avg Loss: 0.5452\n",
            "Diff stats — min: -7.6011, max: 10.0000, mean: 6.7027, std: 3.1211\n",
            "\n",
            "Step 3541 — Test metrics:\n",
            "  precision@10: 0.005091938\n",
            "  recall@10: 0.005094557\n",
            "  ndcg@10: 0.005033325\n",
            "  map@10: 0.001510263\n",
            "Epoch 120, Step 20, LR: 0.000941, Current Loss: 0.5584, Avg Loss: 0.5466\n",
            "Diff stats — min: -6.2405, max: 10.0000, mean: 6.7875, std: 3.1075\n",
            "\n",
            "Epoch 120 completed, Train Loss: 0.000135\n",
            "\n",
            "Epoch 121, Step 1, LR: 0.000922, Current Loss: 0.5604, Avg Loss: 0.5604\n",
            "Diff stats — min: -6.0653, max: 10.0000, mean: 6.8164, std: 3.0916\n",
            "\n",
            "Step 3571 — Test metrics:\n",
            "  precision@10: 0.005233380\n",
            "  recall@10: 0.005233380\n",
            "  ndcg@10: 0.005395387\n",
            "  map@10: 0.001684562\n",
            "Epoch 121, Step 20, LR: 0.000922, Current Loss: 0.5310, Avg Loss: 0.5457\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 6.9104, std: 3.0900\n",
            "\n",
            "Epoch 121 completed, Train Loss: 0.000135\n",
            "\n",
            "Epoch 122, Step 1, LR: 0.000922, Current Loss: 0.5618, Avg Loss: 0.5618\n",
            "Diff stats — min: -7.8735, max: 10.0000, mean: 6.8388, std: 3.1389\n",
            "\n",
            "Step 3601 — Test metrics:\n",
            "  precision@10: 0.005374823\n",
            "  recall@10: 0.005377443\n",
            "  ndcg@10: 0.005596619\n",
            "  map@10: 0.001758586\n",
            "Epoch 122, Step 20, LR: 0.000922, Current Loss: 0.5467, Avg Loss: 0.5441\n",
            "Diff stats — min: -5.8977, max: 10.0000, mean: 6.8140, std: 3.0927\n",
            "\n",
            "Epoch 122 completed, Train Loss: 0.000135\n",
            "\n",
            "Epoch 123, Step 1, LR: 0.000922, Current Loss: 0.5433, Avg Loss: 0.5433\n",
            "Diff stats — min: -5.7895, max: 10.0000, mean: 6.8144, std: 3.1131\n",
            "\n",
            "Step 3631 — Test metrics:\n",
            "  precision@10: 0.005563413\n",
            "  recall@10: 0.005566033\n",
            "  ndcg@10: 0.005710350\n",
            "  map@10: 0.001774349\n",
            "Epoch 123, Step 20, LR: 0.000922, Current Loss: 0.5401, Avg Loss: 0.5458\n",
            "Diff stats — min: -5.8073, max: 10.0000, mean: 6.8464, std: 3.0625\n",
            "\n",
            "Epoch 123 completed, Train Loss: 0.000135\n",
            "\n",
            "Epoch 124, Step 1, LR: 0.000922, Current Loss: 0.5418, Avg Loss: 0.5418\n",
            "Diff stats — min: -7.0135, max: 10.0000, mean: 6.8393, std: 3.1346\n",
            "\n",
            "Step 3661 — Test metrics:\n",
            "  precision@10: 0.005799151\n",
            "  recall@10: 0.005801771\n",
            "  ndcg@10: 0.005774239\n",
            "  map@10: 0.001749605\n",
            "Epoch 124, Step 20, LR: 0.000922, Current Loss: 0.5510, Avg Loss: 0.5449\n",
            "Diff stats — min: -9.2697, max: 10.0000, mean: 6.9197, std: 3.1197\n",
            "\n",
            "Epoch 124 completed, Train Loss: 0.000134\n",
            "\n",
            "Epoch 125, Step 1, LR: 0.000922, Current Loss: 0.5279, Avg Loss: 0.5279\n",
            "Diff stats — min: -6.2513, max: 10.0000, mean: 6.8921, std: 3.0974\n",
            "\n",
            "Step 3691 — Test metrics:\n",
            "  precision@10: 0.005280528\n",
            "  recall@10: 0.005283147\n",
            "  ndcg@10: 0.005404222\n",
            "  map@10: 0.001671671\n",
            "Epoch 125, Step 20, LR: 0.000922, Current Loss: 0.5418, Avg Loss: 0.5440\n",
            "Diff stats — min: -5.6891, max: 10.0000, mean: 6.9288, std: 3.0733\n",
            "\n",
            "Epoch 125 completed, Train Loss: 0.000134\n",
            "\n",
            "Epoch 126, Step 1, LR: 0.000904, Current Loss: 0.5304, Avg Loss: 0.5304\n",
            "Diff stats — min: -7.7769, max: 10.0000, mean: 6.9801, std: 3.0800\n",
            "\n",
            "Step 3721 — Test metrics:\n",
            "  precision@10: 0.005539840\n",
            "  recall@10: 0.005542459\n",
            "  ndcg@10: 0.005627534\n",
            "  map@10: 0.001711616\n",
            "Epoch 126, Step 20, LR: 0.000904, Current Loss: 0.5372, Avg Loss: 0.5420\n",
            "Diff stats — min: -7.5785, max: 10.0000, mean: 7.0050, std: 3.0765\n",
            "\n",
            "Epoch 126 completed, Train Loss: 0.000134\n",
            "\n",
            "Epoch 127, Step 1, LR: 0.000904, Current Loss: 0.5278, Avg Loss: 0.5278\n",
            "Diff stats — min: -5.6400, max: 10.0000, mean: 6.8845, std: 3.1070\n",
            "\n",
            "Step 3751 — Test metrics:\n",
            "  precision@10: 0.005516266\n",
            "  recall@10: 0.005518885\n",
            "  ndcg@10: 0.005608613\n",
            "  map@10: 0.001733806\n",
            "Epoch 127, Step 20, LR: 0.000904, Current Loss: 0.5278, Avg Loss: 0.5407\n",
            "Diff stats — min: -5.1910, max: 10.0000, mean: 7.0164, std: 3.0221\n",
            "\n",
            "Epoch 127 completed, Train Loss: 0.000134\n",
            "\n",
            "Epoch 128, Step 1, LR: 0.000904, Current Loss: 0.5318, Avg Loss: 0.5318\n",
            "Diff stats — min: -4.5707, max: 10.0000, mean: 6.9456, std: 3.0630\n",
            "\n",
            "Step 3781 — Test metrics:\n",
            "  precision@10: 0.005186233\n",
            "  recall@10: 0.005186233\n",
            "  ndcg@10: 0.005355837\n",
            "  map@10: 0.001672916\n",
            "Epoch 128, Step 20, LR: 0.000904, Current Loss: 0.5512, Avg Loss: 0.5424\n",
            "Diff stats — min: -5.7010, max: 10.0000, mean: 6.8894, std: 3.0908\n",
            "\n",
            "Epoch 128 completed, Train Loss: 0.000134\n",
            "\n",
            "Epoch 129, Step 1, LR: 0.000904, Current Loss: 0.5496, Avg Loss: 0.5496\n",
            "Diff stats — min: -6.7742, max: 10.0000, mean: 6.9954, std: 3.0586\n",
            "\n",
            "Step 3811 — Test metrics:\n",
            "  precision@10: 0.005704856\n",
            "  recall@10: 0.005707476\n",
            "  ndcg@10: 0.005947798\n",
            "  map@10: 0.001871853\n",
            "Epoch 129, Step 20, LR: 0.000904, Current Loss: 0.5350, Avg Loss: 0.5438\n",
            "Diff stats — min: -5.2806, max: 10.0000, mean: 6.9208, std: 3.0868\n",
            "\n",
            "Epoch 129 completed, Train Loss: 0.000134\n",
            "\n",
            "Epoch 130, Step 1, LR: 0.000904, Current Loss: 0.5393, Avg Loss: 0.5393\n",
            "Diff stats — min: -6.0067, max: 10.0000, mean: 7.0542, std: 3.0633\n",
            "\n",
            "Step 3841 — Test metrics:\n",
            "  precision@10: 0.005469118\n",
            "  recall@10: 0.005471738\n",
            "  ndcg@10: 0.005731255\n",
            "  map@10: 0.001800551\n",
            "Epoch 130, Step 20, LR: 0.000904, Current Loss: 0.5304, Avg Loss: 0.5390\n",
            "Diff stats — min: -6.8283, max: 10.0000, mean: 7.0343, std: 3.0337\n",
            "\n",
            "Epoch 130 completed, Train Loss: 0.000134\n",
            "\n",
            "Epoch 131, Step 1, LR: 0.000886, Current Loss: 0.5393, Avg Loss: 0.5393\n",
            "Diff stats — min: -5.9403, max: 10.0000, mean: 6.9404, std: 3.0826\n",
            "\n",
            "Step 3871 — Test metrics:\n",
            "  precision@10: 0.005634135\n",
            "  recall@10: 0.005634135\n",
            "  ndcg@10: 0.006041104\n",
            "  map@10: 0.001951863\n",
            "Epoch 131, Step 20, LR: 0.000886, Current Loss: 0.5565, Avg Loss: 0.5394\n",
            "Diff stats — min: -7.1981, max: 10.0000, mean: 7.0212, std: 3.0973\n",
            "\n",
            "Epoch 131 completed, Train Loss: 0.000133\n",
            "\n",
            "Epoch 132, Step 1, LR: 0.000886, Current Loss: 0.5334, Avg Loss: 0.5334\n",
            "Diff stats — min: -5.9737, max: 10.0000, mean: 7.0096, std: 3.0249\n",
            "\n",
            "Step 3901 — Test metrics:\n",
            "  precision@10: 0.006058463\n",
            "  recall@10: 0.006061082\n",
            "  ndcg@10: 0.006281733\n",
            "  map@10: 0.001984782\n",
            "Epoch 132, Step 20, LR: 0.000886, Current Loss: 0.5497, Avg Loss: 0.5382\n",
            "Diff stats — min: -8.8384, max: 10.0000, mean: 6.9960, std: 3.0926\n",
            "\n",
            "Epoch 132 completed, Train Loss: 0.000133\n",
            "\n",
            "Epoch 133, Step 1, LR: 0.000886, Current Loss: 0.5248, Avg Loss: 0.5248\n",
            "Diff stats — min: -8.5930, max: 10.0000, mean: 7.0212, std: 3.1168\n",
            "\n",
            "Step 3931 — Test metrics:\n",
            "  precision@10: 0.005799151\n",
            "  recall@10: 0.005799151\n",
            "  ndcg@10: 0.006045434\n",
            "  map@10: 0.001919093\n",
            "Epoch 133, Step 20, LR: 0.000886, Current Loss: 0.5414, Avg Loss: 0.5368\n",
            "Diff stats — min: -5.1842, max: 10.0000, mean: 7.1151, std: 3.0349\n",
            "\n",
            "Epoch 133 completed, Train Loss: 0.000133\n",
            "\n",
            "Epoch 134, Step 1, LR: 0.000886, Current Loss: 0.5377, Avg Loss: 0.5377\n",
            "Diff stats — min: -6.5827, max: 10.0000, mean: 6.9918, std: 3.0533\n",
            "\n",
            "Step 3961 — Test metrics:\n",
            "  precision@10: 0.005940594\n",
            "  recall@10: 0.005943213\n",
            "  ndcg@10: 0.006316943\n",
            "  map@10: 0.002048740\n",
            "Epoch 134, Step 20, LR: 0.000886, Current Loss: 0.5320, Avg Loss: 0.5400\n",
            "Diff stats — min: -7.2876, max: 10.0000, mean: 7.1233, std: 3.0222\n",
            "\n",
            "Epoch 134 completed, Train Loss: 0.000133\n",
            "\n",
            "Epoch 135, Step 1, LR: 0.000886, Current Loss: 0.5424, Avg Loss: 0.5424\n",
            "Diff stats — min: -6.0305, max: 10.0000, mean: 7.1172, std: 3.0918\n",
            "\n",
            "Step 3991 — Test metrics:\n",
            "  precision@10: 0.006105611\n",
            "  recall@10: 0.006108230\n",
            "  ndcg@10: 0.006535090\n",
            "  map@10: 0.002134364\n",
            "Epoch 135, Step 20, LR: 0.000886, Current Loss: 0.5405, Avg Loss: 0.5389\n",
            "Diff stats — min: -7.7923, max: 10.0000, mean: 7.1565, std: 3.0317\n",
            "\n",
            "Epoch 135 completed, Train Loss: 0.000133\n",
            "\n",
            "Epoch 136, Step 1, LR: 0.000868, Current Loss: 0.5392, Avg Loss: 0.5392\n",
            "Diff stats — min: -6.2120, max: 10.0000, mean: 7.2354, std: 3.0088\n",
            "\n",
            "Step 4021 — Test metrics:\n",
            "  precision@10: 0.006152758\n",
            "  recall@10: 0.006155377\n",
            "  ndcg@10: 0.006418565\n",
            "  map@10: 0.002073904\n",
            "Epoch 136, Step 20, LR: 0.000868, Current Loss: 0.5483, Avg Loss: 0.5367\n",
            "Diff stats — min: -5.6481, max: 10.0000, mean: 7.1370, std: 3.0662\n",
            "\n",
            "Epoch 136 completed, Train Loss: 0.000133\n",
            "\n",
            "Epoch 137, Step 1, LR: 0.000868, Current Loss: 0.5388, Avg Loss: 0.5388\n",
            "Diff stats — min: -9.7426, max: 10.0000, mean: 7.1553, std: 3.0486\n",
            "\n",
            "Step 4051 — Test metrics:\n",
            "  precision@10: 0.006553512\n",
            "  recall@10: 0.006553512\n",
            "  ndcg@10: 0.006755506\n",
            "  map@10: 0.002165570\n",
            "Epoch 137, Step 20, LR: 0.000868, Current Loss: 0.5444, Avg Loss: 0.5348\n",
            "Diff stats — min: -5.2188, max: 10.0000, mean: 7.1039, std: 3.0823\n",
            "\n",
            "Epoch 137 completed, Train Loss: 0.000132\n",
            "\n",
            "Epoch 138, Step 1, LR: 0.000868, Current Loss: 0.5478, Avg Loss: 0.5478\n",
            "Diff stats — min: -7.6125, max: 10.0000, mean: 7.0923, std: 3.0486\n",
            "\n",
            "Step 4081 — Test metrics:\n",
            "  precision@10: 0.006742103\n",
            "  recall@10: 0.006742103\n",
            "  ndcg@10: 0.006831948\n",
            "  map@10: 0.002129948\n",
            "Epoch 138, Step 20, LR: 0.000868, Current Loss: 0.5460, Avg Loss: 0.5379\n",
            "Diff stats — min: -4.9494, max: 10.0000, mean: 7.1420, std: 3.0411\n",
            "\n",
            "Epoch 138 completed, Train Loss: 0.000133\n",
            "\n",
            "Epoch 139, Step 1, LR: 0.000868, Current Loss: 0.5275, Avg Loss: 0.5275\n",
            "Diff stats — min: -5.2636, max: 10.0000, mean: 7.2082, std: 3.0170\n",
            "\n",
            "Step 4111 — Test metrics:\n",
            "  precision@10: 0.006742103\n",
            "  recall@10: 0.006742103\n",
            "  ndcg@10: 0.006873180\n",
            "  map@10: 0.002159144\n",
            "Epoch 139, Step 20, LR: 0.000868, Current Loss: 0.5279, Avg Loss: 0.5373\n",
            "Diff stats — min: -5.0594, max: 10.0000, mean: 7.1334, std: 3.0125\n",
            "\n",
            "Epoch 139 completed, Train Loss: 0.000132\n",
            "\n",
            "Epoch 140, Step 1, LR: 0.000868, Current Loss: 0.5267, Avg Loss: 0.5267\n",
            "Diff stats — min: -5.6826, max: 10.0000, mean: 7.1451, std: 2.9864\n",
            "\n",
            "Step 4141 — Test metrics:\n",
            "  precision@10: 0.006388496\n",
            "  recall@10: 0.006391115\n",
            "  ndcg@10: 0.006573131\n",
            "  map@10: 0.002068918\n",
            "Epoch 140, Step 20, LR: 0.000868, Current Loss: 0.5305, Avg Loss: 0.5313\n",
            "Diff stats — min: -6.1607, max: 10.0000, mean: 7.1667, std: 3.0612\n",
            "\n",
            "Epoch 140 completed, Train Loss: 0.000132\n",
            "\n",
            "Epoch 141, Step 1, LR: 0.000851, Current Loss: 0.5379, Avg Loss: 0.5379\n",
            "Diff stats — min: -6.0182, max: 10.0000, mean: 7.2127, std: 3.0234\n",
            "\n",
            "Step 4171 — Test metrics:\n",
            "  precision@10: 0.006718529\n",
            "  recall@10: 0.006718529\n",
            "  ndcg@10: 0.006813041\n",
            "  map@10: 0.002130986\n",
            "Epoch 141, Step 20, LR: 0.000851, Current Loss: 0.5364, Avg Loss: 0.5347\n",
            "Diff stats — min: -6.8977, max: 10.0000, mean: 7.2695, std: 3.0239\n",
            "\n",
            "Epoch 141 completed, Train Loss: 0.000132\n",
            "\n",
            "Epoch 142, Step 1, LR: 0.000851, Current Loss: 0.5457, Avg Loss: 0.5457\n",
            "Diff stats — min: -7.8572, max: 10.0000, mean: 7.2885, std: 2.9693\n",
            "\n",
            "Step 4201 — Test metrics:\n",
            "  precision@10: 0.006718529\n",
            "  recall@10: 0.006718529\n",
            "  ndcg@10: 0.006893835\n",
            "  map@10: 0.002184336\n",
            "Epoch 142, Step 20, LR: 0.000851, Current Loss: 0.5419, Avg Loss: 0.5360\n",
            "Diff stats — min: -5.8025, max: 10.0000, mean: 7.2205, std: 3.0605\n",
            "\n",
            "Epoch 142 completed, Train Loss: 0.000132\n",
            "\n",
            "Epoch 143, Step 1, LR: 0.000851, Current Loss: 0.5225, Avg Loss: 0.5225\n",
            "Diff stats — min: -6.6046, max: 10.0000, mean: 7.2479, std: 3.0200\n",
            "\n",
            "Step 4231 — Test metrics:\n",
            "  precision@10: 0.006718529\n",
            "  recall@10: 0.006718529\n",
            "  ndcg@10: 0.006720632\n",
            "  map@10: 0.002069657\n",
            "Epoch 143, Step 20, LR: 0.000851, Current Loss: 0.5124, Avg Loss: 0.5322\n",
            "Diff stats — min: -6.3625, max: 10.0000, mean: 7.1892, std: 3.0410\n",
            "\n",
            "Epoch 143 completed, Train Loss: 0.000131\n",
            "\n",
            "Epoch 144, Step 1, LR: 0.000851, Current Loss: 0.5105, Avg Loss: 0.5105\n",
            "Diff stats — min: -7.1891, max: 10.0000, mean: 7.3025, std: 2.9627\n",
            "\n",
            "Step 4261 — Test metrics:\n",
            "  precision@10: 0.006718529\n",
            "  recall@10: 0.006718529\n",
            "  ndcg@10: 0.006661547\n",
            "  map@10: 0.002029376\n",
            "Epoch 144, Step 20, LR: 0.000851, Current Loss: 0.5374, Avg Loss: 0.5336\n",
            "Diff stats — min: -8.0407, max: 10.0000, mean: 7.2409, std: 3.0050\n",
            "\n",
            "Epoch 144 completed, Train Loss: 0.000132\n",
            "\n",
            "Epoch 145, Step 1, LR: 0.000851, Current Loss: 0.5070, Avg Loss: 0.5070\n",
            "Diff stats — min: -6.7940, max: 10.0000, mean: 7.2757, std: 2.9756\n",
            "\n",
            "Step 4291 — Test metrics:\n",
            "  precision@10: 0.006694955\n",
            "  recall@10: 0.006694955\n",
            "  ndcg@10: 0.006737186\n",
            "  map@10: 0.002089021\n",
            "Epoch 145, Step 20, LR: 0.000851, Current Loss: 0.5377, Avg Loss: 0.5332\n",
            "Diff stats — min: -7.9401, max: 10.0000, mean: 7.2912, std: 2.9660\n",
            "\n",
            "Epoch 145 completed, Train Loss: 0.000132\n",
            "\n",
            "Epoch 146, Step 1, LR: 0.000834, Current Loss: 0.5335, Avg Loss: 0.5335\n",
            "Diff stats — min: -4.3614, max: 10.0000, mean: 7.3333, std: 2.9679\n",
            "\n",
            "Step 4321 — Test metrics:\n",
            "  precision@10: 0.007331447\n",
            "  recall@10: 0.007331447\n",
            "  ndcg@10: 0.007291153\n",
            "  map@10: 0.002242101\n",
            "Epoch 146, Step 20, LR: 0.000834, Current Loss: 0.5302, Avg Loss: 0.5324\n",
            "Diff stats — min: -7.0086, max: 10.0000, mean: 7.1942, std: 3.0345\n",
            "\n",
            "Epoch 146 completed, Train Loss: 0.000131\n",
            "\n",
            "Epoch 147, Step 1, LR: 0.000834, Current Loss: 0.5213, Avg Loss: 0.5213\n",
            "Diff stats — min: -9.7953, max: 10.0000, mean: 7.2291, std: 3.0104\n",
            "\n",
            "Step 4351 — Test metrics:\n",
            "  precision@10: 0.006883545\n",
            "  recall@10: 0.006886165\n",
            "  ndcg@10: 0.006978373\n",
            "  map@10: 0.002184805\n",
            "Epoch 147, Step 20, LR: 0.000834, Current Loss: 0.5202, Avg Loss: 0.5332\n",
            "Diff stats — min: -5.2363, max: 10.0000, mean: 7.2485, std: 3.0514\n",
            "\n",
            "Epoch 147 completed, Train Loss: 0.000132\n",
            "\n",
            "Epoch 148, Step 1, LR: 0.000834, Current Loss: 0.5250, Avg Loss: 0.5250\n",
            "Diff stats — min: -5.3677, max: 10.0000, mean: 7.2872, std: 2.9746\n",
            "\n",
            "Step 4381 — Test metrics:\n",
            "  precision@10: 0.007166431\n",
            "  recall@10: 0.007166431\n",
            "  ndcg@10: 0.007199387\n",
            "  map@10: 0.002235122\n",
            "Epoch 148, Step 20, LR: 0.000834, Current Loss: 0.5445, Avg Loss: 0.5330\n",
            "Diff stats — min: -7.8849, max: 10.0000, mean: 7.3064, std: 3.0430\n",
            "\n",
            "Epoch 148 completed, Train Loss: 0.000131\n",
            "\n",
            "Epoch 149, Step 1, LR: 0.000834, Current Loss: 0.5430, Avg Loss: 0.5430\n",
            "Diff stats — min: -8.7237, max: 10.0000, mean: 7.3299, std: 3.0490\n",
            "\n",
            "Step 4411 — Test metrics:\n",
            "  precision@10: 0.006883545\n",
            "  recall@10: 0.006886165\n",
            "  ndcg@10: 0.007150514\n",
            "  map@10: 0.002295114\n",
            "Epoch 149, Step 20, LR: 0.000834, Current Loss: 0.5338, Avg Loss: 0.5331\n",
            "Diff stats — min: -4.4455, max: 10.0000, mean: 7.3027, std: 2.9670\n",
            "\n",
            "Epoch 149 completed, Train Loss: 0.000131\n",
            "\n",
            "Epoch 150, Step 1, LR: 0.000834, Current Loss: 0.5269, Avg Loss: 0.5269\n",
            "Diff stats — min: -4.4597, max: 10.0000, mean: 7.3294, std: 2.9517\n",
            "\n",
            "Step 4441 — Test metrics:\n",
            "  precision@10: 0.006954267\n",
            "  recall@10: 0.006954267\n",
            "  ndcg@10: 0.007143132\n",
            "  map@10: 0.002269220\n",
            "Epoch 150, Step 20, LR: 0.000834, Current Loss: 0.5483, Avg Loss: 0.5316\n",
            "Diff stats — min: -7.4166, max: 10.0000, mean: 7.2805, std: 2.9957\n",
            "\n",
            "Epoch 150 completed, Train Loss: 0.000131\n",
            "\n",
            "Epoch 151, Step 1, LR: 0.000817, Current Loss: 0.5280, Avg Loss: 0.5280\n",
            "Diff stats — min: -4.5168, max: 10.0000, mean: 7.3470, std: 2.9776\n",
            "\n",
            "Step 4471 — Test metrics:\n",
            "  precision@10: 0.007048562\n",
            "  recall@10: 0.007051181\n",
            "  ndcg@10: 0.007124475\n",
            "  map@10: 0.002240183\n",
            "Epoch 151, Step 20, LR: 0.000817, Current Loss: 0.5248, Avg Loss: 0.5295\n",
            "Diff stats — min: -7.9143, max: 10.0000, mean: 7.3797, std: 2.9703\n",
            "\n",
            "Epoch 151 completed, Train Loss: 0.000131\n",
            "\n",
            "Epoch 152, Step 1, LR: 0.000817, Current Loss: 0.5436, Avg Loss: 0.5436\n",
            "Diff stats — min: -6.6916, max: 10.0000, mean: 7.3702, std: 2.9971\n",
            "\n",
            "Step 4501 — Test metrics:\n",
            "  precision@10: 0.007024988\n",
            "  recall@10: 0.007037711\n",
            "  ndcg@10: 0.007211468\n",
            "  map@10: 0.002299857\n",
            "Epoch 152, Step 20, LR: 0.000817, Current Loss: 0.5223, Avg Loss: 0.5302\n",
            "Diff stats — min: -7.5690, max: 10.0000, mean: 7.3891, std: 2.9978\n",
            "\n",
            "Epoch 152 completed, Train Loss: 0.000131\n",
            "\n",
            "Epoch 153, Step 1, LR: 0.000817, Current Loss: 0.5244, Avg Loss: 0.5244\n",
            "Diff stats — min: -7.2808, max: 10.0000, mean: 7.3660, std: 2.9868\n",
            "\n",
            "Step 4531 — Test metrics:\n",
            "  precision@10: 0.007213579\n",
            "  recall@10: 0.007226301\n",
            "  ndcg@10: 0.007405175\n",
            "  map@10: 0.002342796\n",
            "Epoch 153, Step 20, LR: 0.000817, Current Loss: 0.5140, Avg Loss: 0.5305\n",
            "Diff stats — min: -7.7350, max: 10.0000, mean: 7.3556, std: 2.9858\n",
            "\n",
            "Epoch 153 completed, Train Loss: 0.000131\n",
            "\n",
            "Epoch 154, Step 1, LR: 0.000817, Current Loss: 0.5231, Avg Loss: 0.5231\n",
            "Diff stats — min: -6.7281, max: 10.0000, mean: 7.3392, std: 3.0037\n",
            "\n",
            "Step 4561 — Test metrics:\n",
            "  precision@10: 0.006977841\n",
            "  recall@10: 0.006990563\n",
            "  ndcg@10: 0.007335205\n",
            "  map@10: 0.002378875\n",
            "Epoch 154, Step 20, LR: 0.000817, Current Loss: 0.5218, Avg Loss: 0.5293\n",
            "Diff stats — min: -5.3626, max: 10.0000, mean: 7.3708, std: 2.9829\n",
            "\n",
            "Epoch 154 completed, Train Loss: 0.000131\n",
            "\n",
            "Epoch 155, Step 1, LR: 0.000817, Current Loss: 0.5174, Avg Loss: 0.5174\n",
            "Diff stats — min: -4.8084, max: 10.0000, mean: 7.4096, std: 2.9122\n",
            "\n",
            "Step 4591 — Test metrics:\n",
            "  precision@10: 0.006812824\n",
            "  recall@10: 0.006825547\n",
            "  ndcg@10: 0.007201660\n",
            "  map@10: 0.002326031\n",
            "Epoch 155, Step 20, LR: 0.000817, Current Loss: 0.5199, Avg Loss: 0.5301\n",
            "Diff stats — min: -5.6124, max: 10.0000, mean: 7.4798, std: 2.8998\n",
            "\n",
            "Epoch 155 completed, Train Loss: 0.000131\n",
            "\n",
            "Epoch 156, Step 1, LR: 0.000801, Current Loss: 0.5223, Avg Loss: 0.5223\n",
            "Diff stats — min: -4.9138, max: 10.0000, mean: 7.2745, std: 2.9672\n",
            "\n",
            "Step 4621 — Test metrics:\n",
            "  precision@10: 0.007331447\n",
            "  recall@10: 0.007346789\n",
            "  ndcg@10: 0.007544890\n",
            "  map@10: 0.002386062\n",
            "Epoch 156, Step 20, LR: 0.000801, Current Loss: 0.5185, Avg Loss: 0.5280\n",
            "Diff stats — min: -5.4937, max: 10.0000, mean: 7.3940, std: 2.9456\n",
            "\n",
            "Epoch 156 completed, Train Loss: 0.000130\n",
            "\n",
            "Epoch 157, Step 1, LR: 0.000801, Current Loss: 0.5345, Avg Loss: 0.5345\n",
            "Diff stats — min: -5.4323, max: 10.0000, mean: 7.3790, std: 2.9687\n",
            "\n",
            "Step 4651 — Test metrics:\n",
            "  precision@10: 0.007355021\n",
            "  recall@10: 0.007367744\n",
            "  ndcg@10: 0.007502790\n",
            "  map@10: 0.002345957\n",
            "Epoch 157, Step 20, LR: 0.000801, Current Loss: 0.5194, Avg Loss: 0.5283\n",
            "Diff stats — min: -7.2662, max: 10.0000, mean: 7.3840, std: 2.9735\n",
            "\n",
            "Epoch 157 completed, Train Loss: 0.000131\n",
            "\n",
            "Epoch 158, Step 1, LR: 0.000801, Current Loss: 0.5308, Avg Loss: 0.5308\n",
            "Diff stats — min: -6.2837, max: 10.0000, mean: 7.4274, std: 2.9561\n",
            "\n",
            "Step 4681 — Test metrics:\n",
            "  precision@10: 0.007284300\n",
            "  recall@10: 0.007304880\n",
            "  ndcg@10: 0.007485893\n",
            "  map@10: 0.002369017\n",
            "Epoch 158, Step 20, LR: 0.000801, Current Loss: 0.5201, Avg Loss: 0.5281\n",
            "Diff stats — min: -4.4331, max: 10.0000, mean: 7.3661, std: 2.9564\n",
            "\n",
            "Epoch 158 completed, Train Loss: 0.000130\n",
            "\n",
            "Epoch 159, Step 1, LR: 0.000801, Current Loss: 0.5302, Avg Loss: 0.5302\n",
            "Diff stats — min: -9.2164, max: 10.0000, mean: 7.3795, std: 2.9814\n",
            "\n",
            "Step 4711 — Test metrics:\n",
            "  precision@10: 0.007496464\n",
            "  recall@10: 0.007504322\n",
            "  ndcg@10: 0.007420762\n",
            "  map@10: 0.002282155\n",
            "Epoch 159, Step 20, LR: 0.000801, Current Loss: 0.5234, Avg Loss: 0.5281\n",
            "Diff stats — min: -8.8236, max: 10.0000, mean: 7.3858, std: 3.0257\n",
            "\n",
            "Epoch 159 completed, Train Loss: 0.000130\n",
            "\n",
            "Epoch 160, Step 1, LR: 0.000801, Current Loss: 0.5327, Avg Loss: 0.5327\n",
            "Diff stats — min: -5.8047, max: 10.0000, mean: 7.3551, std: 2.9975\n",
            "\n",
            "Step 4741 — Test metrics:\n",
            "  precision@10: 0.007543612\n",
            "  recall@10: 0.007553715\n",
            "  ndcg@10: 0.007699400\n",
            "  map@10: 0.002441898\n",
            "Epoch 160, Step 20, LR: 0.000801, Current Loss: 0.5217, Avg Loss: 0.5248\n",
            "Diff stats — min: -8.8756, max: 10.0000, mean: 7.5034, std: 2.9267\n",
            "\n",
            "Epoch 160 completed, Train Loss: 0.000130\n",
            "\n",
            "Epoch 161, Step 1, LR: 0.000785, Current Loss: 0.5181, Avg Loss: 0.5181\n",
            "Diff stats — min: -6.5068, max: 10.0000, mean: 7.5627, std: 2.9327\n",
            "\n",
            "Step 4771 — Test metrics:\n",
            "  precision@10: 0.007661480\n",
            "  recall@10: 0.007666719\n",
            "  ndcg@10: 0.007725918\n",
            "  map@10: 0.002414891\n",
            "Epoch 161, Step 20, LR: 0.000785, Current Loss: 0.5365, Avg Loss: 0.5266\n",
            "Diff stats — min: -8.1826, max: 10.0000, mean: 7.4853, std: 2.9215\n",
            "\n",
            "Epoch 161 completed, Train Loss: 0.000130\n",
            "\n",
            "Epoch 162, Step 1, LR: 0.000785, Current Loss: 0.5240, Avg Loss: 0.5240\n",
            "Diff stats — min: -6.0437, max: 10.0000, mean: 7.4588, std: 2.9422\n",
            "\n",
            "Step 4801 — Test metrics:\n",
            "  precision@10: 0.007614333\n",
            "  recall@10: 0.007629675\n",
            "  ndcg@10: 0.007855704\n",
            "  map@10: 0.002498098\n",
            "Epoch 162, Step 20, LR: 0.000785, Current Loss: 0.5277, Avg Loss: 0.5252\n",
            "Diff stats — min: -6.2102, max: 10.0000, mean: 7.4771, std: 2.9114\n",
            "\n",
            "Epoch 162 completed, Train Loss: 0.000130\n",
            "\n",
            "Epoch 163, Step 1, LR: 0.000785, Current Loss: 0.5086, Avg Loss: 0.5086\n",
            "Diff stats — min: -7.0432, max: 10.0000, mean: 7.4431, std: 2.9846\n",
            "\n",
            "Step 4831 — Test metrics:\n",
            "  precision@10: 0.007732202\n",
            "  recall@10: 0.007734821\n",
            "  ndcg@10: 0.007905100\n",
            "  map@10: 0.002500402\n",
            "Epoch 163, Step 20, LR: 0.000785, Current Loss: 0.5318, Avg Loss: 0.5261\n",
            "Diff stats — min: -5.3947, max: 10.0000, mean: 7.5471, std: 2.9292\n",
            "\n",
            "Epoch 163 completed, Train Loss: 0.000130\n",
            "\n",
            "Epoch 164, Step 1, LR: 0.000785, Current Loss: 0.5311, Avg Loss: 0.5311\n",
            "Diff stats — min: -6.2009, max: 10.0000, mean: 7.5623, std: 2.8990\n",
            "\n",
            "Step 4861 — Test metrics:\n",
            "  precision@10: 0.007732202\n",
            "  recall@10: 0.007744924\n",
            "  ndcg@10: 0.007929332\n",
            "  map@10: 0.002520337\n",
            "Epoch 164, Step 20, LR: 0.000785, Current Loss: 0.5359, Avg Loss: 0.5252\n",
            "Diff stats — min: -5.2397, max: 10.0000, mean: 7.4214, std: 3.0020\n",
            "\n",
            "Epoch 164 completed, Train Loss: 0.000130\n",
            "\n",
            "Epoch 165, Step 1, LR: 0.000785, Current Loss: 0.5265, Avg Loss: 0.5265\n",
            "Diff stats — min: -6.1614, max: 10.0000, mean: 7.5143, std: 2.8727\n",
            "\n",
            "Step 4891 — Test metrics:\n",
            "  precision@10: 0.007873645\n",
            "  recall@10: 0.007886367\n",
            "  ndcg@10: 0.008094484\n",
            "  map@10: 0.002582106\n",
            "Epoch 165, Step 20, LR: 0.000785, Current Loss: 0.5367, Avg Loss: 0.5252\n",
            "Diff stats — min: -7.8230, max: 10.0000, mean: 7.4847, std: 2.9510\n",
            "\n",
            "Epoch 165 completed, Train Loss: 0.000130\n",
            "\n",
            "Epoch 166, Step 1, LR: 0.000769, Current Loss: 0.5208, Avg Loss: 0.5208\n",
            "Diff stats — min: -7.9122, max: 10.0000, mean: 7.5501, std: 2.9413\n",
            "\n",
            "Step 4921 — Test metrics:\n",
            "  precision@10: 0.007873645\n",
            "  recall@10: 0.007886367\n",
            "  ndcg@10: 0.008033703\n",
            "  map@10: 0.002536632\n",
            "Epoch 166, Step 20, LR: 0.000769, Current Loss: 0.5244, Avg Loss: 0.5243\n",
            "Diff stats — min: -6.2314, max: 10.0000, mean: 7.5420, std: 2.8926\n",
            "\n",
            "Epoch 166 completed, Train Loss: 0.000130\n",
            "\n",
            "Epoch 167, Step 1, LR: 0.000769, Current Loss: 0.5191, Avg Loss: 0.5191\n",
            "Diff stats — min: -6.7117, max: 10.0000, mean: 7.4381, std: 3.0002\n",
            "\n",
            "Step 4951 — Test metrics:\n",
            "  precision@10: 0.007967940\n",
            "  recall@10: 0.007983281\n",
            "  ndcg@10: 0.008280006\n",
            "  map@10: 0.002666495\n",
            "Epoch 167, Step 20, LR: 0.000769, Current Loss: 0.5135, Avg Loss: 0.5233\n",
            "Diff stats — min: -7.6877, max: 10.0000, mean: 7.5375, std: 2.9160\n",
            "\n",
            "Epoch 167 completed, Train Loss: 0.000130\n",
            "\n",
            "Epoch 168, Step 1, LR: 0.000769, Current Loss: 0.5235, Avg Loss: 0.5235\n",
            "Diff stats — min: -7.1875, max: 10.0000, mean: 7.5636, std: 2.8990\n",
            "\n",
            "Step 4981 — Test metrics:\n",
            "  precision@10: 0.007944366\n",
            "  recall@10: 0.007959708\n",
            "  ndcg@10: 0.008201407\n",
            "  map@10: 0.002634621\n",
            "Epoch 168, Step 20, LR: 0.000769, Current Loss: 0.5168, Avg Loss: 0.5248\n",
            "Diff stats — min: -6.2669, max: 10.0000, mean: 7.5850, std: 2.9005\n",
            "\n",
            "Epoch 168 completed, Train Loss: 0.000130\n",
            "\n",
            "Epoch 169, Step 1, LR: 0.000769, Current Loss: 0.5391, Avg Loss: 0.5391\n",
            "Diff stats — min: -6.4999, max: 10.0000, mean: 7.5296, std: 2.9533\n",
            "\n",
            "Step 5011 — Test metrics:\n",
            "  precision@10: 0.008156530\n",
            "  recall@10: 0.008164388\n",
            "  ndcg@10: 0.008507983\n",
            "  map@10: 0.002769385\n",
            "Epoch 169, Step 20, LR: 0.000769, Current Loss: 0.5039, Avg Loss: 0.5257\n",
            "Diff stats — min: -6.1033, max: 10.0000, mean: 7.5568, std: 2.8827\n",
            "\n",
            "Epoch 169 completed, Train Loss: 0.000130\n",
            "\n",
            "Epoch 170, Step 1, LR: 0.000769, Current Loss: 0.5245, Avg Loss: 0.5245\n",
            "Diff stats — min: -5.5944, max: 10.0000, mean: 7.5011, std: 2.9408\n",
            "\n",
            "Step 5041 — Test metrics:\n",
            "  precision@10: 0.008109382\n",
            "  recall@10: 0.008122105\n",
            "  ndcg@10: 0.008548026\n",
            "  map@10: 0.002801267\n",
            "Epoch 170, Step 20, LR: 0.000769, Current Loss: 0.5345, Avg Loss: 0.5257\n",
            "Diff stats — min: -6.1305, max: 10.0000, mean: 7.5637, std: 2.8818\n",
            "\n",
            "Epoch 170 completed, Train Loss: 0.000129\n",
            "\n",
            "Epoch 171, Step 1, LR: 0.000754, Current Loss: 0.5294, Avg Loss: 0.5294\n",
            "Diff stats — min: -7.1699, max: 10.0000, mean: 7.5616, std: 2.8720\n",
            "\n",
            "Step 5071 — Test metrics:\n",
            "  precision@10: 0.008156530\n",
            "  recall@10: 0.008174491\n",
            "  ndcg@10: 0.008587653\n",
            "  map@10: 0.002803532\n",
            "Epoch 171, Step 20, LR: 0.000754, Current Loss: 0.5264, Avg Loss: 0.5235\n",
            "Diff stats — min: -5.7404, max: 10.0000, mean: 7.5770, std: 2.8405\n",
            "\n",
            "Epoch 171 completed, Train Loss: 0.000129\n",
            "\n",
            "Epoch 172, Step 1, LR: 0.000754, Current Loss: 0.5244, Avg Loss: 0.5244\n",
            "Diff stats — min: -6.7871, max: 10.0000, mean: 7.5459, std: 2.9501\n",
            "\n",
            "Step 5101 — Test metrics:\n",
            "  precision@10: 0.007897218\n",
            "  recall@10: 0.007915179\n",
            "  ndcg@10: 0.008373042\n",
            "  map@10: 0.002760622\n",
            "Epoch 172, Step 20, LR: 0.000754, Current Loss: 0.5241, Avg Loss: 0.5244\n",
            "Diff stats — min: -4.9616, max: 10.0000, mean: 7.4822, std: 2.9555\n",
            "\n",
            "Epoch 172 completed, Train Loss: 0.000130\n",
            "\n",
            "Epoch 173, Step 1, LR: 0.000754, Current Loss: 0.5029, Avg Loss: 0.5029\n",
            "Diff stats — min: -6.1296, max: 10.0000, mean: 7.6518, std: 2.8678\n",
            "\n",
            "Step 5131 — Test metrics:\n",
            "  precision@10: 0.008227251\n",
            "  recall@10: 0.008242593\n",
            "  ndcg@10: 0.008713920\n",
            "  map@10: 0.002885771\n",
            "Epoch 173, Step 20, LR: 0.000754, Current Loss: 0.5090, Avg Loss: 0.5208\n",
            "Diff stats — min: -9.7799, max: 10.0000, mean: 7.5645, std: 2.9218\n",
            "\n",
            "Epoch 173 completed, Train Loss: 0.000129\n",
            "\n",
            "Epoch 174, Step 1, LR: 0.000754, Current Loss: 0.5223, Avg Loss: 0.5223\n",
            "Diff stats — min: -4.7766, max: 10.0000, mean: 7.6125, std: 2.8651\n",
            "\n",
            "Step 5161 — Test metrics:\n",
            "  precision@10: 0.008510137\n",
            "  recall@10: 0.008525478\n",
            "  ndcg@10: 0.008939654\n",
            "  map@10: 0.002946658\n",
            "Epoch 174, Step 20, LR: 0.000754, Current Loss: 0.5188, Avg Loss: 0.5238\n",
            "Diff stats — min: -7.2181, max: 10.0000, mean: 7.6076, std: 2.8335\n",
            "\n",
            "Epoch 174 completed, Train Loss: 0.000129\n",
            "\n",
            "Epoch 175, Step 1, LR: 0.000754, Current Loss: 0.5340, Avg Loss: 0.5340\n",
            "Diff stats — min: -6.1876, max: 10.0000, mean: 7.5839, std: 2.9185\n",
            "\n",
            "Step 5191 — Test metrics:\n",
            "  precision@10: 0.008510137\n",
            "  recall@10: 0.008525478\n",
            "  ndcg@10: 0.008829466\n",
            "  map@10: 0.002881253\n",
            "Epoch 175, Step 20, LR: 0.000754, Current Loss: 0.5292, Avg Loss: 0.5223\n",
            "Diff stats — min: -9.5146, max: 10.0000, mean: 7.5581, std: 2.9726\n",
            "\n",
            "Epoch 175 completed, Train Loss: 0.000129\n",
            "\n",
            "Epoch 176, Step 1, LR: 0.000739, Current Loss: 0.5121, Avg Loss: 0.5121\n",
            "Diff stats — min: -7.6673, max: 10.0000, mean: 7.5946, std: 2.8900\n",
            "\n",
            "Step 5221 — Test metrics:\n",
            "  precision@10: 0.007944366\n",
            "  recall@10: 0.007959708\n",
            "  ndcg@10: 0.008418720\n",
            "  map@10: 0.002769081\n",
            "Epoch 176, Step 20, LR: 0.000739, Current Loss: 0.5274, Avg Loss: 0.5241\n",
            "Diff stats — min: -7.4544, max: 10.0000, mean: 7.5527, std: 2.9066\n",
            "\n",
            "Epoch 176 completed, Train Loss: 0.000129\n",
            "\n",
            "Epoch 177, Step 1, LR: 0.000739, Current Loss: 0.5101, Avg Loss: 0.5101\n",
            "Diff stats — min: -7.9651, max: 10.0000, mean: 7.5931, std: 2.9003\n",
            "\n",
            "Step 5251 — Test metrics:\n",
            "  precision@10: 0.008015087\n",
            "  recall@10: 0.008027810\n",
            "  ndcg@10: 0.008421277\n",
            "  map@10: 0.002751357\n",
            "Epoch 177, Step 20, LR: 0.000739, Current Loss: 0.5199, Avg Loss: 0.5204\n",
            "Diff stats — min: -5.1834, max: 10.0000, mean: 7.5822, std: 2.8564\n",
            "\n",
            "Epoch 177 completed, Train Loss: 0.000129\n",
            "\n",
            "Epoch 178, Step 1, LR: 0.000739, Current Loss: 0.5198, Avg Loss: 0.5198\n",
            "Diff stats — min: -6.6817, max: 10.0000, mean: 7.6054, std: 2.8772\n",
            "\n",
            "Step 5281 — Test metrics:\n",
            "  precision@10: 0.008227251\n",
            "  recall@10: 0.008242593\n",
            "  ndcg@10: 0.008549927\n",
            "  map@10: 0.002798018\n",
            "Epoch 178, Step 20, LR: 0.000739, Current Loss: 0.5178, Avg Loss: 0.5192\n",
            "Diff stats — min: -8.3117, max: 10.0000, mean: 7.6127, std: 2.9049\n",
            "\n",
            "Epoch 178 completed, Train Loss: 0.000129\n",
            "\n",
            "Epoch 179, Step 1, LR: 0.000739, Current Loss: 0.5204, Avg Loss: 0.5204\n",
            "Diff stats — min: -5.8704, max: 10.0000, mean: 7.6838, std: 2.9037\n",
            "\n",
            "Step 5311 — Test metrics:\n",
            "  precision@10: 0.007967940\n",
            "  recall@10: 0.008008726\n",
            "  ndcg@10: 0.008391959\n",
            "  map@10: 0.002785284\n",
            "Epoch 179, Step 20, LR: 0.000739, Current Loss: 0.5047, Avg Loss: 0.5242\n",
            "Diff stats — min: -7.8596, max: 10.0000, mean: 7.6476, std: 2.8738\n",
            "\n",
            "Epoch 179 completed, Train Loss: 0.000129\n",
            "\n",
            "Epoch 180, Step 1, LR: 0.000739, Current Loss: 0.5334, Avg Loss: 0.5334\n",
            "Diff stats — min: -7.1706, max: 10.0000, mean: 7.6255, std: 2.8953\n",
            "\n",
            "Step 5341 — Test metrics:\n",
            "  precision@10: 0.008227251\n",
            "  recall@10: 0.008252696\n",
            "  ndcg@10: 0.008668627\n",
            "  map@10: 0.002876521\n",
            "Epoch 180, Step 20, LR: 0.000739, Current Loss: 0.5178, Avg Loss: 0.5219\n",
            "Diff stats — min: -6.8251, max: 10.0000, mean: 7.6470, std: 2.8842\n",
            "\n",
            "Epoch 180 completed, Train Loss: 0.000129\n",
            "\n",
            "Epoch 181, Step 1, LR: 0.000724, Current Loss: 0.5293, Avg Loss: 0.5293\n",
            "Diff stats — min: -9.3454, max: 10.0000, mean: 7.7170, std: 2.8796\n",
            "\n",
            "Step 5371 — Test metrics:\n",
            "  precision@10: 0.008274399\n",
            "  recall@10: 0.008289741\n",
            "  ndcg@10: 0.008817556\n",
            "  map@10: 0.002941320\n",
            "Epoch 181, Step 20, LR: 0.000724, Current Loss: 0.5245, Avg Loss: 0.5188\n",
            "Diff stats — min: -6.3794, max: 10.0000, mean: 7.6408, std: 2.8919\n",
            "\n",
            "Epoch 181 completed, Train Loss: 0.000129\n",
            "\n",
            "Epoch 182, Step 1, LR: 0.000724, Current Loss: 0.5068, Avg Loss: 0.5068\n",
            "Diff stats — min: -6.0618, max: 10.0000, mean: 7.6863, std: 2.8517\n",
            "\n",
            "Step 5401 — Test metrics:\n",
            "  precision@10: 0.008462989\n",
            "  recall@10: 0.008478331\n",
            "  ndcg@10: 0.009014847\n",
            "  map@10: 0.003012648\n",
            "Epoch 182, Step 20, LR: 0.000724, Current Loss: 0.5058, Avg Loss: 0.5175\n",
            "Diff stats — min: -6.4078, max: 10.0000, mean: 7.7304, std: 2.8533\n",
            "\n",
            "Epoch 182 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 183, Step 1, LR: 0.000724, Current Loss: 0.5247, Avg Loss: 0.5247\n",
            "Diff stats — min: -4.9619, max: 10.0000, mean: 7.6091, std: 2.9306\n",
            "\n",
            "Step 5431 — Test metrics:\n",
            "  precision@10: 0.008557284\n",
            "  recall@10: 0.008572626\n",
            "  ndcg@10: 0.009174401\n",
            "  map@10: 0.003066856\n",
            "Epoch 183, Step 20, LR: 0.000724, Current Loss: 0.5282, Avg Loss: 0.5212\n",
            "Diff stats — min: -6.5157, max: 10.0000, mean: 7.6916, std: 2.9107\n",
            "\n",
            "Epoch 183 completed, Train Loss: 0.000129\n",
            "\n",
            "Epoch 184, Step 1, LR: 0.000724, Current Loss: 0.5244, Avg Loss: 0.5244\n",
            "Diff stats — min: -7.5893, max: 10.0000, mean: 7.7013, std: 2.8472\n",
            "\n",
            "Step 5461 — Test metrics:\n",
            "  precision@10: 0.008510137\n",
            "  recall@10: 0.008540820\n",
            "  ndcg@10: 0.009070758\n",
            "  map@10: 0.003048476\n",
            "Epoch 184, Step 20, LR: 0.000724, Current Loss: 0.5052, Avg Loss: 0.5164\n",
            "Diff stats — min: -5.1069, max: 10.0000, mean: 7.6877, std: 2.8784\n",
            "\n",
            "Epoch 184 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 185, Step 1, LR: 0.000724, Current Loss: 0.5208, Avg Loss: 0.5208\n",
            "Diff stats — min: -7.7066, max: 10.0000, mean: 7.7357, std: 2.8367\n",
            "\n",
            "Step 5491 — Test metrics:\n",
            "  precision@10: 0.008769448\n",
            "  recall@10: 0.008810235\n",
            "  ndcg@10: 0.009281305\n",
            "  map@10: 0.003078009\n",
            "Epoch 185, Step 20, LR: 0.000724, Current Loss: 0.5028, Avg Loss: 0.5188\n",
            "Diff stats — min: -6.3921, max: 10.0000, mean: 7.6828, std: 2.8586\n",
            "\n",
            "Epoch 185 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 186, Step 1, LR: 0.000709, Current Loss: 0.5161, Avg Loss: 0.5161\n",
            "Diff stats — min: -5.6822, max: 10.0000, mean: 7.7299, std: 2.8416\n",
            "\n",
            "Step 5521 — Test metrics:\n",
            "  precision@10: 0.008510137\n",
            "  recall@10: 0.008528098\n",
            "  ndcg@10: 0.009202846\n",
            "  map@10: 0.003115994\n",
            "Epoch 186, Step 20, LR: 0.000709, Current Loss: 0.5377, Avg Loss: 0.5185\n",
            "Diff stats — min: -7.6036, max: 10.0000, mean: 7.7376, std: 2.9089\n",
            "\n",
            "Epoch 186 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 187, Step 1, LR: 0.000709, Current Loss: 0.5183, Avg Loss: 0.5183\n",
            "Diff stats — min: -6.2000, max: 10.0000, mean: 7.6964, std: 2.8549\n",
            "\n",
            "Step 5551 — Test metrics:\n",
            "  precision@10: 0.008698727\n",
            "  recall@10: 0.008716688\n",
            "  ndcg@10: 0.009350523\n",
            "  map@10: 0.003151570\n",
            "Epoch 187, Step 20, LR: 0.000709, Current Loss: 0.5112, Avg Loss: 0.5214\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 7.7254, std: 2.8963\n",
            "\n",
            "Epoch 187 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 188, Step 1, LR: 0.000709, Current Loss: 0.5083, Avg Loss: 0.5083\n",
            "Diff stats — min: -7.8666, max: 10.0000, mean: 7.7749, std: 2.8431\n",
            "\n",
            "Step 5581 — Test metrics:\n",
            "  precision@10: 0.008745875\n",
            "  recall@10: 0.008769074\n",
            "  ndcg@10: 0.009493205\n",
            "  map@10: 0.003236073\n",
            "Epoch 188, Step 20, LR: 0.000709, Current Loss: 0.5089, Avg Loss: 0.5199\n",
            "Diff stats — min: -6.2378, max: 10.0000, mean: 7.7388, std: 2.8374\n",
            "\n",
            "Epoch 188 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 189, Step 1, LR: 0.000709, Current Loss: 0.5152, Avg Loss: 0.5152\n",
            "Diff stats — min: -7.3974, max: 10.0000, mean: 7.8064, std: 2.8554\n",
            "\n",
            "Step 5611 — Test metrics:\n",
            "  precision@10: 0.008321546\n",
            "  recall@10: 0.008339507\n",
            "  ndcg@10: 0.009010787\n",
            "  map@10: 0.003006463\n",
            "Epoch 189, Step 20, LR: 0.000709, Current Loss: 0.5187, Avg Loss: 0.5197\n",
            "Diff stats — min: -5.2525, max: 10.0000, mean: 7.7870, std: 2.7868\n",
            "\n",
            "Epoch 189 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 190, Step 1, LR: 0.000709, Current Loss: 0.5029, Avg Loss: 0.5029\n",
            "Diff stats — min: -5.0330, max: 10.0000, mean: 7.7591, std: 2.7991\n",
            "\n",
            "Step 5641 — Test metrics:\n",
            "  precision@10: 0.008675153\n",
            "  recall@10: 0.008693114\n",
            "  ndcg@10: 0.009219850\n",
            "  map@10: 0.003069001\n",
            "Epoch 190, Step 20, LR: 0.000709, Current Loss: 0.5205, Avg Loss: 0.5215\n",
            "Diff stats — min: -4.9543, max: 10.0000, mean: 7.7392, std: 2.8584\n",
            "\n",
            "Epoch 190 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 191, Step 1, LR: 0.000695, Current Loss: 0.5223, Avg Loss: 0.5223\n",
            "Diff stats — min: -9.7717, max: 10.0000, mean: 7.7636, std: 2.8394\n",
            "\n",
            "Step 5671 — Test metrics:\n",
            "  precision@10: 0.008604432\n",
            "  recall@10: 0.008614909\n",
            "  ndcg@10: 0.009192775\n",
            "  map@10: 0.003065017\n",
            "Epoch 191, Step 20, LR: 0.000695, Current Loss: 0.5276, Avg Loss: 0.5157\n",
            "Diff stats — min: -6.6196, max: 10.0000, mean: 7.7744, std: 2.8510\n",
            "\n",
            "Epoch 191 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 192, Step 1, LR: 0.000695, Current Loss: 0.5244, Avg Loss: 0.5244\n",
            "Diff stats — min: -7.3316, max: 10.0000, mean: 7.7859, std: 2.8400\n",
            "\n",
            "Step 5701 — Test metrics:\n",
            "  precision@10: 0.009217350\n",
            "  recall@10: 0.009253272\n",
            "  ndcg@10: 0.009675359\n",
            "  map@10: 0.003208420\n",
            "Epoch 192, Step 20, LR: 0.000695, Current Loss: 0.5170, Avg Loss: 0.5186\n",
            "Diff stats — min: -7.6646, max: 10.0000, mean: 7.7990, std: 2.7920\n",
            "\n",
            "Epoch 192 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 193, Step 1, LR: 0.000695, Current Loss: 0.5295, Avg Loss: 0.5295\n",
            "Diff stats — min: -6.0233, max: 10.0000, mean: 7.7690, std: 2.8513\n",
            "\n",
            "Step 5731 — Test metrics:\n",
            "  precision@10: 0.008958039\n",
            "  recall@10: 0.008983858\n",
            "  ndcg@10: 0.009483226\n",
            "  map@10: 0.003182725\n",
            "Epoch 193, Step 20, LR: 0.000695, Current Loss: 0.5284, Avg Loss: 0.5207\n",
            "Diff stats — min: -5.8699, max: 10.0000, mean: 7.7588, std: 2.8533\n",
            "\n",
            "Epoch 193 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 194, Step 1, LR: 0.000695, Current Loss: 0.5167, Avg Loss: 0.5167\n",
            "Diff stats — min: -6.3902, max: 10.0000, mean: 7.7284, std: 2.8651\n",
            "\n",
            "Step 5761 — Test metrics:\n",
            "  precision@10: 0.009099481\n",
            "  recall@10: 0.009132784\n",
            "  ndcg@10: 0.009513614\n",
            "  map@10: 0.003125929\n",
            "Epoch 194, Step 20, LR: 0.000695, Current Loss: 0.5198, Avg Loss: 0.5177\n",
            "Diff stats — min: -6.7135, max: 10.0000, mean: 7.8117, std: 2.8237\n",
            "\n",
            "Epoch 194 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 195, Step 1, LR: 0.000695, Current Loss: 0.5079, Avg Loss: 0.5079\n",
            "Diff stats — min: -9.2397, max: 10.0000, mean: 7.7922, std: 2.8456\n",
            "\n",
            "Step 5791 — Test metrics:\n",
            "  precision@10: 0.009099481\n",
            "  recall@10: 0.009122681\n",
            "  ndcg@10: 0.009543749\n",
            "  map@10: 0.003154024\n",
            "Epoch 195, Step 20, LR: 0.000695, Current Loss: 0.5356, Avg Loss: 0.5186\n",
            "Diff stats — min: -9.9941, max: 10.0000, mean: 7.7673, std: 2.8702\n",
            "\n",
            "Epoch 195 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 196, Step 1, LR: 0.000681, Current Loss: 0.5193, Avg Loss: 0.5193\n",
            "Diff stats — min: -6.8075, max: 10.0000, mean: 7.7803, std: 2.8439\n",
            "\n",
            "Step 5821 — Test metrics:\n",
            "  precision@10: 0.008981612\n",
            "  recall@10: 0.009002193\n",
            "  ndcg@10: 0.009427398\n",
            "  map@10: 0.003103130\n",
            "Epoch 196, Step 20, LR: 0.000681, Current Loss: 0.5251, Avg Loss: 0.5175\n",
            "Diff stats — min: -6.2517, max: 10.0000, mean: 7.7944, std: 2.8667\n",
            "\n",
            "Epoch 196 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 197, Step 1, LR: 0.000681, Current Loss: 0.5233, Avg Loss: 0.5233\n",
            "Diff stats — min: -5.9024, max: 10.0000, mean: 7.7694, std: 2.8564\n",
            "\n",
            "Step 5851 — Test metrics:\n",
            "  precision@10: 0.008910891\n",
            "  recall@10: 0.008946813\n",
            "  ndcg@10: 0.009413984\n",
            "  map@10: 0.003120758\n",
            "Epoch 197, Step 20, LR: 0.000681, Current Loss: 0.5283, Avg Loss: 0.5175\n",
            "Diff stats — min: -5.8504, max: 10.0000, mean: 7.8069, std: 2.8108\n",
            "\n",
            "Epoch 197 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 198, Step 1, LR: 0.000681, Current Loss: 0.5224, Avg Loss: 0.5224\n",
            "Diff stats — min: -5.0240, max: 10.0000, mean: 7.8298, std: 2.7775\n",
            "\n",
            "Step 5881 — Test metrics:\n",
            "  precision@10: 0.009005186\n",
            "  recall@10: 0.009031005\n",
            "  ndcg@10: 0.009425374\n",
            "  map@10: 0.003120586\n",
            "Epoch 198, Step 20, LR: 0.000681, Current Loss: 0.5197, Avg Loss: 0.5208\n",
            "Diff stats — min: -6.9683, max: 10.0000, mean: 7.8343, std: 2.8454\n",
            "\n",
            "Epoch 198 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 199, Step 1, LR: 0.000681, Current Loss: 0.5198, Avg Loss: 0.5198\n",
            "Diff stats — min: -6.5571, max: 10.0000, mean: 7.8239, std: 2.8204\n",
            "\n",
            "Step 5911 — Test metrics:\n",
            "  precision@10: 0.009099481\n",
            "  recall@10: 0.009115197\n",
            "  ndcg@10: 0.009570169\n",
            "  map@10: 0.003196010\n",
            "Epoch 199, Step 20, LR: 0.000681, Current Loss: 0.5125, Avg Loss: 0.5161\n",
            "Diff stats — min: -5.5463, max: 10.0000, mean: 7.8171, std: 2.8383\n",
            "\n",
            "Epoch 199 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 200, Step 1, LR: 0.000681, Current Loss: 0.5057, Avg Loss: 0.5057\n",
            "Diff stats — min: -5.4426, max: 10.0000, mean: 7.8215, std: 2.8186\n",
            "\n",
            "Step 5941 — Test metrics:\n",
            "  precision@10: 0.009217350\n",
            "  recall@10: 0.009254301\n",
            "  ndcg@10: 0.009545670\n",
            "  map@10: 0.003116488\n",
            "Epoch 200, Step 20, LR: 0.000681, Current Loss: 0.5042, Avg Loss: 0.5158\n",
            "Diff stats — min: -4.5654, max: 10.0000, mean: 7.9027, std: 2.6990\n",
            "\n",
            "Epoch 200 completed, Train Loss: 0.000127\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = train_model(model,\n",
        "                    data,\n",
        "                    (seq_ids, event_type, seq_times, seq_mask),\n",
        "                    edge_type=edge_type,\n",
        "                    num_epochs=num_epochs,\n",
        "                    lr=lr,\n",
        "                    batch_size=batch_size,\n",
        "                    print_every=print_every,\n",
        "                    test_every=test_every,\n",
        "                    top_k=top_k,\n",
        "                    test_batch_size=test_batch_size,\n",
        "                    scheduler_step_size=scheduler_step_size,\n",
        "                    scheduler_gamma=train_scheduler_gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyuwA7iyrmeA",
        "outputId": "a4f6f07b-512f-43f8-f72d-942f2bddb821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of training examples: 121468\n",
            "Epoch 201, Step 1, LR: 0.001000, Current Loss: 0.5159, Avg Loss: 0.5159\n",
            "Diff stats — min: -7.3293, max: 10.0000, mean: 7.8099, std: 2.8935\n",
            "\n",
            "Step 4247 — Test metrics:\n",
            "  precision@10: 0.009028760\n",
            "  recall@10: 0.009069921\n",
            "  ndcg@10: 0.009705921\n",
            "  map@10: 0.003322762\n",
            "Epoch 201, Step 20, LR: 0.001000, Current Loss: 0.5435, Avg Loss: 0.5180\n",
            "Diff stats — min: -6.1184, max: 10.0000, mean: 7.7913, std: 2.8955\n",
            "\n",
            "Epoch 201 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 202, Step 1, LR: 0.001000, Current Loss: 0.5340, Avg Loss: 0.5340\n",
            "Diff stats — min: -3.8437, max: 10.0000, mean: 7.8227, std: 2.7912\n",
            "\n",
            "Step 4277 — Test metrics:\n",
            "  precision@10: 0.008910891\n",
            "  recall@10: 0.008941949\n",
            "  ndcg@10: 0.009360574\n",
            "  map@10: 0.003130419\n",
            "Epoch 202, Step 20, LR: 0.001000, Current Loss: 0.5164, Avg Loss: 0.5188\n",
            "Diff stats — min: -6.3927, max: 10.0000, mean: 7.8914, std: 2.7479\n",
            "\n",
            "Epoch 202 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 203, Step 1, LR: 0.001000, Current Loss: 0.4958, Avg Loss: 0.4958\n",
            "Diff stats — min: -3.7339, max: 10.0000, mean: 7.8677, std: 2.7232\n",
            "\n",
            "Step 4307 — Test metrics:\n",
            "  precision@10: 0.009570957\n",
            "  recall@10: 0.009599395\n",
            "  ndcg@10: 0.010163431\n",
            "  map@10: 0.003452120\n",
            "Epoch 203, Step 20, LR: 0.001000, Current Loss: 0.5309, Avg Loss: 0.5158\n",
            "Diff stats — min: -5.8793, max: 10.0000, mean: 7.7719, std: 2.8741\n",
            "\n",
            "Epoch 203 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 204, Step 1, LR: 0.001000, Current Loss: 0.5234, Avg Loss: 0.5234\n",
            "Diff stats — min: -5.2858, max: 10.0000, mean: 7.8510, std: 2.8041\n",
            "\n",
            "Step 4337 — Test metrics:\n",
            "  precision@10: 0.009123055\n",
            "  recall@10: 0.009154113\n",
            "  ndcg@10: 0.009502127\n",
            "  map@10: 0.003125994\n",
            "Epoch 204, Step 20, LR: 0.001000, Current Loss: 0.5192, Avg Loss: 0.5178\n",
            "Diff stats — min: -5.4375, max: 10.0000, mean: 8.0157, std: 2.7527\n",
            "\n",
            "Epoch 204 completed, Train Loss: 0.000128\n",
            "\n",
            "Epoch 205, Step 1, LR: 0.001000, Current Loss: 0.5005, Avg Loss: 0.5005\n",
            "Diff stats — min: -5.0918, max: 10.0000, mean: 7.7953, std: 2.7895\n",
            "\n",
            "Step 4367 — Test metrics:\n",
            "  precision@10: 0.009217350\n",
            "  recall@10: 0.009255892\n",
            "  ndcg@10: 0.009577171\n",
            "  map@10: 0.003189209\n",
            "Epoch 205, Step 20, LR: 0.001000, Current Loss: 0.5134, Avg Loss: 0.5157\n",
            "Diff stats — min: -3.4252, max: 10.0000, mean: 7.8906, std: 2.7423\n",
            "\n",
            "Epoch 205 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 206, Step 1, LR: 0.000980, Current Loss: 0.5091, Avg Loss: 0.5091\n",
            "Diff stats — min: -5.2490, max: 10.0000, mean: 7.8469, std: 2.7841\n",
            "\n",
            "Step 4397 — Test metrics:\n",
            "  precision@10: 0.009618105\n",
            "  recall@10: 0.009661885\n",
            "  ndcg@10: 0.010092488\n",
            "  map@10: 0.003365756\n",
            "Epoch 206, Step 20, LR: 0.000980, Current Loss: 0.5127, Avg Loss: 0.5166\n",
            "Diff stats — min: -6.8904, max: 10.0000, mean: 7.8660, std: 2.8545\n",
            "\n",
            "Epoch 206 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 207, Step 1, LR: 0.000980, Current Loss: 0.5191, Avg Loss: 0.5191\n",
            "Diff stats — min: -6.8290, max: 10.0000, mean: 7.7921, std: 2.8577\n",
            "\n",
            "Step 4427 — Test metrics:\n",
            "  precision@10: 0.008981612\n",
            "  recall@10: 0.009017534\n",
            "  ndcg@10: 0.009527299\n",
            "  map@10: 0.003182057\n",
            "Epoch 207, Step 20, LR: 0.000980, Current Loss: 0.4974, Avg Loss: 0.5136\n",
            "Diff stats — min: -7.3635, max: 10.0000, mean: 7.8856, std: 2.7734\n",
            "\n",
            "Epoch 207 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 208, Step 1, LR: 0.000980, Current Loss: 0.5047, Avg Loss: 0.5047\n",
            "Diff stats — min: -7.4073, max: 10.0000, mean: 7.9954, std: 2.7236\n",
            "\n",
            "Step 4457 — Test metrics:\n",
            "  precision@10: 0.009806695\n",
            "  recall@10: 0.009860578\n",
            "  ndcg@10: 0.010263400\n",
            "  map@10: 0.003431187\n",
            "Epoch 208, Step 20, LR: 0.000980, Current Loss: 0.5003, Avg Loss: 0.5150\n",
            "Diff stats — min: -4.5265, max: 10.0000, mean: 7.9460, std: 2.7183\n",
            "\n",
            "Epoch 208 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 209, Step 1, LR: 0.000980, Current Loss: 0.5079, Avg Loss: 0.5079\n",
            "Diff stats — min: -4.9603, max: 10.0000, mean: 7.9537, std: 2.7467\n",
            "\n",
            "Step 4487 — Test metrics:\n",
            "  precision@10: 0.010089580\n",
            "  recall@10: 0.010140844\n",
            "  ndcg@10: 0.010409903\n",
            "  map@10: 0.003501819\n",
            "Epoch 209, Step 20, LR: 0.000980, Current Loss: 0.5092, Avg Loss: 0.5128\n",
            "Diff stats — min: -5.7343, max: 10.0000, mean: 7.8991, std: 2.7968\n",
            "\n",
            "Epoch 209 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 210, Step 1, LR: 0.000980, Current Loss: 0.5152, Avg Loss: 0.5152\n",
            "Diff stats — min: -7.9255, max: 10.0000, mean: 7.9211, std: 2.8240\n",
            "\n",
            "Step 4517 — Test metrics:\n",
            "  precision@10: 0.009924564\n",
            "  recall@10: 0.009960860\n",
            "  ndcg@10: 0.010181875\n",
            "  map@10: 0.003333872\n",
            "Epoch 210, Step 20, LR: 0.000980, Current Loss: 0.5177, Avg Loss: 0.5158\n",
            "Diff stats — min: -5.1281, max: 10.0000, mean: 7.9693, std: 2.7226\n",
            "\n",
            "Epoch 210 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 211, Step 1, LR: 0.000960, Current Loss: 0.5088, Avg Loss: 0.5088\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 7.9068, std: 2.7878\n",
            "\n",
            "Step 4547 — Test metrics:\n",
            "  precision@10: 0.010042433\n",
            "  recall@10: 0.010096316\n",
            "  ndcg@10: 0.010508314\n",
            "  map@10: 0.003547615\n",
            "Epoch 211, Step 20, LR: 0.000960, Current Loss: 0.5185, Avg Loss: 0.5145\n",
            "Diff stats — min: -5.0761, max: 10.0000, mean: 7.9525, std: 2.7541\n",
            "\n",
            "Epoch 211 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 212, Step 1, LR: 0.000960, Current Loss: 0.5023, Avg Loss: 0.5023\n",
            "Diff stats — min: -6.1338, max: 10.0000, mean: 8.0055, std: 2.6968\n",
            "\n",
            "Step 4577 — Test metrics:\n",
            "  precision@10: 0.010584630\n",
            "  recall@10: 0.010636268\n",
            "  ndcg@10: 0.011053921\n",
            "  map@10: 0.003739641\n",
            "Epoch 212, Step 20, LR: 0.000960, Current Loss: 0.5213, Avg Loss: 0.5144\n",
            "Diff stats — min: -8.4774, max: 10.0000, mean: 7.8819, std: 2.8114\n",
            "\n",
            "Epoch 212 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 213, Step 1, LR: 0.000960, Current Loss: 0.5262, Avg Loss: 0.5262\n",
            "Diff stats — min: -8.1270, max: 10.0000, mean: 7.9900, std: 2.7556\n",
            "\n",
            "Step 4607 — Test metrics:\n",
            "  precision@10: 0.009948138\n",
            "  recall@10: 0.010002021\n",
            "  ndcg@10: 0.010530084\n",
            "  map@10: 0.003612880\n",
            "Epoch 213, Step 20, LR: 0.000960, Current Loss: 0.5227, Avg Loss: 0.5170\n",
            "Diff stats — min: -8.5462, max: 10.0000, mean: 7.9720, std: 2.7731\n",
            "\n",
            "Epoch 213 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 214, Step 1, LR: 0.000960, Current Loss: 0.5005, Avg Loss: 0.5005\n",
            "Diff stats — min: -4.8558, max: 10.0000, mean: 7.9012, std: 2.7471\n",
            "\n",
            "Step 4637 — Test metrics:\n",
            "  precision@10: 0.009948138\n",
            "  recall@10: 0.009991918\n",
            "  ndcg@10: 0.010389469\n",
            "  map@10: 0.003511916\n",
            "Epoch 214, Step 20, LR: 0.000960, Current Loss: 0.5297, Avg Loss: 0.5141\n",
            "Diff stats — min: -7.9064, max: 10.0000, mean: 7.9719, std: 2.7534\n",
            "\n",
            "Epoch 214 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 215, Step 1, LR: 0.000960, Current Loss: 0.5164, Avg Loss: 0.5164\n",
            "Diff stats — min: -6.8551, max: 10.0000, mean: 7.9470, std: 2.7198\n",
            "\n",
            "Step 4667 — Test metrics:\n",
            "  precision@10: 0.010348892\n",
            "  recall@10: 0.010397911\n",
            "  ndcg@10: 0.010836655\n",
            "  map@10: 0.003681277\n",
            "Epoch 215, Step 20, LR: 0.000960, Current Loss: 0.5275, Avg Loss: 0.5166\n",
            "Diff stats — min: -8.3252, max: 10.0000, mean: 7.9056, std: 2.7798\n",
            "\n",
            "Epoch 215 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 216, Step 1, LR: 0.000941, Current Loss: 0.5032, Avg Loss: 0.5032\n",
            "Diff stats — min: -7.3113, max: 10.0000, mean: 8.0137, std: 2.6989\n",
            "\n",
            "Step 4697 — Test metrics:\n",
            "  precision@10: 0.010301744\n",
            "  recall@10: 0.010345524\n",
            "  ndcg@10: 0.010725492\n",
            "  map@10: 0.003640818\n",
            "Epoch 216, Step 20, LR: 0.000941, Current Loss: 0.5125, Avg Loss: 0.5118\n",
            "Diff stats — min: -4.1618, max: 10.0000, mean: 7.9332, std: 2.7536\n",
            "\n",
            "Epoch 216 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 217, Step 1, LR: 0.000941, Current Loss: 0.5010, Avg Loss: 0.5010\n",
            "Diff stats — min: -5.0894, max: 10.0000, mean: 8.0297, std: 2.6958\n",
            "\n",
            "Step 4727 — Test metrics:\n",
            "  precision@10: 0.010325318\n",
            "  recall@10: 0.010372372\n",
            "  ndcg@10: 0.010719935\n",
            "  map@10: 0.003647997\n",
            "Epoch 217, Step 20, LR: 0.000941, Current Loss: 0.5210, Avg Loss: 0.5111\n",
            "Diff stats — min: -6.4645, max: 10.0000, mean: 8.0467, std: 2.7164\n",
            "\n",
            "Epoch 217 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 218, Step 1, LR: 0.000941, Current Loss: 0.5160, Avg Loss: 0.5160\n",
            "Diff stats — min: -5.4116, max: 10.0000, mean: 8.0419, std: 2.7227\n",
            "\n",
            "Step 4757 — Test metrics:\n",
            "  precision@10: 0.009971711\n",
            "  recall@10: 0.010000150\n",
            "  ndcg@10: 0.010758284\n",
            "  map@10: 0.003739446\n",
            "Epoch 218, Step 20, LR: 0.000941, Current Loss: 0.5222, Avg Loss: 0.5108\n",
            "Diff stats — min: -6.5628, max: 10.0000, mean: 8.0804, std: 2.6427\n",
            "\n",
            "Epoch 218 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 219, Step 1, LR: 0.000941, Current Loss: 0.5282, Avg Loss: 0.5282\n",
            "Diff stats — min: -5.0548, max: 10.0000, mean: 7.9405, std: 2.7519\n",
            "\n",
            "Step 4787 — Test metrics:\n",
            "  precision@10: 0.010631777\n",
            "  recall@10: 0.010696138\n",
            "  ndcg@10: 0.011021447\n",
            "  map@10: 0.003807678\n",
            "Epoch 219, Step 20, LR: 0.000941, Current Loss: 0.5167, Avg Loss: 0.5127\n",
            "Diff stats — min: -5.5329, max: 10.0000, mean: 7.9512, std: 2.7380\n",
            "\n",
            "Epoch 219 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 220, Step 1, LR: 0.000941, Current Loss: 0.4968, Avg Loss: 0.4968\n",
            "Diff stats — min: -5.1915, max: 10.0000, mean: 8.0410, std: 2.7019\n",
            "\n",
            "Step 4817 — Test metrics:\n",
            "  precision@10: 0.010325318\n",
            "  recall@10: 0.010353756\n",
            "  ndcg@10: 0.010673037\n",
            "  map@10: 0.003581043\n",
            "Epoch 220, Step 20, LR: 0.000941, Current Loss: 0.5134, Avg Loss: 0.5093\n",
            "Diff stats — min: -6.6575, max: 10.0000, mean: 8.0010, std: 2.7391\n",
            "\n",
            "Epoch 220 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 221, Step 1, LR: 0.000922, Current Loss: 0.5027, Avg Loss: 0.5027\n",
            "Diff stats — min: -6.2183, max: 10.0000, mean: 7.9735, std: 2.7359\n",
            "\n",
            "Step 4847 — Test metrics:\n",
            "  precision@10: 0.010749646\n",
            "  recall@10: 0.010799320\n",
            "  ndcg@10: 0.011244403\n",
            "  map@10: 0.003869017\n",
            "Epoch 221, Step 20, LR: 0.000922, Current Loss: 0.4894, Avg Loss: 0.5122\n",
            "Diff stats — min: -5.3117, max: 10.0000, mean: 8.0694, std: 2.6706\n",
            "\n",
            "Epoch 221 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 222, Step 1, LR: 0.000922, Current Loss: 0.5236, Avg Loss: 0.5236\n",
            "Diff stats — min: -6.0266, max: 10.0000, mean: 8.0200, std: 2.6963\n",
            "\n",
            "Step 4877 — Test metrics:\n",
            "  precision@10: 0.010914663\n",
            "  recall@10: 0.010950959\n",
            "  ndcg@10: 0.011313333\n",
            "  map@10: 0.003849495\n",
            "Epoch 222, Step 20, LR: 0.000922, Current Loss: 0.5087, Avg Loss: 0.5134\n",
            "Diff stats — min: -7.5288, max: 10.0000, mean: 7.9597, std: 2.7993\n",
            "\n",
            "Epoch 222 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 223, Step 1, LR: 0.000922, Current Loss: 0.5141, Avg Loss: 0.5141\n",
            "Diff stats — min: -6.7950, max: 10.0000, mean: 8.0616, std: 2.7564\n",
            "\n",
            "Step 4907 — Test metrics:\n",
            "  precision@10: 0.010608204\n",
            "  recall@10: 0.010641506\n",
            "  ndcg@10: 0.010925342\n",
            "  map@10: 0.003694393\n",
            "Epoch 223, Step 20, LR: 0.000922, Current Loss: 0.5023, Avg Loss: 0.5130\n",
            "Diff stats — min: -7.2661, max: 10.0000, mean: 8.0374, std: 2.7153\n",
            "\n",
            "Epoch 223 completed, Train Loss: 0.000127\n",
            "\n",
            "Epoch 224, Step 1, LR: 0.000922, Current Loss: 0.5111, Avg Loss: 0.5111\n",
            "Diff stats — min: -5.4118, max: 10.0000, mean: 8.0647, std: 2.6772\n",
            "\n",
            "Step 4937 — Test metrics:\n",
            "  precision@10: 0.010749646\n",
            "  recall@10: 0.010775839\n",
            "  ndcg@10: 0.010828086\n",
            "  map@10: 0.003557507\n",
            "Epoch 224, Step 20, LR: 0.000922, Current Loss: 0.5222, Avg Loss: 0.5105\n",
            "Diff stats — min: -5.6444, max: 10.0000, mean: 8.0604, std: 2.7423\n",
            "\n",
            "Epoch 224 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 225, Step 1, LR: 0.000922, Current Loss: 0.5083, Avg Loss: 0.5083\n",
            "Diff stats — min: -5.0422, max: 10.0000, mean: 8.0987, std: 2.7002\n",
            "\n",
            "Step 4967 — Test metrics:\n",
            "  precision@10: 0.010513909\n",
            "  recall@10: 0.010555069\n",
            "  ndcg@10: 0.010957690\n",
            "  map@10: 0.003732585\n",
            "Epoch 225, Step 20, LR: 0.000922, Current Loss: 0.5200, Avg Loss: 0.5100\n",
            "Diff stats — min: -4.8833, max: 10.0000, mean: 8.0700, std: 2.6939\n",
            "\n",
            "Epoch 225 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 226, Step 1, LR: 0.000904, Current Loss: 0.5085, Avg Loss: 0.5085\n",
            "Diff stats — min: -6.8673, max: 10.0000, mean: 8.1074, std: 2.6780\n",
            "\n",
            "Step 4997 — Test metrics:\n",
            "  precision@10: 0.010325318\n",
            "  recall@10: 0.010363860\n",
            "  ndcg@10: 0.010831812\n",
            "  map@10: 0.003694535\n",
            "Epoch 226, Step 20, LR: 0.000904, Current Loss: 0.5005, Avg Loss: 0.5101\n",
            "Diff stats — min: -5.4847, max: 10.0000, mean: 8.0973, std: 2.6709\n",
            "\n",
            "Epoch 226 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 227, Step 1, LR: 0.000904, Current Loss: 0.5089, Avg Loss: 0.5089\n",
            "Diff stats — min: -6.1399, max: 10.0000, mean: 8.0845, std: 2.6544\n",
            "\n",
            "Step 5027 — Test metrics:\n",
            "  precision@10: 0.010961810\n",
            "  recall@10: 0.011008210\n",
            "  ndcg@10: 0.011279200\n",
            "  map@10: 0.003842456\n",
            "Epoch 227, Step 20, LR: 0.000904, Current Loss: 0.5031, Avg Loss: 0.5108\n",
            "Diff stats — min: -6.5612, max: 10.0000, mean: 8.1374, std: 2.6861\n",
            "\n",
            "Epoch 227 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 228, Step 1, LR: 0.000904, Current Loss: 0.5004, Avg Loss: 0.5004\n",
            "Diff stats — min: -5.6932, max: 10.0000, mean: 8.0983, std: 2.7155\n",
            "\n",
            "Step 5057 — Test metrics:\n",
            "  precision@10: 0.011056106\n",
            "  recall@10: 0.011087163\n",
            "  ndcg@10: 0.011363070\n",
            "  map@10: 0.003841542\n",
            "Epoch 228, Step 20, LR: 0.000904, Current Loss: 0.5219, Avg Loss: 0.5125\n",
            "Diff stats — min: -7.3587, max: 10.0000, mean: 8.0895, std: 2.6734\n",
            "\n",
            "Epoch 228 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 229, Step 1, LR: 0.000904, Current Loss: 0.5209, Avg Loss: 0.5209\n",
            "Diff stats — min: -5.7269, max: 10.0000, mean: 8.0493, std: 2.7168\n",
            "\n",
            "Step 5087 — Test metrics:\n",
            "  precision@10: 0.010631777\n",
            "  recall@10: 0.010680796\n",
            "  ndcg@10: 0.011201588\n",
            "  map@10: 0.003820904\n",
            "Epoch 229, Step 20, LR: 0.000904, Current Loss: 0.5073, Avg Loss: 0.5081\n",
            "Diff stats — min: -5.6879, max: 10.0000, mean: 8.1125, std: 2.6907\n",
            "\n",
            "Epoch 229 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 230, Step 1, LR: 0.000904, Current Loss: 0.5091, Avg Loss: 0.5091\n",
            "Diff stats — min: -7.2061, max: 10.0000, mean: 8.0881, std: 2.7279\n",
            "\n",
            "Step 5117 — Test metrics:\n",
            "  precision@10: 0.010702499\n",
            "  recall@10: 0.010743659\n",
            "  ndcg@10: 0.011090399\n",
            "  map@10: 0.003851600\n",
            "Epoch 230, Step 20, LR: 0.000904, Current Loss: 0.5065, Avg Loss: 0.5101\n",
            "Diff stats — min: -8.7862, max: 10.0000, mean: 8.0561, std: 2.7129\n",
            "\n",
            "Epoch 230 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 231, Step 1, LR: 0.000886, Current Loss: 0.5293, Avg Loss: 0.5293\n",
            "Diff stats — min: -8.2404, max: 10.0000, mean: 8.0870, std: 2.6762\n",
            "\n",
            "Step 5147 — Test metrics:\n",
            "  precision@10: 0.010466761\n",
            "  recall@10: 0.010489961\n",
            "  ndcg@10: 0.010959794\n",
            "  map@10: 0.003765933\n",
            "Epoch 231, Step 20, LR: 0.000886, Current Loss: 0.5050, Avg Loss: 0.5113\n",
            "Diff stats — min: -7.0016, max: 10.0000, mean: 8.0357, std: 2.6896\n",
            "\n",
            "Epoch 231 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 232, Step 1, LR: 0.000886, Current Loss: 0.5120, Avg Loss: 0.5120\n",
            "Diff stats — min: -4.8512, max: 10.0000, mean: 8.1208, std: 2.6725\n",
            "\n",
            "Step 5177 — Test metrics:\n",
            "  precision@10: 0.011079679\n",
            "  recall@10: 0.011113356\n",
            "  ndcg@10: 0.011389676\n",
            "  map@10: 0.003930518\n",
            "Epoch 232, Step 20, LR: 0.000886, Current Loss: 0.5185, Avg Loss: 0.5112\n",
            "Diff stats — min: -7.6550, max: 10.0000, mean: 8.1281, std: 2.7043\n",
            "\n",
            "Epoch 232 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 233, Step 1, LR: 0.000886, Current Loss: 0.5061, Avg Loss: 0.5061\n",
            "Diff stats — min: -5.0853, max: 10.0000, mean: 8.1046, std: 2.6551\n",
            "\n",
            "Step 5207 — Test metrics:\n",
            "  precision@10: 0.010938237\n",
            "  recall@10: 0.010976778\n",
            "  ndcg@10: 0.011458738\n",
            "  map@10: 0.003971245\n",
            "Epoch 233, Step 20, LR: 0.000886, Current Loss: 0.5276, Avg Loss: 0.5094\n",
            "Diff stats — min: -6.9989, max: 10.0000, mean: 8.0293, std: 2.7497\n",
            "\n",
            "Epoch 233 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 234, Step 1, LR: 0.000886, Current Loss: 0.5066, Avg Loss: 0.5066\n",
            "Diff stats — min: -5.7656, max: 10.0000, mean: 8.1328, std: 2.6694\n",
            "\n",
            "Step 5237 — Test metrics:\n",
            "  precision@10: 0.011079679\n",
            "  recall@10: 0.011120840\n",
            "  ndcg@10: 0.011501381\n",
            "  map@10: 0.003993774\n",
            "Epoch 234, Step 20, LR: 0.000886, Current Loss: 0.5115, Avg Loss: 0.5088\n",
            "Diff stats — min: -5.3965, max: 10.0000, mean: 8.0935, std: 2.7109\n",
            "\n",
            "Epoch 234 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 235, Step 1, LR: 0.000886, Current Loss: 0.5172, Avg Loss: 0.5172\n",
            "Diff stats — min: -6.7914, max: 10.0000, mean: 8.0026, std: 2.7583\n",
            "\n",
            "Step 5267 — Test metrics:\n",
            "  precision@10: 0.010867515\n",
            "  recall@10: 0.010911295\n",
            "  ndcg@10: 0.011224863\n",
            "  map@10: 0.003820820\n",
            "Epoch 235, Step 20, LR: 0.000886, Current Loss: 0.5056, Avg Loss: 0.5106\n",
            "Diff stats — min: -4.3637, max: 10.0000, mean: 8.1730, std: 2.6042\n",
            "\n",
            "Epoch 235 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 236, Step 1, LR: 0.000868, Current Loss: 0.5134, Avg Loss: 0.5134\n",
            "Diff stats — min: -6.1015, max: 10.0000, mean: 8.0806, std: 2.6700\n",
            "\n",
            "Step 5297 — Test metrics:\n",
            "  precision@10: 0.010914663\n",
            "  recall@10: 0.010958443\n",
            "  ndcg@10: 0.011168151\n",
            "  map@10: 0.003828636\n",
            "Epoch 236, Step 20, LR: 0.000868, Current Loss: 0.4974, Avg Loss: 0.5085\n",
            "Diff stats — min: -6.0973, max: 10.0000, mean: 8.1243, std: 2.6458\n",
            "\n",
            "Epoch 236 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 237, Step 1, LR: 0.000868, Current Loss: 0.5094, Avg Loss: 0.5094\n",
            "Diff stats — min: -7.1857, max: 10.0000, mean: 8.1756, std: 2.5944\n",
            "\n",
            "Step 5327 — Test metrics:\n",
            "  precision@10: 0.011079679\n",
            "  recall@10: 0.011139830\n",
            "  ndcg@10: 0.011425282\n",
            "  map@10: 0.003996424\n",
            "Epoch 237, Step 20, LR: 0.000868, Current Loss: 0.5107, Avg Loss: 0.5109\n",
            "Diff stats — min: -6.3148, max: 10.0000, mean: 8.1221, std: 2.6800\n",
            "\n",
            "Epoch 237 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 238, Step 1, LR: 0.000868, Current Loss: 0.5038, Avg Loss: 0.5038\n",
            "Diff stats — min: -6.7565, max: 10.0000, mean: 8.1632, std: 2.6964\n",
            "\n",
            "Step 5357 — Test metrics:\n",
            "  precision@10: 0.010796794\n",
            "  recall@10: 0.010833090\n",
            "  ndcg@10: 0.011372190\n",
            "  map@10: 0.003995966\n",
            "Epoch 238, Step 20, LR: 0.000868, Current Loss: 0.5191, Avg Loss: 0.5060\n",
            "Diff stats — min: -4.5023, max: 10.0000, mean: 8.2444, std: 2.6443\n",
            "\n",
            "Epoch 238 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 239, Step 1, LR: 0.000868, Current Loss: 0.5020, Avg Loss: 0.5020\n",
            "Diff stats — min: -7.2859, max: 10.0000, mean: 8.1894, std: 2.6543\n",
            "\n",
            "Step 5387 — Test metrics:\n",
            "  precision@10: 0.011739745\n",
            "  recall@10: 0.011783525\n",
            "  ndcg@10: 0.012221177\n",
            "  map@10: 0.004300710\n",
            "Epoch 239, Step 20, LR: 0.000868, Current Loss: 0.5069, Avg Loss: 0.5066\n",
            "Diff stats — min: -6.8666, max: 10.0000, mean: 8.2523, std: 2.5796\n",
            "\n",
            "Epoch 239 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 240, Step 1, LR: 0.000868, Current Loss: 0.4982, Avg Loss: 0.4982\n",
            "Diff stats — min: -7.6463, max: 10.0000, mean: 8.1989, std: 2.6027\n",
            "\n",
            "Step 5417 — Test metrics:\n",
            "  precision@10: 0.011197548\n",
            "  recall@10: 0.011241328\n",
            "  ndcg@10: 0.011566730\n",
            "  map@10: 0.004014115\n",
            "Epoch 240, Step 20, LR: 0.000868, Current Loss: 0.5028, Avg Loss: 0.5083\n",
            "Diff stats — min: -9.0604, max: 10.0000, mean: 8.0952, std: 2.7057\n",
            "\n",
            "Epoch 240 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 241, Step 1, LR: 0.000851, Current Loss: 0.4990, Avg Loss: 0.4990\n",
            "Diff stats — min: -4.4155, max: 10.0000, mean: 8.1734, std: 2.6365\n",
            "\n",
            "Step 5447 — Test metrics:\n",
            "  precision@10: 0.011150401\n",
            "  recall@10: 0.011212516\n",
            "  ndcg@10: 0.011739012\n",
            "  map@10: 0.004138177\n",
            "Epoch 241, Step 20, LR: 0.000851, Current Loss: 0.5043, Avg Loss: 0.5096\n",
            "Diff stats — min: -8.0767, max: 10.0000, mean: 8.1189, std: 2.6979\n",
            "\n",
            "Epoch 241 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 242, Step 1, LR: 0.000851, Current Loss: 0.5177, Avg Loss: 0.5177\n",
            "Diff stats — min: -6.8250, max: 10.0000, mean: 8.1714, std: 2.6371\n",
            "\n",
            "Step 5477 — Test metrics:\n",
            "  precision@10: 0.011504008\n",
            "  recall@10: 0.011576226\n",
            "  ndcg@10: 0.011849987\n",
            "  map@10: 0.004164098\n",
            "Epoch 242, Step 20, LR: 0.000851, Current Loss: 0.5128, Avg Loss: 0.5073\n",
            "Diff stats — min: -7.8252, max: 10.0000, mean: 8.1761, std: 2.6534\n",
            "\n",
            "Epoch 242 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 243, Step 1, LR: 0.000851, Current Loss: 0.5104, Avg Loss: 0.5104\n",
            "Diff stats — min: -7.9378, max: 10.0000, mean: 8.1751, std: 2.6640\n",
            "\n",
            "Step 5507 — Test metrics:\n",
            "  precision@10: 0.011739745\n",
            "  recall@10: 0.011797277\n",
            "  ndcg@10: 0.012047302\n",
            "  map@10: 0.004199190\n",
            "Epoch 243, Step 20, LR: 0.000851, Current Loss: 0.5084, Avg Loss: 0.5084\n",
            "Diff stats — min: -8.0045, max: 10.0000, mean: 8.2269, std: 2.6332\n",
            "\n",
            "Epoch 243 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 244, Step 1, LR: 0.000851, Current Loss: 0.5126, Avg Loss: 0.5126\n",
            "Diff stats — min: -8.0851, max: 10.0000, mean: 8.2054, std: 2.6622\n",
            "\n",
            "Step 5537 — Test metrics:\n",
            "  precision@10: 0.011315417\n",
            "  recall@10: 0.011374539\n",
            "  ndcg@10: 0.011658690\n",
            "  map@10: 0.004092413\n",
            "Epoch 244, Step 20, LR: 0.000851, Current Loss: 0.5227, Avg Loss: 0.5074\n",
            "Diff stats — min: -3.1524, max: 10.0000, mean: 8.2260, std: 2.6103\n",
            "\n",
            "Epoch 244 completed, Train Loss: 0.000126\n",
            "\n",
            "Epoch 245, Step 1, LR: 0.000851, Current Loss: 0.5074, Avg Loss: 0.5074\n",
            "Diff stats — min: -5.3536, max: 10.0000, mean: 8.2233, std: 2.6368\n",
            "\n",
            "Step 5567 — Test metrics:\n",
            "  precision@10: 0.011881188\n",
            "  recall@10: 0.011945548\n",
            "  ndcg@10: 0.012463672\n",
            "  map@10: 0.004453200\n",
            "Epoch 245, Step 20, LR: 0.000851, Current Loss: 0.5091, Avg Loss: 0.5053\n",
            "Diff stats — min: -6.9780, max: 10.0000, mean: 8.2514, std: 2.5755\n",
            "\n",
            "Epoch 245 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 246, Step 1, LR: 0.000834, Current Loss: 0.5265, Avg Loss: 0.5265\n",
            "Diff stats — min: -5.6402, max: 10.0000, mean: 8.1999, std: 2.6465\n",
            "\n",
            "Step 5597 — Test metrics:\n",
            "  precision@10: 0.011857614\n",
            "  recall@10: 0.011904014\n",
            "  ndcg@10: 0.012328264\n",
            "  map@10: 0.004320258\n",
            "Epoch 246, Step 20, LR: 0.000834, Current Loss: 0.4963, Avg Loss: 0.5082\n",
            "Diff stats — min: -4.3933, max: 10.0000, mean: 8.2454, std: 2.5983\n",
            "\n",
            "Epoch 246 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 247, Step 1, LR: 0.000834, Current Loss: 0.5118, Avg Loss: 0.5118\n",
            "Diff stats — min: -4.4389, max: 10.0000, mean: 8.1869, std: 2.6644\n",
            "\n",
            "Step 5627 — Test metrics:\n",
            "  precision@10: 0.012116926\n",
            "  recall@10: 0.012181286\n",
            "  ndcg@10: 0.012604350\n",
            "  map@10: 0.004436619\n",
            "Epoch 247, Step 20, LR: 0.000834, Current Loss: 0.5034, Avg Loss: 0.5083\n",
            "Diff stats — min: -7.2973, max: 10.0000, mean: 8.2555, std: 2.6520\n",
            "\n",
            "Epoch 247 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 248, Step 1, LR: 0.000834, Current Loss: 0.5033, Avg Loss: 0.5033\n",
            "Diff stats — min: -4.7128, max: 10.0000, mean: 8.2005, std: 2.6422\n",
            "\n",
            "Step 5657 — Test metrics:\n",
            "  precision@10: 0.011904762\n",
            "  recall@10: 0.011956400\n",
            "  ndcg@10: 0.012528140\n",
            "  map@10: 0.004393520\n",
            "Epoch 248, Step 20, LR: 0.000834, Current Loss: 0.5237, Avg Loss: 0.5077\n",
            "Diff stats — min: -6.2040, max: 10.0000, mean: 8.2440, std: 2.6442\n",
            "\n",
            "Epoch 248 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 249, Step 1, LR: 0.000834, Current Loss: 0.5231, Avg Loss: 0.5231\n",
            "Diff stats — min: -5.9741, max: 10.0000, mean: 8.2539, std: 2.6642\n",
            "\n",
            "Step 5687 — Test metrics:\n",
            "  precision@10: 0.011645450\n",
            "  recall@10: 0.011709810\n",
            "  ndcg@10: 0.012228403\n",
            "  map@10: 0.004346253\n",
            "Epoch 249, Step 20, LR: 0.000834, Current Loss: 0.5069, Avg Loss: 0.5083\n",
            "Diff stats — min: -5.3012, max: 10.0000, mean: 8.2328, std: 2.5991\n",
            "\n",
            "Epoch 249 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 250, Step 1, LR: 0.000834, Current Loss: 0.4941, Avg Loss: 0.4941\n",
            "Diff stats — min: -5.5911, max: 10.0000, mean: 8.2802, std: 2.5627\n",
            "\n",
            "Step 5717 — Test metrics:\n",
            "  precision@10: 0.011881188\n",
            "  recall@10: 0.011945548\n",
            "  ndcg@10: 0.012526431\n",
            "  map@10: 0.004470370\n",
            "Epoch 250, Step 20, LR: 0.000834, Current Loss: 0.5116, Avg Loss: 0.5072\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.1265, std: 2.7379\n",
            "\n",
            "Epoch 250 completed, Train Loss: 0.000125\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = train_model(model,\n",
        "                    data,\n",
        "                    (seq_ids, event_type, seq_times, seq_mask),\n",
        "                    edge_type=edge_type,\n",
        "                    num_epochs=50,\n",
        "                    lr=lr,\n",
        "                    batch_size=batch_size,\n",
        "                    print_every=print_every,\n",
        "                    test_every=test_every,\n",
        "                    top_k=top_k,\n",
        "                    test_batch_size=test_batch_size,\n",
        "                    scheduler_step_size=scheduler_step_size,\n",
        "                    scheduler_gamma=train_scheduler_gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-Y6kuSN6yRG",
        "outputId": "438da474-86fd-4834-e841-dca51c1a5268"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of training examples: 121468\n",
            "Epoch 251, Step 1, LR: 0.001000, Current Loss: 0.5102, Avg Loss: 0.5102\n",
            "Diff stats — min: -5.8422, max: 10.0000, mean: 8.2933, std: 2.5675\n",
            "\n",
            "Step 5942 — Test metrics:\n",
            "  precision@10: 0.012376238\n",
            "  recall@10: 0.012443217\n",
            "  ndcg@10: 0.013020149\n",
            "  map@10: 0.004655082\n",
            "Epoch 251, Step 20, LR: 0.001000, Current Loss: 0.5156, Avg Loss: 0.5072\n",
            "Diff stats — min: -5.2126, max: 10.0000, mean: 8.1994, std: 2.6797\n",
            "\n",
            "Epoch 251 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 252, Step 1, LR: 0.001000, Current Loss: 0.4992, Avg Loss: 0.4992\n",
            "Diff stats — min: -5.8123, max: 10.0000, mean: 8.1606, std: 2.7023\n",
            "\n",
            "Step 5972 — Test metrics:\n",
            "  precision@10: 0.011692598\n",
            "  recall@10: 0.011756958\n",
            "  ndcg@10: 0.012244609\n",
            "  map@10: 0.004359675\n",
            "Epoch 252, Step 20, LR: 0.001000, Current Loss: 0.4988, Avg Loss: 0.5067\n",
            "Diff stats — min: -4.6018, max: 10.0000, mean: 8.2991, std: 2.5524\n",
            "\n",
            "Epoch 252 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 253, Step 1, LR: 0.001000, Current Loss: 0.4976, Avg Loss: 0.4976\n",
            "Diff stats — min: -4.4537, max: 10.0000, mean: 8.2704, std: 2.5846\n",
            "\n",
            "Step 6002 — Test metrics:\n",
            "  precision@10: 0.012140500\n",
            "  recall@10: 0.012215992\n",
            "  ndcg@10: 0.012851832\n",
            "  map@10: 0.004653383\n",
            "Epoch 253, Step 20, LR: 0.001000, Current Loss: 0.5004, Avg Loss: 0.5047\n",
            "Diff stats — min: -5.5028, max: 10.0000, mean: 8.2695, std: 2.5633\n",
            "\n",
            "Epoch 253 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 254, Step 1, LR: 0.001000, Current Loss: 0.5099, Avg Loss: 0.5099\n",
            "Diff stats — min: -6.9961, max: 10.0000, mean: 8.2561, std: 2.6139\n",
            "\n",
            "Step 6032 — Test metrics:\n",
            "  precision@10: 0.011645450\n",
            "  recall@10: 0.011712430\n",
            "  ndcg@10: 0.012116416\n",
            "  map@10: 0.004347183\n",
            "Epoch 254, Step 20, LR: 0.001000, Current Loss: 0.5068, Avg Loss: 0.5065\n",
            "Diff stats — min: -5.7561, max: 10.0000, mean: 8.2795, std: 2.5757\n",
            "\n",
            "Epoch 254 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 255, Step 1, LR: 0.001000, Current Loss: 0.5075, Avg Loss: 0.5075\n",
            "Diff stats — min: -6.0319, max: 10.0000, mean: 8.2347, std: 2.6427\n",
            "\n",
            "Step 6062 — Test metrics:\n",
            "  precision@10: 0.011763319\n",
            "  recall@10: 0.011827679\n",
            "  ndcg@10: 0.012266761\n",
            "  map@10: 0.004411128\n",
            "Epoch 255, Step 20, LR: 0.001000, Current Loss: 0.4881, Avg Loss: 0.5033\n",
            "Diff stats — min: -6.3555, max: 10.0000, mean: 8.2675, std: 2.5497\n",
            "\n",
            "Epoch 255 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 256, Step 1, LR: 0.000980, Current Loss: 0.5103, Avg Loss: 0.5103\n",
            "Diff stats — min: -8.1033, max: 10.0000, mean: 8.2700, std: 2.5766\n",
            "\n",
            "Step 6092 — Test metrics:\n",
            "  precision@10: 0.012211221\n",
            "  recall@10: 0.012272962\n",
            "  ndcg@10: 0.012981275\n",
            "  map@10: 0.004683011\n",
            "Epoch 256, Step 20, LR: 0.000980, Current Loss: 0.5144, Avg Loss: 0.5086\n",
            "Diff stats — min: -6.4364, max: 10.0000, mean: 8.2477, std: 2.6494\n",
            "\n",
            "Epoch 256 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 257, Step 1, LR: 0.000980, Current Loss: 0.4871, Avg Loss: 0.4871\n",
            "Diff stats — min: -6.8967, max: 10.0000, mean: 8.3330, std: 2.5415\n",
            "\n",
            "Step 6122 — Test metrics:\n",
            "  precision@10: 0.012234795\n",
            "  recall@10: 0.012310287\n",
            "  ndcg@10: 0.012948903\n",
            "  map@10: 0.004735433\n",
            "Epoch 257, Step 20, LR: 0.000980, Current Loss: 0.5106, Avg Loss: 0.5050\n",
            "Diff stats — min: -6.5842, max: 10.0000, mean: 8.2692, std: 2.5960\n",
            "\n",
            "Epoch 257 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 258, Step 1, LR: 0.000980, Current Loss: 0.4941, Avg Loss: 0.4941\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.3234, std: 2.5756\n",
            "\n",
            "Step 6152 — Test metrics:\n",
            "  precision@10: 0.012211221\n",
            "  recall@10: 0.012278201\n",
            "  ndcg@10: 0.012662865\n",
            "  map@10: 0.004541471\n",
            "Epoch 258, Step 20, LR: 0.000980, Current Loss: 0.5071, Avg Loss: 0.5062\n",
            "Diff stats — min: -4.1354, max: 10.0000, mean: 8.3042, std: 2.6002\n",
            "\n",
            "Epoch 258 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 259, Step 1, LR: 0.000980, Current Loss: 0.5016, Avg Loss: 0.5016\n",
            "Diff stats — min: -5.9408, max: 10.0000, mean: 8.2661, std: 2.5830\n",
            "\n",
            "Step 6182 — Test metrics:\n",
            "  precision@10: 0.012164074\n",
            "  recall@10: 0.012239566\n",
            "  ndcg@10: 0.012872708\n",
            "  map@10: 0.004665858\n",
            "Epoch 259, Step 20, LR: 0.000980, Current Loss: 0.5048, Avg Loss: 0.5070\n",
            "Diff stats — min: -7.9723, max: 10.0000, mean: 8.2256, std: 2.6840\n",
            "\n",
            "Epoch 259 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 260, Step 1, LR: 0.000980, Current Loss: 0.5104, Avg Loss: 0.5104\n",
            "Diff stats — min: -4.2536, max: 10.0000, mean: 8.3577, std: 2.5117\n",
            "\n",
            "Step 6212 — Test metrics:\n",
            "  precision@10: 0.011527581\n",
            "  recall@10: 0.011582493\n",
            "  ndcg@10: 0.012226049\n",
            "  map@10: 0.004477185\n",
            "Epoch 260, Step 20, LR: 0.000980, Current Loss: 0.5055, Avg Loss: 0.5051\n",
            "Diff stats — min: -8.9118, max: 10.0000, mean: 8.3164, std: 2.6064\n",
            "\n",
            "Epoch 260 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 261, Step 1, LR: 0.000960, Current Loss: 0.4968, Avg Loss: 0.4968\n",
            "Diff stats — min: -7.5083, max: 10.0000, mean: 8.2480, std: 2.6421\n",
            "\n",
            "Step 6242 — Test metrics:\n",
            "  precision@10: 0.011857614\n",
            "  recall@10: 0.011909252\n",
            "  ndcg@10: 0.012543755\n",
            "  map@10: 0.004547290\n",
            "Epoch 261, Step 20, LR: 0.000960, Current Loss: 0.5188, Avg Loss: 0.5041\n",
            "Diff stats — min: -5.9596, max: 10.0000, mean: 8.3763, std: 2.5138\n",
            "\n",
            "Epoch 261 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 262, Step 1, LR: 0.000960, Current Loss: 0.4943, Avg Loss: 0.4943\n",
            "Diff stats — min: -7.9996, max: 10.0000, mean: 8.3314, std: 2.5743\n",
            "\n",
            "Step 6272 — Test metrics:\n",
            "  precision@10: 0.012069778\n",
            "  recall@10: 0.012137787\n",
            "  ndcg@10: 0.012896697\n",
            "  map@10: 0.004709138\n",
            "Epoch 262, Step 20, LR: 0.000960, Current Loss: 0.5080, Avg Loss: 0.5058\n",
            "Diff stats — min: -3.9116, max: 10.0000, mean: 8.2478, std: 2.5946\n",
            "\n",
            "Epoch 262 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 263, Step 1, LR: 0.000960, Current Loss: 0.5127, Avg Loss: 0.5127\n",
            "Diff stats — min: -6.4546, max: 10.0000, mean: 8.2645, std: 2.5903\n",
            "\n",
            "Step 6302 — Test metrics:\n",
            "  precision@10: 0.012376238\n",
            "  recall@10: 0.012435733\n",
            "  ndcg@10: 0.013239189\n",
            "  map@10: 0.004843064\n",
            "Epoch 263, Step 20, LR: 0.000960, Current Loss: 0.4998, Avg Loss: 0.5037\n",
            "Diff stats — min: -7.5408, max: 10.0000, mean: 8.3626, std: 2.5579\n",
            "\n",
            "Epoch 263 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 264, Step 1, LR: 0.000960, Current Loss: 0.5204, Avg Loss: 0.5204\n",
            "Diff stats — min: -5.3383, max: 10.0000, mean: 8.2939, std: 2.5754\n",
            "\n",
            "Step 6332 — Test metrics:\n",
            "  precision@10: 0.011999057\n",
            "  recall@10: 0.012055933\n",
            "  ndcg@10: 0.012628818\n",
            "  map@10: 0.004549605\n",
            "Epoch 264, Step 20, LR: 0.000960, Current Loss: 0.4991, Avg Loss: 0.5027\n",
            "Diff stats — min: -4.5622, max: 10.0000, mean: 8.3848, std: 2.5233\n",
            "\n",
            "Epoch 264 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 265, Step 1, LR: 0.000960, Current Loss: 0.4913, Avg Loss: 0.4913\n",
            "Diff stats — min: -3.7015, max: 10.0000, mean: 8.4226, std: 2.4543\n",
            "\n",
            "Step 6362 — Test metrics:\n",
            "  precision@10: 0.012116926\n",
            "  recall@10: 0.012194383\n",
            "  ndcg@10: 0.012994875\n",
            "  map@10: 0.004804900\n",
            "Epoch 265, Step 20, LR: 0.000960, Current Loss: 0.5087, Avg Loss: 0.5028\n",
            "Diff stats — min: -8.8411, max: 10.0000, mean: 8.3596, std: 2.5787\n",
            "\n",
            "Epoch 265 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 266, Step 1, LR: 0.000941, Current Loss: 0.4915, Avg Loss: 0.4915\n",
            "Diff stats — min: -3.8992, max: 10.0000, mean: 8.3484, std: 2.5039\n",
            "\n",
            "Step 6392 — Test metrics:\n",
            "  precision@10: 0.012022631\n",
            "  recall@10: 0.012079507\n",
            "  ndcg@10: 0.012593539\n",
            "  map@10: 0.004591060\n",
            "Epoch 266, Step 20, LR: 0.000941, Current Loss: 0.5102, Avg Loss: 0.5050\n",
            "Diff stats — min: -4.0418, max: 10.0000, mean: 8.3280, std: 2.5710\n",
            "\n",
            "Epoch 266 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 267, Step 1, LR: 0.000941, Current Loss: 0.4990, Avg Loss: 0.4990\n",
            "Diff stats — min: -5.2495, max: 10.0000, mean: 8.3372, std: 2.5145\n",
            "\n",
            "Step 6422 — Test metrics:\n",
            "  precision@10: 0.012352664\n",
            "  recall@10: 0.012418053\n",
            "  ndcg@10: 0.013252404\n",
            "  map@10: 0.004995185\n",
            "Epoch 267, Step 20, LR: 0.000941, Current Loss: 0.5074, Avg Loss: 0.5057\n",
            "Diff stats — min: -8.6328, max: 10.0000, mean: 8.3341, std: 2.5741\n",
            "\n",
            "Epoch 267 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 268, Step 1, LR: 0.000941, Current Loss: 0.5049, Avg Loss: 0.5049\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.3425, std: 2.5629\n",
            "\n",
            "Step 6452 — Test metrics:\n",
            "  precision@10: 0.012541254\n",
            "  recall@10: 0.012618711\n",
            "  ndcg@10: 0.013204296\n",
            "  map@10: 0.004842089\n",
            "Epoch 268, Step 20, LR: 0.000941, Current Loss: 0.5192, Avg Loss: 0.5038\n",
            "Diff stats — min: -5.3208, max: 10.0000, mean: 8.3438, std: 2.5335\n",
            "\n",
            "Epoch 268 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 269, Step 1, LR: 0.000941, Current Loss: 0.5061, Avg Loss: 0.5061\n",
            "Diff stats — min: -6.0840, max: 10.0000, mean: 8.3196, std: 2.5719\n",
            "\n",
            "Step 6482 — Test metrics:\n",
            "  precision@10: 0.012800566\n",
            "  recall@10: 0.012867545\n",
            "  ndcg@10: 0.013540037\n",
            "  map@10: 0.005055955\n",
            "Epoch 269, Step 20, LR: 0.000941, Current Loss: 0.5031, Avg Loss: 0.5057\n",
            "Diff stats — min: -5.4453, max: 10.0000, mean: 8.4106, std: 2.4932\n",
            "\n",
            "Epoch 269 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 270, Step 1, LR: 0.000941, Current Loss: 0.4959, Avg Loss: 0.4959\n",
            "Diff stats — min: -7.8772, max: 10.0000, mean: 8.3436, std: 2.5995\n",
            "\n",
            "Step 6512 — Test metrics:\n",
            "  precision@10: 0.012329090\n",
            "  recall@10: 0.012390831\n",
            "  ndcg@10: 0.013301798\n",
            "  map@10: 0.004996075\n",
            "Epoch 270, Step 20, LR: 0.000941, Current Loss: 0.5030, Avg Loss: 0.5049\n",
            "Diff stats — min: -5.7895, max: 10.0000, mean: 8.3114, std: 2.5507\n",
            "\n",
            "Epoch 270 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 271, Step 1, LR: 0.000922, Current Loss: 0.5071, Avg Loss: 0.5071\n",
            "Diff stats — min: -8.9560, max: 10.0000, mean: 8.3274, std: 2.6275\n",
            "\n",
            "Step 6542 — Test metrics:\n",
            "  precision@10: 0.012541254\n",
            "  recall@10: 0.012601405\n",
            "  ndcg@10: 0.013191530\n",
            "  map@10: 0.004940971\n",
            "Epoch 271, Step 20, LR: 0.000922, Current Loss: 0.4941, Avg Loss: 0.5056\n",
            "Diff stats — min: -4.1641, max: 10.0000, mean: 8.3764, std: 2.4947\n",
            "\n",
            "Epoch 271 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 272, Step 1, LR: 0.000922, Current Loss: 0.4957, Avg Loss: 0.4957\n",
            "Diff stats — min: -6.6769, max: 10.0000, mean: 8.2735, std: 2.6317\n",
            "\n",
            "Step 6572 — Test metrics:\n",
            "  precision@10: 0.012329090\n",
            "  recall@10: 0.012389241\n",
            "  ndcg@10: 0.013261390\n",
            "  map@10: 0.004988517\n",
            "Epoch 272, Step 20, LR: 0.000922, Current Loss: 0.5029, Avg Loss: 0.5053\n",
            "Diff stats — min: -8.1032, max: 10.0000, mean: 8.3410, std: 2.5845\n",
            "\n",
            "Epoch 272 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 273, Step 1, LR: 0.000922, Current Loss: 0.5029, Avg Loss: 0.5029\n",
            "Diff stats — min: -6.3342, max: 10.0000, mean: 8.3031, std: 2.6170\n",
            "\n",
            "Step 6602 — Test metrics:\n",
            "  precision@10: 0.012776992\n",
            "  recall@10: 0.012852484\n",
            "  ndcg@10: 0.013874149\n",
            "  map@10: 0.005343926\n",
            "Epoch 273, Step 20, LR: 0.000922, Current Loss: 0.5074, Avg Loss: 0.5051\n",
            "Diff stats — min: -5.3780, max: 10.0000, mean: 8.3700, std: 2.5400\n",
            "\n",
            "Epoch 273 completed, Train Loss: 0.000125\n",
            "\n",
            "Epoch 274, Step 1, LR: 0.000922, Current Loss: 0.5051, Avg Loss: 0.5051\n",
            "Diff stats — min: -6.7590, max: 10.0000, mean: 8.3752, std: 2.5547\n",
            "\n",
            "Step 6632 — Test metrics:\n",
            "  precision@10: 0.012942008\n",
            "  recall@10: 0.013017501\n",
            "  ndcg@10: 0.013894580\n",
            "  map@10: 0.005205362\n",
            "Epoch 274, Step 20, LR: 0.000922, Current Loss: 0.5086, Avg Loss: 0.5071\n",
            "Diff stats — min: -6.1950, max: 10.0000, mean: 8.2931, std: 2.6083\n",
            "\n",
            "Epoch 274 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 275, Step 1, LR: 0.000922, Current Loss: 0.4795, Avg Loss: 0.4795\n",
            "Diff stats — min: -5.7969, max: 10.0000, mean: 8.3698, std: 2.4916\n",
            "\n",
            "Step 6662 — Test metrics:\n",
            "  precision@10: 0.012753418\n",
            "  recall@10: 0.012831530\n",
            "  ndcg@10: 0.013627992\n",
            "  map@10: 0.005148757\n",
            "Epoch 275, Step 20, LR: 0.000922, Current Loss: 0.4987, Avg Loss: 0.5008\n",
            "Diff stats — min: -7.0133, max: 10.0000, mean: 8.4034, std: 2.5293\n",
            "\n",
            "Epoch 275 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 276, Step 1, LR: 0.000904, Current Loss: 0.5258, Avg Loss: 0.5258\n",
            "Diff stats — min: -6.4711, max: 10.0000, mean: 8.3301, std: 2.5736\n",
            "\n",
            "Step 6692 — Test metrics:\n",
            "  precision@10: 0.012800566\n",
            "  recall@10: 0.012867545\n",
            "  ndcg@10: 0.013696978\n",
            "  map@10: 0.005190227\n",
            "Epoch 276, Step 20, LR: 0.000904, Current Loss: 0.5050, Avg Loss: 0.5024\n",
            "Diff stats — min: -5.3645, max: 10.0000, mean: 8.3497, std: 2.5929\n",
            "\n",
            "Epoch 276 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 277, Step 1, LR: 0.000904, Current Loss: 0.5056, Avg Loss: 0.5056\n",
            "Diff stats — min: -7.5126, max: 10.0000, mean: 8.3149, std: 2.5968\n",
            "\n",
            "Step 6722 — Test metrics:\n",
            "  precision@10: 0.012659123\n",
            "  recall@10: 0.012729751\n",
            "  ndcg@10: 0.013543657\n",
            "  map@10: 0.005065912\n",
            "Epoch 277, Step 20, LR: 0.000904, Current Loss: 0.4922, Avg Loss: 0.5037\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.3927, std: 2.5074\n",
            "\n",
            "Epoch 277 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 278, Step 1, LR: 0.000904, Current Loss: 0.4895, Avg Loss: 0.4895\n",
            "Diff stats — min: -6.0972, max: 10.0000, mean: 8.3656, std: 2.5593\n",
            "\n",
            "Step 6752 — Test metrics:\n",
            "  precision@10: 0.012965582\n",
            "  recall@10: 0.013043694\n",
            "  ndcg@10: 0.013915042\n",
            "  map@10: 0.005200580\n",
            "Epoch 278, Step 20, LR: 0.000904, Current Loss: 0.4910, Avg Loss: 0.5035\n",
            "Diff stats — min: -7.2081, max: 10.0000, mean: 8.3799, std: 2.5685\n",
            "\n",
            "Epoch 278 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 279, Step 1, LR: 0.000904, Current Loss: 0.5046, Avg Loss: 0.5046\n",
            "Diff stats — min: -5.4108, max: 10.0000, mean: 8.4540, std: 2.4818\n",
            "\n",
            "Step 6782 — Test metrics:\n",
            "  precision@10: 0.012776992\n",
            "  recall@10: 0.012828630\n",
            "  ndcg@10: 0.013451651\n",
            "  map@10: 0.004959323\n",
            "Epoch 279, Step 20, LR: 0.000904, Current Loss: 0.4978, Avg Loss: 0.5025\n",
            "Diff stats — min: -4.5117, max: 10.0000, mean: 8.4023, std: 2.5235\n",
            "\n",
            "Epoch 279 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 280, Step 1, LR: 0.000904, Current Loss: 0.5040, Avg Loss: 0.5040\n",
            "Diff stats — min: -5.3913, max: 10.0000, mean: 8.3678, std: 2.5414\n",
            "\n",
            "Step 6812 — Test metrics:\n",
            "  precision@10: 0.012682697\n",
            "  recall@10: 0.012747431\n",
            "  ndcg@10: 0.013457417\n",
            "  map@10: 0.004946602\n",
            "Epoch 280, Step 20, LR: 0.000904, Current Loss: 0.4958, Avg Loss: 0.5051\n",
            "Diff stats — min: -6.0180, max: 10.0000, mean: 8.4305, std: 2.4882\n",
            "\n",
            "Epoch 280 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 281, Step 1, LR: 0.000886, Current Loss: 0.5037, Avg Loss: 0.5037\n",
            "Diff stats — min: -5.6569, max: 10.0000, mean: 8.4013, std: 2.5356\n",
            "\n",
            "Step 6842 — Test metrics:\n",
            "  precision@10: 0.012753418\n",
            "  recall@10: 0.012812914\n",
            "  ndcg@10: 0.013758738\n",
            "  map@10: 0.005139896\n",
            "Epoch 281, Step 20, LR: 0.000886, Current Loss: 0.5177, Avg Loss: 0.5002\n",
            "Diff stats — min: -5.7138, max: 10.0000, mean: 8.4021, std: 2.5351\n",
            "\n",
            "Epoch 281 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 282, Step 1, LR: 0.000886, Current Loss: 0.5009, Avg Loss: 0.5009\n",
            "Diff stats — min: -4.2168, max: 10.0000, mean: 8.4850, std: 2.4581\n",
            "\n",
            "Step 6872 — Test metrics:\n",
            "  precision@10: 0.012776992\n",
            "  recall@10: 0.012837143\n",
            "  ndcg@10: 0.013541092\n",
            "  map@10: 0.005039554\n",
            "Epoch 282, Step 20, LR: 0.000886, Current Loss: 0.4895, Avg Loss: 0.5008\n",
            "Diff stats — min: -8.0312, max: 10.0000, mean: 8.4168, std: 2.5311\n",
            "\n",
            "Epoch 282 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 283, Step 1, LR: 0.000886, Current Loss: 0.4937, Avg Loss: 0.4937\n",
            "Diff stats — min: -5.6950, max: 10.0000, mean: 8.3864, std: 2.5719\n",
            "\n",
            "Step 6902 — Test metrics:\n",
            "  precision@10: 0.012847713\n",
            "  recall@10: 0.012901970\n",
            "  ndcg@10: 0.013786684\n",
            "  map@10: 0.005150866\n",
            "Epoch 283, Step 20, LR: 0.000886, Current Loss: 0.5033, Avg Loss: 0.4999\n",
            "Diff stats — min: -8.3370, max: 10.0000, mean: 8.3984, std: 2.5729\n",
            "\n",
            "Epoch 283 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 284, Step 1, LR: 0.000886, Current Loss: 0.5025, Avg Loss: 0.5025\n",
            "Diff stats — min: -3.2874, max: 10.0000, mean: 8.4493, std: 2.5050\n",
            "\n",
            "Step 6932 — Test metrics:\n",
            "  precision@10: 0.012871287\n",
            "  recall@10: 0.012928164\n",
            "  ndcg@10: 0.013923570\n",
            "  map@10: 0.005277146\n",
            "Epoch 284, Step 20, LR: 0.000886, Current Loss: 0.5016, Avg Loss: 0.5017\n",
            "Diff stats — min: -5.4310, max: 10.0000, mean: 8.4401, std: 2.5226\n",
            "\n",
            "Epoch 284 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 285, Step 1, LR: 0.000886, Current Loss: 0.5042, Avg Loss: 0.5042\n",
            "Diff stats — min: -4.7313, max: 10.0000, mean: 8.4814, std: 2.4917\n",
            "\n",
            "Step 6962 — Test metrics:\n",
            "  precision@10: 0.012894861\n",
            "  recall@10: 0.012951737\n",
            "  ndcg@10: 0.013842395\n",
            "  map@10: 0.005233052\n",
            "Epoch 285, Step 20, LR: 0.000886, Current Loss: 0.5050, Avg Loss: 0.5025\n",
            "Diff stats — min: -5.4634, max: 10.0000, mean: 8.4064, std: 2.5362\n",
            "\n",
            "Epoch 285 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 286, Step 1, LR: 0.000868, Current Loss: 0.5037, Avg Loss: 0.5037\n",
            "Diff stats — min: -7.1226, max: 10.0000, mean: 8.4370, std: 2.4919\n",
            "\n",
            "Step 6992 — Test metrics:\n",
            "  precision@10: 0.013224894\n",
            "  recall@10: 0.013297112\n",
            "  ndcg@10: 0.014249250\n",
            "  map@10: 0.005447123\n",
            "Epoch 286, Step 20, LR: 0.000868, Current Loss: 0.4996, Avg Loss: 0.5011\n",
            "Diff stats — min: -5.5830, max: 10.0000, mean: 8.3974, std: 2.5015\n",
            "\n",
            "Epoch 286 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 287, Step 1, LR: 0.000868, Current Loss: 0.5101, Avg Loss: 0.5101\n",
            "Diff stats — min: -6.0848, max: 10.0000, mean: 8.3859, std: 2.5505\n",
            "\n",
            "Step 7022 — Test metrics:\n",
            "  precision@10: 0.013201320\n",
            "  recall@10: 0.013270919\n",
            "  ndcg@10: 0.014163021\n",
            "  map@10: 0.005345710\n",
            "Epoch 287, Step 20, LR: 0.000868, Current Loss: 0.4977, Avg Loss: 0.5021\n",
            "Diff stats — min: -8.5956, max: 10.0000, mean: 8.4836, std: 2.4586\n",
            "\n",
            "Epoch 287 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 288, Step 1, LR: 0.000868, Current Loss: 0.4879, Avg Loss: 0.4879\n",
            "Diff stats — min: -7.5475, max: 10.0000, mean: 8.4564, std: 2.4832\n",
            "\n",
            "Step 7052 — Test metrics:\n",
            "  precision@10: 0.012776992\n",
            "  recall@10: 0.012828630\n",
            "  ndcg@10: 0.013836470\n",
            "  map@10: 0.005181538\n",
            "Epoch 288, Step 20, LR: 0.000868, Current Loss: 0.5052, Avg Loss: 0.5030\n",
            "Diff stats — min: -5.0557, max: 10.0000, mean: 8.5055, std: 2.4611\n",
            "\n",
            "Epoch 288 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 289, Step 1, LR: 0.000868, Current Loss: 0.5060, Avg Loss: 0.5060\n",
            "Diff stats — min: -4.4652, max: 10.0000, mean: 8.4247, std: 2.5251\n",
            "\n",
            "Step 7082 — Test metrics:\n",
            "  precision@10: 0.012659123\n",
            "  recall@10: 0.012728722\n",
            "  ndcg@10: 0.013498379\n",
            "  map@10: 0.005072100\n",
            "Epoch 289, Step 20, LR: 0.000868, Current Loss: 0.4950, Avg Loss: 0.5019\n",
            "Diff stats — min: -5.8018, max: 10.0000, mean: 8.4510, std: 2.4844\n",
            "\n",
            "Epoch 289 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 290, Step 1, LR: 0.000868, Current Loss: 0.4868, Avg Loss: 0.4868\n",
            "Diff stats — min: -6.0389, max: 10.0000, mean: 8.4955, std: 2.4747\n",
            "\n",
            "Step 7112 — Test metrics:\n",
            "  precision@10: 0.012800566\n",
            "  recall@10: 0.012852204\n",
            "  ndcg@10: 0.013483042\n",
            "  map@10: 0.005021698\n",
            "Epoch 290, Step 20, LR: 0.000868, Current Loss: 0.4880, Avg Loss: 0.5023\n",
            "Diff stats — min: -4.3372, max: 10.0000, mean: 8.4900, std: 2.4373\n",
            "\n",
            "Epoch 290 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 291, Step 1, LR: 0.000851, Current Loss: 0.5012, Avg Loss: 0.5012\n",
            "Diff stats — min: -5.3589, max: 10.0000, mean: 8.4957, std: 2.4846\n",
            "\n",
            "Step 7142 — Test metrics:\n",
            "  precision@10: 0.013248468\n",
            "  recall@10: 0.013312828\n",
            "  ndcg@10: 0.014167323\n",
            "  map@10: 0.005342288\n",
            "Epoch 291, Step 20, LR: 0.000851, Current Loss: 0.4964, Avg Loss: 0.5013\n",
            "Diff stats — min: -4.5490, max: 10.0000, mean: 8.4019, std: 2.5573\n",
            "\n",
            "Epoch 291 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 292, Step 1, LR: 0.000851, Current Loss: 0.5143, Avg Loss: 0.5143\n",
            "Diff stats — min: -7.2252, max: 10.0000, mean: 8.4683, std: 2.4970\n",
            "\n",
            "Step 7172 — Test metrics:\n",
            "  precision@10: 0.012399811\n",
            "  recall@10: 0.012448830\n",
            "  ndcg@10: 0.013200845\n",
            "  map@10: 0.004907939\n",
            "Epoch 292, Step 20, LR: 0.000851, Current Loss: 0.5050, Avg Loss: 0.4987\n",
            "Diff stats — min: -5.5274, max: 10.0000, mean: 8.4557, std: 2.5118\n",
            "\n",
            "Epoch 292 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 293, Step 1, LR: 0.000851, Current Loss: 0.5184, Avg Loss: 0.5184\n",
            "Diff stats — min: -7.2430, max: 10.0000, mean: 8.4946, std: 2.4639\n",
            "\n",
            "Step 7202 — Test metrics:\n",
            "  precision@10: 0.012847713\n",
            "  recall@10: 0.012917312\n",
            "  ndcg@10: 0.013681089\n",
            "  map@10: 0.005105828\n",
            "Epoch 293, Step 20, LR: 0.000851, Current Loss: 0.4908, Avg Loss: 0.5004\n",
            "Diff stats — min: -5.0999, max: 10.0000, mean: 8.4860, std: 2.4959\n",
            "\n",
            "Epoch 293 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 294, Step 1, LR: 0.000851, Current Loss: 0.4990, Avg Loss: 0.4990\n",
            "Diff stats — min: -3.3343, max: 10.0000, mean: 8.4914, std: 2.4371\n",
            "\n",
            "Step 7232 — Test metrics:\n",
            "  precision@10: 0.013107025\n",
            "  recall@10: 0.013163901\n",
            "  ndcg@10: 0.014199932\n",
            "  map@10: 0.005412000\n",
            "Epoch 294, Step 20, LR: 0.000851, Current Loss: 0.4878, Avg Loss: 0.5003\n",
            "Diff stats — min: -5.2815, max: 10.0000, mean: 8.4416, std: 2.5042\n",
            "\n",
            "Epoch 294 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 295, Step 1, LR: 0.000851, Current Loss: 0.5105, Avg Loss: 0.5105\n",
            "Diff stats — min: -6.3829, max: 10.0000, mean: 8.4890, std: 2.5032\n",
            "\n",
            "Step 7262 — Test metrics:\n",
            "  precision@10: 0.012706271\n",
            "  recall@10: 0.012760528\n",
            "  ndcg@10: 0.013593908\n",
            "  map@10: 0.005089108\n",
            "Epoch 295, Step 20, LR: 0.000851, Current Loss: 0.5043, Avg Loss: 0.5020\n",
            "Diff stats — min: -5.5747, max: 10.0000, mean: 8.4858, std: 2.4549\n",
            "\n",
            "Epoch 295 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 296, Step 1, LR: 0.000834, Current Loss: 0.5116, Avg Loss: 0.5116\n",
            "Diff stats — min: -8.6140, max: 10.0000, mean: 8.5001, std: 2.4948\n",
            "\n",
            "Step 7292 — Test metrics:\n",
            "  precision@10: 0.013366337\n",
            "  recall@10: 0.013420594\n",
            "  ndcg@10: 0.014199760\n",
            "  map@10: 0.005251883\n",
            "Epoch 296, Step 20, LR: 0.000834, Current Loss: 0.5058, Avg Loss: 0.5031\n",
            "Diff stats — min: -5.9910, max: 10.0000, mean: 8.5268, std: 2.4660\n",
            "\n",
            "Epoch 296 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 297, Step 1, LR: 0.000834, Current Loss: 0.4892, Avg Loss: 0.4892\n",
            "Diff stats — min: -5.6947, max: 10.0000, mean: 8.4609, std: 2.5009\n",
            "\n",
            "Step 7322 — Test metrics:\n",
            "  precision@10: 0.012824140\n",
            "  recall@10: 0.012886909\n",
            "  ndcg@10: 0.013932784\n",
            "  map@10: 0.005331382\n",
            "Epoch 297, Step 20, LR: 0.000834, Current Loss: 0.4936, Avg Loss: 0.4987\n",
            "Diff stats — min: -3.9364, max: 10.0000, mean: 8.5235, std: 2.4444\n",
            "\n",
            "Epoch 297 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 298, Step 1, LR: 0.000834, Current Loss: 0.5084, Avg Loss: 0.5084\n",
            "Diff stats — min: -5.8930, max: 10.0000, mean: 8.4424, std: 2.5814\n",
            "\n",
            "Step 7352 — Test metrics:\n",
            "  precision@10: 0.012847713\n",
            "  recall@10: 0.012907209\n",
            "  ndcg@10: 0.014034067\n",
            "  map@10: 0.005315142\n",
            "Epoch 298, Step 20, LR: 0.000834, Current Loss: 0.5084, Avg Loss: 0.5017\n",
            "Diff stats — min: -5.3445, max: 10.0000, mean: 8.4688, std: 2.4777\n",
            "\n",
            "Epoch 298 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 299, Step 1, LR: 0.000834, Current Loss: 0.4848, Avg Loss: 0.4848\n",
            "Diff stats — min: -6.8280, max: 10.0000, mean: 8.4502, std: 2.5914\n",
            "\n",
            "Step 7382 — Test metrics:\n",
            "  precision@10: 0.013036304\n",
            "  recall@10: 0.013111141\n",
            "  ndcg@10: 0.014040796\n",
            "  map@10: 0.005224977\n",
            "Epoch 299, Step 20, LR: 0.000834, Current Loss: 0.5040, Avg Loss: 0.4991\n",
            "Diff stats — min: -4.1938, max: 10.0000, mean: 8.4995, std: 2.4868\n",
            "\n",
            "Epoch 299 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 300, Step 1, LR: 0.000834, Current Loss: 0.5067, Avg Loss: 0.5067\n",
            "Diff stats — min: -6.9352, max: 10.0000, mean: 8.4901, std: 2.4903\n",
            "\n",
            "Step 7412 — Test metrics:\n",
            "  precision@10: 0.013059877\n",
            "  recall@10: 0.013125267\n",
            "  ndcg@10: 0.013988855\n",
            "  map@10: 0.005269340\n",
            "Epoch 300, Step 20, LR: 0.000834, Current Loss: 0.4995, Avg Loss: 0.5017\n",
            "Diff stats — min: -5.9586, max: 10.0000, mean: 8.5564, std: 2.4152\n",
            "\n",
            "Epoch 300 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 301, Step 1, LR: 0.000817, Current Loss: 0.5120, Avg Loss: 0.5120\n",
            "Diff stats — min: -5.3770, max: 10.0000, mean: 8.5044, std: 2.4837\n",
            "\n",
            "Step 7442 — Test metrics:\n",
            "  precision@10: 0.012824140\n",
            "  recall@10: 0.012886255\n",
            "  ndcg@10: 0.013785144\n",
            "  map@10: 0.005198968\n",
            "Epoch 301, Step 20, LR: 0.000817, Current Loss: 0.5021, Avg Loss: 0.4980\n",
            "Diff stats — min: -7.4855, max: 10.0000, mean: 8.4786, std: 2.4785\n",
            "\n",
            "Epoch 301 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 302, Step 1, LR: 0.000817, Current Loss: 0.5238, Avg Loss: 0.5238\n",
            "Diff stats — min: -6.0612, max: 10.0000, mean: 8.5284, std: 2.4791\n",
            "\n",
            "Step 7472 — Test metrics:\n",
            "  precision@10: 0.012659123\n",
            "  recall@10: 0.012715999\n",
            "  ndcg@10: 0.013545069\n",
            "  map@10: 0.005161768\n",
            "Epoch 302, Step 20, LR: 0.000817, Current Loss: 0.5093, Avg Loss: 0.5015\n",
            "Diff stats — min: -7.9898, max: 10.0000, mean: 8.5193, std: 2.5047\n",
            "\n",
            "Epoch 302 completed, Train Loss: 0.000124\n",
            "\n",
            "Epoch 303, Step 1, LR: 0.000817, Current Loss: 0.4809, Avg Loss: 0.4809\n",
            "Diff stats — min: -7.2827, max: 10.0000, mean: 8.5058, std: 2.4720\n",
            "\n",
            "Step 7502 — Test metrics:\n",
            "  precision@10: 0.013154173\n",
            "  recall@10: 0.013211049\n",
            "  ndcg@10: 0.013945802\n",
            "  map@10: 0.005216460\n",
            "Epoch 303, Step 20, LR: 0.000817, Current Loss: 0.5176, Avg Loss: 0.5000\n",
            "Diff stats — min: -7.4019, max: 10.0000, mean: 8.4874, std: 2.4780\n",
            "\n",
            "Epoch 303 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 304, Step 1, LR: 0.000817, Current Loss: 0.5007, Avg Loss: 0.5007\n",
            "Diff stats — min: -6.6625, max: 10.0000, mean: 8.5429, std: 2.4484\n",
            "\n",
            "Step 7532 — Test metrics:\n",
            "  precision@10: 0.012800566\n",
            "  recall@10: 0.012868200\n",
            "  ndcg@10: 0.013627738\n",
            "  map@10: 0.005147989\n",
            "Epoch 304, Step 20, LR: 0.000817, Current Loss: 0.4927, Avg Loss: 0.4990\n",
            "Diff stats — min: -7.0188, max: 10.0000, mean: 8.5428, std: 2.4358\n",
            "\n",
            "Epoch 304 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 305, Step 1, LR: 0.000817, Current Loss: 0.5044, Avg Loss: 0.5044\n",
            "Diff stats — min: -6.4191, max: 10.0000, mean: 8.5306, std: 2.4623\n",
            "\n",
            "Step 7562 — Test metrics:\n",
            "  precision@10: 0.013083451\n",
            "  recall@10: 0.013145566\n",
            "  ndcg@10: 0.014061666\n",
            "  map@10: 0.005318506\n",
            "Epoch 305, Step 20, LR: 0.000817, Current Loss: 0.5057, Avg Loss: 0.4980\n",
            "Diff stats — min: -6.7973, max: 10.0000, mean: 8.5493, std: 2.4223\n",
            "\n",
            "Epoch 305 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 306, Step 1, LR: 0.000801, Current Loss: 0.5082, Avg Loss: 0.5082\n",
            "Diff stats — min: -6.2116, max: 10.0000, mean: 8.5536, std: 2.4535\n",
            "\n",
            "Step 7592 — Test metrics:\n",
            "  precision@10: 0.013224894\n",
            "  recall@10: 0.013287009\n",
            "  ndcg@10: 0.014197215\n",
            "  map@10: 0.005339729\n",
            "Epoch 306, Step 20, LR: 0.000801, Current Loss: 0.4872, Avg Loss: 0.5002\n",
            "Diff stats — min: -5.6815, max: 10.0000, mean: 8.5645, std: 2.3966\n",
            "\n",
            "Epoch 306 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 307, Step 1, LR: 0.000801, Current Loss: 0.5008, Avg Loss: 0.5008\n",
            "Diff stats — min: -5.7351, max: 10.0000, mean: 8.5205, std: 2.5088\n",
            "\n",
            "Step 7622 — Test metrics:\n",
            "  precision@10: 0.013484206\n",
            "  recall@10: 0.013559043\n",
            "  ndcg@10: 0.014491133\n",
            "  map@10: 0.005474492\n",
            "Epoch 307, Step 20, LR: 0.000801, Current Loss: 0.4912, Avg Loss: 0.4978\n",
            "Diff stats — min: -5.7255, max: 10.0000, mean: 8.5135, std: 2.4280\n",
            "\n",
            "Epoch 307 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 308, Step 1, LR: 0.000801, Current Loss: 0.5062, Avg Loss: 0.5062\n",
            "Diff stats — min: -5.8534, max: 10.0000, mean: 8.5221, std: 2.4594\n",
            "\n",
            "Step 7652 — Test metrics:\n",
            "  precision@10: 0.013743517\n",
            "  recall@10: 0.013820974\n",
            "  ndcg@10: 0.014655182\n",
            "  map@10: 0.005568880\n",
            "Epoch 308, Step 20, LR: 0.000801, Current Loss: 0.5105, Avg Loss: 0.5004\n",
            "Diff stats — min: -6.6009, max: 10.0000, mean: 8.5627, std: 2.4152\n",
            "\n",
            "Epoch 308 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 309, Step 1, LR: 0.000801, Current Loss: 0.4974, Avg Loss: 0.4974\n",
            "Diff stats — min: -7.2743, max: 10.0000, mean: 8.5527, std: 2.3952\n",
            "\n",
            "Step 7682 — Test metrics:\n",
            "  precision@10: 0.013389910\n",
            "  recall@10: 0.013456890\n",
            "  ndcg@10: 0.014287335\n",
            "  map@10: 0.005382677\n",
            "Epoch 309, Step 20, LR: 0.000801, Current Loss: 0.5023, Avg Loss: 0.4998\n",
            "Diff stats — min: -5.8413, max: 10.0000, mean: 8.4805, std: 2.5397\n",
            "\n",
            "Epoch 309 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 310, Step 1, LR: 0.000801, Current Loss: 0.5035, Avg Loss: 0.5035\n",
            "Diff stats — min: -5.6154, max: 10.0000, mean: 8.5908, std: 2.4173\n",
            "\n",
            "Step 7712 — Test metrics:\n",
            "  precision@10: 0.013578501\n",
            "  recall@10: 0.013653338\n",
            "  ndcg@10: 0.014801989\n",
            "  map@10: 0.005640453\n",
            "Epoch 310, Step 20, LR: 0.000801, Current Loss: 0.5032, Avg Loss: 0.5007\n",
            "Diff stats — min: -6.8942, max: 10.0000, mean: 8.5828, std: 2.4477\n",
            "\n",
            "Epoch 310 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 311, Step 1, LR: 0.000785, Current Loss: 0.5009, Avg Loss: 0.5009\n",
            "Diff stats — min: -6.9575, max: 10.0000, mean: 8.5145, std: 2.4993\n",
            "\n",
            "Step 7742 — Test metrics:\n",
            "  precision@10: 0.013790665\n",
            "  recall@10: 0.013862883\n",
            "  ndcg@10: 0.014694155\n",
            "  map@10: 0.005623440\n",
            "Epoch 311, Step 20, LR: 0.000785, Current Loss: 0.4998, Avg Loss: 0.4993\n",
            "Diff stats — min: -5.8161, max: 10.0000, mean: 8.5267, std: 2.4299\n",
            "\n",
            "Epoch 311 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 312, Step 1, LR: 0.000785, Current Loss: 0.4842, Avg Loss: 0.4842\n",
            "Diff stats — min: -8.6034, max: 10.0000, mean: 8.5054, std: 2.4797\n",
            "\n",
            "Step 7772 — Test metrics:\n",
            "  precision@10: 0.013437058\n",
            "  recall@10: 0.013504412\n",
            "  ndcg@10: 0.014406583\n",
            "  map@10: 0.005445587\n",
            "Epoch 312, Step 20, LR: 0.000785, Current Loss: 0.4889, Avg Loss: 0.4979\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.5854, std: 2.3911\n",
            "\n",
            "Epoch 312 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 313, Step 1, LR: 0.000785, Current Loss: 0.5039, Avg Loss: 0.5039\n",
            "Diff stats — min: -6.6146, max: 10.0000, mean: 8.5412, std: 2.4294\n",
            "\n",
            "Step 7802 — Test metrics:\n",
            "  precision@10: 0.013767091\n",
            "  recall@10: 0.013841928\n",
            "  ndcg@10: 0.014603304\n",
            "  map@10: 0.005546568\n",
            "Epoch 313, Step 20, LR: 0.000785, Current Loss: 0.5003, Avg Loss: 0.4991\n",
            "Diff stats — min: -4.7904, max: 10.0000, mean: 8.6374, std: 2.3210\n",
            "\n",
            "Epoch 313 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 314, Step 1, LR: 0.000785, Current Loss: 0.4928, Avg Loss: 0.4928\n",
            "Diff stats — min: -5.6635, max: 10.0000, mean: 8.6080, std: 2.3385\n",
            "\n",
            "Step 7832 — Test metrics:\n",
            "  precision@10: 0.013389910\n",
            "  recall@10: 0.013459509\n",
            "  ndcg@10: 0.014264091\n",
            "  map@10: 0.005383602\n",
            "Epoch 314, Step 20, LR: 0.000785, Current Loss: 0.4958, Avg Loss: 0.5008\n",
            "Diff stats — min: -6.4985, max: 10.0000, mean: 8.5678, std: 2.4511\n",
            "\n",
            "Epoch 314 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 315, Step 1, LR: 0.000785, Current Loss: 0.4973, Avg Loss: 0.4973\n",
            "Diff stats — min: -6.7997, max: 10.0000, mean: 8.5588, std: 2.4419\n",
            "\n",
            "Step 7862 — Test metrics:\n",
            "  precision@10: 0.013625648\n",
            "  recall@10: 0.013697866\n",
            "  ndcg@10: 0.014686591\n",
            "  map@10: 0.005636613\n",
            "Epoch 315, Step 20, LR: 0.000785, Current Loss: 0.4952, Avg Loss: 0.4989\n",
            "Diff stats — min: -6.4869, max: 10.0000, mean: 8.5422, std: 2.4678\n",
            "\n",
            "Epoch 315 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 316, Step 1, LR: 0.000769, Current Loss: 0.5038, Avg Loss: 0.5038\n",
            "Diff stats — min: -6.5027, max: 10.0000, mean: 8.5491, std: 2.4549\n",
            "\n",
            "Step 7892 — Test metrics:\n",
            "  precision@10: 0.013389910\n",
            "  recall@10: 0.013446787\n",
            "  ndcg@10: 0.014574462\n",
            "  map@10: 0.005584340\n",
            "Epoch 316, Step 20, LR: 0.000769, Current Loss: 0.4909, Avg Loss: 0.4987\n",
            "Diff stats — min: -4.5322, max: 10.0000, mean: 8.5741, std: 2.3809\n",
            "\n",
            "Epoch 316 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 317, Step 1, LR: 0.000769, Current Loss: 0.4870, Avg Loss: 0.4870\n",
            "Diff stats — min: -5.8177, max: 10.0000, mean: 8.5438, std: 2.3895\n",
            "\n",
            "Step 7922 — Test metrics:\n",
            "  precision@10: 0.013696370\n",
            "  recall@10: 0.013765968\n",
            "  ndcg@10: 0.014561451\n",
            "  map@10: 0.005475563\n",
            "Epoch 317, Step 20, LR: 0.000769, Current Loss: 0.4889, Avg Loss: 0.4985\n",
            "Diff stats — min: -7.4128, max: 10.0000, mean: 8.6132, std: 2.3857\n",
            "\n",
            "Epoch 317 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 318, Step 1, LR: 0.000769, Current Loss: 0.4805, Avg Loss: 0.4805\n",
            "Diff stats — min: -8.0592, max: 10.0000, mean: 8.6033, std: 2.3989\n",
            "\n",
            "Step 7952 — Test metrics:\n",
            "  precision@10: 0.013107025\n",
            "  recall@10: 0.013163901\n",
            "  ndcg@10: 0.014158641\n",
            "  map@10: 0.005388057\n",
            "Epoch 318, Step 20, LR: 0.000769, Current Loss: 0.4957, Avg Loss: 0.4976\n",
            "Diff stats — min: -5.9721, max: 10.0000, mean: 8.5666, std: 2.4111\n",
            "\n",
            "Epoch 318 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 319, Step 1, LR: 0.000769, Current Loss: 0.4792, Avg Loss: 0.4792\n",
            "Diff stats — min: -4.5503, max: 10.0000, mean: 8.6089, std: 2.3408\n",
            "\n",
            "Step 7982 — Test metrics:\n",
            "  precision@10: 0.013578501\n",
            "  recall@10: 0.013646509\n",
            "  ndcg@10: 0.014405170\n",
            "  map@10: 0.005421826\n",
            "Epoch 319, Step 20, LR: 0.000769, Current Loss: 0.5003, Avg Loss: 0.4962\n",
            "Diff stats — min: -7.7579, max: 10.0000, mean: 8.5931, std: 2.3960\n",
            "\n",
            "Epoch 319 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 320, Step 1, LR: 0.000769, Current Loss: 0.4927, Avg Loss: 0.4927\n",
            "Diff stats — min: -5.1964, max: 10.0000, mean: 8.5688, std: 2.4133\n",
            "\n",
            "Step 8012 — Test metrics:\n",
            "  precision@10: 0.013649222\n",
            "  recall@10: 0.013718821\n",
            "  ndcg@10: 0.014615655\n",
            "  map@10: 0.005561635\n",
            "Epoch 320, Step 20, LR: 0.000769, Current Loss: 0.5125, Avg Loss: 0.5001\n",
            "Diff stats — min: -5.6931, max: 10.0000, mean: 8.6018, std: 2.4122\n",
            "\n",
            "Epoch 320 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 321, Step 1, LR: 0.000754, Current Loss: 0.4946, Avg Loss: 0.4946\n",
            "Diff stats — min: -5.4274, max: 10.0000, mean: 8.6531, std: 2.3234\n",
            "\n",
            "Step 8042 — Test metrics:\n",
            "  precision@10: 0.013531353\n",
            "  recall@10: 0.013593468\n",
            "  ndcg@10: 0.014216871\n",
            "  map@10: 0.005289478\n",
            "Epoch 321, Step 20, LR: 0.000754, Current Loss: 0.4997, Avg Loss: 0.4959\n",
            "Diff stats — min: -8.0565, max: 10.0000, mean: 8.5607, std: 2.4278\n",
            "\n",
            "Epoch 321 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 322, Step 1, LR: 0.000754, Current Loss: 0.5111, Avg Loss: 0.5111\n",
            "Diff stats — min: -7.9641, max: 10.0000, mean: 8.5832, std: 2.4267\n",
            "\n",
            "Step 8072 — Test metrics:\n",
            "  precision@10: 0.013437058\n",
            "  recall@10: 0.013501418\n",
            "  ndcg@10: 0.014386063\n",
            "  map@10: 0.005427731\n",
            "Epoch 322, Step 20, LR: 0.000754, Current Loss: 0.5002, Avg Loss: 0.5004\n",
            "Diff stats — min: -6.3005, max: 10.0000, mean: 8.6833, std: 2.3121\n",
            "\n",
            "Epoch 322 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 323, Step 1, LR: 0.000754, Current Loss: 0.4987, Avg Loss: 0.4987\n",
            "Diff stats — min: -7.6894, max: 10.0000, mean: 8.5448, std: 2.4460\n",
            "\n",
            "Step 8102 — Test metrics:\n",
            "  precision@10: 0.013649222\n",
            "  recall@10: 0.013721440\n",
            "  ndcg@10: 0.014568806\n",
            "  map@10: 0.005546464\n",
            "Epoch 323, Step 20, LR: 0.000754, Current Loss: 0.5144, Avg Loss: 0.4995\n",
            "Diff stats — min: -5.7149, max: 10.0000, mean: 8.6513, std: 2.3787\n",
            "\n",
            "Epoch 323 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 324, Step 1, LR: 0.000754, Current Loss: 0.5047, Avg Loss: 0.5047\n",
            "Diff stats — min: -5.1264, max: 10.0000, mean: 8.6371, std: 2.3796\n",
            "\n",
            "Step 8132 — Test metrics:\n",
            "  precision@10: 0.013814239\n",
            "  recall@10: 0.013886457\n",
            "  ndcg@10: 0.014608410\n",
            "  map@10: 0.005481145\n",
            "Epoch 324, Step 20, LR: 0.000754, Current Loss: 0.5021, Avg Loss: 0.4973\n",
            "Diff stats — min: -6.0475, max: 10.0000, mean: 8.6192, std: 2.3454\n",
            "\n",
            "Epoch 324 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 325, Step 1, LR: 0.000754, Current Loss: 0.4958, Avg Loss: 0.4958\n",
            "Diff stats — min: -6.3317, max: 10.0000, mean: 8.5811, std: 2.4359\n",
            "\n",
            "Step 8162 — Test metrics:\n",
            "  precision@10: 0.013884960\n",
            "  recall@10: 0.013954933\n",
            "  ndcg@10: 0.014631978\n",
            "  map@10: 0.005568997\n",
            "Epoch 325, Step 20, LR: 0.000754, Current Loss: 0.4959, Avg Loss: 0.4966\n",
            "Diff stats — min: -5.3876, max: 10.0000, mean: 8.6560, std: 2.3601\n",
            "\n",
            "Epoch 325 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 326, Step 1, LR: 0.000739, Current Loss: 0.4907, Avg Loss: 0.4907\n",
            "Diff stats — min: -4.0312, max: 10.0000, mean: 8.5876, std: 2.4074\n",
            "\n",
            "Step 8192 — Test metrics:\n",
            "  precision@10: 0.014049976\n",
            "  recall@10: 0.014127433\n",
            "  ndcg@10: 0.014858750\n",
            "  map@10: 0.005657459\n",
            "Epoch 326, Step 20, LR: 0.000739, Current Loss: 0.4964, Avg Loss: 0.4993\n",
            "Diff stats — min: -6.7665, max: 10.0000, mean: 8.6358, std: 2.3750\n",
            "\n",
            "Epoch 326 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 327, Step 1, LR: 0.000739, Current Loss: 0.4955, Avg Loss: 0.4955\n",
            "Diff stats — min: -6.7803, max: 10.0000, mean: 8.6212, std: 2.3987\n",
            "\n",
            "Step 8222 — Test metrics:\n",
            "  precision@10: 0.013484206\n",
            "  recall@10: 0.013556424\n",
            "  ndcg@10: 0.014622497\n",
            "  map@10: 0.005692097\n",
            "Epoch 327, Step 20, LR: 0.000739, Current Loss: 0.4860, Avg Loss: 0.4984\n",
            "Diff stats — min: -8.3216, max: 10.0000, mean: 8.6073, std: 2.3865\n",
            "\n",
            "Epoch 327 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 328, Step 1, LR: 0.000739, Current Loss: 0.5115, Avg Loss: 0.5115\n",
            "Diff stats — min: -5.3237, max: 10.0000, mean: 8.5839, std: 2.4237\n",
            "\n",
            "Step 8252 — Test metrics:\n",
            "  precision@10: 0.013908534\n",
            "  recall@10: 0.013980752\n",
            "  ndcg@10: 0.014725643\n",
            "  map@10: 0.005629529\n",
            "Epoch 328, Step 20, LR: 0.000739, Current Loss: 0.4976, Avg Loss: 0.4984\n",
            "Diff stats — min: -9.1582, max: 10.0000, mean: 8.6280, std: 2.3462\n",
            "\n",
            "Epoch 328 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 329, Step 1, LR: 0.000739, Current Loss: 0.4883, Avg Loss: 0.4883\n",
            "Diff stats — min: -7.2746, max: 10.0000, mean: 8.6194, std: 2.3527\n",
            "\n",
            "Step 8282 — Test metrics:\n",
            "  precision@10: 0.013719943\n",
            "  recall@10: 0.013782058\n",
            "  ndcg@10: 0.014600563\n",
            "  map@10: 0.005587674\n",
            "Epoch 329, Step 20, LR: 0.000739, Current Loss: 0.4947, Avg Loss: 0.4976\n",
            "Diff stats — min: -8.6436, max: 10.0000, mean: 8.6767, std: 2.3350\n",
            "\n",
            "Epoch 329 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 330, Step 1, LR: 0.000739, Current Loss: 0.4963, Avg Loss: 0.4963\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.6502, std: 2.3789\n",
            "\n",
            "Step 8312 — Test metrics:\n",
            "  precision@10: 0.013484206\n",
            "  recall@10: 0.013546975\n",
            "  ndcg@10: 0.014483365\n",
            "  map@10: 0.005593396\n",
            "Epoch 330, Step 20, LR: 0.000739, Current Loss: 0.4933, Avg Loss: 0.4974\n",
            "Diff stats — min: -4.8800, max: 10.0000, mean: 8.5952, std: 2.4363\n",
            "\n",
            "Epoch 330 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 331, Step 1, LR: 0.000724, Current Loss: 0.4964, Avg Loss: 0.4964\n",
            "Diff stats — min: -7.2417, max: 10.0000, mean: 8.6482, std: 2.3174\n",
            "\n",
            "Step 8342 — Test metrics:\n",
            "  precision@10: 0.013531353\n",
            "  recall@10: 0.013601607\n",
            "  ndcg@10: 0.014356348\n",
            "  map@10: 0.005527767\n",
            "Epoch 331, Step 20, LR: 0.000724, Current Loss: 0.4978, Avg Loss: 0.4970\n",
            "Diff stats — min: -6.1659, max: 10.0000, mean: 8.6368, std: 2.3780\n",
            "\n",
            "Epoch 331 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 332, Step 1, LR: 0.000724, Current Loss: 0.4979, Avg Loss: 0.4979\n",
            "Diff stats — min: -5.9039, max: 10.0000, mean: 8.6042, std: 2.3802\n",
            "\n",
            "Step 8372 — Test metrics:\n",
            "  precision@10: 0.013767091\n",
            "  recall@10: 0.013826587\n",
            "  ndcg@10: 0.014739148\n",
            "  map@10: 0.005680738\n",
            "Epoch 332, Step 20, LR: 0.000724, Current Loss: 0.4940, Avg Loss: 0.4983\n",
            "Diff stats — min: -5.8307, max: 10.0000, mean: 8.7168, std: 2.3199\n",
            "\n",
            "Epoch 332 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 333, Step 1, LR: 0.000724, Current Loss: 0.4900, Avg Loss: 0.4900\n",
            "Diff stats — min: -7.4191, max: 10.0000, mean: 8.6802, std: 2.3408\n",
            "\n",
            "Step 8402 — Test metrics:\n",
            "  precision@10: 0.013295615\n",
            "  recall@10: 0.013347253\n",
            "  ndcg@10: 0.014141405\n",
            "  map@10: 0.005381045\n",
            "Epoch 333, Step 20, LR: 0.000724, Current Loss: 0.4866, Avg Loss: 0.4969\n",
            "Diff stats — min: -5.2086, max: 10.0000, mean: 8.6081, std: 2.4310\n",
            "\n",
            "Epoch 333 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 334, Step 1, LR: 0.000724, Current Loss: 0.5059, Avg Loss: 0.5059\n",
            "Diff stats — min: -8.8129, max: 10.0000, mean: 8.6680, std: 2.3670\n",
            "\n",
            "Step 8432 — Test metrics:\n",
            "  precision@10: 0.013460632\n",
            "  recall@10: 0.013536124\n",
            "  ndcg@10: 0.014439377\n",
            "  map@10: 0.005542676\n",
            "Epoch 334, Step 20, LR: 0.000724, Current Loss: 0.5072, Avg Loss: 0.4975\n",
            "Diff stats — min: -7.0004, max: 10.0000, mean: 8.5411, std: 2.4549\n",
            "\n",
            "Epoch 334 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 335, Step 1, LR: 0.000724, Current Loss: 0.5090, Avg Loss: 0.5090\n",
            "Diff stats — min: -6.7742, max: 10.0000, mean: 8.6540, std: 2.3309\n",
            "\n",
            "Step 8462 — Test metrics:\n",
            "  precision@10: 0.013578501\n",
            "  recall@10: 0.013653993\n",
            "  ndcg@10: 0.014654787\n",
            "  map@10: 0.005682437\n",
            "Epoch 335, Step 20, LR: 0.000724, Current Loss: 0.5029, Avg Loss: 0.4984\n",
            "Diff stats — min: -6.6681, max: 10.0000, mean: 8.5978, std: 2.4434\n",
            "\n",
            "Epoch 335 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 336, Step 1, LR: 0.000709, Current Loss: 0.5054, Avg Loss: 0.5054\n",
            "Diff stats — min: -4.9859, max: 10.0000, mean: 8.6395, std: 2.3788\n",
            "\n",
            "Step 8492 — Test metrics:\n",
            "  precision@10: 0.013837812\n",
            "  recall@10: 0.013915924\n",
            "  ndcg@10: 0.014655748\n",
            "  map@10: 0.005555939\n",
            "Epoch 336, Step 20, LR: 0.000709, Current Loss: 0.5017, Avg Loss: 0.4967\n",
            "Diff stats — min: -5.7798, max: 10.0000, mean: 8.6176, std: 2.3771\n",
            "\n",
            "Epoch 336 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 337, Step 1, LR: 0.000709, Current Loss: 0.5003, Avg Loss: 0.5003\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.6152, std: 2.4122\n",
            "\n",
            "Step 8522 — Test metrics:\n",
            "  precision@10: 0.013507779\n",
            "  recall@10: 0.013585891\n",
            "  ndcg@10: 0.014281132\n",
            "  map@10: 0.005520889\n",
            "Epoch 337, Step 20, LR: 0.000709, Current Loss: 0.4856, Avg Loss: 0.4981\n",
            "Diff stats — min: -9.8394, max: 10.0000, mean: 8.6531, std: 2.3959\n",
            "\n",
            "Epoch 337 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 338, Step 1, LR: 0.000709, Current Loss: 0.4993, Avg Loss: 0.4993\n",
            "Diff stats — min: -4.9019, max: 10.0000, mean: 8.6358, std: 2.3616\n",
            "\n",
            "Step 8552 — Test metrics:\n",
            "  precision@10: 0.013908534\n",
            "  recall@10: 0.013984026\n",
            "  ndcg@10: 0.014890291\n",
            "  map@10: 0.005805038\n",
            "Epoch 338, Step 20, LR: 0.000709, Current Loss: 0.4948, Avg Loss: 0.4972\n",
            "Diff stats — min: -4.6318, max: 10.0000, mean: 8.6425, std: 2.3554\n",
            "\n",
            "Epoch 338 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 339, Step 1, LR: 0.000709, Current Loss: 0.4968, Avg Loss: 0.4968\n",
            "Diff stats — min: -6.3560, max: 10.0000, mean: 8.6370, std: 2.3856\n",
            "\n",
            "Step 8582 — Test metrics:\n",
            "  precision@10: 0.013743517\n",
            "  recall@10: 0.013819009\n",
            "  ndcg@10: 0.014424586\n",
            "  map@10: 0.005523235\n",
            "Epoch 339, Step 20, LR: 0.000709, Current Loss: 0.4946, Avg Loss: 0.4967\n",
            "Diff stats — min: -5.8702, max: 10.0000, mean: 8.6523, std: 2.3474\n",
            "\n",
            "Epoch 339 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 340, Step 1, LR: 0.000709, Current Loss: 0.4788, Avg Loss: 0.4788\n",
            "Diff stats — min: -3.6893, max: 10.0000, mean: 8.5701, std: 2.3901\n",
            "\n",
            "Step 8612 — Test metrics:\n",
            "  precision@10: 0.014120698\n",
            "  recall@10: 0.014198809\n",
            "  ndcg@10: 0.014805122\n",
            "  map@10: 0.005755438\n",
            "Epoch 340, Step 20, LR: 0.000709, Current Loss: 0.5258, Avg Loss: 0.4962\n",
            "Diff stats — min: -6.5805, max: 10.0000, mean: 8.6293, std: 2.3728\n",
            "\n",
            "Epoch 340 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 341, Step 1, LR: 0.000695, Current Loss: 0.4911, Avg Loss: 0.4911\n",
            "Diff stats — min: -7.5583, max: 10.0000, mean: 8.6897, std: 2.3343\n",
            "\n",
            "Step 8642 — Test metrics:\n",
            "  precision@10: 0.013342763\n",
            "  recall@10: 0.013416665\n",
            "  ndcg@10: 0.014064593\n",
            "  map@10: 0.005368913\n",
            "Epoch 341, Step 20, LR: 0.000695, Current Loss: 0.4998, Avg Loss: 0.4973\n",
            "Diff stats — min: -4.6778, max: 10.0000, mean: 8.6571, std: 2.3433\n",
            "\n",
            "Epoch 341 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 342, Step 1, LR: 0.000695, Current Loss: 0.4779, Avg Loss: 0.4779\n",
            "Diff stats — min: -6.8350, max: 10.0000, mean: 8.7282, std: 2.2711\n",
            "\n",
            "Step 8672 — Test metrics:\n",
            "  precision@10: 0.014026403\n",
            "  recall@10: 0.014097030\n",
            "  ndcg@10: 0.014660173\n",
            "  map@10: 0.005592082\n",
            "Epoch 342, Step 20, LR: 0.000695, Current Loss: 0.5077, Avg Loss: 0.4945\n",
            "Diff stats — min: -6.3931, max: 10.0000, mean: 8.6189, std: 2.4190\n",
            "\n",
            "Epoch 342 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 343, Step 1, LR: 0.000695, Current Loss: 0.4929, Avg Loss: 0.4929\n",
            "Diff stats — min: -6.4787, max: 10.0000, mean: 8.7078, std: 2.3005\n",
            "\n",
            "Step 8702 — Test metrics:\n",
            "  precision@10: 0.014167845\n",
            "  recall@10: 0.014246986\n",
            "  ndcg@10: 0.014883621\n",
            "  map@10: 0.005685099\n",
            "Epoch 343, Step 20, LR: 0.000695, Current Loss: 0.4885, Avg Loss: 0.4958\n",
            "Diff stats — min: -7.5764, max: 10.0000, mean: 8.7173, std: 2.2929\n",
            "\n",
            "Epoch 343 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 344, Step 1, LR: 0.000695, Current Loss: 0.4896, Avg Loss: 0.4896\n",
            "Diff stats — min: -7.2582, max: 10.0000, mean: 8.6537, std: 2.3713\n",
            "\n",
            "Step 8732 — Test metrics:\n",
            "  precision@10: 0.014521452\n",
            "  recall@10: 0.014594699\n",
            "  ndcg@10: 0.015429392\n",
            "  map@10: 0.006067329\n",
            "Epoch 344, Step 20, LR: 0.000695, Current Loss: 0.5031, Avg Loss: 0.4942\n",
            "Diff stats — min: -3.4865, max: 10.0000, mean: 8.6777, std: 2.2968\n",
            "\n",
            "Epoch 344 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 345, Step 1, LR: 0.000695, Current Loss: 0.4836, Avg Loss: 0.4836\n",
            "Diff stats — min: -5.9593, max: 10.0000, mean: 8.5707, std: 2.4579\n",
            "\n",
            "Step 8762 — Test metrics:\n",
            "  precision@10: 0.014474305\n",
            "  recall@10: 0.014547552\n",
            "  ndcg@10: 0.015164259\n",
            "  map@10: 0.005935276\n",
            "Epoch 345, Step 20, LR: 0.000695, Current Loss: 0.4975, Avg Loss: 0.4977\n",
            "Diff stats — min: -3.1710, max: 10.0000, mean: 8.6737, std: 2.3378\n",
            "\n",
            "Epoch 345 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 346, Step 1, LR: 0.000681, Current Loss: 0.5184, Avg Loss: 0.5184\n",
            "Diff stats — min: -6.7143, max: 10.0000, mean: 8.6112, std: 2.4194\n",
            "\n",
            "Step 8792 — Test metrics:\n",
            "  precision@10: 0.014144272\n",
            "  recall@10: 0.014217519\n",
            "  ndcg@10: 0.015055873\n",
            "  map@10: 0.005820108\n",
            "Epoch 346, Step 20, LR: 0.000681, Current Loss: 0.4885, Avg Loss: 0.4940\n",
            "Diff stats — min: -6.0018, max: 10.0000, mean: 8.6576, std: 2.3515\n",
            "\n",
            "Epoch 346 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 347, Step 1, LR: 0.000681, Current Loss: 0.4933, Avg Loss: 0.4933\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.6911, std: 2.3444\n",
            "\n",
            "Step 8822 — Test metrics:\n",
            "  precision@10: 0.014804338\n",
            "  recall@10: 0.014887688\n",
            "  ndcg@10: 0.015352942\n",
            "  map@10: 0.005941854\n",
            "Epoch 347, Step 20, LR: 0.000681, Current Loss: 0.4815, Avg Loss: 0.4945\n",
            "Diff stats — min: -5.6668, max: 10.0000, mean: 8.6808, std: 2.3470\n",
            "\n",
            "Epoch 347 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 348, Step 1, LR: 0.000681, Current Loss: 0.5025, Avg Loss: 0.5025\n",
            "Diff stats — min: -6.8695, max: 10.0000, mean: 8.7204, std: 2.3192\n",
            "\n",
            "Step 8852 — Test metrics:\n",
            "  precision@10: 0.014615747\n",
            "  recall@10: 0.014702372\n",
            "  ndcg@10: 0.015473896\n",
            "  map@10: 0.006092355\n",
            "Epoch 348, Step 20, LR: 0.000681, Current Loss: 0.4869, Avg Loss: 0.4944\n",
            "Diff stats — min: -3.7482, max: 10.0000, mean: 8.7030, std: 2.2932\n",
            "\n",
            "Epoch 348 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 349, Step 1, LR: 0.000681, Current Loss: 0.4910, Avg Loss: 0.4910\n",
            "Diff stats — min: -4.8474, max: 10.0000, mean: 8.6625, std: 2.3178\n",
            "\n",
            "Step 8882 — Test metrics:\n",
            "  precision@10: 0.015346535\n",
            "  recall@10: 0.015437743\n",
            "  ndcg@10: 0.016028731\n",
            "  map@10: 0.006279463\n",
            "Epoch 349, Step 20, LR: 0.000681, Current Loss: 0.4947, Avg Loss: 0.4969\n",
            "Diff stats — min: -6.2118, max: 10.0000, mean: 8.6630, std: 2.3830\n",
            "\n",
            "Epoch 349 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 350, Step 1, LR: 0.000681, Current Loss: 0.5212, Avg Loss: 0.5212\n",
            "Diff stats — min: -6.8167, max: 10.0000, mean: 8.6255, std: 2.4770\n",
            "\n",
            "Step 8912 — Test metrics:\n",
            "  precision@10: 0.014592174\n",
            "  recall@10: 0.014675524\n",
            "  ndcg@10: 0.015388011\n",
            "  map@10: 0.006005650\n",
            "Epoch 350, Step 20, LR: 0.000681, Current Loss: 0.4908, Avg Loss: 0.4992\n",
            "Diff stats — min: -7.6744, max: 10.0000, mean: 8.6619, std: 2.3438\n",
            "\n",
            "Epoch 350 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 351, Step 1, LR: 0.000668, Current Loss: 0.5062, Avg Loss: 0.5062\n",
            "Diff stats — min: -6.1248, max: 10.0000, mean: 8.6992, std: 2.2869\n",
            "\n",
            "Step 8942 — Test metrics:\n",
            "  precision@10: 0.014191419\n",
            "  recall@10: 0.014283282\n",
            "  ndcg@10: 0.015116066\n",
            "  map@10: 0.005904849\n",
            "Epoch 351, Step 20, LR: 0.000668, Current Loss: 0.5145, Avg Loss: 0.4987\n",
            "Diff stats — min: -5.3546, max: 10.0000, mean: 8.6556, std: 2.3577\n",
            "\n",
            "Epoch 351 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 352, Step 1, LR: 0.000668, Current Loss: 0.4890, Avg Loss: 0.4890\n",
            "Diff stats — min: -5.9397, max: 10.0000, mean: 8.7092, std: 2.3111\n",
            "\n",
            "Step 8972 — Test metrics:\n",
            "  precision@10: 0.014214993\n",
            "  recall@10: 0.014301617\n",
            "  ndcg@10: 0.015064215\n",
            "  map@10: 0.005868399\n",
            "Epoch 352, Step 20, LR: 0.000668, Current Loss: 0.5004, Avg Loss: 0.4961\n",
            "Diff stats — min: -5.2874, max: 10.0000, mean: 8.6310, std: 2.3506\n",
            "\n",
            "Epoch 352 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 353, Step 1, LR: 0.000668, Current Loss: 0.4851, Avg Loss: 0.4851\n",
            "Diff stats — min: -4.5328, max: 10.0000, mean: 8.7176, std: 2.2777\n",
            "\n",
            "Step 9002 — Test metrics:\n",
            "  precision@10: 0.014380009\n",
            "  recall@10: 0.014467943\n",
            "  ndcg@10: 0.015139071\n",
            "  map@10: 0.005801163\n",
            "Epoch 353, Step 20, LR: 0.000668, Current Loss: 0.5071, Avg Loss: 0.4938\n",
            "Diff stats — min: -5.8685, max: 10.0000, mean: 8.7152, std: 2.3189\n",
            "\n",
            "Epoch 353 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 354, Step 1, LR: 0.000668, Current Loss: 0.4917, Avg Loss: 0.4917\n",
            "Diff stats — min: -6.1610, max: 10.0000, mean: 8.6727, std: 2.3425\n",
            "\n",
            "Step 9032 — Test metrics:\n",
            "  precision@10: 0.014167845\n",
            "  recall@10: 0.014251196\n",
            "  ndcg@10: 0.015286225\n",
            "  map@10: 0.006030144\n",
            "Epoch 354, Step 20, LR: 0.000668, Current Loss: 0.4936, Avg Loss: 0.4953\n",
            "Diff stats — min: -6.4607, max: 10.0000, mean: 8.6403, std: 2.3508\n",
            "\n",
            "Epoch 354 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 355, Step 1, LR: 0.000668, Current Loss: 0.5039, Avg Loss: 0.5039\n",
            "Diff stats — min: -5.4369, max: 10.0000, mean: 8.6534, std: 2.3198\n",
            "\n",
            "Step 9062 — Test metrics:\n",
            "  precision@10: 0.014214993\n",
            "  recall@10: 0.014297688\n",
            "  ndcg@10: 0.015069733\n",
            "  map@10: 0.005903547\n",
            "Epoch 355, Step 20, LR: 0.000668, Current Loss: 0.5031, Avg Loss: 0.4963\n",
            "Diff stats — min: -4.6457, max: 10.0000, mean: 8.6253, std: 2.4026\n",
            "\n",
            "Epoch 355 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 356, Step 1, LR: 0.000654, Current Loss: 0.4849, Avg Loss: 0.4849\n",
            "Diff stats — min: -5.5154, max: 10.0000, mean: 8.6288, std: 2.4125\n",
            "\n",
            "Step 9092 — Test metrics:\n",
            "  precision@10: 0.014875059\n",
            "  recall@10: 0.014961028\n",
            "  ndcg@10: 0.015693310\n",
            "  map@10: 0.006123180\n",
            "Epoch 356, Step 20, LR: 0.000654, Current Loss: 0.4939, Avg Loss: 0.4957\n",
            "Diff stats — min: -5.0454, max: 10.0000, mean: 8.6940, std: 2.3430\n",
            "\n",
            "Epoch 356 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 357, Step 1, LR: 0.000654, Current Loss: 0.4999, Avg Loss: 0.4999\n",
            "Diff stats — min: -6.2528, max: 10.0000, mean: 8.7125, std: 2.2628\n",
            "\n",
            "Step 9122 — Test metrics:\n",
            "  precision@10: 0.014356436\n",
            "  recall@10: 0.014445024\n",
            "  ndcg@10: 0.015172119\n",
            "  map@10: 0.005893759\n",
            "Epoch 357, Step 20, LR: 0.000654, Current Loss: 0.5084, Avg Loss: 0.4971\n",
            "Diff stats — min: -5.6156, max: 10.0000, mean: 8.7440, std: 2.3069\n",
            "\n",
            "Epoch 357 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 358, Step 1, LR: 0.000654, Current Loss: 0.5090, Avg Loss: 0.5090\n",
            "Diff stats — min: -5.9224, max: 10.0000, mean: 8.6834, std: 2.3081\n",
            "\n",
            "Step 9152 — Test metrics:\n",
            "  precision@10: 0.014474305\n",
            "  recall@10: 0.014565513\n",
            "  ndcg@10: 0.015283227\n",
            "  map@10: 0.005961906\n",
            "Epoch 358, Step 20, LR: 0.000654, Current Loss: 0.4771, Avg Loss: 0.4947\n",
            "Diff stats — min: -5.4774, max: 10.0000, mean: 8.7181, std: 2.2861\n",
            "\n",
            "Epoch 358 completed, Train Loss: 0.000123\n",
            "\n",
            "Epoch 359, Step 1, LR: 0.000654, Current Loss: 0.4884, Avg Loss: 0.4884\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.7661, std: 2.2576\n",
            "\n",
            "Step 9182 — Test metrics:\n",
            "  precision@10: 0.014403583\n",
            "  recall@10: 0.014486279\n",
            "  ndcg@10: 0.015372760\n",
            "  map@10: 0.006075469\n",
            "Epoch 359, Step 20, LR: 0.000654, Current Loss: 0.4973, Avg Loss: 0.4943\n",
            "Diff stats — min: -6.3701, max: 10.0000, mean: 8.7416, std: 2.2519\n",
            "\n",
            "Epoch 359 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 360, Step 1, LR: 0.000654, Current Loss: 0.4991, Avg Loss: 0.4991\n",
            "Diff stats — min: -4.7658, max: 10.0000, mean: 8.6933, std: 2.3042\n",
            "\n",
            "Step 9212 — Test metrics:\n",
            "  precision@10: 0.015110797\n",
            "  recall@10: 0.015209863\n",
            "  ndcg@10: 0.015973217\n",
            "  map@10: 0.006324238\n",
            "Epoch 360, Step 20, LR: 0.000654, Current Loss: 0.4942, Avg Loss: 0.4937\n",
            "Diff stats — min: -6.0537, max: 10.0000, mean: 8.6525, std: 2.3753\n",
            "\n",
            "Epoch 360 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 361, Step 1, LR: 0.000641, Current Loss: 0.5092, Avg Loss: 0.5092\n",
            "Diff stats — min: -6.9350, max: 10.0000, mean: 8.7007, std: 2.3825\n",
            "\n",
            "Step 9242 — Test metrics:\n",
            "  precision@10: 0.014568600\n",
            "  recall@10: 0.014653914\n",
            "  ndcg@10: 0.015515834\n",
            "  map@10: 0.006185265\n",
            "Epoch 361, Step 20, LR: 0.000641, Current Loss: 0.5060, Avg Loss: 0.4963\n",
            "Diff stats — min: -9.1473, max: 10.0000, mean: 8.7197, std: 2.3542\n",
            "\n",
            "Epoch 361 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 362, Step 1, LR: 0.000641, Current Loss: 0.4998, Avg Loss: 0.4998\n",
            "Diff stats — min: -6.9197, max: 10.0000, mean: 8.6875, std: 2.3663\n",
            "\n",
            "Step 9272 — Test metrics:\n",
            "  precision@10: 0.014780764\n",
            "  recall@10: 0.014866078\n",
            "  ndcg@10: 0.015826977\n",
            "  map@10: 0.006216682\n",
            "Epoch 362, Step 20, LR: 0.000641, Current Loss: 0.4823, Avg Loss: 0.4923\n",
            "Diff stats — min: -3.2690, max: 10.0000, mean: 8.7259, std: 2.2773\n",
            "\n",
            "Epoch 362 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 363, Step 1, LR: 0.000641, Current Loss: 0.4956, Avg Loss: 0.4956\n",
            "Diff stats — min: -4.7866, max: 10.0000, mean: 8.6920, std: 2.3047\n",
            "\n",
            "Step 9302 — Test metrics:\n",
            "  precision@10: 0.014615747\n",
            "  recall@10: 0.014695823\n",
            "  ndcg@10: 0.015541082\n",
            "  map@10: 0.006148384\n",
            "Epoch 363, Step 20, LR: 0.000641, Current Loss: 0.5072, Avg Loss: 0.4943\n",
            "Diff stats — min: -4.6184, max: 10.0000, mean: 8.7025, std: 2.3379\n",
            "\n",
            "Epoch 363 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 364, Step 1, LR: 0.000641, Current Loss: 0.5157, Avg Loss: 0.5157\n",
            "Diff stats — min: -6.3384, max: 10.0000, mean: 8.7651, std: 2.3141\n",
            "\n",
            "Step 9332 — Test metrics:\n",
            "  precision@10: 0.015275813\n",
            "  recall@10: 0.015361128\n",
            "  ndcg@10: 0.016442171\n",
            "  map@10: 0.006501713\n",
            "Epoch 364, Step 20, LR: 0.000641, Current Loss: 0.4843, Avg Loss: 0.4977\n",
            "Diff stats — min: -6.0715, max: 10.0000, mean: 8.7333, std: 2.3028\n",
            "\n",
            "Epoch 364 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 365, Step 1, LR: 0.000641, Current Loss: 0.4967, Avg Loss: 0.4967\n",
            "Diff stats — min: -4.8464, max: 10.0000, mean: 8.6676, std: 2.3598\n",
            "\n",
            "Step 9362 — Test metrics:\n",
            "  precision@10: 0.014827911\n",
            "  recall@10: 0.014913881\n",
            "  ndcg@10: 0.015697895\n",
            "  map@10: 0.006112900\n",
            "Epoch 365, Step 20, LR: 0.000641, Current Loss: 0.4922, Avg Loss: 0.4953\n",
            "Diff stats — min: -6.7758, max: 10.0000, mean: 8.7209, std: 2.2925\n",
            "\n",
            "Epoch 365 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 366, Step 1, LR: 0.000628, Current Loss: 0.4930, Avg Loss: 0.4930\n",
            "Diff stats — min: -5.2866, max: 10.0000, mean: 8.7387, std: 2.2640\n",
            "\n",
            "Step 9392 — Test metrics:\n",
            "  precision@10: 0.014804338\n",
            "  recall@10: 0.014879175\n",
            "  ndcg@10: 0.015578415\n",
            "  map@10: 0.006047638\n",
            "Epoch 366, Step 20, LR: 0.000628, Current Loss: 0.5046, Avg Loss: 0.4972\n",
            "Diff stats — min: -3.2241, max: 10.0000, mean: 8.7295, std: 2.2626\n",
            "\n",
            "Epoch 366 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 367, Step 1, LR: 0.000628, Current Loss: 0.4979, Avg Loss: 0.4979\n",
            "Diff stats — min: -6.5316, max: 10.0000, mean: 8.7027, std: 2.3284\n",
            "\n",
            "Step 9422 — Test metrics:\n",
            "  precision@10: 0.014497878\n",
            "  recall@10: 0.014575990\n",
            "  ndcg@10: 0.015458407\n",
            "  map@10: 0.006036721\n",
            "Epoch 367, Step 20, LR: 0.000628, Current Loss: 0.5076, Avg Loss: 0.4966\n",
            "Diff stats — min: -9.3663, max: 10.0000, mean: 8.7052, std: 2.3277\n",
            "\n",
            "Epoch 367 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 368, Step 1, LR: 0.000628, Current Loss: 0.4927, Avg Loss: 0.4927\n",
            "Diff stats — min: -4.5493, max: 10.0000, mean: 8.6821, std: 2.3659\n",
            "\n",
            "Step 9452 — Test metrics:\n",
            "  precision@10: 0.014568600\n",
            "  recall@10: 0.014646711\n",
            "  ndcg@10: 0.015365094\n",
            "  map@10: 0.005937096\n",
            "Epoch 368, Step 20, LR: 0.000628, Current Loss: 0.4909, Avg Loss: 0.4954\n",
            "Diff stats — min: -7.0815, max: 10.0000, mean: 8.7128, std: 2.3062\n",
            "\n",
            "Epoch 368 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 369, Step 1, LR: 0.000628, Current Loss: 0.4919, Avg Loss: 0.4919\n",
            "Diff stats — min: -4.3373, max: 10.0000, mean: 8.7644, std: 2.2626\n",
            "\n",
            "Step 9482 — Test metrics:\n",
            "  precision@10: 0.014403583\n",
            "  recall@10: 0.014489553\n",
            "  ndcg@10: 0.015426538\n",
            "  map@10: 0.006105910\n",
            "Epoch 369, Step 20, LR: 0.000628, Current Loss: 0.4918, Avg Loss: 0.4939\n",
            "Diff stats — min: -4.6086, max: 10.0000, mean: 8.7601, std: 2.2223\n",
            "\n",
            "Epoch 369 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 370, Step 1, LR: 0.000628, Current Loss: 0.4849, Avg Loss: 0.4849\n",
            "Diff stats — min: -5.3168, max: 10.0000, mean: 8.7204, std: 2.2394\n",
            "\n",
            "Step 9512 — Test metrics:\n",
            "  precision@10: 0.014497878\n",
            "  recall@10: 0.014575990\n",
            "  ndcg@10: 0.015486577\n",
            "  map@10: 0.006133633\n",
            "Epoch 370, Step 20, LR: 0.000628, Current Loss: 0.4998, Avg Loss: 0.4957\n",
            "Diff stats — min: -4.3951, max: 10.0000, mean: 8.6784, std: 2.3350\n",
            "\n",
            "Epoch 370 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 371, Step 1, LR: 0.000616, Current Loss: 0.5067, Avg Loss: 0.5067\n",
            "Diff stats — min: -6.0323, max: 10.0000, mean: 8.7372, std: 2.2665\n",
            "\n",
            "Step 9542 — Test metrics:\n",
            "  precision@10: 0.014639321\n",
            "  recall@10: 0.014716778\n",
            "  ndcg@10: 0.015715124\n",
            "  map@10: 0.006277491\n",
            "Epoch 371, Step 20, LR: 0.000616, Current Loss: 0.4923, Avg Loss: 0.4940\n",
            "Diff stats — min: -5.2668, max: 10.0000, mean: 8.7464, std: 2.2148\n",
            "\n",
            "Epoch 371 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 372, Step 1, LR: 0.000616, Current Loss: 0.4910, Avg Loss: 0.4910\n",
            "Diff stats — min: -5.1210, max: 10.0000, mean: 8.6808, std: 2.3444\n",
            "\n",
            "Step 9572 — Test metrics:\n",
            "  precision@10: 0.014780764\n",
            "  recall@10: 0.014860840\n",
            "  ndcg@10: 0.015867827\n",
            "  map@10: 0.006351297\n",
            "Epoch 372, Step 20, LR: 0.000616, Current Loss: 0.4999, Avg Loss: 0.4954\n",
            "Diff stats — min: -4.2051, max: 10.0000, mean: 8.7033, std: 2.2987\n",
            "\n",
            "Epoch 372 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 373, Step 1, LR: 0.000616, Current Loss: 0.4897, Avg Loss: 0.4897\n",
            "Diff stats — min: -6.2616, max: 10.0000, mean: 8.7490, std: 2.2608\n",
            "\n",
            "Step 9602 — Test metrics:\n",
            "  precision@10: 0.014686469\n",
            "  recall@10: 0.014753448\n",
            "  ndcg@10: 0.015650234\n",
            "  map@10: 0.006167582\n",
            "Epoch 373, Step 20, LR: 0.000616, Current Loss: 0.4980, Avg Loss: 0.4944\n",
            "Diff stats — min: -6.0525, max: 10.0000, mean: 8.7124, std: 2.3402\n",
            "\n",
            "Epoch 373 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 374, Step 1, LR: 0.000616, Current Loss: 0.4759, Avg Loss: 0.4759\n",
            "Diff stats — min: -4.3546, max: 10.0000, mean: 8.6899, std: 2.3766\n",
            "\n",
            "Step 9632 — Test metrics:\n",
            "  precision@10: 0.014992928\n",
            "  recall@10: 0.015070385\n",
            "  ndcg@10: 0.016066692\n",
            "  map@10: 0.006379330\n",
            "Epoch 374, Step 20, LR: 0.000616, Current Loss: 0.4840, Avg Loss: 0.4940\n",
            "Diff stats — min: -8.3250, max: 10.0000, mean: 8.7236, std: 2.3367\n",
            "\n",
            "Epoch 374 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 375, Step 1, LR: 0.000616, Current Loss: 0.4771, Avg Loss: 0.4771\n",
            "Diff stats — min: -3.8108, max: 10.0000, mean: 8.7371, std: 2.2468\n",
            "\n",
            "Step 9662 — Test metrics:\n",
            "  precision@10: 0.014851485\n",
            "  recall@10: 0.014928942\n",
            "  ndcg@10: 0.015564403\n",
            "  map@10: 0.006070562\n",
            "Epoch 375, Step 20, LR: 0.000616, Current Loss: 0.4892, Avg Loss: 0.4944\n",
            "Diff stats — min: -6.0261, max: 10.0000, mean: 8.7877, std: 2.2399\n",
            "\n",
            "Epoch 375 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 376, Step 1, LR: 0.000603, Current Loss: 0.5002, Avg Loss: 0.5002\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.6871, std: 2.3698\n",
            "\n",
            "Step 9692 — Test metrics:\n",
            "  precision@10: 0.015181518\n",
            "  recall@10: 0.015264868\n",
            "  ndcg@10: 0.016059057\n",
            "  map@10: 0.006347604\n",
            "Epoch 376, Step 20, LR: 0.000603, Current Loss: 0.5004, Avg Loss: 0.4949\n",
            "Diff stats — min: -4.5792, max: 10.0000, mean: 8.7083, std: 2.2374\n",
            "\n",
            "Epoch 376 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 377, Step 1, LR: 0.000603, Current Loss: 0.5053, Avg Loss: 0.5053\n",
            "Diff stats — min: -3.4182, max: 10.0000, mean: 8.6845, std: 2.3695\n",
            "\n",
            "Step 9722 — Test metrics:\n",
            "  precision@10: 0.014804338\n",
            "  recall@10: 0.014879175\n",
            "  ndcg@10: 0.015765361\n",
            "  map@10: 0.006249564\n",
            "Epoch 377, Step 20, LR: 0.000603, Current Loss: 0.4939, Avg Loss: 0.4946\n",
            "Diff stats — min: -6.5965, max: 10.0000, mean: 8.7010, std: 2.3697\n",
            "\n",
            "Epoch 377 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 378, Step 1, LR: 0.000603, Current Loss: 0.4958, Avg Loss: 0.4958\n",
            "Diff stats — min: -5.2702, max: 10.0000, mean: 8.7290, std: 2.2331\n",
            "\n",
            "Step 9752 — Test metrics:\n",
            "  precision@10: 0.015134371\n",
            "  recall@10: 0.015217066\n",
            "  ndcg@10: 0.016192964\n",
            "  map@10: 0.006496498\n",
            "Epoch 378, Step 20, LR: 0.000603, Current Loss: 0.5057, Avg Loss: 0.4937\n",
            "Diff stats — min: -3.7792, max: 10.0000, mean: 8.7718, std: 2.2085\n",
            "\n",
            "Epoch 378 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 379, Step 1, LR: 0.000603, Current Loss: 0.4854, Avg Loss: 0.4854\n",
            "Diff stats — min: -7.6446, max: 10.0000, mean: 8.7960, std: 2.2454\n",
            "\n",
            "Step 9782 — Test metrics:\n",
            "  precision@10: 0.014969354\n",
            "  recall@10: 0.015049430\n",
            "  ndcg@10: 0.015979649\n",
            "  map@10: 0.006334485\n",
            "Epoch 379, Step 20, LR: 0.000603, Current Loss: 0.4942, Avg Loss: 0.4954\n",
            "Diff stats — min: -7.8667, max: 10.0000, mean: 8.7997, std: 2.2206\n",
            "\n",
            "Epoch 379 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 380, Step 1, LR: 0.000603, Current Loss: 0.5161, Avg Loss: 0.5161\n",
            "Diff stats — min: -7.9671, max: 10.0000, mean: 8.7475, std: 2.3682\n",
            "\n",
            "Step 9812 — Test metrics:\n",
            "  precision@10: 0.015228666\n",
            "  recall@10: 0.015311361\n",
            "  ndcg@10: 0.016219344\n",
            "  map@10: 0.006511524\n",
            "Epoch 380, Step 20, LR: 0.000603, Current Loss: 0.4858, Avg Loss: 0.4951\n",
            "Diff stats — min: -5.2687, max: 10.0000, mean: 8.7360, std: 2.3162\n",
            "\n",
            "Epoch 380 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 381, Step 1, LR: 0.000591, Current Loss: 0.5053, Avg Loss: 0.5053\n",
            "Diff stats — min: -5.7995, max: 10.0000, mean: 8.7554, std: 2.3158\n",
            "\n",
            "Step 9842 — Test metrics:\n",
            "  precision@10: 0.015558699\n",
            "  recall@10: 0.015652526\n",
            "  ndcg@10: 0.016443265\n",
            "  map@10: 0.006517583\n",
            "Epoch 381, Step 20, LR: 0.000591, Current Loss: 0.4990, Avg Loss: 0.4961\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.7634, std: 2.3120\n",
            "\n",
            "Epoch 381 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 382, Step 1, LR: 0.000591, Current Loss: 0.5041, Avg Loss: 0.5041\n",
            "Diff stats — min: -3.3458, max: 10.0000, mean: 8.7564, std: 2.2843\n",
            "\n",
            "Step 9872 — Test metrics:\n",
            "  precision@10: 0.015228666\n",
            "  recall@10: 0.015308742\n",
            "  ndcg@10: 0.015948611\n",
            "  map@10: 0.006262556\n",
            "Epoch 382, Step 20, LR: 0.000591, Current Loss: 0.4993, Avg Loss: 0.4937\n",
            "Diff stats — min: -7.7961, max: 10.0000, mean: 8.7507, std: 2.3245\n",
            "\n",
            "Epoch 382 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 383, Step 1, LR: 0.000591, Current Loss: 0.4854, Avg Loss: 0.4854\n",
            "Diff stats — min: -5.3152, max: 10.0000, mean: 8.8056, std: 2.1990\n",
            "\n",
            "Step 9902 — Test metrics:\n",
            "  precision@10: 0.015440830\n",
            "  recall@10: 0.015520906\n",
            "  ndcg@10: 0.016177389\n",
            "  map@10: 0.006384800\n",
            "Epoch 383, Step 20, LR: 0.000591, Current Loss: 0.4920, Avg Loss: 0.4961\n",
            "Diff stats — min: -6.9155, max: 10.0000, mean: 8.8091, std: 2.2468\n",
            "\n",
            "Epoch 383 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 384, Step 1, LR: 0.000591, Current Loss: 0.4886, Avg Loss: 0.4886\n",
            "Diff stats — min: -5.4598, max: 10.0000, mean: 8.8066, std: 2.2696\n",
            "\n",
            "Step 9932 — Test metrics:\n",
            "  precision@10: 0.014780764\n",
            "  recall@10: 0.014863459\n",
            "  ndcg@10: 0.015496507\n",
            "  map@10: 0.006041142\n",
            "Epoch 384, Step 20, LR: 0.000591, Current Loss: 0.4993, Avg Loss: 0.4964\n",
            "Diff stats — min: -6.5742, max: 10.0000, mean: 8.7989, std: 2.2038\n",
            "\n",
            "Epoch 384 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 385, Step 1, LR: 0.000591, Current Loss: 0.4964, Avg Loss: 0.4964\n",
            "Diff stats — min: -5.4306, max: 10.0000, mean: 8.7625, std: 2.2864\n",
            "\n",
            "Step 9962 — Test metrics:\n",
            "  precision@10: 0.014780764\n",
            "  recall@10: 0.014855601\n",
            "  ndcg@10: 0.015530412\n",
            "  map@10: 0.006011826\n",
            "Epoch 385, Step 20, LR: 0.000591, Current Loss: 0.4879, Avg Loss: 0.4934\n",
            "Diff stats — min: -4.6786, max: 10.0000, mean: 8.8350, std: 2.1755\n",
            "\n",
            "Epoch 385 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 386, Step 1, LR: 0.000580, Current Loss: 0.5083, Avg Loss: 0.5083\n",
            "Diff stats — min: -8.6067, max: 10.0000, mean: 8.7666, std: 2.2963\n",
            "\n",
            "Step 9992 — Test metrics:\n",
            "  precision@10: 0.014922207\n",
            "  recall@10: 0.015007521\n",
            "  ndcg@10: 0.015791050\n",
            "  map@10: 0.006230428\n",
            "Epoch 386, Step 20, LR: 0.000580, Current Loss: 0.4893, Avg Loss: 0.4923\n",
            "Diff stats — min: -6.6885, max: 10.0000, mean: 8.7232, std: 2.2764\n",
            "\n",
            "Epoch 386 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 387, Step 1, LR: 0.000580, Current Loss: 0.4946, Avg Loss: 0.4946\n",
            "Diff stats — min: -7.6762, max: 10.0000, mean: 8.7100, std: 2.2993\n",
            "\n",
            "Step 10022 — Test metrics:\n",
            "  precision@10: 0.014757190\n",
            "  recall@10: 0.014837266\n",
            "  ndcg@10: 0.015545678\n",
            "  map@10: 0.006125954\n",
            "Epoch 387, Step 20, LR: 0.000580, Current Loss: 0.4898, Avg Loss: 0.4928\n",
            "Diff stats — min: -4.3631, max: 10.0000, mean: 8.7767, std: 2.2773\n",
            "\n",
            "Epoch 387 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 388, Step 1, LR: 0.000580, Current Loss: 0.4941, Avg Loss: 0.4941\n",
            "Diff stats — min: -7.6025, max: 10.0000, mean: 8.7565, std: 2.3121\n",
            "\n",
            "Step 10052 — Test metrics:\n",
            "  precision@10: 0.014238567\n",
            "  recall@10: 0.014318643\n",
            "  ndcg@10: 0.015499246\n",
            "  map@10: 0.006112637\n",
            "Epoch 388, Step 20, LR: 0.000580, Current Loss: 0.4910, Avg Loss: 0.4957\n",
            "Diff stats — min: -6.8837, max: 10.0000, mean: 8.7391, std: 2.2996\n",
            "\n",
            "Epoch 388 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 389, Step 1, LR: 0.000580, Current Loss: 0.4724, Avg Loss: 0.4724\n",
            "Diff stats — min: -7.4930, max: 10.0000, mean: 8.8214, std: 2.1942\n",
            "\n",
            "Step 10082 — Test metrics:\n",
            "  precision@10: 0.014757190\n",
            "  recall@10: 0.014837266\n",
            "  ndcg@10: 0.015791142\n",
            "  map@10: 0.006277661\n",
            "Epoch 389, Step 20, LR: 0.000580, Current Loss: 0.4973, Avg Loss: 0.4930\n",
            "Diff stats — min: -3.7541, max: 10.0000, mean: 8.7619, std: 2.2288\n",
            "\n",
            "Epoch 389 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 390, Step 1, LR: 0.000580, Current Loss: 0.4962, Avg Loss: 0.4962\n",
            "Diff stats — min: -4.8747, max: 10.0000, mean: 8.7682, std: 2.2081\n",
            "\n",
            "Step 10112 — Test metrics:\n",
            "  precision@10: 0.015110797\n",
            "  recall@10: 0.015190873\n",
            "  ndcg@10: 0.016083049\n",
            "  map@10: 0.006374079\n",
            "Epoch 390, Step 20, LR: 0.000580, Current Loss: 0.4869, Avg Loss: 0.4953\n",
            "Diff stats — min: -6.3164, max: 10.0000, mean: 8.7984, std: 2.2581\n",
            "\n",
            "Epoch 390 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 391, Step 1, LR: 0.000568, Current Loss: 0.5020, Avg Loss: 0.5020\n",
            "Diff stats — min: -5.9735, max: 10.0000, mean: 8.7671, std: 2.2890\n",
            "\n",
            "Step 10142 — Test metrics:\n",
            "  precision@10: 0.015181518\n",
            "  recall@10: 0.015264213\n",
            "  ndcg@10: 0.016093207\n",
            "  map@10: 0.006418571\n",
            "Epoch 391, Step 20, LR: 0.000568, Current Loss: 0.4997, Avg Loss: 0.4942\n",
            "Diff stats — min: -7.9757, max: 10.0000, mean: 8.7603, std: 2.3361\n",
            "\n",
            "Epoch 391 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 392, Step 1, LR: 0.000568, Current Loss: 0.4899, Avg Loss: 0.4899\n",
            "Diff stats — min: -6.1097, max: 10.0000, mean: 8.7911, std: 2.2503\n",
            "\n",
            "Step 10172 — Test metrics:\n",
            "  precision@10: 0.014969354\n",
            "  recall@10: 0.015049430\n",
            "  ndcg@10: 0.016012870\n",
            "  map@10: 0.006335609\n",
            "Epoch 392, Step 20, LR: 0.000568, Current Loss: 0.4946, Avg Loss: 0.4934\n",
            "Diff stats — min: -6.1502, max: 10.0000, mean: 8.7837, std: 2.1947\n",
            "\n",
            "Epoch 392 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 393, Step 1, LR: 0.000568, Current Loss: 0.4994, Avg Loss: 0.4994\n",
            "Diff stats — min: -7.7860, max: 10.0000, mean: 8.7790, std: 2.2878\n",
            "\n",
            "Step 10202 — Test metrics:\n",
            "  precision@10: 0.014615747\n",
            "  recall@10: 0.014698443\n",
            "  ndcg@10: 0.015544465\n",
            "  map@10: 0.006189307\n",
            "Epoch 393, Step 20, LR: 0.000568, Current Loss: 0.4881, Avg Loss: 0.4939\n",
            "Diff stats — min: -6.7844, max: 10.0000, mean: 8.7696, std: 2.2320\n",
            "\n",
            "Epoch 393 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 394, Step 1, LR: 0.000568, Current Loss: 0.4938, Avg Loss: 0.4938\n",
            "Diff stats — min: -4.7753, max: 10.0000, mean: 8.7851, std: 2.2552\n",
            "\n",
            "Step 10232 — Test metrics:\n",
            "  precision@10: 0.015205092\n",
            "  recall@10: 0.015287787\n",
            "  ndcg@10: 0.016027178\n",
            "  map@10: 0.006415562\n",
            "Epoch 394, Step 20, LR: 0.000568, Current Loss: 0.4806, Avg Loss: 0.4964\n",
            "Diff stats — min: -5.2990, max: 10.0000, mean: 8.7141, std: 2.3295\n",
            "\n",
            "Epoch 394 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 395, Step 1, LR: 0.000568, Current Loss: 0.4910, Avg Loss: 0.4910\n",
            "Diff stats — min: -6.5462, max: 10.0000, mean: 8.7914, std: 2.2721\n",
            "\n",
            "Step 10262 — Test metrics:\n",
            "  precision@10: 0.015040075\n",
            "  recall@10: 0.015128009\n",
            "  ndcg@10: 0.015954984\n",
            "  map@10: 0.006349266\n",
            "Epoch 395, Step 20, LR: 0.000568, Current Loss: 0.4931, Avg Loss: 0.4961\n",
            "Diff stats — min: -8.9181, max: 10.0000, mean: 8.7285, std: 2.3155\n",
            "\n",
            "Epoch 395 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 396, Step 1, LR: 0.000557, Current Loss: 0.4926, Avg Loss: 0.4926\n",
            "Diff stats — min: -5.3539, max: 10.0000, mean: 8.7342, std: 2.3661\n",
            "\n",
            "Step 10292 — Test metrics:\n",
            "  precision@10: 0.015511551\n",
            "  recall@10: 0.015591627\n",
            "  ndcg@10: 0.016154849\n",
            "  map@10: 0.006421677\n",
            "Epoch 396, Step 20, LR: 0.000557, Current Loss: 0.5002, Avg Loss: 0.4922\n",
            "Diff stats — min: -6.4373, max: 10.0000, mean: 8.8171, std: 2.1976\n",
            "\n",
            "Epoch 396 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 397, Step 1, LR: 0.000557, Current Loss: 0.4972, Avg Loss: 0.4972\n",
            "Diff stats — min: -3.5546, max: 10.0000, mean: 8.7852, std: 2.2512\n",
            "\n",
            "Step 10322 — Test metrics:\n",
            "  precision@10: 0.014992928\n",
            "  recall@10: 0.015075623\n",
            "  ndcg@10: 0.015894839\n",
            "  map@10: 0.006312568\n",
            "Epoch 397, Step 20, LR: 0.000557, Current Loss: 0.5012, Avg Loss: 0.4934\n",
            "Diff stats — min: -5.7501, max: 10.0000, mean: 8.7399, std: 2.3269\n",
            "\n",
            "Epoch 397 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 398, Step 1, LR: 0.000557, Current Loss: 0.4877, Avg Loss: 0.4877\n",
            "Diff stats — min: -3.1305, max: 10.0000, mean: 8.8222, std: 2.2403\n",
            "\n",
            "Step 10352 — Test metrics:\n",
            "  precision@10: 0.015393682\n",
            "  recall@10: 0.015486855\n",
            "  ndcg@10: 0.016188266\n",
            "  map@10: 0.006347844\n",
            "Epoch 398, Step 20, LR: 0.000557, Current Loss: 0.4706, Avg Loss: 0.4948\n",
            "Diff stats — min: -4.9337, max: 10.0000, mean: 8.7484, std: 2.2589\n",
            "\n",
            "Epoch 398 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 399, Step 1, LR: 0.000557, Current Loss: 0.4946, Avg Loss: 0.4946\n",
            "Diff stats — min: -7.2089, max: 10.0000, mean: 8.7667, std: 2.2794\n",
            "\n",
            "Step 10382 — Test metrics:\n",
            "  precision@10: 0.014945780\n",
            "  recall@10: 0.015033714\n",
            "  ndcg@10: 0.015837983\n",
            "  map@10: 0.006195845\n",
            "Epoch 399, Step 20, LR: 0.000557, Current Loss: 0.4942, Avg Loss: 0.4933\n",
            "Diff stats — min: -4.6251, max: 10.0000, mean: 8.8259, std: 2.2337\n",
            "\n",
            "Epoch 399 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 400, Step 1, LR: 0.000557, Current Loss: 0.4764, Avg Loss: 0.4764\n",
            "Diff stats — min: -4.8507, max: 10.0000, mean: 8.8118, std: 2.1848\n",
            "\n",
            "Step 10412 — Test metrics:\n",
            "  precision@10: 0.015511551\n",
            "  recall@10: 0.015602104\n",
            "  ndcg@10: 0.016533759\n",
            "  map@10: 0.006656027\n",
            "Epoch 400, Step 20, LR: 0.000557, Current Loss: 0.4844, Avg Loss: 0.4909\n",
            "Diff stats — min: -3.8775, max: 10.0000, mean: 8.8265, std: 2.2144\n",
            "\n",
            "Epoch 400 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 401, Step 1, LR: 0.000545, Current Loss: 0.4816, Avg Loss: 0.4816\n",
            "Diff stats — min: -5.1946, max: 10.0000, mean: 8.8106, std: 2.2442\n",
            "\n",
            "Step 10442 — Test metrics:\n",
            "  precision@10: 0.015157944\n",
            "  recall@10: 0.015249152\n",
            "  ndcg@10: 0.016069298\n",
            "  map@10: 0.006351840\n",
            "Epoch 401, Step 20, LR: 0.000545, Current Loss: 0.4964, Avg Loss: 0.4935\n",
            "Diff stats — min: -4.7177, max: 10.0000, mean: 8.7808, std: 2.2956\n",
            "\n",
            "Epoch 401 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 402, Step 1, LR: 0.000545, Current Loss: 0.5022, Avg Loss: 0.5022\n",
            "Diff stats — min: -4.8030, max: 10.0000, mean: 8.7683, std: 2.2685\n",
            "\n",
            "Step 10472 — Test metrics:\n",
            "  precision@10: 0.015063649\n",
            "  recall@10: 0.015157477\n",
            "  ndcg@10: 0.016059904\n",
            "  map@10: 0.006394645\n",
            "Epoch 402, Step 20, LR: 0.000545, Current Loss: 0.4997, Avg Loss: 0.4935\n",
            "Diff stats — min: -7.4286, max: 10.0000, mean: 8.7937, std: 2.2949\n",
            "\n",
            "Epoch 402 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 403, Step 1, LR: 0.000545, Current Loss: 0.4965, Avg Loss: 0.4965\n",
            "Diff stats — min: -4.4245, max: 10.0000, mean: 8.7681, std: 2.2658\n",
            "\n",
            "Step 10502 — Test metrics:\n",
            "  precision@10: 0.015417256\n",
            "  recall@10: 0.015499951\n",
            "  ndcg@10: 0.016200796\n",
            "  map@10: 0.006377386\n",
            "Epoch 403, Step 20, LR: 0.000545, Current Loss: 0.4936, Avg Loss: 0.4944\n",
            "Diff stats — min: -5.4435, max: 10.0000, mean: 8.7826, std: 2.2384\n",
            "\n",
            "Epoch 403 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 404, Step 1, LR: 0.000545, Current Loss: 0.4960, Avg Loss: 0.4960\n",
            "Diff stats — min: -4.4198, max: 10.0000, mean: 8.8170, std: 2.2236\n",
            "\n",
            "Step 10532 — Test metrics:\n",
            "  precision@10: 0.015228666\n",
            "  recall@10: 0.015312016\n",
            "  ndcg@10: 0.016086796\n",
            "  map@10: 0.006355957\n",
            "Epoch 404, Step 20, LR: 0.000545, Current Loss: 0.4889, Avg Loss: 0.4943\n",
            "Diff stats — min: -7.5115, max: 10.0000, mean: 8.7634, std: 2.2789\n",
            "\n",
            "Epoch 404 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 405, Step 1, LR: 0.000545, Current Loss: 0.4937, Avg Loss: 0.4937\n",
            "Diff stats — min: -5.8856, max: 10.0000, mean: 8.8279, std: 2.1946\n",
            "\n",
            "Step 10562 — Test metrics:\n",
            "  precision@10: 0.015134371\n",
            "  recall@10: 0.015222959\n",
            "  ndcg@10: 0.016083517\n",
            "  map@10: 0.006380200\n",
            "Epoch 405, Step 20, LR: 0.000545, Current Loss: 0.4826, Avg Loss: 0.4913\n",
            "Diff stats — min: -4.9814, max: 10.0000, mean: 8.8405, std: 2.2333\n",
            "\n",
            "Epoch 405 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 406, Step 1, LR: 0.000535, Current Loss: 0.4784, Avg Loss: 0.4784\n",
            "Diff stats — min: -5.1775, max: 10.0000, mean: 8.8419, std: 2.1345\n",
            "\n",
            "Step 10592 — Test metrics:\n",
            "  precision@10: 0.015393682\n",
            "  recall@10: 0.015479652\n",
            "  ndcg@10: 0.016219988\n",
            "  map@10: 0.006341340\n",
            "Epoch 406, Step 20, LR: 0.000535, Current Loss: 0.4945, Avg Loss: 0.4917\n",
            "Diff stats — min: -4.9569, max: 10.0000, mean: 8.8328, std: 2.2285\n",
            "\n",
            "Epoch 406 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 407, Step 1, LR: 0.000535, Current Loss: 0.4961, Avg Loss: 0.4961\n",
            "Diff stats — min: -6.8758, max: 10.0000, mean: 8.8080, std: 2.2874\n",
            "\n",
            "Step 10622 — Test metrics:\n",
            "  precision@10: 0.015252240\n",
            "  recall@10: 0.015340828\n",
            "  ndcg@10: 0.016058994\n",
            "  map@10: 0.006284477\n",
            "Epoch 407, Step 20, LR: 0.000535, Current Loss: 0.5057, Avg Loss: 0.4926\n",
            "Diff stats — min: -4.7054, max: 10.0000, mean: 8.7836, std: 2.2512\n",
            "\n",
            "Epoch 407 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 408, Step 1, LR: 0.000535, Current Loss: 0.4964, Avg Loss: 0.4964\n",
            "Diff stats — min: -4.6373, max: 10.0000, mean: 8.7914, std: 2.2519\n",
            "\n",
            "Step 10652 — Test metrics:\n",
            "  precision@10: 0.015157944\n",
            "  recall@10: 0.015240640\n",
            "  ndcg@10: 0.015990112\n",
            "  map@10: 0.006359171\n",
            "Epoch 408, Step 20, LR: 0.000535, Current Loss: 0.4969, Avg Loss: 0.4912\n",
            "Diff stats — min: -6.1473, max: 10.0000, mean: 8.8042, std: 2.2698\n",
            "\n",
            "Epoch 408 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 409, Step 1, LR: 0.000535, Current Loss: 0.4829, Avg Loss: 0.4829\n",
            "Diff stats — min: -6.8254, max: 10.0000, mean: 8.7801, std: 2.2709\n",
            "\n",
            "Step 10682 — Test metrics:\n",
            "  precision@10: 0.014922207\n",
            "  recall@10: 0.015007521\n",
            "  ndcg@10: 0.015856240\n",
            "  map@10: 0.006302039\n",
            "Epoch 409, Step 20, LR: 0.000535, Current Loss: 0.4907, Avg Loss: 0.4937\n",
            "Diff stats — min: -5.8609, max: 10.0000, mean: 8.8271, std: 2.2002\n",
            "\n",
            "Epoch 409 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 410, Step 1, LR: 0.000535, Current Loss: 0.4882, Avg Loss: 0.4882\n",
            "Diff stats — min: -8.7665, max: 10.0000, mean: 8.7542, std: 2.2680\n",
            "\n",
            "Step 10712 — Test metrics:\n",
            "  precision@10: 0.014851485\n",
            "  recall@10: 0.014940074\n",
            "  ndcg@10: 0.015828443\n",
            "  map@10: 0.006208693\n",
            "Epoch 410, Step 20, LR: 0.000535, Current Loss: 0.4859, Avg Loss: 0.4942\n",
            "Diff stats — min: -5.4765, max: 10.0000, mean: 8.8729, std: 2.1757\n",
            "\n",
            "Epoch 410 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 411, Step 1, LR: 0.000524, Current Loss: 0.5147, Avg Loss: 0.5147\n",
            "Diff stats — min: -7.5942, max: 10.0000, mean: 8.7853, std: 2.2828\n",
            "\n",
            "Step 10742 — Test metrics:\n",
            "  precision@10: 0.015582273\n",
            "  recall@10: 0.015670861\n",
            "  ndcg@10: 0.016487278\n",
            "  map@10: 0.006503134\n",
            "Epoch 411, Step 20, LR: 0.000524, Current Loss: 0.4758, Avg Loss: 0.4938\n",
            "Diff stats — min: -4.0432, max: 10.0000, mean: 8.7836, std: 2.2631\n",
            "\n",
            "Epoch 411 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 412, Step 1, LR: 0.000524, Current Loss: 0.4875, Avg Loss: 0.4875\n",
            "Diff stats — min: -8.3707, max: 10.0000, mean: 8.8338, std: 2.2062\n",
            "\n",
            "Step 10772 — Test metrics:\n",
            "  precision@10: 0.015087223\n",
            "  recall@10: 0.015170573\n",
            "  ndcg@10: 0.016034814\n",
            "  map@10: 0.006429028\n",
            "Epoch 412, Step 20, LR: 0.000524, Current Loss: 0.4945, Avg Loss: 0.4926\n",
            "Diff stats — min: -7.0823, max: 10.0000, mean: 8.7733, std: 2.2936\n",
            "\n",
            "Epoch 412 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 413, Step 1, LR: 0.000524, Current Loss: 0.4934, Avg Loss: 0.4934\n",
            "Diff stats — min: -6.8685, max: 10.0000, mean: 8.8346, std: 2.1824\n",
            "\n",
            "Step 10802 — Test metrics:\n",
            "  precision@10: 0.015275813\n",
            "  recall@10: 0.015364402\n",
            "  ndcg@10: 0.015997514\n",
            "  map@10: 0.006320262\n",
            "Epoch 413, Step 20, LR: 0.000524, Current Loss: 0.5023, Avg Loss: 0.4924\n",
            "Diff stats — min: -5.8456, max: 10.0000, mean: 8.8455, std: 2.2081\n",
            "\n",
            "Epoch 413 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 414, Step 1, LR: 0.000524, Current Loss: 0.4823, Avg Loss: 0.4823\n",
            "Diff stats — min: -4.8672, max: 10.0000, mean: 8.7775, std: 2.2882\n",
            "\n",
            "Step 10832 — Test metrics:\n",
            "  precision@10: 0.015016502\n",
            "  recall@10: 0.015110329\n",
            "  ndcg@10: 0.015858352\n",
            "  map@10: 0.006348589\n",
            "Epoch 414, Step 20, LR: 0.000524, Current Loss: 0.5091, Avg Loss: 0.4956\n",
            "Diff stats — min: -4.1763, max: 10.0000, mean: 8.8312, std: 2.2280\n",
            "\n",
            "Epoch 414 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 415, Step 1, LR: 0.000524, Current Loss: 0.4899, Avg Loss: 0.4899\n",
            "Diff stats — min: -6.7026, max: 10.0000, mean: 8.8476, std: 2.1845\n",
            "\n",
            "Step 10862 — Test metrics:\n",
            "  precision@10: 0.014922207\n",
            "  recall@10: 0.015010795\n",
            "  ndcg@10: 0.015828693\n",
            "  map@10: 0.006328526\n",
            "Epoch 415, Step 20, LR: 0.000524, Current Loss: 0.4963, Avg Loss: 0.4911\n",
            "Diff stats — min: -4.7014, max: 10.0000, mean: 8.8076, std: 2.2698\n",
            "\n",
            "Epoch 415 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 416, Step 1, LR: 0.000513, Current Loss: 0.5001, Avg Loss: 0.5001\n",
            "Diff stats — min: -5.9469, max: 10.0000, mean: 8.8960, std: 2.1388\n",
            "\n",
            "Step 10892 — Test metrics:\n",
            "  precision@10: 0.015487977\n",
            "  recall@10: 0.015579185\n",
            "  ndcg@10: 0.016225135\n",
            "  map@10: 0.006470768\n",
            "Epoch 416, Step 20, LR: 0.000513, Current Loss: 0.4915, Avg Loss: 0.4936\n",
            "Diff stats — min: -4.7141, max: 10.0000, mean: 8.8474, std: 2.1519\n",
            "\n",
            "Epoch 416 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 417, Step 1, LR: 0.000513, Current Loss: 0.4916, Avg Loss: 0.4916\n",
            "Diff stats — min: -6.4499, max: 10.0000, mean: 8.8559, std: 2.2307\n",
            "\n",
            "Step 10922 — Test metrics:\n",
            "  precision@10: 0.015205092\n",
            "  recall@10: 0.015293681\n",
            "  ndcg@10: 0.015946773\n",
            "  map@10: 0.006335612\n",
            "Epoch 417, Step 20, LR: 0.000513, Current Loss: 0.4864, Avg Loss: 0.4903\n",
            "Diff stats — min: -4.2329, max: 10.0000, mean: 8.8579, std: 2.1747\n",
            "\n",
            "Epoch 417 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 418, Step 1, LR: 0.000513, Current Loss: 0.4983, Avg Loss: 0.4983\n",
            "Diff stats — min: -8.1583, max: 10.0000, mean: 8.8024, std: 2.2642\n",
            "\n",
            "Step 10952 — Test metrics:\n",
            "  precision@10: 0.015252240\n",
            "  recall@10: 0.015340828\n",
            "  ndcg@10: 0.016215047\n",
            "  map@10: 0.006461666\n",
            "Epoch 418, Step 20, LR: 0.000513, Current Loss: 0.4824, Avg Loss: 0.4942\n",
            "Diff stats — min: -2.8340, max: 10.0000, mean: 8.8151, std: 2.1573\n",
            "\n",
            "Epoch 418 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 419, Step 1, LR: 0.000513, Current Loss: 0.4910, Avg Loss: 0.4910\n",
            "Diff stats — min: -7.3306, max: 10.0000, mean: 8.8480, std: 2.2301\n",
            "\n",
            "Step 10982 — Test metrics:\n",
            "  precision@10: 0.015040075\n",
            "  recall@10: 0.015120806\n",
            "  ndcg@10: 0.015900797\n",
            "  map@10: 0.006203334\n",
            "Epoch 419, Step 20, LR: 0.000513, Current Loss: 0.4991, Avg Loss: 0.4934\n",
            "Diff stats — min: -6.7641, max: 10.0000, mean: 8.8410, std: 2.1810\n",
            "\n",
            "Epoch 419 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 420, Step 1, LR: 0.000513, Current Loss: 0.4880, Avg Loss: 0.4880\n",
            "Diff stats — min: -4.4254, max: 10.0000, mean: 8.8535, std: 2.1948\n",
            "\n",
            "Step 11012 — Test metrics:\n",
            "  precision@10: 0.015205092\n",
            "  recall@10: 0.015287787\n",
            "  ndcg@10: 0.016080293\n",
            "  map@10: 0.006358730\n",
            "Epoch 420, Step 20, LR: 0.000513, Current Loss: 0.4847, Avg Loss: 0.4929\n",
            "Diff stats — min: -4.9592, max: 10.0000, mean: 8.8526, std: 2.1660\n",
            "\n",
            "Epoch 420 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 421, Step 1, LR: 0.000503, Current Loss: 0.4809, Avg Loss: 0.4809\n",
            "Diff stats — min: -5.0391, max: 10.0000, mean: 8.8460, std: 2.1587\n",
            "\n",
            "Step 11042 — Test metrics:\n",
            "  precision@10: 0.015205092\n",
            "  recall@10: 0.015282549\n",
            "  ndcg@10: 0.016079564\n",
            "  map@10: 0.006283206\n",
            "Epoch 421, Step 20, LR: 0.000503, Current Loss: 0.5020, Avg Loss: 0.4909\n",
            "Diff stats — min: -4.9920, max: 10.0000, mean: 8.8738, std: 2.1700\n",
            "\n",
            "Epoch 421 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 422, Step 1, LR: 0.000503, Current Loss: 0.4974, Avg Loss: 0.4974\n",
            "Diff stats — min: -8.4910, max: 10.0000, mean: 8.8249, std: 2.2049\n",
            "\n",
            "Step 11072 — Test metrics:\n",
            "  precision@10: 0.015228666\n",
            "  recall@10: 0.015311361\n",
            "  ndcg@10: 0.016256528\n",
            "  map@10: 0.006431029\n",
            "Epoch 422, Step 20, LR: 0.000503, Current Loss: 0.4862, Avg Loss: 0.4942\n",
            "Diff stats — min: -5.7873, max: 10.0000, mean: 8.8267, std: 2.2406\n",
            "\n",
            "Epoch 422 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 423, Step 1, LR: 0.000503, Current Loss: 0.4966, Avg Loss: 0.4966\n",
            "Diff stats — min: -8.7502, max: 10.0000, mean: 8.8571, std: 2.2149\n",
            "\n",
            "Step 11102 — Test metrics:\n",
            "  precision@10: 0.015535125\n",
            "  recall@10: 0.015626333\n",
            "  ndcg@10: 0.016390549\n",
            "  map@10: 0.006438542\n",
            "Epoch 423, Step 20, LR: 0.000503, Current Loss: 0.4874, Avg Loss: 0.4947\n",
            "Diff stats — min: -9.0527, max: 10.0000, mean: 8.8122, std: 2.2636\n",
            "\n",
            "Epoch 423 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 424, Step 1, LR: 0.000503, Current Loss: 0.5079, Avg Loss: 0.5079\n",
            "Diff stats — min: -4.4505, max: 10.0000, mean: 8.8413, std: 2.1502\n",
            "\n",
            "Step 11132 — Test metrics:\n",
            "  precision@10: 0.014851485\n",
            "  recall@10: 0.014928942\n",
            "  ndcg@10: 0.015744484\n",
            "  map@10: 0.006172581\n",
            "Epoch 424, Step 20, LR: 0.000503, Current Loss: 0.4999, Avg Loss: 0.4931\n",
            "Diff stats — min: -5.1172, max: 10.0000, mean: 8.7792, std: 2.3122\n",
            "\n",
            "Epoch 424 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 425, Step 1, LR: 0.000503, Current Loss: 0.5048, Avg Loss: 0.5048\n",
            "Diff stats — min: -6.1617, max: 10.0000, mean: 8.8924, std: 2.1294\n",
            "\n",
            "Step 11162 — Test metrics:\n",
            "  precision@10: 0.015063649\n",
            "  recall@10: 0.015141106\n",
            "  ndcg@10: 0.015912352\n",
            "  map@10: 0.006238294\n",
            "Epoch 425, Step 20, LR: 0.000503, Current Loss: 0.4801, Avg Loss: 0.4925\n",
            "Diff stats — min: -8.2158, max: 10.0000, mean: 8.8274, std: 2.2340\n",
            "\n",
            "Epoch 425 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 426, Step 1, LR: 0.000493, Current Loss: 0.4893, Avg Loss: 0.4893\n",
            "Diff stats — min: -3.3959, max: 10.0000, mean: 8.8573, std: 2.1889\n",
            "\n",
            "Step 11192 — Test metrics:\n",
            "  precision@10: 0.015393682\n",
            "  recall@10: 0.015482271\n",
            "  ndcg@10: 0.016401471\n",
            "  map@10: 0.006526326\n",
            "Epoch 426, Step 20, LR: 0.000493, Current Loss: 0.4752, Avg Loss: 0.4896\n",
            "Diff stats — min: -5.3594, max: 10.0000, mean: 8.8970, std: 2.1634\n",
            "\n",
            "Epoch 426 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 427, Step 1, LR: 0.000493, Current Loss: 0.5006, Avg Loss: 0.5006\n",
            "Diff stats — min: -6.1566, max: 10.0000, mean: 8.8405, std: 2.1639\n",
            "\n",
            "Step 11222 — Test metrics:\n",
            "  precision@10: 0.015370108\n",
            "  recall@10: 0.015456078\n",
            "  ndcg@10: 0.016493453\n",
            "  map@10: 0.006616031\n",
            "Epoch 427, Step 20, LR: 0.000493, Current Loss: 0.4826, Avg Loss: 0.4920\n",
            "Diff stats — min: -5.7842, max: 10.0000, mean: 8.8208, std: 2.2626\n",
            "\n",
            "Epoch 427 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 428, Step 1, LR: 0.000493, Current Loss: 0.4831, Avg Loss: 0.4831\n",
            "Diff stats — min: -5.2473, max: 10.0000, mean: 8.8410, std: 2.2310\n",
            "\n",
            "Step 11252 — Test metrics:\n",
            "  precision@10: 0.015511551\n",
            "  recall@10: 0.015600140\n",
            "  ndcg@10: 0.016654204\n",
            "  map@10: 0.006703960\n",
            "Epoch 428, Step 20, LR: 0.000493, Current Loss: 0.4734, Avg Loss: 0.4906\n",
            "Diff stats — min: -5.6058, max: 10.0000, mean: 8.8150, std: 2.2286\n",
            "\n",
            "Epoch 428 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 429, Step 1, LR: 0.000493, Current Loss: 0.4990, Avg Loss: 0.4990\n",
            "Diff stats — min: -5.6720, max: 10.0000, mean: 8.8662, std: 2.1822\n",
            "\n",
            "Step 11282 — Test metrics:\n",
            "  precision@10: 0.016030174\n",
            "  recall@10: 0.016129240\n",
            "  ndcg@10: 0.017067875\n",
            "  map@10: 0.006832364\n",
            "Epoch 429, Step 20, LR: 0.000493, Current Loss: 0.4895, Avg Loss: 0.4949\n",
            "Diff stats — min: -6.5397, max: 10.0000, mean: 8.8515, std: 2.1860\n",
            "\n",
            "Epoch 429 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 430, Step 1, LR: 0.000493, Current Loss: 0.4813, Avg Loss: 0.4813\n",
            "Diff stats — min: -5.9823, max: 10.0000, mean: 8.8626, std: 2.1846\n",
            "\n",
            "Step 11312 — Test metrics:\n",
            "  precision@10: 0.015393682\n",
            "  recall@10: 0.015482271\n",
            "  ndcg@10: 0.016489059\n",
            "  map@10: 0.006546334\n",
            "Epoch 430, Step 20, LR: 0.000493, Current Loss: 0.4989, Avg Loss: 0.4905\n",
            "Diff stats — min: -4.4714, max: 10.0000, mean: 8.8364, std: 2.1789\n",
            "\n",
            "Epoch 430 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 431, Step 1, LR: 0.000483, Current Loss: 0.5005, Avg Loss: 0.5005\n",
            "Diff stats — min: -6.2484, max: 10.0000, mean: 8.8405, std: 2.2269\n",
            "\n",
            "Step 11342 — Test metrics:\n",
            "  precision@10: 0.015723715\n",
            "  recall@10: 0.015817543\n",
            "  ndcg@10: 0.016514449\n",
            "  map@10: 0.006491880\n",
            "Epoch 431, Step 20, LR: 0.000483, Current Loss: 0.4922, Avg Loss: 0.4946\n",
            "Diff stats — min: -5.6192, max: 10.0000, mean: 8.8833, std: 2.1677\n",
            "\n",
            "Epoch 431 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 432, Step 1, LR: 0.000483, Current Loss: 0.5036, Avg Loss: 0.5036\n",
            "Diff stats — min: -2.0018, max: 10.0000, mean: 8.8492, std: 2.1689\n",
            "\n",
            "Step 11372 — Test metrics:\n",
            "  precision@10: 0.015912306\n",
            "  recall@10: 0.016006133\n",
            "  ndcg@10: 0.016818774\n",
            "  map@10: 0.006726520\n",
            "Epoch 432, Step 20, LR: 0.000483, Current Loss: 0.4782, Avg Loss: 0.4918\n",
            "Diff stats — min: -5.4218, max: 10.0000, mean: 8.8222, std: 2.2119\n",
            "\n",
            "Epoch 432 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 433, Step 1, LR: 0.000483, Current Loss: 0.4843, Avg Loss: 0.4843\n",
            "Diff stats — min: -8.3003, max: 10.0000, mean: 8.8740, std: 2.2027\n",
            "\n",
            "Step 11402 — Test metrics:\n",
            "  precision@10: 0.015841584\n",
            "  recall@10: 0.015940650\n",
            "  ndcg@10: 0.016799126\n",
            "  map@10: 0.006707586\n",
            "Epoch 433, Step 20, LR: 0.000483, Current Loss: 0.4854, Avg Loss: 0.4921\n",
            "Diff stats — min: -5.4917, max: 10.0000, mean: 8.8251, std: 2.2579\n",
            "\n",
            "Epoch 433 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 434, Step 1, LR: 0.000483, Current Loss: 0.4964, Avg Loss: 0.4964\n",
            "Diff stats — min: -5.4555, max: 10.0000, mean: 8.8011, std: 2.2883\n",
            "\n",
            "Step 11432 — Test metrics:\n",
            "  precision@10: 0.016242339\n",
            "  recall@10: 0.016338785\n",
            "  ndcg@10: 0.017100271\n",
            "  map@10: 0.006930607\n",
            "Epoch 434, Step 20, LR: 0.000483, Current Loss: 0.5046, Avg Loss: 0.4932\n",
            "Diff stats — min: -6.3113, max: 10.0000, mean: 8.8722, std: 2.1916\n",
            "\n",
            "Epoch 434 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 435, Step 1, LR: 0.000483, Current Loss: 0.5060, Avg Loss: 0.5060\n",
            "Diff stats — min: -5.2658, max: 10.0000, mean: 8.8424, std: 2.2355\n",
            "\n",
            "Step 11462 — Test metrics:\n",
            "  precision@10: 0.016313060\n",
            "  recall@10: 0.016412126\n",
            "  ndcg@10: 0.017188287\n",
            "  map@10: 0.006925617\n",
            "Epoch 435, Step 20, LR: 0.000483, Current Loss: 0.4968, Avg Loss: 0.4931\n",
            "Diff stats — min: -6.8353, max: 10.0000, mean: 8.8568, std: 2.1815\n",
            "\n",
            "Epoch 435 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 436, Step 1, LR: 0.000474, Current Loss: 0.5061, Avg Loss: 0.5061\n",
            "Diff stats — min: -3.6948, max: 10.0000, mean: 8.8702, std: 2.1745\n",
            "\n",
            "Step 11492 — Test metrics:\n",
            "  precision@10: 0.016383781\n",
            "  recall@10: 0.016480228\n",
            "  ndcg@10: 0.017649866\n",
            "  map@10: 0.007199891\n",
            "Epoch 436, Step 20, LR: 0.000474, Current Loss: 0.4937, Avg Loss: 0.4936\n",
            "Diff stats — min: -4.9441, max: 10.0000, mean: 8.8043, std: 2.2443\n",
            "\n",
            "Epoch 436 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 437, Step 1, LR: 0.000474, Current Loss: 0.4826, Avg Loss: 0.4826\n",
            "Diff stats — min: -4.8282, max: 10.0000, mean: 8.8703, std: 2.1650\n",
            "\n",
            "Step 11522 — Test metrics:\n",
            "  precision@10: 0.016124470\n",
            "  recall@10: 0.016218297\n",
            "  ndcg@10: 0.017203633\n",
            "  map@10: 0.006969944\n",
            "Epoch 437, Step 20, LR: 0.000474, Current Loss: 0.5125, Avg Loss: 0.4911\n",
            "Diff stats — min: -5.4786, max: 10.0000, mean: 8.8425, std: 2.2148\n",
            "\n",
            "Epoch 437 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 438, Step 1, LR: 0.000474, Current Loss: 0.4841, Avg Loss: 0.4841\n",
            "Diff stats — min: -5.3494, max: 10.0000, mean: 8.8852, std: 2.2028\n",
            "\n",
            "Step 11552 — Test metrics:\n",
            "  precision@10: 0.016100896\n",
            "  recall@10: 0.016186210\n",
            "  ndcg@10: 0.017253118\n",
            "  map@10: 0.007023981\n",
            "Epoch 438, Step 20, LR: 0.000474, Current Loss: 0.4934, Avg Loss: 0.4896\n",
            "Diff stats — min: -9.2109, max: 10.0000, mean: 8.8018, std: 2.3167\n",
            "\n",
            "Epoch 438 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 439, Step 1, LR: 0.000474, Current Loss: 0.4936, Avg Loss: 0.4936\n",
            "Diff stats — min: -9.0313, max: 10.0000, mean: 8.9095, std: 2.1763\n",
            "\n",
            "Step 11582 — Test metrics:\n",
            "  precision@10: 0.016195191\n",
            "  recall@10: 0.016286399\n",
            "  ndcg@10: 0.017345331\n",
            "  map@10: 0.007074896\n",
            "Epoch 439, Step 20, LR: 0.000474, Current Loss: 0.5003, Avg Loss: 0.4928\n",
            "Diff stats — min: -6.8911, max: 10.0000, mean: 8.8922, std: 2.1765\n",
            "\n",
            "Epoch 439 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 440, Step 1, LR: 0.000474, Current Loss: 0.5031, Avg Loss: 0.5031\n",
            "Diff stats — min: -5.3522, max: 10.0000, mean: 8.9178, std: 2.1023\n",
            "\n",
            "Step 11612 — Test metrics:\n",
            "  precision@10: 0.016265912\n",
            "  recall@10: 0.016359740\n",
            "  ndcg@10: 0.017205916\n",
            "  map@10: 0.007025832\n",
            "Epoch 440, Step 20, LR: 0.000474, Current Loss: 0.4762, Avg Loss: 0.4910\n",
            "Diff stats — min: -4.2983, max: 10.0000, mean: 8.8695, std: 2.1747\n",
            "\n",
            "Epoch 440 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 441, Step 1, LR: 0.000464, Current Loss: 0.4962, Avg Loss: 0.4962\n",
            "Diff stats — min: -6.5347, max: 10.0000, mean: 8.8555, std: 2.2214\n",
            "\n",
            "Step 11642 — Test metrics:\n",
            "  precision@10: 0.015582273\n",
            "  recall@10: 0.015681339\n",
            "  ndcg@10: 0.016717173\n",
            "  map@10: 0.006782075\n",
            "Epoch 441, Step 20, LR: 0.000464, Current Loss: 0.4947, Avg Loss: 0.4914\n",
            "Diff stats — min: -5.1935, max: 10.0000, mean: 8.8746, std: 2.1806\n",
            "\n",
            "Epoch 441 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 442, Step 1, LR: 0.000464, Current Loss: 0.4734, Avg Loss: 0.4734\n",
            "Diff stats — min: -5.9643, max: 10.0000, mean: 8.8541, std: 2.1717\n",
            "\n",
            "Step 11672 — Test metrics:\n",
            "  precision@10: 0.015700141\n",
            "  recall@10: 0.015799207\n",
            "  ndcg@10: 0.016746303\n",
            "  map@10: 0.006776359\n",
            "Epoch 442, Step 20, LR: 0.000464, Current Loss: 0.4907, Avg Loss: 0.4928\n",
            "Diff stats — min: -6.2189, max: 10.0000, mean: 8.8678, std: 2.2230\n",
            "\n",
            "Epoch 442 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 443, Step 1, LR: 0.000464, Current Loss: 0.5023, Avg Loss: 0.5023\n",
            "Diff stats — min: -4.9336, max: 10.0000, mean: 8.9067, std: 2.1587\n",
            "\n",
            "Step 11702 — Test metrics:\n",
            "  precision@10: 0.015818010\n",
            "  recall@10: 0.015914457\n",
            "  ndcg@10: 0.016910611\n",
            "  map@10: 0.006794711\n",
            "Epoch 443, Step 20, LR: 0.000464, Current Loss: 0.4932, Avg Loss: 0.4915\n",
            "Diff stats — min: -5.7037, max: 10.0000, mean: 8.8178, std: 2.2871\n",
            "\n",
            "Epoch 443 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 444, Step 1, LR: 0.000464, Current Loss: 0.4863, Avg Loss: 0.4863\n",
            "Diff stats — min: -6.3992, max: 10.0000, mean: 8.8812, std: 2.1618\n",
            "\n",
            "Step 11732 — Test metrics:\n",
            "  precision@10: 0.015770863\n",
            "  recall@10: 0.015856832\n",
            "  ndcg@10: 0.016837865\n",
            "  map@10: 0.006755322\n",
            "Epoch 444, Step 20, LR: 0.000464, Current Loss: 0.5024, Avg Loss: 0.4915\n",
            "Diff stats — min: -6.6568, max: 10.0000, mean: 8.9027, std: 2.2135\n",
            "\n",
            "Epoch 444 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 445, Step 1, LR: 0.000464, Current Loss: 0.4879, Avg Loss: 0.4879\n",
            "Diff stats — min: -5.4693, max: 10.0000, mean: 8.8273, std: 2.1982\n",
            "\n",
            "Step 11762 — Test metrics:\n",
            "  precision@10: 0.015558699\n",
            "  recall@10: 0.015647288\n",
            "  ndcg@10: 0.016755148\n",
            "  map@10: 0.006782125\n",
            "Epoch 445, Step 20, LR: 0.000464, Current Loss: 0.5007, Avg Loss: 0.4925\n",
            "Diff stats — min: -5.3314, max: 10.0000, mean: 8.8493, std: 2.2317\n",
            "\n",
            "Epoch 445 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 446, Step 1, LR: 0.000455, Current Loss: 0.5153, Avg Loss: 0.5153\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.8463, std: 2.2352\n",
            "\n",
            "Step 11792 — Test metrics:\n",
            "  precision@10: 0.015605846\n",
            "  recall@10: 0.015699674\n",
            "  ndcg@10: 0.016872509\n",
            "  map@10: 0.006956038\n",
            "Epoch 446, Step 20, LR: 0.000455, Current Loss: 0.4875, Avg Loss: 0.4933\n",
            "Diff stats — min: -4.3312, max: 10.0000, mean: 8.8174, std: 2.2601\n",
            "\n",
            "Epoch 446 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 447, Step 1, LR: 0.000455, Current Loss: 0.5053, Avg Loss: 0.5053\n",
            "Diff stats — min: -6.5969, max: 10.0000, mean: 8.8150, std: 2.2838\n",
            "\n",
            "Step 11822 — Test metrics:\n",
            "  precision@10: 0.015676568\n",
            "  recall@10: 0.015775634\n",
            "  ndcg@10: 0.016881349\n",
            "  map@10: 0.006886419\n",
            "Epoch 447, Step 20, LR: 0.000455, Current Loss: 0.4895, Avg Loss: 0.4911\n",
            "Diff stats — min: -5.6010, max: 10.0000, mean: 8.9034, std: 2.1986\n",
            "\n",
            "Epoch 447 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 448, Step 1, LR: 0.000455, Current Loss: 0.4961, Avg Loss: 0.4961\n",
            "Diff stats — min: -6.4357, max: 10.0000, mean: 8.8808, std: 2.1720\n",
            "\n",
            "Step 11852 — Test metrics:\n",
            "  precision@10: 0.015818010\n",
            "  recall@10: 0.015906599\n",
            "  ndcg@10: 0.016730557\n",
            "  map@10: 0.006764613\n",
            "Epoch 448, Step 20, LR: 0.000455, Current Loss: 0.5030, Avg Loss: 0.4929\n",
            "Diff stats — min: -6.2209, max: 10.0000, mean: 8.8609, std: 2.1992\n",
            "\n",
            "Epoch 448 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 449, Step 1, LR: 0.000455, Current Loss: 0.4965, Avg Loss: 0.4965\n",
            "Diff stats — min: -4.5920, max: 10.0000, mean: 8.9028, std: 2.1281\n",
            "\n",
            "Step 11882 — Test metrics:\n",
            "  precision@10: 0.016171617\n",
            "  recall@10: 0.016273957\n",
            "  ndcg@10: 0.017288055\n",
            "  map@10: 0.007012854\n",
            "Epoch 449, Step 20, LR: 0.000455, Current Loss: 0.4826, Avg Loss: 0.4934\n",
            "Diff stats — min: -4.5984, max: 10.0000, mean: 8.8954, std: 2.1677\n",
            "\n",
            "Epoch 449 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 450, Step 1, LR: 0.000455, Current Loss: 0.4872, Avg Loss: 0.4872\n",
            "Diff stats — min: -5.5012, max: 10.0000, mean: 8.9148, std: 2.1206\n",
            "\n",
            "Step 11912 — Test metrics:\n",
            "  precision@10: 0.016383781\n",
            "  recall@10: 0.016483502\n",
            "  ndcg@10: 0.017299986\n",
            "  map@10: 0.007044939\n",
            "Epoch 450, Step 20, LR: 0.000455, Current Loss: 0.5210, Avg Loss: 0.4901\n",
            "Diff stats — min: -8.8296, max: 10.0000, mean: 8.8418, std: 2.2540\n",
            "\n",
            "Epoch 450 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 451, Step 1, LR: 0.000446, Current Loss: 0.5082, Avg Loss: 0.5082\n",
            "Diff stats — min: -8.1508, max: 10.0000, mean: 8.9348, std: 2.1275\n",
            "\n",
            "Step 11942 — Test metrics:\n",
            "  precision@10: 0.016289486\n",
            "  recall@10: 0.016389207\n",
            "  ndcg@10: 0.017147299\n",
            "  map@10: 0.006861810\n",
            "Epoch 451, Step 20, LR: 0.000446, Current Loss: 0.4733, Avg Loss: 0.4896\n",
            "Diff stats — min: -6.8073, max: 10.0000, mean: 8.8551, std: 2.2126\n",
            "\n",
            "Epoch 451 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 452, Step 1, LR: 0.000446, Current Loss: 0.4850, Avg Loss: 0.4850\n",
            "Diff stats — min: -3.5787, max: 10.0000, mean: 8.8945, std: 2.1550\n",
            "\n",
            "Step 11972 — Test metrics:\n",
            "  precision@10: 0.015983027\n",
            "  recall@10: 0.016082093\n",
            "  ndcg@10: 0.016914072\n",
            "  map@10: 0.006820354\n",
            "Epoch 452, Step 20, LR: 0.000446, Current Loss: 0.4844, Avg Loss: 0.4926\n",
            "Diff stats — min: -3.6346, max: 10.0000, mean: 8.8949, std: 2.1140\n",
            "\n",
            "Epoch 452 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 453, Step 1, LR: 0.000446, Current Loss: 0.4907, Avg Loss: 0.4907\n",
            "Diff stats — min: -7.0884, max: 10.0000, mean: 8.8558, std: 2.2011\n",
            "\n",
            "Step 12002 — Test metrics:\n",
            "  precision@10: 0.015959453\n",
            "  recall@10: 0.016055900\n",
            "  ndcg@10: 0.016925295\n",
            "  map@10: 0.006864004\n",
            "Epoch 453, Step 20, LR: 0.000446, Current Loss: 0.4913, Avg Loss: 0.4932\n",
            "Diff stats — min: -5.3779, max: 10.0000, mean: 8.8589, std: 2.1978\n",
            "\n",
            "Epoch 453 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 454, Step 1, LR: 0.000446, Current Loss: 0.5039, Avg Loss: 0.5039\n",
            "Diff stats — min: -6.5622, max: 10.0000, mean: 8.8623, std: 2.2353\n",
            "\n",
            "Step 12032 — Test metrics:\n",
            "  precision@10: 0.016242339\n",
            "  recall@10: 0.016347298\n",
            "  ndcg@10: 0.017274310\n",
            "  map@10: 0.006928865\n",
            "Epoch 454, Step 20, LR: 0.000446, Current Loss: 0.4913, Avg Loss: 0.4929\n",
            "Diff stats — min: -5.7008, max: 10.0000, mean: 8.8876, std: 2.1746\n",
            "\n",
            "Epoch 454 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 455, Step 1, LR: 0.000446, Current Loss: 0.5079, Avg Loss: 0.5079\n",
            "Diff stats — min: -4.2057, max: 10.0000, mean: 8.9426, std: 2.1527\n",
            "\n",
            "Step 12062 — Test metrics:\n",
            "  precision@10: 0.016242339\n",
            "  recall@10: 0.016338785\n",
            "  ndcg@10: 0.017176280\n",
            "  map@10: 0.006909844\n",
            "Epoch 455, Step 20, LR: 0.000446, Current Loss: 0.4954, Avg Loss: 0.4912\n",
            "Diff stats — min: -9.5938, max: 10.0000, mean: 8.8736, std: 2.1506\n",
            "\n",
            "Epoch 455 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 456, Step 1, LR: 0.000437, Current Loss: 0.5014, Avg Loss: 0.5014\n",
            "Diff stats — min: -5.4130, max: 10.0000, mean: 8.8714, std: 2.2414\n",
            "\n",
            "Step 12092 — Test metrics:\n",
            "  precision@10: 0.016053748\n",
            "  recall@10: 0.016152814\n",
            "  ndcg@10: 0.017039598\n",
            "  map@10: 0.006929743\n",
            "Epoch 456, Step 20, LR: 0.000437, Current Loss: 0.4798, Avg Loss: 0.4931\n",
            "Diff stats — min: -5.1551, max: 10.0000, mean: 8.8845, std: 2.1313\n",
            "\n",
            "Epoch 456 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 457, Step 1, LR: 0.000437, Current Loss: 0.4889, Avg Loss: 0.4889\n",
            "Diff stats — min: -4.4362, max: 10.0000, mean: 8.8870, std: 2.1486\n",
            "\n",
            "Step 12122 — Test metrics:\n",
            "  precision@10: 0.015935879\n",
            "  recall@10: 0.016032326\n",
            "  ndcg@10: 0.016887146\n",
            "  map@10: 0.006762168\n",
            "Epoch 457, Step 20, LR: 0.000437, Current Loss: 0.4785, Avg Loss: 0.4916\n",
            "Diff stats — min: -3.7605, max: 10.0000, mean: 8.8960, std: 2.1324\n",
            "\n",
            "Epoch 457 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 458, Step 1, LR: 0.000437, Current Loss: 0.4912, Avg Loss: 0.4912\n",
            "Diff stats — min: -6.5208, max: 10.0000, mean: 8.8281, std: 2.2650\n",
            "\n",
            "Step 12152 — Test metrics:\n",
            "  precision@10: 0.016148043\n",
            "  recall@10: 0.016252348\n",
            "  ndcg@10: 0.017229322\n",
            "  map@10: 0.006934250\n",
            "Epoch 458, Step 20, LR: 0.000437, Current Loss: 0.4891, Avg Loss: 0.4900\n",
            "Diff stats — min: -4.4109, max: 10.0000, mean: 8.8598, std: 2.2296\n",
            "\n",
            "Epoch 458 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 459, Step 1, LR: 0.000437, Current Loss: 0.4808, Avg Loss: 0.4808\n",
            "Diff stats — min: -4.0970, max: 10.0000, mean: 8.8502, std: 2.1761\n",
            "\n",
            "Step 12182 — Test metrics:\n",
            "  precision@10: 0.016265912\n",
            "  recall@10: 0.016364978\n",
            "  ndcg@10: 0.017271520\n",
            "  map@10: 0.006972477\n",
            "Epoch 459, Step 20, LR: 0.000437, Current Loss: 0.4829, Avg Loss: 0.4938\n",
            "Diff stats — min: -6.2811, max: 10.0000, mean: 8.9408, std: 2.1033\n",
            "\n",
            "Epoch 459 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 460, Step 1, LR: 0.000437, Current Loss: 0.4963, Avg Loss: 0.4963\n",
            "Diff stats — min: -3.6736, max: 10.0000, mean: 8.8929, std: 2.1225\n",
            "\n",
            "Step 12212 — Test metrics:\n",
            "  precision@10: 0.015770863\n",
            "  recall@10: 0.015862071\n",
            "  ndcg@10: 0.016931848\n",
            "  map@10: 0.006832066\n",
            "Epoch 460, Step 20, LR: 0.000437, Current Loss: 0.4914, Avg Loss: 0.4912\n",
            "Diff stats — min: -4.3494, max: 10.0000, mean: 8.9185, std: 2.1141\n",
            "\n",
            "Epoch 460 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 461, Step 1, LR: 0.000428, Current Loss: 0.5000, Avg Loss: 0.5000\n",
            "Diff stats — min: -4.8494, max: 10.0000, mean: 8.9359, std: 2.1474\n",
            "\n",
            "Step 12242 — Test metrics:\n",
            "  precision@10: 0.016242339\n",
            "  recall@10: 0.016336166\n",
            "  ndcg@10: 0.017426256\n",
            "  map@10: 0.007106030\n",
            "Epoch 461, Step 20, LR: 0.000428, Current Loss: 0.4852, Avg Loss: 0.4932\n",
            "Diff stats — min: -8.1415, max: 10.0000, mean: 8.8395, std: 2.2398\n",
            "\n",
            "Epoch 461 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 462, Step 1, LR: 0.000428, Current Loss: 0.4971, Avg Loss: 0.4971\n",
            "Diff stats — min: -6.3747, max: 10.0000, mean: 8.8860, std: 2.1819\n",
            "\n",
            "Step 12272 — Test metrics:\n",
            "  precision@10: 0.016195191\n",
            "  recall@10: 0.016291638\n",
            "  ndcg@10: 0.017423231\n",
            "  map@10: 0.007147464\n",
            "Epoch 462, Step 20, LR: 0.000428, Current Loss: 0.5007, Avg Loss: 0.4921\n",
            "Diff stats — min: -4.7301, max: 10.0000, mean: 8.8982, std: 2.1690\n",
            "\n",
            "Epoch 462 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 463, Step 1, LR: 0.000428, Current Loss: 0.4953, Avg Loss: 0.4953\n",
            "Diff stats — min: -8.4921, max: 10.0000, mean: 8.9148, std: 2.1568\n",
            "\n",
            "Step 12302 — Test metrics:\n",
            "  precision@10: 0.016077322\n",
            "  recall@10: 0.016173769\n",
            "  ndcg@10: 0.017452302\n",
            "  map@10: 0.007093576\n",
            "Epoch 463, Step 20, LR: 0.000428, Current Loss: 0.4797, Avg Loss: 0.4911\n",
            "Diff stats — min: -5.1788, max: 10.0000, mean: 8.9413, std: 2.1197\n",
            "\n",
            "Epoch 463 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 464, Step 1, LR: 0.000428, Current Loss: 0.5018, Avg Loss: 0.5018\n",
            "Diff stats — min: -7.3282, max: 10.0000, mean: 8.9224, std: 2.1785\n",
            "\n",
            "Step 12332 — Test metrics:\n",
            "  precision@10: 0.016454503\n",
            "  recall@10: 0.016556188\n",
            "  ndcg@10: 0.017377886\n",
            "  map@10: 0.006995871\n",
            "Epoch 464, Step 20, LR: 0.000428, Current Loss: 0.4919, Avg Loss: 0.4936\n",
            "Diff stats — min: -5.2964, max: 10.0000, mean: 8.8483, std: 2.2170\n",
            "\n",
            "Epoch 464 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 465, Step 1, LR: 0.000428, Current Loss: 0.4988, Avg Loss: 0.4988\n",
            "Diff stats — min: -7.6357, max: 10.0000, mean: 8.9018, std: 2.1653\n",
            "\n",
            "Step 12362 — Test metrics:\n",
            "  precision@10: 0.016360207\n",
            "  recall@10: 0.016467131\n",
            "  ndcg@10: 0.017356436\n",
            "  map@10: 0.007023189\n",
            "Epoch 465, Step 20, LR: 0.000428, Current Loss: 0.4802, Avg Loss: 0.4939\n",
            "Diff stats — min: -5.9201, max: 10.0000, mean: 8.9146, std: 2.1632\n",
            "\n",
            "Epoch 465 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 466, Step 1, LR: 0.000419, Current Loss: 0.4965, Avg Loss: 0.4965\n",
            "Diff stats — min: -3.7035, max: 10.0000, mean: 8.9102, std: 2.1806\n",
            "\n",
            "Step 12392 — Test metrics:\n",
            "  precision@10: 0.016430929\n",
            "  recall@10: 0.016532614\n",
            "  ndcg@10: 0.017543630\n",
            "  map@10: 0.007105522\n",
            "Epoch 466, Step 20, LR: 0.000419, Current Loss: 0.5024, Avg Loss: 0.4906\n",
            "Diff stats — min: -5.5914, max: 10.0000, mean: 8.8767, std: 2.2151\n",
            "\n",
            "Epoch 466 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 467, Step 1, LR: 0.000419, Current Loss: 0.4830, Avg Loss: 0.4830\n",
            "Diff stats — min: -4.5859, max: 10.0000, mean: 8.9463, std: 2.1180\n",
            "\n",
            "Step 12422 — Test metrics:\n",
            "  precision@10: 0.016690240\n",
            "  recall@10: 0.016791926\n",
            "  ndcg@10: 0.017779746\n",
            "  map@10: 0.007187001\n",
            "Epoch 467, Step 20, LR: 0.000419, Current Loss: 0.5027, Avg Loss: 0.4919\n",
            "Diff stats — min: -5.8438, max: 10.0000, mean: 8.9135, std: 2.1406\n",
            "\n",
            "Epoch 467 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 468, Step 1, LR: 0.000419, Current Loss: 0.4783, Avg Loss: 0.4783\n",
            "Diff stats — min: -7.6527, max: 10.0000, mean: 8.9125, std: 2.1534\n",
            "\n",
            "Step 12452 — Test metrics:\n",
            "  precision@10: 0.016548798\n",
            "  recall@10: 0.016653102\n",
            "  ndcg@10: 0.017695283\n",
            "  map@10: 0.007183180\n",
            "Epoch 468, Step 20, LR: 0.000419, Current Loss: 0.4965, Avg Loss: 0.4881\n",
            "Diff stats — min: -5.5369, max: 10.0000, mean: 8.9189, std: 2.1295\n",
            "\n",
            "Epoch 468 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 469, Step 1, LR: 0.000419, Current Loss: 0.4978, Avg Loss: 0.4978\n",
            "Diff stats — min: -5.1749, max: 10.0000, mean: 8.9313, std: 2.1532\n",
            "\n",
            "Step 12482 — Test metrics:\n",
            "  precision@10: 0.016383781\n",
            "  recall@10: 0.016482847\n",
            "  ndcg@10: 0.017561700\n",
            "  map@10: 0.007173555\n",
            "Epoch 469, Step 20, LR: 0.000419, Current Loss: 0.4928, Avg Loss: 0.4934\n",
            "Diff stats — min: -4.4984, max: 10.0000, mean: 8.8869, std: 2.1757\n",
            "\n",
            "Epoch 469 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 470, Step 1, LR: 0.000419, Current Loss: 0.4865, Avg Loss: 0.4865\n",
            "Diff stats — min: -4.0249, max: 10.0000, mean: 8.8675, std: 2.1967\n",
            "\n",
            "Step 12512 — Test metrics:\n",
            "  precision@10: 0.016336634\n",
            "  recall@10: 0.016440938\n",
            "  ndcg@10: 0.017577319\n",
            "  map@10: 0.007156499\n",
            "Epoch 470, Step 20, LR: 0.000419, Current Loss: 0.4975, Avg Loss: 0.4916\n",
            "Diff stats — min: -5.6568, max: 10.0000, mean: 8.8761, std: 2.1936\n",
            "\n",
            "Epoch 470 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 471, Step 1, LR: 0.000411, Current Loss: 0.4904, Avg Loss: 0.4904\n",
            "Diff stats — min: -5.5664, max: 10.0000, mean: 8.9133, std: 2.1304\n",
            "\n",
            "Step 12542 — Test metrics:\n",
            "  precision@10: 0.016313060\n",
            "  recall@10: 0.016412126\n",
            "  ndcg@10: 0.017352262\n",
            "  map@10: 0.007037958\n",
            "Epoch 471, Step 20, LR: 0.000411, Current Loss: 0.4786, Avg Loss: 0.4911\n",
            "Diff stats — min: -4.2762, max: 10.0000, mean: 8.9366, std: 2.1235\n",
            "\n",
            "Epoch 471 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 472, Step 1, LR: 0.000411, Current Loss: 0.4808, Avg Loss: 0.4808\n",
            "Diff stats — min: -7.5728, max: 10.0000, mean: 8.8565, std: 2.2320\n",
            "\n",
            "Step 12572 — Test metrics:\n",
            "  precision@10: 0.016336634\n",
            "  recall@10: 0.016438319\n",
            "  ndcg@10: 0.017327910\n",
            "  map@10: 0.006960553\n",
            "Epoch 472, Step 20, LR: 0.000411, Current Loss: 0.4886, Avg Loss: 0.4880\n",
            "Diff stats — min: -4.2747, max: 10.0000, mean: 8.8840, std: 2.1951\n",
            "\n",
            "Epoch 472 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 473, Step 1, LR: 0.000411, Current Loss: 0.4867, Avg Loss: 0.4867\n",
            "Diff stats — min: -7.0485, max: 10.0000, mean: 8.9376, std: 2.1569\n",
            "\n",
            "Step 12602 — Test metrics:\n",
            "  precision@10: 0.016124470\n",
            "  recall@10: 0.016215678\n",
            "  ndcg@10: 0.017050032\n",
            "  map@10: 0.006935084\n",
            "Epoch 473, Step 20, LR: 0.000411, Current Loss: 0.4910, Avg Loss: 0.4888\n",
            "Diff stats — min: -5.2947, max: 10.0000, mean: 9.0090, std: 2.0686\n",
            "\n",
            "Epoch 473 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 474, Step 1, LR: 0.000411, Current Loss: 0.5055, Avg Loss: 0.5055\n",
            "Diff stats — min: -4.4754, max: 10.0000, mean: 8.9408, std: 2.1769\n",
            "\n",
            "Step 12632 — Test metrics:\n",
            "  precision@10: 0.016383781\n",
            "  recall@10: 0.016477609\n",
            "  ndcg@10: 0.017222525\n",
            "  map@10: 0.006983343\n",
            "Epoch 474, Step 20, LR: 0.000411, Current Loss: 0.4839, Avg Loss: 0.4910\n",
            "Diff stats — min: -7.8315, max: 10.0000, mean: 8.9366, std: 2.1042\n",
            "\n",
            "Epoch 474 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 475, Step 1, LR: 0.000411, Current Loss: 0.4950, Avg Loss: 0.4950\n",
            "Diff stats — min: -5.6322, max: 10.0000, mean: 8.9215, std: 2.1637\n",
            "\n",
            "Step 12662 — Test metrics:\n",
            "  precision@10: 0.016595945\n",
            "  recall@10: 0.016695011\n",
            "  ndcg@10: 0.017412063\n",
            "  map@10: 0.007011525\n",
            "Epoch 475, Step 20, LR: 0.000411, Current Loss: 0.4889, Avg Loss: 0.4902\n",
            "Diff stats — min: -6.8221, max: 10.0000, mean: 8.9190, std: 2.1502\n",
            "\n",
            "Epoch 475 completed, Train Loss: 0.000122\n",
            "\n",
            "Epoch 476, Step 1, LR: 0.000403, Current Loss: 0.4929, Avg Loss: 0.4929\n",
            "Diff stats — min: -4.9579, max: 10.0000, mean: 8.9631, std: 2.1135\n",
            "\n",
            "Step 12692 — Test metrics:\n",
            "  precision@10: 0.016430929\n",
            "  recall@10: 0.016532614\n",
            "  ndcg@10: 0.017377001\n",
            "  map@10: 0.006997164\n",
            "Epoch 476, Step 20, LR: 0.000403, Current Loss: 0.5026, Avg Loss: 0.4890\n",
            "Diff stats — min: -8.4043, max: 10.0000, mean: 8.9103, std: 2.2409\n",
            "\n",
            "Epoch 476 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 477, Step 1, LR: 0.000403, Current Loss: 0.4967, Avg Loss: 0.4967\n",
            "Diff stats — min: -4.4767, max: 10.0000, mean: 8.8650, std: 2.2326\n",
            "\n",
            "Step 12722 — Test metrics:\n",
            "  precision@10: 0.016478076\n",
            "  recall@10: 0.016577142\n",
            "  ndcg@10: 0.017545604\n",
            "  map@10: 0.007149362\n",
            "Epoch 477, Step 20, LR: 0.000403, Current Loss: 0.4884, Avg Loss: 0.4927\n",
            "Diff stats — min: -3.8562, max: 10.0000, mean: 8.9399, std: 2.1264\n",
            "\n",
            "Epoch 477 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 478, Step 1, LR: 0.000403, Current Loss: 0.4915, Avg Loss: 0.4915\n",
            "Diff stats — min: -6.6198, max: 10.0000, mean: 8.9176, std: 2.1300\n",
            "\n",
            "Step 12752 — Test metrics:\n",
            "  precision@10: 0.016666667\n",
            "  recall@10: 0.016765733\n",
            "  ndcg@10: 0.017660391\n",
            "  map@10: 0.007134041\n",
            "Epoch 478, Step 20, LR: 0.000403, Current Loss: 0.4965, Avg Loss: 0.4916\n",
            "Diff stats — min: -8.1535, max: 10.0000, mean: 8.9540, std: 2.1370\n",
            "\n",
            "Epoch 478 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 479, Step 1, LR: 0.000403, Current Loss: 0.4756, Avg Loss: 0.4756\n",
            "Diff stats — min: -4.8064, max: 10.0000, mean: 8.8919, std: 2.1390\n",
            "\n",
            "Step 12782 — Test metrics:\n",
            "  precision@10: 0.016760962\n",
            "  recall@10: 0.016857409\n",
            "  ndcg@10: 0.017798200\n",
            "  map@10: 0.007218696\n",
            "Epoch 479, Step 20, LR: 0.000403, Current Loss: 0.4930, Avg Loss: 0.4909\n",
            "Diff stats — min: -3.7099, max: 10.0000, mean: 8.9158, std: 2.1188\n",
            "\n",
            "Epoch 479 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 480, Step 1, LR: 0.000403, Current Loss: 0.4980, Avg Loss: 0.4980\n",
            "Diff stats — min: -5.1555, max: 10.0000, mean: 8.9064, std: 2.1833\n",
            "\n",
            "Step 12812 — Test metrics:\n",
            "  precision@10: 0.016760962\n",
            "  recall@10: 0.016857409\n",
            "  ndcg@10: 0.017632202\n",
            "  map@10: 0.007076531\n",
            "Epoch 480, Step 20, LR: 0.000403, Current Loss: 0.4822, Avg Loss: 0.4913\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.9233, std: 2.1454\n",
            "\n",
            "Epoch 480 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 481, Step 1, LR: 0.000395, Current Loss: 0.4857, Avg Loss: 0.4857\n",
            "Diff stats — min: -4.9615, max: 10.0000, mean: 8.9702, std: 2.1223\n",
            "\n",
            "Step 12842 — Test metrics:\n",
            "  precision@10: 0.016855257\n",
            "  recall@10: 0.016949084\n",
            "  ndcg@10: 0.017729951\n",
            "  map@10: 0.007164970\n",
            "Epoch 481, Step 20, LR: 0.000395, Current Loss: 0.4694, Avg Loss: 0.4918\n",
            "Diff stats — min: -7.6670, max: 10.0000, mean: 8.8608, std: 2.2069\n",
            "\n",
            "Epoch 481 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 482, Step 1, LR: 0.000395, Current Loss: 0.5099, Avg Loss: 0.5099\n",
            "Diff stats — min: -5.9807, max: 10.0000, mean: 8.8967, std: 2.2065\n",
            "\n",
            "Step 12872 — Test metrics:\n",
            "  precision@10: 0.016878831\n",
            "  recall@10: 0.016977897\n",
            "  ndcg@10: 0.017736368\n",
            "  map@10: 0.007298258\n",
            "Epoch 482, Step 20, LR: 0.000395, Current Loss: 0.4996, Avg Loss: 0.4910\n",
            "Diff stats — min: -3.6912, max: 10.0000, mean: 8.9087, std: 2.1456\n",
            "\n",
            "Epoch 482 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 483, Step 1, LR: 0.000395, Current Loss: 0.4910, Avg Loss: 0.4910\n",
            "Diff stats — min: -7.7800, max: 10.0000, mean: 8.8852, std: 2.2060\n",
            "\n",
            "Step 12902 — Test metrics:\n",
            "  precision@10: 0.016478076\n",
            "  recall@10: 0.016574523\n",
            "  ndcg@10: 0.017579590\n",
            "  map@10: 0.007180528\n",
            "Epoch 483, Step 20, LR: 0.000395, Current Loss: 0.4900, Avg Loss: 0.4896\n",
            "Diff stats — min: -9.8604, max: 10.0000, mean: 8.9700, std: 2.0926\n",
            "\n",
            "Epoch 483 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 484, Step 1, LR: 0.000395, Current Loss: 0.4837, Avg Loss: 0.4837\n",
            "Diff stats — min: -5.8667, max: 10.0000, mean: 8.8996, std: 2.1426\n",
            "\n",
            "Step 12932 — Test metrics:\n",
            "  precision@10: 0.016572372\n",
            "  recall@10: 0.016679295\n",
            "  ndcg@10: 0.017496314\n",
            "  map@10: 0.007154262\n",
            "Epoch 484, Step 20, LR: 0.000395, Current Loss: 0.4882, Avg Loss: 0.4907\n",
            "Diff stats — min: -3.4731, max: 10.0000, mean: 8.8884, std: 2.1499\n",
            "\n",
            "Epoch 484 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 485, Step 1, LR: 0.000395, Current Loss: 0.4865, Avg Loss: 0.4865\n",
            "Diff stats — min: -7.5305, max: 10.0000, mean: 8.9484, std: 2.1323\n",
            "\n",
            "Step 12962 — Test metrics:\n",
            "  precision@10: 0.016737388\n",
            "  recall@10: 0.016836454\n",
            "  ndcg@10: 0.017813201\n",
            "  map@10: 0.007237101\n",
            "Epoch 485, Step 20, LR: 0.000395, Current Loss: 0.4898, Avg Loss: 0.4880\n",
            "Diff stats — min: -8.4227, max: 10.0000, mean: 8.9012, std: 2.1930\n",
            "\n",
            "Epoch 485 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 486, Step 1, LR: 0.000387, Current Loss: 0.4993, Avg Loss: 0.4993\n",
            "Diff stats — min: -5.0189, max: 10.0000, mean: 8.9180, std: 2.2055\n",
            "\n",
            "Step 12992 — Test metrics:\n",
            "  precision@10: 0.016478076\n",
            "  recall@10: 0.016577797\n",
            "  ndcg@10: 0.017234706\n",
            "  map@10: 0.006898634\n",
            "Epoch 486, Step 20, LR: 0.000387, Current Loss: 0.4871, Avg Loss: 0.4884\n",
            "Diff stats — min: -4.3031, max: 10.0000, mean: 8.9466, std: 2.1214\n",
            "\n",
            "Epoch 486 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 487, Step 1, LR: 0.000387, Current Loss: 0.4987, Avg Loss: 0.4987\n",
            "Diff stats — min: -7.9578, max: 10.0000, mean: 8.8890, std: 2.1955\n",
            "\n",
            "Step 13022 — Test metrics:\n",
            "  precision@10: 0.016690240\n",
            "  recall@10: 0.016791926\n",
            "  ndcg@10: 0.017592925\n",
            "  map@10: 0.007071883\n",
            "Epoch 487, Step 20, LR: 0.000387, Current Loss: 0.4835, Avg Loss: 0.4918\n",
            "Diff stats — min: -5.5437, max: 10.0000, mean: 8.9304, std: 2.1014\n",
            "\n",
            "Epoch 487 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 488, Step 1, LR: 0.000387, Current Loss: 0.4869, Avg Loss: 0.4869\n",
            "Diff stats — min: -5.0734, max: 10.0000, mean: 8.9336, std: 2.1080\n",
            "\n",
            "Step 13052 — Test metrics:\n",
            "  precision@10: 0.016572372\n",
            "  recall@10: 0.016676676\n",
            "  ndcg@10: 0.017864155\n",
            "  map@10: 0.007345961\n",
            "Epoch 488, Step 20, LR: 0.000387, Current Loss: 0.4831, Avg Loss: 0.4934\n",
            "Diff stats — min: -3.8296, max: 10.0000, mean: 8.9683, std: 2.0769\n",
            "\n",
            "Epoch 488 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 489, Step 1, LR: 0.000387, Current Loss: 0.4884, Avg Loss: 0.4884\n",
            "Diff stats — min: -4.6765, max: 10.0000, mean: 8.9747, std: 2.0989\n",
            "\n",
            "Step 13082 — Test metrics:\n",
            "  precision@10: 0.016784536\n",
            "  recall@10: 0.016878363\n",
            "  ndcg@10: 0.017974651\n",
            "  map@10: 0.007440261\n",
            "Epoch 489, Step 20, LR: 0.000387, Current Loss: 0.4920, Avg Loss: 0.4904\n",
            "Diff stats — min: -7.8600, max: 10.0000, mean: 8.9083, std: 2.1661\n",
            "\n",
            "Epoch 489 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 490, Step 1, LR: 0.000387, Current Loss: 0.4898, Avg Loss: 0.4898\n",
            "Diff stats — min: -4.8955, max: 10.0000, mean: 8.9446, std: 2.0949\n",
            "\n",
            "Step 13112 — Test metrics:\n",
            "  precision@10: 0.016430929\n",
            "  recall@10: 0.016529340\n",
            "  ndcg@10: 0.017660410\n",
            "  map@10: 0.007226216\n",
            "Epoch 490, Step 20, LR: 0.000387, Current Loss: 0.4907, Avg Loss: 0.4919\n",
            "Diff stats — min: -6.5703, max: 10.0000, mean: 8.8976, std: 2.1898\n",
            "\n",
            "Epoch 490 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 491, Step 1, LR: 0.000379, Current Loss: 0.5036, Avg Loss: 0.5036\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.9519, std: 2.1658\n",
            "\n",
            "Step 13142 — Test metrics:\n",
            "  precision@10: 0.016360207\n",
            "  recall@10: 0.016459273\n",
            "  ndcg@10: 0.017616879\n",
            "  map@10: 0.007162222\n",
            "Epoch 491, Step 20, LR: 0.000379, Current Loss: 0.4875, Avg Loss: 0.4900\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.9463, std: 2.1376\n",
            "\n",
            "Epoch 491 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 492, Step 1, LR: 0.000379, Current Loss: 0.4859, Avg Loss: 0.4859\n",
            "Diff stats — min: -5.1087, max: 10.0000, mean: 8.9310, std: 2.1181\n",
            "\n",
            "Step 13172 — Test metrics:\n",
            "  precision@10: 0.016666667\n",
            "  recall@10: 0.016763113\n",
            "  ndcg@10: 0.017831210\n",
            "  map@10: 0.007283179\n",
            "Epoch 492, Step 20, LR: 0.000379, Current Loss: 0.4875, Avg Loss: 0.4882\n",
            "Diff stats — min: -3.6683, max: 10.0000, mean: 8.9223, std: 2.1498\n",
            "\n",
            "Epoch 492 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 493, Step 1, LR: 0.000379, Current Loss: 0.4890, Avg Loss: 0.4890\n",
            "Diff stats — min: -4.0033, max: 10.0000, mean: 8.9407, std: 2.1500\n",
            "\n",
            "Step 13202 — Test metrics:\n",
            "  precision@10: 0.016690240\n",
            "  recall@10: 0.016789306\n",
            "  ndcg@10: 0.017814122\n",
            "  map@10: 0.007280729\n",
            "Epoch 493, Step 20, LR: 0.000379, Current Loss: 0.4696, Avg Loss: 0.4915\n",
            "Diff stats — min: -3.0672, max: 10.0000, mean: 8.9883, std: 2.0922\n",
            "\n",
            "Epoch 493 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 494, Step 1, LR: 0.000379, Current Loss: 0.4923, Avg Loss: 0.4923\n",
            "Diff stats — min: -6.0933, max: 10.0000, mean: 8.9688, std: 2.0769\n",
            "\n",
            "Step 13232 — Test metrics:\n",
            "  precision@10: 0.016878831\n",
            "  recall@10: 0.016977897\n",
            "  ndcg@10: 0.017920817\n",
            "  map@10: 0.007333912\n",
            "Epoch 494, Step 20, LR: 0.000379, Current Loss: 0.4966, Avg Loss: 0.4897\n",
            "Diff stats — min: -4.7742, max: 10.0000, mean: 8.9494, std: 2.1457\n",
            "\n",
            "Epoch 494 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 495, Step 1, LR: 0.000379, Current Loss: 0.4960, Avg Loss: 0.4960\n",
            "Diff stats — min: -6.3099, max: 10.0000, mean: 8.9377, std: 2.1118\n",
            "\n",
            "Step 13262 — Test metrics:\n",
            "  precision@10: 0.016690240\n",
            "  recall@10: 0.016789306\n",
            "  ndcg@10: 0.017563850\n",
            "  map@10: 0.007123441\n",
            "Epoch 495, Step 20, LR: 0.000379, Current Loss: 0.4929, Avg Loss: 0.4889\n",
            "Diff stats — min: -4.4756, max: 10.0000, mean: 8.9727, std: 2.1179\n",
            "\n",
            "Epoch 495 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 496, Step 1, LR: 0.000372, Current Loss: 0.4927, Avg Loss: 0.4927\n",
            "Diff stats — min: -6.2433, max: 10.0000, mean: 8.9147, std: 2.1446\n",
            "\n",
            "Step 13292 — Test metrics:\n",
            "  precision@10: 0.016690240\n",
            "  recall@10: 0.016786687\n",
            "  ndcg@10: 0.017629421\n",
            "  map@10: 0.007122467\n",
            "Epoch 496, Step 20, LR: 0.000372, Current Loss: 0.4908, Avg Loss: 0.4918\n",
            "Diff stats — min: -8.8638, max: 10.0000, mean: 8.9259, std: 2.1254\n",
            "\n",
            "Epoch 496 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 497, Step 1, LR: 0.000372, Current Loss: 0.4917, Avg Loss: 0.4917\n",
            "Diff stats — min: -10.0000, max: 10.0000, mean: 8.9568, std: 2.1374\n",
            "\n",
            "Step 13322 — Test metrics:\n",
            "  precision@10: 0.016572372\n",
            "  recall@10: 0.016666199\n",
            "  ndcg@10: 0.017790721\n",
            "  map@10: 0.007253274\n",
            "Epoch 497, Step 20, LR: 0.000372, Current Loss: 0.5042, Avg Loss: 0.4907\n",
            "Diff stats — min: -5.0599, max: 10.0000, mean: 8.9938, std: 2.1000\n",
            "\n",
            "Epoch 497 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 498, Step 1, LR: 0.000372, Current Loss: 0.4966, Avg Loss: 0.4966\n",
            "Diff stats — min: -5.2073, max: 10.0000, mean: 8.9737, std: 2.0839\n",
            "\n",
            "Step 13352 — Test metrics:\n",
            "  precision@10: 0.017043847\n",
            "  recall@10: 0.017145533\n",
            "  ndcg@10: 0.018170126\n",
            "  map@10: 0.007466128\n",
            "Epoch 498, Step 20, LR: 0.000372, Current Loss: 0.4838, Avg Loss: 0.4899\n",
            "Diff stats — min: -7.6217, max: 10.0000, mean: 8.9509, std: 2.1575\n",
            "\n",
            "Epoch 498 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 499, Step 1, LR: 0.000372, Current Loss: 0.4928, Avg Loss: 0.4928\n",
            "Diff stats — min: -4.9677, max: 10.0000, mean: 8.9740, std: 2.0853\n",
            "\n",
            "Step 13382 — Test metrics:\n",
            "  precision@10: 0.016383781\n",
            "  recall@10: 0.016477609\n",
            "  ndcg@10: 0.017434222\n",
            "  map@10: 0.007058482\n",
            "Epoch 499, Step 20, LR: 0.000372, Current Loss: 0.4978, Avg Loss: 0.4910\n",
            "Diff stats — min: -9.3858, max: 10.0000, mean: 8.9074, std: 2.2322\n",
            "\n",
            "Epoch 499 completed, Train Loss: 0.000121\n",
            "\n",
            "Epoch 500, Step 1, LR: 0.000372, Current Loss: 0.4737, Avg Loss: 0.4737\n",
            "Diff stats — min: -3.9693, max: 10.0000, mean: 9.0262, std: 1.9952\n",
            "\n",
            "Step 13412 — Test metrics:\n",
            "  precision@10: 0.016430929\n",
            "  recall@10: 0.016527376\n",
            "  ndcg@10: 0.017502895\n",
            "  map@10: 0.007127937\n",
            "Epoch 500, Step 20, LR: 0.000372, Current Loss: 0.4860, Avg Loss: 0.4901\n",
            "Diff stats — min: -8.2768, max: 10.0000, mean: 8.8970, std: 2.1884\n",
            "\n",
            "Epoch 500 completed, Train Loss: 0.000121\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = train_model(model,\n",
        "                    data,\n",
        "                    (seq_ids, event_type, seq_times, seq_mask),\n",
        "                    edge_type=edge_type,\n",
        "                    num_epochs=50,\n",
        "                    lr=lr,\n",
        "                    batch_size=batch_size,\n",
        "                    print_every=print_every,\n",
        "                    test_every=test_every,\n",
        "                    top_k=top_k,\n",
        "                    test_batch_size=test_batch_size,\n",
        "                    scheduler_step_size=scheduler_step_size,\n",
        "                    scheduler_gamma=train_scheduler_gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "My23qnoFSefl",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "torch.save(model, \"gnn_model_mvl.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "3k81pKcYSefm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "pfx9vWVjSefm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "log_model(\n",
        "    experiment=experiment,\n",
        "    model=model,\n",
        "    model_name=\"GNN+THP\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDPVRfVHSefm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "experiment.end()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i41cHhy5Sefm",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 7302197,
          "sourceId": 11637841,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 7705289,
          "sourceId": 12229447,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
