{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-24T18:33:53.732306Z",
     "iopub.status.busy": "2025-06-24T18:33:53.732056Z",
     "iopub.status.idle": "2025-06-24T18:34:09.173844Z",
     "shell.execute_reply": "2025-06-24T18:34:09.172822Z",
     "shell.execute_reply.started": "2025-06-24T18:33:53.732262Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.1/727.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install torch_geometric rectools\n",
    "!pip -q install comet_ml\n",
    "!pip -q install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:09.175870Z",
     "iopub.status.busy": "2025-06-24T18:34:09.175582Z",
     "iopub.status.idle": "2025-06-24T18:34:14.600361Z",
     "shell.execute_reply": "2025-06-24T18:34:14.599796Z",
     "shell.execute_reply.started": "2025-06-24T18:34:09.175845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:14.606078Z",
     "iopub.status.busy": "2025-06-24T18:34:14.605916Z",
     "iopub.status.idle": "2025-06-24T18:34:14.633150Z",
     "shell.execute_reply": "2025-06-24T18:34:14.632641Z",
     "shell.execute_reply.started": "2025-06-24T18:34:14.606065Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:14.636103Z",
     "iopub.status.busy": "2025-06-24T18:34:14.635594Z",
     "iopub.status.idle": "2025-06-24T18:34:20.699353Z",
     "shell.execute_reply": "2025-06-24T18:34:20.698767Z",
     "shell.execute_reply.started": "2025-06-24T18:34:14.636078Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/annanet/gnn-recommender/6740d9eac8334723b516a010c02f5704\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "  api_key=os.getenv('API_KEY'),\n",
    "  project_name=\"gnn-recommender\",\n",
    "  workspace=\"annanet\",\n",
    "  log_code=True\n",
    ")\n",
    "\n",
    "experiment.set_name('adding new training task THP - v1 - movielens')\n",
    "experiment.add_tags(['movielens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:20.700218Z",
     "iopub.status.busy": "2025-06-24T18:34:20.700041Z",
     "iopub.status.idle": "2025-06-24T18:34:20.705016Z",
     "shell.execute_reply": "2025-06-24T18:34:20.704512Z",
     "shell.execute_reply.started": "2025-06-24T18:34:20.700204Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'seed': 42,\n",
    "    'types_of_feedback': [\"explicit_positive\", \"expliсit_negative\",\n",
    "                          \"implicit_positive\", \"implicit_negative\"],\n",
    "    'max_len_of_thp_history': 100,\n",
    "    'pad_id': 0,         \n",
    "    'cls_id': None,  # filled in at the stage of creating a story for thp\n",
    "    'thp_dmodel': 64,  # размер эмбеддингов\n",
    "    'thp_n_head': 4,  # число attention-голов\n",
    "    'thp_window_size': 101,  # окно THP\n",
    "    'thp_decay': 1.0,  # скорость экспоненциального затухания\n",
    "    'thp_dropout': 0.2,  # dropout\n",
    "    'train_edge_type': [('item','item2explicit_positive','explicit_positive'), \n",
    "                        ('item','item2implicit_positive','implicit_positive')],\n",
    "    'train_num_epochs': 100,\n",
    "    'train_lr': 1e-3,\n",
    "    'train_batch_size': 4096,\n",
    "    'train_print_every': 20,  # раз в сколько шагов печатаем статистику\n",
    "    'train_test_every': 50,\n",
    "    'test_topk': 10,\n",
    "    'test_batch_size': 8192,\n",
    "    'train_scheduler_step_size': 150,\n",
    "    'train_scheduler_gamma': 0.98,\n",
    "    'train_margin': 1.0,\n",
    "    'train_lambda_margin': 0.1,\n",
    "    'train_lambda_ce': 0.7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:20.706302Z",
     "iopub.status.busy": "2025-06-24T18:34:20.705801Z",
     "iopub.status.idle": "2025-06-24T18:34:20.743622Z",
     "shell.execute_reply": "2025-06-24T18:34:20.743124Z",
     "shell.execute_reply.started": "2025-06-24T18:34:20.706264Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv', 'test.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/kaggle/input/gnn-dataset/data/leave-n-out/mvln')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:20.745124Z",
     "iopub.status.busy": "2025-06-24T18:34:20.744935Z",
     "iopub.status.idle": "2025-06-24T18:34:30.385086Z",
     "shell.execute_reply": "2025-06-24T18:34:30.384299Z",
     "shell.execute_reply.started": "2025-06-24T18:34:20.745108Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, GATConv\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from rectools import Columns\n",
    "from rectools.metrics import MAP, Precision, Recall, NDCG, calc_metrics\n",
    "\n",
    "import gc\n",
    "\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:30.386242Z",
     "iopub.status.busy": "2025-06-24T18:34:30.385846Z",
     "iopub.status.idle": "2025-06-24T18:34:30.395533Z",
     "shell.execute_reply": "2025-06-24T18:34:30.394762Z",
     "shell.execute_reply.started": "2025-06-24T18:34:30.386224Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = hyperparameters['seed']\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:30.396630Z",
     "iopub.status.busy": "2025-06-24T18:34:30.396352Z",
     "iopub.status.idle": "2025-06-24T18:34:31.561526Z",
     "shell.execute_reply": "2025-06-24T18:34:31.560780Z",
     "shell.execute_reply.started": "2025-06-24T18:34:30.396589Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  timestamp                date\n",
      "0        1      3186       4  978300019 2000-12-31 22:00:19\n",
      "1        1      1270       5  978300055 2000-12-31 22:00:55\n",
      "2        1      1721       4  978300055 2000-12-31 22:00:55\n",
      "3        1      1022       5  978300055 2000-12-31 22:00:55\n",
      "4        1      2340       3  978300103 2000-12-31 22:01:43\n"
     ]
    }
   ],
   "source": [
    "rootpath = '/kaggle/input/gnn-dataset/data/leave-n-out/mvln/'\n",
    "train = pd.read_csv(\n",
    "    rootpath+'train.csv'\n",
    ")\n",
    "train['date'] = pd.to_datetime(train['timestamp'], unit='s')\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:31.562680Z",
     "iopub.status.busy": "2025-06-24T18:34:31.562424Z",
     "iopub.status.idle": "2025-06-24T18:34:31.600066Z",
     "shell.execute_reply": "2025-06-24T18:34:31.599322Z",
     "shell.execute_reply.started": "2025-06-24T18:34:31.562664Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество explicit позитивного фидбека 211802\n",
      "Количество explicit негативного фидбека 153484\n"
     ]
    }
   ],
   "source": [
    "explicit_positive = train[(train[\"rating\"] == 5)].index\n",
    "explisit_negative = train[(train[\"rating\"] <= 2)].index\n",
    "\n",
    "explicit_combined_feedback = explicit_positive.union(explisit_negative)\n",
    "print('Количество explicit позитивного фидбека', explicit_positive.shape[0])\n",
    "print('Количество explicit негативного фидбека', explisit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:31.601269Z",
     "iopub.status.busy": "2025-06-24T18:34:31.601008Z",
     "iopub.status.idle": "2025-06-24T18:34:31.638609Z",
     "shell.execute_reply": "2025-06-24T18:34:31.637862Z",
     "shell.execute_reply.started": "2025-06-24T18:34:31.601242Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество implicit позитивного фидбека 327987\n",
      "Количество implicit негативного фидбека 246536\n"
     ]
    }
   ],
   "source": [
    "implicit_positive = train[(train[\"rating\"] == 4)].index\n",
    "implicit_negative = train[(train[\"rating\"] == 3)].index\n",
    "\n",
    "implicit_combined_feedback = implicit_positive.union(implicit_negative)\n",
    "print('Количество implicit позитивного фидбека', implicit_positive.shape[0])\n",
    "print('Количество implicit негативного фидбека', implicit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:31.639965Z",
     "iopub.status.busy": "2025-06-24T18:34:31.639453Z",
     "iopub.status.idle": "2025-06-24T18:34:31.745613Z",
     "shell.execute_reply": "2025-06-24T18:34:31.744737Z",
     "shell.execute_reply.started": "2025-06-24T18:34:31.639938Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2000-12-31 22:00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2000-12-31 22:01:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id             target                date\n",
       "0        1      3186  implicit_positive 2000-12-31 22:00:19\n",
       "1        1      1270  explicit_positive 2000-12-31 22:00:55\n",
       "2        1      1721  implicit_positive 2000-12-31 22:00:55\n",
       "3        1      1022  explicit_positive 2000-12-31 22:00:55\n",
       "4        1      2340  implicit_negative 2000-12-31 22:01:43"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:, \"target\"] = \"\"\n",
    "train.loc[explicit_positive, \"target\"] = \"explicit_positive\"\n",
    "train.loc[explisit_negative, \"target\"] = \"expliсit_negative\"\n",
    "train.loc[implicit_positive, \"target\"] = \"implicit_positive\"\n",
    "train.loc[implicit_negative, \"target\"] = \"implicit_negative\"\n",
    "\n",
    "train = train[['user_id','movie_id','target','date']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:31.749361Z",
     "iopub.status.busy": "2025-06-24T18:34:31.749103Z",
     "iopub.status.idle": "2025-06-24T18:34:31.916896Z",
     "shell.execute_reply": "2025-06-24T18:34:31.916326Z",
     "shell.execute_reply.started": "2025-06-24T18:34:31.749343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = train.sort_values(by=[\"user_id\", \"date\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:31.917825Z",
     "iopub.status.busy": "2025-06-24T18:34:31.917610Z",
     "iopub.status.idle": "2025-06-24T18:34:31.921670Z",
     "shell.execute_reply": "2025-06-24T18:34:31.921120Z",
     "shell.execute_reply.started": "2025-06-24T18:34:31.917809Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.columns = ['user_id', 'item_id', 'target', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:31.922584Z",
     "iopub.status.busy": "2025-06-24T18:34:31.922371Z",
     "iopub.status.idle": "2025-06-24T18:34:32.015091Z",
     "shell.execute_reply": "2025-06-24T18:34:32.014469Z",
     "shell.execute_reply.started": "2025-06-24T18:34:31.922570Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  timestamp                date\n",
      "0        1      2687       3  978824268 2001-01-06 23:37:48\n",
      "1        1       745       3  978824268 2001-01-06 23:37:48\n",
      "2        1       588       4  978824268 2001-01-06 23:37:48\n",
      "3        1         1       5  978824268 2001-01-06 23:37:48\n",
      "4        1      2355       5  978824291 2001-01-06 23:38:11\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\n",
    "    rootpath+'test.csv'\n",
    ")\n",
    "test['date'] = pd.to_datetime(test['timestamp'], unit='s')\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:32.016163Z",
     "iopub.status.busy": "2025-06-24T18:34:32.015921Z",
     "iopub.status.idle": "2025-06-24T18:34:32.024310Z",
     "shell.execute_reply": "2025-06-24T18:34:32.023740Z",
     "shell.execute_reply.started": "2025-06-24T18:34:32.016146Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2687</td>\n",
       "      <td>2001-01-06 23:37:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>745</td>\n",
       "      <td>2001-01-06 23:37:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>2001-01-06 23:37:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-01-06 23:37:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>2001-01-06 23:38:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id                date\n",
       "0        1      2687 2001-01-06 23:37:48\n",
       "1        1       745 2001-01-06 23:37:48\n",
       "2        1       588 2001-01-06 23:37:48\n",
       "3        1         1 2001-01-06 23:37:48\n",
       "4        1      2355 2001-01-06 23:38:11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[['user_id','movie_id', 'date']]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:32.025668Z",
     "iopub.status.busy": "2025-06-24T18:34:32.025185Z",
     "iopub.status.idle": "2025-06-24T18:34:32.035304Z",
     "shell.execute_reply": "2025-06-24T18:34:32.034628Z",
     "shell.execute_reply.started": "2025-06-24T18:34:32.025651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test.columns = ['user_id', 'item_id', 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP model v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:32.036208Z",
     "iopub.status.busy": "2025-06-24T18:34:32.035992Z",
     "iopub.status.idle": "2025-06-24T18:34:32.185003Z",
     "shell.execute_reply": "2025-06-24T18:34:32.184495Z",
     "shell.execute_reply.started": "2025-06-24T18:34:32.036186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.loc[:, \"event\"] = 0\n",
    "train.loc[(train[\"target\"] == \"explicit_positive\") | (train[\"target\"] == \"implicit_positive\"), \"event\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:32.186394Z",
     "iopub.status.busy": "2025-06-24T18:34:32.185723Z",
     "iopub.status.idle": "2025-06-24T18:34:32.205878Z",
     "shell.execute_reply": "2025-06-24T18:34:32.205334Z",
     "shell.execute_reply.started": "2025-06-24T18:34:32.186375Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60394, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[(test.user_id.isin(train.user_id)) & (test.item_id.isin(train.item_id))].copy()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:32.206896Z",
     "iopub.status.busy": "2025-06-24T18:34:32.206717Z",
     "iopub.status.idle": "2025-06-24T18:34:32.365891Z",
     "shell.execute_reply": "2025-06-24T18:34:32.365312Z",
     "shell.execute_reply.started": "2025-06-24T18:34:32.206882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. Преобразование данных - для куарека не особо нужно, но для других - напоминалка\n",
    "# делаем всегда! чтобы не сломать ничего дальше и чтобы все индексы были от 0 до N без пропусков\n",
    "user_encoder = LabelEncoder()\n",
    "video_encoder = LabelEncoder()\n",
    "\n",
    "train.loc[:, 'user_id'] = user_encoder.fit_transform(train['user_id'])\n",
    "train.loc[:, 'item_id'] = video_encoder.fit_transform(train['item_id'])\n",
    "\n",
    "test.loc[:, 'user_id'] = user_encoder.transform(test['user_id'])\n",
    "test.loc[:, 'item_id'] = video_encoder.transform(test['item_id'])\n",
    "train['user_id'] = train['user_id'].astype(int)\n",
    "train['item_id'] = train['item_id'].astype(int)\n",
    "test['user_id'] = test['user_id'].astype(int)\n",
    "test['item_id'] = test['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:32.366859Z",
     "iopub.status.busy": "2025-06-24T18:34:32.366593Z",
     "iopub.status.idle": "2025-06-24T18:34:32.374423Z",
     "shell.execute_reply": "2025-06-24T18:34:32.373662Z",
     "shell.execute_reply.started": "2025-06-24T18:34:32.366835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# так как используем pad, то нумерацию item_id начинаем с 1 до max + 1, чтобы для pad забить 0\n",
    "train.loc[:, 'item_id'] += 1\n",
    "test.loc[:, 'item_id'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:32.375605Z",
     "iopub.status.busy": "2025-06-24T18:34:32.375322Z",
     "iopub.status.idle": "2025-06-24T18:34:32.400014Z",
     "shell.execute_reply": "2025-06-24T18:34:32.399358Z",
     "shell.execute_reply.started": "2025-06-24T18:34:32.375580Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных item_id 3700\n",
      "Количество уникальных user_id 6040\n"
     ]
    }
   ],
   "source": [
    "# т.е. сразу знаем количество и в каких пределах изменяется user_id и item_id\n",
    "num_videos = train['item_id'].nunique()\n",
    "num_users = train['user_id'].nunique()\n",
    "\n",
    "print('Количество уникальных item_id', num_videos)\n",
    "print('Количество уникальных user_id', num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:32.401122Z",
     "iopub.status.busy": "2025-06-24T18:34:32.400873Z",
     "iopub.status.idle": "2025-06-24T18:34:32.409900Z",
     "shell.execute_reply": "2025-06-24T18:34:32.409116Z",
     "shell.execute_reply.started": "2025-06-24T18:34:32.401098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_hetero_data(df: pd.DataFrame) -> HeteroData:\n",
    "    \"\"\"\n",
    "    Construct a heterogeneous graph for recommendation from interaction records.\n",
    "\n",
    "    Node types:\n",
    "      - 'user': one node per unique user_id\n",
    "      - 'item': one node per unique item_id\n",
    "      - one node per user per feedback type ('implicit_positive',\n",
    "        'explicit_positive', 'implicit_negative', 'explicit_negative')\n",
    "\n",
    "    Edges:\n",
    "      1) item -> feedback_node: connect each item to the corresponding feedback node.\n",
    "      2) feedback_node -> item: reverse connection, to allow message passing back to items.\n",
    "      3) feedback_node -> user: link each feedback node to the user who generated that feedback.\n",
    "      4) user -> user: a complete graph among all users under the relation 'interacts'.\n",
    "\n",
    "    For edges (1)-(3), each edge stores:\n",
    "      - edge_attr: a vector of length (1 + num_feedback_types),\n",
    "                   where index 0 is Δt = (reference_time - event_timestamp),\n",
    "                   and indices 1.. end are a one-hot encoding of the feedback type.\n",
    "      - edge_time: a separate tensor containing only Δt for convenience.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Must contain columns:\n",
    "          - 'user_id': integer user identifier (0-indexed or otherwise)\n",
    "          - 'item_id': integer item identifier\n",
    "          - 'target': feedback type (one of 'implicit_positive',\n",
    "                      'explicit_positive', 'implicit_negative',\n",
    "                      'explicit_negative')\n",
    "          - 'date': timestamp string for the interaction\n",
    "    reference_time : float\n",
    "        A Unix timestamp (in seconds). For each interaction, Δt is computed as\n",
    "        (reference_time - interaction_timestamp).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    data : torch_geometric.data.HeteroData\n",
    "        A heterogeneous graph with node types 'user', 'item', and each feedback type.\n",
    "        Edge indices, edge_attr, and edge_time are set for relations:\n",
    "          - ('item', 'item2<ft>', ft)\n",
    "          - (ft, '<ft>2item', 'item')\n",
    "          - (ft, '<ft>2user', 'user')\n",
    "        Additionally, ('user', 'interacts', 'user') is a complete graph among users.\n",
    "    \"\"\"\n",
    "    # Determine the number of users and items\n",
    "    num_users = df['user_id'].nunique()\n",
    "    num_items = int(df['item_id'].max()) + 1\n",
    "    feedback_types = df['target'].unique().tolist()\n",
    "    type2idx = {tp: i for i, tp in enumerate(feedback_types)}\n",
    "\n",
    "    # Transform data to seconds\n",
    "    times = pd.to_datetime(df['date']).astype('datetime64[ns]').astype(int) / 1e9\n",
    "    df['timestamp'] = times\n",
    "\n",
    "    # Initialize HeteroData\n",
    "    data = HeteroData()\n",
    "    data['user'].node_id = torch.arange(num_users)\n",
    "    data['item'].node_id = torch.arange(num_items)\n",
    "    for ft in feedback_types:\n",
    "        data[ft].node_id = torch.arange(num_users)\n",
    "\n",
    "    # Build edges: item -> feedback -> user\n",
    "    for ft in feedback_types:\n",
    "        mask = df['target'] == ft\n",
    "        # user -> ft\n",
    "        src_fu = torch.LongTensor(df.loc[mask, 'user_id'].values)    # [E_ft]\n",
    "        dst_fu = torch.LongTensor(df.loc[mask, 'user_id'].values)    # тот же user_id, т.к. ft_node ID = user_id\n",
    "        # ft -> item\n",
    "        src_fi = torch.LongTensor(df.loc[mask, 'user_id'].values)\n",
    "        dst_fi = torch.LongTensor(df.loc[mask, 'item_id'].values)\n",
    "        # item -> ft\n",
    "        src_if = torch.LongTensor(df.loc[mask, 'item_id'].values)  \n",
    "        dst_if = torch.LongTensor(df.loc[mask, 'user_id'].values)\n",
    "\n",
    "        # edge_attr\n",
    "        # delta_t = reference_time - timestamp\n",
    "        # delta = reference_time - torch.tensor(df.loc[mask, 'timestamp'].values, dtype=torch.float)  # [E_ft]\n",
    "        # delta = delta.unsqueeze(1)    # [E_ft, 1]\n",
    "        # one-hot of ft\n",
    "        # idx = type2idx[ft]\n",
    "        # one_hot = F.one_hot(torch.full((src_fu.size(0),), idx, dtype=torch.long),\n",
    "        #                     num_classes=len(feedback_types)).float()  # [E_ft, 4]\n",
    "        # combine: [delta | one_hot] → [E_ft, 5]\n",
    "        # edge_attr = torch.cat([delta, one_hot], dim=1)  # [E_ft, 1+4]\n",
    "\n",
    "        data['item', f'item2{ft}', ft].edge_index = torch.stack([src_if, dst_if], dim=0)\n",
    "        # data['item', f'item2{ft}', ft].edge_attr = edge_attr\n",
    "        # data['item', f'item2{ft}', ft].edge_time = delta\n",
    "\n",
    "        data[ft, f'{ft}2item', 'item'].edge_index = torch.stack([src_fi, dst_fi], dim=0)\n",
    "        # data[ft, f'{ft}2item', 'item'].edge_attr = edge_attr\n",
    "        # data[ft, f'{ft}2item', 'item'].edge_time = delta\n",
    "\n",
    "        data[ft, f'{ft}2user', 'user'].edge_index = torch.stack([src_fu, dst_fu], dim=0)\n",
    "        # data[ft, f'{ft}2user', 'user'].edge_attr = edge_attr\n",
    "        # data[ft, f'{ft}2user', 'user'].edge_time = delta\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:32.410839Z",
     "iopub.status.busy": "2025-06-24T18:34:32.410671Z",
     "iopub.status.idle": "2025-06-24T18:34:32.897389Z",
     "shell.execute_reply": "2025-06-24T18:34:32.896543Z",
     "shell.execute_reply.started": "2025-06-24T18:34:32.410826Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ node_id=[6040] },\n",
       "  item={ node_id=[3701] },\n",
       "  implicit_positive={ node_id=[6040] },\n",
       "  explicit_positive={ node_id=[6040] },\n",
       "  implicit_negative={ node_id=[6040] },\n",
       "  expliсit_negative={ node_id=[6040] },\n",
       "  (item, item2implicit_positive, implicit_positive)={ edge_index=[2, 327987] },\n",
       "  (implicit_positive, implicit_positive2item, item)={ edge_index=[2, 327987] },\n",
       "  (implicit_positive, implicit_positive2user, user)={ edge_index=[2, 327987] },\n",
       "  (item, item2explicit_positive, explicit_positive)={ edge_index=[2, 211802] },\n",
       "  (explicit_positive, explicit_positive2item, item)={ edge_index=[2, 211802] },\n",
       "  (explicit_positive, explicit_positive2user, user)={ edge_index=[2, 211802] },\n",
       "  (item, item2implicit_negative, implicit_negative)={ edge_index=[2, 246536] },\n",
       "  (implicit_negative, implicit_negative2item, item)={ edge_index=[2, 246536] },\n",
       "  (implicit_negative, implicit_negative2user, user)={ edge_index=[2, 246536] },\n",
       "  (item, item2expliсit_negative, expliсit_negative)={ edge_index=[2, 153484] },\n",
       "  (expliсit_negative, expliсit_negative2item, item)={ edge_index=[2, 153484] },\n",
       "  (expliсit_negative, expliсit_negative2user, user)={ edge_index=[2, 153484] }\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = prepare_hetero_data(train)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:32.898531Z",
     "iopub.status.busy": "2025-06-24T18:34:32.898235Z",
     "iopub.status.idle": "2025-06-24T18:34:32.910864Z",
     "shell.execute_reply": "2025-06-24T18:34:32.910219Z",
     "shell.execute_reply.started": "2025-06-24T18:34:32.898505Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,    1,    2,  ..., 3698, 3699, 3700])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['item'].node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:32.911970Z",
     "iopub.status.busy": "2025-06-24T18:34:32.911730Z",
     "iopub.status.idle": "2025-06-24T18:34:32.919931Z",
     "shell.execute_reply": "2025-06-24T18:34:32.919398Z",
     "shell.execute_reply.started": "2025-06-24T18:34:32.911950Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_thp_data(df: pd.DataFrame, max_len: int, pad: int, cls_id: int):\n",
    "    \"\"\"\n",
    "    Build sequences of item ids, event types and timestamps per user for THP training.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame with columns ['user_id','item_id','event','date']\n",
    "    max_len : int, maximum sequence length (pad or truncate to this length)\n",
    "    pad : int, padding token value (left-padding)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    seq_ids   : LongTensor [num_users, max_len]\n",
    "    event_type: LongTensor [num_users, max_len]\n",
    "    seq_times : FloatTensor [num_users, max_len]\n",
    "    seq_mask  : BoolTensor [num_users, max_len]\n",
    "    \"\"\"\n",
    "    users = df['user_id'].unique()\n",
    "    num_users = len(users)\n",
    "\n",
    "    # +1 for the [CLS] token\n",
    "    new_max_len = max_len + 1\n",
    "    \n",
    "    seq_ids    = torch.full((num_users, new_max_len), pad, dtype=torch.long)\n",
    "    event_type = torch.full((num_users, new_max_len), pad, dtype=torch.long)\n",
    "    seq_times  = torch.zeros((num_users, new_max_len), dtype=torch.float)\n",
    "    seq_mask   = torch.zeros((num_users, new_max_len), dtype=torch.bool)\n",
    "\n",
    "    # map event labels to ints\n",
    "    label2idx = {label: idx for idx, label in enumerate(df['event'].unique())}\n",
    "\n",
    "    # устанавливаем CLS-токен в позицию 0\n",
    "    seq_ids[:, 0]  = cls_id\n",
    "    event_type[:,0] = cls_id   \n",
    "    seq_mask[:, 0] = True\n",
    "\n",
    "    for i, u in enumerate(users):\n",
    "        user_df = df[df['user_id'] == u].sort_values('date')\n",
    "        items = user_df['item_id'].values\n",
    "        types = user_df['event'].map(label2idx).values\n",
    "        times = pd.to_datetime(user_df['date']).values.astype('datetime64[ns]').astype(np.int64) / 1e9\n",
    "        \n",
    "        seq = len(items)\n",
    "        if seq == 0:\n",
    "            continue\n",
    "\n",
    "        # вставляем реальные события **cдвинутые на 1** вправо из-за CLS,\n",
    "        # чтобы первые new_max_len-lengt...new_max_len-1 оказались данными\n",
    "        length = min(seq, max_len)\n",
    "        start = max(0, new_max_len - length)\n",
    "        seq_ids[i, start:]    = torch.tensor(items[-length:],    dtype=torch.long)\n",
    "        event_type[i, start:] = torch.tensor(types[-length:],    dtype=torch.long)\n",
    "        seq_times[i, start:]  = torch.tensor(times[-length:],    dtype=torch.float)\n",
    "        seq_mask[i, start:]   = True\n",
    "\n",
    "    return seq_ids, event_type, seq_times, seq_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:32.920975Z",
     "iopub.status.busy": "2025-06-24T18:34:32.920741Z",
     "iopub.status.idle": "2025-06-24T18:34:46.984053Z",
     "shell.execute_reply": "2025-06-24T18:34:46.983443Z",
     "shell.execute_reply.started": "2025-06-24T18:34:32.920955Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3701,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 2966, 1177,\n",
       "         1573,  956, 2145, 1657, 3173, 2596, 1116,  254,  690, 1103,  858,  594,\n",
       "         2485, 1780, 1847, 2886,  877,  969, 1781,  962, 1837,  145, 1024,  853,\n",
       "         1194, 2589, 2554, 1153,  640, 2707,  518, 2895, 2583, 2126,  963, 1106,\n",
       "          581, 2203, 1420,  514,  582]),\n",
       " tensor([3701,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    1,    0,    0,    0,    0,    0,    1,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
       "            0,    0,    0,    0,    1,    0,    0,    0,    0,    1,    0,    1,\n",
       "            0,    0,    0,    0,    0]),\n",
       " tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7830e+08, 9.7830e+08,\n",
       "         9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08,\n",
       "         9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08,\n",
       "         9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08,\n",
       "         9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08,\n",
       "         9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08,\n",
       "         9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08,\n",
       "         9.7830e+08, 9.7830e+08, 9.7882e+08, 9.7882e+08, 9.7882e+08]),\n",
       " tensor([ True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_ID = hyperparameters['pad_id'] \n",
    "CLS_ID = data['item'].node_id.shape[0]  \n",
    "hyperparameters['cls_id'] = CLS_ID\n",
    "max_len = hyperparameters['max_len_of_thp_history']\n",
    "\n",
    "seq_ids, event_type, seq_times, seq_mask = prepare_thp_data(train, \n",
    "                                                            max_len=max_len, \n",
    "                                                            pad=PAD_ID,\n",
    "                                                            cls_id=CLS_ID)\n",
    "seq_ids[0], event_type[0], seq_times[0], seq_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:46.984974Z",
     "iopub.status.busy": "2025-06-24T18:34:46.984779Z",
     "iopub.status.idle": "2025-06-24T18:34:46.999614Z",
     "shell.execute_reply": "2025-06-24T18:34:46.998987Z",
     "shell.execute_reply.started": "2025-06-24T18:34:46.984951Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class THPEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head Transformer Hawkes-inspired encoder with local window.\n",
    "    Integrates exponential decay kernel within last `window_size` events.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, n_head: int, window_size: int = 50, \n",
    "                 decay: float = 1.0, dropout: float = 0.1, max_len: int = 101):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_len = max_len\n",
    "        # Learnable positional embeddings\n",
    "        self.pos_emb = nn.Embedding(max_len, d_model)\n",
    "        # Temporal (time) embedding: simple linear projection from scalar to d_model\n",
    "        self.time_emb = nn.Linear(1, d_model)\n",
    "        \n",
    "        self.heads = nn.ModuleList([\n",
    "            _THPHead(d_model, decay, window_size, dropout) for _ in range(n_head)\n",
    "        ])\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "                nn.LayerNorm(d_model),\n",
    "                nn.Linear(d_model, d_model * 4),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(d_model * 4, d_model),\n",
    "                nn.Dropout(dropout)\n",
    "            )\n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, emb: torch.Tensor, times: torch.Tensor, mask: torch.BoolTensor = None):\n",
    "        # emb: [B, L, D], times: [B, L], mask: [B, L]\n",
    "        B, L, D = emb.shape\n",
    "        \n",
    "        positions = torch.arange(L, device=emb.device).unsqueeze(0).expand(B, -1)  # [B, L]\n",
    "        pe = self.pos_emb(positions)  # [B, L, D]\n",
    "        te = self.time_emb(times.unsqueeze(-1))  # [B, L, D]\n",
    "        x = emb + pe + te\n",
    "        \n",
    "        attn_out = torch.stack([head(x, times, mask) for head in self.heads], dim=0).sum(0)\n",
    "        \n",
    "        # Residual connection + normalization\n",
    "        x = x + attn_out\n",
    "        x = x + self.ffn(x)\n",
    "        \n",
    "        return self.final_norm(x)  # [B, L, D]\n",
    "\n",
    "class _THPHead(nn.Module):\n",
    "    def __init__(self, d_model: int, decay: float, window_size: int, dropout: float,\n",
    "                pos_lambda: float = None):\n",
    "        super().__init__()\n",
    "        self.linear_v = nn.Linear(d_model, d_model, bias=False)\n",
    "        nn.init.xavier_uniform_(self.linear_v.weight)\n",
    "        self.temperature = d_model ** 0.5\n",
    "        self.decay = decay\n",
    "        self.window_size = window_size\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.input_norm = nn.LayerNorm(d_model)\n",
    "        self.pos_lambda = pos_lambda or (1.0 / window_size)\n",
    "\n",
    "    def forward(self, emb: torch.Tensor, times: torch.Tensor, mask: torch.BoolTensor = None):\n",
    "        B, L, D = emb.size()\n",
    "        emb_norm = self.input_norm(emb)\n",
    "        q = emb_norm / self.temperature           # [B, L, D]\n",
    "        k = emb_norm                              # [B, L, D]\n",
    "        v = F.elu(self.linear_v(emb_norm))        # [B, L, D]\n",
    "\n",
    "        if not torch.isfinite(q).all():\n",
    "            print(\"NaN/Inf в q:\", torch.isnan(q).sum().item(), torch.isinf(q).sum().item())\n",
    "        if not torch.isfinite(k).all():\n",
    "            print(\"NaN/Inf в k:\", torch.isnan(k).sum().item(), torch.isinf(k).sum().item())\n",
    "        if not torch.isfinite(v).all():\n",
    "            print(\"NaN/Inf в v:\", torch.isnan(v).sum().item(), torch.isinf(v).sum().item())\n",
    "\n",
    "        # 3) Build pad mask only\n",
    "        if mask is not None:\n",
    "            pad_mask = ~mask.unsqueeze(1).expand(-1, L, -1)  # [B, L, L]\n",
    "        else:\n",
    "            pad_mask = torch.zeros((B, L, L), dtype=torch.bool, device=emb.device)\n",
    "\n",
    "        # Always allow self-attention for pad_mask diagonal\n",
    "        idx = torch.arange(L, device=emb.device)\n",
    "        pad_mask[:, idx, idx] = False\n",
    "\n",
    "        scores = torch.bmm(q, k.transpose(1, 2))  # [B, L, L]\n",
    "\n",
    "        # Apply temporal decay kernel\n",
    "        delta = (times.unsqueeze(-1) - times.unsqueeze(-2)).clamp(min=0)\n",
    "        scores = scores * torch.exp(-self.decay * delta)\n",
    "\n",
    "        # Apply smooth positional decay\n",
    "        dist = (idx.unsqueeze(0) - idx.unsqueeze(1)).abs().float()  # [L, L]\n",
    "        pos_decay = torch.exp(-self.pos_lambda * dist).unsqueeze(0)    # [1, L, L]\n",
    "        scores = scores * pos_decay\n",
    "\n",
    "        scores = torch.clamp(scores, min=-1e3, max=1e3)\n",
    "        scores = scores.masked_fill(pad_mask, float('-inf'))\n",
    "\n",
    "        # Debug range\n",
    "        finite = scores[~pad_mask]\n",
    "        # if finite.numel() > 0:\n",
    "        #     print(f\"Диапазон scores до softmax: min={finite.min().item():.3e}, max={finite.max().item():.3e}\")\n",
    "\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        if not torch.isfinite(attn).all():\n",
    "            print(\"NaN/Inf в attn после softmax:\", torch.isnan(attn).sum().item(), torch.isinf(attn).sum().item())\n",
    "        \n",
    "        attn = torch.nan_to_num(attn, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.bmm(attn, v)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:47.000538Z",
     "iopub.status.busy": "2025-06-24T18:34:47.000377Z",
     "iopub.status.idle": "2025-06-24T18:34:47.025246Z",
     "shell.execute_reply": "2025-06-24T18:34:47.024696Z",
     "shell.execute_reply.started": "2025-06-24T18:34:47.000526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HeteroGNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 feedback_types: list,\n",
    "                 emb_dim: int = 32,\n",
    "                 hidden_dim: int = 16,\n",
    "                 heads: int = 2,\n",
    "                 dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.feedback_types = feedback_types\n",
    "        self.pos_types = ['implicit_positive', 'explicit_positive']\n",
    "        self.neg_types = ['implicit_negative', 'expliсit_negative']\n",
    "\n",
    "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(num_items + 1, emb_dim, padding_idx=0)\n",
    "        self.fb_emb   = nn.ModuleDict({\n",
    "            ft: nn.Embedding(num_users, emb_dim) for ft in feedback_types\n",
    "        })\n",
    "\n",
    "        conv1, conv2 = {}, {}\n",
    "        for ft in feedback_types:\n",
    "            # ft -> user\n",
    "            conv1[(ft, f'{ft}2user', 'user')] = GATConv(emb_dim, hidden_dim,\n",
    "                                                      heads=heads,\n",
    "                                                      add_self_loops=False)\n",
    "            conv2[(ft, f'{ft}2user', 'user')] = GATConv(hidden_dim*heads, emb_dim,\n",
    "                                                      heads=1,\n",
    "                                                      add_self_loops=False)\n",
    "            # ft -> item\n",
    "            conv1[(ft, f'{ft}2item', 'item')] = GATConv(emb_dim, hidden_dim,\n",
    "                                                       heads=heads,\n",
    "                                                       add_self_loops=False)\n",
    "            conv2[(ft, f'{ft}2item', 'item')] = GATConv(hidden_dim*heads, emb_dim,\n",
    "                                                       heads=1,\n",
    "                                                       add_self_loops=False)\n",
    "\n",
    "            # item -> ft\n",
    "            conv1[('item', f'item2{ft}', ft)] = GATConv(emb_dim, hidden_dim,\n",
    "                                                       heads=heads,\n",
    "                                                       add_self_loops=False)\n",
    "            conv2[('item', f'item2{ft}', ft)] = GATConv(hidden_dim*heads, emb_dim,\n",
    "                                                       heads=1,\n",
    "                                                       add_self_loops=False)\n",
    "\n",
    "        self.conv1 = HeteroConv(conv1, aggr='mean')\n",
    "        self.conv2 = HeteroConv(conv2, aggr='mean')\n",
    "\n",
    "        # LayerNorm и Dropout\n",
    "        types = ['user', 'item'] + feedback_types\n",
    "        self.norm1 = nn.ModuleDict({t: nn.LayerNorm(hidden_dim*heads) for t in types})\n",
    "        self.norm2 = nn.ModuleDict({t: nn.LayerNorm(emb_dim) for t in types})\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = {\n",
    "            'user': self.user_emb(data['user'].node_id),\n",
    "            'item': self.item_emb(data['item'].node_id)\n",
    "        }\n",
    "        for ft in self.feedback_types:\n",
    "            x[ft] = self.fb_emb[ft](data[ft].node_id)\n",
    "\n",
    "        h1 = self.conv1(x, data.edge_index_dict)\n",
    "        for t, h in h1.items():\n",
    "            h1[t] = self.dropout(F.leaky_relu(self.norm1[t](h)))\n",
    "        # print(h1.keys())\n",
    "\n",
    "        h2 = self.conv2(h1, data.edge_index_dict)\n",
    "        # print(h2.keys())\n",
    "        out = {}\n",
    "        for t, h in h2.items():\n",
    "            out[t] = self.norm2[t](h)\n",
    "\n",
    "        # print(out.keys())\n",
    "            \n",
    "        return out['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:47.026161Z",
     "iopub.status.busy": "2025-06-24T18:34:47.025955Z",
     "iopub.status.idle": "2025-06-24T18:34:47.045129Z",
     "shell.execute_reply": "2025-06-24T18:34:47.044634Z",
     "shell.execute_reply.started": "2025-06-24T18:34:47.026139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 feedback_types: list,\n",
    "                 d_model: int = 32,\n",
    "                 n_head: int = 4,\n",
    "                 window_size: int = 50,\n",
    "                 decay: float = 1.0,\n",
    "                 dropout: float = 0.1,\n",
    "                 num_event_types: int = 2):\n",
    "        super().__init__()\n",
    "        # Static graph encoder\n",
    "        self.gnn = HeteroGNN(num_users, num_items, feedback_types,\n",
    "                                   emb_dim=d_model, hidden_dim=d_model//2,\n",
    "                                   heads=2, dropout=dropout)\n",
    "        # Inlined THP sequence encoder\n",
    "        self.thp = THPEncoder(d_model=d_model,\n",
    "                              n_head=n_head,\n",
    "                              window_size=window_size,\n",
    "                              decay=decay,\n",
    "                              dropout=dropout)\n",
    "        # 3) Multi‐task heads:\n",
    "        #   a) ranking: produce updated user embedding\n",
    "        #   b) classification: predict next event type\n",
    "        self.event_classifier = nn.Linear(d_model, num_event_types)\n",
    "\n",
    "    def forward(self, data, seq_ids, seq_times, seq_mask, batch_users):\n",
    "        # Static graph embeddings\n",
    "        user_embs = self.gnn(data)          # [num_users, d_model]\n",
    "        # Sequence encoding\n",
    "        seq_item_emb = self.gnn.item_emb(seq_ids)  # [B, L, d_model]\n",
    "        attn_out = self.thp(seq_item_emb, seq_times, seq_mask)\n",
    "        seq_rep = attn_out[:, -1, :]        # [B, d_model]\n",
    "        # Get static user embeddings\n",
    "        gnn_rep = user_embs[batch_users]   # [B, d_model]\n",
    "        # Updated user embedding\n",
    "        updated_user_emb = seq_rep + gnn_rep\n",
    "        event_logits = self.event_classifier(seq_rep)\n",
    "        return updated_user_emb, event_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:47.046640Z",
     "iopub.status.busy": "2025-06-24T18:34:47.045826Z",
     "iopub.status.idle": "2025-06-24T18:34:47.115874Z",
     "shell.execute_reply": "2025-06-24T18:34:47.115414Z",
     "shell.execute_reply.started": "2025-06-24T18:34:47.046617Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_users = data['user'].node_id.shape[0]      \n",
    "num_items = data['item'].node_id.shape[0]      \n",
    "feedback_types = train['target'].unique().tolist()\n",
    "data.user_idx = data['user'].node_id\n",
    "d_model = hyperparameters['thp_dmodel']             \n",
    "n_head = hyperparameters['thp_n_head']          \n",
    "window_size = hyperparameters['thp_window_size']     \n",
    "decay = hyperparameters['thp_decay']         \n",
    "dropout = hyperparameters['thp_dropout']       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:47.116686Z",
     "iopub.status.busy": "2025-06-24T18:34:47.116486Z",
     "iopub.status.idle": "2025-06-24T18:34:47.121436Z",
     "shell.execute_reply": "2025-06-24T18:34:47.120859Z",
     "shell.execute_reply.started": "2025-06-24T18:34:47.116671Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user_idx=[6040],\n",
       "  user={ node_id=[6040] },\n",
       "  item={ node_id=[3701] },\n",
       "  implicit_positive={ node_id=[6040] },\n",
       "  explicit_positive={ node_id=[6040] },\n",
       "  implicit_negative={ node_id=[6040] },\n",
       "  expliсit_negative={ node_id=[6040] },\n",
       "  (item, item2implicit_positive, implicit_positive)={ edge_index=[2, 327987] },\n",
       "  (implicit_positive, implicit_positive2item, item)={ edge_index=[2, 327987] },\n",
       "  (implicit_positive, implicit_positive2user, user)={ edge_index=[2, 327987] },\n",
       "  (item, item2explicit_positive, explicit_positive)={ edge_index=[2, 211802] },\n",
       "  (explicit_positive, explicit_positive2item, item)={ edge_index=[2, 211802] },\n",
       "  (explicit_positive, explicit_positive2user, user)={ edge_index=[2, 211802] },\n",
       "  (item, item2implicit_negative, implicit_negative)={ edge_index=[2, 246536] },\n",
       "  (implicit_negative, implicit_negative2item, item)={ edge_index=[2, 246536] },\n",
       "  (implicit_negative, implicit_negative2user, user)={ edge_index=[2, 246536] },\n",
       "  (item, item2expliсit_negative, expliсit_negative)={ edge_index=[2, 153484] },\n",
       "  (expliсit_negative, expliсit_negative2item, item)={ edge_index=[2, 153484] },\n",
       "  (expliсit_negative, expliсit_negative2user, user)={ edge_index=[2, 153484] }\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:47.122337Z",
     "iopub.status.busy": "2025-06-24T18:34:47.122079Z",
     "iopub.status.idle": "2025-06-24T18:34:49.152912Z",
     "shell.execute_reply": "2025-06-24T18:34:49.152127Z",
     "shell.execute_reply.started": "2025-06-24T18:34:47.122315Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6040, 64])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heterognn = HeteroGNN(num_users, num_items, feedback_types,\n",
    "                            emb_dim=d_model, hidden_dim=d_model//2,\n",
    "                            heads=2, dropout=dropout)\n",
    "output = heterognn(data)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:49.153948Z",
     "iopub.status.busy": "2025-06-24T18:34:49.153727Z",
     "iopub.status.idle": "2025-06-24T18:34:49.194096Z",
     "shell.execute_reply": "2025-06-24T18:34:49.193609Z",
     "shell.execute_reply.started": "2025-06-24T18:34:49.153931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    feedback_types=feedback_types,\n",
    "    d_model=d_model,\n",
    "    n_head=n_head,\n",
    "    window_size=window_size,\n",
    "    decay=decay,\n",
    "    dropout=dropout,\n",
    "    num_event_types=2\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:49.194939Z",
     "iopub.status.busy": "2025-06-24T18:34:49.194740Z",
     "iopub.status.idle": "2025-06-24T18:34:49.860586Z",
     "shell.execute_reply": "2025-06-24T18:34:49.859958Z",
     "shell.execute_reply.started": "2025-06-24T18:34:49.194924Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THPEncoder output shape: torch.Size([32, 101, 64])\n"
     ]
    }
   ],
   "source": [
    "B = 32\n",
    "seq_ids_batch   = seq_ids[:B]     # [B, L]\n",
    "seq_times_batch = seq_times[:B]   # [B, L]\n",
    "seq_mask_batch  = seq_mask[:B]    # [B, L]\n",
    "\n",
    "item_emb = model.gnn.item_emb \n",
    "d_model = item_emb.embedding_dim\n",
    "\n",
    "# Получаем seq_item_emb: [B, L, D]\n",
    "seq_item_emb = item_emb(seq_ids_batch)\n",
    "\n",
    "thp_encoder = THPEncoder(\n",
    "    d_model=d_model,\n",
    "    n_head=4,\n",
    "    window_size=50,\n",
    "    decay=1.0,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "thp_encoder.to(device)\n",
    "seq_item_emb   = seq_item_emb.to(device)\n",
    "seq_times_batch= seq_times_batch.to(device)\n",
    "seq_mask_batch = seq_mask_batch.to(device)\n",
    "\n",
    "out = thp_encoder(\n",
    "    emb=seq_item_emb,\n",
    "    times=seq_times_batch,\n",
    "    mask=seq_mask_batch\n",
    ")\n",
    "\n",
    "print(\"THPEncoder output shape:\", out.shape)  # ожидаем [B, L, D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:49.861459Z",
     "iopub.status.busy": "2025-06-24T18:34:49.861268Z",
     "iopub.status.idle": "2025-06-24T18:34:49.988102Z",
     "shell.execute_reply": "2025-06-24T18:34:49.987518Z",
     "shell.execute_reply.started": "2025-06-24T18:34:49.861445Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated user embeddings: torch.Size([32, 64]) torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "B = 32\n",
    "batch_seq_ids   = seq_ids[:B].to(device)    # [B, L]\n",
    "batch_seq_times = seq_times[:B].to(device)  # [B, L]\n",
    "batch_seq_mask  = seq_mask[:B].to(device)   # [B, L]\n",
    "\n",
    "# data.user_idx = data['user'].node_id[:B]\n",
    "batch_users = data.user_idx[:B].to(device)\n",
    "model.to(device)\n",
    "data.to(device)\n",
    "\n",
    "updated_user_emb = model(\n",
    "    data=data,\n",
    "    seq_ids=batch_seq_ids,\n",
    "    seq_times=batch_seq_times,\n",
    "    seq_mask=batch_seq_mask,\n",
    "    batch_users=batch_users\n",
    ")  # [B, d_model]\n",
    "\n",
    "print(\"Updated user embeddings:\", updated_user_emb[0].shape, updated_user_emb[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:49.989055Z",
     "iopub.status.busy": "2025-06-24T18:34:49.988803Z",
     "iopub.status.idle": "2025-06-24T18:34:50.007736Z",
     "shell.execute_reply": "2025-06-24T18:34:50.007165Z",
     "shell.execute_reply.started": "2025-06-24T18:34:49.989036Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3700, 1, 3700)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.item_id.nunique(), train.item_id.min(), train.item_id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:50.008772Z",
     "iopub.status.busy": "2025-06-24T18:34:50.008496Z",
     "iopub.status.idle": "2025-06-24T18:34:50.013652Z",
     "shell.execute_reply": "2025-06-24T18:34:50.013065Z",
     "shell.execute_reply.started": "2025-06-24T18:34:50.008750Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (gnn): HeteroGNN(\n",
       "    (user_emb): Embedding(6040, 64)\n",
       "    (item_emb): Embedding(3702, 64, padding_idx=0)\n",
       "    (fb_emb): ModuleDict(\n",
       "      (implicit_positive): Embedding(6040, 64)\n",
       "      (explicit_positive): Embedding(6040, 64)\n",
       "      (implicit_negative): Embedding(6040, 64)\n",
       "      (expliсit_negative): Embedding(6040, 64)\n",
       "    )\n",
       "    (conv1): HeteroConv(num_relations=12)\n",
       "    (conv2): HeteroConv(num_relations=12)\n",
       "    (norm1): ModuleDict(\n",
       "      (user): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (item): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_positive): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (explicit_positive): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_negative): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (expliсit_negative): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (norm2): ModuleDict(\n",
       "      (user): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (item): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_positive): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (explicit_positive): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_negative): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (expliсit_negative): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (thp): THPEncoder(\n",
       "    (pos_emb): Embedding(101, 64)\n",
       "    (time_emb): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (heads): ModuleList(\n",
       "      (0-3): 4 x _THPHead(\n",
       "        (linear_v): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (input_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ffn): Sequential(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=64, out_features=256, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (4): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (final_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (event_classifier): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:50.014676Z",
     "iopub.status.busy": "2025-06-24T18:34:50.014451Z",
     "iopub.status.idle": "2025-06-24T18:34:50.351014Z",
     "shell.execute_reply": "2025-06-24T18:34:50.350218Z",
     "shell.execute_reply.started": "2025-06-24T18:34:50.014661Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = test[['user_id', 'item_id']]\n",
    "interactions = test_df.rename(columns={\n",
    "    'user_id': Columns.User,\n",
    "    'item_id': Columns.Item,\n",
    "})\n",
    "\n",
    "viewed_items = train.groupby(\"user_id\")[\"item_id\"].agg(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:50.355618Z",
     "iopub.status.busy": "2025-06-24T18:34:50.355399Z",
     "iopub.status.idle": "2025-06-24T18:34:51.067415Z",
     "shell.execute_reply": "2025-06-24T18:34:51.066531Z",
     "shell.execute_reply.started": "2025-06-24T18:34:50.355602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "user2lists = {ft: defaultdict(list) for ft in feedback_types}\n",
    "\n",
    "for ft, sub in train.groupby('target'):\n",
    "    mapping = sub.groupby('user_id')['item_id'].apply(list)\n",
    "    for u, items in mapping.items():\n",
    "        user2lists[ft][u] = items\n",
    "\n",
    "user2explicit_pos = user2lists['explicit_positive']\n",
    "user2implicit_pos = user2lists['implicit_positive']\n",
    "user2explicit_neg = user2lists['expliсit_negative']\n",
    "user2implicit_neg = user2lists['implicit_negative']\n",
    "all_items_set = set(train.item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:51.068765Z",
     "iopub.status.busy": "2025-06-24T18:34:51.068539Z",
     "iopub.status.idle": "2025-06-24T18:34:51.080315Z",
     "shell.execute_reply": "2025-06-24T18:34:51.079645Z",
     "shell.execute_reply.started": "2025-06-24T18:34:51.068749Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, train_data, seq_train_data,\n",
    "             test_batch_size, top_k,\n",
    "             viewed_items, interactions,\n",
    "             device, test_step):\n",
    "    \"\"\"\n",
    "    Оцениваем модель по всем пользователям:\n",
    "    - строим топ-K рекомендации\n",
    "    - фильтруем уже просмотренные\n",
    "    - считаем recall@K, precision@K, map@K\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    seq_ids, event_type, seq_times, seq_mask = seq_train_data\n",
    "    num_users = seq_ids.size(0)\n",
    "    test_top_k = top_k * 150\n",
    "\n",
    "    item_emb = model.gnn.item_emb.weight\n",
    "    num_items = item_emb.shape[0]\n",
    "    item_emb_t = item_emb.t().detach()\n",
    "    del item_emb\n",
    "    gc.collect()\n",
    "\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_users, test_batch_size):\n",
    "            end = min(i + test_batch_size, num_users)\n",
    "            batch_users = torch.arange(i, end).to(device)\n",
    "            s_ids   = seq_ids[i:end].to(device)\n",
    "            s_times = seq_times[i:end].to(device)\n",
    "            s_mask  = seq_mask[i:end].to(device)\n",
    "            user_e, polar = model(\n",
    "                data=train_data.to(device),\n",
    "                seq_ids=s_ids,\n",
    "                seq_times=s_times,\n",
    "                seq_mask=s_mask,\n",
    "                batch_users=batch_users\n",
    "            )\n",
    "            rating = torch.mm(user_e.detach(), item_emb_t)\n",
    "            _, topk = torch.topk(rating, k=test_top_k, dim=1)\n",
    "            all_scores.append(topk)\n",
    "\n",
    "            del user_e, rating\n",
    "            gc.collect()\n",
    "    all_scores = torch.cat(all_scores, dim=0).cpu().numpy()\n",
    "\n",
    "    users_list, items, ranks = [], [], []\n",
    "    for u in range(num_users):\n",
    "        seen = viewed_items.get(u, set())\n",
    "        recs = all_scores[u]\n",
    "        mask = (\n",
    "            (~np.isin(recs, list(seen)))   \n",
    "            & (recs != 0)                  \n",
    "            & (recs != num_items - 1)     \n",
    "            )\n",
    "        filtered = recs[mask][:top_k]\n",
    "        for rank, it in enumerate(filtered, 1):\n",
    "            users_list.append(u)\n",
    "            items.append(int(it))\n",
    "            ranks.append(rank)\n",
    "    reco_df = pd.DataFrame({\n",
    "        'user_id': users_list,\n",
    "        'item_id': items,\n",
    "        'rank': ranks\n",
    "    })\n",
    "\n",
    "    metrics = {\n",
    "        f'map@{top_k}': MAP(k=top_k),\n",
    "        f'precision@{top_k}': Precision(k=top_k),\n",
    "        f'recall@{top_k}': Recall(k=top_k),\n",
    "        f'ndcg@{top_k}': NDCG(k=top_k)\n",
    "    }\n",
    "    results = calc_metrics(metrics=metrics,\n",
    "                           reco=reco_df,\n",
    "                           interactions=interactions)\n",
    "    print(f\"Step {test_step} — Test metrics:\")\n",
    "    for name, val in results.items():\n",
    "        print(f\"  {name}: {val:.9f}\")\n",
    "        experiment.log_metric(f\"Test {name} vs step\", val, step=test_step)\n",
    "    del all_scores\n",
    "    gc.collect()\n",
    "\n",
    "    model.to(device)\n",
    "    train_data.to(device)\n",
    "    model.train()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:51.081337Z",
     "iopub.status.busy": "2025-06-24T18:34:51.081087Z",
     "iopub.status.idle": "2025-06-24T18:34:51.109149Z",
     "shell.execute_reply": "2025-06-24T18:34:51.108343Z",
     "shell.execute_reply.started": "2025-06-24T18:34:51.081318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                train_data: HeteroData,\n",
    "                seq_train_data: tuple,\n",
    "                edge_type: tuple,\n",
    "                num_epochs: int = 10,\n",
    "                lr: float = 1e-3,\n",
    "                batch_size: int = 1024,\n",
    "                device: str = None,\n",
    "                print_every: int = 100,\n",
    "                test_every: int = 500,\n",
    "                top_k: int = 10,\n",
    "                test_batch_size=2048,\n",
    "                scheduler_step_size: int = 1,\n",
    "                scheduler_gamma: float = 0.9) -> Model:\n",
    "    seq_ids, event_type, seq_times, seq_mask = seq_train_data\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    train_data = train_data.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma)\n",
    "\n",
    "    if isinstance(edge_type, list):\n",
    "        src_list, dst_list = [], []\n",
    "        for et in edge_type:\n",
    "            # print(et, train_data[et])\n",
    "            s, d = train_data[et].edge_index\n",
    "            src_list.append(s)\n",
    "            dst_list.append(d)\n",
    "        src = torch.cat(src_list, dim=0)\n",
    "        dst = torch.cat(dst_list, dim=0)\n",
    "    else:\n",
    "        src, dst = train_data[edge_type].edge_index\n",
    "    \n",
    "    num_train = src.size(0)\n",
    "    test_top_k = top_k * 150\n",
    "    total_steps = 0\n",
    "    \n",
    "    print(f\"Num of training examples: {num_train}\")\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        perm = torch.randperm(num_train, device=device)\n",
    "        total_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        running_steps = 0\n",
    "        step = 0\n",
    "\n",
    "        for i in range(0, num_train, batch_size):\n",
    "            idx = perm[i:i + batch_size]\n",
    "            users = dst[idx]\n",
    "            cpu_users = users.to('cpu')\n",
    "\n",
    "            seq_ids_batch = seq_ids[cpu_users, :-1].to(device)\n",
    "            seq_times_batch = seq_times[cpu_users, :-1].to(device)\n",
    "            seq_mask_batch = seq_mask[cpu_users, :-1].to(device)\n",
    "            true_evt  = event_type[cpu_users, -1].to(device)\n",
    "            \n",
    "            pos_items = src[idx]\n",
    "            neg_items = torch.randint(1, model.gnn.item_emb.num_embeddings - 1,\n",
    "                                      size=pos_items.size(), device=device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            user_embs, event_logits = model(data=train_data, \n",
    "                              seq_ids=seq_ids_batch,\n",
    "                              seq_times=seq_times_batch,\n",
    "                              seq_mask=seq_mask_batch,\n",
    "                              batch_users=users)\n",
    "            \n",
    "            pos_emb = model.gnn.item_emb(pos_items)\n",
    "            neg_emb = model.gnn.item_emb(neg_items)\n",
    "            pos_score = (user_embs * pos_emb).sum(dim=1)\n",
    "            neg_score = (user_embs * neg_emb).sum(dim=1)\n",
    "            diff = pos_score - neg_score\n",
    "            diff = torch.clamp(diff, -10.0, 10.0)\n",
    "            ce_loss = F.cross_entropy(event_logits, true_evt)\n",
    "            bpr_loss = -torch.log(torch.sigmoid(diff) + 1e-15).mean()\n",
    "\n",
    "            loss = bpr_loss + ce_loss\n",
    "            \n",
    "            nan_mask = torch.isnan(diff)            \n",
    "            if nan_mask.any():\n",
    "                idxs = torch.nonzero(nan_mask).squeeze()\n",
    "                print(f\"!!! FOUND {nan_mask.sum().item()} NaN(s) in diff at positions: {idxs.tolist()}\")\n",
    "\n",
    "            # with torch.autograd.detect_anomaly():\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            running_loss += loss.item()\n",
    "            running_steps += 1\n",
    "            step += 1\n",
    "\n",
    "            experiment.log_metric('Train Loss vs step', loss.item(), step=total_steps)\n",
    "            experiment.log_metric('Train CE Loss vs step', ce_loss.item(), step=total_steps)\n",
    "            experiment.log_metric('Train BPR Loss vs step', bpr_loss.item(), step=total_steps)\n",
    "            \n",
    "            if step % print_every == 0 or step == 1:\n",
    "                avg_loss = running_loss / running_steps\n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                d = diff.detach().cpu()\n",
    "                print(f\"Epoch {epoch}, Step {step}, LR: {current_lr:.6f}, Current Loss: {loss.item():.4f}, Avg Loss: {avg_loss:.4f}\")\n",
    "                print(f\"Diff stats — min: {d.min():.4f}, max: {d.max():.4f}, mean: {d.mean():.4f}, std: {d.std():.4f}\")\n",
    "                print()\n",
    "\n",
    "                experiment.log_metric('Diff stats (mean) vs step', d.mean(), step=total_steps)\n",
    "                experiment.log_metric('Diff stats (std) vs step', d.std(), step=total_steps)\n",
    "\n",
    "            del user_embs, pos_emb, neg_emb, pos_score, neg_score,\\\n",
    "            seq_ids_batch, seq_times_batch, seq_mask_batch\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            scheduler.step()\n",
    "            \n",
    "            if step % test_every == 0 or step == 1:\n",
    "                evaluate(model, train_data, seq_train_data,\n",
    "                         test_batch_size, top_k,\n",
    "                         viewed_items, interactions,\n",
    "                         device, test_step=total_steps)\n",
    "\n",
    "            total_steps += 1\n",
    "        epoch_loss = total_loss / num_train\n",
    "        experiment.log_metric(f'Train Loss vs epoch', epoch_loss, epoch=epoch)\n",
    "        print(f\"Epoch {epoch} completed, Train Loss: {epoch_loss:.6f}\")\n",
    "        print()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:51.110131Z",
     "iopub.status.busy": "2025-06-24T18:34:51.109882Z",
     "iopub.status.idle": "2025-06-24T18:34:51.315385Z",
     "shell.execute_reply": "2025-06-24T18:34:51.314691Z",
     "shell.execute_reply.started": "2025-06-24T18:34:51.110103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "experiment.log_parameters(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:51.316441Z",
     "iopub.status.busy": "2025-06-24T18:34:51.316188Z",
     "iopub.status.idle": "2025-06-24T18:34:51.320734Z",
     "shell.execute_reply": "2025-06-24T18:34:51.319902Z",
     "shell.execute_reply.started": "2025-06-24T18:34:51.316422Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:34:51.321752Z",
     "iopub.status.busy": "2025-06-24T18:34:51.321498Z",
     "iopub.status.idle": "2025-06-24T19:46:33.826251Z",
     "shell.execute_reply": "2025-06-24T19:46:33.825082Z",
     "shell.execute_reply.started": "2025-06-24T18:34:51.321727Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training examples: 539789\n",
      "Epoch 1, Step 1, LR: 0.001000, Current Loss: 4.5596, Avg Loss: 4.5596\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: -0.0560, std: 8.2436\n",
      "\n",
      "Step 0 — Test metrics:\n",
      "  precision@10: 0.003509934\n",
      "  recall@10: 0.003509934\n",
      "  ndcg@10: 0.003835959\n",
      "  map@10: 0.001216664\n",
      "Epoch 1, Step 20, LR: 0.001000, Current Loss: 3.3900, Avg Loss: 4.0268\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 0.6743, std: 6.8169\n",
      "\n",
      "Epoch 1, Step 40, LR: 0.001000, Current Loss: 2.2354, Avg Loss: 3.4013\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 0.2593, std: 3.8161\n",
      "\n",
      "Step 49 — Test metrics:\n",
      "  precision@10: 0.003377483\n",
      "  recall@10: 0.003377483\n",
      "  ndcg@10: 0.003383516\n",
      "  map@10: 0.001010604\n",
      "Epoch 1, Step 60, LR: 0.001000, Current Loss: 1.8124, Avg Loss: 2.9256\n",
      "Diff stats — min: -9.6978, max: 10.0000, mean: 0.1663, std: 2.4972\n",
      "\n",
      "Epoch 1, Step 80, LR: 0.001000, Current Loss: 1.6255, Avg Loss: 2.6227\n",
      "Diff stats — min: -7.8397, max: 10.0000, mean: 0.2110, std: 1.9630\n",
      "\n",
      "Epoch 1, Step 100, LR: 0.001000, Current Loss: 1.5732, Avg Loss: 2.4210\n",
      "Diff stats — min: -7.7205, max: 9.6085, mean: 0.1814, std: 1.7154\n",
      "\n",
      "Step 99 — Test metrics:\n",
      "  precision@10: 0.004254967\n",
      "  recall@10: 0.004254967\n",
      "  ndcg@10: 0.004215515\n",
      "  map@10: 0.001235415\n",
      "Epoch 1, Step 120, LR: 0.001000, Current Loss: 1.5365, Avg Loss: 2.2767\n",
      "Diff stats — min: -6.5170, max: 8.8363, mean: 0.1982, std: 1.6107\n",
      "\n",
      "Epoch 1 completed, Train Loss: 0.000540\n",
      "\n",
      "Epoch 2, Step 1, LR: 0.001000, Current Loss: 1.4798, Avg Loss: 1.4798\n",
      "Diff stats — min: -7.6813, max: 6.5550, mean: 0.2525, std: 1.4999\n",
      "\n",
      "Step 132 — Test metrics:\n",
      "  precision@10: 0.004867550\n",
      "  recall@10: 0.004867550\n",
      "  ndcg@10: 0.004707642\n",
      "  map@10: 0.001353917\n",
      "Epoch 2, Step 20, LR: 0.000980, Current Loss: 1.4784, Avg Loss: 1.4893\n",
      "Diff stats — min: -5.4359, max: 5.6606, mean: 0.2155, std: 1.4318\n",
      "\n",
      "Epoch 2, Step 40, LR: 0.000980, Current Loss: 1.4322, Avg Loss: 1.4755\n",
      "Diff stats — min: -6.2724, max: 6.9680, mean: 0.2742, std: 1.3492\n",
      "\n",
      "Step 181 — Test metrics:\n",
      "  precision@10: 0.005860927\n",
      "  recall@10: 0.005860927\n",
      "  ndcg@10: 0.005875555\n",
      "  map@10: 0.001742760\n",
      "Epoch 2, Step 60, LR: 0.000980, Current Loss: 1.4253, Avg Loss: 1.4645\n",
      "Diff stats — min: -5.9804, max: 7.9686, mean: 0.2756, std: 1.3130\n",
      "\n",
      "Epoch 2, Step 80, LR: 0.000980, Current Loss: 1.4057, Avg Loss: 1.4541\n",
      "Diff stats — min: -6.0530, max: 6.2977, mean: 0.3002, std: 1.2818\n",
      "\n",
      "Epoch 2, Step 100, LR: 0.000980, Current Loss: 1.3995, Avg Loss: 1.4448\n",
      "Diff stats — min: -4.7869, max: 6.9350, mean: 0.3125, std: 1.2853\n",
      "\n",
      "Step 231 — Test metrics:\n",
      "  precision@10: 0.006109272\n",
      "  recall@10: 0.006109272\n",
      "  ndcg@10: 0.005954018\n",
      "  map@10: 0.001726138\n",
      "Epoch 2, Step 120, LR: 0.000980, Current Loss: 1.3559, Avg Loss: 1.4357\n",
      "Diff stats — min: -5.0962, max: 6.5825, mean: 0.3964, std: 1.2392\n",
      "\n",
      "Epoch 2 completed, Train Loss: 0.000350\n",
      "\n",
      "Epoch 3, Step 1, LR: 0.000980, Current Loss: 1.3794, Avg Loss: 1.3794\n",
      "Diff stats — min: -4.9800, max: 5.9313, mean: 0.3666, std: 1.2836\n",
      "\n",
      "Step 264 — Test metrics:\n",
      "  precision@10: 0.007185430\n",
      "  recall@10: 0.007185430\n",
      "  ndcg@10: 0.007019182\n",
      "  map@10: 0.002044308\n",
      "Epoch 3, Step 20, LR: 0.000980, Current Loss: 1.3533, Avg Loss: 1.3674\n",
      "Diff stats — min: -4.2170, max: 5.9633, mean: 0.4173, std: 1.2492\n",
      "\n",
      "Epoch 3, Step 40, LR: 0.000960, Current Loss: 1.3354, Avg Loss: 1.3596\n",
      "Diff stats — min: -5.2798, max: 5.4525, mean: 0.4609, std: 1.2653\n",
      "\n",
      "Step 313 — Test metrics:\n",
      "  precision@10: 0.007847682\n",
      "  recall@10: 0.007847682\n",
      "  ndcg@10: 0.007908538\n",
      "  map@10: 0.002360848\n",
      "Epoch 3, Step 60, LR: 0.000960, Current Loss: 1.3408, Avg Loss: 1.3516\n",
      "Diff stats — min: -4.3486, max: 5.4337, mean: 0.4712, std: 1.3076\n",
      "\n",
      "Epoch 3, Step 80, LR: 0.000960, Current Loss: 1.3322, Avg Loss: 1.3439\n",
      "Diff stats — min: -4.2139, max: 6.0056, mean: 0.5058, std: 1.3312\n",
      "\n",
      "Epoch 3, Step 100, LR: 0.000960, Current Loss: 1.2999, Avg Loss: 1.3360\n",
      "Diff stats — min: -4.5174, max: 6.3578, mean: 0.6339, std: 1.3903\n",
      "\n",
      "Step 363 — Test metrics:\n",
      "  precision@10: 0.008791391\n",
      "  recall@10: 0.008791391\n",
      "  ndcg@10: 0.008973234\n",
      "  map@10: 0.002715692\n",
      "Epoch 3, Step 120, LR: 0.000960, Current Loss: 1.2885, Avg Loss: 1.3287\n",
      "Diff stats — min: -4.5334, max: 7.1609, mean: 0.6601, std: 1.4069\n",
      "\n",
      "Epoch 3 completed, Train Loss: 0.000324\n",
      "\n",
      "Epoch 4, Step 1, LR: 0.000960, Current Loss: 1.2824, Avg Loss: 1.2824\n",
      "Diff stats — min: -4.8946, max: 6.2569, mean: 0.6825, std: 1.4016\n",
      "\n",
      "Step 396 — Test metrics:\n",
      "  precision@10: 0.011109272\n",
      "  recall@10: 0.011109272\n",
      "  ndcg@10: 0.011337255\n",
      "  map@10: 0.003458734\n",
      "Epoch 4, Step 20, LR: 0.000960, Current Loss: 1.2512, Avg Loss: 1.2678\n",
      "Diff stats — min: -4.7752, max: 6.5690, mean: 0.7941, std: 1.4591\n",
      "\n",
      "Epoch 4, Step 40, LR: 0.000960, Current Loss: 1.2430, Avg Loss: 1.2565\n",
      "Diff stats — min: -4.1739, max: 7.0840, mean: 0.8935, std: 1.5534\n",
      "\n",
      "Step 445 — Test metrics:\n",
      "  precision@10: 0.013443709\n",
      "  recall@10: 0.013445548\n",
      "  ndcg@10: 0.014651337\n",
      "  map@10: 0.004779059\n",
      "Epoch 4, Step 60, LR: 0.000941, Current Loss: 1.2346, Avg Loss: 1.2486\n",
      "Diff stats — min: -4.8549, max: 7.3565, mean: 0.9299, std: 1.5649\n",
      "\n",
      "Epoch 4, Step 80, LR: 0.000941, Current Loss: 1.2116, Avg Loss: 1.2401\n",
      "Diff stats — min: -4.6025, max: 7.5457, mean: 1.0529, std: 1.6481\n",
      "\n",
      "Epoch 4, Step 100, LR: 0.000941, Current Loss: 1.2020, Avg Loss: 1.2325\n",
      "Diff stats — min: -4.9270, max: 7.4726, mean: 1.0980, std: 1.6548\n",
      "\n",
      "Step 495 — Test metrics:\n",
      "  precision@10: 0.016655629\n",
      "  recall@10: 0.016657469\n",
      "  ndcg@10: 0.017560704\n",
      "  map@10: 0.005617051\n",
      "Epoch 4, Step 120, LR: 0.000941, Current Loss: 1.1697, Avg Loss: 1.2248\n",
      "Diff stats — min: -4.4899, max: 8.3447, mean: 1.1774, std: 1.6560\n",
      "\n",
      "Epoch 4 completed, Train Loss: 0.000298\n",
      "\n",
      "Epoch 5, Step 1, LR: 0.000941, Current Loss: 1.1686, Avg Loss: 1.1686\n",
      "Diff stats — min: -4.6351, max: 7.4006, mean: 1.2145, std: 1.6817\n",
      "\n",
      "Step 528 — Test metrics:\n",
      "  precision@10: 0.018460265\n",
      "  recall@10: 0.018462104\n",
      "  ndcg@10: 0.019203840\n",
      "  map@10: 0.006130398\n",
      "Epoch 5, Step 20, LR: 0.000941, Current Loss: 1.1519, Avg Loss: 1.1653\n",
      "Diff stats — min: -4.6162, max: 7.1058, mean: 1.3255, std: 1.7587\n",
      "\n",
      "Epoch 5, Step 40, LR: 0.000941, Current Loss: 1.1393, Avg Loss: 1.1572\n",
      "Diff stats — min: -4.8368, max: 10.0000, mean: 1.4255, std: 1.8128\n",
      "\n",
      "Step 577 — Test metrics:\n",
      "  precision@10: 0.022533113\n",
      "  recall@10: 0.022534952\n",
      "  ndcg@10: 0.023211811\n",
      "  map@10: 0.007397962\n",
      "Epoch 5, Step 60, LR: 0.000941, Current Loss: 1.1340, Avg Loss: 1.1499\n",
      "Diff stats — min: -5.0621, max: 8.3865, mean: 1.4820, std: 1.8439\n",
      "\n",
      "Epoch 5, Step 80, LR: 0.000922, Current Loss: 1.1155, Avg Loss: 1.1442\n",
      "Diff stats — min: -6.9424, max: 8.4531, mean: 1.5605, std: 1.8648\n",
      "\n",
      "Epoch 5, Step 100, LR: 0.000922, Current Loss: 1.1053, Avg Loss: 1.1380\n",
      "Diff stats — min: -6.5999, max: 8.7724, mean: 1.6056, std: 1.8960\n",
      "\n",
      "Step 627 — Test metrics:\n",
      "  precision@10: 0.024122517\n",
      "  recall@10: 0.024124356\n",
      "  ndcg@10: 0.025049266\n",
      "  map@10: 0.008144011\n",
      "Epoch 5, Step 120, LR: 0.000922, Current Loss: 1.1089, Avg Loss: 1.1325\n",
      "Diff stats — min: -6.6514, max: 9.2534, mean: 1.6528, std: 1.9358\n",
      "\n",
      "Epoch 5 completed, Train Loss: 0.000276\n",
      "\n",
      "Epoch 6, Step 1, LR: 0.000922, Current Loss: 1.1112, Avg Loss: 1.1112\n",
      "Diff stats — min: -4.6620, max: 8.7212, mean: 1.6670, std: 1.9726\n",
      "\n",
      "Step 660 — Test metrics:\n",
      "  precision@10: 0.025960265\n",
      "  recall@10: 0.025962104\n",
      "  ndcg@10: 0.027552367\n",
      "  map@10: 0.009212308\n",
      "Epoch 6, Step 20, LR: 0.000922, Current Loss: 1.1099, Avg Loss: 1.0921\n",
      "Diff stats — min: -5.4768, max: 9.1573, mean: 1.7385, std: 2.0272\n",
      "\n",
      "Epoch 6, Step 40, LR: 0.000922, Current Loss: 1.0833, Avg Loss: 1.0845\n",
      "Diff stats — min: -4.4618, max: 9.0988, mean: 1.8518, std: 2.0254\n",
      "\n",
      "Step 709 — Test metrics:\n",
      "  precision@10: 0.028245033\n",
      "  recall@10: 0.028246873\n",
      "  ndcg@10: 0.029234651\n",
      "  map@10: 0.009684673\n",
      "Epoch 6, Step 60, LR: 0.000922, Current Loss: 1.0927, Avg Loss: 1.0815\n",
      "Diff stats — min: -5.8011, max: 8.4758, mean: 1.8336, std: 2.0508\n",
      "\n",
      "Epoch 6, Step 80, LR: 0.000922, Current Loss: 1.0688, Avg Loss: 1.0785\n",
      "Diff stats — min: -6.1470, max: 9.2377, mean: 1.8789, std: 2.0131\n",
      "\n",
      "Epoch 6, Step 100, LR: 0.000904, Current Loss: 1.0633, Avg Loss: 1.0752\n",
      "Diff stats — min: -6.7213, max: 9.3012, mean: 1.9802, std: 2.0652\n",
      "\n",
      "Step 759 — Test metrics:\n",
      "  precision@10: 0.029801325\n",
      "  recall@10: 0.029803164\n",
      "  ndcg@10: 0.032218797\n",
      "  map@10: 0.011180619\n",
      "Epoch 6, Step 120, LR: 0.000904, Current Loss: 1.0627, Avg Loss: 1.0714\n",
      "Diff stats — min: -6.0573, max: 10.0000, mean: 2.0500, std: 2.1271\n",
      "\n",
      "Epoch 6 completed, Train Loss: 0.000262\n",
      "\n",
      "Epoch 7, Step 1, LR: 0.000904, Current Loss: 1.0427, Avg Loss: 1.0427\n",
      "Diff stats — min: -6.4715, max: 10.0000, mean: 2.0836, std: 2.1040\n",
      "\n",
      "Step 792 — Test metrics:\n",
      "  precision@10: 0.030298013\n",
      "  recall@10: 0.030299853\n",
      "  ndcg@10: 0.032651336\n",
      "  map@10: 0.011372024\n",
      "Epoch 7, Step 20, LR: 0.000904, Current Loss: 1.0416, Avg Loss: 1.0477\n",
      "Diff stats — min: -6.6299, max: 10.0000, mean: 2.0770, std: 2.0815\n",
      "\n",
      "Epoch 7, Step 40, LR: 0.000904, Current Loss: 1.0454, Avg Loss: 1.0457\n",
      "Diff stats — min: -5.3118, max: 9.0556, mean: 2.0810, std: 2.1096\n",
      "\n",
      "Step 841 — Test metrics:\n",
      "  precision@10: 0.031274834\n",
      "  recall@10: 0.031276674\n",
      "  ndcg@10: 0.033877874\n",
      "  map@10: 0.011968649\n",
      "Epoch 7, Step 60, LR: 0.000904, Current Loss: 1.0536, Avg Loss: 1.0436\n",
      "Diff stats — min: -7.5004, max: 10.0000, mean: 2.1111, std: 2.1675\n",
      "\n",
      "Epoch 7, Step 80, LR: 0.000904, Current Loss: 1.0379, Avg Loss: 1.0427\n",
      "Diff stats — min: -5.0324, max: 10.0000, mean: 2.1303, std: 2.1078\n",
      "\n",
      "Epoch 7, Step 100, LR: 0.000904, Current Loss: 1.0444, Avg Loss: 1.0412\n",
      "Diff stats — min: -6.1159, max: 9.8574, mean: 2.1702, std: 2.1654\n",
      "\n",
      "Step 891 — Test metrics:\n",
      "  precision@10: 0.033261589\n",
      "  recall@10: 0.033263429\n",
      "  ndcg@10: 0.036010004\n",
      "  map@10: 0.012840779\n",
      "Epoch 7, Step 120, LR: 0.000886, Current Loss: 1.0466, Avg Loss: 1.0396\n",
      "Diff stats — min: -5.8436, max: 10.0000, mean: 2.1871, std: 2.2091\n",
      "\n",
      "Epoch 7 completed, Train Loss: 0.000254\n",
      "\n",
      "Epoch 8, Step 1, LR: 0.000886, Current Loss: 1.0547, Avg Loss: 1.0547\n",
      "Diff stats — min: -6.9356, max: 10.0000, mean: 2.1334, std: 2.1820\n",
      "\n",
      "Step 924 — Test metrics:\n",
      "  precision@10: 0.034586093\n",
      "  recall@10: 0.034587932\n",
      "  ndcg@10: 0.036715737\n",
      "  map@10: 0.012884310\n",
      "Epoch 8, Step 20, LR: 0.000886, Current Loss: 1.0170, Avg Loss: 1.0302\n",
      "Diff stats — min: -4.8928, max: 10.0000, mean: 2.2376, std: 2.1211\n",
      "\n",
      "Epoch 8, Step 40, LR: 0.000886, Current Loss: 1.0132, Avg Loss: 1.0270\n",
      "Diff stats — min: -5.0142, max: 10.0000, mean: 2.3060, std: 2.1614\n",
      "\n",
      "Step 973 — Test metrics:\n",
      "  precision@10: 0.035480132\n",
      "  recall@10: 0.035481972\n",
      "  ndcg@10: 0.037565691\n",
      "  map@10: 0.013422008\n",
      "Epoch 8, Step 60, LR: 0.000886, Current Loss: 1.0090, Avg Loss: 1.0239\n",
      "Diff stats — min: -7.1728, max: 10.0000, mean: 2.3401, std: 2.1828\n",
      "\n",
      "Epoch 8, Step 80, LR: 0.000886, Current Loss: 1.0131, Avg Loss: 1.0229\n",
      "Diff stats — min: -5.5713, max: 9.7626, mean: 2.3322, std: 2.1888\n",
      "\n",
      "Epoch 8, Step 100, LR: 0.000886, Current Loss: 1.0208, Avg Loss: 1.0211\n",
      "Diff stats — min: -6.5361, max: 9.6809, mean: 2.2975, std: 2.2021\n",
      "\n",
      "Step 1023 — Test metrics:\n",
      "  precision@10: 0.035860927\n",
      "  recall@10: 0.035862767\n",
      "  ndcg@10: 0.038172502\n",
      "  map@10: 0.013575447\n",
      "Epoch 8, Step 120, LR: 0.000886, Current Loss: 1.0109, Avg Loss: 1.0205\n",
      "Diff stats — min: -6.2078, max: 10.0000, mean: 2.3681, std: 2.2201\n",
      "\n",
      "Epoch 8 completed, Train Loss: 0.000249\n",
      "\n",
      "Epoch 9, Step 1, LR: 0.000868, Current Loss: 1.0131, Avg Loss: 1.0131\n",
      "Diff stats — min: -5.1532, max: 10.0000, mean: 2.3566, std: 2.2308\n",
      "\n",
      "Step 1056 — Test metrics:\n",
      "  precision@10: 0.036009934\n",
      "  recall@10: 0.036011773\n",
      "  ndcg@10: 0.038447163\n",
      "  map@10: 0.013805400\n",
      "Epoch 9, Step 20, LR: 0.000868, Current Loss: 1.0120, Avg Loss: 1.0146\n",
      "Diff stats — min: -5.3507, max: 9.6822, mean: 2.3433, std: 2.1901\n",
      "\n",
      "Epoch 9, Step 40, LR: 0.000868, Current Loss: 1.0108, Avg Loss: 1.0142\n",
      "Diff stats — min: -4.8446, max: 10.0000, mean: 2.3595, std: 2.2095\n",
      "\n",
      "Step 1105 — Test metrics:\n",
      "  precision@10: 0.036125828\n",
      "  recall@10: 0.036127667\n",
      "  ndcg@10: 0.038284899\n",
      "  map@10: 0.013624387\n",
      "Epoch 9, Step 60, LR: 0.000868, Current Loss: 0.9956, Avg Loss: 1.0133\n",
      "Diff stats — min: -5.7739, max: 10.0000, mean: 2.4297, std: 2.2460\n",
      "\n",
      "Epoch 9, Step 80, LR: 0.000868, Current Loss: 1.0107, Avg Loss: 1.0128\n",
      "Diff stats — min: -5.4273, max: 10.0000, mean: 2.4091, std: 2.2809\n",
      "\n",
      "Epoch 9, Step 100, LR: 0.000868, Current Loss: 1.0249, Avg Loss: 1.0115\n",
      "Diff stats — min: -4.8256, max: 10.0000, mean: 2.4433, std: 2.3407\n",
      "\n",
      "Step 1155 — Test metrics:\n",
      "  precision@10: 0.036026490\n",
      "  recall@10: 0.036028330\n",
      "  ndcg@10: 0.038157969\n",
      "  map@10: 0.013696242\n",
      "Epoch 9, Step 120, LR: 0.000868, Current Loss: 0.9889, Avg Loss: 1.0110\n",
      "Diff stats — min: -5.3169, max: 10.0000, mean: 2.4864, std: 2.2631\n",
      "\n",
      "Epoch 9 completed, Train Loss: 0.000247\n",
      "\n",
      "Epoch 10, Step 1, LR: 0.000868, Current Loss: 1.0093, Avg Loss: 1.0093\n",
      "Diff stats — min: -6.1925, max: 10.0000, mean: 2.4036, std: 2.2640\n",
      "\n",
      "Step 1188 — Test metrics:\n",
      "  precision@10: 0.036639073\n",
      "  recall@10: 0.036640912\n",
      "  ndcg@10: 0.038649576\n",
      "  map@10: 0.013858293\n",
      "Epoch 10, Step 20, LR: 0.000851, Current Loss: 1.0046, Avg Loss: 1.0047\n",
      "Diff stats — min: -5.0297, max: 10.0000, mean: 2.4307, std: 2.2789\n",
      "\n",
      "Epoch 10, Step 40, LR: 0.000851, Current Loss: 1.0027, Avg Loss: 1.0055\n",
      "Diff stats — min: -4.7334, max: 10.0000, mean: 2.4813, std: 2.3383\n",
      "\n",
      "Step 1237 — Test metrics:\n",
      "  precision@10: 0.036109272\n",
      "  recall@10: 0.036111111\n",
      "  ndcg@10: 0.038174522\n",
      "  map@10: 0.013684103\n",
      "Epoch 10, Step 60, LR: 0.000851, Current Loss: 1.0064, Avg Loss: 1.0051\n",
      "Diff stats — min: -4.6267, max: 9.9621, mean: 2.4682, std: 2.3132\n",
      "\n",
      "Epoch 10, Step 80, LR: 0.000851, Current Loss: 1.0019, Avg Loss: 1.0044\n",
      "Diff stats — min: -6.2157, max: 10.0000, mean: 2.5139, std: 2.3440\n",
      "\n",
      "Epoch 10, Step 100, LR: 0.000851, Current Loss: 1.0057, Avg Loss: 1.0039\n",
      "Diff stats — min: -5.9082, max: 10.0000, mean: 2.5179, std: 2.3840\n",
      "\n",
      "Step 1287 — Test metrics:\n",
      "  precision@10: 0.035711921\n",
      "  recall@10: 0.035713760\n",
      "  ndcg@10: 0.037104206\n",
      "  map@10: 0.013178648\n",
      "Epoch 10, Step 120, LR: 0.000851, Current Loss: 0.9971, Avg Loss: 1.0032\n",
      "Diff stats — min: -5.4183, max: 10.0000, mean: 2.5206, std: 2.3207\n",
      "\n",
      "Epoch 10 completed, Train Loss: 0.000245\n",
      "\n",
      "Epoch 11, Step 1, LR: 0.000851, Current Loss: 0.9979, Avg Loss: 0.9979\n",
      "Diff stats — min: -5.2827, max: 10.0000, mean: 2.5115, std: 2.3552\n",
      "\n",
      "Step 1320 — Test metrics:\n",
      "  precision@10: 0.035678808\n",
      "  recall@10: 0.035680648\n",
      "  ndcg@10: 0.037585971\n",
      "  map@10: 0.013417154\n",
      "Epoch 11, Step 20, LR: 0.000851, Current Loss: 1.0065, Avg Loss: 1.0006\n",
      "Diff stats — min: -4.4690, max: 10.0000, mean: 2.5481, std: 2.3985\n",
      "\n",
      "Epoch 11, Step 40, LR: 0.000834, Current Loss: 0.9973, Avg Loss: 1.0003\n",
      "Diff stats — min: -4.9959, max: 10.0000, mean: 2.5496, std: 2.3837\n",
      "\n",
      "Step 1369 — Test metrics:\n",
      "  precision@10: 0.036175497\n",
      "  recall@10: 0.036177336\n",
      "  ndcg@10: 0.037447877\n",
      "  map@10: 0.013339089\n",
      "Epoch 11, Step 60, LR: 0.000834, Current Loss: 1.0056, Avg Loss: 1.0009\n",
      "Diff stats — min: -4.8746, max: 10.0000, mean: 2.5623, std: 2.4022\n",
      "\n",
      "Epoch 11, Step 80, LR: 0.000834, Current Loss: 0.9936, Avg Loss: 1.0002\n",
      "Diff stats — min: -5.0727, max: 10.0000, mean: 2.5529, std: 2.3735\n",
      "\n",
      "Epoch 11, Step 100, LR: 0.000834, Current Loss: 0.9904, Avg Loss: 0.9998\n",
      "Diff stats — min: -6.2499, max: 10.0000, mean: 2.5794, std: 2.4003\n",
      "\n",
      "Step 1419 — Test metrics:\n",
      "  precision@10: 0.036258278\n",
      "  recall@10: 0.036260118\n",
      "  ndcg@10: 0.037815192\n",
      "  map@10: 0.013491979\n",
      "Epoch 11, Step 120, LR: 0.000834, Current Loss: 0.9895, Avg Loss: 0.9994\n",
      "Diff stats — min: -5.3599, max: 10.0000, mean: 2.5497, std: 2.3658\n",
      "\n",
      "Epoch 11 completed, Train Loss: 0.000244\n",
      "\n",
      "Epoch 12, Step 1, LR: 0.000834, Current Loss: 0.9789, Avg Loss: 0.9789\n",
      "Diff stats — min: -5.3587, max: 10.0000, mean: 2.6486, std: 2.4055\n",
      "\n",
      "Step 1452 — Test metrics:\n",
      "  precision@10: 0.035877483\n",
      "  recall@10: 0.035879323\n",
      "  ndcg@10: 0.037115221\n",
      "  map@10: 0.013069911\n",
      "Epoch 12, Step 20, LR: 0.000834, Current Loss: 1.0170, Avg Loss: 0.9946\n",
      "Diff stats — min: -7.8144, max: 10.0000, mean: 2.5536, std: 2.4700\n",
      "\n",
      "Epoch 12, Step 40, LR: 0.000834, Current Loss: 0.9892, Avg Loss: 0.9945\n",
      "Diff stats — min: -5.7590, max: 10.0000, mean: 2.6298, std: 2.4228\n",
      "\n",
      "Epoch 12, Step 60, LR: 0.000817, Current Loss: 1.0064, Avg Loss: 0.9951\n",
      "Diff stats — min: -5.0975, max: 10.0000, mean: 2.5816, std: 2.4310\n",
      "\n",
      "Epoch 12, Step 80, LR: 0.000817, Current Loss: 1.0002, Avg Loss: 0.9946\n",
      "Diff stats — min: -5.3294, max: 10.0000, mean: 2.5569, std: 2.4175\n",
      "\n",
      "Epoch 12, Step 100, LR: 0.000817, Current Loss: 0.9808, Avg Loss: 0.9944\n",
      "Diff stats — min: -5.6632, max: 10.0000, mean: 2.6896, std: 2.4367\n",
      "\n",
      "Step 1551 — Test metrics:\n",
      "  precision@10: 0.034536424\n",
      "  recall@10: 0.034538263\n",
      "  ndcg@10: 0.036015536\n",
      "  map@10: 0.012721355\n",
      "Epoch 12, Step 120, LR: 0.000817, Current Loss: 1.0075, Avg Loss: 0.9942\n",
      "Diff stats — min: -6.5013, max: 10.0000, mean: 2.6092, std: 2.5124\n",
      "\n",
      "Epoch 12 completed, Train Loss: 0.000243\n",
      "\n",
      "Epoch 13, Step 1, LR: 0.000817, Current Loss: 0.9966, Avg Loss: 0.9966\n",
      "Diff stats — min: -5.7924, max: 10.0000, mean: 2.6136, std: 2.4241\n",
      "\n",
      "Step 1584 — Test metrics:\n",
      "  precision@10: 0.036390728\n",
      "  recall@10: 0.036390728\n",
      "  ndcg@10: 0.038183351\n",
      "  map@10: 0.013667600\n",
      "Epoch 13, Step 20, LR: 0.000817, Current Loss: 0.9859, Avg Loss: 0.9927\n",
      "Diff stats — min: -4.5873, max: 10.0000, mean: 2.6575, std: 2.4506\n",
      "\n",
      "Epoch 13, Step 40, LR: 0.000817, Current Loss: 0.9903, Avg Loss: 0.9912\n",
      "Diff stats — min: -4.4948, max: 10.0000, mean: 2.6335, std: 2.4682\n",
      "\n",
      "Step 1633 — Test metrics:\n",
      "  precision@10: 0.035331126\n",
      "  recall@10: 0.035332965\n",
      "  ndcg@10: 0.036921281\n",
      "  map@10: 0.013126780\n",
      "Epoch 13, Step 60, LR: 0.000817, Current Loss: 0.9634, Avg Loss: 0.9920\n",
      "Diff stats — min: -6.3044, max: 10.0000, mean: 2.7283, std: 2.4408\n",
      "\n",
      "Epoch 13, Step 80, LR: 0.000801, Current Loss: 0.9701, Avg Loss: 0.9918\n",
      "Diff stats — min: -4.9006, max: 10.0000, mean: 2.7217, std: 2.4337\n",
      "\n",
      "Epoch 13, Step 100, LR: 0.000801, Current Loss: 0.9928, Avg Loss: 0.9916\n",
      "Diff stats — min: -5.1107, max: 10.0000, mean: 2.7024, std: 2.5166\n",
      "\n",
      "Step 1683 — Test metrics:\n",
      "  precision@10: 0.034453642\n",
      "  recall@10: 0.034453642\n",
      "  ndcg@10: 0.035678644\n",
      "  map@10: 0.012514119\n",
      "Epoch 13, Step 120, LR: 0.000801, Current Loss: 1.0017, Avg Loss: 0.9913\n",
      "Diff stats — min: -5.2495, max: 10.0000, mean: 2.6385, std: 2.5070\n",
      "\n",
      "Epoch 13 completed, Train Loss: 0.000242\n",
      "\n",
      "Epoch 14, Step 1, LR: 0.000801, Current Loss: 0.9858, Avg Loss: 0.9858\n",
      "Diff stats — min: -5.3596, max: 10.0000, mean: 2.6743, std: 2.4536\n",
      "\n",
      "Step 1716 — Test metrics:\n",
      "  precision@10: 0.035264901\n",
      "  recall@10: 0.035264901\n",
      "  ndcg@10: 0.036766721\n",
      "  map@10: 0.012947013\n",
      "Epoch 14, Step 20, LR: 0.000801, Current Loss: 0.9952, Avg Loss: 0.9910\n",
      "Diff stats — min: -5.1404, max: 10.0000, mean: 2.6492, std: 2.4727\n",
      "\n",
      "Epoch 14, Step 40, LR: 0.000801, Current Loss: 0.9786, Avg Loss: 0.9865\n",
      "Diff stats — min: -4.4132, max: 10.0000, mean: 2.7723, std: 2.4976\n",
      "\n",
      "Step 1765 — Test metrics:\n",
      "  precision@10: 0.034685430\n",
      "  recall@10: 0.034685430\n",
      "  ndcg@10: 0.036341680\n",
      "  map@10: 0.012831566\n",
      "Epoch 14, Step 60, LR: 0.000801, Current Loss: 0.9745, Avg Loss: 0.9861\n",
      "Diff stats — min: -5.5148, max: 10.0000, mean: 2.7305, std: 2.4947\n",
      "\n",
      "Epoch 14, Step 80, LR: 0.000801, Current Loss: 0.9893, Avg Loss: 0.9865\n",
      "Diff stats — min: -6.1752, max: 10.0000, mean: 2.7756, std: 2.5676\n",
      "\n",
      "Epoch 14, Step 100, LR: 0.000785, Current Loss: 1.0028, Avg Loss: 0.9865\n",
      "Diff stats — min: -5.5605, max: 10.0000, mean: 2.6900, std: 2.5841\n",
      "\n",
      "Step 1815 — Test metrics:\n",
      "  precision@10: 0.033741722\n",
      "  recall@10: 0.033741722\n",
      "  ndcg@10: 0.035504051\n",
      "  map@10: 0.012564806\n",
      "Epoch 14, Step 120, LR: 0.000785, Current Loss: 0.9838, Avg Loss: 0.9869\n",
      "Diff stats — min: -5.8176, max: 10.0000, mean: 2.6897, std: 2.4753\n",
      "\n",
      "Epoch 14 completed, Train Loss: 0.000241\n",
      "\n",
      "Epoch 15, Step 1, LR: 0.000785, Current Loss: 0.9898, Avg Loss: 0.9898\n",
      "Diff stats — min: -4.9064, max: 10.0000, mean: 2.6871, std: 2.5171\n",
      "\n",
      "Step 1848 — Test metrics:\n",
      "  precision@10: 0.033874172\n",
      "  recall@10: 0.033876012\n",
      "  ndcg@10: 0.035548960\n",
      "  map@10: 0.012661017\n",
      "Epoch 15, Step 20, LR: 0.000785, Current Loss: 0.9919, Avg Loss: 0.9846\n",
      "Diff stats — min: -5.6607, max: 10.0000, mean: 2.6926, std: 2.5588\n",
      "\n",
      "Epoch 15, Step 40, LR: 0.000785, Current Loss: 0.9878, Avg Loss: 0.9849\n",
      "Diff stats — min: -5.1087, max: 10.0000, mean: 2.7265, std: 2.5406\n",
      "\n",
      "Step 1897 — Test metrics:\n",
      "  precision@10: 0.033642384\n",
      "  recall@10: 0.033644224\n",
      "  ndcg@10: 0.034804351\n",
      "  map@10: 0.012149657\n",
      "Epoch 15, Step 60, LR: 0.000785, Current Loss: 0.9702, Avg Loss: 0.9850\n",
      "Diff stats — min: -5.8982, max: 10.0000, mean: 2.7805, std: 2.5172\n",
      "\n",
      "Epoch 15, Step 80, LR: 0.000785, Current Loss: 0.9837, Avg Loss: 0.9851\n",
      "Diff stats — min: -5.0665, max: 10.0000, mean: 2.7661, std: 2.5744\n",
      "\n",
      "Epoch 15, Step 100, LR: 0.000785, Current Loss: 0.9978, Avg Loss: 0.9850\n",
      "Diff stats — min: -4.9684, max: 10.0000, mean: 2.7137, std: 2.5648\n",
      "\n",
      "Step 1947 — Test metrics:\n",
      "  precision@10: 0.034006623\n",
      "  recall@10: 0.034008462\n",
      "  ndcg@10: 0.035376532\n",
      "  map@10: 0.012400456\n",
      "Epoch 15, Step 120, LR: 0.000769, Current Loss: 0.9833, Avg Loss: 0.9853\n",
      "Diff stats — min: -4.9596, max: 10.0000, mean: 2.7165, std: 2.5269\n",
      "\n",
      "Epoch 15 completed, Train Loss: 0.000241\n",
      "\n",
      "Epoch 16, Step 1, LR: 0.000769, Current Loss: 0.9919, Avg Loss: 0.9919\n",
      "Diff stats — min: -5.8335, max: 10.0000, mean: 2.7560, std: 2.5926\n",
      "\n",
      "Step 1980 — Test metrics:\n",
      "  precision@10: 0.034321192\n",
      "  recall@10: 0.034323032\n",
      "  ndcg@10: 0.035726675\n",
      "  map@10: 0.012549229\n",
      "Epoch 16, Step 20, LR: 0.000769, Current Loss: 0.9737, Avg Loss: 0.9825\n",
      "Diff stats — min: -4.7639, max: 10.0000, mean: 2.7969, std: 2.5715\n",
      "\n",
      "Epoch 16, Step 40, LR: 0.000769, Current Loss: 0.9876, Avg Loss: 0.9832\n",
      "Diff stats — min: -5.0475, max: 10.0000, mean: 2.7318, std: 2.5595\n",
      "\n",
      "Step 2029 — Test metrics:\n",
      "  precision@10: 0.033228477\n",
      "  recall@10: 0.033230316\n",
      "  ndcg@10: 0.034486674\n",
      "  map@10: 0.012124750\n",
      "Epoch 16, Step 60, LR: 0.000769, Current Loss: 0.9874, Avg Loss: 0.9831\n",
      "Diff stats — min: -5.6729, max: 10.0000, mean: 2.7584, std: 2.6057\n",
      "\n",
      "Epoch 16, Step 80, LR: 0.000769, Current Loss: 0.9844, Avg Loss: 0.9826\n",
      "Diff stats — min: -6.6816, max: 10.0000, mean: 2.8122, std: 2.6196\n",
      "\n",
      "Epoch 16, Step 100, LR: 0.000769, Current Loss: 0.9792, Avg Loss: 0.9823\n",
      "Diff stats — min: -5.8387, max: 10.0000, mean: 2.8383, std: 2.5804\n",
      "\n",
      "Step 2079 — Test metrics:\n",
      "  precision@10: 0.034536424\n",
      "  recall@10: 0.034536424\n",
      "  ndcg@10: 0.036013237\n",
      "  map@10: 0.012725829\n",
      "Epoch 16, Step 120, LR: 0.000769, Current Loss: 0.9901, Avg Loss: 0.9824\n",
      "Diff stats — min: -5.1522, max: 10.0000, mean: 2.7433, std: 2.5775\n",
      "\n",
      "Epoch 16 completed, Train Loss: 0.000240\n",
      "\n",
      "Epoch 17, Step 1, LR: 0.000754, Current Loss: 0.9812, Avg Loss: 0.9812\n",
      "Diff stats — min: -5.0326, max: 10.0000, mean: 2.8507, std: 2.5995\n",
      "\n",
      "Step 2112 — Test metrics:\n",
      "  precision@10: 0.034105960\n",
      "  recall@10: 0.034105960\n",
      "  ndcg@10: 0.035368563\n",
      "  map@10: 0.012488779\n",
      "Epoch 17, Step 20, LR: 0.000754, Current Loss: 0.9797, Avg Loss: 0.9845\n",
      "Diff stats — min: -4.7053, max: 10.0000, mean: 2.7861, std: 2.5822\n",
      "\n",
      "Epoch 17, Step 40, LR: 0.000754, Current Loss: 0.9729, Avg Loss: 0.9815\n",
      "Diff stats — min: -4.2182, max: 10.0000, mean: 2.8210, std: 2.5946\n",
      "\n",
      "Step 2161 — Test metrics:\n",
      "  precision@10: 0.033476821\n",
      "  recall@10: 0.033478661\n",
      "  ndcg@10: 0.034657954\n",
      "  map@10: 0.012165793\n",
      "Epoch 17, Step 60, LR: 0.000754, Current Loss: 0.9742, Avg Loss: 0.9819\n",
      "Diff stats — min: -4.9025, max: 10.0000, mean: 2.7990, std: 2.5474\n",
      "\n",
      "Epoch 17, Step 80, LR: 0.000754, Current Loss: 0.9876, Avg Loss: 0.9812\n",
      "Diff stats — min: -5.6557, max: 10.0000, mean: 2.7892, std: 2.6206\n",
      "\n",
      "Epoch 17, Step 100, LR: 0.000754, Current Loss: 0.9790, Avg Loss: 0.9809\n",
      "Diff stats — min: -6.1797, max: 10.0000, mean: 2.8104, std: 2.5812\n",
      "\n",
      "Step 2211 — Test metrics:\n",
      "  precision@10: 0.033443709\n",
      "  recall@10: 0.033443709\n",
      "  ndcg@10: 0.034481513\n",
      "  map@10: 0.012028454\n",
      "Epoch 17, Step 120, LR: 0.000754, Current Loss: 0.9695, Avg Loss: 0.9807\n",
      "Diff stats — min: -7.7063, max: 10.0000, mean: 2.8864, std: 2.6080\n",
      "\n",
      "Epoch 17 completed, Train Loss: 0.000240\n",
      "\n",
      "Epoch 18, Step 1, LR: 0.000754, Current Loss: 0.9752, Avg Loss: 0.9752\n",
      "Diff stats — min: -4.8711, max: 10.0000, mean: 2.8004, std: 2.5737\n",
      "\n",
      "Step 2244 — Test metrics:\n",
      "  precision@10: 0.034470199\n",
      "  recall@10: 0.034470199\n",
      "  ndcg@10: 0.036011638\n",
      "  map@10: 0.012651050\n",
      "Epoch 18, Step 20, LR: 0.000739, Current Loss: 0.9784, Avg Loss: 0.9799\n",
      "Diff stats — min: -4.4375, max: 10.0000, mean: 2.8054, std: 2.6035\n",
      "\n",
      "Epoch 18, Step 40, LR: 0.000739, Current Loss: 0.9972, Avg Loss: 0.9786\n",
      "Diff stats — min: -5.0765, max: 10.0000, mean: 2.7647, std: 2.6527\n",
      "\n",
      "Step 2293 — Test metrics:\n",
      "  precision@10: 0.032152318\n",
      "  recall@10: 0.032154157\n",
      "  ndcg@10: 0.033613279\n",
      "  map@10: 0.011825068\n",
      "Epoch 18, Step 60, LR: 0.000739, Current Loss: 0.9856, Avg Loss: 0.9795\n",
      "Diff stats — min: -5.0300, max: 10.0000, mean: 2.7523, std: 2.5931\n",
      "\n",
      "Epoch 18, Step 80, LR: 0.000739, Current Loss: 0.9794, Avg Loss: 0.9795\n",
      "Diff stats — min: -5.3457, max: 10.0000, mean: 2.8455, std: 2.6551\n",
      "\n",
      "Epoch 18, Step 100, LR: 0.000739, Current Loss: 0.9682, Avg Loss: 0.9788\n",
      "Diff stats — min: -4.7607, max: 10.0000, mean: 2.9087, std: 2.6456\n",
      "\n",
      "Step 2343 — Test metrics:\n",
      "  precision@10: 0.033559603\n",
      "  recall@10: 0.033559603\n",
      "  ndcg@10: 0.034511680\n",
      "  map@10: 0.011966848\n",
      "Epoch 18, Step 120, LR: 0.000739, Current Loss: 0.9894, Avg Loss: 0.9785\n",
      "Diff stats — min: -4.8799, max: 10.0000, mean: 2.8176, std: 2.6654\n",
      "\n",
      "Epoch 18 completed, Train Loss: 0.000239\n",
      "\n",
      "Epoch 19, Step 1, LR: 0.000739, Current Loss: 0.9726, Avg Loss: 0.9726\n",
      "Diff stats — min: -5.0798, max: 10.0000, mean: 2.8067, std: 2.5776\n",
      "\n",
      "Step 2376 — Test metrics:\n",
      "  precision@10: 0.032731788\n",
      "  recall@10: 0.032735467\n",
      "  ndcg@10: 0.034332191\n",
      "  map@10: 0.012081494\n",
      "Epoch 19, Step 20, LR: 0.000739, Current Loss: 0.9746, Avg Loss: 0.9784\n",
      "Diff stats — min: -6.0553, max: 10.0000, mean: 2.8556, std: 2.6417\n",
      "\n",
      "Epoch 19, Step 40, LR: 0.000724, Current Loss: 0.9799, Avg Loss: 0.9782\n",
      "Diff stats — min: -4.9891, max: 10.0000, mean: 2.7946, std: 2.5900\n",
      "\n",
      "Step 2425 — Test metrics:\n",
      "  precision@10: 0.032831126\n",
      "  recall@10: 0.032832965\n",
      "  ndcg@10: 0.034130281\n",
      "  map@10: 0.011901425\n",
      "Epoch 19, Step 60, LR: 0.000724, Current Loss: 0.9777, Avg Loss: 0.9791\n",
      "Diff stats — min: -4.0345, max: 10.0000, mean: 2.8917, std: 2.6648\n",
      "\n",
      "Epoch 19, Step 80, LR: 0.000724, Current Loss: 0.9774, Avg Loss: 0.9782\n",
      "Diff stats — min: -5.7084, max: 10.0000, mean: 2.8141, std: 2.6058\n",
      "\n",
      "Epoch 19, Step 100, LR: 0.000724, Current Loss: 0.9694, Avg Loss: 0.9773\n",
      "Diff stats — min: -5.3015, max: 10.0000, mean: 2.9524, std: 2.6844\n",
      "\n",
      "Step 2475 — Test metrics:\n",
      "  precision@10: 0.034437086\n",
      "  recall@10: 0.034440765\n",
      "  ndcg@10: 0.035892586\n",
      "  map@10: 0.012588445\n",
      "Epoch 19, Step 120, LR: 0.000724, Current Loss: 0.9697, Avg Loss: 0.9772\n",
      "Diff stats — min: -5.1938, max: 10.0000, mean: 2.9160, std: 2.6655\n",
      "\n",
      "Epoch 19 completed, Train Loss: 0.000239\n",
      "\n",
      "Epoch 20, Step 1, LR: 0.000724, Current Loss: 0.9682, Avg Loss: 0.9682\n",
      "Diff stats — min: -4.7241, max: 10.0000, mean: 2.9812, std: 2.6677\n",
      "\n",
      "Step 2508 — Test metrics:\n",
      "  precision@10: 0.033410596\n",
      "  recall@10: 0.033412436\n",
      "  ndcg@10: 0.034343629\n",
      "  map@10: 0.011903047\n",
      "Epoch 20, Step 20, LR: 0.000724, Current Loss: 0.9916, Avg Loss: 0.9774\n",
      "Diff stats — min: -5.8138, max: 10.0000, mean: 2.8391, std: 2.6705\n",
      "\n",
      "Epoch 20, Step 40, LR: 0.000724, Current Loss: 0.9904, Avg Loss: 0.9764\n",
      "Diff stats — min: -6.2587, max: 10.0000, mean: 2.8467, std: 2.7099\n",
      "\n",
      "Step 2557 — Test metrics:\n",
      "  precision@10: 0.032980132\n",
      "  recall@10: 0.032981972\n",
      "  ndcg@10: 0.034234224\n",
      "  map@10: 0.011887378\n",
      "Epoch 20, Step 60, LR: 0.000709, Current Loss: 0.9726, Avg Loss: 0.9745\n",
      "Diff stats — min: -5.3604, max: 10.0000, mean: 2.8821, std: 2.6468\n",
      "\n",
      "Epoch 20, Step 80, LR: 0.000709, Current Loss: 0.9725, Avg Loss: 0.9743\n",
      "Diff stats — min: -7.2600, max: 10.0000, mean: 2.9577, std: 2.6816\n",
      "\n",
      "Epoch 20, Step 100, LR: 0.000709, Current Loss: 0.9612, Avg Loss: 0.9742\n",
      "Diff stats — min: -4.9284, max: 10.0000, mean: 2.9630, std: 2.6267\n",
      "\n",
      "Step 2607 — Test metrics:\n",
      "  precision@10: 0.033509934\n",
      "  recall@10: 0.033513613\n",
      "  ndcg@10: 0.034697732\n",
      "  map@10: 0.012067964\n",
      "Epoch 20, Step 120, LR: 0.000709, Current Loss: 0.9587, Avg Loss: 0.9747\n",
      "Diff stats — min: -4.5203, max: 10.0000, mean: 2.9292, std: 2.6325\n",
      "\n",
      "Epoch 20 completed, Train Loss: 0.000238\n",
      "\n",
      "Epoch 21, Step 1, LR: 0.000709, Current Loss: 0.9742, Avg Loss: 0.9742\n",
      "Diff stats — min: -5.4082, max: 10.0000, mean: 2.9563, std: 2.6799\n",
      "\n",
      "Step 2640 — Test metrics:\n",
      "  precision@10: 0.033443709\n",
      "  recall@10: 0.033445548\n",
      "  ndcg@10: 0.034799040\n",
      "  map@10: 0.012169187\n",
      "Epoch 21, Step 20, LR: 0.000709, Current Loss: 0.9820, Avg Loss: 0.9708\n",
      "Diff stats — min: -4.5221, max: 10.0000, mean: 2.9281, std: 2.7214\n",
      "\n",
      "Epoch 21, Step 40, LR: 0.000709, Current Loss: 0.9692, Avg Loss: 0.9708\n",
      "Diff stats — min: -5.7887, max: 10.0000, mean: 2.9603, std: 2.7084\n",
      "\n",
      "Step 2689 — Test metrics:\n",
      "  precision@10: 0.032317881\n",
      "  recall@10: 0.032321560\n",
      "  ndcg@10: 0.033266168\n",
      "  map@10: 0.011459842\n",
      "Epoch 21, Step 60, LR: 0.000709, Current Loss: 0.9520, Avg Loss: 0.9706\n",
      "Diff stats — min: -5.2171, max: 10.0000, mean: 3.0407, std: 2.7109\n",
      "\n",
      "Epoch 21, Step 80, LR: 0.000695, Current Loss: 0.9841, Avg Loss: 0.9713\n",
      "Diff stats — min: -5.4977, max: 10.0000, mean: 2.8888, std: 2.7151\n",
      "\n",
      "Epoch 21, Step 100, LR: 0.000695, Current Loss: 0.9706, Avg Loss: 0.9709\n",
      "Diff stats — min: -5.0793, max: 10.0000, mean: 2.9602, std: 2.6799\n",
      "\n",
      "Step 2739 — Test metrics:\n",
      "  precision@10: 0.033195364\n",
      "  recall@10: 0.033199043\n",
      "  ndcg@10: 0.034311235\n",
      "  map@10: 0.011856716\n",
      "Epoch 21, Step 120, LR: 0.000695, Current Loss: 0.9686, Avg Loss: 0.9707\n",
      "Diff stats — min: -5.1163, max: 10.0000, mean: 2.9659, std: 2.7028\n",
      "\n",
      "Epoch 21 completed, Train Loss: 0.000237\n",
      "\n",
      "Epoch 22, Step 1, LR: 0.000695, Current Loss: 0.9693, Avg Loss: 0.9693\n",
      "Diff stats — min: -4.2412, max: 10.0000, mean: 2.9749, std: 2.7164\n",
      "\n",
      "Step 2772 — Test metrics:\n",
      "  precision@10: 0.033692053\n",
      "  recall@10: 0.033695732\n",
      "  ndcg@10: 0.035019809\n",
      "  map@10: 0.012203118\n",
      "Epoch 22, Step 20, LR: 0.000695, Current Loss: 0.9703, Avg Loss: 0.9708\n",
      "Diff stats — min: -5.2212, max: 10.0000, mean: 2.8973, std: 2.6739\n",
      "\n",
      "Epoch 22, Step 40, LR: 0.000695, Current Loss: 0.9688, Avg Loss: 0.9699\n",
      "Diff stats — min: -5.5867, max: 10.0000, mean: 3.0494, std: 2.7846\n",
      "\n",
      "Step 2821 — Test metrics:\n",
      "  precision@10: 0.031937086\n",
      "  recall@10: 0.031938926\n",
      "  ndcg@10: 0.033230090\n",
      "  map@10: 0.011431575\n",
      "Epoch 22, Step 60, LR: 0.000695, Current Loss: 0.9523, Avg Loss: 0.9694\n",
      "Diff stats — min: -5.8232, max: 10.0000, mean: 2.9937, std: 2.6766\n",
      "\n",
      "Epoch 22, Step 80, LR: 0.000681, Current Loss: 0.9810, Avg Loss: 0.9690\n",
      "Diff stats — min: -4.7591, max: 10.0000, mean: 3.0180, std: 2.7879\n",
      "\n",
      "Epoch 22, Step 100, LR: 0.000681, Current Loss: 0.9671, Avg Loss: 0.9693\n",
      "Diff stats — min: -5.2617, max: 10.0000, mean: 2.9837, std: 2.7102\n",
      "\n",
      "Step 2871 — Test metrics:\n",
      "  precision@10: 0.032119205\n",
      "  recall@10: 0.032121045\n",
      "  ndcg@10: 0.033434329\n",
      "  map@10: 0.011553086\n",
      "Epoch 22, Step 120, LR: 0.000681, Current Loss: 0.9724, Avg Loss: 0.9695\n",
      "Diff stats — min: -5.2622, max: 10.0000, mean: 2.9572, std: 2.7178\n",
      "\n",
      "Epoch 22 completed, Train Loss: 0.000237\n",
      "\n",
      "Epoch 23, Step 1, LR: 0.000681, Current Loss: 0.9687, Avg Loss: 0.9687\n",
      "Diff stats — min: -5.1146, max: 10.0000, mean: 3.0136, std: 2.7293\n",
      "\n",
      "Step 2904 — Test metrics:\n",
      "  precision@10: 0.032500000\n",
      "  recall@10: 0.032500000\n",
      "  ndcg@10: 0.034422678\n",
      "  map@10: 0.012117018\n",
      "Epoch 23, Step 20, LR: 0.000681, Current Loss: 0.9637, Avg Loss: 0.9665\n",
      "Diff stats — min: -6.0831, max: 10.0000, mean: 3.0419, std: 2.7508\n",
      "\n",
      "Epoch 23, Step 40, LR: 0.000681, Current Loss: 0.9663, Avg Loss: 0.9661\n",
      "Diff stats — min: -5.1283, max: 10.0000, mean: 2.9693, std: 2.7165\n",
      "\n",
      "Step 2953 — Test metrics:\n",
      "  precision@10: 0.033145695\n",
      "  recall@10: 0.033145695\n",
      "  ndcg@10: 0.034839316\n",
      "  map@10: 0.012176981\n",
      "Epoch 23, Step 60, LR: 0.000681, Current Loss: 0.9670, Avg Loss: 0.9666\n",
      "Diff stats — min: -5.6444, max: 10.0000, mean: 3.0818, std: 2.7735\n",
      "\n",
      "Epoch 23, Step 80, LR: 0.000681, Current Loss: 0.9608, Avg Loss: 0.9667\n",
      "Diff stats — min: -4.9070, max: 10.0000, mean: 3.0279, std: 2.7561\n",
      "\n",
      "Epoch 23, Step 100, LR: 0.000668, Current Loss: 0.9597, Avg Loss: 0.9669\n",
      "Diff stats — min: -4.8575, max: 10.0000, mean: 3.0270, std: 2.7375\n",
      "\n",
      "Step 3003 — Test metrics:\n",
      "  precision@10: 0.032466887\n",
      "  recall@10: 0.032468727\n",
      "  ndcg@10: 0.033760401\n",
      "  map@10: 0.011656601\n",
      "Epoch 23, Step 120, LR: 0.000668, Current Loss: 0.9794, Avg Loss: 0.9667\n",
      "Diff stats — min: -6.1206, max: 10.0000, mean: 3.0345, std: 2.8027\n",
      "\n",
      "Epoch 23 completed, Train Loss: 0.000236\n",
      "\n",
      "Epoch 24, Step 1, LR: 0.000668, Current Loss: 0.9606, Avg Loss: 0.9606\n",
      "Diff stats — min: -5.1797, max: 10.0000, mean: 3.0780, std: 2.7910\n",
      "\n",
      "Step 3036 — Test metrics:\n",
      "  precision@10: 0.033145695\n",
      "  recall@10: 0.033147535\n",
      "  ndcg@10: 0.035102963\n",
      "  map@10: 0.012284230\n",
      "Epoch 24, Step 20, LR: 0.000668, Current Loss: 0.9513, Avg Loss: 0.9638\n",
      "Diff stats — min: -4.8241, max: 10.0000, mean: 3.0384, std: 2.6851\n",
      "\n",
      "Epoch 24, Step 40, LR: 0.000668, Current Loss: 0.9712, Avg Loss: 0.9662\n",
      "Diff stats — min: -4.9298, max: 10.0000, mean: 2.9987, std: 2.7375\n",
      "\n",
      "Step 3085 — Test metrics:\n",
      "  precision@10: 0.032334437\n",
      "  recall@10: 0.032336277\n",
      "  ndcg@10: 0.033834020\n",
      "  map@10: 0.011770196\n",
      "Epoch 24, Step 60, LR: 0.000668, Current Loss: 0.9771, Avg Loss: 0.9654\n",
      "Diff stats — min: -7.2265, max: 10.0000, mean: 2.9828, std: 2.7449\n",
      "\n",
      "Epoch 24, Step 80, LR: 0.000668, Current Loss: 0.9716, Avg Loss: 0.9653\n",
      "Diff stats — min: -4.5371, max: 10.0000, mean: 3.0473, std: 2.7673\n",
      "\n",
      "Epoch 24, Step 100, LR: 0.000668, Current Loss: 0.9670, Avg Loss: 0.9651\n",
      "Diff stats — min: -4.4201, max: 10.0000, mean: 3.0784, std: 2.7955\n",
      "\n",
      "Step 3135 — Test metrics:\n",
      "  precision@10: 0.032367550\n",
      "  recall@10: 0.032367550\n",
      "  ndcg@10: 0.033751556\n",
      "  map@10: 0.011654499\n",
      "Epoch 24, Step 120, LR: 0.000654, Current Loss: 0.9726, Avg Loss: 0.9647\n",
      "Diff stats — min: -5.1726, max: 10.0000, mean: 3.0511, std: 2.8121\n",
      "\n",
      "Epoch 24 completed, Train Loss: 0.000236\n",
      "\n",
      "Epoch 25, Step 1, LR: 0.000654, Current Loss: 0.9482, Avg Loss: 0.9482\n",
      "Diff stats — min: -4.4363, max: 10.0000, mean: 3.0756, std: 2.7170\n",
      "\n",
      "Step 3168 — Test metrics:\n",
      "  precision@10: 0.032781457\n",
      "  recall@10: 0.032783297\n",
      "  ndcg@10: 0.034359586\n",
      "  map@10: 0.011920544\n",
      "Epoch 25, Step 20, LR: 0.000654, Current Loss: 0.9833, Avg Loss: 0.9638\n",
      "Diff stats — min: -6.8554, max: 10.0000, mean: 2.9848, std: 2.8076\n",
      "\n",
      "Epoch 25, Step 40, LR: 0.000654, Current Loss: 0.9692, Avg Loss: 0.9640\n",
      "Diff stats — min: -6.2753, max: 10.0000, mean: 3.0432, std: 2.7881\n",
      "\n",
      "Step 3217 — Test metrics:\n",
      "  precision@10: 0.033046358\n",
      "  recall@10: 0.033048197\n",
      "  ndcg@10: 0.034573757\n",
      "  map@10: 0.011953038\n",
      "Epoch 25, Step 60, LR: 0.000654, Current Loss: 0.9815, Avg Loss: 0.9644\n",
      "Diff stats — min: -5.6265, max: 10.0000, mean: 2.9137, std: 2.7316\n",
      "\n",
      "Epoch 25, Step 80, LR: 0.000654, Current Loss: 0.9568, Avg Loss: 0.9642\n",
      "Diff stats — min: -4.9443, max: 10.0000, mean: 3.0566, std: 2.7454\n",
      "\n",
      "Epoch 25, Step 100, LR: 0.000654, Current Loss: 0.9561, Avg Loss: 0.9635\n",
      "Diff stats — min: -5.5835, max: 10.0000, mean: 3.0535, std: 2.7183\n",
      "\n",
      "Step 3267 — Test metrics:\n",
      "  precision@10: 0.033476821\n",
      "  recall@10: 0.033476821\n",
      "  ndcg@10: 0.035199862\n",
      "  map@10: 0.012259132\n",
      "Epoch 25, Step 120, LR: 0.000654, Current Loss: 0.9726, Avg Loss: 0.9638\n",
      "Diff stats — min: -5.9974, max: 10.0000, mean: 3.0593, std: 2.8299\n",
      "\n",
      "Epoch 25 completed, Train Loss: 0.000236\n",
      "\n",
      "Epoch 26, Step 1, LR: 0.000641, Current Loss: 0.9638, Avg Loss: 0.9638\n",
      "Diff stats — min: -6.8572, max: 10.0000, mean: 3.0214, std: 2.7426\n",
      "\n",
      "Step 3300 — Test metrics:\n",
      "  precision@10: 0.032367550\n",
      "  recall@10: 0.032371229\n",
      "  ndcg@10: 0.033891797\n",
      "  map@10: 0.011694740\n",
      "Epoch 26, Step 20, LR: 0.000641, Current Loss: 0.9616, Avg Loss: 0.9602\n",
      "Diff stats — min: -5.8654, max: 10.0000, mean: 3.0791, std: 2.8066\n",
      "\n",
      "Epoch 26, Step 40, LR: 0.000641, Current Loss: 0.9688, Avg Loss: 0.9587\n",
      "Diff stats — min: -7.2147, max: 10.0000, mean: 3.1522, std: 2.8822\n",
      "\n",
      "Step 3349 — Test metrics:\n",
      "  precision@10: 0.033493377\n",
      "  recall@10: 0.033497057\n",
      "  ndcg@10: 0.035169393\n",
      "  map@10: 0.012208636\n",
      "Epoch 26, Step 60, LR: 0.000641, Current Loss: 0.9626, Avg Loss: 0.9579\n",
      "Diff stats — min: -5.4493, max: 10.0000, mean: 3.1314, std: 2.8328\n",
      "\n",
      "Epoch 26, Step 80, LR: 0.000641, Current Loss: 0.9569, Avg Loss: 0.9585\n",
      "Diff stats — min: -4.8755, max: 10.0000, mean: 3.1364, std: 2.8219\n",
      "\n",
      "Epoch 26, Step 100, LR: 0.000641, Current Loss: 0.9541, Avg Loss: 0.9587\n",
      "Diff stats — min: -4.8702, max: 10.0000, mean: 3.1454, std: 2.7945\n",
      "\n",
      "Step 3399 — Test metrics:\n",
      "  precision@10: 0.033079470\n",
      "  recall@10: 0.033083149\n",
      "  ndcg@10: 0.034713351\n",
      "  map@10: 0.012111947\n",
      "Epoch 26, Step 120, LR: 0.000641, Current Loss: 0.9447, Avg Loss: 0.9591\n",
      "Diff stats — min: -4.8309, max: 10.0000, mean: 3.2249, std: 2.8316\n",
      "\n",
      "Epoch 26 completed, Train Loss: 0.000235\n",
      "\n",
      "Epoch 27, Step 1, LR: 0.000641, Current Loss: 0.9603, Avg Loss: 0.9603\n",
      "Diff stats — min: -4.8803, max: 10.0000, mean: 3.0860, std: 2.8003\n",
      "\n",
      "Step 3432 — Test metrics:\n",
      "  precision@10: 0.033245033\n",
      "  recall@10: 0.033246873\n",
      "  ndcg@10: 0.034578156\n",
      "  map@10: 0.011849009\n",
      "Epoch 27, Step 20, LR: 0.000628, Current Loss: 0.9595, Avg Loss: 0.9587\n",
      "Diff stats — min: -5.5161, max: 10.0000, mean: 3.1359, std: 2.8648\n",
      "\n",
      "Epoch 27, Step 40, LR: 0.000628, Current Loss: 0.9592, Avg Loss: 0.9585\n",
      "Diff stats — min: -4.4703, max: 10.0000, mean: 3.2381, std: 2.9014\n",
      "\n",
      "Step 3481 — Test metrics:\n",
      "  precision@10: 0.033890728\n",
      "  recall@10: 0.033894408\n",
      "  ndcg@10: 0.035505525\n",
      "  map@10: 0.012303001\n",
      "Epoch 27, Step 60, LR: 0.000628, Current Loss: 0.9568, Avg Loss: 0.9576\n",
      "Diff stats — min: -4.9302, max: 10.0000, mean: 3.1197, std: 2.8211\n",
      "\n",
      "Epoch 27, Step 80, LR: 0.000628, Current Loss: 0.9588, Avg Loss: 0.9566\n",
      "Diff stats — min: -5.3894, max: 10.0000, mean: 3.1440, std: 2.8619\n",
      "\n",
      "Epoch 27, Step 100, LR: 0.000628, Current Loss: 0.9602, Avg Loss: 0.9576\n",
      "Diff stats — min: -5.2153, max: 10.0000, mean: 3.0942, std: 2.7963\n",
      "\n",
      "Step 3531 — Test metrics:\n",
      "  precision@10: 0.033841060\n",
      "  recall@10: 0.033844739\n",
      "  ndcg@10: 0.035197521\n",
      "  map@10: 0.012156048\n",
      "Epoch 27, Step 120, LR: 0.000628, Current Loss: 0.9600, Avg Loss: 0.9574\n",
      "Diff stats — min: -5.8403, max: 10.0000, mean: 3.0886, std: 2.7997\n",
      "\n",
      "Epoch 27 completed, Train Loss: 0.000234\n",
      "\n",
      "Epoch 28, Step 1, LR: 0.000628, Current Loss: 0.9499, Avg Loss: 0.9499\n",
      "Diff stats — min: -4.7816, max: 10.0000, mean: 3.1930, std: 2.8240\n",
      "\n",
      "Step 3564 — Test metrics:\n",
      "  precision@10: 0.034072848\n",
      "  recall@10: 0.034074687\n",
      "  ndcg@10: 0.035591590\n",
      "  map@10: 0.012381990\n",
      "Epoch 28, Step 20, LR: 0.000628, Current Loss: 0.9573, Avg Loss: 0.9588\n",
      "Diff stats — min: -4.3078, max: 10.0000, mean: 3.1055, std: 2.7635\n",
      "\n",
      "Epoch 28, Step 40, LR: 0.000616, Current Loss: 0.9642, Avg Loss: 0.9582\n",
      "Diff stats — min: -5.0734, max: 10.0000, mean: 3.0750, std: 2.7843\n",
      "\n",
      "Step 3613 — Test metrics:\n",
      "  precision@10: 0.033923841\n",
      "  recall@10: 0.033927520\n",
      "  ndcg@10: 0.035677715\n",
      "  map@10: 0.012458314\n",
      "Epoch 28, Step 60, LR: 0.000616, Current Loss: 0.9670, Avg Loss: 0.9573\n",
      "Diff stats — min: -6.2113, max: 10.0000, mean: 3.2147, std: 2.8982\n",
      "\n",
      "Epoch 28, Step 80, LR: 0.000616, Current Loss: 0.9614, Avg Loss: 0.9577\n",
      "Diff stats — min: -6.2485, max: 10.0000, mean: 3.1391, std: 2.8159\n",
      "\n",
      "Epoch 28, Step 100, LR: 0.000616, Current Loss: 0.9537, Avg Loss: 0.9565\n",
      "Diff stats — min: -5.3624, max: 10.0000, mean: 3.2294, std: 2.8670\n",
      "\n",
      "Step 3663 — Test metrics:\n",
      "  precision@10: 0.034337748\n",
      "  recall@10: 0.034341428\n",
      "  ndcg@10: 0.035805597\n",
      "  map@10: 0.012447979\n",
      "Epoch 28, Step 120, LR: 0.000616, Current Loss: 0.9558, Avg Loss: 0.9560\n",
      "Diff stats — min: -5.9054, max: 10.0000, mean: 3.1672, std: 2.8450\n",
      "\n",
      "Epoch 28 completed, Train Loss: 0.000234\n",
      "\n",
      "Epoch 29, Step 1, LR: 0.000616, Current Loss: 0.9469, Avg Loss: 0.9469\n",
      "Diff stats — min: -4.7191, max: 10.0000, mean: 3.1883, std: 2.7979\n",
      "\n",
      "Step 3696 — Test metrics:\n",
      "  precision@10: 0.033394040\n",
      "  recall@10: 0.033397719\n",
      "  ndcg@10: 0.035021189\n",
      "  map@10: 0.012184479\n",
      "Epoch 29, Step 20, LR: 0.000616, Current Loss: 0.9512, Avg Loss: 0.9512\n",
      "Diff stats — min: -5.5871, max: 10.0000, mean: 3.2572, std: 2.8657\n",
      "\n",
      "Epoch 29, Step 40, LR: 0.000616, Current Loss: 0.9510, Avg Loss: 0.9509\n",
      "Diff stats — min: -5.5153, max: 10.0000, mean: 3.1782, std: 2.8172\n",
      "\n",
      "Step 3745 — Test metrics:\n",
      "  precision@10: 0.033559603\n",
      "  recall@10: 0.033565121\n",
      "  ndcg@10: 0.035487592\n",
      "  map@10: 0.012420117\n",
      "Epoch 29, Step 60, LR: 0.000603, Current Loss: 0.9555, Avg Loss: 0.9514\n",
      "Diff stats — min: -5.3325, max: 10.0000, mean: 3.2267, std: 2.8854\n",
      "\n",
      "Epoch 29, Step 80, LR: 0.000603, Current Loss: 0.9496, Avg Loss: 0.9506\n",
      "Diff stats — min: -5.5482, max: 10.0000, mean: 3.2739, std: 2.8906\n",
      "\n",
      "Epoch 29, Step 100, LR: 0.000603, Current Loss: 0.9469, Avg Loss: 0.9511\n",
      "Diff stats — min: -4.0716, max: 10.0000, mean: 3.2317, std: 2.8364\n",
      "\n",
      "Step 3795 — Test metrics:\n",
      "  precision@10: 0.033559603\n",
      "  recall@10: 0.033563282\n",
      "  ndcg@10: 0.035474133\n",
      "  map@10: 0.012440619\n",
      "Epoch 29, Step 120, LR: 0.000603, Current Loss: 0.9570, Avg Loss: 0.9510\n",
      "Diff stats — min: -5.0939, max: 10.0000, mean: 3.2284, std: 2.8770\n",
      "\n",
      "Epoch 29 completed, Train Loss: 0.000233\n",
      "\n",
      "Epoch 30, Step 1, LR: 0.000603, Current Loss: 0.9560, Avg Loss: 0.9560\n",
      "Diff stats — min: -5.7284, max: 10.0000, mean: 3.1579, std: 2.8366\n",
      "\n",
      "Step 3828 — Test metrics:\n",
      "  precision@10: 0.034370861\n",
      "  recall@10: 0.034372701\n",
      "  ndcg@10: 0.035980502\n",
      "  map@10: 0.012528231\n",
      "Epoch 30, Step 20, LR: 0.000603, Current Loss: 0.9508, Avg Loss: 0.9543\n",
      "Diff stats — min: -4.8859, max: 10.0000, mean: 3.1815, std: 2.8197\n",
      "\n",
      "Epoch 30, Step 40, LR: 0.000603, Current Loss: 0.9655, Avg Loss: 0.9539\n",
      "Diff stats — min: -5.9195, max: 10.0000, mean: 3.1961, std: 2.8880\n",
      "\n",
      "Step 3877 — Test metrics:\n",
      "  precision@10: 0.034486755\n",
      "  recall@10: 0.034490434\n",
      "  ndcg@10: 0.036171567\n",
      "  map@10: 0.012553100\n",
      "Epoch 30, Step 60, LR: 0.000603, Current Loss: 0.9353, Avg Loss: 0.9515\n",
      "Diff stats — min: -4.5164, max: 10.0000, mean: 3.2270, std: 2.8018\n",
      "\n",
      "Epoch 30, Step 80, LR: 0.000591, Current Loss: 0.9436, Avg Loss: 0.9501\n",
      "Diff stats — min: -4.6671, max: 10.0000, mean: 3.3192, std: 2.8921\n",
      "\n",
      "Epoch 30, Step 100, LR: 0.000591, Current Loss: 0.9450, Avg Loss: 0.9512\n",
      "Diff stats — min: -5.5504, max: 10.0000, mean: 3.2110, std: 2.8501\n",
      "\n",
      "Step 3927 — Test metrics:\n",
      "  precision@10: 0.034668874\n",
      "  recall@10: 0.034672553\n",
      "  ndcg@10: 0.036479341\n",
      "  map@10: 0.012719621\n",
      "Epoch 30, Step 120, LR: 0.000591, Current Loss: 0.9561, Avg Loss: 0.9514\n",
      "Diff stats — min: -6.5759, max: 10.0000, mean: 3.2493, std: 2.9092\n",
      "\n",
      "Epoch 30 completed, Train Loss: 0.000233\n",
      "\n",
      "Epoch 31, Step 1, LR: 0.000591, Current Loss: 0.9453, Avg Loss: 0.9453\n",
      "Diff stats — min: -5.4191, max: 10.0000, mean: 3.2365, std: 2.8337\n",
      "\n",
      "Step 3960 — Test metrics:\n",
      "  precision@10: 0.033774834\n",
      "  recall@10: 0.033780353\n",
      "  ndcg@10: 0.035645218\n",
      "  map@10: 0.012347447\n",
      "Epoch 31, Step 20, LR: 0.000591, Current Loss: 0.9357, Avg Loss: 0.9477\n",
      "Diff stats — min: -5.9505, max: 10.0000, mean: 3.2799, std: 2.8469\n",
      "\n",
      "Epoch 31, Step 40, LR: 0.000591, Current Loss: 0.9471, Avg Loss: 0.9477\n",
      "Diff stats — min: -4.7917, max: 10.0000, mean: 3.2830, std: 2.8685\n",
      "\n",
      "Step 4009 — Test metrics:\n",
      "  precision@10: 0.034089404\n",
      "  recall@10: 0.034093083\n",
      "  ndcg@10: 0.035667988\n",
      "  map@10: 0.012366262\n",
      "Epoch 31, Step 60, LR: 0.000591, Current Loss: 0.9570, Avg Loss: 0.9479\n",
      "Diff stats — min: -4.5805, max: 10.0000, mean: 3.2110, std: 2.8901\n",
      "\n",
      "Epoch 31, Step 80, LR: 0.000591, Current Loss: 0.9503, Avg Loss: 0.9479\n",
      "Diff stats — min: -4.5477, max: 10.0000, mean: 3.2434, std: 2.8585\n",
      "\n",
      "Epoch 31, Step 100, LR: 0.000580, Current Loss: 0.9390, Avg Loss: 0.9480\n",
      "Diff stats — min: -5.9784, max: 10.0000, mean: 3.3156, std: 2.8293\n",
      "\n",
      "Step 4059 — Test metrics:\n",
      "  precision@10: 0.033460265\n",
      "  recall@10: 0.033463944\n",
      "  ndcg@10: 0.035047684\n",
      "  map@10: 0.012162109\n",
      "Epoch 31, Step 120, LR: 0.000580, Current Loss: 0.9489, Avg Loss: 0.9477\n",
      "Diff stats — min: -5.4683, max: 10.0000, mean: 3.3291, std: 2.8940\n",
      "\n",
      "Epoch 31 completed, Train Loss: 0.000232\n",
      "\n",
      "Epoch 32, Step 1, LR: 0.000580, Current Loss: 0.9494, Avg Loss: 0.9494\n",
      "Diff stats — min: -5.1428, max: 10.0000, mean: 3.2585, std: 2.8697\n",
      "\n",
      "Step 4092 — Test metrics:\n",
      "  precision@10: 0.033278146\n",
      "  recall@10: 0.033283664\n",
      "  ndcg@10: 0.034576898\n",
      "  map@10: 0.011894757\n",
      "Epoch 32, Step 20, LR: 0.000580, Current Loss: 0.9310, Avg Loss: 0.9455\n",
      "Diff stats — min: -7.4327, max: 10.0000, mean: 3.3083, std: 2.8585\n",
      "\n",
      "Epoch 32, Step 40, LR: 0.000580, Current Loss: 0.9412, Avg Loss: 0.9456\n",
      "Diff stats — min: -4.9604, max: 10.0000, mean: 3.3953, std: 2.9305\n",
      "\n",
      "Step 4141 — Test metrics:\n",
      "  precision@10: 0.034188742\n",
      "  recall@10: 0.034192421\n",
      "  ndcg@10: 0.035587815\n",
      "  map@10: 0.012270663\n",
      "Epoch 32, Step 60, LR: 0.000580, Current Loss: 0.9429, Avg Loss: 0.9452\n",
      "Diff stats — min: -4.6526, max: 10.0000, mean: 3.2528, std: 2.8492\n",
      "\n",
      "Epoch 32, Step 80, LR: 0.000580, Current Loss: 0.9455, Avg Loss: 0.9460\n",
      "Diff stats — min: -5.9146, max: 10.0000, mean: 3.2717, std: 2.8645\n",
      "\n",
      "Epoch 32, Step 100, LR: 0.000580, Current Loss: 0.9354, Avg Loss: 0.9459\n",
      "Diff stats — min: -5.4421, max: 10.0000, mean: 3.3832, std: 2.8864\n",
      "\n",
      "Step 4191 — Test metrics:\n",
      "  precision@10: 0.034635762\n",
      "  recall@10: 0.034639441\n",
      "  ndcg@10: 0.035930237\n",
      "  map@10: 0.012437461\n",
      "Epoch 32, Step 120, LR: 0.000568, Current Loss: 0.9461, Avg Loss: 0.9459\n",
      "Diff stats — min: -5.0913, max: 10.0000, mean: 3.3232, std: 2.9340\n",
      "\n",
      "Epoch 32 completed, Train Loss: 0.000231\n",
      "\n",
      "Epoch 33, Step 1, LR: 0.000568, Current Loss: 0.9586, Avg Loss: 0.9586\n",
      "Diff stats — min: -5.0280, max: 10.0000, mean: 3.3493, std: 2.9762\n",
      "\n",
      "Step 4224 — Test metrics:\n",
      "  precision@10: 0.034254967\n",
      "  recall@10: 0.034260486\n",
      "  ndcg@10: 0.036265182\n",
      "  map@10: 0.012726578\n",
      "Epoch 33, Step 20, LR: 0.000568, Current Loss: 0.9485, Avg Loss: 0.9439\n",
      "Diff stats — min: -5.2281, max: 10.0000, mean: 3.2796, std: 2.8757\n",
      "\n",
      "Epoch 33, Step 40, LR: 0.000568, Current Loss: 0.9378, Avg Loss: 0.9434\n",
      "Diff stats — min: -5.5604, max: 10.0000, mean: 3.3616, std: 2.8928\n",
      "\n",
      "Step 4273 — Test metrics:\n",
      "  precision@10: 0.034817881\n",
      "  recall@10: 0.034821560\n",
      "  ndcg@10: 0.036306853\n",
      "  map@10: 0.012571048\n",
      "Epoch 33, Step 60, LR: 0.000568, Current Loss: 0.9408, Avg Loss: 0.9433\n",
      "Diff stats — min: -5.5151, max: 10.0000, mean: 3.3148, std: 2.9085\n",
      "\n",
      "Epoch 33, Step 80, LR: 0.000568, Current Loss: 0.9377, Avg Loss: 0.9440\n",
      "Diff stats — min: -6.2140, max: 10.0000, mean: 3.3714, std: 2.8877\n",
      "\n",
      "Epoch 33, Step 100, LR: 0.000568, Current Loss: 0.9338, Avg Loss: 0.9439\n",
      "Diff stats — min: -4.4780, max: 10.0000, mean: 3.3891, std: 2.9380\n",
      "\n",
      "Step 4323 — Test metrics:\n",
      "  precision@10: 0.034288079\n",
      "  recall@10: 0.034293598\n",
      "  ndcg@10: 0.035614427\n",
      "  map@10: 0.012299617\n",
      "Epoch 33, Step 120, LR: 0.000568, Current Loss: 0.9705, Avg Loss: 0.9443\n",
      "Diff stats — min: -6.3977, max: 10.0000, mean: 3.2136, std: 2.9241\n",
      "\n",
      "Epoch 33 completed, Train Loss: 0.000231\n",
      "\n",
      "Epoch 34, Step 1, LR: 0.000557, Current Loss: 0.9604, Avg Loss: 0.9604\n",
      "Diff stats — min: -5.9781, max: 10.0000, mean: 3.3046, std: 2.9251\n",
      "\n",
      "Step 4356 — Test metrics:\n",
      "  precision@10: 0.034387417\n",
      "  recall@10: 0.034391096\n",
      "  ndcg@10: 0.035697006\n",
      "  map@10: 0.012393100\n",
      "Epoch 34, Step 20, LR: 0.000557, Current Loss: 0.9452, Avg Loss: 0.9419\n",
      "Diff stats — min: -5.4420, max: 10.0000, mean: 3.3189, std: 2.8920\n",
      "\n",
      "Epoch 34, Step 40, LR: 0.000557, Current Loss: 0.9474, Avg Loss: 0.9420\n",
      "Diff stats — min: -5.4465, max: 10.0000, mean: 3.2684, std: 2.8962\n",
      "\n",
      "Step 4405 — Test metrics:\n",
      "  precision@10: 0.034403974\n",
      "  recall@10: 0.034407653\n",
      "  ndcg@10: 0.035812395\n",
      "  map@10: 0.012412390\n",
      "Epoch 34, Step 60, LR: 0.000557, Current Loss: 0.9545, Avg Loss: 0.9421\n",
      "Diff stats — min: -6.1130, max: 10.0000, mean: 3.3501, std: 2.9591\n",
      "\n",
      "Epoch 34, Step 80, LR: 0.000557, Current Loss: 0.9197, Avg Loss: 0.9415\n",
      "Diff stats — min: -5.4566, max: 10.0000, mean: 3.4967, std: 2.9200\n",
      "\n",
      "Epoch 34, Step 100, LR: 0.000557, Current Loss: 0.9442, Avg Loss: 0.9411\n",
      "Diff stats — min: -4.8017, max: 10.0000, mean: 3.3729, std: 2.9594\n",
      "\n",
      "Step 4455 — Test metrics:\n",
      "  precision@10: 0.034619205\n",
      "  recall@10: 0.034622884\n",
      "  ndcg@10: 0.036288387\n",
      "  map@10: 0.012581937\n",
      "Epoch 34, Step 120, LR: 0.000557, Current Loss: 0.9416, Avg Loss: 0.9413\n",
      "Diff stats — min: -4.3728, max: 10.0000, mean: 3.3526, std: 2.9155\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/622032216.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtrain_lambda_ce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_lambda_ce'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m model = train_model(model,\n\u001b[0m\u001b[1;32m     27\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mseq_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/1552439942.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, seq_train_data, edge_type, num_epochs, lr, batch_size, device, print_every, test_every, top_k, test_batch_size, scheduler_step_size, scheduler_gamma)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0muser_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mseq_ids_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_times_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_mask_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    feedback_types=feedback_types,\n",
    "    d_model=d_model,\n",
    "    n_head=n_head,\n",
    "    window_size=window_size,\n",
    "    decay=decay,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "edge_type = hyperparameters['train_edge_type']\n",
    "num_epochs = hyperparameters['train_num_epochs']\n",
    "lr = hyperparameters['train_lr']\n",
    "batch_size = hyperparameters['train_batch_size']\n",
    "print_every = hyperparameters['train_print_every']\n",
    "test_every = hyperparameters['train_test_every']\n",
    "top_k = hyperparameters['test_topk']\n",
    "test_batch_size = hyperparameters['test_batch_size']\n",
    "scheduler_step_size = hyperparameters['train_scheduler_step_size']\n",
    "train_scheduler_gamma = hyperparameters['train_scheduler_gamma']\n",
    "train_margin = hyperparameters['train_margin']\n",
    "train_lambda_margin = hyperparameters['train_lambda_margin']\n",
    "train_lambda_ce = hyperparameters['train_lambda_ce']\n",
    "\n",
    "model = train_model(model,\n",
    "                    data,\n",
    "                    (seq_ids, event_type, seq_times, seq_mask),\n",
    "                    edge_type=edge_type,\n",
    "                    num_epochs=num_epochs,\n",
    "                    lr=lr,\n",
    "                    batch_size=batch_size,\n",
    "                    print_every=print_every,\n",
    "                    test_every=test_every,\n",
    "                    top_k=top_k,\n",
    "                    test_batch_size=test_batch_size,\n",
    "                    scheduler_step_size=scheduler_step_size,\n",
    "                    scheduler_gamma=train_scheduler_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:46:36.038978Z",
     "iopub.status.busy": "2025-06-24T19:46:36.038409Z",
     "iopub.status.idle": "2025-06-24T19:46:36.079527Z",
     "shell.execute_reply": "2025-06-24T19:46:36.078928Z",
     "shell.execute_reply.started": "2025-06-24T19:46:36.038958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='gnn_model_mvl.model' target='_blank'>gnn_model_mvl.model</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/gnn_model_mvl.model"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, \"gnn_model_mvl.model\")\n",
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('gnn_model_mvl.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:46:37.064457Z",
     "iopub.status.busy": "2025-06-24T19:46:37.063864Z",
     "iopub.status.idle": "2025-06-24T19:46:37.584391Z",
     "shell.execute_reply": "2025-06-24T19:46:37.583767Z",
     "shell.execute_reply.started": "2025-06-24T19:46:37.064436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:48:46.336592Z",
     "iopub.status.busy": "2025-06-24T19:48:46.335934Z",
     "iopub.status.idle": "2025-06-24T19:48:46.368897Z",
     "shell.execute_reply": "2025-06-24T19:48:46.368186Z",
     "shell.execute_reply.started": "2025-06-24T19:48:46.336572Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "log_model(\n",
    "    experiment=experiment,\n",
    "    model=model,\n",
    "    model_name=\"GNN+THP\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:48:47.646515Z",
     "iopub.status.busy": "2025-06-24T19:48:47.646229Z",
     "iopub.status.idle": "2025-06-24T19:48:47.649996Z",
     "shell.execute_reply": "2025-06-24T19:48:47.649330Z",
     "shell.execute_reply.started": "2025-06-24T19:48:47.646495Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7302197,
     "sourceId": 11637841,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7705289,
     "sourceId": 12229447,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
