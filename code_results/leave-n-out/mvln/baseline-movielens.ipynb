{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:02.611656Z",
     "iopub.status.busy": "2025-06-24T18:36:02.611433Z",
     "iopub.status.idle": "2025-06-24T18:36:17.385441Z",
     "shell.execute_reply": "2025-06-24T18:36:17.384542Z",
     "shell.execute_reply.started": "2025-06-24T18:36:02.611635Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.1/727.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install torch_geometric rectools\n",
    "!pip -q install comet_ml\n",
    "!pip -q install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:17.386712Z",
     "iopub.status.busy": "2025-06-24T18:36:17.386450Z",
     "iopub.status.idle": "2025-06-24T18:36:22.778719Z",
     "shell.execute_reply": "2025-06-24T18:36:22.778190Z",
     "shell.execute_reply.started": "2025-06-24T18:36:17.386683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:22.781207Z",
     "iopub.status.busy": "2025-06-24T18:36:22.780681Z",
     "iopub.status.idle": "2025-06-24T18:36:22.787394Z",
     "shell.execute_reply": "2025-06-24T18:36:22.786750Z",
     "shell.execute_reply.started": "2025-06-24T18:36:22.781186Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:22.788277Z",
     "iopub.status.busy": "2025-06-24T18:36:22.788014Z",
     "iopub.status.idle": "2025-06-24T18:36:29.002998Z",
     "shell.execute_reply": "2025-06-24T18:36:29.002468Z",
     "shell.execute_reply.started": "2025-06-24T18:36:22.788260Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/annanet/gnn-recommender/4b3f9c68f8684549869e2e3830603d43\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "  api_key=os.getenv('API_KEY'),\n",
    "  project_name=\"gnn-recommender\",\n",
    "  workspace=\"annanet\",\n",
    "  log_code=True\n",
    ")\n",
    "\n",
    "experiment.set_name('baseline-movielens')\n",
    "experiment.add_tags(['movielens', 'leave-n-out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:29.006271Z",
     "iopub.status.busy": "2025-06-24T18:36:29.006030Z",
     "iopub.status.idle": "2025-06-24T18:36:29.010381Z",
     "shell.execute_reply": "2025-06-24T18:36:29.009604Z",
     "shell.execute_reply.started": "2025-06-24T18:36:29.006254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'seed': 42,\n",
    "    'types_of_feedback': [\"explicit_positive\", \"expliсit_negative\",\n",
    "                          \"implicit_positive\", \"implicit_negative\"],\n",
    "    'train_edge_type': ('item','to_feedback_explicit_positive','explicit_positive'),\n",
    "    'train_num_epochs': 100,\n",
    "    'train_lr': 8e-5,\n",
    "    'train_batch_size': 16384,\n",
    "    'train_print_every': 10,  \n",
    "    'train_test_every': 50,\n",
    "    'test_topk': 10,\n",
    "    'test_batch_size': 8192\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:29.011246Z",
     "iopub.status.busy": "2025-06-24T18:36:29.011009Z",
     "iopub.status.idle": "2025-06-24T18:36:29.039608Z",
     "shell.execute_reply": "2025-06-24T18:36:29.039115Z",
     "shell.execute_reply.started": "2025-06-24T18:36:29.011227Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv', 'test.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('/kaggle/input/data/leave-n-out/mvln')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:29.040444Z",
     "iopub.status.busy": "2025-06-24T18:36:29.040227Z",
     "iopub.status.idle": "2025-06-24T18:36:38.901718Z",
     "shell.execute_reply": "2025-06-24T18:36:38.900925Z",
     "shell.execute_reply.started": "2025-06-24T18:36:29.040428Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv, GATConv\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from rectools import Columns\n",
    "from rectools.metrics import MAP, Precision, Recall, NDCG, calc_metrics\n",
    "\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:38.904611Z",
     "iopub.status.busy": "2025-06-24T18:36:38.904197Z",
     "iopub.status.idle": "2025-06-24T18:36:38.913461Z",
     "shell.execute_reply": "2025-06-24T18:36:38.912917Z",
     "shell.execute_reply.started": "2025-06-24T18:36:38.904591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = hyperparameters['seed']\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:38.914401Z",
     "iopub.status.busy": "2025-06-24T18:36:38.914187Z",
     "iopub.status.idle": "2025-06-24T18:36:40.053949Z",
     "shell.execute_reply": "2025-06-24T18:36:40.053238Z",
     "shell.execute_reply.started": "2025-06-24T18:36:38.914379Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  timestamp                date\n",
      "0        1      3186       4  978300019 2000-12-31 22:00:19\n",
      "1        1      1270       5  978300055 2000-12-31 22:00:55\n",
      "2        1      1721       4  978300055 2000-12-31 22:00:55\n",
      "3        1      1022       5  978300055 2000-12-31 22:00:55\n",
      "4        1      2340       3  978300103 2000-12-31 22:01:43\n"
     ]
    }
   ],
   "source": [
    "rootpath = '/kaggle/input/data/leave-n-out/mvln/'\n",
    "train = pd.read_csv(\n",
    "    rootpath+'train.csv'\n",
    ")\n",
    "train['date'] = pd.to_datetime(train['timestamp'], unit='s')\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:40.055020Z",
     "iopub.status.busy": "2025-06-24T18:36:40.054748Z",
     "iopub.status.idle": "2025-06-24T18:36:40.093636Z",
     "shell.execute_reply": "2025-06-24T18:36:40.092830Z",
     "shell.execute_reply.started": "2025-06-24T18:36:40.054995Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество explicit позитивного фидбека 211802\n",
      "Количество explicit негативного фидбека 153484\n"
     ]
    }
   ],
   "source": [
    "explicit_positive = train[(train[\"rating\"] == 5)].index\n",
    "explisit_negative = train[(train[\"rating\"] <= 2)].index\n",
    "\n",
    "explicit_combined_feedback = explicit_positive.union(explisit_negative)\n",
    "print('Количество explicit позитивного фидбека', explicit_positive.shape[0])\n",
    "print('Количество explicit негативного фидбека', explisit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:40.095131Z",
     "iopub.status.busy": "2025-06-24T18:36:40.094521Z",
     "iopub.status.idle": "2025-06-24T18:36:40.137565Z",
     "shell.execute_reply": "2025-06-24T18:36:40.136905Z",
     "shell.execute_reply.started": "2025-06-24T18:36:40.095102Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество implicit позитивного фидбека 327987\n",
      "Количество implicit негативного фидбека 246536\n"
     ]
    }
   ],
   "source": [
    "implicit_positive = train[(train[\"rating\"] == 4)].index\n",
    "implicit_negative = train[(train[\"rating\"] == 3)].index\n",
    "\n",
    "implicit_combined_feedback = implicit_positive.union(implicit_negative)\n",
    "print('Количество implicit позитивного фидбека', implicit_positive.shape[0])\n",
    "print('Количество implicit негативного фидбека', implicit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:40.138412Z",
     "iopub.status.busy": "2025-06-24T18:36:40.138224Z",
     "iopub.status.idle": "2025-06-24T18:36:40.460255Z",
     "shell.execute_reply": "2025-06-24T18:36:40.459457Z",
     "shell.execute_reply.started": "2025-06-24T18:36:40.138390Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2000-12-31 22:00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2000-12-31 22:01:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id             target                date\n",
       "0        1      3186  implicit_positive 2000-12-31 22:00:19\n",
       "1        1      1270  explicit_positive 2000-12-31 22:00:55\n",
       "2        1      1721  implicit_positive 2000-12-31 22:00:55\n",
       "3        1      1022  explicit_positive 2000-12-31 22:00:55\n",
       "4        1      2340  implicit_negative 2000-12-31 22:01:43"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:, \"target\"] = \"\"\n",
    "train.loc[explicit_positive, \"target\"] = \"explicit_positive\"\n",
    "train.loc[explisit_negative, \"target\"] = \"expliсit_negative\"\n",
    "train.loc[implicit_positive, \"target\"] = \"implicit_positive\"\n",
    "train.loc[implicit_negative, \"target\"] = \"implicit_negative\"\n",
    "\n",
    "train = train[['user_id','movie_id','target','date']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:40.461285Z",
     "iopub.status.busy": "2025-06-24T18:36:40.461015Z",
     "iopub.status.idle": "2025-06-24T18:36:40.640564Z",
     "shell.execute_reply": "2025-06-24T18:36:40.638958Z",
     "shell.execute_reply.started": "2025-06-24T18:36:40.461259Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = train.sort_values(by=[\"user_id\", \"date\"]).reset_index(drop=True)\n",
    "train.columns = ['user_id', 'item_id', 'target', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:40.641907Z",
     "iopub.status.busy": "2025-06-24T18:36:40.641557Z",
     "iopub.status.idle": "2025-06-24T18:36:40.726505Z",
     "shell.execute_reply": "2025-06-24T18:36:40.725849Z",
     "shell.execute_reply.started": "2025-06-24T18:36:40.641875Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  timestamp                date\n",
      "0        1      2687       3  978824268 2001-01-06 23:37:48\n",
      "1        1       745       3  978824268 2001-01-06 23:37:48\n",
      "2        1       588       4  978824268 2001-01-06 23:37:48\n",
      "3        1         1       5  978824268 2001-01-06 23:37:48\n",
      "4        1      2355       5  978824291 2001-01-06 23:38:11\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\n",
    "    rootpath+'test.csv'\n",
    ")\n",
    "test['date'] = pd.to_datetime(test['timestamp'], unit='s')\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:40.727488Z",
     "iopub.status.busy": "2025-06-24T18:36:40.727197Z",
     "iopub.status.idle": "2025-06-24T18:36:40.735924Z",
     "shell.execute_reply": "2025-06-24T18:36:40.735348Z",
     "shell.execute_reply.started": "2025-06-24T18:36:40.727466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2687</td>\n",
       "      <td>2001-01-06 23:37:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>745</td>\n",
       "      <td>2001-01-06 23:37:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>2001-01-06 23:37:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-01-06 23:37:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>2001-01-06 23:38:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id                date\n",
       "0        1     2687 2001-01-06 23:37:48\n",
       "1        1      745 2001-01-06 23:37:48\n",
       "2        1      588 2001-01-06 23:37:48\n",
       "3        1        1 2001-01-06 23:37:48\n",
       "4        1     2355 2001-01-06 23:38:11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[['user_id','movie_id', 'date']]\n",
    "test.columns = ['user_id', 'item_id', 'date']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP model v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:40.736982Z",
     "iopub.status.busy": "2025-06-24T18:36:40.736691Z",
     "iopub.status.idle": "2025-06-24T18:36:40.761753Z",
     "shell.execute_reply": "2025-06-24T18:36:40.761235Z",
     "shell.execute_reply.started": "2025-06-24T18:36:40.736963Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60394, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[(test.user_id.isin(train.user_id)) & (test.item_id.isin(train.item_id))].copy()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:40.762551Z",
     "iopub.status.busy": "2025-06-24T18:36:40.762360Z",
     "iopub.status.idle": "2025-06-24T18:36:40.911167Z",
     "shell.execute_reply": "2025-06-24T18:36:40.910558Z",
     "shell.execute_reply.started": "2025-06-24T18:36:40.762536Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. Преобразование данных - для куарека не особо нужно, но для других - напоминалка\n",
    "# делаем всегда! чтобы не сломать ничего дальше и чтобы все индексы были от 0 до N без пропусков\n",
    "user_encoder = LabelEncoder()\n",
    "video_encoder = LabelEncoder()\n",
    "\n",
    "train.loc[:, 'user_id'] = user_encoder.fit_transform(train['user_id'])\n",
    "train.loc[:, 'item_id'] = video_encoder.fit_transform(train['item_id'])\n",
    "\n",
    "test.loc[:, 'user_id'] = user_encoder.transform(test['user_id'])\n",
    "test.loc[:, 'item_id'] = video_encoder.transform(test['item_id'])\n",
    "\n",
    "train['user_id'] = train['user_id'].astype(int)\n",
    "train['item_id'] = train['item_id'].astype(int)\n",
    "test['user_id'] = test['user_id'].astype(int)\n",
    "test['item_id'] = test['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:40.912124Z",
     "iopub.status.busy": "2025-06-24T18:36:40.911853Z",
     "iopub.status.idle": "2025-06-24T18:36:40.929482Z",
     "shell.execute_reply": "2025-06-24T18:36:40.928911Z",
     "shell.execute_reply.started": "2025-06-24T18:36:40.912101Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных item_id 3700\n",
      "Количество уникальных user_id 6040\n"
     ]
    }
   ],
   "source": [
    "# т.е. сразу знаем количество и в каких пределах изменяется user_id и video_id\n",
    "num_videos = train['item_id'].nunique()\n",
    "num_users = train['user_id'].nunique()\n",
    "\n",
    "print('Количество уникальных item_id', num_videos)\n",
    "print('Количество уникальных user_id', num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:40.930261Z",
     "iopub.status.busy": "2025-06-24T18:36:40.930054Z",
     "iopub.status.idle": "2025-06-24T18:36:40.935746Z",
     "shell.execute_reply": "2025-06-24T18:36:40.935199Z",
     "shell.execute_reply.started": "2025-06-24T18:36:40.930245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_hetero_data(df) -> HeteroData:\n",
    "    \"\"\"\n",
    "    Build a simple hetero-graph with only item->user edges based on interactions in df.\n",
    "    df must contain columns 'item_id' and 'user_id'.\n",
    "    \"\"\"\n",
    "    data = HeteroData()\n",
    "\n",
    "    # Create user and item nodes\n",
    "    users = torch.from_numpy(df['user_id'].unique())\n",
    "    items = torch.from_numpy(df['item_id'].unique())\n",
    "    num_users = int(users.max().item()) + 1\n",
    "    num_items = int(items.max().item()) + 1\n",
    "\n",
    "    data['user'].node_id = torch.arange(num_users)\n",
    "    data['item'].node_id = torch.arange(num_items)\n",
    "\n",
    "    # Build item -> user edge index from interactions\n",
    "    item_ids = torch.LongTensor(df['item_id'].values)\n",
    "    user_ids = torch.LongTensor(df['user_id'].values)\n",
    "    edge_index = torch.stack([item_ids, user_ids], dim=0)\n",
    "\n",
    "    data['item', 'interacts', 'user'].edge_index = edge_index\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:43.340899Z",
     "iopub.status.busy": "2025-06-24T18:36:43.340184Z",
     "iopub.status.idle": "2025-06-24T18:36:43.349254Z",
     "shell.execute_reply": "2025-06-24T18:36:43.348509Z",
     "shell.execute_reply.started": "2025-06-24T18:36:43.340875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, HeteroConv\n",
    "\n",
    "class SimpleItemUserGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Heterogeneous GNN for a bipartite graph with single edge type item->user.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 emb_dim: int = 32,\n",
    "                 hidden_dim: int = 16,\n",
    "                 heads: int = 2,\n",
    "                 dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        # Embeddings\n",
    "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_dim)\n",
    "\n",
    "        # Two-layer HeteroConv with one relation: ('item','interacts','user')\n",
    "        conv1 = {\n",
    "            ('item', 'interacts', 'user'): GATConv(\n",
    "                in_channels=emb_dim,\n",
    "                out_channels=hidden_dim,\n",
    "                heads=heads,\n",
    "                add_self_loops=False\n",
    "            ),\n",
    "        }\n",
    "        conv2 = {\n",
    "            ('item', 'interacts', 'user'): GATConv(\n",
    "                in_channels=hidden_dim * heads,\n",
    "                out_channels=emb_dim,\n",
    "                heads=1,\n",
    "                add_self_loops=False\n",
    "            ),\n",
    "        }\n",
    "        self.conv1 = HeteroConv(conv1, aggr='mean')\n",
    "        self.conv2 = HeteroConv(conv2, aggr='mean')\n",
    "\n",
    "        # LayerNorm & Dropout\n",
    "        self.norm1 = nn.ModuleDict({\n",
    "            'user': nn.LayerNorm(hidden_dim * heads),\n",
    "            'item': nn.LayerNorm(emb_dim)\n",
    "        })\n",
    "        self.norm2 = nn.ModuleDict({\n",
    "            'user': nn.LayerNorm(emb_dim),\n",
    "            'item': nn.LayerNorm(emb_dim)\n",
    "        })\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Initial node features\n",
    "        x = {\n",
    "            'user': self.user_emb(data['user'].node_id),\n",
    "            'item': self.item_emb(data['item'].node_id)\n",
    "        }\n",
    "        # First hetero-conv\n",
    "        h1 = self.conv1(x, data.edge_index_dict)\n",
    "        # Apply activation, norm, dropout\n",
    "        h1_user = F.elu(self.norm1['user'](h1['user']))\n",
    "        h1_user = self.dropout(h1_user)\n",
    "        h1 = {'user': h1_user, 'item': self.item_emb(data['item'].node_id)}\n",
    "\n",
    "        # Second hetero-conv\n",
    "        h2 = self.conv2(h1, data.edge_index_dict)\n",
    "        # Final normalization\n",
    "        h2_user = self.norm2['user'](h2['user'])\n",
    "\n",
    "        return h2_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:43.549548Z",
     "iopub.status.busy": "2025-06-24T18:36:43.549261Z",
     "iopub.status.idle": "2025-06-24T18:36:43.585366Z",
     "shell.execute_reply": "2025-06-24T18:36:43.584720Z",
     "shell.execute_reply.started": "2025-06-24T18:36:43.549528Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ node_id=[6040] },\n",
       "  item={ node_id=[3700] },\n",
       "  (item, interacts, user)={ edge_index=[2, 939809] }\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = prepare_hetero_data(train)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:43.953207Z",
     "iopub.status.busy": "2025-06-24T18:36:43.952566Z",
     "iopub.status.idle": "2025-06-24T18:36:43.969573Z",
     "shell.execute_reply": "2025-06-24T18:36:43.968958Z",
     "shell.execute_reply.started": "2025-06-24T18:36:43.953186Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3700, 0, 3699)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.item_id.nunique(), train.item_id.min(), train.item_id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:45.024869Z",
     "iopub.status.busy": "2025-06-24T18:36:45.024102Z",
     "iopub.status.idle": "2025-06-24T18:36:45.102728Z",
     "shell.execute_reply": "2025-06-24T18:36:45.101913Z",
     "shell.execute_reply.started": "2025-06-24T18:36:45.024846Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch_geometric/nn/conv/hetero_conv.py:76: UserWarning: There exist node types ({'item'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_users = len(train['user_id'].unique())\n",
    "num_items = train['item_id'].max() + 1\n",
    "model = SimpleItemUserGNN(num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:45.239001Z",
     "iopub.status.busy": "2025-06-24T18:36:45.238756Z",
     "iopub.status.idle": "2025-06-24T18:36:45.244150Z",
     "shell.execute_reply": "2025-06-24T18:36:45.243401Z",
     "shell.execute_reply.started": "2025-06-24T18:36:45.238984Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleItemUserGNN(\n",
       "  (user_emb): Embedding(6040, 32)\n",
       "  (item_emb): Embedding(3700, 32)\n",
       "  (conv1): HeteroConv(num_relations=1)\n",
       "  (conv2): HeteroConv(num_relations=1)\n",
       "  (norm1): ModuleDict(\n",
       "    (user): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (item): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (norm2): ModuleDict(\n",
       "    (user): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    (item): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:46.646714Z",
     "iopub.status.busy": "2025-06-24T18:36:46.646027Z",
     "iopub.status.idle": "2025-06-24T18:36:46.975502Z",
     "shell.execute_reply": "2025-06-24T18:36:46.974694Z",
     "shell.execute_reply.started": "2025-06-24T18:36:46.646692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = test[['user_id', 'item_id']]\n",
    "interactions = test_df.rename(columns={\n",
    "    'user_id': Columns.User,\n",
    "    'item_id': Columns.Item,\n",
    "})\n",
    "\n",
    "viewed_items = train.groupby(\"user_id\")[\"item_id\"].agg(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:48.371043Z",
     "iopub.status.busy": "2025-06-24T18:36:48.370345Z",
     "iopub.status.idle": "2025-06-24T18:36:48.386714Z",
     "shell.execute_reply": "2025-06-24T18:36:48.385951Z",
     "shell.execute_reply.started": "2025-06-24T18:36:48.371012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, train_data,\n",
    "             test_batch_size, top_k,\n",
    "             viewed_items, interactions,\n",
    "             device, test_step):\n",
    "    \"\"\"\n",
    "    Оцениваем модель по всем пользователям:\n",
    "    - строим топ-K рекомендации\n",
    "    - фильтруем уже просмотренные\n",
    "    - считаем recall@K, precision@K, map@K\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    num_users = train_data['user'].node_id.shape[0]\n",
    "    test_top_k = top_k * 150\n",
    "\n",
    "    item_emb = model.item_emb.weight\n",
    "    item_emb_t = item_emb.t().detach()\n",
    "    del item_emb\n",
    "    gc.collect()\n",
    "\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_users, test_batch_size):\n",
    "            end = min(i + test_batch_size, num_users)\n",
    "            batch_users = torch.arange(i, end).to(device)\n",
    "            user_e = model(\n",
    "                data=train_data.to(device)\n",
    "            )\n",
    "            rating = torch.mm(user_e[batch_users].detach(), item_emb_t)\n",
    "            _, topk = torch.topk(rating, k=test_top_k, dim=1)\n",
    "            all_scores.append(topk)\n",
    "\n",
    "            del user_e, rating\n",
    "            gc.collect()\n",
    "    all_scores = torch.cat(all_scores, dim=0).cpu().numpy()\n",
    "\n",
    "    users_list, items, ranks = [], [], []\n",
    "    for u in range(num_users):\n",
    "        seen = viewed_items.get(u, set())\n",
    "        recs = all_scores[u]\n",
    "        mask = ~np.isin(recs, list(seen))\n",
    "        filtered = recs[mask][:top_k]\n",
    "        for rank, it in enumerate(filtered, 1):\n",
    "            users_list.append(u)\n",
    "            items.append(int(it))\n",
    "            ranks.append(rank)\n",
    "    reco_df = pd.DataFrame({\n",
    "        'user_id': users_list,\n",
    "        'item_id': items,\n",
    "        'rank': ranks\n",
    "    })\n",
    "\n",
    "    metrics = {\n",
    "        f'map@{top_k}': MAP(k=top_k),\n",
    "        f'precision@{top_k}': Precision(k=top_k),\n",
    "        f'recall@{top_k}': Recall(k=top_k),\n",
    "        f'ndcg@{top_k}': NDCG(k=top_k)\n",
    "    }\n",
    "    results = calc_metrics(metrics=metrics,\n",
    "                           reco=reco_df,\n",
    "                           interactions=interactions)\n",
    "    print(f\"Step {test_step} — Test metrics:\")\n",
    "    for name, val in results.items():\n",
    "        print(f\"  {name}: {val:.9f}\")\n",
    "        experiment.log_metric(f\"Test {name} vs step\", val, step=test_step)\n",
    "    del all_scores\n",
    "    gc.collect()\n",
    "\n",
    "    model.to(device)\n",
    "    train_data.to(device)\n",
    "    model.train()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:49.743664Z",
     "iopub.status.busy": "2025-06-24T18:36:49.743032Z",
     "iopub.status.idle": "2025-06-24T18:36:49.769475Z",
     "shell.execute_reply": "2025-06-24T18:36:49.768818Z",
     "shell.execute_reply.started": "2025-06-24T18:36:49.743642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import gc\n",
    "\n",
    "def train_simple_model(model,\n",
    "                       data: HeteroData,\n",
    "                       num_epochs: int = 10,\n",
    "                       lr: float = 1e-3,\n",
    "                       batch_size: int = 1024,\n",
    "                       device: str = None,\n",
    "                       print_every: int = 100,\n",
    "                       test_every: int = 100,\n",
    "                      top_k: int = 10,\n",
    "                      test_batch_size: int = 2048):\n",
    "    \"\"\"\n",
    "    Train a SimpleItemUserGNN on item->user interactions with BPR loss.\n",
    "\n",
    "    Args:\n",
    "        model: SimpleItemUserGNN instance\n",
    "        data: HeteroData containing 'item','interacts','user' edges\n",
    "        num_epochs: number of epochs\n",
    "        lr: learning rate\n",
    "        batch_size: negative sampling batch size\n",
    "        device: 'cpu' or 'cuda'\n",
    "        print_every: print stats every N steps\n",
    "    \"\"\"\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    data = data.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # extract positive edge indices\n",
    "    src, dst = data['item', 'interacts', 'user'].edge_index\n",
    "    num_train = src.size(0)\n",
    "    print(f\"Num of training interactions: {num_train}\")\n",
    "\n",
    "    global_step = 0\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        perm = torch.randperm(num_train, device=device)\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for step, start in enumerate(range(0, num_train, batch_size), 1):\n",
    "            idx = perm[start:start + batch_size]\n",
    "            pos_items = src[idx]\n",
    "            users = dst[idx]\n",
    "            neg_items = torch.randint(\n",
    "                0,\n",
    "                model.item_emb.num_embeddings,\n",
    "                size=pos_items.size(),\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass: get updated embeddings\n",
    "            embeddings = model(data)\n",
    "            user_embs = embeddings[users]\n",
    "            pos_embs = model.item_emb.weight[pos_items]\n",
    "            neg_embs = model.item_emb.weight[neg_items]\n",
    "\n",
    "            # BPR loss\n",
    "            pos_scores = (user_embs * pos_embs).sum(dim=1)\n",
    "            neg_scores = (user_embs * neg_embs).sum(dim=1)\n",
    "            loss = -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-15).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            experiment.log_metric('Train BPR Loss vs step', loss.item(), step=global_step)\n",
    "\n",
    "            total_loss += loss.item() * users.size(0)\n",
    "\n",
    "            if step % print_every == 0 or step == 1:\n",
    "                avg_loss = total_loss / (step * batch_size)\n",
    "                print(f\"Epoch {epoch} Step {step} Loss: {loss.item():.4f}, Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "            if step % test_every == 0 or step == 1:\n",
    "                evaluate(model, data,\n",
    "                         test_batch_size, top_k,\n",
    "                         viewed_items, interactions,\n",
    "                         device, test_step=global_step)\n",
    "\n",
    "            # cleanup\n",
    "            del embeddings, user_embs, pos_embs, neg_embs, pos_scores, neg_scores\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "        epoch_loss = total_loss / num_train\n",
    "        print(f\"Epoch {epoch} completed. Train BPR Loss: {epoch_loss:.4f}\\n\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:51.653002Z",
     "iopub.status.busy": "2025-06-24T18:36:51.652340Z",
     "iopub.status.idle": "2025-06-24T18:36:52.265531Z",
     "shell.execute_reply": "2025-06-24T18:36:52.264737Z",
     "shell.execute_reply.started": "2025-06-24T18:36:51.652978Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "experiment.log_parameters(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:52.267440Z",
     "iopub.status.busy": "2025-06-24T18:36:52.266776Z",
     "iopub.status.idle": "2025-06-24T18:36:52.270878Z",
     "shell.execute_reply": "2025-06-24T18:36:52.270254Z",
     "shell.execute_reply.started": "2025-06-24T18:36:52.267413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T18:36:52.312335Z",
     "iopub.status.busy": "2025-06-24T18:36:52.311890Z",
     "iopub.status.idle": "2025-06-24T19:10:25.821146Z",
     "shell.execute_reply": "2025-06-24T19:10:25.820340Z",
     "shell.execute_reply.started": "2025-06-24T18:36:52.312318Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training interactions: 939809\n",
      "Epoch 1 Step 1 Loss: 3.2878, Avg Loss: 3.2878\n",
      "Step 0 — Test metrics:\n",
      "  precision@10: 0.002500000\n",
      "  recall@10: 0.002500000\n",
      "  ndcg@10: 0.002433203\n",
      "  map@10: 0.000693735\n",
      "Epoch 1 Step 10 Loss: 3.2169, Avg Loss: 3.2378\n",
      "Epoch 1 Step 20 Loss: 3.2794, Avg Loss: 3.2405\n",
      "Epoch 1 Step 30 Loss: 3.1672, Avg Loss: 3.2269\n",
      "Epoch 1 Step 40 Loss: 3.1380, Avg Loss: 3.2173\n",
      "Epoch 1 Step 50 Loss: 3.1365, Avg Loss: 3.2060\n",
      "Step 49 — Test metrics:\n",
      "  precision@10: 0.002682119\n",
      "  recall@10: 0.002683959\n",
      "  ndcg@10: 0.002452411\n",
      "  map@10: 0.000653441\n",
      "Epoch 1 completed. Train BPR Loss: 3.1952\n",
      "\n",
      "Epoch 2 Step 1 Loss: 3.1270, Avg Loss: 3.1270\n",
      "Step 58 — Test metrics:\n",
      "  precision@10: 0.002682119\n",
      "  recall@10: 0.002683959\n",
      "  ndcg@10: 0.002460874\n",
      "  map@10: 0.000657759\n",
      "Epoch 2 Step 10 Loss: 3.1583, Avg Loss: 3.1245\n",
      "Epoch 2 Step 20 Loss: 3.0870, Avg Loss: 3.1119\n",
      "Epoch 2 Step 30 Loss: 3.0536, Avg Loss: 3.0989\n",
      "Epoch 2 Step 40 Loss: 3.0678, Avg Loss: 3.0906\n",
      "Epoch 2 Step 50 Loss: 3.0485, Avg Loss: 3.0820\n",
      "Step 107 — Test metrics:\n",
      "  precision@10: 0.002649007\n",
      "  recall@10: 0.002650846\n",
      "  ndcg@10: 0.002407273\n",
      "  map@10: 0.000637076\n",
      "Epoch 2 completed. Train BPR Loss: 3.0760\n",
      "\n",
      "Epoch 3 Step 1 Loss: 3.0279, Avg Loss: 3.0279\n",
      "Step 116 — Test metrics:\n",
      "  precision@10: 0.002764901\n",
      "  recall@10: 0.002766740\n",
      "  ndcg@10: 0.002478458\n",
      "  map@10: 0.000648712\n",
      "Epoch 3 Step 10 Loss: 3.0177, Avg Loss: 3.0262\n",
      "Epoch 3 Step 20 Loss: 2.9396, Avg Loss: 3.0008\n",
      "Epoch 3 Step 30 Loss: 2.9434, Avg Loss: 2.9884\n",
      "Epoch 3 Step 40 Loss: 2.9432, Avg Loss: 2.9785\n",
      "Epoch 3 Step 50 Loss: 2.8864, Avg Loss: 2.9689\n",
      "Step 165 — Test metrics:\n",
      "  precision@10: 0.002715232\n",
      "  recall@10: 0.002717071\n",
      "  ndcg@10: 0.002447043\n",
      "  map@10: 0.000644763\n",
      "Epoch 3 completed. Train BPR Loss: 2.9598\n",
      "\n",
      "Epoch 4 Step 1 Loss: 2.8962, Avg Loss: 2.8962\n",
      "Step 174 — Test metrics:\n",
      "  precision@10: 0.002715232\n",
      "  recall@10: 0.002717071\n",
      "  ndcg@10: 0.002465399\n",
      "  map@10: 0.000655420\n",
      "Epoch 4 Step 10 Loss: 2.9135, Avg Loss: 2.8980\n",
      "Epoch 4 Step 20 Loss: 2.8573, Avg Loss: 2.8789\n",
      "Epoch 4 Step 30 Loss: 2.8450, Avg Loss: 2.8712\n",
      "Epoch 4 Step 40 Loss: 2.8169, Avg Loss: 2.8637\n",
      "Epoch 4 Step 50 Loss: 2.8049, Avg Loss: 2.8535\n",
      "Step 223 — Test metrics:\n",
      "  precision@10: 0.002764901\n",
      "  recall@10: 0.002766740\n",
      "  ndcg@10: 0.002524329\n",
      "  map@10: 0.000678006\n",
      "Epoch 4 completed. Train BPR Loss: 2.8449\n",
      "\n",
      "Epoch 5 Step 1 Loss: 2.8496, Avg Loss: 2.8496\n",
      "Step 232 — Test metrics:\n",
      "  precision@10: 0.002748344\n",
      "  recall@10: 0.002750184\n",
      "  ndcg@10: 0.002531267\n",
      "  map@10: 0.000687086\n",
      "Epoch 5 Step 10 Loss: 2.8028, Avg Loss: 2.7841\n",
      "Epoch 5 Step 20 Loss: 2.7388, Avg Loss: 2.7708\n",
      "Epoch 5 Step 30 Loss: 2.7138, Avg Loss: 2.7632\n",
      "Epoch 5 Step 40 Loss: 2.7125, Avg Loss: 2.7514\n",
      "Epoch 5 Step 50 Loss: 2.7508, Avg Loss: 2.7451\n",
      "Step 281 — Test metrics:\n",
      "  precision@10: 0.002781457\n",
      "  recall@10: 0.002783297\n",
      "  ndcg@10: 0.002478958\n",
      "  map@10: 0.000646156\n",
      "Epoch 5 completed. Train BPR Loss: 2.7407\n",
      "\n",
      "Epoch 6 Step 1 Loss: 2.6766, Avg Loss: 2.6766\n",
      "Step 290 — Test metrics:\n",
      "  precision@10: 0.002698675\n",
      "  recall@10: 0.002700515\n",
      "  ndcg@10: 0.002433317\n",
      "  map@10: 0.000642983\n",
      "Epoch 6 Step 10 Loss: 2.6931, Avg Loss: 2.6711\n",
      "Epoch 6 Step 20 Loss: 2.6023, Avg Loss: 2.6656\n",
      "Epoch 6 Step 30 Loss: 2.6270, Avg Loss: 2.6589\n",
      "Epoch 6 Step 40 Loss: 2.6278, Avg Loss: 2.6530\n",
      "Epoch 6 Step 50 Loss: 2.6110, Avg Loss: 2.6390\n",
      "Step 339 — Test metrics:\n",
      "  precision@10: 0.002549669\n",
      "  recall@10: 0.002551508\n",
      "  ndcg@10: 0.002312488\n",
      "  map@10: 0.000618253\n",
      "Epoch 6 completed. Train BPR Loss: 2.6314\n",
      "\n",
      "Epoch 7 Step 1 Loss: 2.6061, Avg Loss: 2.6061\n",
      "Step 348 — Test metrics:\n",
      "  precision@10: 0.002549669\n",
      "  recall@10: 0.002549669\n",
      "  ndcg@10: 0.002293268\n",
      "  map@10: 0.000606486\n",
      "Epoch 7 Step 10 Loss: 2.5862, Avg Loss: 2.5761\n",
      "Epoch 7 Step 20 Loss: 2.5520, Avg Loss: 2.5656\n",
      "Epoch 7 Step 30 Loss: 2.5044, Avg Loss: 2.5566\n",
      "Epoch 7 Step 40 Loss: 2.4848, Avg Loss: 2.5495\n",
      "Epoch 7 Step 50 Loss: 2.5253, Avg Loss: 2.5423\n",
      "Step 397 — Test metrics:\n",
      "  precision@10: 0.002533113\n",
      "  recall@10: 0.002533113\n",
      "  ndcg@10: 0.002234254\n",
      "  map@10: 0.000580377\n",
      "Epoch 7 completed. Train BPR Loss: 2.5372\n",
      "\n",
      "Epoch 8 Step 1 Loss: 2.4853, Avg Loss: 2.4853\n",
      "Step 406 — Test metrics:\n",
      "  precision@10: 0.002466887\n",
      "  recall@10: 0.002466887\n",
      "  ndcg@10: 0.002172785\n",
      "  map@10: 0.000562165\n",
      "Epoch 8 Step 10 Loss: 2.4957, Avg Loss: 2.4769\n",
      "Epoch 8 Step 20 Loss: 2.4662, Avg Loss: 2.4692\n",
      "Epoch 8 Step 30 Loss: 2.4157, Avg Loss: 2.4641\n",
      "Epoch 8 Step 40 Loss: 2.3941, Avg Loss: 2.4546\n",
      "Epoch 8 Step 50 Loss: 2.4039, Avg Loss: 2.4485\n",
      "Step 455 — Test metrics:\n",
      "  precision@10: 0.002384106\n",
      "  recall@10: 0.002384106\n",
      "  ndcg@10: 0.002087675\n",
      "  map@10: 0.000534551\n",
      "Epoch 8 completed. Train BPR Loss: 2.4434\n",
      "\n",
      "Epoch 9 Step 1 Loss: 2.4404, Avg Loss: 2.4404\n",
      "Step 464 — Test metrics:\n",
      "  precision@10: 0.002417219\n",
      "  recall@10: 0.002417219\n",
      "  ndcg@10: 0.002109674\n",
      "  map@10: 0.000538277\n",
      "Epoch 9 Step 10 Loss: 2.3556, Avg Loss: 2.4066\n",
      "Epoch 9 Step 20 Loss: 2.4326, Avg Loss: 2.3973\n",
      "Epoch 9 Step 30 Loss: 2.3652, Avg Loss: 2.3917\n",
      "Epoch 9 Step 40 Loss: 2.2738, Avg Loss: 2.3808\n",
      "Epoch 9 Step 50 Loss: 2.3167, Avg Loss: 2.3705\n",
      "Step 513 — Test metrics:\n",
      "  precision@10: 0.002235099\n",
      "  recall@10: 0.002235099\n",
      "  ndcg@10: 0.001971394\n",
      "  map@10: 0.000509283\n",
      "Epoch 9 completed. Train BPR Loss: 2.3651\n",
      "\n",
      "Epoch 10 Step 1 Loss: 2.3352, Avg Loss: 2.3352\n",
      "Step 522 — Test metrics:\n",
      "  precision@10: 0.002201987\n",
      "  recall@10: 0.002201987\n",
      "  ndcg@10: 0.001948415\n",
      "  map@10: 0.000505223\n",
      "Epoch 10 Step 10 Loss: 2.3140, Avg Loss: 2.3113\n",
      "Epoch 10 Step 20 Loss: 2.3101, Avg Loss: 2.3043\n",
      "Epoch 10 Step 30 Loss: 2.2864, Avg Loss: 2.2987\n",
      "Epoch 10 Step 40 Loss: 2.2818, Avg Loss: 2.2933\n",
      "Epoch 10 Step 50 Loss: 2.2693, Avg Loss: 2.2892\n",
      "Step 571 — Test metrics:\n",
      "  precision@10: 0.002152318\n",
      "  recall@10: 0.002152318\n",
      "  ndcg@10: 0.001930449\n",
      "  map@10: 0.000512227\n",
      "Epoch 10 completed. Train BPR Loss: 2.2852\n",
      "\n",
      "Epoch 11 Step 1 Loss: 2.2601, Avg Loss: 2.2601\n",
      "Step 580 — Test metrics:\n",
      "  precision@10: 0.002201987\n",
      "  recall@10: 0.002201987\n",
      "  ndcg@10: 0.001965542\n",
      "  map@10: 0.000518921\n",
      "Epoch 11 Step 10 Loss: 2.2350, Avg Loss: 2.2372\n",
      "Epoch 11 Step 20 Loss: 2.2489, Avg Loss: 2.2284\n",
      "Epoch 11 Step 30 Loss: 2.2227, Avg Loss: 2.2215\n",
      "Epoch 11 Step 40 Loss: 2.1725, Avg Loss: 2.2190\n",
      "Epoch 11 Step 50 Loss: 2.1922, Avg Loss: 2.2159\n",
      "Step 629 — Test metrics:\n",
      "  precision@10: 0.002086093\n",
      "  recall@10: 0.002086093\n",
      "  ndcg@10: 0.001871289\n",
      "  map@10: 0.000496078\n",
      "Epoch 11 completed. Train BPR Loss: 2.2130\n",
      "\n",
      "Epoch 12 Step 1 Loss: 2.1235, Avg Loss: 2.1235\n",
      "Step 638 — Test metrics:\n",
      "  precision@10: 0.002036424\n",
      "  recall@10: 0.002036424\n",
      "  ndcg@10: 0.001852988\n",
      "  map@10: 0.000499553\n",
      "Epoch 12 Step 10 Loss: 2.1830, Avg Loss: 2.1509\n",
      "Epoch 12 Step 20 Loss: 2.1622, Avg Loss: 2.1489\n",
      "Epoch 12 Step 30 Loss: 2.1090, Avg Loss: 2.1470\n",
      "Epoch 12 Step 40 Loss: 2.1020, Avg Loss: 2.1447\n",
      "Epoch 12 Step 50 Loss: 2.1631, Avg Loss: 2.1389\n",
      "Step 687 — Test metrics:\n",
      "  precision@10: 0.002069536\n",
      "  recall@10: 0.002069536\n",
      "  ndcg@10: 0.001874123\n",
      "  map@10: 0.000504842\n",
      "Epoch 12 completed. Train BPR Loss: 2.1343\n",
      "\n",
      "Epoch 13 Step 1 Loss: 2.0885, Avg Loss: 2.0885\n",
      "Step 696 — Test metrics:\n",
      "  precision@10: 0.002052980\n",
      "  recall@10: 0.002052980\n",
      "  ndcg@10: 0.001863763\n",
      "  map@10: 0.000503213\n",
      "Epoch 13 Step 10 Loss: 2.1076, Avg Loss: 2.0868\n",
      "Epoch 13 Step 20 Loss: 2.1130, Avg Loss: 2.0895\n",
      "Epoch 13 Step 30 Loss: 2.0719, Avg Loss: 2.0830\n",
      "Epoch 13 Step 40 Loss: 2.0982, Avg Loss: 2.0777\n",
      "Epoch 13 Step 50 Loss: 2.0615, Avg Loss: 2.0732\n",
      "Step 745 — Test metrics:\n",
      "  precision@10: 0.002086093\n",
      "  recall@10: 0.002086093\n",
      "  ndcg@10: 0.001867797\n",
      "  map@10: 0.000497451\n",
      "Epoch 13 completed. Train BPR Loss: 2.0687\n",
      "\n",
      "Epoch 14 Step 1 Loss: 2.0345, Avg Loss: 2.0345\n",
      "Step 754 — Test metrics:\n",
      "  precision@10: 0.002036424\n",
      "  recall@10: 0.002036424\n",
      "  ndcg@10: 0.001836492\n",
      "  map@10: 0.000492720\n",
      "Epoch 14 Step 10 Loss: 2.0302, Avg Loss: 2.0175\n",
      "Epoch 14 Step 20 Loss: 2.0305, Avg Loss: 2.0133\n",
      "Epoch 14 Step 30 Loss: 1.9553, Avg Loss: 2.0092\n",
      "Epoch 14 Step 40 Loss: 1.9685, Avg Loss: 2.0062\n",
      "Epoch 14 Step 50 Loss: 1.9688, Avg Loss: 2.0029\n",
      "Step 803 — Test metrics:\n",
      "  precision@10: 0.002185430\n",
      "  recall@10: 0.002185430\n",
      "  ndcg@10: 0.001934663\n",
      "  map@10: 0.000508639\n",
      "Epoch 14 completed. Train BPR Loss: 2.0004\n",
      "\n",
      "Epoch 15 Step 1 Loss: 1.9760, Avg Loss: 1.9760\n",
      "Step 812 — Test metrics:\n",
      "  precision@10: 0.002185430\n",
      "  recall@10: 0.002185430\n",
      "  ndcg@10: 0.001930947\n",
      "  map@10: 0.000506793\n",
      "Epoch 15 Step 10 Loss: 1.9842, Avg Loss: 1.9669\n",
      "Epoch 15 Step 20 Loss: 1.9272, Avg Loss: 1.9619\n",
      "Epoch 15 Step 30 Loss: 1.9570, Avg Loss: 1.9594\n",
      "Epoch 15 Step 40 Loss: 1.9421, Avg Loss: 1.9542\n",
      "Epoch 15 Step 50 Loss: 1.9173, Avg Loss: 1.9480\n",
      "Step 861 — Test metrics:\n",
      "  precision@10: 0.002119205\n",
      "  recall@10: 0.002119205\n",
      "  ndcg@10: 0.001897857\n",
      "  map@10: 0.000500729\n",
      "Epoch 15 completed. Train BPR Loss: 1.9413\n",
      "\n",
      "Epoch 16 Step 1 Loss: 1.9383, Avg Loss: 1.9383\n",
      "Step 870 — Test metrics:\n",
      "  precision@10: 0.002102649\n",
      "  recall@10: 0.002102649\n",
      "  ndcg@10: 0.001881483\n",
      "  map@10: 0.000496038\n",
      "Epoch 16 Step 10 Loss: 1.9000, Avg Loss: 1.9106\n",
      "Epoch 16 Step 20 Loss: 1.9231, Avg Loss: 1.9056\n",
      "Epoch 16 Step 30 Loss: 1.8858, Avg Loss: 1.8972\n",
      "Epoch 16 Step 40 Loss: 1.8347, Avg Loss: 1.8923\n",
      "Epoch 16 Step 50 Loss: 1.8316, Avg Loss: 1.8861\n",
      "Step 919 — Test metrics:\n",
      "  precision@10: 0.002152318\n",
      "  recall@10: 0.002152318\n",
      "  ndcg@10: 0.001934052\n",
      "  map@10: 0.000511918\n",
      "Epoch 16 completed. Train BPR Loss: 1.8824\n",
      "\n",
      "Epoch 17 Step 1 Loss: 1.8439, Avg Loss: 1.8439\n",
      "Step 928 — Test metrics:\n",
      "  precision@10: 0.002152318\n",
      "  recall@10: 0.002152318\n",
      "  ndcg@10: 0.001939170\n",
      "  map@10: 0.000514401\n",
      "Epoch 17 Step 10 Loss: 1.8542, Avg Loss: 1.8552\n",
      "Epoch 17 Step 20 Loss: 1.7951, Avg Loss: 1.8407\n",
      "Epoch 17 Step 30 Loss: 1.8014, Avg Loss: 1.8404\n",
      "Epoch 17 Step 40 Loss: 1.8136, Avg Loss: 1.8322\n",
      "Epoch 17 Step 50 Loss: 1.8708, Avg Loss: 1.8295\n",
      "Step 977 — Test metrics:\n",
      "  precision@10: 0.002168874\n",
      "  recall@10: 0.002168874\n",
      "  ndcg@10: 0.001948324\n",
      "  map@10: 0.000514934\n",
      "Epoch 17 completed. Train BPR Loss: 1.8262\n",
      "\n",
      "Epoch 18 Step 1 Loss: 1.8021, Avg Loss: 1.8021\n",
      "Step 986 — Test metrics:\n",
      "  precision@10: 0.002185430\n",
      "  recall@10: 0.002185430\n",
      "  ndcg@10: 0.001961727\n",
      "  map@10: 0.000517857\n",
      "Epoch 18 Step 10 Loss: 1.7886, Avg Loss: 1.7813\n",
      "Epoch 18 Step 20 Loss: 1.7814, Avg Loss: 1.7837\n",
      "Epoch 18 Step 30 Loss: 1.7809, Avg Loss: 1.7806\n",
      "Epoch 18 Step 40 Loss: 1.7575, Avg Loss: 1.7733\n",
      "Epoch 18 Step 50 Loss: 1.7342, Avg Loss: 1.7685\n",
      "Step 1035 — Test metrics:\n",
      "  precision@10: 0.002201987\n",
      "  recall@10: 0.002201987\n",
      "  ndcg@10: 0.001979871\n",
      "  map@10: 0.000523218\n",
      "Epoch 18 completed. Train BPR Loss: 1.7635\n",
      "\n",
      "Epoch 19 Step 1 Loss: 1.7191, Avg Loss: 1.7191\n",
      "Step 1044 — Test metrics:\n",
      "  precision@10: 0.002235099\n",
      "  recall@10: 0.002235099\n",
      "  ndcg@10: 0.002004501\n",
      "  map@10: 0.000528185\n",
      "Epoch 19 Step 10 Loss: 1.7145, Avg Loss: 1.7287\n",
      "Epoch 19 Step 20 Loss: 1.7005, Avg Loss: 1.7275\n",
      "Epoch 19 Step 30 Loss: 1.7187, Avg Loss: 1.7224\n",
      "Epoch 19 Step 40 Loss: 1.6955, Avg Loss: 1.7202\n",
      "Epoch 19 Step 50 Loss: 1.7151, Avg Loss: 1.7153\n",
      "Step 1093 — Test metrics:\n",
      "  precision@10: 0.002201987\n",
      "  recall@10: 0.002201987\n",
      "  ndcg@10: 0.001989450\n",
      "  map@10: 0.000527797\n",
      "Epoch 19 completed. Train BPR Loss: 1.7138\n",
      "\n",
      "Epoch 20 Step 1 Loss: 1.6703, Avg Loss: 1.6703\n",
      "Step 1102 — Test metrics:\n",
      "  precision@10: 0.002201987\n",
      "  recall@10: 0.002201987\n",
      "  ndcg@10: 0.001990627\n",
      "  map@10: 0.000528323\n",
      "Epoch 20 Step 10 Loss: 1.6948, Avg Loss: 1.6702\n",
      "Epoch 20 Step 20 Loss: 1.6383, Avg Loss: 1.6723\n",
      "Epoch 20 Step 30 Loss: 1.6496, Avg Loss: 1.6715\n",
      "Epoch 20 Step 40 Loss: 1.6757, Avg Loss: 1.6662\n",
      "Epoch 20 Step 50 Loss: 1.6163, Avg Loss: 1.6616\n",
      "Step 1151 — Test metrics:\n",
      "  precision@10: 0.002268212\n",
      "  recall@10: 0.002268212\n",
      "  ndcg@10: 0.002050430\n",
      "  map@10: 0.000543808\n",
      "Epoch 20 completed. Train BPR Loss: 1.6589\n",
      "\n",
      "Epoch 21 Step 1 Loss: 1.6789, Avg Loss: 1.6789\n",
      "Step 1160 — Test metrics:\n",
      "  precision@10: 0.002301325\n",
      "  recall@10: 0.002301325\n",
      "  ndcg@10: 0.002074679\n",
      "  map@10: 0.000548578\n",
      "Epoch 21 Step 10 Loss: 1.6351, Avg Loss: 1.6353\n",
      "Epoch 21 Step 20 Loss: 1.5961, Avg Loss: 1.6303\n",
      "Epoch 21 Step 30 Loss: 1.6006, Avg Loss: 1.6258\n",
      "Epoch 21 Step 40 Loss: 1.6089, Avg Loss: 1.6204\n",
      "Epoch 21 Step 50 Loss: 1.6220, Avg Loss: 1.6179\n",
      "Step 1209 — Test metrics:\n",
      "  precision@10: 0.002301325\n",
      "  recall@10: 0.002301325\n",
      "  ndcg@10: 0.002081186\n",
      "  map@10: 0.000551272\n",
      "Epoch 21 completed. Train BPR Loss: 1.6138\n",
      "\n",
      "Epoch 22 Step 1 Loss: 1.5688, Avg Loss: 1.5688\n",
      "Step 1218 — Test metrics:\n",
      "  precision@10: 0.002284768\n",
      "  recall@10: 0.002284768\n",
      "  ndcg@10: 0.002071582\n",
      "  map@10: 0.000550017\n",
      "Epoch 22 Step 10 Loss: 1.5776, Avg Loss: 1.5860\n",
      "Epoch 22 Step 20 Loss: 1.5415, Avg Loss: 1.5837\n",
      "Epoch 22 Step 30 Loss: 1.5673, Avg Loss: 1.5797\n",
      "Epoch 22 Step 40 Loss: 1.5735, Avg Loss: 1.5765\n",
      "Epoch 22 Step 50 Loss: 1.5467, Avg Loss: 1.5710\n",
      "Step 1267 — Test metrics:\n",
      "  precision@10: 0.002301325\n",
      "  recall@10: 0.002301325\n",
      "  ndcg@10: 0.002085699\n",
      "  map@10: 0.000553841\n",
      "Epoch 22 completed. Train BPR Loss: 1.5684\n",
      "\n",
      "Epoch 23 Step 1 Loss: 1.5420, Avg Loss: 1.5420\n",
      "Step 1276 — Test metrics:\n",
      "  precision@10: 0.002350993\n",
      "  recall@10: 0.002350993\n",
      "  ndcg@10: 0.002120899\n",
      "  map@10: 0.000560595\n",
      "Epoch 23 Step 10 Loss: 1.5523, Avg Loss: 1.5440\n",
      "Epoch 23 Step 20 Loss: 1.5057, Avg Loss: 1.5303\n",
      "Epoch 23 Step 30 Loss: 1.5106, Avg Loss: 1.5295\n",
      "Epoch 23 Step 40 Loss: 1.5546, Avg Loss: 1.5285\n",
      "Epoch 23 Step 50 Loss: 1.5244, Avg Loss: 1.5231\n",
      "Step 1325 — Test metrics:\n",
      "  precision@10: 0.002450331\n",
      "  recall@10: 0.002450331\n",
      "  ndcg@10: 0.002175171\n",
      "  map@10: 0.000565351\n",
      "Epoch 23 completed. Train BPR Loss: 1.5192\n",
      "\n",
      "Epoch 24 Step 1 Loss: 1.5020, Avg Loss: 1.5020\n",
      "Step 1334 — Test metrics:\n",
      "  precision@10: 0.002483444\n",
      "  recall@10: 0.002483444\n",
      "  ndcg@10: 0.002202889\n",
      "  map@10: 0.000572637\n",
      "Epoch 24 Step 10 Loss: 1.4908, Avg Loss: 1.4832\n",
      "Epoch 24 Step 20 Loss: 1.4726, Avg Loss: 1.4889\n",
      "Epoch 24 Step 30 Loss: 1.4578, Avg Loss: 1.4851\n",
      "Epoch 24 Step 40 Loss: 1.4642, Avg Loss: 1.4804\n",
      "Epoch 24 Step 50 Loss: 1.4722, Avg Loss: 1.4777\n",
      "Step 1383 — Test metrics:\n",
      "  precision@10: 0.002549669\n",
      "  recall@10: 0.002549669\n",
      "  ndcg@10: 0.002269113\n",
      "  map@10: 0.000592597\n",
      "Epoch 24 completed. Train BPR Loss: 1.4749\n",
      "\n",
      "Epoch 25 Step 1 Loss: 1.4003, Avg Loss: 1.4003\n",
      "Step 1392 — Test metrics:\n",
      "  precision@10: 0.002500000\n",
      "  recall@10: 0.002500000\n",
      "  ndcg@10: 0.002237327\n",
      "  map@10: 0.000587578\n",
      "Epoch 25 Step 10 Loss: 1.4387, Avg Loss: 1.4398\n",
      "Epoch 25 Step 20 Loss: 1.4717, Avg Loss: 1.4428\n",
      "Epoch 25 Step 30 Loss: 1.4432, Avg Loss: 1.4410\n",
      "Epoch 25 Step 40 Loss: 1.4256, Avg Loss: 1.4371\n",
      "Epoch 25 Step 50 Loss: 1.4187, Avg Loss: 1.4342\n",
      "Step 1441 — Test metrics:\n",
      "  precision@10: 0.002582781\n",
      "  recall@10: 0.002582781\n",
      "  ndcg@10: 0.002293086\n",
      "  map@10: 0.000597472\n",
      "Epoch 25 completed. Train BPR Loss: 1.4312\n",
      "\n",
      "Epoch 26 Step 1 Loss: 1.4197, Avg Loss: 1.4197\n",
      "Step 1450 — Test metrics:\n",
      "  precision@10: 0.002599338\n",
      "  recall@10: 0.002599338\n",
      "  ndcg@10: 0.002307762\n",
      "  map@10: 0.000601092\n",
      "Epoch 26 Step 10 Loss: 1.4156, Avg Loss: 1.4142\n",
      "Epoch 26 Step 20 Loss: 1.3511, Avg Loss: 1.4052\n",
      "Epoch 26 Step 30 Loss: 1.3755, Avg Loss: 1.4027\n",
      "Epoch 26 Step 40 Loss: 1.3943, Avg Loss: 1.4006\n",
      "Epoch 26 Step 50 Loss: 1.3514, Avg Loss: 1.3959\n",
      "Step 1499 — Test metrics:\n",
      "  precision@10: 0.002682119\n",
      "  recall@10: 0.002682119\n",
      "  ndcg@10: 0.002379427\n",
      "  map@10: 0.000618601\n",
      "Epoch 26 completed. Train BPR Loss: 1.3925\n",
      "\n",
      "Epoch 27 Step 1 Loss: 1.3665, Avg Loss: 1.3665\n",
      "Step 1508 — Test metrics:\n",
      "  precision@10: 0.002682119\n",
      "  recall@10: 0.002682119\n",
      "  ndcg@10: 0.002381813\n",
      "  map@10: 0.000619731\n",
      "Epoch 27 Step 10 Loss: 1.3459, Avg Loss: 1.3679\n",
      "Epoch 27 Step 20 Loss: 1.3665, Avg Loss: 1.3631\n",
      "Epoch 27 Step 30 Loss: 1.3584, Avg Loss: 1.3583\n",
      "Epoch 27 Step 40 Loss: 1.3472, Avg Loss: 1.3549\n",
      "Epoch 27 Step 50 Loss: 1.3271, Avg Loss: 1.3530\n",
      "Step 1557 — Test metrics:\n",
      "  precision@10: 0.002731788\n",
      "  recall@10: 0.002731788\n",
      "  ndcg@10: 0.002424188\n",
      "  map@10: 0.000629763\n",
      "Epoch 27 completed. Train BPR Loss: 1.3532\n",
      "\n",
      "Epoch 28 Step 1 Loss: 1.3446, Avg Loss: 1.3446\n",
      "Step 1566 — Test metrics:\n",
      "  precision@10: 0.002715232\n",
      "  recall@10: 0.002715232\n",
      "  ndcg@10: 0.002410144\n",
      "  map@10: 0.000626314\n",
      "Epoch 28 Step 10 Loss: 1.2858, Avg Loss: 1.3283\n",
      "Epoch 28 Step 20 Loss: 1.3049, Avg Loss: 1.3260\n",
      "Epoch 28 Step 30 Loss: 1.3244, Avg Loss: 1.3228\n",
      "Epoch 28 Step 40 Loss: 1.2911, Avg Loss: 1.3200\n",
      "Epoch 28 Step 50 Loss: 1.3012, Avg Loss: 1.3156\n",
      "Step 1615 — Test metrics:\n",
      "  precision@10: 0.002665563\n",
      "  recall@10: 0.002665563\n",
      "  ndcg@10: 0.002389564\n",
      "  map@10: 0.000627116\n",
      "Epoch 28 completed. Train BPR Loss: 1.3127\n",
      "\n",
      "Epoch 29 Step 1 Loss: 1.2966, Avg Loss: 1.2966\n",
      "Step 1624 — Test metrics:\n",
      "  precision@10: 0.002682119\n",
      "  recall@10: 0.002682119\n",
      "  ndcg@10: 0.002403818\n",
      "  map@10: 0.000630506\n",
      "Epoch 29 Step 10 Loss: 1.2688, Avg Loss: 1.2859\n",
      "Epoch 29 Step 20 Loss: 1.2739, Avg Loss: 1.2828\n",
      "Epoch 29 Step 30 Loss: 1.2728, Avg Loss: 1.2799\n",
      "Epoch 29 Step 40 Loss: 1.2952, Avg Loss: 1.2792\n",
      "Epoch 29 Step 50 Loss: 1.2709, Avg Loss: 1.2766\n",
      "Step 1673 — Test metrics:\n",
      "  precision@10: 0.002764901\n",
      "  recall@10: 0.002764901\n",
      "  ndcg@10: 0.002455983\n",
      "  map@10: 0.000636964\n",
      "Epoch 29 completed. Train BPR Loss: 1.2740\n",
      "\n",
      "Epoch 30 Step 1 Loss: 1.2959, Avg Loss: 1.2959\n",
      "Step 1682 — Test metrics:\n",
      "  precision@10: 0.002781457\n",
      "  recall@10: 0.002781457\n",
      "  ndcg@10: 0.002460934\n",
      "  map@10: 0.000635466\n",
      "Epoch 30 Step 10 Loss: 1.2445, Avg Loss: 1.2546\n",
      "Epoch 30 Step 20 Loss: 1.2558, Avg Loss: 1.2518\n",
      "Epoch 30 Step 30 Loss: 1.2229, Avg Loss: 1.2510\n",
      "Epoch 30 Step 40 Loss: 1.2428, Avg Loss: 1.2473\n",
      "Epoch 30 Step 50 Loss: 1.2128, Avg Loss: 1.2454\n",
      "Step 1731 — Test metrics:\n",
      "  precision@10: 0.002781457\n",
      "  recall@10: 0.002781457\n",
      "  ndcg@10: 0.002477386\n",
      "  map@10: 0.000644020\n",
      "Epoch 30 completed. Train BPR Loss: 1.2437\n",
      "\n",
      "Epoch 31 Step 1 Loss: 1.2204, Avg Loss: 1.2204\n",
      "Step 1740 — Test metrics:\n",
      "  precision@10: 0.002781457\n",
      "  recall@10: 0.002781457\n",
      "  ndcg@10: 0.002475724\n",
      "  map@10: 0.000643350\n",
      "Epoch 31 Step 10 Loss: 1.2323, Avg Loss: 1.2303\n",
      "Epoch 31 Step 20 Loss: 1.2141, Avg Loss: 1.2210\n",
      "Epoch 31 Step 30 Loss: 1.1840, Avg Loss: 1.2152\n",
      "Epoch 31 Step 40 Loss: 1.1796, Avg Loss: 1.2118\n",
      "Epoch 31 Step 50 Loss: 1.2106, Avg Loss: 1.2107\n",
      "Step 1789 — Test metrics:\n",
      "  precision@10: 0.002798013\n",
      "  recall@10: 0.002798013\n",
      "  ndcg@10: 0.002503979\n",
      "  map@10: 0.000653284\n",
      "Epoch 31 completed. Train BPR Loss: 1.2078\n",
      "\n",
      "Epoch 32 Step 1 Loss: 1.1737, Avg Loss: 1.1737\n",
      "Step 1798 — Test metrics:\n",
      "  precision@10: 0.002781457\n",
      "  recall@10: 0.002781457\n",
      "  ndcg@10: 0.002491721\n",
      "  map@10: 0.000650781\n",
      "Epoch 32 Step 10 Loss: 1.1969, Avg Loss: 1.1882\n",
      "Epoch 32 Step 20 Loss: 1.1681, Avg Loss: 1.1814\n",
      "Epoch 32 Step 30 Loss: 1.1687, Avg Loss: 1.1800\n",
      "Epoch 32 Step 40 Loss: 1.1693, Avg Loss: 1.1788\n",
      "Epoch 32 Step 50 Loss: 1.1816, Avg Loss: 1.1779\n",
      "Step 1847 — Test metrics:\n",
      "  precision@10: 0.002831126\n",
      "  recall@10: 0.002831126\n",
      "  ndcg@10: 0.002529882\n",
      "  map@10: 0.000658783\n",
      "Epoch 32 completed. Train BPR Loss: 1.1759\n",
      "\n",
      "Epoch 33 Step 1 Loss: 1.1739, Avg Loss: 1.1739\n",
      "Step 1856 — Test metrics:\n",
      "  precision@10: 0.002831126\n",
      "  recall@10: 0.002831126\n",
      "  ndcg@10: 0.002534117\n",
      "  map@10: 0.000661128\n",
      "Epoch 33 Step 10 Loss: 1.1440, Avg Loss: 1.1542\n",
      "Epoch 33 Step 20 Loss: 1.1241, Avg Loss: 1.1511\n",
      "Epoch 33 Step 30 Loss: 1.1511, Avg Loss: 1.1488\n",
      "Epoch 33 Step 40 Loss: 1.1222, Avg Loss: 1.1457\n",
      "Epoch 33 Step 50 Loss: 1.1152, Avg Loss: 1.1434\n",
      "Step 1905 — Test metrics:\n",
      "  precision@10: 0.002831126\n",
      "  recall@10: 0.002831126\n",
      "  ndcg@10: 0.002527963\n",
      "  map@10: 0.000657410\n",
      "Epoch 33 completed. Train BPR Loss: 1.1419\n",
      "\n",
      "Epoch 34 Step 1 Loss: 1.1187, Avg Loss: 1.1187\n",
      "Step 1914 — Test metrics:\n",
      "  precision@10: 0.002864238\n",
      "  recall@10: 0.002864238\n",
      "  ndcg@10: 0.002549141\n",
      "  map@10: 0.000662514\n",
      "Epoch 34 Step 10 Loss: 1.1291, Avg Loss: 1.1195\n",
      "Epoch 34 Step 20 Loss: 1.1105, Avg Loss: 1.1228\n",
      "Epoch 34 Step 30 Loss: 1.0998, Avg Loss: 1.1196\n",
      "Epoch 34 Step 40 Loss: 1.1251, Avg Loss: 1.1174\n",
      "Epoch 34 Step 50 Loss: 1.1005, Avg Loss: 1.1147\n",
      "Step 1963 — Test metrics:\n",
      "  precision@10: 0.002963576\n",
      "  recall@10: 0.002963576\n",
      "  ndcg@10: 0.002624791\n",
      "  map@10: 0.000678368\n",
      "Epoch 34 completed. Train BPR Loss: 1.1135\n",
      "\n",
      "Epoch 35 Step 1 Loss: 1.1346, Avg Loss: 1.1346\n",
      "Step 1972 — Test metrics:\n",
      "  precision@10: 0.002980132\n",
      "  recall@10: 0.002980132\n",
      "  ndcg@10: 0.002635764\n",
      "  map@10: 0.000679977\n",
      "Epoch 35 Step 10 Loss: 1.0839, Avg Loss: 1.0970\n",
      "Epoch 35 Step 20 Loss: 1.0784, Avg Loss: 1.0962\n",
      "Epoch 35 Step 30 Loss: 1.0917, Avg Loss: 1.0927\n",
      "Epoch 35 Step 40 Loss: 1.0754, Avg Loss: 1.0904\n",
      "Epoch 35 Step 50 Loss: 1.0621, Avg Loss: 1.0867\n",
      "Step 2021 — Test metrics:\n",
      "  precision@10: 0.003079470\n",
      "  recall@10: 0.003079470\n",
      "  ndcg@10: 0.002697364\n",
      "  map@10: 0.000687172\n",
      "Epoch 35 completed. Train BPR Loss: 1.0853\n",
      "\n",
      "Epoch 36 Step 1 Loss: 1.0817, Avg Loss: 1.0817\n",
      "Step 2030 — Test metrics:\n",
      "  precision@10: 0.003096026\n",
      "  recall@10: 0.003096026\n",
      "  ndcg@10: 0.002707875\n",
      "  map@10: 0.000688735\n",
      "Epoch 36 Step 10 Loss: 1.0542, Avg Loss: 1.0673\n",
      "Epoch 36 Step 20 Loss: 1.0696, Avg Loss: 1.0632\n",
      "Epoch 36 Step 30 Loss: 1.0463, Avg Loss: 1.0600\n",
      "Epoch 36 Step 40 Loss: 1.0439, Avg Loss: 1.0577\n",
      "Epoch 36 Step 50 Loss: 1.0195, Avg Loss: 1.0566\n",
      "Step 2079 — Test metrics:\n",
      "  precision@10: 0.003112583\n",
      "  recall@10: 0.003112583\n",
      "  ndcg@10: 0.002736628\n",
      "  map@10: 0.000702473\n",
      "Epoch 36 completed. Train BPR Loss: 1.0548\n",
      "\n",
      "Epoch 37 Step 1 Loss: 1.0480, Avg Loss: 1.0480\n",
      "Step 2088 — Test metrics:\n",
      "  precision@10: 0.003145695\n",
      "  recall@10: 0.003145695\n",
      "  ndcg@10: 0.002758855\n",
      "  map@10: 0.000706178\n",
      "Epoch 37 Step 10 Loss: 1.0440, Avg Loss: 1.0419\n",
      "Epoch 37 Step 20 Loss: 1.0274, Avg Loss: 1.0384\n",
      "Epoch 37 Step 30 Loss: 1.0300, Avg Loss: 1.0365\n",
      "Epoch 37 Step 40 Loss: 1.0105, Avg Loss: 1.0348\n",
      "Epoch 37 Step 50 Loss: 1.0226, Avg Loss: 1.0326\n",
      "Step 2137 — Test metrics:\n",
      "  precision@10: 0.003294702\n",
      "  recall@10: 0.003294702\n",
      "  ndcg@10: 0.002862260\n",
      "  map@10: 0.000725271\n",
      "Epoch 37 completed. Train BPR Loss: 1.0310\n",
      "\n",
      "Epoch 38 Step 1 Loss: 1.0045, Avg Loss: 1.0045\n",
      "Step 2146 — Test metrics:\n",
      "  precision@10: 0.003294702\n",
      "  recall@10: 0.003294702\n",
      "  ndcg@10: 0.002863966\n",
      "  map@10: 0.000726282\n",
      "Epoch 38 Step 10 Loss: 0.9992, Avg Loss: 1.0145\n",
      "Epoch 38 Step 20 Loss: 0.9966, Avg Loss: 1.0095\n",
      "Epoch 38 Step 30 Loss: 0.9920, Avg Loss: 1.0077\n",
      "Epoch 38 Step 40 Loss: 0.9997, Avg Loss: 1.0053\n",
      "Epoch 38 Step 50 Loss: 1.0235, Avg Loss: 1.0040\n",
      "Step 2195 — Test metrics:\n",
      "  precision@10: 0.003294702\n",
      "  recall@10: 0.003294702\n",
      "  ndcg@10: 0.002861607\n",
      "  map@10: 0.000724876\n",
      "Epoch 38 completed. Train BPR Loss: 1.0023\n",
      "\n",
      "Epoch 39 Step 1 Loss: 0.9774, Avg Loss: 0.9774\n",
      "Step 2204 — Test metrics:\n",
      "  precision@10: 0.003294702\n",
      "  recall@10: 0.003294702\n",
      "  ndcg@10: 0.002857092\n",
      "  map@10: 0.000722577\n",
      "Epoch 39 Step 10 Loss: 0.9853, Avg Loss: 0.9865\n",
      "Epoch 39 Step 20 Loss: 0.9879, Avg Loss: 0.9863\n",
      "Epoch 39 Step 30 Loss: 0.9484, Avg Loss: 0.9832\n",
      "Epoch 39 Step 40 Loss: 0.9818, Avg Loss: 0.9800\n",
      "Epoch 39 Step 50 Loss: 0.9723, Avg Loss: 0.9766\n",
      "Step 2253 — Test metrics:\n",
      "  precision@10: 0.003360927\n",
      "  recall@10: 0.003360927\n",
      "  ndcg@10: 0.002897958\n",
      "  map@10: 0.000727754\n",
      "Epoch 39 completed. Train BPR Loss: 0.9748\n",
      "\n",
      "Epoch 40 Step 1 Loss: 0.9698, Avg Loss: 0.9698\n",
      "Step 2262 — Test metrics:\n",
      "  precision@10: 0.003377483\n",
      "  recall@10: 0.003377483\n",
      "  ndcg@10: 0.002917380\n",
      "  map@10: 0.000733752\n",
      "Epoch 40 Step 10 Loss: 0.9307, Avg Loss: 0.9549\n",
      "Epoch 40 Step 20 Loss: 0.9457, Avg Loss: 0.9545\n",
      "Epoch 40 Step 30 Loss: 0.9482, Avg Loss: 0.9557\n",
      "Epoch 40 Step 40 Loss: 0.9523, Avg Loss: 0.9555\n",
      "Epoch 40 Step 50 Loss: 0.9563, Avg Loss: 0.9548\n",
      "Step 2311 — Test metrics:\n",
      "  precision@10: 0.003410596\n",
      "  recall@10: 0.003410596\n",
      "  ndcg@10: 0.002945009\n",
      "  map@10: 0.000738496\n",
      "Epoch 40 completed. Train BPR Loss: 0.9524\n",
      "\n",
      "Epoch 41 Step 1 Loss: 0.9562, Avg Loss: 0.9562\n",
      "Step 2320 — Test metrics:\n",
      "  precision@10: 0.003394040\n",
      "  recall@10: 0.003394040\n",
      "  ndcg@10: 0.002937360\n",
      "  map@10: 0.000738240\n",
      "Epoch 41 Step 10 Loss: 0.9381, Avg Loss: 0.9413\n",
      "Epoch 41 Step 20 Loss: 0.9556, Avg Loss: 0.9388\n",
      "Epoch 41 Step 30 Loss: 0.9160, Avg Loss: 0.9356\n",
      "Epoch 41 Step 40 Loss: 0.9267, Avg Loss: 0.9319\n",
      "Epoch 41 Step 50 Loss: 0.9324, Avg Loss: 0.9294\n",
      "Step 2369 — Test metrics:\n",
      "  precision@10: 0.003394040\n",
      "  recall@10: 0.003394040\n",
      "  ndcg@10: 0.002942494\n",
      "  map@10: 0.000740756\n",
      "Epoch 41 completed. Train BPR Loss: 0.9283\n",
      "\n",
      "Epoch 42 Step 1 Loss: 0.9098, Avg Loss: 0.9098\n",
      "Step 2378 — Test metrics:\n",
      "  precision@10: 0.003410596\n",
      "  recall@10: 0.003410596\n",
      "  ndcg@10: 0.002955216\n",
      "  map@10: 0.000745211\n",
      "Epoch 42 Step 10 Loss: 0.9297, Avg Loss: 0.9122\n",
      "Epoch 42 Step 20 Loss: 0.9259, Avg Loss: 0.9098\n",
      "Epoch 42 Step 30 Loss: 0.8810, Avg Loss: 0.9104\n",
      "Epoch 42 Step 40 Loss: 0.9030, Avg Loss: 0.9108\n",
      "Epoch 42 Step 50 Loss: 0.8838, Avg Loss: 0.9081\n",
      "Step 2427 — Test metrics:\n",
      "  precision@10: 0.003410596\n",
      "  recall@10: 0.003410596\n",
      "  ndcg@10: 0.002950630\n",
      "  map@10: 0.000741052\n",
      "Epoch 42 completed. Train BPR Loss: 0.9071\n",
      "\n",
      "Epoch 43 Step 1 Loss: 0.9112, Avg Loss: 0.9112\n",
      "Step 2436 — Test metrics:\n",
      "  precision@10: 0.003427152\n",
      "  recall@10: 0.003427152\n",
      "  ndcg@10: 0.002962918\n",
      "  map@10: 0.000743673\n",
      "Epoch 43 Step 10 Loss: 0.8958, Avg Loss: 0.8957\n",
      "Epoch 43 Step 20 Loss: 0.8832, Avg Loss: 0.8930\n",
      "Epoch 43 Step 30 Loss: 0.8712, Avg Loss: 0.8910\n",
      "Epoch 43 Step 40 Loss: 0.8780, Avg Loss: 0.8889\n",
      "Epoch 43 Step 50 Loss: 0.8909, Avg Loss: 0.8876\n",
      "Step 2485 — Test metrics:\n",
      "  precision@10: 0.003476821\n",
      "  recall@10: 0.003476821\n",
      "  ndcg@10: 0.003002097\n",
      "  map@10: 0.000752359\n",
      "Epoch 43 completed. Train BPR Loss: 0.8855\n",
      "\n",
      "Epoch 44 Step 1 Loss: 0.8777, Avg Loss: 0.8777\n",
      "Step 2494 — Test metrics:\n",
      "  precision@10: 0.003493377\n",
      "  recall@10: 0.003493377\n",
      "  ndcg@10: 0.003013771\n",
      "  map@10: 0.000756228\n",
      "Epoch 44 Step 10 Loss: 0.8861, Avg Loss: 0.8739\n",
      "Epoch 44 Step 20 Loss: 0.8633, Avg Loss: 0.8734\n",
      "Epoch 44 Step 30 Loss: 0.8557, Avg Loss: 0.8724\n",
      "Epoch 44 Step 40 Loss: 0.8652, Avg Loss: 0.8683\n",
      "Epoch 44 Step 50 Loss: 0.8366, Avg Loss: 0.8665\n",
      "Step 2543 — Test metrics:\n",
      "  precision@10: 0.003592715\n",
      "  recall@10: 0.003592715\n",
      "  ndcg@10: 0.003089100\n",
      "  map@10: 0.000770235\n",
      "Epoch 44 completed. Train BPR Loss: 0.8647\n",
      "\n",
      "Epoch 45 Step 1 Loss: 0.8788, Avg Loss: 0.8788\n",
      "Step 2552 — Test metrics:\n",
      "  precision@10: 0.003642384\n",
      "  recall@10: 0.003642384\n",
      "  ndcg@10: 0.003121257\n",
      "  map@10: 0.000775084\n",
      "Epoch 45 Step 10 Loss: 0.8654, Avg Loss: 0.8587\n",
      "Epoch 45 Step 20 Loss: 0.8568, Avg Loss: 0.8542\n",
      "Epoch 45 Step 30 Loss: 0.8448, Avg Loss: 0.8526\n",
      "Epoch 45 Step 40 Loss: 0.8493, Avg Loss: 0.8518\n",
      "Epoch 45 Step 50 Loss: 0.8445, Avg Loss: 0.8502\n",
      "Step 2601 — Test metrics:\n",
      "  precision@10: 0.003725166\n",
      "  recall@10: 0.003725166\n",
      "  ndcg@10: 0.003187622\n",
      "  map@10: 0.000790372\n",
      "Epoch 45 completed. Train BPR Loss: 0.8486\n",
      "\n",
      "Epoch 46 Step 1 Loss: 0.8386, Avg Loss: 0.8386\n",
      "Step 2610 — Test metrics:\n",
      "  precision@10: 0.003725166\n",
      "  recall@10: 0.003725166\n",
      "  ndcg@10: 0.003188593\n",
      "  map@10: 0.000791272\n",
      "Epoch 46 Step 10 Loss: 0.8387, Avg Loss: 0.8341\n",
      "Epoch 46 Step 20 Loss: 0.8344, Avg Loss: 0.8336\n",
      "Epoch 46 Step 30 Loss: 0.8007, Avg Loss: 0.8310\n",
      "Epoch 46 Step 40 Loss: 0.8146, Avg Loss: 0.8295\n",
      "Epoch 46 Step 50 Loss: 0.8039, Avg Loss: 0.8265\n",
      "Step 2659 — Test metrics:\n",
      "  precision@10: 0.003807947\n",
      "  recall@10: 0.003807947\n",
      "  ndcg@10: 0.003238567\n",
      "  map@10: 0.000797376\n",
      "Epoch 46 completed. Train BPR Loss: 0.8260\n",
      "\n",
      "Epoch 47 Step 1 Loss: 0.8072, Avg Loss: 0.8072\n",
      "Step 2668 — Test metrics:\n",
      "  precision@10: 0.003841060\n",
      "  recall@10: 0.003841060\n",
      "  ndcg@10: 0.003256950\n",
      "  map@10: 0.000799380\n",
      "Epoch 47 Step 10 Loss: 0.8188, Avg Loss: 0.8115\n",
      "Epoch 47 Step 20 Loss: 0.8063, Avg Loss: 0.8109\n",
      "Epoch 47 Step 30 Loss: 0.8095, Avg Loss: 0.8102\n",
      "Epoch 47 Step 40 Loss: 0.8143, Avg Loss: 0.8097\n",
      "Epoch 47 Step 50 Loss: 0.7812, Avg Loss: 0.8085\n",
      "Step 2717 — Test metrics:\n",
      "  precision@10: 0.003890728\n",
      "  recall@10: 0.003890728\n",
      "  ndcg@10: 0.003307513\n",
      "  map@10: 0.000813558\n",
      "Epoch 47 completed. Train BPR Loss: 0.8076\n",
      "\n",
      "Epoch 48 Step 1 Loss: 0.8186, Avg Loss: 0.8186\n",
      "Step 2726 — Test metrics:\n",
      "  precision@10: 0.003907285\n",
      "  recall@10: 0.003907285\n",
      "  ndcg@10: 0.003321079\n",
      "  map@10: 0.000817198\n",
      "Epoch 48 Step 10 Loss: 0.8035, Avg Loss: 0.7996\n",
      "Epoch 48 Step 20 Loss: 0.7884, Avg Loss: 0.7966\n",
      "Epoch 48 Step 30 Loss: 0.7910, Avg Loss: 0.7948\n",
      "Epoch 48 Step 40 Loss: 0.7943, Avg Loss: 0.7933\n",
      "Epoch 48 Step 50 Loss: 0.7879, Avg Loss: 0.7922\n",
      "Step 2775 — Test metrics:\n",
      "  precision@10: 0.003923841\n",
      "  recall@10: 0.003923841\n",
      "  ndcg@10: 0.003332670\n",
      "  map@10: 0.000819747\n",
      "Epoch 48 completed. Train BPR Loss: 0.7912\n",
      "\n",
      "Epoch 49 Step 1 Loss: 0.7903, Avg Loss: 0.7903\n",
      "Step 2784 — Test metrics:\n",
      "  precision@10: 0.003940397\n",
      "  recall@10: 0.003940397\n",
      "  ndcg@10: 0.003343488\n",
      "  map@10: 0.000821475\n",
      "Epoch 49 Step 10 Loss: 0.8024, Avg Loss: 0.7873\n",
      "Epoch 49 Step 20 Loss: 0.7641, Avg Loss: 0.7836\n",
      "Epoch 49 Step 30 Loss: 0.7646, Avg Loss: 0.7802\n",
      "Epoch 49 Step 40 Loss: 0.7837, Avg Loss: 0.7794\n",
      "Epoch 49 Step 50 Loss: 0.7746, Avg Loss: 0.7772\n",
      "Step 2833 — Test metrics:\n",
      "  precision@10: 0.004006623\n",
      "  recall@10: 0.004006623\n",
      "  ndcg@10: 0.003404199\n",
      "  map@10: 0.000836684\n",
      "Epoch 49 completed. Train BPR Loss: 0.7754\n",
      "\n",
      "Epoch 50 Step 1 Loss: 0.7672, Avg Loss: 0.7672\n",
      "Step 2842 — Test metrics:\n",
      "  precision@10: 0.004039735\n",
      "  recall@10: 0.004039735\n",
      "  ndcg@10: 0.003427532\n",
      "  map@10: 0.000841007\n",
      "Epoch 50 Step 10 Loss: 0.7804, Avg Loss: 0.7704\n",
      "Epoch 50 Step 20 Loss: 0.7626, Avg Loss: 0.7690\n",
      "Epoch 50 Step 30 Loss: 0.7721, Avg Loss: 0.7665\n",
      "Epoch 50 Step 40 Loss: 0.7601, Avg Loss: 0.7655\n",
      "Epoch 50 Step 50 Loss: 0.7768, Avg Loss: 0.7637\n",
      "Step 2891 — Test metrics:\n",
      "  precision@10: 0.004205298\n",
      "  recall@10: 0.004205298\n",
      "  ndcg@10: 0.003545692\n",
      "  map@10: 0.000865441\n",
      "Epoch 50 completed. Train BPR Loss: 0.7620\n",
      "\n",
      "Epoch 51 Step 1 Loss: 0.7506, Avg Loss: 0.7506\n",
      "Step 2900 — Test metrics:\n",
      "  precision@10: 0.004221854\n",
      "  recall@10: 0.004221854\n",
      "  ndcg@10: 0.003559303\n",
      "  map@10: 0.000868824\n",
      "Epoch 51 Step 10 Loss: 0.7544, Avg Loss: 0.7482\n",
      "Epoch 51 Step 20 Loss: 0.7499, Avg Loss: 0.7479\n",
      "Epoch 51 Step 30 Loss: 0.7418, Avg Loss: 0.7459\n",
      "Epoch 51 Step 40 Loss: 0.7324, Avg Loss: 0.7453\n",
      "Epoch 51 Step 50 Loss: 0.7357, Avg Loss: 0.7439\n",
      "Step 2949 — Test metrics:\n",
      "  precision@10: 0.004221854\n",
      "  recall@10: 0.004221854\n",
      "  ndcg@10: 0.003535505\n",
      "  map@10: 0.000853451\n",
      "Epoch 51 completed. Train BPR Loss: 0.7429\n",
      "\n",
      "Epoch 52 Step 1 Loss: 0.7545, Avg Loss: 0.7545\n",
      "Step 2958 — Test metrics:\n",
      "  precision@10: 0.004221854\n",
      "  recall@10: 0.004221854\n",
      "  ndcg@10: 0.003542693\n",
      "  map@10: 0.000857241\n",
      "Epoch 52 Step 10 Loss: 0.7332, Avg Loss: 0.7366\n",
      "Epoch 52 Step 20 Loss: 0.7295, Avg Loss: 0.7325\n",
      "Epoch 52 Step 30 Loss: 0.7215, Avg Loss: 0.7320\n",
      "Epoch 52 Step 40 Loss: 0.7318, Avg Loss: 0.7309\n",
      "Epoch 52 Step 50 Loss: 0.7339, Avg Loss: 0.7296\n",
      "Step 3007 — Test metrics:\n",
      "  precision@10: 0.004304636\n",
      "  recall@10: 0.004304636\n",
      "  ndcg@10: 0.003620223\n",
      "  map@10: 0.000875808\n",
      "Epoch 52 completed. Train BPR Loss: 0.7294\n",
      "\n",
      "Epoch 53 Step 1 Loss: 0.7115, Avg Loss: 0.7115\n",
      "Step 3016 — Test metrics:\n",
      "  precision@10: 0.004321192\n",
      "  recall@10: 0.004321192\n",
      "  ndcg@10: 0.003624739\n",
      "  map@10: 0.000874415\n",
      "Epoch 53 Step 10 Loss: 0.7225, Avg Loss: 0.7197\n",
      "Epoch 53 Step 20 Loss: 0.7118, Avg Loss: 0.7187\n",
      "Epoch 53 Step 30 Loss: 0.7068, Avg Loss: 0.7180\n",
      "Epoch 53 Step 40 Loss: 0.7117, Avg Loss: 0.7183\n",
      "Epoch 53 Step 50 Loss: 0.7206, Avg Loss: 0.7161\n",
      "Step 3065 — Test metrics:\n",
      "  precision@10: 0.004403974\n",
      "  recall@10: 0.004403974\n",
      "  ndcg@10: 0.003698667\n",
      "  map@10: 0.000894532\n",
      "Epoch 53 completed. Train BPR Loss: 0.7149\n",
      "\n",
      "Epoch 54 Step 1 Loss: 0.7083, Avg Loss: 0.7083\n",
      "Step 3074 — Test metrics:\n",
      "  precision@10: 0.004453642\n",
      "  recall@10: 0.004453642\n",
      "  ndcg@10: 0.003729338\n",
      "  map@10: 0.000898947\n",
      "Epoch 54 Step 10 Loss: 0.7043, Avg Loss: 0.7062\n",
      "Epoch 54 Step 20 Loss: 0.7037, Avg Loss: 0.7075\n",
      "Epoch 54 Step 30 Loss: 0.6829, Avg Loss: 0.7052\n",
      "Epoch 54 Step 40 Loss: 0.6920, Avg Loss: 0.7049\n",
      "Epoch 54 Step 50 Loss: 0.6855, Avg Loss: 0.7033\n",
      "Step 3123 — Test metrics:\n",
      "  precision@10: 0.004486755\n",
      "  recall@10: 0.004486755\n",
      "  ndcg@10: 0.003763015\n",
      "  map@10: 0.000907699\n",
      "Epoch 54 completed. Train BPR Loss: 0.7021\n",
      "\n",
      "Epoch 55 Step 1 Loss: 0.6897, Avg Loss: 0.6897\n",
      "Step 3132 — Test metrics:\n",
      "  precision@10: 0.004503311\n",
      "  recall@10: 0.004503311\n",
      "  ndcg@10: 0.003778843\n",
      "  map@10: 0.000912206\n",
      "Epoch 55 Step 10 Loss: 0.7003, Avg Loss: 0.6925\n",
      "Epoch 55 Step 20 Loss: 0.6922, Avg Loss: 0.6916\n",
      "Epoch 55 Step 30 Loss: 0.6922, Avg Loss: 0.6905\n",
      "Epoch 55 Step 40 Loss: 0.6949, Avg Loss: 0.6906\n",
      "Epoch 55 Step 50 Loss: 0.6660, Avg Loss: 0.6894\n",
      "Step 3181 — Test metrics:\n",
      "  precision@10: 0.004586093\n",
      "  recall@10: 0.004586093\n",
      "  ndcg@10: 0.003854712\n",
      "  map@10: 0.000933558\n",
      "Epoch 55 completed. Train BPR Loss: 0.6886\n",
      "\n",
      "Epoch 56 Step 1 Loss: 0.6883, Avg Loss: 0.6883\n",
      "Step 3190 — Test metrics:\n",
      "  precision@10: 0.004652318\n",
      "  recall@10: 0.004652318\n",
      "  ndcg@10: 0.003904717\n",
      "  map@10: 0.000944379\n",
      "Epoch 56 Step 10 Loss: 0.6755, Avg Loss: 0.6822\n",
      "Epoch 56 Step 20 Loss: 0.6763, Avg Loss: 0.6798\n",
      "Epoch 56 Step 30 Loss: 0.6769, Avg Loss: 0.6789\n",
      "Epoch 56 Step 40 Loss: 0.6717, Avg Loss: 0.6780\n",
      "Epoch 56 Step 50 Loss: 0.6729, Avg Loss: 0.6766\n",
      "Step 3239 — Test metrics:\n",
      "  precision@10: 0.004701987\n",
      "  recall@10: 0.004701987\n",
      "  ndcg@10: 0.003955117\n",
      "  map@10: 0.000958268\n",
      "Epoch 56 completed. Train BPR Loss: 0.6765\n",
      "\n",
      "Epoch 57 Step 1 Loss: 0.6727, Avg Loss: 0.6727\n",
      "Step 3248 — Test metrics:\n",
      "  precision@10: 0.004735099\n",
      "  recall@10: 0.004735099\n",
      "  ndcg@10: 0.003977072\n",
      "  map@10: 0.000961829\n",
      "Epoch 57 Step 10 Loss: 0.6743, Avg Loss: 0.6659\n",
      "Epoch 57 Step 20 Loss: 0.6598, Avg Loss: 0.6675\n",
      "Epoch 57 Step 30 Loss: 0.6511, Avg Loss: 0.6672\n",
      "Epoch 57 Step 40 Loss: 0.6542, Avg Loss: 0.6653\n",
      "Epoch 57 Step 50 Loss: 0.6653, Avg Loss: 0.6640\n",
      "Step 3297 — Test metrics:\n",
      "  precision@10: 0.004900662\n",
      "  recall@10: 0.004900662\n",
      "  ndcg@10: 0.004093271\n",
      "  map@10: 0.000983293\n",
      "Epoch 57 completed. Train BPR Loss: 0.6639\n",
      "\n",
      "Epoch 58 Step 1 Loss: 0.6729, Avg Loss: 0.6729\n",
      "Step 3306 — Test metrics:\n",
      "  precision@10: 0.004884106\n",
      "  recall@10: 0.004884106\n",
      "  ndcg@10: 0.004076245\n",
      "  map@10: 0.000977045\n",
      "Epoch 58 Step 10 Loss: 0.6498, Avg Loss: 0.6577\n",
      "Epoch 58 Step 20 Loss: 0.6546, Avg Loss: 0.6555\n",
      "Epoch 58 Step 30 Loss: 0.6480, Avg Loss: 0.6542\n",
      "Epoch 58 Step 40 Loss: 0.6529, Avg Loss: 0.6537\n",
      "Epoch 58 Step 50 Loss: 0.6396, Avg Loss: 0.6532\n",
      "Step 3355 — Test metrics:\n",
      "  precision@10: 0.005016556\n",
      "  recall@10: 0.005016556\n",
      "  ndcg@10: 0.004197978\n",
      "  map@10: 0.001009191\n",
      "Epoch 58 completed. Train BPR Loss: 0.6524\n",
      "\n",
      "Epoch 59 Step 1 Loss: 0.6498, Avg Loss: 0.6498\n",
      "Step 3364 — Test metrics:\n",
      "  precision@10: 0.005049669\n",
      "  recall@10: 0.005049669\n",
      "  ndcg@10: 0.004220622\n",
      "  map@10: 0.001014848\n",
      "Epoch 59 Step 10 Loss: 0.6410, Avg Loss: 0.6453\n",
      "Epoch 59 Step 20 Loss: 0.6265, Avg Loss: 0.6420\n",
      "Epoch 59 Step 30 Loss: 0.6381, Avg Loss: 0.6427\n",
      "Epoch 59 Step 40 Loss: 0.6407, Avg Loss: 0.6412\n",
      "Epoch 59 Step 50 Loss: 0.6414, Avg Loss: 0.6405\n",
      "Step 3413 — Test metrics:\n",
      "  precision@10: 0.005198675\n",
      "  recall@10: 0.005198675\n",
      "  ndcg@10: 0.004339065\n",
      "  map@10: 0.001042823\n",
      "Epoch 59 completed. Train BPR Loss: 0.6405\n",
      "\n",
      "Epoch 60 Step 1 Loss: 0.6404, Avg Loss: 0.6404\n",
      "Step 3422 — Test metrics:\n",
      "  precision@10: 0.005215232\n",
      "  recall@10: 0.005215232\n",
      "  ndcg@10: 0.004352412\n",
      "  map@10: 0.001044327\n",
      "Epoch 60 Step 10 Loss: 0.6240, Avg Loss: 0.6339\n",
      "Epoch 60 Step 20 Loss: 0.6471, Avg Loss: 0.6331\n",
      "Epoch 60 Step 30 Loss: 0.6363, Avg Loss: 0.6330\n",
      "Epoch 60 Step 40 Loss: 0.6281, Avg Loss: 0.6319\n",
      "Epoch 60 Step 50 Loss: 0.6231, Avg Loss: 0.6310\n",
      "Step 3471 — Test metrics:\n",
      "  precision@10: 0.005331126\n",
      "  recall@10: 0.005331126\n",
      "  ndcg@10: 0.004455856\n",
      "  map@10: 0.001074260\n",
      "Epoch 60 completed. Train BPR Loss: 0.6306\n",
      "\n",
      "Epoch 61 Step 1 Loss: 0.6188, Avg Loss: 0.6188\n",
      "Step 3480 — Test metrics:\n",
      "  precision@10: 0.005331126\n",
      "  recall@10: 0.005331126\n",
      "  ndcg@10: 0.004459598\n",
      "  map@10: 0.001074484\n",
      "Epoch 61 Step 10 Loss: 0.6247, Avg Loss: 0.6261\n",
      "Epoch 61 Step 20 Loss: 0.6161, Avg Loss: 0.6231\n",
      "Epoch 61 Step 30 Loss: 0.6219, Avg Loss: 0.6226\n",
      "Epoch 61 Step 40 Loss: 0.6156, Avg Loss: 0.6218\n",
      "Epoch 61 Step 50 Loss: 0.6063, Avg Loss: 0.6202\n",
      "Step 3529 — Test metrics:\n",
      "  precision@10: 0.005413907\n",
      "  recall@10: 0.005413907\n",
      "  ndcg@10: 0.004551122\n",
      "  map@10: 0.001101480\n",
      "Epoch 61 completed. Train BPR Loss: 0.6203\n",
      "\n",
      "Epoch 62 Step 1 Loss: 0.6157, Avg Loss: 0.6157\n",
      "Step 3538 — Test metrics:\n",
      "  precision@10: 0.005463576\n",
      "  recall@10: 0.005463576\n",
      "  ndcg@10: 0.004582043\n",
      "  map@10: 0.001105941\n",
      "Epoch 62 Step 10 Loss: 0.6247, Avg Loss: 0.6144\n",
      "Epoch 62 Step 20 Loss: 0.6224, Avg Loss: 0.6137\n",
      "Epoch 62 Step 30 Loss: 0.5985, Avg Loss: 0.6132\n",
      "Epoch 62 Step 40 Loss: 0.5971, Avg Loss: 0.6120\n",
      "Epoch 62 Step 50 Loss: 0.6001, Avg Loss: 0.6105\n",
      "Step 3587 — Test metrics:\n",
      "  precision@10: 0.005662252\n",
      "  recall@10: 0.005662252\n",
      "  ndcg@10: 0.004763763\n",
      "  map@10: 0.001157548\n",
      "Epoch 62 completed. Train BPR Loss: 0.6097\n",
      "\n",
      "Epoch 63 Step 1 Loss: 0.5987, Avg Loss: 0.5987\n",
      "Step 3596 — Test metrics:\n",
      "  precision@10: 0.005645695\n",
      "  recall@10: 0.005645695\n",
      "  ndcg@10: 0.004731766\n",
      "  map@10: 0.001142042\n",
      "Epoch 63 Step 10 Loss: 0.6030, Avg Loss: 0.6067\n",
      "Epoch 63 Step 20 Loss: 0.5956, Avg Loss: 0.6063\n",
      "Epoch 63 Step 30 Loss: 0.5997, Avg Loss: 0.6045\n",
      "Epoch 63 Step 40 Loss: 0.5985, Avg Loss: 0.6030\n",
      "Epoch 63 Step 50 Loss: 0.5893, Avg Loss: 0.6020\n",
      "Step 3645 — Test metrics:\n",
      "  precision@10: 0.005811258\n",
      "  recall@10: 0.005811258\n",
      "  ndcg@10: 0.004900824\n",
      "  map@10: 0.001193045\n",
      "Epoch 63 completed. Train BPR Loss: 0.6010\n",
      "\n",
      "Epoch 64 Step 1 Loss: 0.5994, Avg Loss: 0.5994\n",
      "Step 3654 — Test metrics:\n",
      "  precision@10: 0.005877483\n",
      "  recall@10: 0.005877483\n",
      "  ndcg@10: 0.004955774\n",
      "  map@10: 0.001206021\n",
      "Epoch 64 Step 10 Loss: 0.5874, Avg Loss: 0.5926\n",
      "Epoch 64 Step 20 Loss: 0.5921, Avg Loss: 0.5922\n",
      "Epoch 64 Step 30 Loss: 0.5912, Avg Loss: 0.5914\n",
      "Epoch 64 Step 40 Loss: 0.5881, Avg Loss: 0.5921\n",
      "Epoch 64 Step 50 Loss: 0.5893, Avg Loss: 0.5914\n",
      "Step 3703 — Test metrics:\n",
      "  precision@10: 0.006059603\n",
      "  recall@10: 0.006059603\n",
      "  ndcg@10: 0.005109020\n",
      "  map@10: 0.001243010\n",
      "Epoch 64 completed. Train BPR Loss: 0.5913\n",
      "\n",
      "Epoch 65 Step 1 Loss: 0.5814, Avg Loss: 0.5814\n",
      "Step 3712 — Test metrics:\n",
      "  precision@10: 0.006109272\n",
      "  recall@10: 0.006109272\n",
      "  ndcg@10: 0.005145745\n",
      "  map@10: 0.001250749\n",
      "Epoch 65 Step 10 Loss: 0.6084, Avg Loss: 0.5863\n",
      "Epoch 65 Step 20 Loss: 0.5808, Avg Loss: 0.5870\n",
      "Epoch 65 Step 30 Loss: 0.5797, Avg Loss: 0.5874\n",
      "Epoch 65 Step 40 Loss: 0.5843, Avg Loss: 0.5869\n",
      "Epoch 65 Step 50 Loss: 0.5824, Avg Loss: 0.5856\n",
      "Step 3761 — Test metrics:\n",
      "  precision@10: 0.006258278\n",
      "  recall@10: 0.006258278\n",
      "  ndcg@10: 0.005283781\n",
      "  map@10: 0.001288395\n",
      "Epoch 65 completed. Train BPR Loss: 0.5847\n",
      "\n",
      "Epoch 66 Step 1 Loss: 0.5736, Avg Loss: 0.5736\n",
      "Step 3770 — Test metrics:\n",
      "  precision@10: 0.006241722\n",
      "  recall@10: 0.006241722\n",
      "  ndcg@10: 0.005295076\n",
      "  map@10: 0.001298697\n",
      "Epoch 66 Step 10 Loss: 0.5779, Avg Loss: 0.5769\n",
      "Epoch 66 Step 20 Loss: 0.5720, Avg Loss: 0.5787\n",
      "Epoch 66 Step 30 Loss: 0.5863, Avg Loss: 0.5787\n",
      "Epoch 66 Step 40 Loss: 0.5760, Avg Loss: 0.5777\n",
      "Epoch 66 Step 50 Loss: 0.5722, Avg Loss: 0.5766\n",
      "Step 3819 — Test metrics:\n",
      "  precision@10: 0.006506623\n",
      "  recall@10: 0.006506623\n",
      "  ndcg@10: 0.005490744\n",
      "  map@10: 0.001337827\n",
      "Epoch 66 completed. Train BPR Loss: 0.5760\n",
      "\n",
      "Epoch 67 Step 1 Loss: 0.5714, Avg Loss: 0.5714\n",
      "Step 3828 — Test metrics:\n",
      "  precision@10: 0.006572848\n",
      "  recall@10: 0.006572848\n",
      "  ndcg@10: 0.005546087\n",
      "  map@10: 0.001354206\n",
      "Epoch 67 Step 10 Loss: 0.5749, Avg Loss: 0.5712\n",
      "Epoch 67 Step 20 Loss: 0.5777, Avg Loss: 0.5701\n",
      "Epoch 67 Step 30 Loss: 0.5646, Avg Loss: 0.5690\n",
      "Epoch 67 Step 40 Loss: 0.5588, Avg Loss: 0.5680\n",
      "Epoch 67 Step 50 Loss: 0.5689, Avg Loss: 0.5672\n",
      "Step 3877 — Test metrics:\n",
      "  precision@10: 0.006754967\n",
      "  recall@10: 0.006754967\n",
      "  ndcg@10: 0.005692765\n",
      "  map@10: 0.001388284\n",
      "Epoch 67 completed. Train BPR Loss: 0.5672\n",
      "\n",
      "Epoch 68 Step 1 Loss: 0.5622, Avg Loss: 0.5622\n",
      "Step 3886 — Test metrics:\n",
      "  precision@10: 0.006788079\n",
      "  recall@10: 0.006788079\n",
      "  ndcg@10: 0.005742931\n",
      "  map@10: 0.001408264\n",
      "Epoch 68 Step 10 Loss: 0.5796, Avg Loss: 0.5631\n",
      "Epoch 68 Step 20 Loss: 0.5620, Avg Loss: 0.5610\n",
      "Epoch 68 Step 30 Loss: 0.5664, Avg Loss: 0.5618\n",
      "Epoch 68 Step 40 Loss: 0.5491, Avg Loss: 0.5611\n",
      "Epoch 68 Step 50 Loss: 0.5663, Avg Loss: 0.5611\n",
      "Step 3935 — Test metrics:\n",
      "  precision@10: 0.007019868\n",
      "  recall@10: 0.007019868\n",
      "  ndcg@10: 0.005962039\n",
      "  map@10: 0.001473668\n",
      "Epoch 68 completed. Train BPR Loss: 0.5609\n",
      "\n",
      "Epoch 69 Step 1 Loss: 0.5623, Avg Loss: 0.5623\n",
      "Step 3944 — Test metrics:\n",
      "  precision@10: 0.007069536\n",
      "  recall@10: 0.007069536\n",
      "  ndcg@10: 0.005999907\n",
      "  map@10: 0.001480895\n",
      "Epoch 69 Step 10 Loss: 0.5510, Avg Loss: 0.5539\n",
      "Epoch 69 Step 20 Loss: 0.5505, Avg Loss: 0.5536\n",
      "Epoch 69 Step 30 Loss: 0.5524, Avg Loss: 0.5553\n",
      "Epoch 69 Step 40 Loss: 0.5619, Avg Loss: 0.5550\n",
      "Epoch 69 Step 50 Loss: 0.5508, Avg Loss: 0.5541\n",
      "Step 3993 — Test metrics:\n",
      "  precision@10: 0.007367550\n",
      "  recall@10: 0.007367550\n",
      "  ndcg@10: 0.006267439\n",
      "  map@10: 0.001550786\n",
      "Epoch 69 completed. Train BPR Loss: 0.5536\n",
      "\n",
      "Epoch 70 Step 1 Loss: 0.5586, Avg Loss: 0.5586\n",
      "Step 4002 — Test metrics:\n",
      "  precision@10: 0.007417219\n",
      "  recall@10: 0.007417219\n",
      "  ndcg@10: 0.006309174\n",
      "  map@10: 0.001560936\n",
      "Epoch 70 Step 10 Loss: 0.5454, Avg Loss: 0.5483\n",
      "Epoch 70 Step 20 Loss: 0.5521, Avg Loss: 0.5482\n",
      "Epoch 70 Step 30 Loss: 0.5575, Avg Loss: 0.5481\n",
      "Epoch 70 Step 40 Loss: 0.5392, Avg Loss: 0.5478\n",
      "Epoch 70 Step 50 Loss: 0.5542, Avg Loss: 0.5474\n",
      "Step 4051 — Test metrics:\n",
      "  precision@10: 0.007764901\n",
      "  recall@10: 0.007764901\n",
      "  ndcg@10: 0.006585146\n",
      "  map@10: 0.001622096\n",
      "Epoch 70 completed. Train BPR Loss: 0.5474\n",
      "\n",
      "Epoch 71 Step 1 Loss: 0.5379, Avg Loss: 0.5379\n",
      "Step 4060 — Test metrics:\n",
      "  precision@10: 0.007748344\n",
      "  recall@10: 0.007748344\n",
      "  ndcg@10: 0.006581751\n",
      "  map@10: 0.001623765\n",
      "Epoch 71 Step 10 Loss: 0.5474, Avg Loss: 0.5406\n",
      "Epoch 71 Step 20 Loss: 0.5373, Avg Loss: 0.5419\n",
      "Epoch 71 Step 30 Loss: 0.5551, Avg Loss: 0.5413\n",
      "Epoch 71 Step 40 Loss: 0.5308, Avg Loss: 0.5415\n",
      "Epoch 71 Step 50 Loss: 0.5350, Avg Loss: 0.5407\n",
      "Step 4109 — Test metrics:\n",
      "  precision@10: 0.007847682\n",
      "  recall@10: 0.007847682\n",
      "  ndcg@10: 0.006680138\n",
      "  map@10: 0.001654355\n",
      "Epoch 71 completed. Train BPR Loss: 0.5404\n",
      "\n",
      "Epoch 72 Step 1 Loss: 0.5471, Avg Loss: 0.5471\n",
      "Step 4118 — Test metrics:\n",
      "  precision@10: 0.007864238\n",
      "  recall@10: 0.007864238\n",
      "  ndcg@10: 0.006741243\n",
      "  map@10: 0.001684051\n",
      "Epoch 72 Step 10 Loss: 0.5314, Avg Loss: 0.5376\n",
      "Epoch 72 Step 20 Loss: 0.5337, Avg Loss: 0.5349\n",
      "Epoch 72 Step 30 Loss: 0.5402, Avg Loss: 0.5347\n",
      "Epoch 72 Step 40 Loss: 0.5470, Avg Loss: 0.5354\n",
      "Epoch 72 Step 50 Loss: 0.5267, Avg Loss: 0.5345\n",
      "Step 4167 — Test metrics:\n",
      "  precision@10: 0.008062914\n",
      "  recall@10: 0.008062914\n",
      "  ndcg@10: 0.006966870\n",
      "  map@10: 0.001758574\n",
      "Epoch 72 completed. Train BPR Loss: 0.5338\n",
      "\n",
      "Epoch 73 Step 1 Loss: 0.5268, Avg Loss: 0.5268\n",
      "Step 4176 — Test metrics:\n",
      "  precision@10: 0.008112583\n",
      "  recall@10: 0.008112583\n",
      "  ndcg@10: 0.007015624\n",
      "  map@10: 0.001771858\n",
      "Epoch 73 Step 10 Loss: 0.5398, Avg Loss: 0.5287\n",
      "Epoch 73 Step 20 Loss: 0.5351, Avg Loss: 0.5297\n",
      "Epoch 73 Step 30 Loss: 0.5134, Avg Loss: 0.5287\n",
      "Epoch 73 Step 40 Loss: 0.5261, Avg Loss: 0.5283\n",
      "Epoch 73 Step 50 Loss: 0.5163, Avg Loss: 0.5280\n",
      "Step 4225 — Test metrics:\n",
      "  precision@10: 0.008427152\n",
      "  recall@10: 0.008427152\n",
      "  ndcg@10: 0.007281628\n",
      "  map@10: 0.001839391\n",
      "Epoch 73 completed. Train BPR Loss: 0.5279\n",
      "\n",
      "Epoch 74 Step 1 Loss: 0.5306, Avg Loss: 0.5306\n",
      "Step 4234 — Test metrics:\n",
      "  precision@10: 0.008443709\n",
      "  recall@10: 0.008443709\n",
      "  ndcg@10: 0.007302838\n",
      "  map@10: 0.001846362\n",
      "Epoch 74 Step 10 Loss: 0.5291, Avg Loss: 0.5251\n",
      "Epoch 74 Step 20 Loss: 0.5228, Avg Loss: 0.5245\n",
      "Epoch 74 Step 30 Loss: 0.5250, Avg Loss: 0.5239\n",
      "Epoch 74 Step 40 Loss: 0.5192, Avg Loss: 0.5238\n",
      "Epoch 74 Step 50 Loss: 0.5051, Avg Loss: 0.5229\n",
      "Step 4283 — Test metrics:\n",
      "  precision@10: 0.008609272\n",
      "  recall@10: 0.008609272\n",
      "  ndcg@10: 0.007471825\n",
      "  map@10: 0.001893882\n",
      "Epoch 74 completed. Train BPR Loss: 0.5223\n",
      "\n",
      "Epoch 75 Step 1 Loss: 0.5137, Avg Loss: 0.5137\n",
      "Step 4292 — Test metrics:\n",
      "  precision@10: 0.008708609\n",
      "  recall@10: 0.008708609\n",
      "  ndcg@10: 0.007545772\n",
      "  map@10: 0.001909459\n",
      "Epoch 75 Step 10 Loss: 0.5067, Avg Loss: 0.5191\n",
      "Epoch 75 Step 20 Loss: 0.5205, Avg Loss: 0.5199\n",
      "Epoch 75 Step 30 Loss: 0.5094, Avg Loss: 0.5196\n",
      "Epoch 75 Step 40 Loss: 0.5130, Avg Loss: 0.5179\n",
      "Epoch 75 Step 50 Loss: 0.5091, Avg Loss: 0.5172\n",
      "Step 4341 — Test metrics:\n",
      "  precision@10: 0.009122517\n",
      "  recall@10: 0.009122517\n",
      "  ndcg@10: 0.007895467\n",
      "  map@10: 0.001997530\n",
      "Epoch 75 completed. Train BPR Loss: 0.5166\n",
      "\n",
      "Epoch 76 Step 1 Loss: 0.5153, Avg Loss: 0.5153\n",
      "Step 4350 — Test metrics:\n",
      "  precision@10: 0.009172185\n",
      "  recall@10: 0.009172185\n",
      "  ndcg@10: 0.007944638\n",
      "  map@10: 0.002011202\n",
      "Epoch 76 Step 10 Loss: 0.5158, Avg Loss: 0.5131\n",
      "Epoch 76 Step 20 Loss: 0.5104, Avg Loss: 0.5140\n",
      "Epoch 76 Step 30 Loss: 0.5090, Avg Loss: 0.5129\n",
      "Epoch 76 Step 40 Loss: 0.5037, Avg Loss: 0.5130\n",
      "Epoch 76 Step 50 Loss: 0.5100, Avg Loss: 0.5117\n",
      "Step 4399 — Test metrics:\n",
      "  precision@10: 0.009403974\n",
      "  recall@10: 0.009403974\n",
      "  ndcg@10: 0.008204458\n",
      "  map@10: 0.002093602\n",
      "Epoch 76 completed. Train BPR Loss: 0.5118\n",
      "\n",
      "Epoch 77 Step 1 Loss: 0.5021, Avg Loss: 0.5021\n",
      "Step 4408 — Test metrics:\n",
      "  precision@10: 0.009470199\n",
      "  recall@10: 0.009470199\n",
      "  ndcg@10: 0.008262342\n",
      "  map@10: 0.002108431\n",
      "Epoch 77 Step 10 Loss: 0.5112, Avg Loss: 0.5103\n",
      "Epoch 77 Step 20 Loss: 0.4972, Avg Loss: 0.5096\n",
      "Epoch 77 Step 30 Loss: 0.5066, Avg Loss: 0.5089\n",
      "Epoch 77 Step 40 Loss: 0.5020, Avg Loss: 0.5071\n",
      "Epoch 77 Step 50 Loss: 0.4983, Avg Loss: 0.5060\n",
      "Step 4457 — Test metrics:\n",
      "  precision@10: 0.009602649\n",
      "  recall@10: 0.009602649\n",
      "  ndcg@10: 0.008467597\n",
      "  map@10: 0.002188965\n",
      "Epoch 77 completed. Train BPR Loss: 0.5058\n",
      "\n",
      "Epoch 78 Step 1 Loss: 0.5017, Avg Loss: 0.5017\n",
      "Step 4466 — Test metrics:\n",
      "  precision@10: 0.009701987\n",
      "  recall@10: 0.009701987\n",
      "  ndcg@10: 0.008552951\n",
      "  map@10: 0.002212998\n",
      "Epoch 78 Step 10 Loss: 0.5071, Avg Loss: 0.5003\n",
      "Epoch 78 Step 20 Loss: 0.5002, Avg Loss: 0.5021\n",
      "Epoch 78 Step 30 Loss: 0.5028, Avg Loss: 0.5019\n",
      "Epoch 78 Step 40 Loss: 0.4913, Avg Loss: 0.5008\n",
      "Epoch 78 Step 50 Loss: 0.4939, Avg Loss: 0.5009\n",
      "Step 4515 — Test metrics:\n",
      "  precision@10: 0.010099338\n",
      "  recall@10: 0.010099338\n",
      "  ndcg@10: 0.008912832\n",
      "  map@10: 0.002315673\n",
      "Epoch 78 completed. Train BPR Loss: 0.5007\n",
      "\n",
      "Epoch 79 Step 1 Loss: 0.5073, Avg Loss: 0.5073\n",
      "Step 4524 — Test metrics:\n",
      "  precision@10: 0.010165563\n",
      "  recall@10: 0.010165563\n",
      "  ndcg@10: 0.008986212\n",
      "  map@10: 0.002338051\n",
      "Epoch 79 Step 10 Loss: 0.4898, Avg Loss: 0.4986\n",
      "Epoch 79 Step 20 Loss: 0.5039, Avg Loss: 0.4977\n",
      "Epoch 79 Step 30 Loss: 0.4957, Avg Loss: 0.4975\n",
      "Epoch 79 Step 40 Loss: 0.4966, Avg Loss: 0.4973\n",
      "Epoch 79 Step 50 Loss: 0.4924, Avg Loss: 0.4969\n",
      "Step 4573 — Test metrics:\n",
      "  precision@10: 0.010364238\n",
      "  recall@10: 0.010364238\n",
      "  ndcg@10: 0.009180098\n",
      "  map@10: 0.002392890\n",
      "Epoch 79 completed. Train BPR Loss: 0.4964\n",
      "\n",
      "Epoch 80 Step 1 Loss: 0.4912, Avg Loss: 0.4912\n",
      "Step 4582 — Test metrics:\n",
      "  precision@10: 0.010413907\n",
      "  recall@10: 0.010413907\n",
      "  ndcg@10: 0.009238610\n",
      "  map@10: 0.002410057\n",
      "Epoch 80 Step 10 Loss: 0.4938, Avg Loss: 0.4941\n",
      "Epoch 80 Step 20 Loss: 0.4882, Avg Loss: 0.4937\n",
      "Epoch 80 Step 30 Loss: 0.4928, Avg Loss: 0.4935\n",
      "Epoch 80 Step 40 Loss: 0.4893, Avg Loss: 0.4934\n",
      "Epoch 80 Step 50 Loss: 0.4939, Avg Loss: 0.4933\n",
      "Step 4631 — Test metrics:\n",
      "  precision@10: 0.010794702\n",
      "  recall@10: 0.010794702\n",
      "  ndcg@10: 0.009574955\n",
      "  map@10: 0.002499304\n",
      "Epoch 80 completed. Train BPR Loss: 0.4933\n",
      "\n",
      "Epoch 81 Step 1 Loss: 0.4977, Avg Loss: 0.4977\n",
      "Step 4640 — Test metrics:\n",
      "  precision@10: 0.010811258\n",
      "  recall@10: 0.010811258\n",
      "  ndcg@10: 0.009613528\n",
      "  map@10: 0.002513790\n",
      "Epoch 81 Step 10 Loss: 0.4832, Avg Loss: 0.4897\n",
      "Epoch 81 Step 20 Loss: 0.4863, Avg Loss: 0.4888\n",
      "Epoch 81 Step 30 Loss: 0.4958, Avg Loss: 0.4892\n",
      "Epoch 81 Step 40 Loss: 0.4891, Avg Loss: 0.4893\n",
      "Epoch 81 Step 50 Loss: 0.4751, Avg Loss: 0.4888\n",
      "Step 4689 — Test metrics:\n",
      "  precision@10: 0.011092715\n",
      "  recall@10: 0.011092715\n",
      "  ndcg@10: 0.009890107\n",
      "  map@10: 0.002601611\n",
      "Epoch 81 completed. Train BPR Loss: 0.4884\n",
      "\n",
      "Epoch 82 Step 1 Loss: 0.4804, Avg Loss: 0.4804\n",
      "Step 4698 — Test metrics:\n",
      "  precision@10: 0.011274834\n",
      "  recall@10: 0.011274834\n",
      "  ndcg@10: 0.010050430\n",
      "  map@10: 0.002645295\n",
      "Epoch 82 Step 10 Loss: 0.4879, Avg Loss: 0.4862\n",
      "Epoch 82 Step 20 Loss: 0.4810, Avg Loss: 0.4851\n",
      "Epoch 82 Step 30 Loss: 0.4752, Avg Loss: 0.4844\n",
      "Epoch 82 Step 40 Loss: 0.4875, Avg Loss: 0.4841\n",
      "Epoch 82 Step 50 Loss: 0.4862, Avg Loss: 0.4838\n",
      "Step 4747 — Test metrics:\n",
      "  precision@10: 0.011605960\n",
      "  recall@10: 0.011605960\n",
      "  ndcg@10: 0.010379329\n",
      "  map@10: 0.002743581\n",
      "Epoch 82 completed. Train BPR Loss: 0.4840\n",
      "\n",
      "Epoch 83 Step 1 Loss: 0.4821, Avg Loss: 0.4821\n",
      "Step 4756 — Test metrics:\n",
      "  precision@10: 0.011655629\n",
      "  recall@10: 0.011655629\n",
      "  ndcg@10: 0.010427124\n",
      "  map@10: 0.002757194\n",
      "Epoch 83 Step 10 Loss: 0.4809, Avg Loss: 0.4829\n",
      "Epoch 83 Step 20 Loss: 0.4758, Avg Loss: 0.4810\n",
      "Epoch 83 Step 30 Loss: 0.4824, Avg Loss: 0.4813\n",
      "Epoch 83 Step 40 Loss: 0.4789, Avg Loss: 0.4810\n",
      "Epoch 83 Step 50 Loss: 0.4739, Avg Loss: 0.4805\n",
      "Step 4805 — Test metrics:\n",
      "  precision@10: 0.012268212\n",
      "  recall@10: 0.012268212\n",
      "  ndcg@10: 0.010957082\n",
      "  map@10: 0.002907679\n",
      "Epoch 83 completed. Train BPR Loss: 0.4804\n",
      "\n",
      "Epoch 84 Step 1 Loss: 0.4756, Avg Loss: 0.4756\n",
      "Step 4814 — Test metrics:\n",
      "  precision@10: 0.012400662\n",
      "  recall@10: 0.012400662\n",
      "  ndcg@10: 0.011054937\n",
      "  map@10: 0.002930976\n",
      "Epoch 84 Step 10 Loss: 0.4750, Avg Loss: 0.4789\n",
      "Epoch 84 Step 20 Loss: 0.4774, Avg Loss: 0.4788\n",
      "Epoch 84 Step 30 Loss: 0.4832, Avg Loss: 0.4787\n",
      "Epoch 84 Step 40 Loss: 0.4730, Avg Loss: 0.4782\n",
      "Epoch 84 Step 50 Loss: 0.4733, Avg Loss: 0.4775\n",
      "Step 4863 — Test metrics:\n",
      "  precision@10: 0.012831126\n",
      "  recall@10: 0.012831126\n",
      "  ndcg@10: 0.011472159\n",
      "  map@10: 0.003061541\n",
      "Epoch 84 completed. Train BPR Loss: 0.4772\n",
      "\n",
      "Epoch 85 Step 1 Loss: 0.4753, Avg Loss: 0.4753\n",
      "Step 4872 — Test metrics:\n",
      "  precision@10: 0.013029801\n",
      "  recall@10: 0.013029801\n",
      "  ndcg@10: 0.011614778\n",
      "  map@10: 0.003093806\n",
      "Epoch 85 Step 10 Loss: 0.4662, Avg Loss: 0.4768\n",
      "Epoch 85 Step 20 Loss: 0.4765, Avg Loss: 0.4763\n",
      "Epoch 85 Step 30 Loss: 0.4808, Avg Loss: 0.4758\n",
      "Epoch 85 Step 40 Loss: 0.4727, Avg Loss: 0.4748\n",
      "Epoch 85 Step 50 Loss: 0.4742, Avg Loss: 0.4742\n",
      "Step 4921 — Test metrics:\n",
      "  precision@10: 0.013493377\n",
      "  recall@10: 0.013493377\n",
      "  ndcg@10: 0.012073959\n",
      "  map@10: 0.003242293\n",
      "Epoch 85 completed. Train BPR Loss: 0.4737\n",
      "\n",
      "Epoch 86 Step 1 Loss: 0.4679, Avg Loss: 0.4679\n",
      "Step 4930 — Test metrics:\n",
      "  precision@10: 0.013625828\n",
      "  recall@10: 0.013625828\n",
      "  ndcg@10: 0.012207850\n",
      "  map@10: 0.003287580\n",
      "Epoch 86 Step 10 Loss: 0.4736, Avg Loss: 0.4722\n",
      "Epoch 86 Step 20 Loss: 0.4700, Avg Loss: 0.4718\n",
      "Epoch 86 Step 30 Loss: 0.4713, Avg Loss: 0.4701\n",
      "Epoch 86 Step 40 Loss: 0.4686, Avg Loss: 0.4696\n",
      "Epoch 86 Step 50 Loss: 0.4770, Avg Loss: 0.4702\n",
      "Step 4979 — Test metrics:\n",
      "  precision@10: 0.014354305\n",
      "  recall@10: 0.014354305\n",
      "  ndcg@10: 0.012848696\n",
      "  map@10: 0.003466776\n",
      "Epoch 86 completed. Train BPR Loss: 0.4705\n",
      "\n",
      "Epoch 87 Step 1 Loss: 0.4640, Avg Loss: 0.4640\n",
      "Step 4988 — Test metrics:\n",
      "  precision@10: 0.014453642\n",
      "  recall@10: 0.014453642\n",
      "  ndcg@10: 0.012930526\n",
      "  map@10: 0.003483693\n",
      "Epoch 87 Step 10 Loss: 0.4681, Avg Loss: 0.4686\n",
      "Epoch 87 Step 20 Loss: 0.4750, Avg Loss: 0.4675\n",
      "Epoch 87 Step 30 Loss: 0.4645, Avg Loss: 0.4679\n",
      "Epoch 87 Step 40 Loss: 0.4692, Avg Loss: 0.4669\n",
      "Epoch 87 Step 50 Loss: 0.4730, Avg Loss: 0.4668\n",
      "Step 5037 — Test metrics:\n",
      "  precision@10: 0.015016556\n",
      "  recall@10: 0.015016556\n",
      "  ndcg@10: 0.013469485\n",
      "  map@10: 0.003652140\n",
      "Epoch 87 completed. Train BPR Loss: 0.4664\n",
      "\n",
      "Epoch 88 Step 1 Loss: 0.4616, Avg Loss: 0.4616\n",
      "Step 5046 — Test metrics:\n",
      "  precision@10: 0.015182119\n",
      "  recall@10: 0.015182119\n",
      "  ndcg@10: 0.013642091\n",
      "  map@10: 0.003711356\n",
      "Epoch 88 Step 10 Loss: 0.4697, Avg Loss: 0.4648\n",
      "Epoch 88 Step 20 Loss: 0.4641, Avg Loss: 0.4639\n",
      "Epoch 88 Step 30 Loss: 0.4652, Avg Loss: 0.4643\n",
      "Epoch 88 Step 40 Loss: 0.4612, Avg Loss: 0.4642\n",
      "Epoch 88 Step 50 Loss: 0.4571, Avg Loss: 0.4643\n",
      "Step 5095 — Test metrics:\n",
      "  precision@10: 0.015761589\n",
      "  recall@10: 0.015761589\n",
      "  ndcg@10: 0.014216060\n",
      "  map@10: 0.003901010\n",
      "Epoch 88 completed. Train BPR Loss: 0.4637\n",
      "\n",
      "Epoch 89 Step 1 Loss: 0.4757, Avg Loss: 0.4757\n",
      "Step 5104 — Test metrics:\n",
      "  precision@10: 0.015877483\n",
      "  recall@10: 0.015877483\n",
      "  ndcg@10: 0.014314375\n",
      "  map@10: 0.003928683\n",
      "Epoch 89 Step 10 Loss: 0.4720, Avg Loss: 0.4663\n",
      "Epoch 89 Step 20 Loss: 0.4625, Avg Loss: 0.4635\n",
      "Epoch 89 Step 30 Loss: 0.4681, Avg Loss: 0.4631\n",
      "Epoch 89 Step 40 Loss: 0.4582, Avg Loss: 0.4620\n",
      "Epoch 89 Step 50 Loss: 0.4580, Avg Loss: 0.4613\n",
      "Step 5153 — Test metrics:\n",
      "  precision@10: 0.016622517\n",
      "  recall@10: 0.016622517\n",
      "  ndcg@10: 0.014967153\n",
      "  map@10: 0.004124409\n",
      "Epoch 89 completed. Train BPR Loss: 0.4608\n",
      "\n",
      "Epoch 90 Step 1 Loss: 0.4640, Avg Loss: 0.4640\n",
      "Step 5162 — Test metrics:\n",
      "  precision@10: 0.016605960\n",
      "  recall@10: 0.016605960\n",
      "  ndcg@10: 0.014973553\n",
      "  map@10: 0.004135840\n",
      "Epoch 90 Step 10 Loss: 0.4582, Avg Loss: 0.4566\n",
      "Epoch 90 Step 20 Loss: 0.4538, Avg Loss: 0.4573\n",
      "Epoch 90 Step 30 Loss: 0.4572, Avg Loss: 0.4575\n",
      "Epoch 90 Step 40 Loss: 0.4518, Avg Loss: 0.4578\n",
      "Epoch 90 Step 50 Loss: 0.4633, Avg Loss: 0.4583\n",
      "Step 5211 — Test metrics:\n",
      "  precision@10: 0.017516556\n",
      "  recall@10: 0.017516556\n",
      "  ndcg@10: 0.015714038\n",
      "  map@10: 0.004333340\n",
      "Epoch 90 completed. Train BPR Loss: 0.4580\n",
      "\n",
      "Epoch 91 Step 1 Loss: 0.4638, Avg Loss: 0.4638\n",
      "Step 5220 — Test metrics:\n",
      "  precision@10: 0.017549669\n",
      "  recall@10: 0.017549669\n",
      "  ndcg@10: 0.015777625\n",
      "  map@10: 0.004358634\n",
      "Epoch 91 Step 10 Loss: 0.4669, Avg Loss: 0.4564\n",
      "Epoch 91 Step 20 Loss: 0.4582, Avg Loss: 0.4572\n",
      "Epoch 91 Step 30 Loss: 0.4578, Avg Loss: 0.4566\n",
      "Epoch 91 Step 40 Loss: 0.4642, Avg Loss: 0.4567\n",
      "Epoch 91 Step 50 Loss: 0.4561, Avg Loss: 0.4561\n",
      "Step 5269 — Test metrics:\n",
      "  precision@10: 0.018278146\n",
      "  recall@10: 0.018278146\n",
      "  ndcg@10: 0.016412245\n",
      "  map@10: 0.004551876\n",
      "Epoch 91 completed. Train BPR Loss: 0.4555\n",
      "\n",
      "Epoch 92 Step 1 Loss: 0.4493, Avg Loss: 0.4493\n",
      "Step 5278 — Test metrics:\n",
      "  precision@10: 0.018311258\n",
      "  recall@10: 0.018311258\n",
      "  ndcg@10: 0.016458249\n",
      "  map@10: 0.004566245\n",
      "Epoch 92 Step 10 Loss: 0.4470, Avg Loss: 0.4517\n",
      "Epoch 92 Step 20 Loss: 0.4522, Avg Loss: 0.4515\n",
      "Epoch 92 Step 30 Loss: 0.4567, Avg Loss: 0.4516\n",
      "Epoch 92 Step 40 Loss: 0.4541, Avg Loss: 0.4516\n",
      "Epoch 92 Step 50 Loss: 0.4423, Avg Loss: 0.4513\n",
      "Step 5327 — Test metrics:\n",
      "  precision@10: 0.018940397\n",
      "  recall@10: 0.018940397\n",
      "  ndcg@10: 0.017091024\n",
      "  map@10: 0.004786135\n",
      "Epoch 92 completed. Train BPR Loss: 0.4515\n",
      "\n",
      "Epoch 93 Step 1 Loss: 0.4513, Avg Loss: 0.4513\n",
      "Step 5336 — Test metrics:\n",
      "  precision@10: 0.018973510\n",
      "  recall@10: 0.018973510\n",
      "  ndcg@10: 0.017130863\n",
      "  map@10: 0.004797586\n",
      "Epoch 93 Step 10 Loss: 0.4429, Avg Loss: 0.4495\n",
      "Epoch 93 Step 20 Loss: 0.4519, Avg Loss: 0.4505\n",
      "Epoch 93 Step 30 Loss: 0.4517, Avg Loss: 0.4501\n",
      "Epoch 93 Step 40 Loss: 0.4524, Avg Loss: 0.4502\n",
      "Epoch 93 Step 50 Loss: 0.4498, Avg Loss: 0.4499\n",
      "Step 5385 — Test metrics:\n",
      "  precision@10: 0.019635762\n",
      "  recall@10: 0.019635762\n",
      "  ndcg@10: 0.017784023\n",
      "  map@10: 0.005021950\n",
      "Epoch 93 completed. Train BPR Loss: 0.4500\n",
      "\n",
      "Epoch 94 Step 1 Loss: 0.4462, Avg Loss: 0.4462\n",
      "Step 5394 — Test metrics:\n",
      "  precision@10: 0.019834437\n",
      "  recall@10: 0.019834437\n",
      "  ndcg@10: 0.017950105\n",
      "  map@10: 0.005072999\n",
      "Epoch 94 Step 10 Loss: 0.4484, Avg Loss: 0.4471\n",
      "Epoch 94 Step 20 Loss: 0.4439, Avg Loss: 0.4480\n",
      "Epoch 94 Step 30 Loss: 0.4496, Avg Loss: 0.4477\n",
      "Epoch 94 Step 40 Loss: 0.4534, Avg Loss: 0.4477\n",
      "Epoch 94 Step 50 Loss: 0.4430, Avg Loss: 0.4479\n",
      "Step 5443 — Test metrics:\n",
      "  precision@10: 0.020447020\n",
      "  recall@10: 0.020447020\n",
      "  ndcg@10: 0.018638789\n",
      "  map@10: 0.005317191\n",
      "Epoch 94 completed. Train BPR Loss: 0.4478\n",
      "\n",
      "Epoch 95 Step 1 Loss: 0.4535, Avg Loss: 0.4535\n",
      "Step 5452 — Test metrics:\n",
      "  precision@10: 0.020612583\n",
      "  recall@10: 0.020612583\n",
      "  ndcg@10: 0.018751171\n",
      "  map@10: 0.005344266\n",
      "Epoch 95 Step 10 Loss: 0.4455, Avg Loss: 0.4480\n",
      "Epoch 95 Step 20 Loss: 0.4486, Avg Loss: 0.4463\n",
      "Epoch 95 Step 30 Loss: 0.4476, Avg Loss: 0.4464\n",
      "Epoch 95 Step 40 Loss: 0.4410, Avg Loss: 0.4465\n",
      "Epoch 95 Step 50 Loss: 0.4446, Avg Loss: 0.4463\n",
      "Step 5501 — Test metrics:\n",
      "  precision@10: 0.021026490\n",
      "  recall@10: 0.021026490\n",
      "  ndcg@10: 0.019231856\n",
      "  map@10: 0.005533743\n",
      "Epoch 95 completed. Train BPR Loss: 0.4460\n",
      "\n",
      "Epoch 96 Step 1 Loss: 0.4377, Avg Loss: 0.4377\n",
      "Step 5510 — Test metrics:\n",
      "  precision@10: 0.021175497\n",
      "  recall@10: 0.021175497\n",
      "  ndcg@10: 0.019343680\n",
      "  map@10: 0.005550011\n",
      "Epoch 96 Step 10 Loss: 0.4517, Avg Loss: 0.4428\n",
      "Epoch 96 Step 20 Loss: 0.4365, Avg Loss: 0.4424\n",
      "Epoch 96 Step 30 Loss: 0.4391, Avg Loss: 0.4430\n",
      "Epoch 96 Step 40 Loss: 0.4453, Avg Loss: 0.4430\n",
      "Epoch 96 Step 50 Loss: 0.4384, Avg Loss: 0.4431\n",
      "Step 5559 — Test metrics:\n",
      "  precision@10: 0.021887417\n",
      "  recall@10: 0.021887417\n",
      "  ndcg@10: 0.020060748\n",
      "  map@10: 0.005806121\n",
      "Epoch 96 completed. Train BPR Loss: 0.4431\n",
      "\n",
      "Epoch 97 Step 1 Loss: 0.4476, Avg Loss: 0.4476\n",
      "Step 5568 — Test metrics:\n",
      "  precision@10: 0.022102649\n",
      "  recall@10: 0.022102649\n",
      "  ndcg@10: 0.020280565\n",
      "  map@10: 0.005872878\n",
      "Epoch 97 Step 10 Loss: 0.4371, Avg Loss: 0.4421\n",
      "Epoch 97 Step 20 Loss: 0.4436, Avg Loss: 0.4415\n",
      "Epoch 97 Step 30 Loss: 0.4442, Avg Loss: 0.4419\n",
      "Epoch 97 Step 40 Loss: 0.4421, Avg Loss: 0.4415\n",
      "Epoch 97 Step 50 Loss: 0.4418, Avg Loss: 0.4415\n",
      "Step 5617 — Test metrics:\n",
      "  precision@10: 0.022516556\n",
      "  recall@10: 0.022516556\n",
      "  ndcg@10: 0.020696501\n",
      "  map@10: 0.006023323\n",
      "Epoch 97 completed. Train BPR Loss: 0.4415\n",
      "\n",
      "Epoch 98 Step 1 Loss: 0.4328, Avg Loss: 0.4328\n",
      "Step 5626 — Test metrics:\n",
      "  precision@10: 0.022599338\n",
      "  recall@10: 0.022599338\n",
      "  ndcg@10: 0.020760113\n",
      "  map@10: 0.006041791\n",
      "Epoch 98 Step 10 Loss: 0.4443, Avg Loss: 0.4376\n",
      "Epoch 98 Step 20 Loss: 0.4419, Avg Loss: 0.4372\n",
      "Epoch 98 Step 30 Loss: 0.4357, Avg Loss: 0.4381\n",
      "Epoch 98 Step 40 Loss: 0.4393, Avg Loss: 0.4387\n",
      "Epoch 98 Step 50 Loss: 0.4367, Avg Loss: 0.4387\n",
      "Step 5675 — Test metrics:\n",
      "  precision@10: 0.023013245\n",
      "  recall@10: 0.023013245\n",
      "  ndcg@10: 0.021196798\n",
      "  map@10: 0.006206986\n",
      "Epoch 98 completed. Train BPR Loss: 0.4389\n",
      "\n",
      "Epoch 99 Step 1 Loss: 0.4439, Avg Loss: 0.4439\n",
      "Step 5684 — Test metrics:\n",
      "  precision@10: 0.023029801\n",
      "  recall@10: 0.023029801\n",
      "  ndcg@10: 0.021220023\n",
      "  map@10: 0.006216887\n",
      "Epoch 99 Step 10 Loss: 0.4392, Avg Loss: 0.4383\n",
      "Epoch 99 Step 20 Loss: 0.4346, Avg Loss: 0.4378\n",
      "Epoch 99 Step 30 Loss: 0.4248, Avg Loss: 0.4375\n",
      "Epoch 99 Step 40 Loss: 0.4344, Avg Loss: 0.4370\n",
      "Epoch 99 Step 50 Loss: 0.4441, Avg Loss: 0.4367\n",
      "Step 5733 — Test metrics:\n",
      "  precision@10: 0.023543046\n",
      "  recall@10: 0.023543046\n",
      "  ndcg@10: 0.021818163\n",
      "  map@10: 0.006442165\n",
      "Epoch 99 completed. Train BPR Loss: 0.4370\n",
      "\n",
      "Epoch 100 Step 1 Loss: 0.4357, Avg Loss: 0.4357\n",
      "Step 5742 — Test metrics:\n",
      "  precision@10: 0.023609272\n",
      "  recall@10: 0.023609272\n",
      "  ndcg@10: 0.021954980\n",
      "  map@10: 0.006508948\n",
      "Epoch 100 Step 10 Loss: 0.4396, Avg Loss: 0.4355\n",
      "Epoch 100 Step 20 Loss: 0.4320, Avg Loss: 0.4352\n",
      "Epoch 100 Step 30 Loss: 0.4426, Avg Loss: 0.4351\n",
      "Epoch 100 Step 40 Loss: 0.4367, Avg Loss: 0.4353\n",
      "Epoch 100 Step 50 Loss: 0.4494, Avg Loss: 0.4354\n",
      "Step 5791 — Test metrics:\n",
      "  precision@10: 0.024271523\n",
      "  recall@10: 0.024271523\n",
      "  ndcg@10: 0.022687986\n",
      "  map@10: 0.006801200\n",
      "Epoch 100 completed. Train BPR Loss: 0.4350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "edge_type = hyperparameters['train_edge_type']\n",
    "num_epochs = hyperparameters['train_num_epochs']\n",
    "lr = hyperparameters['train_lr']\n",
    "batch_size = hyperparameters['train_batch_size']\n",
    "print_every = hyperparameters['train_print_every']\n",
    "test_every = hyperparameters['train_test_every']\n",
    "top_k = hyperparameters['test_topk']\n",
    "test_batch_size = hyperparameters['test_batch_size']\n",
    "model = train_simple_model(model,\n",
    "                    data,\n",
    "                    num_epochs=num_epochs,\n",
    "                    lr=lr,\n",
    "                    batch_size=batch_size,\n",
    "                    device=device,\n",
    "                    print_every=print_every,\n",
    "                    test_every=test_every,\n",
    "                    top_k=top_k,\n",
    "                    test_batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:10:25.822907Z",
     "iopub.status.busy": "2025-06-24T19:10:25.822626Z",
     "iopub.status.idle": "2025-06-24T19:10:25.833810Z",
     "shell.execute_reply": "2025-06-24T19:10:25.833118Z",
     "shell.execute_reply.started": "2025-06-24T19:10:25.822890Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='gnn_model_mvl.model' target='_blank'>gnn_model_mvl.model</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/gnn_model_mvl.model"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, \"gnn_model_mvl.model\")\n",
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('gnn_model_mvl.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:10:25.834651Z",
     "iopub.status.busy": "2025-06-24T19:10:25.834450Z",
     "iopub.status.idle": "2025-06-24T19:10:26.071666Z",
     "shell.execute_reply": "2025-06-24T19:10:26.070992Z",
     "shell.execute_reply.started": "2025-06-24T19:10:25.834637Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:10:26.073564Z",
     "iopub.status.busy": "2025-06-24T19:10:26.073325Z",
     "iopub.status.idle": "2025-06-24T19:10:26.281822Z",
     "shell.execute_reply": "2025-06-24T19:10:26.281081Z",
     "shell.execute_reply.started": "2025-06-24T19:10:26.073546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "log_model(\n",
    "    experiment=experiment,\n",
    "    model=model,\n",
    "    model_name=\"GNN\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T19:10:26.282991Z",
     "iopub.status.busy": "2025-06-24T19:10:26.282738Z",
     "iopub.status.idle": "2025-06-24T19:10:28.707115Z",
     "shell.execute_reply": "2025-06-24T19:10:28.706370Z",
     "shell.execute_reply.started": "2025-06-24T19:10:26.282967Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : baseline-movielens\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/annanet/gnn-recommender/4b3f9c68f8684549869e2e3830603d43\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test map@10 vs step [200]       : (0.0004927204877536003, 0.006801199674130139)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test ndcg@10 vs step [200]      : (0.0018364915583727217, 0.022687986491322955)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test precision@10 vs step [200] : (0.002036423841059603, 0.02427152317880795)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test recall@10 vs step [200]    : (0.002036423841059603, 0.02427152317880795)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Train BPR Loss vs step [5800]   : (0.4244499206542969, 3.3260836601257324)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [580]                      : (0.4274894595146179, 3.28778076171875)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : baseline-movielens\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed              : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_batch_size   : 8192\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_topk         : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_batch_size  : 16384\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_edge_type   : ('item', 'to_feedback_explicit_positive', 'explicit_positive')\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_lr          : 8e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_num_epochs  : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_print_every : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_test_every  : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     types_of_feedback : ['explicit_positive', 'expliсit_negative', 'implicit_positive', 'implicit_negative']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 2 (1.20 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7705289,
     "sourceId": 12229447,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
