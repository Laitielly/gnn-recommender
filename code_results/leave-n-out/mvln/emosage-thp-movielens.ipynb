{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-24T21:27:38.363257Z",
     "iopub.status.busy": "2025-06-24T21:27:38.363028Z",
     "iopub.status.idle": "2025-06-24T21:27:54.475673Z",
     "shell.execute_reply": "2025-06-24T21:27:54.474805Z",
     "shell.execute_reply.started": "2025-06-24T21:27:38.363237Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.1/727.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip -q install torch_geometric rectools\n",
    "!pip -q install comet_ml\n",
    "!pip -q install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:27:54.477681Z",
     "iopub.status.busy": "2025-06-24T21:27:54.477444Z",
     "iopub.status.idle": "2025-06-24T21:28:00.149797Z",
     "shell.execute_reply": "2025-06-24T21:28:00.149027Z",
     "shell.execute_reply.started": "2025-06-24T21:27:54.477660Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "from comet_ml import Experiment\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:00.150912Z",
     "iopub.status.busy": "2025-06-24T21:28:00.150568Z",
     "iopub.status.idle": "2025-06-24T21:28:00.157405Z",
     "shell.execute_reply": "2025-06-24T21:28:00.156812Z",
     "shell.execute_reply.started": "2025-06-24T21:28:00.150893Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:00.158438Z",
     "iopub.status.busy": "2025-06-24T21:28:00.158195Z",
     "iopub.status.idle": "2025-06-24T21:28:06.222632Z",
     "shell.execute_reply": "2025-06-24T21:28:06.222081Z",
     "shell.execute_reply.started": "2025-06-24T21:28:00.158415Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/annanet/gnn-recommender/63f8eff601f84d4191b0dbc3136908bd\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/kaggle/working' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
     ]
    }
   ],
   "source": [
    "experiment = Experiment(\n",
    "  api_key=os.getenv('API_KEY'),\n",
    "  project_name=\"gnn-recommender\",\n",
    "  workspace=\"annanet\",\n",
    "  log_code=True\n",
    ")\n",
    "\n",
    "experiment.set_name('emoSAGE+THP-movielens')\n",
    "experiment.add_tags(['movielens', 'leave-n-out'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.comet.com/annanet/gnn-recommender/63f8eff601f84d4191b0dbc3136908bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:06.223996Z",
     "iopub.status.busy": "2025-06-24T21:28:06.223484Z",
     "iopub.status.idle": "2025-06-24T21:28:06.229015Z",
     "shell.execute_reply": "2025-06-24T21:28:06.228264Z",
     "shell.execute_reply.started": "2025-06-24T21:28:06.223971Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'seed': 42,\n",
    "    'types_of_feedback': [\"explicit_positive\", \"expliсit_negative\",\n",
    "                          \"implicit_positive\", \"implicit_negative\"],\n",
    "    'max_len_of_thp_history': 100,\n",
    "    'pad_id': 0,         \n",
    "    'cls_id': None,  # filled in at the stage of creating a story for thp\n",
    "    'thp_dmodel': 64,  # размер эмбеддингов\n",
    "    'thp_n_head': 4,  # число attention-голов\n",
    "    'thp_window_size': 101,  # окно THP\n",
    "    'thp_decay': 1.0,  # скорость экспоненциального затухания\n",
    "    'thp_dropout': 0.2,  # dropout\n",
    "    'train_edge_type': [('item','to_feedback_explicit_positive','explicit_positive'), \n",
    "                        ('item','to_feedback_implicit_positive','implicit_positive')],\n",
    "    'train_num_epochs': 200,\n",
    "    'train_lr': 1e-3,\n",
    "    'train_batch_size': 4096,\n",
    "    'train_print_every': 20,  # раз в сколько шагов печатаем статистику\n",
    "    'train_test_every': 50,\n",
    "    'test_topk': 10,\n",
    "    'test_batch_size': 8192,\n",
    "    'train_scheduler_step_size': 150,\n",
    "    'train_scheduler_gamma': 0.98\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:06.229933Z",
     "iopub.status.busy": "2025-06-24T21:28:06.229726Z",
     "iopub.status.idle": "2025-06-24T21:28:06.261340Z",
     "shell.execute_reply": "2025-06-24T21:28:06.260806Z",
     "shell.execute_reply.started": "2025-06-24T21:28:06.229918Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv', 'test.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/kaggle/input/data/leave-n-out/mvln')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:06.264028Z",
     "iopub.status.busy": "2025-06-24T21:28:06.263569Z",
     "iopub.status.idle": "2025-06-24T21:28:16.488572Z",
     "shell.execute_reply": "2025-06-24T21:28:16.487787Z",
     "shell.execute_reply.started": "2025-06-24T21:28:06.264012Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from rectools import Columns\n",
    "from rectools.metrics import MAP, Precision, Recall, NDCG, calc_metrics\n",
    "\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:16.490101Z",
     "iopub.status.busy": "2025-06-24T21:28:16.489412Z",
     "iopub.status.idle": "2025-06-24T21:28:16.499671Z",
     "shell.execute_reply": "2025-06-24T21:28:16.498811Z",
     "shell.execute_reply.started": "2025-06-24T21:28:16.490079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = hyperparameters['seed']\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:16.500750Z",
     "iopub.status.busy": "2025-06-24T21:28:16.500519Z",
     "iopub.status.idle": "2025-06-24T21:28:17.701670Z",
     "shell.execute_reply": "2025-06-24T21:28:17.700895Z",
     "shell.execute_reply.started": "2025-06-24T21:28:16.500732Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  timestamp                date\n",
      "0        1      3186       4  978300019 2000-12-31 22:00:19\n",
      "1        1      1270       5  978300055 2000-12-31 22:00:55\n",
      "2        1      1721       4  978300055 2000-12-31 22:00:55\n",
      "3        1      1022       5  978300055 2000-12-31 22:00:55\n",
      "4        1      2340       3  978300103 2000-12-31 22:01:43\n"
     ]
    }
   ],
   "source": [
    "rootpath = '/kaggle/input/data/leave-n-out/mvln/'\n",
    "train = pd.read_csv(\n",
    "    rootpath+'train.csv'\n",
    ")\n",
    "train['date'] = pd.to_datetime(train['timestamp'], unit='s')\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:17.702784Z",
     "iopub.status.busy": "2025-06-24T21:28:17.702506Z",
     "iopub.status.idle": "2025-06-24T21:28:17.744397Z",
     "shell.execute_reply": "2025-06-24T21:28:17.743536Z",
     "shell.execute_reply.started": "2025-06-24T21:28:17.702739Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество explicit позитивного фидбека 211802\n",
      "Количество explicit негативного фидбека 153484\n"
     ]
    }
   ],
   "source": [
    "explicit_positive = train[(train[\"rating\"] == 5)].index\n",
    "explisit_negative = train[(train[\"rating\"] <= 2)].index\n",
    "\n",
    "explicit_combined_feedback = explicit_positive.union(explisit_negative)\n",
    "print('Количество explicit позитивного фидбека', explicit_positive.shape[0])\n",
    "print('Количество explicit негативного фидбека', explisit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:17.745870Z",
     "iopub.status.busy": "2025-06-24T21:28:17.745283Z",
     "iopub.status.idle": "2025-06-24T21:28:17.787436Z",
     "shell.execute_reply": "2025-06-24T21:28:17.786737Z",
     "shell.execute_reply.started": "2025-06-24T21:28:17.745844Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество implicit позитивного фидбека 327987\n",
      "Количество implicit негативного фидбека 246536\n"
     ]
    }
   ],
   "source": [
    "implicit_positive = train[(train[\"rating\"] == 4)].index\n",
    "implicit_negative = train[(train[\"rating\"] == 3)].index\n",
    "\n",
    "implicit_combined_feedback = implicit_positive.union(implicit_negative)\n",
    "print('Количество implicit позитивного фидбека', implicit_positive.shape[0])\n",
    "print('Количество implicit негативного фидбека', implicit_negative.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:17.788325Z",
     "iopub.status.busy": "2025-06-24T21:28:17.788132Z",
     "iopub.status.idle": "2025-06-24T21:28:17.904285Z",
     "shell.execute_reply": "2025-06-24T21:28:17.903473Z",
     "shell.execute_reply.started": "2025-06-24T21:28:17.788311Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2000-12-31 22:00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2000-12-31 22:01:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id             target                date\n",
       "0        1      3186  implicit_positive 2000-12-31 22:00:19\n",
       "1        1      1270  explicit_positive 2000-12-31 22:00:55\n",
       "2        1      1721  implicit_positive 2000-12-31 22:00:55\n",
       "3        1      1022  explicit_positive 2000-12-31 22:00:55\n",
       "4        1      2340  implicit_negative 2000-12-31 22:01:43"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:, \"target\"] = \"\"\n",
    "train.loc[explicit_positive, \"target\"] = \"explicit_positive\"\n",
    "train.loc[explisit_negative, \"target\"] = \"expliсit_negative\"\n",
    "train.loc[implicit_positive, \"target\"] = \"implicit_positive\"\n",
    "train.loc[implicit_negative, \"target\"] = \"implicit_negative\"\n",
    "\n",
    "train = train[['user_id','movie_id','target','date']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:17.905455Z",
     "iopub.status.busy": "2025-06-24T21:28:17.905180Z",
     "iopub.status.idle": "2025-06-24T21:28:18.092863Z",
     "shell.execute_reply": "2025-06-24T21:28:18.092193Z",
     "shell.execute_reply.started": "2025-06-24T21:28:17.905437Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = train.sort_values(by=[\"user_id\", \"date\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:18.093892Z",
     "iopub.status.busy": "2025-06-24T21:28:18.093648Z",
     "iopub.status.idle": "2025-06-24T21:28:18.103695Z",
     "shell.execute_reply": "2025-06-24T21:28:18.102903Z",
     "shell.execute_reply.started": "2025-06-24T21:28:18.093874Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3186</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2000-12-31 22:00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1721</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2000-12-31 22:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2340</td>\n",
       "      <td>implicit_negative</td>\n",
       "      <td>2000-12-31 22:01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939804</th>\n",
       "      <td>6040</td>\n",
       "      <td>1947</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2001-08-10 14:33:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939805</th>\n",
       "      <td>6040</td>\n",
       "      <td>1211</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2001-08-10 14:34:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939806</th>\n",
       "      <td>6040</td>\n",
       "      <td>2571</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2001-08-10 14:35:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939807</th>\n",
       "      <td>6040</td>\n",
       "      <td>1333</td>\n",
       "      <td>implicit_positive</td>\n",
       "      <td>2001-08-10 14:35:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939808</th>\n",
       "      <td>6040</td>\n",
       "      <td>953</td>\n",
       "      <td>explicit_positive</td>\n",
       "      <td>2001-08-10 14:36:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>939809 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  movie_id             target                date\n",
       "0             1      3186  implicit_positive 2000-12-31 22:00:19\n",
       "1             1      1270  explicit_positive 2000-12-31 22:00:55\n",
       "2             1      1721  implicit_positive 2000-12-31 22:00:55\n",
       "3             1      1022  explicit_positive 2000-12-31 22:00:55\n",
       "4             1      2340  implicit_negative 2000-12-31 22:01:43\n",
       "...         ...       ...                ...                 ...\n",
       "939804     6040      1947  implicit_positive 2001-08-10 14:33:56\n",
       "939805     6040      1211  explicit_positive 2001-08-10 14:34:40\n",
       "939806     6040      2571  implicit_positive 2001-08-10 14:35:26\n",
       "939807     6040      1333  implicit_positive 2001-08-10 14:35:40\n",
       "939808     6040       953  explicit_positive 2001-08-10 14:36:00\n",
       "\n",
       "[939809 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:18.104985Z",
     "iopub.status.busy": "2025-06-24T21:28:18.104651Z",
     "iopub.status.idle": "2025-06-24T21:28:18.119525Z",
     "shell.execute_reply": "2025-06-24T21:28:18.118906Z",
     "shell.execute_reply.started": "2025-06-24T21:28:18.104965Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.columns = ['user_id', 'item_id', 'target', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:18.120428Z",
     "iopub.status.busy": "2025-06-24T21:28:18.120187Z",
     "iopub.status.idle": "2025-06-24T21:28:18.210901Z",
     "shell.execute_reply": "2025-06-24T21:28:18.210141Z",
     "shell.execute_reply.started": "2025-06-24T21:28:18.120407Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  movie_id  rating  timestamp                date\n",
      "0        1      2687       3  978824268 2001-01-06 23:37:48\n",
      "1        1       745       3  978824268 2001-01-06 23:37:48\n",
      "2        1       588       4  978824268 2001-01-06 23:37:48\n",
      "3        1         1       5  978824268 2001-01-06 23:37:48\n",
      "4        1      2355       5  978824291 2001-01-06 23:38:11\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\n",
    "    rootpath+'test.csv'\n",
    ")\n",
    "test['date'] = pd.to_datetime(test['timestamp'], unit='s')\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:18.212049Z",
     "iopub.status.busy": "2025-06-24T21:28:18.211744Z",
     "iopub.status.idle": "2025-06-24T21:28:18.220848Z",
     "shell.execute_reply": "2025-06-24T21:28:18.220172Z",
     "shell.execute_reply.started": "2025-06-24T21:28:18.212025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2687</td>\n",
       "      <td>2001-01-06 23:37:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>745</td>\n",
       "      <td>2001-01-06 23:37:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>2001-01-06 23:37:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-01-06 23:37:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>2001-01-06 23:38:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id                date\n",
       "0        1      2687 2001-01-06 23:37:48\n",
       "1        1       745 2001-01-06 23:37:48\n",
       "2        1       588 2001-01-06 23:37:48\n",
       "3        1         1 2001-01-06 23:37:48\n",
       "4        1      2355 2001-01-06 23:38:11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[['user_id','movie_id', 'date']]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:18.221654Z",
     "iopub.status.busy": "2025-06-24T21:28:18.221483Z",
     "iopub.status.idle": "2025-06-24T21:28:18.234570Z",
     "shell.execute_reply": "2025-06-24T21:28:18.233957Z",
     "shell.execute_reply.started": "2025-06-24T21:28:18.221640Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test.columns = ['user_id', 'item_id', 'date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP model v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:18.235712Z",
     "iopub.status.busy": "2025-06-24T21:28:18.235410Z",
     "iopub.status.idle": "2025-06-24T21:28:18.394456Z",
     "shell.execute_reply": "2025-06-24T21:28:18.393813Z",
     "shell.execute_reply.started": "2025-06-24T21:28:18.235690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train.loc[:, \"event\"] = 0\n",
    "train.loc[(train[\"target\"] == \"explicit_positive\") | (train[\"target\"] == \"implicit_positive\"), \"event\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:18.395388Z",
     "iopub.status.busy": "2025-06-24T21:28:18.395192Z",
     "iopub.status.idle": "2025-06-24T21:28:18.416986Z",
     "shell.execute_reply": "2025-06-24T21:28:18.416345Z",
     "shell.execute_reply.started": "2025-06-24T21:28:18.395373Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60394, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[(test.user_id.isin(train.user_id)) & (test.item_id.isin(train.item_id))].copy()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:18.418030Z",
     "iopub.status.busy": "2025-06-24T21:28:18.417676Z",
     "iopub.status.idle": "2025-06-24T21:28:18.598902Z",
     "shell.execute_reply": "2025-06-24T21:28:18.598320Z",
     "shell.execute_reply.started": "2025-06-24T21:28:18.418011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. Преобразование данных - для куарека не особо нужно, но для других - напоминалка\n",
    "# делаем всегда! чтобы не сломать ничего дальше и чтобы все индексы были от 0 до N без пропусков\n",
    "user_encoder = LabelEncoder()\n",
    "video_encoder = LabelEncoder()\n",
    "\n",
    "train.loc[:, 'user_id'] = user_encoder.fit_transform(train['user_id'])\n",
    "train.loc[:, 'item_id'] = video_encoder.fit_transform(train['item_id'])\n",
    "\n",
    "test.loc[:, 'user_id'] = user_encoder.transform(test['user_id'])\n",
    "test.loc[:, 'item_id'] = video_encoder.transform(test['item_id'])\n",
    "\n",
    "train['user_id'] = train['user_id'].astype(int)\n",
    "train['item_id'] = train['item_id'].astype(int)\n",
    "test['user_id'] = test['user_id'].astype(int)\n",
    "test['item_id'] = test['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:18.603036Z",
     "iopub.status.busy": "2025-06-24T21:28:18.602832Z",
     "iopub.status.idle": "2025-06-24T21:28:18.622104Z",
     "shell.execute_reply": "2025-06-24T21:28:18.621400Z",
     "shell.execute_reply.started": "2025-06-24T21:28:18.603022Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных item_id 3700\n",
      "Количество уникальных user_id 6040\n"
     ]
    }
   ],
   "source": [
    "# т.е. сразу знаем количество и в каких пределах изменяется user_id и video_id\n",
    "num_videos = train['item_id'].nunique()\n",
    "num_users = train['user_id'].nunique()\n",
    "\n",
    "print('Количество уникальных item_id', num_videos)\n",
    "print('Количество уникальных user_id', num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:18.622974Z",
     "iopub.status.busy": "2025-06-24T21:28:18.622740Z",
     "iopub.status.idle": "2025-06-24T21:28:18.632904Z",
     "shell.execute_reply": "2025-06-24T21:28:18.631938Z",
     "shell.execute_reply.started": "2025-06-24T21:28:18.622958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# так как используем pad, то нумерацию item_id начинаем с 1 до max + 1, чтобы для pad забить 0\n",
    "train.loc[:, 'item_id'] += 1\n",
    "test.loc[:, 'item_id'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:18.634120Z",
     "iopub.status.busy": "2025-06-24T21:28:18.633792Z",
     "iopub.status.idle": "2025-06-24T21:28:18.642476Z",
     "shell.execute_reply": "2025-06-24T21:28:18.641891Z",
     "shell.execute_reply.started": "2025-06-24T21:28:18.634095Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "\n",
    "def prepare_hetero_data(df: pd.DataFrame) -> HeteroData:\n",
    "    \"\"\"\n",
    "    Build a heterogeneous graph dataset from interaction records.\n",
    "\n",
    "    This function constructs a PyTorch Geometric HeteroData object with three types of nodes:\n",
    "      - 'user': representing each unique user in the dataset\n",
    "      - 'item': representing each unique item (formerly movie)\n",
    "      - one node set per feedback type (target), representing feedback interaction events\n",
    "\n",
    "    Edges are created as follows:\n",
    "      1) item -> feedback: connecting items to feedback events of type ft\n",
    "      2) feedback -> item: reverse link from feedback events back to items (for message passing)\n",
    "      3) feedback -> user: linking each feedback event of type ft to its corresponding user (one-to-one)\n",
    "      4) user -> user: a complete graph among all users under the relation 'interacts'\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame must contain the following columns:\n",
    "          - 'user_id' : integer identifiers for users (0-indexed or otherwise)\n",
    "          - 'item_id' : integer identifiers for items (e.g. movies), values must be in [0, max(item_id)]\n",
    "          - 'target' : categorical or numeric label indicating feedback type (e.g. click, purchase)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    data : torch_geometric.data.HeteroData\n",
    "        A heterogeneous graph with node types 'user', 'item', and one per feedback label, and edge_index\n",
    "        tensors appropriately set for message passing in a GNN.\n",
    "    \"\"\"\n",
    "    # Determine the number of users and items\n",
    "    num_users = df['user_id'].nunique()\n",
    "    num_items = int(df['item_id'].max()) + 1\n",
    "    feedback_types = df['target'].unique().tolist()\n",
    "\n",
    "    # Initialize HeteroData\n",
    "    data = HeteroData()\n",
    "    data['user'].node_id = torch.arange(num_users)\n",
    "    data['item'].node_id = torch.arange(num_items)\n",
    "    for ft in feedback_types:\n",
    "        data[ft].node_id = torch.arange(num_users)\n",
    "\n",
    "    # Build edges: item <-> feedback <-> user\n",
    "    for ft in feedback_types:\n",
    "        mask = df['target'] == ft\n",
    "        items = torch.LongTensor(df.loc[mask, 'item_id'].values)\n",
    "        users_idx = torch.LongTensor(df.loc[mask, 'user_id'].values)\n",
    "\n",
    "        # item -> feedback\n",
    "        data['item', f'to_feedback_{ft}', ft].edge_index = torch.stack([items, users_idx], dim=0)\n",
    "        # feedback -> item\n",
    "        data[ft, f'feedback_to_item_{ft}', 'item'].edge_index = torch.stack([users_idx, items], dim=0)\n",
    "        # feedback -> user (1:1 mapping)\n",
    "        idx = torch.arange(num_users)\n",
    "        data[ft, f'to_user_{ft}', 'user'].edge_index = torch.stack([idx, idx], dim=0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:18.643676Z",
     "iopub.status.busy": "2025-06-24T21:28:18.643344Z",
     "iopub.status.idle": "2025-06-24T21:28:19.008127Z",
     "shell.execute_reply": "2025-06-24T21:28:19.007392Z",
     "shell.execute_reply.started": "2025-06-24T21:28:18.643654Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  user={ node_id=[6040] },\n",
       "  item={ node_id=[3701] },\n",
       "  implicit_positive={ node_id=[6040] },\n",
       "  explicit_positive={ node_id=[6040] },\n",
       "  implicit_negative={ node_id=[6040] },\n",
       "  expliсit_negative={ node_id=[6040] },\n",
       "  (item, to_feedback_implicit_positive, implicit_positive)={ edge_index=[2, 327987] },\n",
       "  (implicit_positive, feedback_to_item_implicit_positive, item)={ edge_index=[2, 327987] },\n",
       "  (implicit_positive, to_user_implicit_positive, user)={ edge_index=[2, 6040] },\n",
       "  (item, to_feedback_explicit_positive, explicit_positive)={ edge_index=[2, 211802] },\n",
       "  (explicit_positive, feedback_to_item_explicit_positive, item)={ edge_index=[2, 211802] },\n",
       "  (explicit_positive, to_user_explicit_positive, user)={ edge_index=[2, 6040] },\n",
       "  (item, to_feedback_implicit_negative, implicit_negative)={ edge_index=[2, 246536] },\n",
       "  (implicit_negative, feedback_to_item_implicit_negative, item)={ edge_index=[2, 246536] },\n",
       "  (implicit_negative, to_user_implicit_negative, user)={ edge_index=[2, 6040] },\n",
       "  (item, to_feedback_expliсit_negative, expliсit_negative)={ edge_index=[2, 153484] },\n",
       "  (expliсit_negative, feedback_to_item_expliсit_negative, item)={ edge_index=[2, 153484] },\n",
       "  (expliсit_negative, to_user_expliсit_negative, user)={ edge_index=[2, 6040] }\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = prepare_hetero_data(train)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:19.009292Z",
     "iopub.status.busy": "2025-06-24T21:28:19.008972Z",
     "iopub.status.idle": "2025-06-24T21:28:19.021241Z",
     "shell.execute_reply": "2025-06-24T21:28:19.020621Z",
     "shell.execute_reply.started": "2025-06-24T21:28:19.009275Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,    1,    2,  ..., 3698, 3699, 3700])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['item'].node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:19.022351Z",
     "iopub.status.busy": "2025-06-24T21:28:19.022119Z",
     "iopub.status.idle": "2025-06-24T21:28:19.031457Z",
     "shell.execute_reply": "2025-06-24T21:28:19.030894Z",
     "shell.execute_reply.started": "2025-06-24T21:28:19.022331Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_thp_data(df: pd.DataFrame, max_len: int, pad: int, cls_id: int):\n",
    "    \"\"\"\n",
    "    Build sequences of item ids, event types and timestamps per user for THP training.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame with columns ['user_id','item_id','event','date']\n",
    "    max_len : int, maximum sequence length (pad or truncate to this length)\n",
    "    pad : int, padding token value (left-padding)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    seq_ids   : LongTensor [num_users, max_len]\n",
    "    event_type: LongTensor [num_users, max_len]\n",
    "    seq_times : FloatTensor [num_users, max_len]\n",
    "    seq_mask  : BoolTensor [num_users, max_len]\n",
    "    \"\"\"\n",
    "    users = df['user_id'].unique()\n",
    "    num_users = len(users)\n",
    "\n",
    "    # +1 for the [CLS] token\n",
    "    new_max_len = max_len + 1\n",
    "    \n",
    "    seq_ids    = torch.full((num_users, new_max_len), pad, dtype=torch.long)\n",
    "    event_type = torch.full((num_users, new_max_len), pad, dtype=torch.long)\n",
    "    seq_times  = torch.zeros((num_users, new_max_len), dtype=torch.float)\n",
    "    seq_mask   = torch.zeros((num_users, new_max_len), dtype=torch.bool)\n",
    "\n",
    "    # map event labels to ints\n",
    "    label2idx = {label: idx for idx, label in enumerate(df['event'].unique())}\n",
    "\n",
    "    # устанавливаем CLS-токен в позицию 0\n",
    "    seq_ids[:, 0]  = cls_id\n",
    "    event_type[:,0] = cls_id   \n",
    "    seq_mask[:, 0] = True\n",
    "\n",
    "    for i, u in enumerate(users):\n",
    "        user_df = df[df['user_id'] == u].sort_values('date')\n",
    "        items = user_df['item_id'].values\n",
    "        types = user_df['event'].map(label2idx).values\n",
    "        times = pd.to_datetime(user_df['date']).values.astype('datetime64[ns]').astype(np.int64) / 1e9\n",
    "        \n",
    "        seq = len(items)\n",
    "        if seq == 0:\n",
    "            continue\n",
    "\n",
    "        # вставляем реальные события **cдвинутые на 1** вправо из-за CLS,\n",
    "        # чтобы первые new_max_len-lengt...new_max_len-1 оказались данными\n",
    "        length = min(seq, max_len)\n",
    "        start = max(0, new_max_len - length)\n",
    "        seq_ids[i, start:]    = torch.tensor(items[-length:],    dtype=torch.long)\n",
    "        event_type[i, start:] = torch.tensor(types[-length:],    dtype=torch.long)\n",
    "        seq_times[i, start:]  = torch.tensor(times[-length:],    dtype=torch.float)\n",
    "        seq_mask[i, start:]   = True\n",
    "\n",
    "    return seq_ids, event_type, seq_times, seq_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:19.032430Z",
     "iopub.status.busy": "2025-06-24T21:28:19.032204Z",
     "iopub.status.idle": "2025-06-24T21:28:33.842737Z",
     "shell.execute_reply": "2025-06-24T21:28:33.842014Z",
     "shell.execute_reply.started": "2025-06-24T21:28:19.032415Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3701,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 2966, 1177,\n",
       "         1573,  956, 2145, 1657, 3173, 2596, 1116,  254,  690, 1103,  858,  594,\n",
       "         2485, 1780, 1847, 2886,  877,  969, 1781,  962, 1837,  145, 1024,  853,\n",
       "         1194, 2589, 2554, 1153,  640, 2707,  518, 2895, 2583, 2126,  963, 1106,\n",
       "          581, 2203, 1420,  514,  582]),\n",
       " tensor([3701,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    1,    0,    0,    0,    0,    0,    1,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
       "            0,    0,    0,    0,    1,    0,    0,    0,    0,    1,    0,    1,\n",
       "            0,    0,    0,    0,    0]),\n",
       " tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.7830e+08, 9.7830e+08,\n",
       "         9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08,\n",
       "         9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08,\n",
       "         9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08,\n",
       "         9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08,\n",
       "         9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08,\n",
       "         9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08, 9.7830e+08,\n",
       "         9.7830e+08, 9.7830e+08, 9.7882e+08, 9.7882e+08, 9.7882e+08]),\n",
       " tensor([ True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_ID = hyperparameters['pad_id'] \n",
    "CLS_ID = data['item'].node_id.shape[0]  \n",
    "hyperparameters['cls_id'] = CLS_ID\n",
    "max_len = hyperparameters['max_len_of_thp_history']\n",
    "\n",
    "seq_ids, event_type, seq_times, seq_mask = prepare_thp_data(train, \n",
    "                                                            max_len=max_len, \n",
    "                                                            pad=PAD_ID,\n",
    "                                                            cls_id=CLS_ID)\n",
    "seq_ids[0], event_type[0], seq_times[0], seq_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:33.843953Z",
     "iopub.status.busy": "2025-06-24T21:28:33.843670Z",
     "iopub.status.idle": "2025-06-24T21:28:33.858754Z",
     "shell.execute_reply": "2025-06-24T21:28:33.857901Z",
     "shell.execute_reply.started": "2025-06-24T21:28:33.843931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class THPEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head Transformer Hawkes-inspired encoder with local window.\n",
    "    Integrates exponential decay kernel within last `window_size` events.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int, n_head: int, window_size: int = 50, \n",
    "                 decay: float = 1.0, dropout: float = 0.1, max_len: int = 101):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_len = max_len\n",
    "        # Learnable positional embeddings\n",
    "        self.pos_emb = nn.Embedding(max_len, d_model)\n",
    "        # Temporal (time) embedding: simple linear projection from scalar to d_model\n",
    "        self.time_emb = nn.Linear(1, d_model)\n",
    "        \n",
    "        self.heads = nn.ModuleList([\n",
    "            _THPHead(d_model, decay, window_size, dropout) for _ in range(n_head)\n",
    "        ])\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "                nn.LayerNorm(d_model),\n",
    "                nn.Linear(d_model, d_model * 4),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(d_model * 4, d_model),\n",
    "                nn.Dropout(dropout)\n",
    "            )\n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, emb: torch.Tensor, times: torch.Tensor, mask: torch.BoolTensor = None):\n",
    "        # emb: [B, L, D], times: [B, L], mask: [B, L]\n",
    "        B, L, D = emb.shape\n",
    "        \n",
    "        positions = torch.arange(L, device=emb.device).unsqueeze(0).expand(B, -1)  # [B, L]\n",
    "        pe = self.pos_emb(positions)  # [B, L, D]\n",
    "        te = self.time_emb(times.unsqueeze(-1))  # [B, L, D]\n",
    "        x = emb + pe + te\n",
    "        \n",
    "        attn_out = torch.stack([head(x, times, mask) for head in self.heads], dim=0).sum(0)\n",
    "        \n",
    "        # Residual connection + normalization\n",
    "        x = x + attn_out\n",
    "        x = x + self.ffn(x)\n",
    "        \n",
    "        return self.final_norm(x)  # [B, L, D]\n",
    "\n",
    "class _THPHead(nn.Module):\n",
    "    def __init__(self, d_model: int, decay: float, window_size: int, dropout: float,\n",
    "                pos_lambda: float = None):\n",
    "        super().__init__()\n",
    "        self.linear_v = nn.Linear(d_model, d_model, bias=False)\n",
    "        nn.init.xavier_uniform_(self.linear_v.weight)\n",
    "        self.temperature = d_model ** 0.5\n",
    "        self.decay = decay\n",
    "        self.window_size = window_size\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.input_norm = nn.LayerNorm(d_model)\n",
    "        self.pos_lambda = pos_lambda or (1.0 / window_size)\n",
    "\n",
    "    def forward(self, emb: torch.Tensor, times: torch.Tensor, mask: torch.BoolTensor = None):\n",
    "        B, L, D = emb.size()\n",
    "        emb_norm = self.input_norm(emb)\n",
    "        q = emb_norm / self.temperature           # [B, L, D]\n",
    "        k = emb_norm                              # [B, L, D]\n",
    "        v = F.elu(self.linear_v(emb_norm))        # [B, L, D]\n",
    "\n",
    "        if not torch.isfinite(q).all():\n",
    "            print(\"NaN/Inf в q:\", torch.isnan(q).sum().item(), torch.isinf(q).sum().item())\n",
    "        if not torch.isfinite(k).all():\n",
    "            print(\"NaN/Inf в k:\", torch.isnan(k).sum().item(), torch.isinf(k).sum().item())\n",
    "        if not torch.isfinite(v).all():\n",
    "            print(\"NaN/Inf в v:\", torch.isnan(v).sum().item(), torch.isinf(v).sum().item())\n",
    "\n",
    "        # 3) Build pad mask only\n",
    "        if mask is not None:\n",
    "            pad_mask = ~mask.unsqueeze(1).expand(-1, L, -1)  # [B, L, L]\n",
    "        else:\n",
    "            pad_mask = torch.zeros((B, L, L), dtype=torch.bool, device=emb.device)\n",
    "\n",
    "        # Always allow self-attention for pad_mask diagonal\n",
    "        idx = torch.arange(L, device=emb.device)\n",
    "        pad_mask[:, idx, idx] = False\n",
    "\n",
    "        scores = torch.bmm(q, k.transpose(1, 2))  # [B, L, L]\n",
    "\n",
    "        # Apply temporal decay kernel\n",
    "        delta = (times.unsqueeze(-1) - times.unsqueeze(-2)).clamp(min=0)\n",
    "        scores = scores * torch.exp(-self.decay * delta)\n",
    "\n",
    "        # Apply smooth positional decay\n",
    "        dist = (idx.unsqueeze(0) - idx.unsqueeze(1)).abs().float()  # [L, L]\n",
    "        pos_decay = torch.exp(-self.pos_lambda * dist).unsqueeze(0)    # [1, L, L]\n",
    "        scores = scores * pos_decay\n",
    "\n",
    "        scores = torch.clamp(scores, min=-1e3, max=1e3)\n",
    "        scores = scores.masked_fill(pad_mask, float('-inf'))\n",
    "\n",
    "        # Debug range\n",
    "        finite = scores[~pad_mask]\n",
    "        # if finite.numel() > 0:\n",
    "        #     print(f\"Диапазон scores до softmax: min={finite.min().item():.3e}, max={finite.max().item():.3e}\")\n",
    "\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        if not torch.isfinite(attn).all():\n",
    "            print(\"NaN/Inf в attn после softmax:\", torch.isnan(attn).sum().item(), torch.isinf(attn).sum().item())\n",
    "        \n",
    "        attn = torch.nan_to_num(attn, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.bmm(attn, v)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:33.860125Z",
     "iopub.status.busy": "2025-06-24T21:28:33.859640Z",
     "iopub.status.idle": "2025-06-24T21:28:33.889502Z",
     "shell.execute_reply": "2025-06-24T21:28:33.888833Z",
     "shell.execute_reply.started": "2025-06-24T21:28:33.860105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HeteroGNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 feedback_types: list,\n",
    "                 emb_dim: int = 32,\n",
    "                 hidden_dim: int = 16,\n",
    "                 dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.feedback_types = feedback_types\n",
    "        # Embeddings\n",
    "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
    "        # 0 - padding, все остальное - item_id\n",
    "        self.item_emb = nn.Embedding(num_items + 1, emb_dim, padding_idx=0)  \n",
    "        self.fb_emb = nn.ModuleDict({ft: nn.Embedding(num_users, emb_dim)\n",
    "                                     for ft in feedback_types})\n",
    "        # LayerNorms\n",
    "        types = ['user', 'item'] + feedback_types\n",
    "        self.norm1 = nn.ModuleDict({t: nn.LayerNorm(hidden_dim) for t in types})\n",
    "        self.norm2 = nn.ModuleDict({t: nn.LayerNorm(emb_dim) for t in types})\n",
    "        # Convolutions\n",
    "        conv1, conv2 = {}, {}\n",
    "        for ft in feedback_types:\n",
    "            conv1[('item', f'to_feedback_{ft}', ft)] = SAGEConv(emb_dim, hidden_dim)\n",
    "            conv1[(ft, f'feedback_to_item_{ft}', 'item')] = SAGEConv(emb_dim, hidden_dim)\n",
    "            conv1[(ft, f'to_user_{ft}', 'user')] = SAGEConv(emb_dim, hidden_dim)\n",
    "            conv2[('item', f'to_feedback_{ft}', ft)] = SAGEConv(hidden_dim, emb_dim)\n",
    "            conv2[(ft, f'feedback_to_item_{ft}', 'item')] = SAGEConv(hidden_dim, emb_dim)\n",
    "            conv2[(ft, f'to_user_{ft}', 'user')] = SAGEConv(hidden_dim, emb_dim)\n",
    "        # user-user\n",
    "        conv1[('user', 'interacts', 'user')] = SAGEConv(emb_dim, hidden_dim)\n",
    "        conv2[('user', 'interacts', 'user')] = SAGEConv(hidden_dim, emb_dim)\n",
    "        self.conv1 = HeteroConv(conv1, aggr='mean')\n",
    "        self.conv2 = HeteroConv(conv2, aggr='mean')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Node features\n",
    "        x = {\n",
    "            'user': self.user_emb(data['user'].node_id),\n",
    "            'item': self.item_emb(data['item'].node_id)\n",
    "        }\n",
    "        for ft in self.feedback_types:\n",
    "            x[ft] = self.fb_emb[ft](data[ft].node_id)\n",
    "            \n",
    "        h1 = self.conv1(x, data.edge_index_dict)\n",
    "        h1 = {t: self.dropout(F.leaky_relu(self.norm1[t](h1[t]))) for t in h1}\n",
    "        \n",
    "        h2 = self.conv2(h1, data.edge_index_dict)\n",
    "        out = {t: self.norm2[t](h2[t]) for t in h2}\n",
    "        return out['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:33.890644Z",
     "iopub.status.busy": "2025-06-24T21:28:33.890365Z",
     "iopub.status.idle": "2025-06-24T21:28:33.911465Z",
     "shell.execute_reply": "2025-06-24T21:28:33.910796Z",
     "shell.execute_reply.started": "2025-06-24T21:28:33.890622Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_users: int,\n",
    "                 num_items: int,\n",
    "                 feedback_types: list,\n",
    "                 d_model: int = 32,\n",
    "                 n_head: int = 4,\n",
    "                 window_size: int = 50,\n",
    "                 decay: float = 1.0,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        # Static graph encoder\n",
    "        self.gnn = HeteroGNN(num_users, num_items, feedback_types,\n",
    "                             emb_dim=d_model, hidden_dim=d_model//2,\n",
    "                             dropout=dropout)\n",
    "        # Inlined THP sequence encoder\n",
    "        self.thp = THPEncoder(d_model=d_model,\n",
    "                              n_head=n_head,\n",
    "                              window_size=window_size,\n",
    "                              decay=decay,\n",
    "                              dropout=dropout)\n",
    "\n",
    "    def forward(self, data, seq_ids, seq_times, seq_mask, batch_users):\n",
    "        # Static graph embeddings\n",
    "        user_embs = self.gnn(data)          # [num_users, d_model]\n",
    "        # Sequence encoding\n",
    "        seq_item_emb = self.gnn.item_emb(seq_ids)  # [B, L, d_model]\n",
    "        attn_out = self.thp(seq_item_emb, seq_times, seq_mask)\n",
    "        seq_rep = attn_out[:, -1, :]        # [B, d_model]\n",
    "        # Get static user embeddings\n",
    "        gnn_rep = user_embs[batch_users]   # [B, d_model]\n",
    "        # Updated user embedding\n",
    "        updated_user_emb = seq_rep + gnn_rep\n",
    "        return updated_user_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:33.912447Z",
     "iopub.status.busy": "2025-06-24T21:28:33.912198Z",
     "iopub.status.idle": "2025-06-24T21:28:34.059245Z",
     "shell.execute_reply": "2025-06-24T21:28:34.058462Z",
     "shell.execute_reply.started": "2025-06-24T21:28:33.912431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_users = data['user'].node_id.shape[0]      \n",
    "num_items = data['item'].node_id.shape[0]      \n",
    "feedback_types = train['target'].unique().tolist()\n",
    "data.user_idx = data['user'].node_id\n",
    "d_model = hyperparameters['thp_dmodel']             \n",
    "n_head = hyperparameters['thp_n_head']          \n",
    "window_size = hyperparameters['thp_window_size']     \n",
    "decay = hyperparameters['thp_decay']         \n",
    "dropout = hyperparameters['thp_dropout']           \n",
    "\n",
    "model = Model(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    feedback_types=feedback_types,\n",
    "    d_model=d_model,\n",
    "    n_head=n_head,\n",
    "    window_size=window_size,\n",
    "    decay=decay,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:34.060349Z",
     "iopub.status.busy": "2025-06-24T21:28:34.060108Z",
     "iopub.status.idle": "2025-06-24T21:28:34.065438Z",
     "shell.execute_reply": "2025-06-24T21:28:34.064748Z",
     "shell.execute_reply.started": "2025-06-24T21:28:34.060323Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3701"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:34.066388Z",
     "iopub.status.busy": "2025-06-24T21:28:34.066201Z",
     "iopub.status.idle": "2025-06-24T21:28:34.841953Z",
     "shell.execute_reply": "2025-06-24T21:28:34.841279Z",
     "shell.execute_reply.started": "2025-06-24T21:28:34.066374Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THPEncoder output shape: torch.Size([32, 101, 64])\n"
     ]
    }
   ],
   "source": [
    "B = 32\n",
    "seq_ids_batch   = seq_ids[:B]     # [B, L]\n",
    "seq_times_batch = seq_times[:B]   # [B, L]\n",
    "seq_mask_batch  = seq_mask[:B]    # [B, L]\n",
    "\n",
    "item_emb = model.gnn.item_emb \n",
    "d_model = item_emb.embedding_dim\n",
    "\n",
    "# Получаем seq_item_emb: [B, L, D]\n",
    "seq_item_emb = item_emb(seq_ids_batch)\n",
    "\n",
    "thp_encoder = THPEncoder(\n",
    "    d_model=d_model,\n",
    "    n_head=4,\n",
    "    window_size=50,\n",
    "    decay=1.0,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "thp_encoder.to(device)\n",
    "seq_item_emb   = seq_item_emb.to(device)\n",
    "seq_times_batch= seq_times_batch.to(device)\n",
    "seq_mask_batch = seq_mask_batch.to(device)\n",
    "\n",
    "out = thp_encoder(\n",
    "    emb=seq_item_emb,\n",
    "    times=seq_times_batch,\n",
    "    mask=seq_mask_batch\n",
    ")\n",
    "\n",
    "print(\"THPEncoder output shape:\", out.shape)  # ожидаем [B, L, D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:34.842993Z",
     "iopub.status.busy": "2025-06-24T21:28:34.842721Z",
     "iopub.status.idle": "2025-06-24T21:28:34.942930Z",
     "shell.execute_reply": "2025-06-24T21:28:34.941956Z",
     "shell.execute_reply.started": "2025-06-24T21:28:34.842967Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated user embeddings: torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "B = 32\n",
    "batch_seq_ids   = seq_ids[:B].to(device)    # [B, L]\n",
    "batch_seq_times = seq_times[:B].to(device)  # [B, L]\n",
    "batch_seq_mask  = seq_mask[:B].to(device)   # [B, L]\n",
    "\n",
    "# data.user_idx = data['user'].node_id[:B]\n",
    "batch_users = data.user_idx[:B].to(device)\n",
    "model.to(device)\n",
    "data.to(device)\n",
    "\n",
    "updated_user_emb = model(\n",
    "    data=data,\n",
    "    seq_ids=batch_seq_ids,\n",
    "    seq_times=batch_seq_times,\n",
    "    seq_mask=batch_seq_mask,\n",
    "    batch_users=batch_users\n",
    ")  # [B, d_model]\n",
    "\n",
    "print(\"Updated user embeddings:\", updated_user_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:34.943915Z",
     "iopub.status.busy": "2025-06-24T21:28:34.943703Z",
     "iopub.status.idle": "2025-06-24T21:28:34.963328Z",
     "shell.execute_reply": "2025-06-24T21:28:34.962684Z",
     "shell.execute_reply.started": "2025-06-24T21:28:34.943899Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3700, 1, 3700)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.item_id.nunique(), train.item_id.min(), train.item_id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:34.964425Z",
     "iopub.status.busy": "2025-06-24T21:28:34.964138Z",
     "iopub.status.idle": "2025-06-24T21:28:34.975999Z",
     "shell.execute_reply": "2025-06-24T21:28:34.975338Z",
     "shell.execute_reply.started": "2025-06-24T21:28:34.964409Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (gnn): HeteroGNN(\n",
       "    (user_emb): Embedding(6040, 64)\n",
       "    (item_emb): Embedding(3702, 64, padding_idx=0)\n",
       "    (fb_emb): ModuleDict(\n",
       "      (implicit_positive): Embedding(6040, 64)\n",
       "      (explicit_positive): Embedding(6040, 64)\n",
       "      (implicit_negative): Embedding(6040, 64)\n",
       "      (expliсit_negative): Embedding(6040, 64)\n",
       "    )\n",
       "    (norm1): ModuleDict(\n",
       "      (user): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (item): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_positive): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (explicit_positive): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_negative): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (expliсit_negative): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (norm2): ModuleDict(\n",
       "      (user): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (item): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_positive): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (explicit_positive): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (implicit_negative): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (expliсit_negative): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (conv1): HeteroConv(num_relations=13)\n",
       "    (conv2): HeteroConv(num_relations=13)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (thp): THPEncoder(\n",
       "    (pos_emb): Embedding(101, 64)\n",
       "    (time_emb): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (heads): ModuleList(\n",
       "      (0-3): 4 x _THPHead(\n",
       "        (linear_v): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (input_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ffn): Sequential(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=64, out_features=256, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (4): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (final_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:34.977033Z",
     "iopub.status.busy": "2025-06-24T21:28:34.976702Z",
     "iopub.status.idle": "2025-06-24T21:28:35.300346Z",
     "shell.execute_reply": "2025-06-24T21:28:35.299774Z",
     "shell.execute_reply.started": "2025-06-24T21:28:34.977017Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = test[['user_id', 'item_id']]\n",
    "interactions = test_df.rename(columns={\n",
    "    'user_id': Columns.User,\n",
    "    'item_id': Columns.Item,\n",
    "})\n",
    "\n",
    "viewed_items = train.groupby(\"user_id\")[\"item_id\"].agg(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:35.301316Z",
     "iopub.status.busy": "2025-06-24T21:28:35.301088Z",
     "iopub.status.idle": "2025-06-24T21:28:35.306438Z",
     "shell.execute_reply": "2025-06-24T21:28:35.305674Z",
     "shell.execute_reply.started": "2025-06-24T21:28:35.301299Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLS_ID == model.gnn.item_emb.weight.shape[0] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:35.307645Z",
     "iopub.status.busy": "2025-06-24T21:28:35.307384Z",
     "iopub.status.idle": "2025-06-24T21:28:35.327675Z",
     "shell.execute_reply": "2025-06-24T21:28:35.327036Z",
     "shell.execute_reply.started": "2025-06-24T21:28:35.307623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, train_data, seq_train_data,\n",
    "             test_batch_size, top_k,\n",
    "             viewed_items, interactions,\n",
    "             device, test_step):\n",
    "    \"\"\"\n",
    "    Оцениваем модель по всем пользователям:\n",
    "    - строим топ-K рекомендации\n",
    "    - фильтруем уже просмотренные\n",
    "    - считаем recall@K, precision@K, map@K\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    seq_ids, event_type, seq_times, seq_mask = seq_train_data\n",
    "    num_users = seq_ids.size(0)\n",
    "    test_top_k = top_k * 150\n",
    "\n",
    "    item_emb = model.gnn.item_emb.weight\n",
    "    num_items = item_emb.shape[0]\n",
    "    item_emb_t = item_emb.t().detach()\n",
    "    del item_emb\n",
    "    gc.collect()\n",
    "\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_users, test_batch_size):\n",
    "            end = min(i + test_batch_size, num_users)\n",
    "            batch_users = torch.arange(i, end).to(device)\n",
    "            s_ids   = seq_ids[i:end].to(device)\n",
    "            s_times = seq_times[i:end].to(device)\n",
    "            s_mask  = seq_mask[i:end].to(device)\n",
    "            user_e = model(\n",
    "                data=train_data.to(device),\n",
    "                seq_ids=s_ids,\n",
    "                seq_times=s_times,\n",
    "                seq_mask=s_mask,\n",
    "                batch_users=batch_users\n",
    "            )\n",
    "            rating = torch.mm(user_e.detach(), item_emb_t)\n",
    "            _, topk = torch.topk(rating, k=test_top_k, dim=1)\n",
    "            all_scores.append(topk)\n",
    "\n",
    "            del user_e, rating\n",
    "            gc.collect()\n",
    "    all_scores = torch.cat(all_scores, dim=0).cpu().numpy()\n",
    "\n",
    "    users_list, items, ranks = [], [], []\n",
    "    for u in range(num_users):\n",
    "        seen = viewed_items.get(u, set())\n",
    "        recs = all_scores[u]\n",
    "        mask = (\n",
    "            (~np.isin(recs, list(seen)))   \n",
    "            & (recs != 0)                  \n",
    "            & (recs != num_items - 1)     \n",
    "            )\n",
    "        filtered = recs[mask][:top_k]\n",
    "        for rank, it in enumerate(filtered, 1):\n",
    "            users_list.append(u)\n",
    "            items.append(int(it))\n",
    "            ranks.append(rank)\n",
    "    reco_df = pd.DataFrame({\n",
    "        'user_id': users_list,\n",
    "        'item_id': items,\n",
    "        'rank': ranks\n",
    "    })\n",
    "\n",
    "    metrics = {\n",
    "        f'map@{top_k}': MAP(k=top_k),\n",
    "        f'precision@{top_k}': Precision(k=top_k),\n",
    "        f'recall@{top_k}': Recall(k=top_k),\n",
    "        f'ndcg@{top_k}': NDCG(k=top_k)\n",
    "    }\n",
    "    results = calc_metrics(metrics=metrics,\n",
    "                           reco=reco_df,\n",
    "                           interactions=interactions)\n",
    "    print(f\"Step {test_step} — Test metrics:\")\n",
    "    for name, val in results.items():\n",
    "        print(f\"  {name}: {val:.9f}\")\n",
    "        experiment.log_metric(f\"Test {name} vs step\", val, step=test_step)\n",
    "    del all_scores\n",
    "    gc.collect()\n",
    "\n",
    "    model.to(device)\n",
    "    train_data.to(device)\n",
    "    model.train()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:35.328735Z",
     "iopub.status.busy": "2025-06-24T21:28:35.328505Z",
     "iopub.status.idle": "2025-06-24T21:28:35.362236Z",
     "shell.execute_reply": "2025-06-24T21:28:35.361350Z",
     "shell.execute_reply.started": "2025-06-24T21:28:35.328714Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model: HeteroGNN,\n",
    "                train_data: HeteroData,\n",
    "                seq_train_data: tuple,\n",
    "                edge_type: tuple,\n",
    "                num_epochs: int = 10,\n",
    "                lr: float = 1e-3,\n",
    "                batch_size: int = 1024,\n",
    "                device: str = None,\n",
    "                print_every: int = 100,\n",
    "                test_every: int = 500,\n",
    "                top_k: int = 10,\n",
    "                test_batch_size=2048,\n",
    "                scheduler_step_size: int = 1,\n",
    "                scheduler_gamma: float = 0.9) -> Model:\n",
    "    seq_ids, event_type, seq_times, seq_mask = seq_train_data\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    train_data = train_data.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma)\n",
    "\n",
    "    if isinstance(edge_type, list):\n",
    "        src_list, dst_list = [], []\n",
    "        for et in edge_type:\n",
    "            s, d = train_data[et].edge_index\n",
    "            src_list.append(s)\n",
    "            dst_list.append(d)\n",
    "        src = torch.cat(src_list, dim=0)\n",
    "        dst = torch.cat(dst_list, dim=0)\n",
    "    else:\n",
    "        src, dst = train_data[edge_type].edge_index\n",
    "    \n",
    "    num_train = src.size(0)\n",
    "    test_top_k = top_k * 150\n",
    "    total_steps = 0\n",
    "    \n",
    "    print(f\"Num of training examples: {num_train}\")\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        perm = torch.randperm(num_train, device=device)\n",
    "        total_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        running_steps = 0\n",
    "        step = 0\n",
    "\n",
    "        for i in range(0, num_train, batch_size):\n",
    "            idx = perm[i:i + batch_size]\n",
    "            users = dst[idx]\n",
    "            cpu_users = users.to('cpu')\n",
    "\n",
    "            seq_ids_batch = seq_ids[cpu_users].to(device)\n",
    "            seq_times_batch = seq_times[cpu_users].to(device)\n",
    "            seq_mask_batch = seq_mask[cpu_users].to(device)\n",
    "            \n",
    "            pos_items = src[idx]\n",
    "            neg_items = torch.randint(1, model.gnn.item_emb.num_embeddings - 1,\n",
    "                                      size=pos_items.size(), device=device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            user_embs = model(data=train_data, \n",
    "                              seq_ids=seq_ids_batch,\n",
    "                              seq_times=seq_times_batch,\n",
    "                              seq_mask=seq_mask_batch,\n",
    "                              batch_users=users)\n",
    "            \n",
    "            pos_emb = model.gnn.item_emb(pos_items)\n",
    "            neg_emb = model.gnn.item_emb(neg_items)\n",
    "            pos_score = (user_embs * pos_emb).sum(dim=1)\n",
    "            neg_score = (user_embs * neg_emb).sum(dim=1)\n",
    "            diff = pos_score - neg_score\n",
    "            diff = torch.clamp(diff, -10.0, 10.0)\n",
    "            loss = -torch.log(torch.sigmoid(diff) + 1e-15).mean()\n",
    "            \n",
    "            nan_mask = torch.isnan(diff)            \n",
    "            if nan_mask.any():\n",
    "                idxs = torch.nonzero(nan_mask).squeeze()\n",
    "                print(f\"!!! FOUND {nan_mask.sum().item()} NaN(s) in diff at positions: {idxs.tolist()}\")\n",
    "\n",
    "            # with torch.autograd.detect_anomaly():\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            running_loss += loss.item()\n",
    "            running_steps += 1\n",
    "            step += 1\n",
    "\n",
    "            experiment.log_metric('Train Loss vs step', loss.item(), step=total_steps)\n",
    "            \n",
    "            if step % print_every == 0 or step == 1:\n",
    "                avg_loss = running_loss / running_steps\n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                d = diff.detach().cpu()\n",
    "                print(f\"Epoch {epoch}, Step {step}, LR: {current_lr:.6f}, Current Loss: {loss.item():.4f}, Avg Loss: {avg_loss:.4f}\")\n",
    "                print(f\"Diff stats — min: {d.min():.4f}, max: {d.max():.4f}, mean: {d.mean():.4f}, std: {d.std():.4f}\")\n",
    "                print()\n",
    "\n",
    "                experiment.log_metric('Diff stats (mean) vs step', d.mean(), step=total_steps)\n",
    "                experiment.log_metric('Diff stats (std) vs step', d.std(), step=total_steps)\n",
    "\n",
    "            del user_embs, pos_emb, neg_emb, pos_score, neg_score,\\\n",
    "            seq_ids_batch, seq_times_batch, seq_mask_batch\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            scheduler.step()\n",
    "            \n",
    "            if step % test_every == 0 or step == 1:\n",
    "                evaluate(model, train_data, seq_train_data,\n",
    "                         test_batch_size, top_k,\n",
    "                         viewed_items, interactions,\n",
    "                         device, test_step=total_steps)\n",
    "            total_steps += 1\n",
    "        epoch_loss = total_loss / num_train\n",
    "        experiment.log_metric(f'Train Loss vs epoch', epoch_loss, epoch=epoch)\n",
    "        print(f\"Epoch {epoch} completed, Train Loss: {epoch_loss:.6f}\")\n",
    "        print()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:35.363341Z",
     "iopub.status.busy": "2025-06-24T21:28:35.363121Z",
     "iopub.status.idle": "2025-06-24T21:28:35.570680Z",
     "shell.execute_reply": "2025-06-24T21:28:35.570138Z",
     "shell.execute_reply.started": "2025-06-24T21:28:35.363325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "experiment.log_parameters(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:35.571708Z",
     "iopub.status.busy": "2025-06-24T21:28:35.571502Z",
     "iopub.status.idle": "2025-06-24T21:28:35.575457Z",
     "shell.execute_reply": "2025-06-24T21:28:35.574834Z",
     "shell.execute_reply.started": "2025-06-24T21:28:35.571692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-24T21:28:35.576516Z",
     "iopub.status.busy": "2025-06-24T21:28:35.576278Z",
     "iopub.status.idle": "2025-06-24T22:25:33.685458Z",
     "shell.execute_reply": "2025-06-24T22:25:33.684230Z",
     "shell.execute_reply.started": "2025-06-24T21:28:35.576495Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training examples: 539789\n",
      "Epoch 1, Step 1, LR: 0.001000, Current Loss: 4.0300, Avg Loss: 4.0300\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: -0.5097, std: 8.1334\n",
      "\n",
      "Step 0 — Test metrics:\n",
      "  precision@10: 0.002384106\n",
      "  recall@10: 0.002384106\n",
      "  ndcg@10: 0.002278277\n",
      "  map@10: 0.000642272\n",
      "Epoch 1, Step 20, LR: 0.001000, Current Loss: 2.9217, Avg Loss: 3.3952\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 0.3558, std: 6.9580\n",
      "\n",
      "Epoch 1, Step 40, LR: 0.001000, Current Loss: 1.9259, Avg Loss: 2.8416\n",
      "Diff stats — min: -10.0000, max: 10.0000, mean: 0.1710, std: 4.6401\n",
      "\n",
      "Step 49 — Test metrics:\n",
      "  precision@10: 0.003509934\n",
      "  recall@10: 0.003509934\n",
      "  ndcg@10: 0.003374285\n",
      "  map@10: 0.000957197\n",
      "Epoch 1, Step 60, LR: 0.001000, Current Loss: 1.2642, Avg Loss: 2.3905\n",
      "Diff stats — min: -10.0000, max: 9.9359, mean: 0.2089, std: 2.9234\n",
      "\n",
      "Epoch 1, Step 80, LR: 0.001000, Current Loss: 1.0481, Avg Loss: 2.0793\n",
      "Diff stats — min: -8.8854, max: 10.0000, mean: 0.2576, std: 2.3520\n",
      "\n",
      "Epoch 1, Step 100, LR: 0.001000, Current Loss: 0.9382, Avg Loss: 1.8604\n",
      "Diff stats — min: -6.9914, max: 7.5140, mean: 0.2084, std: 1.9102\n",
      "\n",
      "Step 99 — Test metrics:\n",
      "  precision@10: 0.004056291\n",
      "  recall@10: 0.004056291\n",
      "  ndcg@10: 0.004066700\n",
      "  map@10: 0.001207157\n",
      "Epoch 1, Step 120, LR: 0.001000, Current Loss: 0.8978, Avg Loss: 1.7004\n",
      "Diff stats — min: -5.8746, max: 7.0597, mean: 0.2099, std: 1.7741\n",
      "\n",
      "Epoch 1 completed, Train Loss: 0.000397\n",
      "\n",
      "Epoch 2, Step 1, LR: 0.001000, Current Loss: 0.8178, Avg Loss: 0.8178\n",
      "Diff stats — min: -5.9809, max: 6.8374, mean: 0.2935, std: 1.6222\n",
      "\n",
      "Step 132 — Test metrics:\n",
      "  precision@10: 0.004536424\n",
      "  recall@10: 0.004536424\n",
      "  ndcg@10: 0.004611328\n",
      "  map@10: 0.001382253\n",
      "Epoch 2, Step 20, LR: 0.000980, Current Loss: 0.7975, Avg Loss: 0.8011\n",
      "Diff stats — min: -6.0808, max: 6.1750, mean: 0.2832, std: 1.5298\n",
      "\n",
      "Epoch 2, Step 40, LR: 0.000980, Current Loss: 0.7388, Avg Loss: 0.7853\n",
      "Diff stats — min: -5.0442, max: 6.5088, mean: 0.3457, std: 1.4132\n",
      "\n",
      "Step 181 — Test metrics:\n",
      "  precision@10: 0.005612583\n",
      "  recall@10: 0.005612583\n",
      "  ndcg@10: 0.005627602\n",
      "  map@10: 0.001665786\n",
      "Epoch 2, Step 60, LR: 0.000980, Current Loss: 0.7117, Avg Loss: 0.7701\n",
      "Diff stats — min: -5.1158, max: 6.4736, mean: 0.4252, std: 1.4370\n",
      "\n",
      "Epoch 2, Step 80, LR: 0.000980, Current Loss: 0.7058, Avg Loss: 0.7564\n",
      "Diff stats — min: -5.1445, max: 5.6687, mean: 0.3897, std: 1.3551\n",
      "\n",
      "Epoch 2, Step 100, LR: 0.000980, Current Loss: 0.6843, Avg Loss: 0.7432\n",
      "Diff stats — min: -3.9711, max: 4.7349, mean: 0.4293, std: 1.3321\n",
      "\n",
      "Step 231 — Test metrics:\n",
      "  precision@10: 0.006970199\n",
      "  recall@10: 0.006970199\n",
      "  ndcg@10: 0.006849455\n",
      "  map@10: 0.002006912\n",
      "Epoch 2, Step 120, LR: 0.000980, Current Loss: 0.6605, Avg Loss: 0.7310\n",
      "Diff stats — min: -4.5506, max: 6.0278, mean: 0.4917, std: 1.3431\n",
      "\n",
      "Epoch 2 completed, Train Loss: 0.000177\n",
      "\n",
      "Epoch 3, Step 1, LR: 0.000980, Current Loss: 0.6400, Avg Loss: 0.6400\n",
      "Diff stats — min: -4.9795, max: 4.9844, mean: 0.5311, std: 1.3237\n",
      "\n",
      "Step 264 — Test metrics:\n",
      "  precision@10: 0.008327815\n",
      "  recall@10: 0.008327815\n",
      "  ndcg@10: 0.008243197\n",
      "  map@10: 0.002448689\n",
      "Epoch 3, Step 20, LR: 0.000980, Current Loss: 0.6267, Avg Loss: 0.6344\n",
      "Diff stats — min: -3.8137, max: 5.4392, mean: 0.5718, std: 1.3361\n",
      "\n",
      "Epoch 3, Step 40, LR: 0.000960, Current Loss: 0.6164, Avg Loss: 0.6255\n",
      "Diff stats — min: -4.5258, max: 5.9701, mean: 0.6211, std: 1.3709\n",
      "\n",
      "Step 313 — Test metrics:\n",
      "  precision@10: 0.010794702\n",
      "  recall@10: 0.010794702\n",
      "  ndcg@10: 0.010299192\n",
      "  map@10: 0.003019782\n",
      "Epoch 3, Step 60, LR: 0.000960, Current Loss: 0.5980, Avg Loss: 0.6172\n",
      "Diff stats — min: -4.8695, max: 5.9640, mean: 0.6944, std: 1.4101\n",
      "\n",
      "Epoch 3, Step 80, LR: 0.000960, Current Loss: 0.5801, Avg Loss: 0.6087\n",
      "Diff stats — min: -4.0064, max: 5.8921, mean: 0.7773, std: 1.4620\n",
      "\n",
      "Epoch 3, Step 100, LR: 0.000960, Current Loss: 0.5511, Avg Loss: 0.5994\n",
      "Diff stats — min: -4.4620, max: 6.3548, mean: 0.8768, std: 1.4898\n",
      "\n",
      "Step 363 — Test metrics:\n",
      "  precision@10: 0.013791391\n",
      "  recall@10: 0.013791391\n",
      "  ndcg@10: 0.013328551\n",
      "  map@10: 0.004006774\n",
      "Epoch 3, Step 120, LR: 0.000960, Current Loss: 0.5497, Avg Loss: 0.5905\n",
      "Diff stats — min: -5.0475, max: 5.9411, mean: 0.9168, std: 1.5342\n",
      "\n",
      "Epoch 3 completed, Train Loss: 0.000143\n",
      "\n",
      "Epoch 4, Step 1, LR: 0.000960, Current Loss: 0.5104, Avg Loss: 0.5104\n",
      "Diff stats — min: -4.8126, max: 6.2311, mean: 1.0302, std: 1.5267\n",
      "\n",
      "Step 396 — Test metrics:\n",
      "  precision@10: 0.015165563\n",
      "  recall@10: 0.015165563\n",
      "  ndcg@10: 0.014469202\n",
      "  map@10: 0.004329418\n",
      "Epoch 4, Step 20, LR: 0.000960, Current Loss: 0.4999, Avg Loss: 0.5164\n",
      "Diff stats — min: -4.1454, max: 6.5794, mean: 1.0829, std: 1.5611\n",
      "\n",
      "Epoch 4, Step 40, LR: 0.000960, Current Loss: 0.4885, Avg Loss: 0.5086\n",
      "Diff stats — min: -4.4392, max: 7.4144, mean: 1.1672, std: 1.6219\n",
      "\n",
      "Step 445 — Test metrics:\n",
      "  precision@10: 0.018162252\n",
      "  recall@10: 0.018164091\n",
      "  ndcg@10: 0.017641673\n",
      "  map@10: 0.005451376\n",
      "Epoch 4, Step 60, LR: 0.000941, Current Loss: 0.4775, Avg Loss: 0.5009\n",
      "Diff stats — min: -5.2540, max: 6.8086, mean: 1.2499, std: 1.6709\n",
      "\n",
      "Epoch 4, Step 80, LR: 0.000941, Current Loss: 0.4613, Avg Loss: 0.4936\n",
      "Diff stats — min: -5.1735, max: 7.3877, mean: 1.3266, std: 1.7003\n",
      "\n",
      "Epoch 4, Step 100, LR: 0.000941, Current Loss: 0.4717, Avg Loss: 0.4864\n",
      "Diff stats — min: -5.5867, max: 7.7190, mean: 1.3580, std: 1.7824\n",
      "\n",
      "Step 495 — Test metrics:\n",
      "  precision@10: 0.020778146\n",
      "  recall@10: 0.020778146\n",
      "  ndcg@10: 0.019397782\n",
      "  map@10: 0.005838714\n",
      "Epoch 4, Step 120, LR: 0.000941, Current Loss: 0.4334, Avg Loss: 0.4793\n",
      "Diff stats — min: -4.9356, max: 7.9761, mean: 1.4950, std: 1.7872\n",
      "\n",
      "Epoch 4 completed, Train Loss: 0.000116\n",
      "\n",
      "Epoch 5, Step 1, LR: 0.000941, Current Loss: 0.4327, Avg Loss: 0.4327\n",
      "Diff stats — min: -5.5203, max: 8.6894, mean: 1.5532, std: 1.8461\n",
      "\n",
      "Step 528 — Test metrics:\n",
      "  precision@10: 0.022417219\n",
      "  recall@10: 0.022417219\n",
      "  ndcg@10: 0.021934044\n",
      "  map@10: 0.006985953\n",
      "Epoch 5, Step 20, LR: 0.000941, Current Loss: 0.4220, Avg Loss: 0.4205\n",
      "Diff stats — min: -4.9610, max: 7.7122, mean: 1.6181, std: 1.8770\n",
      "\n",
      "Epoch 5, Step 40, LR: 0.000941, Current Loss: 0.4144, Avg Loss: 0.4180\n",
      "Diff stats — min: -5.9549, max: 7.7780, mean: 1.6793, std: 1.8906\n",
      "\n",
      "Step 577 — Test metrics:\n",
      "  precision@10: 0.025066225\n",
      "  recall@10: 0.025066225\n",
      "  ndcg@10: 0.025190162\n",
      "  map@10: 0.008269230\n",
      "Epoch 5, Step 60, LR: 0.000941, Current Loss: 0.4155, Avg Loss: 0.4135\n",
      "Diff stats — min: -5.3010, max: 8.3269, mean: 1.6802, std: 1.9032\n",
      "\n",
      "Epoch 5, Step 80, LR: 0.000922, Current Loss: 0.3990, Avg Loss: 0.4089\n",
      "Diff stats — min: -5.0901, max: 8.9191, mean: 1.7491, std: 1.9197\n",
      "\n",
      "Epoch 5, Step 100, LR: 0.000922, Current Loss: 0.3840, Avg Loss: 0.4047\n",
      "Diff stats — min: -4.4587, max: 7.8669, mean: 1.8700, std: 1.9550\n",
      "\n",
      "Step 627 — Test metrics:\n",
      "  precision@10: 0.026953642\n",
      "  recall@10: 0.026955482\n",
      "  ndcg@10: 0.027474771\n",
      "  map@10: 0.009262739\n",
      "Epoch 5, Step 120, LR: 0.000922, Current Loss: 0.3817, Avg Loss: 0.4006\n",
      "Diff stats — min: -5.4094, max: 7.9393, mean: 1.8946, std: 1.9729\n",
      "\n",
      "Epoch 5 completed, Train Loss: 0.000097\n",
      "\n",
      "Epoch 6, Step 1, LR: 0.000922, Current Loss: 0.3591, Avg Loss: 0.3591\n",
      "Diff stats — min: -5.2217, max: 8.0461, mean: 1.9786, std: 1.9590\n",
      "\n",
      "Step 660 — Test metrics:\n",
      "  precision@10: 0.028807947\n",
      "  recall@10: 0.028809787\n",
      "  ndcg@10: 0.029536427\n",
      "  map@10: 0.010216894\n",
      "Epoch 6, Step 20, LR: 0.000922, Current Loss: 0.3456, Avg Loss: 0.3681\n",
      "Diff stats — min: -5.4474, max: 8.0235, mean: 2.0242, std: 1.9513\n",
      "\n",
      "Epoch 6, Step 40, LR: 0.000922, Current Loss: 0.3730, Avg Loss: 0.3648\n",
      "Diff stats — min: -7.0468, max: 8.9112, mean: 2.0074, std: 2.0497\n",
      "\n",
      "Step 709 — Test metrics:\n",
      "  precision@10: 0.031274834\n",
      "  recall@10: 0.031276674\n",
      "  ndcg@10: 0.032182163\n",
      "  map@10: 0.011324149\n",
      "Epoch 6, Step 60, LR: 0.000922, Current Loss: 0.3608, Avg Loss: 0.3631\n",
      "Diff stats — min: -6.8645, max: 8.7825, mean: 2.0332, std: 2.0262\n",
      "\n",
      "Epoch 6, Step 80, LR: 0.000922, Current Loss: 0.3602, Avg Loss: 0.3609\n",
      "Diff stats — min: -6.4465, max: 8.4057, mean: 2.0815, std: 2.0585\n",
      "\n",
      "Epoch 6, Step 100, LR: 0.000904, Current Loss: 0.3454, Avg Loss: 0.3590\n",
      "Diff stats — min: -4.9160, max: 8.7778, mean: 2.1191, std: 2.0457\n",
      "\n",
      "Step 759 — Test metrics:\n",
      "  precision@10: 0.033807947\n",
      "  recall@10: 0.033807947\n",
      "  ndcg@10: 0.035554473\n",
      "  map@10: 0.012995046\n",
      "Epoch 6, Step 120, LR: 0.000904, Current Loss: 0.3452, Avg Loss: 0.3573\n",
      "Diff stats — min: -4.7586, max: 8.6497, mean: 2.1343, std: 2.0535\n",
      "\n",
      "Epoch 6 completed, Train Loss: 0.000087\n",
      "\n",
      "Epoch 7, Step 1, LR: 0.000904, Current Loss: 0.3369, Avg Loss: 0.3369\n",
      "Diff stats — min: -4.8408, max: 8.6546, mean: 2.1681, std: 2.0413\n",
      "\n",
      "Step 792 — Test metrics:\n",
      "  precision@10: 0.034105960\n",
      "  recall@10: 0.034107800\n",
      "  ndcg@10: 0.035628380\n",
      "  map@10: 0.012883239\n",
      "Epoch 7, Step 20, LR: 0.000904, Current Loss: 0.3286, Avg Loss: 0.3444\n",
      "Diff stats — min: -5.4519, max: 9.6495, mean: 2.2423, std: 2.0826\n",
      "\n",
      "Epoch 7, Step 40, LR: 0.000904, Current Loss: 0.3341, Avg Loss: 0.3435\n",
      "Diff stats — min: -5.6076, max: 8.0117, mean: 2.1942, std: 2.0481\n",
      "\n",
      "Step 841 — Test metrics:\n",
      "  precision@10: 0.034884106\n",
      "  recall@10: 0.034884106\n",
      "  ndcg@10: 0.037201409\n",
      "  map@10: 0.013771359\n",
      "Epoch 7, Step 60, LR: 0.000904, Current Loss: 0.3517, Avg Loss: 0.3426\n",
      "Diff stats — min: -6.4396, max: 9.4351, mean: 2.1631, std: 2.1056\n",
      "\n",
      "Epoch 7, Step 80, LR: 0.000904, Current Loss: 0.3371, Avg Loss: 0.3413\n",
      "Diff stats — min: -5.6866, max: 8.7020, mean: 2.2159, std: 2.0862\n",
      "\n",
      "Epoch 7, Step 100, LR: 0.000904, Current Loss: 0.3335, Avg Loss: 0.3401\n",
      "Diff stats — min: -5.3728, max: 9.2371, mean: 2.2219, std: 2.0906\n",
      "\n",
      "Step 891 — Test metrics:\n",
      "  precision@10: 0.035397351\n",
      "  recall@10: 0.035397351\n",
      "  ndcg@10: 0.037356281\n",
      "  map@10: 0.013630243\n",
      "Epoch 7, Step 120, LR: 0.000886, Current Loss: 0.3272, Avg Loss: 0.3393\n",
      "Diff stats — min: -4.8081, max: 8.4106, mean: 2.2713, std: 2.0879\n",
      "\n",
      "Epoch 7 completed, Train Loss: 0.000083\n",
      "\n",
      "Epoch 8, Step 1, LR: 0.000886, Current Loss: 0.3187, Avg Loss: 0.3187\n",
      "Diff stats — min: -5.8954, max: 8.4738, mean: 2.2836, std: 2.0777\n",
      "\n",
      "Step 924 — Test metrics:\n",
      "  precision@10: 0.037599338\n",
      "  recall@10: 0.037599338\n",
      "  ndcg@10: 0.039827080\n",
      "  map@10: 0.014571980\n",
      "Epoch 8, Step 20, LR: 0.000886, Current Loss: 0.3334, Avg Loss: 0.3325\n",
      "Diff stats — min: -5.1323, max: 9.7099, mean: 2.2522, std: 2.1094\n",
      "\n",
      "Epoch 8, Step 40, LR: 0.000886, Current Loss: 0.3201, Avg Loss: 0.3318\n",
      "Diff stats — min: -5.5743, max: 8.0646, mean: 2.2924, std: 2.0850\n",
      "\n",
      "Step 973 — Test metrics:\n",
      "  precision@10: 0.037930464\n",
      "  recall@10: 0.037930464\n",
      "  ndcg@10: 0.040332764\n",
      "  map@10: 0.014835810\n",
      "Epoch 8, Step 60, LR: 0.000886, Current Loss: 0.3304, Avg Loss: 0.3321\n",
      "Diff stats — min: -4.9978, max: 8.6923, mean: 2.2891, std: 2.1208\n",
      "\n",
      "Epoch 8, Step 80, LR: 0.000886, Current Loss: 0.3303, Avg Loss: 0.3298\n",
      "Diff stats — min: -5.3270, max: 8.6578, mean: 2.2970, std: 2.1322\n",
      "\n",
      "Epoch 8, Step 100, LR: 0.000886, Current Loss: 0.3370, Avg Loss: 0.3302\n",
      "Diff stats — min: -5.0809, max: 9.4484, mean: 2.2965, std: 2.1626\n",
      "\n",
      "Step 1023 — Test metrics:\n",
      "  precision@10: 0.037284768\n",
      "  recall@10: 0.037284768\n",
      "  ndcg@10: 0.038711176\n",
      "  map@10: 0.014010341\n",
      "Epoch 8, Step 120, LR: 0.000886, Current Loss: 0.3485, Avg Loss: 0.3304\n",
      "Diff stats — min: -6.2398, max: 9.3805, mean: 2.2288, std: 2.1465\n",
      "\n",
      "Epoch 8 completed, Train Loss: 0.000081\n",
      "\n",
      "Epoch 9, Step 1, LR: 0.000868, Current Loss: 0.3263, Avg Loss: 0.3263\n",
      "Diff stats — min: -6.1635, max: 9.2991, mean: 2.2868, std: 2.1075\n",
      "\n",
      "Step 1056 — Test metrics:\n",
      "  precision@10: 0.037897351\n",
      "  recall@10: 0.037897351\n",
      "  ndcg@10: 0.040412065\n",
      "  map@10: 0.014802402\n",
      "Epoch 9, Step 20, LR: 0.000868, Current Loss: 0.3115, Avg Loss: 0.3237\n",
      "Diff stats — min: -5.7746, max: 9.2064, mean: 2.3923, std: 2.1448\n",
      "\n",
      "Epoch 9, Step 40, LR: 0.000868, Current Loss: 0.3386, Avg Loss: 0.3271\n",
      "Diff stats — min: -5.2195, max: 9.4690, mean: 2.2854, std: 2.1607\n",
      "\n",
      "Step 1105 — Test metrics:\n",
      "  precision@10: 0.036870861\n",
      "  recall@10: 0.036872701\n",
      "  ndcg@10: 0.038930303\n",
      "  map@10: 0.014171365\n",
      "Epoch 9, Step 60, LR: 0.000868, Current Loss: 0.3423, Avg Loss: 0.3271\n",
      "Diff stats — min: -5.9925, max: 9.0564, mean: 2.2831, std: 2.1649\n",
      "\n",
      "Epoch 9, Step 80, LR: 0.000868, Current Loss: 0.3289, Avg Loss: 0.3268\n",
      "Diff stats — min: -4.7922, max: 10.0000, mean: 2.3067, std: 2.1525\n",
      "\n",
      "Epoch 9, Step 100, LR: 0.000868, Current Loss: 0.3360, Avg Loss: 0.3265\n",
      "Diff stats — min: -6.2723, max: 8.9828, mean: 2.3380, std: 2.2006\n",
      "\n",
      "Step 1155 — Test metrics:\n",
      "  precision@10: 0.038824503\n",
      "  recall@10: 0.038826343\n",
      "  ndcg@10: 0.040565359\n",
      "  map@10: 0.014744443\n",
      "Epoch 9, Step 120, LR: 0.000868, Current Loss: 0.3185, Avg Loss: 0.3263\n",
      "Diff stats — min: -5.1990, max: 8.7465, mean: 2.3717, std: 2.1595\n",
      "\n",
      "Epoch 9 completed, Train Loss: 0.000080\n",
      "\n",
      "Epoch 10, Step 1, LR: 0.000868, Current Loss: 0.3178, Avg Loss: 0.3178\n",
      "Diff stats — min: -5.1956, max: 9.4233, mean: 2.3699, std: 2.1570\n",
      "\n",
      "Step 1188 — Test metrics:\n",
      "  precision@10: 0.037649007\n",
      "  recall@10: 0.037650846\n",
      "  ndcg@10: 0.039344840\n",
      "  map@10: 0.014388744\n",
      "Epoch 10, Step 20, LR: 0.000851, Current Loss: 0.3125, Avg Loss: 0.3222\n",
      "Diff stats — min: -5.2879, max: 9.4915, mean: 2.3807, std: 2.1538\n",
      "\n",
      "Epoch 10, Step 40, LR: 0.000851, Current Loss: 0.3141, Avg Loss: 0.3236\n",
      "Diff stats — min: -4.6678, max: 10.0000, mean: 2.3618, std: 2.1311\n",
      "\n",
      "Step 1237 — Test metrics:\n",
      "  precision@10: 0.038443709\n",
      "  recall@10: 0.038443709\n",
      "  ndcg@10: 0.040564412\n",
      "  map@10: 0.014848326\n",
      "Epoch 10, Step 60, LR: 0.000851, Current Loss: 0.3150, Avg Loss: 0.3221\n",
      "Diff stats — min: -5.9782, max: 8.6533, mean: 2.3856, std: 2.1695\n",
      "\n",
      "Epoch 10, Step 80, LR: 0.000851, Current Loss: 0.3171, Avg Loss: 0.3225\n",
      "Diff stats — min: -4.6467, max: 9.0415, mean: 2.4108, std: 2.2065\n",
      "\n",
      "Epoch 10, Step 100, LR: 0.000851, Current Loss: 0.3135, Avg Loss: 0.3220\n",
      "Diff stats — min: -5.4098, max: 9.4557, mean: 2.4034, std: 2.1853\n",
      "\n",
      "Step 1287 — Test metrics:\n",
      "  precision@10: 0.039122517\n",
      "  recall@10: 0.039124356\n",
      "  ndcg@10: 0.041659393\n",
      "  map@10: 0.015502438\n",
      "Epoch 10, Step 120, LR: 0.000851, Current Loss: 0.3150, Avg Loss: 0.3220\n",
      "Diff stats — min: -5.6030, max: 8.8801, mean: 2.3847, std: 2.1728\n",
      "\n",
      "Epoch 10 completed, Train Loss: 0.000079\n",
      "\n",
      "Epoch 11, Step 1, LR: 0.000851, Current Loss: 0.3222, Avg Loss: 0.3222\n",
      "Diff stats — min: -6.2988, max: 9.2502, mean: 2.3715, std: 2.1928\n",
      "\n",
      "Step 1320 — Test metrics:\n",
      "  precision@10: 0.039321192\n",
      "  recall@10: 0.039321192\n",
      "  ndcg@10: 0.041778652\n",
      "  map@10: 0.015528941\n",
      "Epoch 11, Step 20, LR: 0.000851, Current Loss: 0.3073, Avg Loss: 0.3174\n",
      "Diff stats — min: -5.5716, max: 9.4532, mean: 2.4362, std: 2.1801\n",
      "\n",
      "Epoch 11, Step 40, LR: 0.000834, Current Loss: 0.3122, Avg Loss: 0.3188\n",
      "Diff stats — min: -6.2805, max: 9.0520, mean: 2.4172, std: 2.1938\n",
      "\n",
      "Step 1369 — Test metrics:\n",
      "  precision@10: 0.037466887\n",
      "  recall@10: 0.037468727\n",
      "  ndcg@10: 0.040005184\n",
      "  map@10: 0.014946015\n",
      "Epoch 11, Step 60, LR: 0.000834, Current Loss: 0.3091, Avg Loss: 0.3195\n",
      "Diff stats — min: -5.9600, max: 9.4183, mean: 2.4146, std: 2.1744\n",
      "\n",
      "Epoch 11, Step 80, LR: 0.000834, Current Loss: 0.3266, Avg Loss: 0.3195\n",
      "Diff stats — min: -5.2752, max: 9.6702, mean: 2.3285, std: 2.1849\n",
      "\n",
      "Epoch 11, Step 100, LR: 0.000834, Current Loss: 0.3173, Avg Loss: 0.3194\n",
      "Diff stats — min: -5.2235, max: 10.0000, mean: 2.4644, std: 2.2548\n",
      "\n",
      "Step 1419 — Test metrics:\n",
      "  precision@10: 0.038625828\n",
      "  recall@10: 0.038625828\n",
      "  ndcg@10: 0.040999216\n",
      "  map@10: 0.015089660\n",
      "Epoch 11, Step 120, LR: 0.000834, Current Loss: 0.3214, Avg Loss: 0.3193\n",
      "Diff stats — min: -4.9885, max: 9.3196, mean: 2.4143, std: 2.2370\n",
      "\n",
      "Epoch 11 completed, Train Loss: 0.000078\n",
      "\n",
      "Epoch 12, Step 1, LR: 0.000834, Current Loss: 0.3196, Avg Loss: 0.3196\n",
      "Diff stats — min: -6.3106, max: 8.9078, mean: 2.4238, std: 2.2436\n",
      "\n",
      "Step 1452 — Test metrics:\n",
      "  precision@10: 0.038956954\n",
      "  recall@10: 0.038958793\n",
      "  ndcg@10: 0.041574449\n",
      "  map@10: 0.015329819\n",
      "Epoch 12, Step 20, LR: 0.000834, Current Loss: 0.3190, Avg Loss: 0.3166\n",
      "Diff stats — min: -5.1869, max: 10.0000, mean: 2.4509, std: 2.2525\n",
      "\n",
      "Epoch 12, Step 40, LR: 0.000834, Current Loss: 0.3235, Avg Loss: 0.3166\n",
      "Diff stats — min: -4.6596, max: 9.8004, mean: 2.4654, std: 2.2760\n",
      "\n",
      "Step 1501 — Test metrics:\n",
      "  precision@10: 0.038625828\n",
      "  recall@10: 0.038627667\n",
      "  ndcg@10: 0.040718470\n",
      "  map@10: 0.014949451\n",
      "Epoch 12, Step 60, LR: 0.000817, Current Loss: 0.3213, Avg Loss: 0.3181\n",
      "Diff stats — min: -5.3365, max: 9.5654, mean: 2.4057, std: 2.2330\n",
      "\n",
      "Epoch 12, Step 80, LR: 0.000817, Current Loss: 0.3136, Avg Loss: 0.3185\n",
      "Diff stats — min: -4.2968, max: 10.0000, mean: 2.4258, std: 2.2263\n",
      "\n",
      "Epoch 12, Step 100, LR: 0.000817, Current Loss: 0.3135, Avg Loss: 0.3185\n",
      "Diff stats — min: -5.1798, max: 9.2421, mean: 2.4099, std: 2.2204\n",
      "\n",
      "Step 1551 — Test metrics:\n",
      "  precision@10: 0.039205298\n",
      "  recall@10: 0.039205298\n",
      "  ndcg@10: 0.041387731\n",
      "  map@10: 0.015253896\n",
      "Epoch 12, Step 120, LR: 0.000817, Current Loss: 0.3080, Avg Loss: 0.3184\n",
      "Diff stats — min: -4.7721, max: 9.1806, mean: 2.4419, std: 2.2018\n",
      "\n",
      "Epoch 12 completed, Train Loss: 0.000078\n",
      "\n",
      "Epoch 13, Step 1, LR: 0.000817, Current Loss: 0.3088, Avg Loss: 0.3088\n",
      "Diff stats — min: -5.4866, max: 9.3105, mean: 2.4503, std: 2.2134\n",
      "\n",
      "Step 1584 — Test metrics:\n",
      "  precision@10: 0.039039735\n",
      "  recall@10: 0.039039735\n",
      "  ndcg@10: 0.040715775\n",
      "  map@10: 0.014916226\n",
      "Epoch 13, Step 20, LR: 0.000817, Current Loss: 0.3296, Avg Loss: 0.3183\n",
      "Diff stats — min: -5.6157, max: 9.5256, mean: 2.3760, std: 2.2375\n",
      "\n",
      "Epoch 13, Step 40, LR: 0.000817, Current Loss: 0.3175, Avg Loss: 0.3170\n",
      "Diff stats — min: -6.0035, max: 9.3558, mean: 2.4260, std: 2.2340\n",
      "\n",
      "Step 1633 — Test metrics:\n",
      "  precision@10: 0.038841060\n",
      "  recall@10: 0.038841060\n",
      "  ndcg@10: 0.041248282\n",
      "  map@10: 0.015266096\n",
      "Epoch 13, Step 60, LR: 0.000817, Current Loss: 0.3145, Avg Loss: 0.3156\n",
      "Diff stats — min: -5.3140, max: 10.0000, mean: 2.4930, std: 2.2907\n",
      "\n",
      "Epoch 13, Step 80, LR: 0.000801, Current Loss: 0.3073, Avg Loss: 0.3154\n",
      "Diff stats — min: -4.5367, max: 9.9012, mean: 2.5164, std: 2.2865\n",
      "\n",
      "Epoch 13, Step 100, LR: 0.000801, Current Loss: 0.3139, Avg Loss: 0.3162\n",
      "Diff stats — min: -5.3389, max: 10.0000, mean: 2.4405, std: 2.2426\n",
      "\n",
      "Step 1683 — Test metrics:\n",
      "  precision@10: 0.039122517\n",
      "  recall@10: 0.039122517\n",
      "  ndcg@10: 0.041678874\n",
      "  map@10: 0.015442638\n",
      "Epoch 13, Step 120, LR: 0.000801, Current Loss: 0.3196, Avg Loss: 0.3160\n",
      "Diff stats — min: -4.9717, max: 10.0000, mean: 2.4911, std: 2.3112\n",
      "\n",
      "Epoch 13 completed, Train Loss: 0.000077\n",
      "\n",
      "Epoch 14, Step 1, LR: 0.000801, Current Loss: 0.3044, Avg Loss: 0.3044\n",
      "Diff stats — min: -4.8188, max: 9.8433, mean: 2.5145, std: 2.2710\n",
      "\n",
      "Step 1716 — Test metrics:\n",
      "  precision@10: 0.038228477\n",
      "  recall@10: 0.038230316\n",
      "  ndcg@10: 0.040169216\n",
      "  map@10: 0.015052691\n",
      "Epoch 14, Step 20, LR: 0.000801, Current Loss: 0.3045, Avg Loss: 0.3158\n",
      "Diff stats — min: -5.4353, max: 9.9590, mean: 2.5109, std: 2.2708\n",
      "\n",
      "Epoch 14, Step 40, LR: 0.000801, Current Loss: 0.3299, Avg Loss: 0.3155\n",
      "Diff stats — min: -7.8014, max: 9.5289, mean: 2.4527, std: 2.3417\n",
      "\n",
      "Step 1765 — Test metrics:\n",
      "  precision@10: 0.038062914\n",
      "  recall@10: 0.038062914\n",
      "  ndcg@10: 0.039597080\n",
      "  map@10: 0.014519329\n",
      "Epoch 14, Step 60, LR: 0.000801, Current Loss: 0.3246, Avg Loss: 0.3163\n",
      "Diff stats — min: -4.6657, max: 10.0000, mean: 2.4051, std: 2.2691\n",
      "\n",
      "Epoch 14, Step 80, LR: 0.000801, Current Loss: 0.3129, Avg Loss: 0.3164\n",
      "Diff stats — min: -4.0136, max: 9.3380, mean: 2.4758, std: 2.2840\n",
      "\n",
      "Epoch 14, Step 100, LR: 0.000785, Current Loss: 0.3185, Avg Loss: 0.3162\n",
      "Diff stats — min: -5.6519, max: 10.0000, mean: 2.4875, std: 2.3242\n",
      "\n",
      "Step 1815 — Test metrics:\n",
      "  precision@10: 0.039172185\n",
      "  recall@10: 0.039174025\n",
      "  ndcg@10: 0.040522005\n",
      "  map@10: 0.014709713\n",
      "Epoch 14, Step 120, LR: 0.000785, Current Loss: 0.3062, Avg Loss: 0.3161\n",
      "Diff stats — min: -5.8532, max: 10.0000, mean: 2.5250, std: 2.2932\n",
      "\n",
      "Epoch 14 completed, Train Loss: 0.000077\n",
      "\n",
      "Epoch 15, Step 1, LR: 0.000785, Current Loss: 0.3210, Avg Loss: 0.3210\n",
      "Diff stats — min: -5.4313, max: 10.0000, mean: 2.5218, std: 2.3430\n",
      "\n",
      "Step 1848 — Test metrics:\n",
      "  precision@10: 0.038162252\n",
      "  recall@10: 0.038162252\n",
      "  ndcg@10: 0.039653626\n",
      "  map@10: 0.014466020\n",
      "Epoch 15, Step 20, LR: 0.000785, Current Loss: 0.3081, Avg Loss: 0.3135\n",
      "Diff stats — min: -5.0595, max: 9.3770, mean: 2.4989, std: 2.2980\n",
      "\n",
      "Epoch 15, Step 40, LR: 0.000785, Current Loss: 0.3139, Avg Loss: 0.3128\n",
      "Diff stats — min: -5.3158, max: 10.0000, mean: 2.5283, std: 2.3338\n",
      "\n",
      "Step 1897 — Test metrics:\n",
      "  precision@10: 0.038940397\n",
      "  recall@10: 0.038942237\n",
      "  ndcg@10: 0.040908431\n",
      "  map@10: 0.015068157\n",
      "Epoch 15, Step 60, LR: 0.000785, Current Loss: 0.3221, Avg Loss: 0.3140\n",
      "Diff stats — min: -5.8278, max: 10.0000, mean: 2.4432, std: 2.3047\n",
      "\n",
      "Epoch 15, Step 80, LR: 0.000785, Current Loss: 0.3253, Avg Loss: 0.3135\n",
      "Diff stats — min: -5.1488, max: 10.0000, mean: 2.4898, std: 2.3862\n",
      "\n",
      "Epoch 15, Step 100, LR: 0.000785, Current Loss: 0.3211, Avg Loss: 0.3138\n",
      "Diff stats — min: -5.1003, max: 9.8750, mean: 2.5110, std: 2.3654\n",
      "\n",
      "Step 1947 — Test metrics:\n",
      "  precision@10: 0.038923841\n",
      "  recall@10: 0.038923841\n",
      "  ndcg@10: 0.040773942\n",
      "  map@10: 0.014925917\n",
      "Epoch 15, Step 120, LR: 0.000769, Current Loss: 0.3160, Avg Loss: 0.3135\n",
      "Diff stats — min: -5.2147, max: 10.0000, mean: 2.5305, std: 2.3704\n",
      "\n",
      "Epoch 15 completed, Train Loss: 0.000077\n",
      "\n",
      "Epoch 16, Step 1, LR: 0.000769, Current Loss: 0.2934, Avg Loss: 0.2934\n",
      "Diff stats — min: -5.2672, max: 9.6099, mean: 2.5969, std: 2.3002\n",
      "\n",
      "Step 1980 — Test metrics:\n",
      "  precision@10: 0.039089404\n",
      "  recall@10: 0.039091244\n",
      "  ndcg@10: 0.041381971\n",
      "  map@10: 0.015346099\n",
      "Epoch 16, Step 20, LR: 0.000769, Current Loss: 0.3112, Avg Loss: 0.3114\n",
      "Diff stats — min: -4.5900, max: 10.0000, mean: 2.5577, std: 2.3612\n",
      "\n",
      "Epoch 16, Step 40, LR: 0.000769, Current Loss: 0.3195, Avg Loss: 0.3123\n",
      "Diff stats — min: -4.9392, max: 10.0000, mean: 2.5782, std: 2.4045\n",
      "\n",
      "Step 2029 — Test metrics:\n",
      "  precision@10: 0.039552980\n",
      "  recall@10: 0.039554820\n",
      "  ndcg@10: 0.041750530\n",
      "  map@10: 0.015549524\n",
      "Epoch 16, Step 60, LR: 0.000769, Current Loss: 0.3021, Avg Loss: 0.3122\n",
      "Diff stats — min: -4.6141, max: 10.0000, mean: 2.5832, std: 2.3673\n",
      "\n",
      "Epoch 16, Step 80, LR: 0.000769, Current Loss: 0.3325, Avg Loss: 0.3125\n",
      "Diff stats — min: -4.8481, max: 10.0000, mean: 2.4640, std: 2.3969\n",
      "\n",
      "Epoch 16, Step 100, LR: 0.000769, Current Loss: 0.3080, Avg Loss: 0.3129\n",
      "Diff stats — min: -4.3863, max: 10.0000, mean: 2.5825, std: 2.3708\n",
      "\n",
      "Step 2079 — Test metrics:\n",
      "  precision@10: 0.039304636\n",
      "  recall@10: 0.039306475\n",
      "  ndcg@10: 0.041094640\n",
      "  map@10: 0.015158194\n",
      "Epoch 16, Step 120, LR: 0.000769, Current Loss: 0.3079, Avg Loss: 0.3130\n",
      "Diff stats — min: -5.5628, max: 9.9679, mean: 2.5783, std: 2.3729\n",
      "\n",
      "Epoch 16 completed, Train Loss: 0.000077\n",
      "\n",
      "Epoch 17, Step 1, LR: 0.000754, Current Loss: 0.3092, Avg Loss: 0.3092\n",
      "Diff stats — min: -5.1967, max: 10.0000, mean: 2.5344, std: 2.3512\n",
      "\n",
      "Step 2112 — Test metrics:\n",
      "  precision@10: 0.038029801\n",
      "  recall@10: 0.038031641\n",
      "  ndcg@10: 0.040032000\n",
      "  map@10: 0.014614791\n",
      "Epoch 17, Step 20, LR: 0.000754, Current Loss: 0.3021, Avg Loss: 0.3098\n",
      "Diff stats — min: -4.3201, max: 10.0000, mean: 2.6515, std: 2.4172\n",
      "\n",
      "Epoch 17, Step 40, LR: 0.000754, Current Loss: 0.3127, Avg Loss: 0.3123\n",
      "Diff stats — min: -6.2277, max: 10.0000, mean: 2.5402, std: 2.3666\n",
      "\n",
      "Step 2161 — Test metrics:\n",
      "  precision@10: 0.038774834\n",
      "  recall@10: 0.038776674\n",
      "  ndcg@10: 0.040863060\n",
      "  map@10: 0.015029692\n",
      "Epoch 17, Step 60, LR: 0.000754, Current Loss: 0.3040, Avg Loss: 0.3121\n",
      "Diff stats — min: -5.8286, max: 10.0000, mean: 2.5840, std: 2.3569\n",
      "\n",
      "Epoch 17, Step 80, LR: 0.000754, Current Loss: 0.3043, Avg Loss: 0.3121\n",
      "Diff stats — min: -5.7371, max: 10.0000, mean: 2.5934, std: 2.3740\n",
      "\n",
      "Epoch 17, Step 100, LR: 0.000754, Current Loss: 0.3115, Avg Loss: 0.3120\n",
      "Diff stats — min: -6.1074, max: 10.0000, mean: 2.6210, std: 2.4239\n",
      "\n",
      "Step 2211 — Test metrics:\n",
      "  precision@10: 0.037781457\n",
      "  recall@10: 0.037783297\n",
      "  ndcg@10: 0.040020933\n",
      "  map@10: 0.014653860\n",
      "Epoch 17, Step 120, LR: 0.000754, Current Loss: 0.3227, Avg Loss: 0.3120\n",
      "Diff stats — min: -6.1027, max: 10.0000, mean: 2.5249, std: 2.4408\n",
      "\n",
      "Epoch 17 completed, Train Loss: 0.000076\n",
      "\n",
      "Epoch 18, Step 1, LR: 0.000754, Current Loss: 0.3026, Avg Loss: 0.3026\n",
      "Diff stats — min: -4.7870, max: 10.0000, mean: 2.6185, std: 2.4011\n",
      "\n",
      "Step 2244 — Test metrics:\n",
      "  precision@10: 0.037268212\n",
      "  recall@10: 0.037271891\n",
      "  ndcg@10: 0.038806782\n",
      "  map@10: 0.013994791\n",
      "Epoch 18, Step 20, LR: 0.000739, Current Loss: 0.3050, Avg Loss: 0.3073\n",
      "Diff stats — min: -4.4564, max: 10.0000, mean: 2.6685, std: 2.4479\n",
      "\n",
      "Epoch 18, Step 40, LR: 0.000739, Current Loss: 0.3057, Avg Loss: 0.3080\n",
      "Diff stats — min: -7.8765, max: 10.0000, mean: 2.6262, std: 2.4334\n",
      "\n",
      "Step 2293 — Test metrics:\n",
      "  precision@10: 0.038443709\n",
      "  recall@10: 0.038445548\n",
      "  ndcg@10: 0.040373046\n",
      "  map@10: 0.014763869\n",
      "Epoch 18, Step 60, LR: 0.000739, Current Loss: 0.3087, Avg Loss: 0.3085\n",
      "Diff stats — min: -6.2549, max: 10.0000, mean: 2.6099, std: 2.4115\n",
      "\n",
      "Epoch 18, Step 80, LR: 0.000739, Current Loss: 0.3110, Avg Loss: 0.3094\n",
      "Diff stats — min: -4.3140, max: 10.0000, mean: 2.5826, std: 2.4187\n",
      "\n",
      "Epoch 18, Step 100, LR: 0.000739, Current Loss: 0.3170, Avg Loss: 0.3098\n",
      "Diff stats — min: -4.5654, max: 10.0000, mean: 2.5551, std: 2.4000\n",
      "\n",
      "Step 2343 — Test metrics:\n",
      "  precision@10: 0.039105960\n",
      "  recall@10: 0.039105960\n",
      "  ndcg@10: 0.041955172\n",
      "  map@10: 0.015677008\n",
      "Epoch 18, Step 120, LR: 0.000739, Current Loss: 0.3127, Avg Loss: 0.3102\n",
      "Diff stats — min: -6.9659, max: 10.0000, mean: 2.5815, std: 2.4449\n",
      "\n",
      "Epoch 18 completed, Train Loss: 0.000076\n",
      "\n",
      "Epoch 19, Step 1, LR: 0.000739, Current Loss: 0.3018, Avg Loss: 0.3018\n",
      "Diff stats — min: -4.6071, max: 10.0000, mean: 2.6228, std: 2.4202\n",
      "\n",
      "Step 2376 — Test metrics:\n",
      "  precision@10: 0.038592715\n",
      "  recall@10: 0.038592715\n",
      "  ndcg@10: 0.040527411\n",
      "  map@10: 0.014895603\n",
      "Epoch 19, Step 20, LR: 0.000739, Current Loss: 0.3163, Avg Loss: 0.3082\n",
      "Diff stats — min: -6.2380, max: 10.0000, mean: 2.6153, std: 2.4659\n",
      "\n",
      "Epoch 19, Step 40, LR: 0.000724, Current Loss: 0.3014, Avg Loss: 0.3080\n",
      "Diff stats — min: -4.6366, max: 10.0000, mean: 2.6363, std: 2.4408\n",
      "\n",
      "Step 2425 — Test metrics:\n",
      "  precision@10: 0.038245033\n",
      "  recall@10: 0.038246873\n",
      "  ndcg@10: 0.040188817\n",
      "  map@10: 0.014650439\n",
      "Epoch 19, Step 60, LR: 0.000724, Current Loss: 0.3066, Avg Loss: 0.3077\n",
      "Diff stats — min: -5.0919, max: 10.0000, mean: 2.7030, std: 2.5332\n",
      "\n",
      "Epoch 19, Step 80, LR: 0.000724, Current Loss: 0.3063, Avg Loss: 0.3081\n",
      "Diff stats — min: -5.7711, max: 10.0000, mean: 2.6324, std: 2.4465\n",
      "\n",
      "Epoch 19, Step 100, LR: 0.000724, Current Loss: 0.3000, Avg Loss: 0.3079\n",
      "Diff stats — min: -5.3718, max: 10.0000, mean: 2.6889, std: 2.4710\n",
      "\n",
      "Step 2475 — Test metrics:\n",
      "  precision@10: 0.038543046\n",
      "  recall@10: 0.038543046\n",
      "  ndcg@10: 0.040399776\n",
      "  map@10: 0.014738292\n",
      "Epoch 19, Step 120, LR: 0.000724, Current Loss: 0.2915, Avg Loss: 0.3083\n",
      "Diff stats — min: -6.5920, max: 10.0000, mean: 2.6880, std: 2.4423\n",
      "\n",
      "Epoch 19 completed, Train Loss: 0.000075\n",
      "\n",
      "Epoch 20, Step 1, LR: 0.000724, Current Loss: 0.3108, Avg Loss: 0.3108\n",
      "Diff stats — min: -5.7467, max: 10.0000, mean: 2.6566, std: 2.5044\n",
      "\n",
      "Step 2508 — Test metrics:\n",
      "  precision@10: 0.038344371\n",
      "  recall@10: 0.038346210\n",
      "  ndcg@10: 0.039826908\n",
      "  map@10: 0.014221578\n",
      "Epoch 20, Step 20, LR: 0.000724, Current Loss: 0.3026, Avg Loss: 0.3075\n",
      "Diff stats — min: -5.7641, max: 10.0000, mean: 2.6759, std: 2.4820\n",
      "\n",
      "Epoch 20, Step 40, LR: 0.000724, Current Loss: 0.3189, Avg Loss: 0.3084\n",
      "Diff stats — min: -5.6369, max: 10.0000, mean: 2.6351, std: 2.4940\n",
      "\n",
      "Step 2557 — Test metrics:\n",
      "  precision@10: 0.038327815\n",
      "  recall@10: 0.038327815\n",
      "  ndcg@10: 0.040081538\n",
      "  map@10: 0.014548979\n",
      "Epoch 20, Step 60, LR: 0.000709, Current Loss: 0.3150, Avg Loss: 0.3084\n",
      "Diff stats — min: -5.9509, max: 10.0000, mean: 2.6303, std: 2.4839\n",
      "\n",
      "Epoch 20, Step 80, LR: 0.000709, Current Loss: 0.3094, Avg Loss: 0.3081\n",
      "Diff stats — min: -6.1975, max: 10.0000, mean: 2.6756, std: 2.5247\n",
      "\n",
      "Epoch 20, Step 100, LR: 0.000709, Current Loss: 0.3272, Avg Loss: 0.3080\n",
      "Diff stats — min: -5.4637, max: 10.0000, mean: 2.5489, std: 2.4912\n",
      "\n",
      "Step 2607 — Test metrics:\n",
      "  precision@10: 0.037168874\n",
      "  recall@10: 0.037170714\n",
      "  ndcg@10: 0.038814509\n",
      "  map@10: 0.013975842\n",
      "Epoch 20, Step 120, LR: 0.000709, Current Loss: 0.3020, Avg Loss: 0.3076\n",
      "Diff stats — min: -4.5855, max: 10.0000, mean: 2.7177, std: 2.5179\n",
      "\n",
      "Epoch 20 completed, Train Loss: 0.000075\n",
      "\n",
      "Epoch 21, Step 1, LR: 0.000709, Current Loss: 0.2954, Avg Loss: 0.2954\n",
      "Diff stats — min: -4.6046, max: 10.0000, mean: 2.6648, std: 2.4459\n",
      "\n",
      "Step 2640 — Test metrics:\n",
      "  precision@10: 0.037268212\n",
      "  recall@10: 0.037270052\n",
      "  ndcg@10: 0.038384115\n",
      "  map@10: 0.013583561\n",
      "Epoch 21, Step 20, LR: 0.000709, Current Loss: 0.3102, Avg Loss: 0.3064\n",
      "Diff stats — min: -4.4566, max: 10.0000, mean: 2.7027, std: 2.5422\n",
      "\n",
      "Epoch 21, Step 40, LR: 0.000709, Current Loss: 0.3029, Avg Loss: 0.3071\n",
      "Diff stats — min: -4.9416, max: 10.0000, mean: 2.6701, std: 2.4933\n",
      "\n",
      "Step 2689 — Test metrics:\n",
      "  precision@10: 0.039023179\n",
      "  recall@10: 0.039023179\n",
      "  ndcg@10: 0.041103841\n",
      "  map@10: 0.014822427\n",
      "Epoch 21, Step 60, LR: 0.000709, Current Loss: 0.3089, Avg Loss: 0.3071\n",
      "Diff stats — min: -4.9465, max: 10.0000, mean: 2.6852, std: 2.5366\n",
      "\n",
      "Epoch 21, Step 80, LR: 0.000695, Current Loss: 0.3009, Avg Loss: 0.3079\n",
      "Diff stats — min: -4.7437, max: 10.0000, mean: 2.6675, std: 2.4751\n",
      "\n",
      "Epoch 21, Step 100, LR: 0.000695, Current Loss: 0.3053, Avg Loss: 0.3075\n",
      "Diff stats — min: -4.9254, max: 10.0000, mean: 2.7660, std: 2.5755\n",
      "\n",
      "Step 2739 — Test metrics:\n",
      "  precision@10: 0.038592715\n",
      "  recall@10: 0.038594555\n",
      "  ndcg@10: 0.040218054\n",
      "  map@10: 0.014418414\n",
      "Epoch 21, Step 120, LR: 0.000695, Current Loss: 0.3101, Avg Loss: 0.3077\n",
      "Diff stats — min: -6.2143, max: 10.0000, mean: 2.6853, std: 2.5448\n",
      "\n",
      "Epoch 21 completed, Train Loss: 0.000075\n",
      "\n",
      "Epoch 22, Step 1, LR: 0.000695, Current Loss: 0.3048, Avg Loss: 0.3048\n",
      "Diff stats — min: -4.7200, max: 10.0000, mean: 2.7212, std: 2.5554\n",
      "\n",
      "Step 2772 — Test metrics:\n",
      "  precision@10: 0.037400662\n",
      "  recall@10: 0.037404341\n",
      "  ndcg@10: 0.038771953\n",
      "  map@10: 0.013988472\n",
      "Epoch 22, Step 20, LR: 0.000695, Current Loss: 0.3048, Avg Loss: 0.3062\n",
      "Diff stats — min: -5.1883, max: 10.0000, mean: 2.6915, std: 2.5199\n",
      "\n",
      "Epoch 22, Step 40, LR: 0.000695, Current Loss: 0.3144, Avg Loss: 0.3066\n",
      "Diff stats — min: -5.1205, max: 10.0000, mean: 2.6628, std: 2.5362\n",
      "\n",
      "Step 2821 — Test metrics:\n",
      "  precision@10: 0.037897351\n",
      "  recall@10: 0.037897351\n",
      "  ndcg@10: 0.039532379\n",
      "  map@10: 0.014372563\n",
      "Epoch 22, Step 60, LR: 0.000695, Current Loss: 0.3148, Avg Loss: 0.3069\n",
      "Diff stats — min: -5.4990, max: 10.0000, mean: 2.6870, std: 2.5624\n",
      "\n",
      "Epoch 22, Step 80, LR: 0.000681, Current Loss: 0.2919, Avg Loss: 0.3063\n",
      "Diff stats — min: -5.9566, max: 10.0000, mean: 2.8063, std: 2.5688\n",
      "\n",
      "Epoch 22, Step 100, LR: 0.000681, Current Loss: 0.3016, Avg Loss: 0.3060\n",
      "Diff stats — min: -7.2713, max: 10.0000, mean: 2.7823, std: 2.5930\n",
      "\n",
      "Step 2871 — Test metrics:\n",
      "  precision@10: 0.038211921\n",
      "  recall@10: 0.038213760\n",
      "  ndcg@10: 0.039752032\n",
      "  map@10: 0.014246150\n",
      "Epoch 22, Step 120, LR: 0.000681, Current Loss: 0.2985, Avg Loss: 0.3058\n",
      "Diff stats — min: -6.3384, max: 10.0000, mean: 2.7504, std: 2.5506\n",
      "\n",
      "Epoch 22 completed, Train Loss: 0.000075\n",
      "\n",
      "Epoch 23, Step 1, LR: 0.000681, Current Loss: 0.3044, Avg Loss: 0.3044\n",
      "Diff stats — min: -5.9015, max: 10.0000, mean: 2.7428, std: 2.5841\n",
      "\n",
      "Step 2904 — Test metrics:\n",
      "  precision@10: 0.037731788\n",
      "  recall@10: 0.037731788\n",
      "  ndcg@10: 0.039316887\n",
      "  map@10: 0.014170076\n",
      "Epoch 23, Step 20, LR: 0.000681, Current Loss: 0.3122, Avg Loss: 0.3046\n",
      "Diff stats — min: -5.1099, max: 10.0000, mean: 2.6589, std: 2.5378\n",
      "\n",
      "Epoch 23, Step 40, LR: 0.000681, Current Loss: 0.3116, Avg Loss: 0.3039\n",
      "Diff stats — min: -5.8413, max: 10.0000, mean: 2.6984, std: 2.5790\n",
      "\n",
      "Step 2953 — Test metrics:\n",
      "  precision@10: 0.038211921\n",
      "  recall@10: 0.038211921\n",
      "  ndcg@10: 0.039307411\n",
      "  map@10: 0.014054491\n",
      "Epoch 23, Step 60, LR: 0.000681, Current Loss: 0.3143, Avg Loss: 0.3037\n",
      "Diff stats — min: -5.3260, max: 10.0000, mean: 2.7189, std: 2.6158\n",
      "\n",
      "Epoch 23, Step 80, LR: 0.000681, Current Loss: 0.3051, Avg Loss: 0.3038\n",
      "Diff stats — min: -4.6552, max: 10.0000, mean: 2.7118, std: 2.5658\n",
      "\n",
      "Epoch 23, Step 100, LR: 0.000668, Current Loss: 0.2944, Avg Loss: 0.3041\n",
      "Diff stats — min: -6.1679, max: 10.0000, mean: 2.7550, std: 2.5368\n",
      "\n",
      "Step 3003 — Test metrics:\n",
      "  precision@10: 0.037135762\n",
      "  recall@10: 0.037139441\n",
      "  ndcg@10: 0.039426499\n",
      "  map@10: 0.014452001\n",
      "Epoch 23, Step 120, LR: 0.000668, Current Loss: 0.3012, Avg Loss: 0.3041\n",
      "Diff stats — min: -4.7287, max: 10.0000, mean: 2.7020, std: 2.5364\n",
      "\n",
      "Epoch 23 completed, Train Loss: 0.000074\n",
      "\n",
      "Epoch 24, Step 1, LR: 0.000668, Current Loss: 0.2957, Avg Loss: 0.2957\n",
      "Diff stats — min: -5.2318, max: 10.0000, mean: 2.7788, std: 2.5798\n",
      "\n",
      "Step 3036 — Test metrics:\n",
      "  precision@10: 0.037781457\n",
      "  recall@10: 0.037783297\n",
      "  ndcg@10: 0.039027902\n",
      "  map@10: 0.013901024\n",
      "Epoch 24, Step 20, LR: 0.000668, Current Loss: 0.2961, Avg Loss: 0.3013\n",
      "Diff stats — min: -5.4527, max: 10.0000, mean: 2.7551, std: 2.5591\n",
      "\n",
      "Epoch 24, Step 40, LR: 0.000668, Current Loss: 0.3003, Avg Loss: 0.3004\n",
      "Diff stats — min: -4.9911, max: 10.0000, mean: 2.8404, std: 2.6659\n",
      "\n",
      "Step 3085 — Test metrics:\n",
      "  precision@10: 0.037268212\n",
      "  recall@10: 0.037271891\n",
      "  ndcg@10: 0.038496010\n",
      "  map@10: 0.013749994\n",
      "Epoch 24, Step 60, LR: 0.000668, Current Loss: 0.2942, Avg Loss: 0.3010\n",
      "Diff stats — min: -6.2852, max: 10.0000, mean: 2.8086, std: 2.5884\n",
      "\n",
      "Epoch 24, Step 80, LR: 0.000668, Current Loss: 0.2975, Avg Loss: 0.3011\n",
      "Diff stats — min: -9.5862, max: 10.0000, mean: 2.7834, std: 2.6044\n",
      "\n",
      "Epoch 24, Step 100, LR: 0.000668, Current Loss: 0.2879, Avg Loss: 0.3013\n",
      "Diff stats — min: -6.2489, max: 10.0000, mean: 2.8373, std: 2.5969\n",
      "\n",
      "Step 3135 — Test metrics:\n",
      "  precision@10: 0.037566225\n",
      "  recall@10: 0.037566225\n",
      "  ndcg@10: 0.038593006\n",
      "  map@10: 0.013651392\n",
      "Epoch 24, Step 120, LR: 0.000654, Current Loss: 0.3078, Avg Loss: 0.3016\n",
      "Diff stats — min: -5.5897, max: 10.0000, mean: 2.7144, std: 2.5818\n",
      "\n",
      "Epoch 24 completed, Train Loss: 0.000074\n",
      "\n",
      "Epoch 25, Step 1, LR: 0.000654, Current Loss: 0.2922, Avg Loss: 0.2922\n",
      "Diff stats — min: -5.0412, max: 10.0000, mean: 2.8364, std: 2.5993\n",
      "\n",
      "Step 3168 — Test metrics:\n",
      "  precision@10: 0.037135762\n",
      "  recall@10: 0.037137601\n",
      "  ndcg@10: 0.038355989\n",
      "  map@10: 0.013599890\n",
      "Epoch 25, Step 20, LR: 0.000654, Current Loss: 0.2990, Avg Loss: 0.2996\n",
      "Diff stats — min: -5.6650, max: 10.0000, mean: 2.7686, std: 2.6047\n",
      "\n",
      "Epoch 25, Step 40, LR: 0.000654, Current Loss: 0.2940, Avg Loss: 0.3009\n",
      "Diff stats — min: -4.9405, max: 10.0000, mean: 2.7922, std: 2.6007\n",
      "\n",
      "Step 3217 — Test metrics:\n",
      "  precision@10: 0.037201987\n",
      "  recall@10: 0.037203826\n",
      "  ndcg@10: 0.038783804\n",
      "  map@10: 0.013869711\n",
      "Epoch 25, Step 60, LR: 0.000654, Current Loss: 0.2954, Avg Loss: 0.3014\n",
      "Diff stats — min: -4.8894, max: 10.0000, mean: 2.8018, std: 2.6086\n",
      "\n",
      "Epoch 25, Step 80, LR: 0.000654, Current Loss: 0.3124, Avg Loss: 0.3016\n",
      "Diff stats — min: -4.7512, max: 10.0000, mean: 2.7585, std: 2.6414\n",
      "\n",
      "Epoch 25, Step 100, LR: 0.000654, Current Loss: 0.2848, Avg Loss: 0.3007\n",
      "Diff stats — min: -7.1116, max: 10.0000, mean: 2.8565, std: 2.6038\n",
      "\n",
      "Step 3267 — Test metrics:\n",
      "  precision@10: 0.037980132\n",
      "  recall@10: 0.037981972\n",
      "  ndcg@10: 0.039743574\n",
      "  map@10: 0.014502142\n",
      "Epoch 25, Step 120, LR: 0.000654, Current Loss: 0.3082, Avg Loss: 0.3010\n",
      "Diff stats — min: -5.8499, max: 10.0000, mean: 2.7496, std: 2.6053\n",
      "\n",
      "Epoch 25 completed, Train Loss: 0.000074\n",
      "\n",
      "Epoch 26, Step 1, LR: 0.000641, Current Loss: 0.2877, Avg Loss: 0.2877\n",
      "Diff stats — min: -4.5567, max: 10.0000, mean: 2.8087, std: 2.5808\n",
      "\n",
      "Step 3300 — Test metrics:\n",
      "  precision@10: 0.038493377\n",
      "  recall@10: 0.038493377\n",
      "  ndcg@10: 0.040540919\n",
      "  map@10: 0.014710554\n",
      "Epoch 26, Step 20, LR: 0.000641, Current Loss: 0.2823, Avg Loss: 0.2947\n",
      "Diff stats — min: -5.2772, max: 10.0000, mean: 2.8800, std: 2.6335\n",
      "\n",
      "Epoch 26, Step 40, LR: 0.000641, Current Loss: 0.2994, Avg Loss: 0.2967\n",
      "Diff stats — min: -4.8296, max: 10.0000, mean: 2.8687, std: 2.6474\n",
      "\n",
      "Step 3349 — Test metrics:\n",
      "  precision@10: 0.037152318\n",
      "  recall@10: 0.037154157\n",
      "  ndcg@10: 0.038689431\n",
      "  map@10: 0.013705099\n",
      "Epoch 26, Step 60, LR: 0.000641, Current Loss: 0.3060, Avg Loss: 0.2968\n",
      "Diff stats — min: -4.5422, max: 10.0000, mean: 2.7993, std: 2.6576\n",
      "\n",
      "Epoch 26, Step 80, LR: 0.000641, Current Loss: 0.2921, Avg Loss: 0.2969\n",
      "Diff stats — min: -4.9057, max: 10.0000, mean: 2.8616, std: 2.6705\n",
      "\n",
      "Epoch 26, Step 100, LR: 0.000641, Current Loss: 0.2852, Avg Loss: 0.2973\n",
      "Diff stats — min: -4.5068, max: 10.0000, mean: 2.9211, std: 2.6810\n",
      "\n",
      "Step 3399 — Test metrics:\n",
      "  precision@10: 0.036605960\n",
      "  recall@10: 0.036609639\n",
      "  ndcg@10: 0.037760479\n",
      "  map@10: 0.013337700\n",
      "Epoch 26, Step 120, LR: 0.000641, Current Loss: 0.2911, Avg Loss: 0.2978\n",
      "Diff stats — min: -7.0682, max: 10.0000, mean: 2.8435, std: 2.6279\n",
      "\n",
      "Epoch 26 completed, Train Loss: 0.000073\n",
      "\n",
      "Epoch 27, Step 1, LR: 0.000641, Current Loss: 0.3019, Avg Loss: 0.3019\n",
      "Diff stats — min: -4.4667, max: 10.0000, mean: 2.8976, std: 2.7285\n",
      "\n",
      "Step 3432 — Test metrics:\n",
      "  precision@10: 0.036804636\n",
      "  recall@10: 0.036806475\n",
      "  ndcg@10: 0.038294056\n",
      "  map@10: 0.013647877\n",
      "Epoch 27, Step 20, LR: 0.000628, Current Loss: 0.2928, Avg Loss: 0.2993\n",
      "Diff stats — min: -6.0569, max: 10.0000, mean: 2.8139, std: 2.6207\n",
      "\n",
      "Epoch 27, Step 40, LR: 0.000628, Current Loss: 0.2988, Avg Loss: 0.2982\n",
      "Diff stats — min: -4.5232, max: 10.0000, mean: 2.8359, std: 2.6483\n",
      "\n",
      "Step 3481 — Test metrics:\n",
      "  precision@10: 0.037019868\n",
      "  recall@10: 0.037023547\n",
      "  ndcg@10: 0.038481486\n",
      "  map@10: 0.013768778\n",
      "Epoch 27, Step 60, LR: 0.000628, Current Loss: 0.2993, Avg Loss: 0.2980\n",
      "Diff stats — min: -5.8654, max: 10.0000, mean: 2.7892, std: 2.6287\n",
      "\n",
      "Epoch 27, Step 80, LR: 0.000628, Current Loss: 0.3067, Avg Loss: 0.2981\n",
      "Diff stats — min: -5.6491, max: 10.0000, mean: 2.7899, std: 2.6700\n",
      "\n",
      "Epoch 27, Step 100, LR: 0.000628, Current Loss: 0.3052, Avg Loss: 0.2980\n",
      "Diff stats — min: -7.1229, max: 10.0000, mean: 2.8405, std: 2.6938\n",
      "\n",
      "Step 3531 — Test metrics:\n",
      "  precision@10: 0.036539735\n",
      "  recall@10: 0.036541575\n",
      "  ndcg@10: 0.038024307\n",
      "  map@10: 0.013534178\n",
      "Epoch 27, Step 120, LR: 0.000628, Current Loss: 0.3041, Avg Loss: 0.2980\n",
      "Diff stats — min: -6.0708, max: 10.0000, mean: 2.8218, std: 2.6934\n",
      "\n",
      "Epoch 27 completed, Train Loss: 0.000073\n",
      "\n",
      "Epoch 28, Step 1, LR: 0.000628, Current Loss: 0.2745, Avg Loss: 0.2745\n",
      "Diff stats — min: -5.2678, max: 10.0000, mean: 2.9720, std: 2.6895\n",
      "\n",
      "Step 3564 — Test metrics:\n",
      "  precision@10: 0.036192053\n",
      "  recall@10: 0.036193893\n",
      "  ndcg@10: 0.037962232\n",
      "  map@10: 0.013704595\n",
      "Epoch 28, Step 20, LR: 0.000628, Current Loss: 0.2980, Avg Loss: 0.2934\n",
      "Diff stats — min: -6.4781, max: 10.0000, mean: 2.9175, std: 2.7234\n",
      "\n",
      "Epoch 28, Step 40, LR: 0.000616, Current Loss: 0.3054, Avg Loss: 0.2941\n",
      "Diff stats — min: -5.4032, max: 10.0000, mean: 2.8212, std: 2.6862\n",
      "\n",
      "Step 3613 — Test metrics:\n",
      "  precision@10: 0.036274834\n",
      "  recall@10: 0.036278514\n",
      "  ndcg@10: 0.037422066\n",
      "  map@10: 0.013253955\n",
      "Epoch 28, Step 60, LR: 0.000616, Current Loss: 0.2970, Avg Loss: 0.2939\n",
      "Diff stats — min: -5.4856, max: 10.0000, mean: 2.9421, std: 2.7316\n",
      "\n",
      "Epoch 28, Step 80, LR: 0.000616, Current Loss: 0.2974, Avg Loss: 0.2941\n",
      "Diff stats — min: -5.7063, max: 10.0000, mean: 2.8781, std: 2.6983\n",
      "\n",
      "Epoch 28, Step 100, LR: 0.000616, Current Loss: 0.2906, Avg Loss: 0.2938\n",
      "Diff stats — min: -6.0838, max: 10.0000, mean: 2.8930, std: 2.6668\n",
      "\n",
      "Step 3663 — Test metrics:\n",
      "  precision@10: 0.036804636\n",
      "  recall@10: 0.036810155\n",
      "  ndcg@10: 0.038272531\n",
      "  map@10: 0.013679866\n",
      "Epoch 28, Step 120, LR: 0.000616, Current Loss: 0.2992, Avg Loss: 0.2939\n",
      "Diff stats — min: -4.6919, max: 10.0000, mean: 2.9311, std: 2.7680\n",
      "\n",
      "Epoch 28 completed, Train Loss: 0.000072\n",
      "\n",
      "Epoch 29, Step 1, LR: 0.000616, Current Loss: 0.2859, Avg Loss: 0.2859\n",
      "Diff stats — min: -4.7754, max: 10.0000, mean: 2.9471, std: 2.6975\n",
      "\n",
      "Step 3696 — Test metrics:\n",
      "  precision@10: 0.036589404\n",
      "  recall@10: 0.036593083\n",
      "  ndcg@10: 0.037771245\n",
      "  map@10: 0.013428433\n",
      "Epoch 29, Step 20, LR: 0.000616, Current Loss: 0.2872, Avg Loss: 0.2906\n",
      "Diff stats — min: -5.3608, max: 10.0000, mean: 2.9345, std: 2.7113\n",
      "\n",
      "Epoch 29, Step 40, LR: 0.000616, Current Loss: 0.2877, Avg Loss: 0.2912\n",
      "Diff stats — min: -7.1951, max: 10.0000, mean: 2.9114, std: 2.6845\n",
      "\n",
      "Step 3745 — Test metrics:\n",
      "  precision@10: 0.037980132\n",
      "  recall@10: 0.037983812\n",
      "  ndcg@10: 0.039021895\n",
      "  map@10: 0.013872306\n",
      "Epoch 29, Step 60, LR: 0.000603, Current Loss: 0.3112, Avg Loss: 0.2920\n",
      "Diff stats — min: -5.5198, max: 10.0000, mean: 2.8286, std: 2.7162\n",
      "\n",
      "Epoch 29, Step 80, LR: 0.000603, Current Loss: 0.2833, Avg Loss: 0.2914\n",
      "Diff stats — min: -5.1712, max: 10.0000, mean: 2.9584, std: 2.6978\n",
      "\n",
      "Epoch 29, Step 100, LR: 0.000603, Current Loss: 0.2881, Avg Loss: 0.2920\n",
      "Diff stats — min: -5.2926, max: 10.0000, mean: 2.9471, std: 2.6982\n",
      "\n",
      "Step 3795 — Test metrics:\n",
      "  precision@10: 0.035927152\n",
      "  recall@10: 0.035930831\n",
      "  ndcg@10: 0.037404679\n",
      "  map@10: 0.013352748\n",
      "Epoch 29, Step 120, LR: 0.000603, Current Loss: 0.2834, Avg Loss: 0.2921\n",
      "Diff stats — min: -5.5460, max: 10.0000, mean: 2.9464, std: 2.7056\n",
      "\n",
      "Epoch 29 completed, Train Loss: 0.000071\n",
      "\n",
      "Epoch 30, Step 1, LR: 0.000603, Current Loss: 0.3025, Avg Loss: 0.3025\n",
      "Diff stats — min: -5.7418, max: 10.0000, mean: 2.9173, std: 2.7915\n",
      "\n",
      "Step 3828 — Test metrics:\n",
      "  precision@10: 0.036639073\n",
      "  recall@10: 0.036640912\n",
      "  ndcg@10: 0.037865408\n",
      "  map@10: 0.013427073\n",
      "Epoch 30, Step 20, LR: 0.000603, Current Loss: 0.3001, Avg Loss: 0.2898\n",
      "Diff stats — min: -5.1285, max: 10.0000, mean: 2.9261, std: 2.7534\n",
      "\n",
      "Epoch 30, Step 40, LR: 0.000603, Current Loss: 0.2819, Avg Loss: 0.2891\n",
      "Diff stats — min: -6.3758, max: 10.0000, mean: 2.9390, std: 2.6828\n",
      "\n",
      "Step 3877 — Test metrics:\n",
      "  precision@10: 0.036158940\n",
      "  recall@10: 0.036160780\n",
      "  ndcg@10: 0.037612916\n",
      "  map@10: 0.013447940\n",
      "Epoch 30, Step 60, LR: 0.000603, Current Loss: 0.2981, Avg Loss: 0.2893\n",
      "Diff stats — min: -5.2638, max: 10.0000, mean: 2.9594, std: 2.7598\n",
      "\n",
      "Epoch 30, Step 80, LR: 0.000591, Current Loss: 0.2854, Avg Loss: 0.2888\n",
      "Diff stats — min: -5.7178, max: 10.0000, mean: 3.0317, std: 2.7647\n",
      "\n",
      "Epoch 30, Step 100, LR: 0.000591, Current Loss: 0.2991, Avg Loss: 0.2891\n",
      "Diff stats — min: -4.6690, max: 10.0000, mean: 2.9486, std: 2.7661\n",
      "\n",
      "Step 3927 — Test metrics:\n",
      "  precision@10: 0.037500000\n",
      "  recall@10: 0.037501840\n",
      "  ndcg@10: 0.039038603\n",
      "  map@10: 0.013905084\n",
      "Epoch 30, Step 120, LR: 0.000591, Current Loss: 0.2758, Avg Loss: 0.2890\n",
      "Diff stats — min: -5.4367, max: 10.0000, mean: 3.0268, std: 2.7215\n",
      "\n",
      "Epoch 30 completed, Train Loss: 0.000071\n",
      "\n",
      "Epoch 31, Step 1, LR: 0.000591, Current Loss: 0.3012, Avg Loss: 0.3012\n",
      "Diff stats — min: -7.2620, max: 10.0000, mean: 2.9102, std: 2.7692\n",
      "\n",
      "Step 3960 — Test metrics:\n",
      "  precision@10: 0.037417219\n",
      "  recall@10: 0.037417219\n",
      "  ndcg@10: 0.038435553\n",
      "  map@10: 0.013657561\n",
      "Epoch 31, Step 20, LR: 0.000591, Current Loss: 0.2801, Avg Loss: 0.2884\n",
      "Diff stats — min: -7.0961, max: 10.0000, mean: 2.9989, std: 2.7316\n",
      "\n",
      "Epoch 31, Step 40, LR: 0.000591, Current Loss: 0.2848, Avg Loss: 0.2876\n",
      "Diff stats — min: -5.4947, max: 10.0000, mean: 3.0142, std: 2.7496\n",
      "\n",
      "Step 4009 — Test metrics:\n",
      "  precision@10: 0.038062914\n",
      "  recall@10: 0.038062914\n",
      "  ndcg@10: 0.038918953\n",
      "  map@10: 0.013762733\n",
      "Epoch 31, Step 60, LR: 0.000591, Current Loss: 0.2885, Avg Loss: 0.2867\n",
      "Diff stats — min: -4.9762, max: 10.0000, mean: 2.9791, std: 2.7427\n",
      "\n",
      "Epoch 31, Step 80, LR: 0.000591, Current Loss: 0.2887, Avg Loss: 0.2869\n",
      "Diff stats — min: -5.1414, max: 10.0000, mean: 2.9869, std: 2.7531\n",
      "\n",
      "Epoch 31, Step 100, LR: 0.000580, Current Loss: 0.3000, Avg Loss: 0.2869\n",
      "Diff stats — min: -6.7079, max: 10.0000, mean: 2.9791, std: 2.7987\n",
      "\n",
      "Step 4059 — Test metrics:\n",
      "  precision@10: 0.038509934\n",
      "  recall@10: 0.038509934\n",
      "  ndcg@10: 0.039410131\n",
      "  map@10: 0.014008475\n",
      "Epoch 31, Step 120, LR: 0.000580, Current Loss: 0.2759, Avg Loss: 0.2872\n",
      "Diff stats — min: -4.5109, max: 10.0000, mean: 3.0157, std: 2.7019\n",
      "\n",
      "Epoch 31 completed, Train Loss: 0.000070\n",
      "\n",
      "Epoch 32, Step 1, LR: 0.000580, Current Loss: 0.2722, Avg Loss: 0.2722\n",
      "Diff stats — min: -4.7174, max: 10.0000, mean: 3.0261, std: 2.7185\n",
      "\n",
      "Step 4092 — Test metrics:\n",
      "  precision@10: 0.037549669\n",
      "  recall@10: 0.037553348\n",
      "  ndcg@10: 0.039305181\n",
      "  map@10: 0.014203558\n",
      "Epoch 32, Step 20, LR: 0.000580, Current Loss: 0.2863, Avg Loss: 0.2844\n",
      "Diff stats — min: -6.9713, max: 10.0000, mean: 3.0355, std: 2.7685\n",
      "\n",
      "Epoch 32, Step 40, LR: 0.000580, Current Loss: 0.2909, Avg Loss: 0.2873\n",
      "Diff stats — min: -5.3422, max: 10.0000, mean: 2.9686, std: 2.7749\n",
      "\n",
      "Step 4141 — Test metrics:\n",
      "  precision@10: 0.037400662\n",
      "  recall@10: 0.037402502\n",
      "  ndcg@10: 0.039143439\n",
      "  map@10: 0.014107584\n",
      "Epoch 32, Step 60, LR: 0.000580, Current Loss: 0.2853, Avg Loss: 0.2861\n",
      "Diff stats — min: -5.4257, max: 10.0000, mean: 3.0123, std: 2.7653\n",
      "\n",
      "Epoch 32, Step 80, LR: 0.000580, Current Loss: 0.2957, Avg Loss: 0.2865\n",
      "Diff stats — min: -5.7429, max: 10.0000, mean: 2.9232, std: 2.7127\n",
      "\n",
      "Epoch 32, Step 100, LR: 0.000580, Current Loss: 0.2809, Avg Loss: 0.2858\n",
      "Diff stats — min: -5.4057, max: 10.0000, mean: 3.1043, std: 2.8094\n",
      "\n",
      "Step 4191 — Test metrics:\n",
      "  precision@10: 0.037168874\n",
      "  recall@10: 0.037170714\n",
      "  ndcg@10: 0.038723675\n",
      "  map@10: 0.013978805\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/1841242746.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtrain_scheduler_gamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_scheduler_gamma'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m model = train_model(model,\n\u001b[0m\u001b[1;32m     24\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mseq_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/1892270750.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, seq_train_data, edge_type, num_epochs, lr, batch_size, device, print_every, test_every, top_k, test_batch_size, scheduler_step_size, scheduler_gamma)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             user_embs = model(data=train_data, \n\u001b[0m\u001b[1;32m     62\u001b[0m                               \u001b[0mseq_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_ids_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                               \u001b[0mseq_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_times_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/1645146296.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, seq_ids, seq_times, seq_mask, batch_users)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Sequence encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mseq_item_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, L, d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mattn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_item_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mseq_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m        \u001b[0;31m# [B, d_model]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Get static user embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/1104076740.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, emb, times, mask)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpe\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mattn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Residual connection + normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/1104076740.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpe\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mte\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mattn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Residual connection + normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/1104076740.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, emb, times, mask)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaN/Inf в q:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NaN/Inf в k:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    feedback_types=feedback_types,\n",
    "    d_model=d_model,\n",
    "    n_head=n_head,\n",
    "    window_size=window_size,\n",
    "    decay=decay,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "edge_type = hyperparameters['train_edge_type']\n",
    "num_epochs = hyperparameters['train_num_epochs']\n",
    "lr = hyperparameters['train_lr']\n",
    "batch_size = hyperparameters['train_batch_size']\n",
    "print_every = hyperparameters['train_print_every']\n",
    "test_every = hyperparameters['train_test_every']\n",
    "top_k = hyperparameters['test_topk']\n",
    "test_batch_size = hyperparameters['test_batch_size']\n",
    "scheduler_step_size = hyperparameters['train_scheduler_step_size']\n",
    "train_scheduler_gamma = hyperparameters['train_scheduler_gamma']\n",
    "\n",
    "model = train_model(model,\n",
    "                    data,\n",
    "                    (seq_ids, event_type, seq_times, seq_mask),\n",
    "                    edge_type=edge_type,\n",
    "                    num_epochs=num_epochs,\n",
    "                    lr=lr,\n",
    "                    batch_size=batch_size,\n",
    "                    print_every=print_every,\n",
    "                    test_every=test_every,\n",
    "                    top_k=top_k,\n",
    "                    test_batch_size=test_batch_size,\n",
    "                    scheduler_step_size=scheduler_step_size,\n",
    "                    scheduler_gamma=train_scheduler_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:25:37.079558Z",
     "iopub.status.busy": "2025-06-24T22:25:37.079010Z",
     "iopub.status.idle": "2025-06-24T22:25:37.120444Z",
     "shell.execute_reply": "2025-06-24T22:25:37.119682Z",
     "shell.execute_reply.started": "2025-06-24T22:25:37.079534Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='gnn_model_mvl.model' target='_blank'>gnn_model_mvl.model</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/gnn_model_mvl.model"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model, \"gnn_model_mvl.model\")\n",
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('gnn_model_mvl.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:25:37.531165Z",
     "iopub.status.busy": "2025-06-24T22:25:37.530463Z",
     "iopub.status.idle": "2025-06-24T22:25:37.843853Z",
     "shell.execute_reply": "2025-06-24T22:25:37.843028Z",
     "shell.execute_reply.started": "2025-06-24T22:25:37.531139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:25:38.655099Z",
     "iopub.status.busy": "2025-06-24T22:25:38.654229Z",
     "iopub.status.idle": "2025-06-24T22:25:38.948197Z",
     "shell.execute_reply": "2025-06-24T22:25:38.947480Z",
     "shell.execute_reply.started": "2025-06-24T22:25:38.655063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "log_model(\n",
    "    experiment=experiment,\n",
    "    model=model,\n",
    "    model_name=\"GNN+THP\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T22:25:38.989869Z",
     "iopub.status.busy": "2025-06-24T22:25:38.989581Z",
     "iopub.status.idle": "2025-06-24T22:25:42.936972Z",
     "shell.execute_reply": "2025-06-24T22:25:42.936346Z",
     "shell.execute_reply.started": "2025-06-24T22:25:38.989848Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : emoSAGE+THP-movielens\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/annanet/gnn-recommender/63f8eff601f84d4191b0dbc3136908bd\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Diff stats (mean) vs step [223] : (-0.5097155570983887, 3.10430908203125)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Diff stats (std) vs step [223]  : (1.3237004280090332, 8.133367538452148)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test map@10 vs step [96]        : (0.0006422724166929466, 0.01567700777882897)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test ndcg@10 vs step [96]       : (0.0022782769186490684, 0.04195517198287384)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test precision@10 vs step [96]  : (0.0023841059602649007, 0.03955298013245033)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Test recall@10 vs step [96]     : (0.0023841059602649007, 0.039554819720382633)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Train Loss vs epoch [31]        : (7.030746030448932e-05, 0.0003967423951331505)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Train Loss vs step [4202]       : (0.2625778615474701, 4.029974937438965)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [421]                      : (0.26900458335876465, 4.029974937438965)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name : emoSAGE+THP-movielens\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     cls_id                    : 3701\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     max_len_of_thp_history    : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     pad_id                    : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     seed                      : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_batch_size           : 8192\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_topk                 : 10\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     thp_decay                 : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     thp_dmodel                : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     thp_dropout               : 0.2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     thp_n_head                : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     thp_window_size           : 101\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_batch_size          : 4096\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_edge_type           : [('item', 'to_feedback_explicit_positive', 'explicit_positive'), ('item', 'to_feedback_implicit_positive', 'implicit_positive')]\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_lr                  : 0.001\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_num_epochs          : 200\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_print_every         : 20\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_scheduler_gamma     : 0.98\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_scheduler_step_size : 150\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_test_every          : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     types_of_feedback         : ['explicit_positive', 'expliсit_negative', 'implicit_positive', 'implicit_negative']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element       : 2 (8.96 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 1 metrics, params and output messages\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 file(s), remaining 3.06 MB/8.96 MB\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7705289,
     "sourceId": 12229447,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
